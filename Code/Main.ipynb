{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_so = os.path.join(path_dataset, 'Stack Overflow')\n",
    "path_ts = os.path.join(path_dataset, 'Tool-specific Others')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')  \n",
    "\n",
    "path_so_raw = os.path.join(path_so, 'Raw')\n",
    "path_ts_raw = os.path.join(path_ts, 'Raw')\n",
    "path_so_filtered = os.path.join(path_so, 'Filtered')\n",
    "path_ts_filtered = os.path.join(path_ts, 'Filtered')\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "if not os.path.isdir(path_so):\n",
    "    os.mkdir(path_so)\n",
    "\n",
    "if not os.path.isdir(path_ts):\n",
    "    os.mkdir(path_ts)\n",
    "\n",
    "if not os.path.isdir(path_labeling):\n",
    "    os.mkdir(path_labeling)\n",
    "\n",
    "if not os.path.isdir(path_so_raw):\n",
    "    os.mkdir(path_so_raw)\n",
    "\n",
    "if not os.path.isdir(path_ts_raw):\n",
    "    os.mkdir(path_ts_raw)\n",
    "\n",
    "if not os.path.isdir(path_so_filtered):\n",
    "    os.mkdir(path_so_filtered)\n",
    "\n",
    "if not os.path.isdir(path_ts_filtered):\n",
    "    os.mkdir(path_ts_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2tag = {\n",
    "    'Amazon SageMaker': {'amazon-sagemaker', 'amazon-sagemaker-experiments', 'amazon-sagemaker-studio'},\n",
    "    'Azure Machine Learning': {'azure-machine-learning-service', 'azure-machine-learning-studio', 'azure-machine-learning-workbench'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'Comet': {'comet-ml'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Kedro': {'kedro'},\n",
    "    'MLflow': {'mlflow'},\n",
    "    'MLRun': {'mlrun'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Optuna': {'optuna'},\n",
    "    'Sacred': {'python-sacred'},\n",
    "    'Vertex AI': {'google-cloud-vertex-ai'},\n",
    "    'Weights & Biases': {'wandb'}\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Amazon SageMaker': ['amazon sagemaker', 'aws sagemaker', 'sagemaker'],\n",
    "    'Azure Machine Learning': ['microsoft azure machine learning', 'azure machine learning', 'microsoft azure ml', 'microsoft azureml', 'azure ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'Comet': ['comet'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Optuna': ['optuna'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Vertex AI': ['google vertex ai', 'vertex ai'],\n",
    "    'Weights & Biases': ['weights & biases', 'weights and biases', 'wandb']\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# function to scrape the posts from the tool-specific discussion fora\n",
    "\n",
    "\n",
    "def scrape_post(base_url, page_suffix, file_name):\n",
    "    page = -1\n",
    "    post_list = []\n",
    "\n",
    "    while True:\n",
    "        page = page + 1\n",
    "        page_url = base_url + page_suffix + str(page)\n",
    "        topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "        for topic in topic_list['topics']:\n",
    "            post_url = base_url + 't/' + \\\n",
    "                topic['slug'] + '/' + str(topic['id'])\n",
    "\n",
    "            post = {}\n",
    "            post['Question_title'] = topic['title']\n",
    "            post['Question_link'] = post_url\n",
    "            post['Question_creation_time'] = topic['created_at']\n",
    "            post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "            post['Question_score'] = topic['like_count']\n",
    "            post['Question_view_count'] = topic['views']\n",
    "            post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "            comments = requests.get(\n",
    "                post_url + '.json').json()['post_stream']['posts']\n",
    "            post['Question_body'] = comments[0]['cooked']\n",
    "            \n",
    "            answer_list = []\n",
    "            for comment in comments[1:]:\n",
    "                answer = {}\n",
    "                answer['Answer_creation_time'] = comment['created_at']\n",
    "                answer['Answer_body'] = comment['cooked']\n",
    "                answer['Answer_score'] = comment['score']\n",
    "                answer['Answer_has_accepted'] = comment['accepted_answer']\n",
    "                answer_list.append(answer)                \n",
    "            post['Answer_list'] = answer_list\n",
    "            \n",
    "            post_list.append(post)\n",
    "            time.sleep(5)\n",
    "\n",
    "        if 'more_topics_url' not in topic_list.keys():\n",
    "            break\n",
    "\n",
    "    with open(os.path.join(path_ts_raw, file_name), 'w') as outfile:\n",
    "        json_post_list = json.dumps(post_list, indent='\\t')\n",
    "        outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Guild AI\n",
    "base_url = 'https://my.guild.ai/'\n",
    "page_suffix = 'c/troubleshooting/6.json?page='\n",
    "file_name = 'Guild AI.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Weights & Biases\n",
    "base_url = 'https://community.wandb.ai/'\n",
    "page_suffix = 'c/w-b-support/36.json?page='\n",
    "file_name = 'Weights & Biases.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from SigOpt\n",
    "base_url = 'https://community.sigopt.com/'\n",
    "page_suffix = 'c/general-discussion/9.json?page='\n",
    "file_name = 'SigOpt.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from DVC\n",
    "base_url = 'https://discuss.dvc.org/'\n",
    "page_suffix = 'c/questions/9.json?page='\n",
    "file_name = 'DVC.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# exclude tool-specific posts with negative upvote count\n",
    "df_ts_questions = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_ts_raw, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    if 'Question_score' in repos.columns:\n",
    "        repos = repos[repos['Question_score'] > -1]\n",
    "    repos['Tool'] = os.path.split(file_name)[1].split('.')[0]\n",
    "    df_ts_questions = pd.concat([df_ts_questions, repos], ignore_index=True)\n",
    "\n",
    "df_ts_questions.to_json(os.path.join(path_ts_filtered,\n",
    "                                     'questions.json'), orient='records', indent=4)\n",
    "\n",
    "# keep only posts with at least one answer\n",
    "df_ts_answers = df_ts_questions[df_ts_questions['Question_answer_count'] > 0]\n",
    "\n",
    "for tool in df_ts_answers['Tool'].unique().tolist():\n",
    "    number_accepted_answer = df_ts_answers[df_ts_answers['Tool']\n",
    "                                           == tool]['Question_has_accepted_answer'].sum()\n",
    "    if number_accepted_answer > 0:\n",
    "        df_ts_answers = df_ts_answers.drop(df_ts_answers[(df_ts_answers['Tool'] == tool) & (\n",
    "            df_ts_answers['Question_has_accepted_answer'] == False)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>348</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>735</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker        528        167\n",
       "1  Azure Machine Learning       1435        343\n",
       "2                     DVC        348        330\n",
       "3                  Domino         13          4\n",
       "4                Guild AI        118        109\n",
       "5                  MLFlow        280        143\n",
       "6                Polyaxon         43         34\n",
       "7                  SigOpt         15          7\n",
       "8               Vertex AI        297         32\n",
       "9        Weights & Biases        735        117"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_question_summary = df_ts_questions.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "df_ts_answer_summary = df_ts_answers.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "\n",
    "df_ts_question_summary.columns = ['Tool', '#Question']\n",
    "df_ts_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_ts_question_summary, df_ts_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_time</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "      <th>Question_last_edit_time</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>Question_view_count</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_time</th>\n",
       "      <th>Answer_last_edit_time</th>\n",
       "      <th>Answer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3846656</td>\n",
       "      <td>How does the 3 way merge in Mercurial/Meld work?</td>\n",
       "      <td>&lt;p&gt;I'm working on a project where I have a com...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-02 16:52:51.763000+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2012-11-02 14:42:02.530000+00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>[mercurial, merge, dvcs, 3-way-merge]</td>\n",
       "      <td>15819</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Local&lt;/strong&gt; is r133&lt;/p&gt;\\n\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-10-02 16:58:23.490000+00:00</td>\n",
       "      <td>2010-10-02 20:30:59.770000+00:00</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1745000</td>\n",
       "      <td>Can I clone part of a Mercurial repository?</td>\n",
       "      <td>&lt;p&gt;Is it possible to clone part of a Mercurial...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-11-16 21:34:33.500000+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2012-01-20 08:31:22.290000+00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>[mercurial, dvcs]</td>\n",
       "      <td>18159</td>\n",
       "      <td>&lt;p&gt;Yes you can.  I'm sure you've moved on, but...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-02-14 20:13:26.563000+00:00</td>\n",
       "      <td>2017-05-31 11:39:12+00:00</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12070220</td>\n",
       "      <td>Mercurial - cannot commit merge with missing f...</td>\n",
       "      <td>&lt;p&gt;I have done a 'hg merge' however when I att...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-22 09:33:57.333000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35</td>\n",
       "      <td>[mercurial, dvcs]</td>\n",
       "      <td>17364</td>\n",
       "      <td>&lt;p&gt;Try &lt;code&gt;hg status&lt;/code&gt; and look for fil...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-08-22 10:19:13.800000+00:00</td>\n",
       "      <td>2012-09-21 12:28:37.273000+00:00</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3981043</td>\n",
       "      <td>How to abort a merge in mercurial?</td>\n",
       "      <td>&lt;p&gt;I goofed up a merge.  I'd like to revert th...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-20 18:24:00.770000+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-07-13 16:44:14.087000+00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>[version-control, mercurial, merge, dvcs, undo]</td>\n",
       "      <td>31732</td>\n",
       "      <td>&lt;p&gt;&lt;code&gt;hg update -C &amp;lt;one of the two merge...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2010-10-20 18:28:03.953000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15056327</td>\n",
       "      <td>How do I synchronise two remote Git repositories?</td>\n",
       "      <td>&lt;p&gt;I have two repository urls, and I want to s...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-24 20:33:38.440000+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-02-24 21:08:23.193000+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>[git, version-control, github, dvcs]</td>\n",
       "      <td>58999</td>\n",
       "      <td>&lt;p&gt;Git branches do not have \"heads\" in the Mer...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013-02-24 22:33:15.687000+00:00</td>\n",
       "      <td>2013-02-25 02:21:02.693000+00:00</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                                     Question_title  \\\n",
       "0      3846656   How does the 3 way merge in Mercurial/Meld work?   \n",
       "1      1745000        Can I clone part of a Mercurial repository?   \n",
       "2     12070220  Mercurial - cannot commit merge with missing f...   \n",
       "3      3981043                 How to abort a merge in mercurial?   \n",
       "4     15056327  How do I synchronise two remote Git repositories?   \n",
       "\n",
       "                                       Question_body  Question_answer_count  \\\n",
       "0  <p>I'm working on a project where I have a com...                      2   \n",
       "1  <p>Is it possible to clone part of a Mercurial...                      8   \n",
       "2  <p>I have done a 'hg merge' however when I att...                      3   \n",
       "3  <p>I goofed up a merge.  I'd like to revert th...                      3   \n",
       "4  <p>I have two repository urls, and I want to s...                      6   \n",
       "\n",
       "   Question_comment_count           Question_creation_time  \\\n",
       "0                       0 2010-10-02 16:52:51.763000+00:00   \n",
       "1                       2 2009-11-16 21:34:33.500000+00:00   \n",
       "2                       0 2012-08-22 09:33:57.333000+00:00   \n",
       "3                       1 2010-10-20 18:24:00.770000+00:00   \n",
       "4                       0 2013-02-24 20:33:38.440000+00:00   \n",
       "\n",
       "   Question_favorite_count          Question_last_edit_time  Question_score  \\\n",
       "0                     11.0 2012-11-02 14:42:02.530000+00:00              33   \n",
       "1                     11.0 2012-01-20 08:31:22.290000+00:00              45   \n",
       "2                      2.0                              NaT              35   \n",
       "3                     11.0 2017-07-13 16:44:14.087000+00:00              90   \n",
       "4                     11.0 2013-02-24 21:08:23.193000+00:00              27   \n",
       "\n",
       "                                     Question_tags  Question_view_count  \\\n",
       "0            [mercurial, merge, dvcs, 3-way-merge]                15819   \n",
       "1                                [mercurial, dvcs]                18159   \n",
       "2                                [mercurial, dvcs]                17364   \n",
       "3  [version-control, mercurial, merge, dvcs, undo]                31732   \n",
       "4             [git, version-control, github, dvcs]                58999   \n",
       "\n",
       "                                         Answer_body  Answer_comment_count  \\\n",
       "0  <p><strong>Local</strong> is r133</p>\\n\\n<p><s...                   1.0   \n",
       "1  <p>Yes you can.  I'm sure you've moved on, but...                   3.0   \n",
       "2  <p>Try <code>hg status</code> and look for fil...                   2.0   \n",
       "3  <p><code>hg update -C &lt;one of the two merge...                   7.0   \n",
       "4  <p>Git branches do not have \"heads\" in the Mer...                   9.0   \n",
       "\n",
       "              Answer_creation_time            Answer_last_edit_time  \\\n",
       "0 2010-10-02 16:58:23.490000+00:00 2010-10-02 20:30:59.770000+00:00   \n",
       "1 2011-02-14 20:13:26.563000+00:00        2017-05-31 11:39:12+00:00   \n",
       "2 2012-08-22 10:19:13.800000+00:00 2012-09-21 12:28:37.273000+00:00   \n",
       "3 2010-10-20 18:28:03.953000+00:00                              NaT   \n",
       "4 2013-02-24 22:33:15.687000+00:00 2013-02-25 02:21:02.693000+00:00   \n",
       "\n",
       "   Answer_score  \n",
       "0          35.0  \n",
       "1          37.0  \n",
       "2          56.0  \n",
       "3         113.0  \n",
       "4          30.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(\n",
    "    path_so_raw, 'bq-results-20230321-204446-1679431620160.json'), lines=True)\n",
    "df['Question_tags'] = df['Question_tags'].str.split('|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag collection\n",
    "tags = set()\n",
    "for key, value in tool2tag.items():\n",
    "    tags = tags.union(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags\n",
    "df['Question_valid_tags'] = [[] for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'Question_valid_tags'] = list(\n",
    "        tags.intersection(set(row['Question_tags'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with at least 1 tags has 5308 in total.\n",
      "Posts with at least 2 tags has 220 in total.\n",
      "Posts with at least 3 tags has 18 in total.\n"
     ]
    }
   ],
   "source": [
    "# count post number with different tags\n",
    "arity = 0\n",
    "while True:\n",
    "    post_number = df[df['Question_valid_tags'].map(len) > arity].shape[0]\n",
    "    if post_number < 1:\n",
    "        break\n",
    "    arity = arity + 1\n",
    "    print(f'Posts with at least {arity} tags has {post_number} in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/fg_w39cx6pq23vf3798tdmq00000gn/T/ipykernel_80260/105066014.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['Question_link'] = df_valid['Question_id'].apply(\n"
     ]
    }
   ],
   "source": [
    "# exclude Stack Overflow posts with unrelated tags\n",
    "df_valid = df[df['Question_valid_tags'].map(len) > 0]\n",
    "df_valid['Question_link'] = df_valid['Question_id'].apply(\n",
    "    lambda x: f'https://stackoverflow.com/questions/{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Stack Overflow posts with negative upvote count\n",
    "df_qualified = df_valid[df_valid['Question_score'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map from tag to tool\n",
    "tag2tool = dict()\n",
    "for key, value in tool2tag.items():\n",
    "    for elem in value:\n",
    "        tag2tool.setdefault(elem, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Stack Overflow post collection with multiple tags based on the tool map\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = set()\n",
    "    for tag in row['Question_valid_tags']:\n",
    "        tags.add(tag2tool[tag])\n",
    "    df_qualified.at[index, 'Question_valid_tags'] = sorted(list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Amazon SageMaker, MLflow]                 16\n",
       "[Azure Machine Learning, MLflow]           11\n",
       "[Kedro, MLflow]                             4\n",
       "[Azure Machine Learning, Kedro, MLflow]     2\n",
       "[MLflow, Sacred]                            1\n",
       "[DVC, MLflow]                               1\n",
       "[Kedro, Neptune]                            1\n",
       "Name: Question_valid_tags, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the posts with more than one tags look like\n",
    "df_multiply_tagged = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_multiply_tagged['Question_valid_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/fg_w39cx6pq23vf3798tdmq00000gn/T/ipykernel_80260/3320897229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qualified.at[index, 'Tool'] = tags[0]\n"
     ]
    }
   ],
   "source": [
    "# create Stack Overflow post collection with exclusive tags\n",
    "multiply_tagged_posts_split = []\n",
    "df_qualified.assign(Tool='')\n",
    "\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = row['Question_valid_tags']\n",
    "    df_qualified.at[index, 'Tool'] = tags[0]\n",
    "    if len(tags) > 1:\n",
    "        for tag in tags[1:]:\n",
    "            series = row.copy()\n",
    "            series['Tool'] = tag\n",
    "            multiply_tagged_posts_split.append(series)\n",
    "\n",
    "df_multiply_tagged_posts_split = pd.DataFrame(multiply_tagged_posts_split)\n",
    "df_qualified_exclusive_tagged = pd.concat(\n",
    "    [df_qualified, df_multiply_tagged_posts_split], ignore_index=True)\n",
    "del df_qualified_exclusive_tagged['Question_valid_tags']\n",
    "\n",
    "# keep Stack Overflow posts with accepted answers\n",
    "df_qualified_exclusive_tagged_completed = df_qualified_exclusive_tagged.dropna(\n",
    "    subset=['Answer_body'])\n",
    "\n",
    "df_qualified_exclusive_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'questions.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2248</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1546</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>149</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>552</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>141</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Question  #Answered\n",
       "0         Amazon SageMaker       2248        739\n",
       "1   Azure Machine Learning       1546        594\n",
       "2                  ClearML         40         20\n",
       "3                    Comet         10          4\n",
       "4                      DVC         91         49\n",
       "5                    Kedro        149         60\n",
       "6                   MLflow        552        129\n",
       "7                  Neptune          8          3\n",
       "8                   Optuna        141         37\n",
       "9                   Sacred         10          7\n",
       "10               Vertex AI        341        112\n",
       "11        Weights & Biases         77         22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_question_summary = df_qualified_exclusive_tagged.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "df_so_answer_summary = df_qualified_exclusive_tagged_completed.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "\n",
    "df_so_question_summary.columns = ['Tool', '#Question']\n",
    "df_so_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_so_question_summary, df_so_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create question dataset\n",
    "\n",
    "df_question_so = pd.read_json(os.path.join(path_so_filtered, 'questions.json'))\n",
    "df_question_ts = pd.read_json(os.path.join(path_ts_filtered, 'questions.json'))\n",
    "\n",
    "df_question_so['Platform'] = 'Stack Overflow'\n",
    "df_question_ts['Platform'] = 'Tool-specific'\n",
    "\n",
    "df_questions = pd.concat([df_question_so, df_question_ts], ignore_index=True)\n",
    "del df_questions['Question_tags']\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'original.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add potential field to questions for later filling\n",
    "df_questions = pd.read_json(os.path.join(path_labeling, 'original.json'))\n",
    "\n",
    "df_questions['Question_original_content'] = ''\n",
    "df_questions['Question_gpt_summary_original'] = ''\n",
    "df_questions['Question_gpt_summary'] = ''\n",
    "df_questions['Question_preprocessed_content'] = ''\n",
    "df_questions['Answer_original_content'] = ''\n",
    "df_questions['Answer_gpt_summary_original'] = ''\n",
    "df_questions['Answer_gpt_summary'] = ''\n",
    "df_questions['Answer_preprocessed_content'] = ''\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add potential field to questions for later filling\n",
    "# df_questions = pd.read_json(os.path.join(path_labeling, 'original.json'))\n",
    "# df_optuna = pd.read_json(os.path.join(path_labeling, 'optuna.json'))\n",
    "# df_previous = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "\n",
    "# df_questions['Question_original_content'] = ''\n",
    "# df_questions['Question_original_content_gpt_summary'] = ''\n",
    "# df_questions['Question_preprocessed_content'] = ''\n",
    "# df_questions['Answer_original_content'] = ''\n",
    "# df_questions['Answer_original_content_gpt_summary'] = ''\n",
    "# df_questions['Answer_preprocessed_content'] = ''\n",
    "\n",
    "\n",
    "# for index, row in df_questions.iterrows():\n",
    "#     for index_2, row_2 in df_previous.iterrows():\n",
    "#         if row['Question_link'] == row_2['Question_link']:\n",
    "#             df_questions.at[index, 'Question_original_content_gpt_summary'] = row_2['Question_original_content_gpt_summary']\n",
    "#             df_questions.at[index, 'Answer_original_content_gpt_summary'] = row_2['Answer_original_content_gpt_summary']\n",
    "#             break\n",
    "\n",
    "# # # Experiment 1: feed the original content to BerTopic\n",
    "# # df_questions['Question_original_content'] = ''\n",
    "\n",
    "# # # Experiment 2: feed the original content to GPT model and get the generated summary, then feed the summary to BerTopic\n",
    "# # df_questions['Question_original_content_gpt_summary'] = ''\n",
    "\n",
    "# # # Experiment 3: feed the preprocessed content to BerTopic\n",
    "# # df_questions['Question_preprocessed_content'] = ''\n",
    "\n",
    "# # # Experiment 4: feed the original content to BerTopic\n",
    "# # df_questions['Answer_original_content'] = ''\n",
    "\n",
    "# # # Experiment 5: feed the original content to GPT model and get the generated summary, then feed the summary to BerTopic\n",
    "# # df_questions['Answer_original_content_gpt_summary'] = ''\n",
    "\n",
    "# # # Experiment 6: feed the preprocessed content to BerTopic\n",
    "# # df_questions['Answer_preprocessed_content'] = ''\n",
    "\n",
    "# df_questions.to_json(os.path.join(path_labeling, 'topic_modeling_new.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# content filtering patterns\n",
    "regex = r\"(<.*?>)|({.*?})|((!)?\\[.*?\\])|(\\(.*?\\))|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|([^\\s]*[<=>]=[^\\s]+)|(@[^\\s]+)|((https?:\\/)?\\/[^\\s]+)|([^\\s]*\\\\[^\\s]+)|([^\\s]+\\/[^\\s]+)|([^\\s]+\\.[^\\s]+)|([^\\s]+-[^\\s]+)|([^\\s]+_[^\\s]+)|(_+[^\\s]+_*)|(_*[^\\s]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\-#*=~:{}\\(\\)\\[\\]<>]+)\"\n",
    "\n",
    "\n",
    "def preprocess_text(text, remove_code=False):          \n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    remove_tags = ['script', 'style']\n",
    "    remove_tags.append('code') if remove_code else None\n",
    "    for tag in soup(remove_tags):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    text = text.lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "    for tool_keywords in tools_keywords.values():\n",
    "        for tool_keyword in tool_keywords:\n",
    "            if tool_keyword in text:\n",
    "                text = text.replace(tool_keyword, '')\n",
    "    \n",
    "    text = re.sub(regex, ' ', text, 0, re.DOTALL) if remove_code else text\n",
    "    text = preprocess_string(text)\n",
    "    text = remove_stopwords(' '.join(text))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt for gpt model\n",
    "prompt_question = 'Please write a one-sentence summary of the user\\'s encountered challenges. For instance, you could begin with a sentence such as: \"The user XXXXXX.\"\\n###'\n",
    "prompt_answer = 'Below is a question-answer pair. Given the context of the question, extract any possible solutions (if any) from the answer and make a high-level, human-readable, and concise summary of them.\\n###'\n",
    "\n",
    "import random\n",
    "\n",
    "def retry_with_backoff(fn, retries=2, backoff_in_seconds=1, *args, **kwargs):\n",
    "    x = 0\n",
    "\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except:\n",
    "            if x == retries:\n",
    "                raise\n",
    "\n",
    "            sleep = backoff_in_seconds * 2 ** x + random.uniform(0, 1)\n",
    "            time.sleep(sleep)\n",
    "            x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo azur support yolov import\n",
      "endpoint deploi webservic grei \n",
      "studio error durind deploi autom \n",
      "data result point \n",
      "test fail custom speech \n",
      "frame datafram work \n",
      "abl select jupyt notebook \n",
      "releas user releas readi\n",
      "send slack alert failur slack\n",
      "support spark \n",
      "optim gener discuss board optim\n",
      "advanc nlu standard nlu \n",
      "export googl automl translat model \n",
      " \n",
      "googl translat javascript api \n",
      "text speech googl cloud python \n",
      "deploi pretrain fasttext model code\n",
      "integr wai integr articl resourc\n",
      " \n",
      " start journei data scienc engin\n",
      "issu handov protocol facebook dialogflow \n",
      "cloud vision text coordin format \n",
      " discuss space talk thing relat\n",
      "support help differ categori\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    question = preprocess_text(row['Question_title']) + ' ' + preprocess_text(str(row['Question_body']))\n",
    "\n",
    "    if len(question.split()) < 6 or len(question) < 30:\n",
    "        df_questions.drop(index, inplace=True)\n",
    "        print(question)\n",
    "    else:\n",
    "        df_questions.at[index, 'Question_original_content'] = question\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling,\n",
    "                     'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment 2\n",
    "\n",
    "# df_questions = pd.read_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "# df_questions['Question_gpt_summary_original'] = df_questions['Question_original_content_gpt_summary']\n",
    "# df_questions['Question_gpt_summary'] = ''\n",
    "\n",
    "# df_questions['Answer_gpt_summary_original'] = df_questions['Answer_original_content_gpt_summary']\n",
    "# df_questions['Answer_gpt_summary'] = ''\n",
    "\n",
    "# del df_questions['Question_original_content_gpt_summary']\n",
    "# del df_questions['Answer_original_content_gpt_summary']\n",
    "\n",
    "# for index, row in df_questions.iterrows():\n",
    "#     content = row['Question_gpt_summary_original']\n",
    "#     df_questions.at[index, 'Question_gpt_summary'] = preprocess_text(content)\n",
    "#     content = row['Answer_gpt_summary_original']\n",
    "#     df_questions.at[index, 'Answer_gpt_summary'] = preprocess_text(content)\n",
    "\n",
    "# df_questions.to_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on question {index}')\n",
    "        df_questions.to_json(os.path.join(\n",
    "            path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n",
    "        \n",
    "    if row['Question_gpt_summary_original']:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        question = prompt_question + 'Title: ' + row['Question_title'] + ' Body: ' + row['Question_body'] + '###\\n'\n",
    "        response = retry_with_backoff(\n",
    "            openai.ChatCompletion.create,\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful summarizer.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        content = response['choices'][0]['message']['content'].strip()\n",
    "        df_questions.at[index, 'Question_gpt_summary_original'] = content\n",
    "        df_questions.at[index, 'Question_gpt_summary'] = preprocess_text(content)\n",
    "    except Exception as e:\n",
    "        # output unsuccesful requests\n",
    "        print(f'{e} on question {row[\"Question_link\"]}')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "assert (df_questions.shape[0] == df_questions.dropna(\n",
    "    subset=['Question_gpt_summary_original']).shape[0])\n",
    "\n",
    "# output the number of asset-management-related Q&A questions\n",
    "df_questions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment 3\n",
    "\n",
    "# df_questions = pd.read_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "# for index, row in df_questions.iterrows():\n",
    "#     if row['Question_gpt_summary']:\n",
    "#         continue\n",
    "#     df_questions.at[index, 'Question_gpt_summary'] = preprocess_text(row['Question_gpt_summary_original'])\n",
    "\n",
    "# df_questions.to_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    content = preprocess_text(row['Question_title'], remove_code=True) + ' ' + preprocess_text(str(row['Question_body']), remove_code=True)\n",
    "    df_questions.at[index, 'Question_preprocessed_content'] = content\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "\n",
    "df_answers = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_answers.iterrows():\n",
    "    answer = ''\n",
    "    if row['Answer_body']:\n",
    "        answer = row['Answer_body']\n",
    "    elif row['Answer_list']:\n",
    "        if row['Question_has_accepted_answer']:\n",
    "            if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    if comment['Answer_has_accepted']:\n",
    "                        answer = comment['Answer_body']\n",
    "                        break\n",
    "        elif 'Answer_body' in row['Answer_list'][0]:\n",
    "            for comment in row['Answer_list']:\n",
    "                answer += comment['Answer_body'] + '\\n'\n",
    "\n",
    "    df_answers.at[index, 'Answer_original_content'] = preprocess_text(answer)\n",
    "\n",
    "df_answers.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "\n",
    "df_answers = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_answers.iterrows():\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on answer {index}')\n",
    "        df_answers.to_json(os.path.join(\n",
    "            path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n",
    "    \n",
    "    answer = ''\n",
    "    if row['Answer_body']:\n",
    "        answer = row['Answer_body']\n",
    "    elif row['Answer_list']:\n",
    "        if row['Question_has_accepted_answer']:\n",
    "            if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    if comment['Answer_has_accepted']:\n",
    "                        answer = comment['Answer_body']\n",
    "                        break\n",
    "        elif 'Answer_body' in row['Answer_list'][0]:\n",
    "            for comment in row['Answer_list']:\n",
    "                answer += comment['Answer_body'] + '\\n'\n",
    "\n",
    "    if not answer or row['Answer_gpt_summary_original']:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        answer = prompt_answer + 'Question: ' + row['Question_gpt_summary'] + ' Answer: ' + answer + '###\\n'\n",
    "        response = retry_with_backoff(\n",
    "            openai.ChatCompletion.create,\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful summarizer.\"},\n",
    "                {\"role\": \"user\", \"content\": answer},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        content = response['choices'][0]['message']['content'].strip()\n",
    "        df_answers.at[index, 'Answer_gpt_summary_original'] = content\n",
    "        df_answers.at[index, 'Answer_gpt_summary'] = preprocess_text(content)\n",
    "    except Exception as e:\n",
    "        # output unsuccesful requests\n",
    "        print(f'{e} on answer {row[\"Question_link\"]}')\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "df_answers.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "df_questions = df_questions[df_questions['Answer_original_content'] != '']\n",
    "\n",
    "assert (df_questions.shape[0] == df_questions.dropna(\n",
    "    subset=['Answer_gpt_summary_original']).shape[0])\n",
    "\n",
    "# output the number of asset-management-related Q&A answers\n",
    "len(df_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size is based on the recommendation from https://www.calculator.net/sample-size-calculator.html\n",
    "\n",
    "sample_size = 369\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "df_sample = df_questions[df_questions['Answer_gpt_summary_original'] != ''].sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_sample.to_json(os.path.join(\n",
    "    path_labeling, 'sample.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6\n",
    "\n",
    "df_answers = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_answers.iterrows():\n",
    "    answer = ''\n",
    "    if row['Answer_body']:\n",
    "        answer = row['Answer_body']\n",
    "    elif row['Answer_list']:\n",
    "        if row['Question_has_accepted_answer']:\n",
    "            if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    if comment['Answer_has_accepted']:\n",
    "                        answer = comment['Answer_body']\n",
    "                        break\n",
    "        elif 'Answer_body' in row['Answer_list'][0]:\n",
    "            for comment in row['Answer_list']:\n",
    "                answer += comment['Answer_body'] + '\\n'\n",
    "\n",
    "    df_answers.at[index, 'Answer_preprocessed_content'] = preprocess_text(answer, remove_code=True)\n",
    "\n",
    "df_answers.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
