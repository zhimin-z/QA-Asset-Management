{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2tag = {\n",
    "    'Azure Machine Learning': {'azure-machine-learning-service', 'azure-machine-learning-studio', 'azure-machine-learning-workbench'},\n",
    "    'Vertex AI': {'google-cloud-vertex-ai', 'vertex-ai-pipeline'},\n",
    "    'Amazon SageMaker': {'amazon-sagemaker', 'amazon-sagemaker-experiments'},\n",
    "    'MLFlow': {'mlflow'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Weights & Biases': {'wandb'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'Comet': {'comet-ml'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Pachyderm': {'pachyderm'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_so = os.path.join(path_dataset, 'Stack Overflow')\n",
    "path_to = os.path.join(path_dataset, 'Tool-specific Others')\n",
    "\n",
    "path_so_raw = os.path.join(path_so, 'Raw')\n",
    "path_to_raw = os.path.join(path_to, 'Raw')\n",
    "path_so_filtered = os.path.join(path_so, 'Filtered')\n",
    "path_to_filtered = os.path.join(path_to, 'Filtered')\n",
    "path_so_sampled = os.path.join(path_so, 'Sampled')\n",
    "path_to_sampled = os.path.join(path_to, 'Sampled')\n",
    "path_so_sampled_questions = os.path.join(path_so_sampled, 'Questions')\n",
    "path_to_sampled_questions = os.path.join(path_to_sampled, 'Questions')\n",
    "path_so_sampled_answers = os.path.join(path_so_sampled, 'Answers')\n",
    "path_to_sampled_answers = os.path.join(path_to_sampled, 'Answers')\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "if not os.path.isdir(path_so):\n",
    "    os.mkdir(path_so)\n",
    "\n",
    "if not os.path.isdir(path_to):\n",
    "    os.mkdir(path_to)\n",
    "\n",
    "if not os.path.isdir(path_so_raw):\n",
    "    os.mkdir(path_so_raw)\n",
    "\n",
    "if not os.path.isdir(path_to_raw):\n",
    "    os.mkdir(path_to_raw)\n",
    "\n",
    "if not os.path.isdir(path_so_filtered):\n",
    "    os.mkdir(path_so_filtered)\n",
    "\n",
    "if not os.path.isdir(path_to_filtered):\n",
    "    os.mkdir(path_to_filtered)\n",
    "\n",
    "if not os.path.isdir(path_so_sampled):\n",
    "    os.mkdir(path_so_sampled)\n",
    "\n",
    "if not os.path.isdir(path_to_sampled):\n",
    "    os.mkdir(path_to_sampled)\n",
    "\n",
    "if not os.path.isdir(path_so_sampled_questions):\n",
    "    os.mkdir(path_so_sampled_questions)\n",
    "\n",
    "if not os.path.isdir(path_to_sampled_questions):\n",
    "    os.mkdir(path_to_sampled_questions)\n",
    "\n",
    "if not os.path.isdir(path_so_sampled_answers):\n",
    "    os.mkdir(path_so_sampled_answers)\n",
    "\n",
    "if not os.path.isdir(path_to_sampled_answers):\n",
    "    os.mkdir(path_to_sampled_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://my.guild.ai/'\n",
    "page_suffix = 'c/troubleshooting/6.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_date'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'Guild AI.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://community.wandb.ai/'\n",
    "page_suffix = 'c/w-b-support/36.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_date'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'Weights & Biases.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://community.sigopt.com/'\n",
    "page_suffix = 'c/general-discussion/9.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_date'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'SigOpt.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://discuss.dvc.org/'\n",
    "page_suffix = 'c/questions/9.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_date'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'DVC.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to = pd.DataFrame()\n",
    "# exclude tool-specific posts with negative upvote count\n",
    "for file_name in glob.glob(os.path.join(path_to_raw, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    if 'Question_upvote_count' in repos.columns:\n",
    "        repos = repos[repos['Question_upvote_count'] > -1]\n",
    "    repos['Tool'] = os.path.split(file_name)[1].split('.')[0]\n",
    "    df_to = pd.concat([df_to, repos], ignore_index=True)\n",
    "df_to.to_json(os.path.join(path_to_filtered,\n",
    "              'valid_posts_with_at_least_zero_score.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_answered = df_to[df_to['Question_answer_count'] > 0]\n",
    "for tool in df_to_answered['Tool'].unique().tolist():\n",
    "    number_accepted_answer = df_to_answered[df_to_answered['Tool'] == tool]['Question_has_accepted_answer'].sum()\n",
    "    if number_accepted_answer > 0:\n",
    "        df_to_answered = df_to_answered.drop(df_to_answered[(df_to_answered['Tool'] == tool) & (df_to_answered['Question_has_accepted_answer'] == False)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>315</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>583</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker        528        167\n",
       "1  Azure Machine Learning       1435        343\n",
       "2                     DVC        315        300\n",
       "3                  Domino         13          4\n",
       "4                Guild AI        115        108\n",
       "5                  MLFlow        280        143\n",
       "6                Polyaxon         43         34\n",
       "7                  SigOpt         15          7\n",
       "8               Vertex AI        297         32\n",
       "9        Weights & Biases        583         92"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only posts with at least one answer\n",
    "df_to_summary = df_to.groupby('Tool').count()['Question_title'].reset_index()\n",
    "df_to_answered_summary = df_to_answered.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "\n",
    "df_to_summary.columns = ['Tool', '#Question']\n",
    "df_to_answered_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = df_to_summary.merge(df_to_answered_summary, on='Tool')\n",
    "\n",
    "df_summary.to_csv(os.path.join(path_to, 'summary.csv'), index=False)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "      <th>#Sample Question</th>\n",
       "      <th>#Sample Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "      <td>223</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "      <td>304</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>315</td>\n",
       "      <td>300</td>\n",
       "      <td>174</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "      <td>168</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>583</td>\n",
       "      <td>92</td>\n",
       "      <td>232</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered  #Sample Question  \\\n",
       "0        Amazon SageMaker        528        167               223   \n",
       "1  Azure Machine Learning       1435        343               304   \n",
       "2                     DVC        315        300               174   \n",
       "3                  Domino         13          4                13   \n",
       "4                Guild AI        115        108                89   \n",
       "5                  MLFlow        280        143               163   \n",
       "6                Polyaxon         43         34                39   \n",
       "7                  SigOpt         15          7                15   \n",
       "8               Vertex AI        297         32               168   \n",
       "9        Weights & Biases        583         92               232   \n",
       "\n",
       "   #Sample Answered  \n",
       "0               117  \n",
       "1               182  \n",
       "2               169  \n",
       "3                 4  \n",
       "4                85  \n",
       "5               105  \n",
       "6                32  \n",
       "7                 7  \n",
       "8                30  \n",
       "9                75  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_to_summary = pd.read_csv(os.path.join(path_to, 'summary.csv'))\n",
    "df_to_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tool-specific posts accordingly\n",
    "for index, row in df_to_summary.iterrows():\n",
    "    df_to[df_to['Tool'] == row['Tool']].sample(n=row['#Sample Question'], random_state=0).to_json(\n",
    "        os.path.join(path_to_sampled_questions, row['Tool'] + '.json'), orient='records', indent=4)\n",
    "    df_to_answered[df_to_answered['Tool'] == row['Tool']].sample(n=row['#Sample Answered'], random_state=0).to_json(\n",
    "        os.path.join(path_to_sampled_answers, row['Tool'] + '.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_date</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "      <th>Question_last_edit_date</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner_reputation</th>\n",
       "      <th>Owner_up_votes</th>\n",
       "      <th>Owner_down_votes</th>\n",
       "      <th>Owner_views</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_date</th>\n",
       "      <th>Answer_score</th>\n",
       "      <th>Owner_location</th>\n",
       "      <th>Answer_last_edit_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3037664</td>\n",
       "      <td>Does any Version Control System like SVN, Git,...</td>\n",
       "      <td>&lt;p&gt;In our project files, if there are binary f...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-06-14 13:42:06.327 UTC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-06-14 22:18:01.693 UTC</td>\n",
       "      <td>10</td>\n",
       "      <td>svn|git|mercurial|dvcs</td>\n",
       "      <td>...</td>\n",
       "      <td>141372</td>\n",
       "      <td>1451</td>\n",
       "      <td>39</td>\n",
       "      <td>12992</td>\n",
       "      <td>&lt;p&gt;I do know one that does this, but you're no...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-07-13 22:17:41.03 UTC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29647782</td>\n",
       "      <td>Azureml Web Service - How to create a Rest Ser...</td>\n",
       "      <td>&lt;p&gt;I've looked all over the google and stackov...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-15 10:26:48.083 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-04-16 19:48:33.29 UTC</td>\n",
       "      <td>1</td>\n",
       "      <td>json|web-services|azure|webforms|azure-machine...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60784209</td>\n",
       "      <td>Sagemaker Neo Compilation witn Dynamic Input D...</td>\n",
       "      <td>&lt;p&gt;I'm trying to compile a &lt;code&gt;PyTorch&lt;/code...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-21 03:31:41.6 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon-web-services|pytorch|amazon-sagemaker</td>\n",
       "      <td>...</td>\n",
       "      <td>2306</td>\n",
       "      <td>1283</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, QC, Canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70494276</td>\n",
       "      <td>Not able to read HDF5 file present in S3 in sa...</td>\n",
       "      <td>&lt;p&gt;My directory structure looks like this: &lt;co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-27 10:26:41.04 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon-s3|hdf5|amazon-sagemaker</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51940106</td>\n",
       "      <td>What is the best practice to develop CD/CI whe...</td>\n",
       "      <td>&lt;p&gt;In our backend development process, we have...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-21 00:33:31.857 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-21 03:35:00.183 UTC</td>\n",
       "      <td>0</td>\n",
       "      <td>azure-machine-learning-studio|ml-studio</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                                     Question_title  \\\n",
       "0      3037664  Does any Version Control System like SVN, Git,...   \n",
       "1     29647782  Azureml Web Service - How to create a Rest Ser...   \n",
       "2     60784209  Sagemaker Neo Compilation witn Dynamic Input D...   \n",
       "3     70494276  Not able to read HDF5 file present in S3 in sa...   \n",
       "4     51940106  What is the best practice to develop CD/CI whe...   \n",
       "\n",
       "                                       Question_body  Question_answer_count  \\\n",
       "0  <p>In our project files, if there are binary f...                     10   \n",
       "1  <p>I've looked all over the google and stackov...                      1   \n",
       "2  <p>I'm trying to compile a <code>PyTorch</code...                      0   \n",
       "3  <p>My directory structure looks like this: <co...                      1   \n",
       "4  <p>In our backend development process, we have...                      1   \n",
       "\n",
       "   Question_comment_count       Question_creation_date  \\\n",
       "0                       3  2010-06-14 13:42:06.327 UTC   \n",
       "1                       0  2015-04-15 10:26:48.083 UTC   \n",
       "2                       0    2020-03-21 03:31:41.6 UTC   \n",
       "3                       0   2021-12-27 10:26:41.04 UTC   \n",
       "4                       0  2018-08-21 00:33:31.857 UTC   \n",
       "\n",
       "   Question_favorite_count      Question_last_edit_date  Question_score  \\\n",
       "0                      1.0  2010-06-14 22:18:01.693 UTC              10   \n",
       "1                      NaN   2015-04-16 19:48:33.29 UTC               1   \n",
       "2                      NaN                          NaN               1   \n",
       "3                      NaN                          NaN               0   \n",
       "4                      NaN  2018-08-21 03:35:00.183 UTC               0   \n",
       "\n",
       "                                       Question_tags  ...  Owner_reputation  \\\n",
       "0                             svn|git|mercurial|dvcs  ...            141372   \n",
       "1  json|web-services|azure|webforms|azure-machine...  ...                23   \n",
       "2       amazon-web-services|pytorch|amazon-sagemaker  ...              2306   \n",
       "3                    amazon-s3|hdf5|amazon-sagemaker  ...                 1   \n",
       "4            azure-machine-learning-studio|ml-studio  ...                37   \n",
       "\n",
       "  Owner_up_votes Owner_down_votes  Owner_views  \\\n",
       "0           1451               39        12992   \n",
       "1              0                0            9   \n",
       "2           1283                3          182   \n",
       "3              0                0            1   \n",
       "4              2                0            8   \n",
       "\n",
       "                                         Answer_body  Answer_comment_count  \\\n",
       "0  <p>I do know one that does this, but you're no...                   0.0   \n",
       "1                                                NaN                   NaN   \n",
       "2                                                NaN                   NaN   \n",
       "3                                                NaN                   NaN   \n",
       "4                                                NaN                   NaN   \n",
       "\n",
       "         Answer_creation_date Answer_score        Owner_location  \\\n",
       "0  2010-07-13 22:17:41.03 UTC          4.0                   NaN   \n",
       "1                         NaN          NaN                   NaN   \n",
       "2                         NaN          NaN  Montreal, QC, Canada   \n",
       "3                         NaN          NaN                   NaN   \n",
       "4                         NaN          NaN             Australia   \n",
       "\n",
       "  Answer_last_edit_date  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(\n",
    "    path_so_raw, 'bq-results-20221220-235957-1671580809671.json'), lines=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag collection\n",
    "tags = []\n",
    "for key, value in tool2tag.items():\n",
    "    tags.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags\n",
    "df['Question_valid_tags'] = [[] for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    row_tags = set(str(row['Question_tags']).strip().split('|'))\n",
    "    df.at[index, 'Question_valid_tags'] = list(row_tags.intersection(tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with at least 1 tags has 4981 in total.\n",
      "Posts with at least 2 tags has 213 in total.\n",
      "Posts with at least 3 tags has 16 in total.\n"
     ]
    }
   ],
   "source": [
    "# count post number with different tags\n",
    "arity = 0\n",
    "while True:\n",
    "    post_number = df[df['Question_valid_tags'].map(len) > arity].shape[0]\n",
    "    if post_number < 1:\n",
    "        break\n",
    "    arity = arity + 1\n",
    "    print(f'Posts with at least {arity} tags has {post_number} in total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhimi\\AppData\\Local\\Temp\\ipykernel_18060\\1288630396.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['Question_link'] = df_valid['Question_id'].apply(\n"
     ]
    }
   ],
   "source": [
    "# exclude Stack Overflow posts with unrelated tags\n",
    "df_valid = df[df['Question_valid_tags'].map(len) > 0]\n",
    "df_valid['Question_link'] = df_valid['Question_id'].apply(\n",
    "    lambda x: f'https://stackoverflow.com/questions/{x}')\n",
    "df_valid.to_json(os.path.join(path_so_filtered, 'valid_posts.json'),\n",
    "                 indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Stack Overflow posts with negative upvote count\n",
    "df_qualified = df_valid[df_valid['Question_score'] > -1]\n",
    "df_qualified.to_json(os.path.join(\n",
    "    path_so_filtered, 'valid_posts_with_at_least_zero_score.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['azure-machine-learning-studio', 'azure-machine-learning-service']\",\n",
       " \"['azure-machine-learning-workbench', 'azure-machine-learning-studio', 'azure-machine-learning-service']\",\n",
       " \"['azure-machine-learning-workbench', 'azure-machine-learning-studio']\",\n",
       " \"['mlflow', 'amazon-sagemaker']\",\n",
       " \"['dvc', 'mlflow']\",\n",
       " \"['mlflow', 'azure-machine-learning-service']\",\n",
       " \"['dvc', 'pachyderm']\",\n",
       " \"['azure-machine-learning-workbench', 'azure-machine-learning-service']\",\n",
       " \"['mlflow', 'azure-machine-learning-studio']\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the posts with more than one tags look like\n",
    "df_one_plus_tags = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_one_plus_tags['Question_valid_tags'].map(str).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map from tag to tool\n",
    "tag2tool = {}\n",
    "for key, value in tool2tag.items():\n",
    "    for elem in value:\n",
    "        tag2tool.setdefault(elem, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Stack Overflow post collection with multiple tags based on the tool map\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = set()\n",
    "    for tag in row['Question_valid_tags']:\n",
    "        tags.add(tag2tool[tag])\n",
    "    df_qualified.at[index, 'Question_valid_tags'] = sorted(list(tags))\n",
    "\n",
    "df_multiply_tagged = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_multiply_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'valid_posts_with_at_least_zero_score_and_multiply_tagged.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Stack Overflow post collection with exclusive tags\n",
    "multiply_tagged_posts_split = []\n",
    "df_qualified.assign(Question_exclusive_tag='')\n",
    "\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = row['Question_valid_tags']\n",
    "    df_qualified.at[index, 'Question_exclusive_tag'] = tags[0]\n",
    "    if len(tags) > 1:\n",
    "        for tag in tags[1:]:\n",
    "            series = row.copy()\n",
    "            series['Question_exclusive_tag'] = tag\n",
    "            multiply_tagged_posts_split.append(series)\n",
    "\n",
    "df_multiply_tagged_posts_split = pd.DataFrame(multiply_tagged_posts_split)\n",
    "df_qualified_exclusive_tagged = pd.concat(\n",
    "    [df_qualified, df_multiply_tagged_posts_split], ignore_index=True)\n",
    "del df_qualified_exclusive_tagged['Question_valid_tags']\n",
    "df_qualified_exclusive_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'valid_posts_with_at_least_zero_score_and_exclusively_tagged.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Stack Overflow posts with accepted answers\n",
    "df_qualified_exclusive_tagged_completed = df_qualified_exclusive_tagged.dropna(\n",
    "    subset=['Answer_body'])\n",
    "df_qualified_exclusive_tagged_completed.to_json(os.path.join(\n",
    "    path_so_filtered, 'valid_posts_with_at_least_zero_score_and_one_exclusive_tag_and_completed.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker       2233        737\n",
       "1  Azure Machine Learning       1530        586\n",
       "2                 ClearML         40         20\n",
       "3                   Comet         10          4\n",
       "4                     DVC         91         49\n",
       "5                  MLFlow        551        129\n",
       "6                 Neptune          8          3\n",
       "7               Pachyderm          7          2\n",
       "8               Vertex AI        341        112\n",
       "9        Weights & Biases         77         22"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_summary = df_qualified_exclusive_tagged.groupby(\n",
    "    'Question_exclusive_tag').count()['Question_id'].reset_index()\n",
    "df_so_answered_summary = df_qualified_exclusive_tagged_completed.groupby(\n",
    "    'Question_exclusive_tag').count()['Question_id'].reset_index()\n",
    "\n",
    "df_so_summary.columns = ['Tool', '#Question']\n",
    "df_so_answered_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_so_summary, df_so_answered_summary, on='Tool')\n",
    "df_summary.to_csv(os.path.join(path_so, 'summary.csv'), index=False)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "      <th>#Sample Question</th>\n",
       "      <th>#Sample Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "      <td>328</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "      <td>308</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "      <td>227</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "      <td>181</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered  #Sample Question  \\\n",
       "0        Amazon SageMaker       2233        737               328   \n",
       "1  Azure Machine Learning       1530        586               308   \n",
       "2                 ClearML         40         20                37   \n",
       "3                   Comet         10          4                10   \n",
       "4                     DVC         91         49                74   \n",
       "5                  MLFlow        551        129               227   \n",
       "6                 Neptune          8          3                 8   \n",
       "7               Pachyderm          7          2                 7   \n",
       "8               Vertex AI        341        112               181   \n",
       "9        Weights & Biases         77         22                65   \n",
       "\n",
       "   #Sample Answered  \n",
       "0               253  \n",
       "1               233  \n",
       "2                20  \n",
       "3                 4  \n",
       "4                44  \n",
       "5                97  \n",
       "6                 3  \n",
       "7                 2  \n",
       "8                87  \n",
       "9                21  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_so, 'summary.csv'))\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Stack Overflow posts accordingly\n",
    "for index, row in df_summary.iterrows():\n",
    "    df_qualified_exclusive_tagged[df_qualified_exclusive_tagged['Question_exclusive_tag'] == row['Tool']].sample(n=row['#Sample Question'], random_state=0).to_json(\n",
    "        os.path.join(path_so_sampled_questions, row['Tool'] + '.json'), orient='records', indent=4)\n",
    "    df_qualified_exclusive_tagged_completed[df_qualified_exclusive_tagged_completed['Question_exclusive_tag'] == row['Tool']].sample(n=row['#Sample Answered'], random_state=0).to_json(\n",
    "        os.path.join(path_so_sampled_answers, row['Tool'] + '.json'), orient='records', indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9e7b88a259684df50811b5249344f7cc06d54cdb1cf11111ce301ae44eac9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
