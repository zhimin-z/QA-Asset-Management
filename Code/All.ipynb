{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_so = os.path.join(path_dataset, 'Stack Overflow')\n",
    "path_ts = os.path.join(path_dataset, 'Tool-specific Others')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_so_raw = os.path.join(path_so, 'Raw')\n",
    "path_ts_raw = os.path.join(path_ts, 'Raw')\n",
    "path_so_filtered = os.path.join(path_so, 'Filtered')\n",
    "path_ts_filtered = os.path.join(path_ts, 'Filtered')\n",
    "\n",
    "path_labeling_question = os.path.join(path_labeling, 'Question')\n",
    "path_labeling_answer = os.path.join(path_labeling, 'Answer')\n",
    "    \n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "if not os.path.isdir(path_so):\n",
    "    os.mkdir(path_so)\n",
    "\n",
    "if not os.path.isdir(path_ts):\n",
    "    os.mkdir(path_ts)\n",
    "\n",
    "if not os.path.isdir(path_labeling):\n",
    "    os.mkdir(path_labeling)\n",
    "\n",
    "if not os.path.isdir(path_so_raw):\n",
    "    os.mkdir(path_so_raw)\n",
    "\n",
    "if not os.path.isdir(path_ts_raw):\n",
    "    os.mkdir(path_ts_raw)\n",
    "\n",
    "if not os.path.isdir(path_so_filtered):\n",
    "    os.mkdir(path_so_filtered)\n",
    "\n",
    "if not os.path.isdir(path_ts_filtered):\n",
    "    os.mkdir(path_ts_filtered)\n",
    "\n",
    "if not os.path.exists(path_labeling_question):\n",
    "    os.makedirs(path_labeling_question)\n",
    "\n",
    "if not os.path.exists(path_labeling_answer):\n",
    "    os.makedirs(path_labeling_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2tag = {\n",
    "    'Amazon SageMaker': {'amazon-sagemaker', 'amazon-sagemaker-experiments', 'amazon-sagemaker-studio'},\n",
    "    'Azure Machine Learning': {'azure-machine-learning-service', 'azure-machine-learning-studio', 'azure-machine-learning-workbench'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'Comet': {'comet-ml'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Kedro': {'kedro'},\n",
    "    'MLflow': {'mlflow'},\n",
    "    'MLRun': {'mlrun'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Sacred': {'python-sacred'},\n",
    "    'Vertex AI': {'google-cloud-vertex-ai'},\n",
    "    'Weights & Biases': {'wandb'}\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Amazon SageMaker': ['amazon sagemaker', 'aws sagemaker', 'sagemaker'],\n",
    "    'Azure Machine Learning': ['microsoft azure machine learning', 'azure machine learning', 'microsoft azure ml', 'microsoft azureml', 'azure ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'Comet': ['comet'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Vertex AI': ['google vertex ai', 'vertex ai'],\n",
    "    'Weights & Biases': ['weights & biases', 'weights and biases', 'wandb']\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_project = 'asset-management-project'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# function to scrape the posts from the tool-specific discussion fora\n",
    "\n",
    "def scrape_post(base_url, page_suffix, file_name):\n",
    "    page = -1\n",
    "    post_list = []\n",
    "    \n",
    "    while True:\n",
    "        page = page + 1\n",
    "        page_url = base_url + page_suffix + str(page)\n",
    "        topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "        for topic in topic_list['topics']:\n",
    "            post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id'])\n",
    "\n",
    "            post = {}\n",
    "            post['Question_title'] = topic['title']\n",
    "            post['Question_link'] = post_url\n",
    "            post['Question_creation_time'] = topic['created_at']\n",
    "            post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "            post['Question_score'] = topic['like_count']\n",
    "            post['Question_view_count'] = topic['views']\n",
    "            post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "            comments = requests.get(post_url + '.json').json()['post_stream']['posts']\n",
    "            post['Question_body'] = comments[0]['cooked']\n",
    "            post['Answer_list'] = comments[1:]\n",
    "            post_list.append(post)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "        if 'more_topics_url' not in topic_list.keys():\n",
    "            break\n",
    "        \n",
    "    with open(os.path.join(path_ts_raw, file_name), 'w') as outfile:\n",
    "        json_post_list = json.dumps(post_list, indent='\\t')\n",
    "        outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Guild AI\n",
    "base_url = 'https://my.guild.ai/'\n",
    "page_suffix = 'c/troubleshooting/6.json?page='\n",
    "file_name = 'Guild AI.json'\n",
    "post_list = scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Weights & Biases\n",
    "base_url = 'https://community.wandb.ai/'\n",
    "page_suffix = 'c/w-b-support/36.json?page='\n",
    "file_name = 'Weights & Biases.json'\n",
    "post_list = scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from SigOpt\n",
    "base_url = 'https://community.sigopt.com/'\n",
    "page_suffix = 'c/general-discussion/9.json?page='\n",
    "file_name = 'SigOpt.json'\n",
    "post_list = scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from DVC\n",
    "base_url = 'https://discuss.dvc.org/'\n",
    "page_suffix = 'c/questions/9.json?page='\n",
    "file_name = 'DVC.json'\n",
    "post_list = scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_questions = pd.DataFrame()\n",
    "\n",
    "# exclude tool-specific posts with negative upvote count\n",
    "for file_name in glob.glob(os.path.join(path_ts_raw, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    if 'Question_score' in repos.columns:\n",
    "        repos = repos[repos['Question_score'] > -1]\n",
    "    repos['Tool'] = os.path.split(file_name)[1].split('.')[0]\n",
    "    df_ts_questions = pd.concat([df_ts_questions, repos], ignore_index=True)\n",
    "    \n",
    "df_ts_answers = df_ts_questions[df_ts_questions['Question_answer_count'] > 0]\n",
    "for tool in df_ts_answers['Tool'].unique().tolist():\n",
    "    number_accepted_answer = df_ts_answers[df_ts_answers['Tool']\n",
    "                                            == tool]['Question_has_accepted_answer'].sum()\n",
    "    if number_accepted_answer > 0:\n",
    "        df_ts_answers = df_ts_answers.drop(df_ts_answers[(df_ts_answers['Tool'] == tool) & (\n",
    "            df_ts_answers['Question_has_accepted_answer'] == False)].index)\n",
    "\n",
    "df_ts_questions.to_json(os.path.join(path_ts_filtered,\n",
    "              'questions.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>315</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>583</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker        528        167\n",
       "1  Azure Machine Learning       1435        343\n",
       "2                     DVC        315        300\n",
       "3                  Domino         13          4\n",
       "4                Guild AI        115        108\n",
       "5                  MLFlow        280        143\n",
       "6                Polyaxon         43         34\n",
       "7                  SigOpt         15          7\n",
       "8               Vertex AI        297         32\n",
       "9        Weights & Biases        583         92"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only posts with at least one answer\n",
    "df_ts_question_summary = df_ts_questions.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "df_ts_answer_summary = df_ts_answers.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "\n",
    "df_ts_question_summary.columns = ['Tool', '#Question']\n",
    "df_ts_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_ts_question_summary, df_ts_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_time</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>Question_view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner_up_votes</th>\n",
       "      <th>Owner_down_votes</th>\n",
       "      <th>Owner_views</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_time</th>\n",
       "      <th>Answer_score</th>\n",
       "      <th>Owner_location</th>\n",
       "      <th>Question_last_edit_time</th>\n",
       "      <th>Answer_last_edit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70098779</td>\n",
       "      <td>How to connect to MLFlow tracking server that ...</td>\n",
       "      <td>&lt;p&gt;I want to connect to remote tracking server...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-24 15:30:11.310000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[authorization, tracking, mlflow]</td>\n",
       "      <td>2102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://mlflow.org/docs/latest/tra...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-11-24 17:01:13.483000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38927230</td>\n",
       "      <td>Panda AssertionError columns passed, passed da...</td>\n",
       "      <td>&lt;p&gt;I am working on Azure ML implementation on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-12 22:23:17.197000+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>[python, pandas, dataframe, nltk, azure-machin...</td>\n",
       "      <td>48200</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>55</td>\n",
       "      <td>339</td>\n",
       "      <td>&lt;p&gt;Try this:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;dataframe_outpu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-08-12 22:26:09.603000+00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Toronto, ON, Canada</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68773463</td>\n",
       "      <td>AccessDeniedException on sagemaker:CreateDomai...</td>\n",
       "      <td>&lt;p&gt;I am trying to use the AWS SageMaker Studio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-13 13:49:08.683000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[amazon-web-services, amazon-iam, amazon-sagem...</td>\n",
       "      <td>366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67701971</td>\n",
       "      <td>How to label a text with multiple paragraphs i...</td>\n",
       "      <td>&lt;p&gt;I was trying setup a single label labeling ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-26 09:16:33.420000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[amazon-web-services, text, amazon-sagemaker, ...</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zürich, Suïssa</td>\n",
       "      <td>2021-05-26 11:54:00.030000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48398509</td>\n",
       "      <td>How to Invoke AWS Sagemaker API with c# .NET?</td>\n",
       "      <td>&lt;p&gt;I have trained and deployed a model in AWS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-23 09:42:48.607000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[c#, asp.net, amazon-web-services, aws-sdk, am...</td>\n",
       "      <td>743</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pune India</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                                     Question_title  \\\n",
       "0     70098779  How to connect to MLFlow tracking server that ...   \n",
       "1     38927230  Panda AssertionError columns passed, passed da...   \n",
       "2     68773463  AccessDeniedException on sagemaker:CreateDomai...   \n",
       "3     67701971  How to label a text with multiple paragraphs i...   \n",
       "4     48398509      How to Invoke AWS Sagemaker API with c# .NET?   \n",
       "\n",
       "                                       Question_body  Question_answer_count  \\\n",
       "0  <p>I want to connect to remote tracking server...                      1   \n",
       "1  <p>I am working on Azure ML implementation on ...                      1   \n",
       "2  <p>I am trying to use the AWS SageMaker Studio...                      1   \n",
       "3  <p>I was trying setup a single label labeling ...                      0   \n",
       "4  <p>I have trained and deployed a model in AWS ...                      1   \n",
       "\n",
       "   Question_comment_count           Question_creation_time  \\\n",
       "0                       0 2021-11-24 15:30:11.310000+00:00   \n",
       "1                       0 2016-08-12 22:23:17.197000+00:00   \n",
       "2                       0 2021-08-13 13:49:08.683000+00:00   \n",
       "3                       2 2021-05-26 09:16:33.420000+00:00   \n",
       "4                       0 2018-01-23 09:42:48.607000+00:00   \n",
       "\n",
       "   Question_favorite_count  Question_score  \\\n",
       "0                      1.0               1   \n",
       "1                      3.0               7   \n",
       "2                      NaN               0   \n",
       "3                      NaN               1   \n",
       "4                      NaN               0   \n",
       "\n",
       "                                       Question_tags  Question_view_count  \\\n",
       "0                  [authorization, tracking, mlflow]                 2102   \n",
       "1  [python, pandas, dataframe, nltk, azure-machin...                48200   \n",
       "2  [amazon-web-services, amazon-iam, amazon-sagem...                  366   \n",
       "3  [amazon-web-services, text, amazon-sagemaker, ...                  161   \n",
       "4  [c#, asp.net, amazon-web-services, aws-sdk, am...                  743   \n",
       "\n",
       "   ... Owner_up_votes Owner_down_votes  Owner_views  \\\n",
       "0  ...              0                0           11   \n",
       "1  ...            136               55          339   \n",
       "2  ...              0                0           11   \n",
       "3  ...             75               10          147   \n",
       "4  ...             34                1          124   \n",
       "\n",
       "                                         Answer_body  Answer_comment_count  \\\n",
       "0  <p><a href=\"https://mlflow.org/docs/latest/tra...                   2.0   \n",
       "1  <p>Try this:</p>\\n\\n<pre><code>dataframe_outpu...                   0.0   \n",
       "2                                                NaN                   NaN   \n",
       "3                                                NaN                   NaN   \n",
       "4                                                NaN                   NaN   \n",
       "\n",
       "              Answer_creation_time Answer_score       Owner_location  \\\n",
       "0 2021-11-24 17:01:13.483000+00:00          2.0                  NaN   \n",
       "1 2016-08-12 22:26:09.603000+00:00         13.0  Toronto, ON, Canada   \n",
       "2                              NaT          NaN                  NaN   \n",
       "3                              NaT          NaN       Zürich, Suïssa   \n",
       "4                              NaT          NaN           Pune India   \n",
       "\n",
       "           Question_last_edit_time  Answer_last_edit_time  \n",
       "0                              NaT                    NaT  \n",
       "1                              NaT                    NaT  \n",
       "2                              NaT                    NaT  \n",
       "3 2021-05-26 11:54:00.030000+00:00                    NaT  \n",
       "4                              NaT                    NaT  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(\n",
    "    path_so_raw, 'bq-results-20230201-032754-1675222092237.json'), lines=True)\n",
    "df['Question_tags'] = df['Question_tags'].str.split('|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag collection\n",
    "tags = set()\n",
    "for key, value in tool2tag.items():\n",
    "    tags = tags.union(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags\n",
    "df['Question_valid_tags'] = [[] for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'Question_valid_tags'] = list(tags.intersection(set(row['Question_tags'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with at least 1 tags has 5130 in total.\n",
      "Posts with at least 2 tags has 220 in total.\n",
      "Posts with at least 3 tags has 18 in total.\n"
     ]
    }
   ],
   "source": [
    "# count post number with different tags\n",
    "arity = 0\n",
    "while True:\n",
    "    post_number = df[df['Question_valid_tags'].map(len) > arity].shape[0]\n",
    "    if post_number < 1:\n",
    "        break\n",
    "    arity = arity + 1\n",
    "    print(f'Posts with at least {arity} tags has {post_number} in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-8534f91f27f9>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['Question_link'] = df_valid['Question_id'].apply(\n"
     ]
    }
   ],
   "source": [
    "# exclude Stack Overflow posts with unrelated tags\n",
    "df_valid = df[df['Question_valid_tags'].map(len) > 0]\n",
    "df_valid['Question_link'] = df_valid['Question_id'].apply(\n",
    "    lambda x: f'https://stackoverflow.com/questions/{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Stack Overflow posts with negative upvote count\n",
    "df_qualified = df_valid[df_valid['Question_score'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map from tag to tool\n",
    "tag2tool = dict()\n",
    "for key, value in tool2tag.items():\n",
    "    for elem in value:\n",
    "        tag2tool.setdefault(elem, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Stack Overflow post collection with multiple tags based on the tool map\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = set()\n",
    "    for tag in row['Question_valid_tags']:\n",
    "        tags.add(tag2tool[tag])\n",
    "    df_qualified.at[index, 'Question_valid_tags'] = sorted(list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Amazon SageMaker, MLFlow]                 16\n",
       "[Azure Machine Learning, MLFlow]           11\n",
       "[Kedro, MLFlow]                             4\n",
       "[Azure Machine Learning, Kedro, MLFlow]     2\n",
       "[DVC, MLFlow]                               1\n",
       "[MLFlow, Sacred]                            1\n",
       "[Kedro, Neptune]                            1\n",
       "Name: Question_valid_tags, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the posts with more than one tags look like\n",
    "df_multiply_tagged = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_multiply_tagged['Question_valid_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-9867e953fe3c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qualified.at[index, 'Tool'] = tags[0]\n"
     ]
    }
   ],
   "source": [
    "# create Stack Overflow post collection with exclusive tags\n",
    "multiply_tagged_posts_split = []\n",
    "df_qualified.assign(Tool='')\n",
    "\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = row['Question_valid_tags']\n",
    "    df_qualified.at[index, 'Tool'] = tags[0]\n",
    "    if len(tags) > 1:\n",
    "        for tag in tags[1:]:\n",
    "            series = row.copy()\n",
    "            series['Tool'] = tag\n",
    "            multiply_tagged_posts_split.append(series)\n",
    "\n",
    "df_multiply_tagged_posts_split = pd.DataFrame(multiply_tagged_posts_split)\n",
    "df_qualified_exclusive_tagged = pd.concat(\n",
    "    [df_qualified, df_multiply_tagged_posts_split], ignore_index=True)\n",
    "del df_qualified_exclusive_tagged['Question_valid_tags']\n",
    "\n",
    "# keep Stack Overflow posts with accepted answers\n",
    "df_qualified_exclusive_tagged_completed = df_qualified_exclusive_tagged.dropna(\n",
    "    subset=['Answer_body'])\n",
    "\n",
    "df_qualified_exclusive_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'questions.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>149</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Question  #Answered\n",
       "0         Amazon SageMaker       2233        737\n",
       "1   Azure Machine Learning       1530        586\n",
       "2                  ClearML         40         20\n",
       "3                    Comet         10          4\n",
       "4                      DVC         91         49\n",
       "5                    Kedro        149         60\n",
       "6                   MLFlow        551        129\n",
       "7                  Neptune          8          3\n",
       "8                   Sacred         10          7\n",
       "9                Vertex AI        341        112\n",
       "10        Weights & Biases         77         22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_question_summary = df_qualified_exclusive_tagged.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "df_so_answer_summary = df_qualified_exclusive_tagged_completed.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "\n",
    "df_so_question_summary.columns = ['Tool', '#Question']\n",
    "df_so_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_so_question_summary, df_so_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create question dataset\n",
    "\n",
    "df_question_so = pd.read_json(os.path.join(path_so_filtered, 'questions.json'))\n",
    "df_question_ts = pd.read_json(os.path.join(path_ts_filtered, 'questions.json'))\n",
    "\n",
    "df_question_so['Platform'] = 'Stack Overflow'\n",
    "df_question_ts['Platform'] = 'Tool-specific'\n",
    "\n",
    "df_questions = pd.concat([df_question_so, df_question_ts], ignore_index=True)\n",
    "df_questions.to_json(os.path.join(path_labeling, 'original.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add potential field to questions for later filling\n",
    "df_questions = pd.read_json(os.path.join(path_labeling_question, 'original.json'))\n",
    "\n",
    "# Experiment 1: feed the original content to BerTopic\n",
    "df_questions['Question_original_content_preprocessed_text'] = ''\n",
    "\n",
    "# Experiment 2: feed the original content to text-davinci-003 model and get the generated summary, then feed the summary to BerTopic\n",
    "df_questions['Question_original_content_gpt_summary'] = ''\n",
    "\n",
    "# Experiment 3: feed the preprocessed content to BerTopic\n",
    "df_questions['Question_preprocessed_content'] = ''\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_labeling_question, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    title = row['Question_title'].lower()\n",
    "    body = str(row['Question_body']).lower()\n",
    "    content = 'Title: ' + title + '; Content: ' + body\n",
    "    \n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, '')\n",
    "    \n",
    "    df_questions.at[index, 'Question_original_content_preprocessed_text'] = ' '.join(content.split())\n",
    "    \n",
    "df_questions.to_json(os.path.join(path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "import random\n",
    "\n",
    "question_prompt = 'Please write a one-sentence summary of the user\\'s encountered challenges. For instance, you could begin with a sentence such as: \"The user XXXX\".\\n\"\"\"'\n",
    "\n",
    "def retry_with_backoff(fn, retries=2, backoff_in_seconds=1, *args, **kwargs):\n",
    "    x = 0\n",
    "\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except:\n",
    "            if x == retries:\n",
    "                raise\n",
    "\n",
    "            sleep = backoff_in_seconds * 2 ** x + random.uniform(0, 1)\n",
    "            time.sleep(sleep)\n",
    "            x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens, however you requested 5260 tokens (5060 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 110\n",
      "persisting on question 150\n",
      "This model's maximum context length is 4097 tokens, however you requested 5293 tokens (5093 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 153\n",
      "This model's maximum context length is 4097 tokens, however you requested 4372 tokens (4172 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 181\n",
      "persisting on question 200\n",
      "This model's maximum context length is 4097 tokens, however you requested 4348 tokens (4148 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 216\n",
      "This model's maximum context length is 4097 tokens, however you requested 5660 tokens (5460 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 237\n",
      "persisting on question 250\n",
      "persisting on question 300\n",
      "This model's maximum context length is 4097 tokens, however you requested 4951 tokens (4751 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 328\n",
      "persisting on question 350\n",
      "persisting on question 400\n",
      "This model's maximum context length is 4097 tokens, however you requested 5530 tokens (5330 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 427\n",
      "This model's maximum context length is 4097 tokens, however you requested 9069 tokens (8869 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 443\n",
      "persisting on question 450\n",
      "persisting on question 500\n",
      "persisting on question 550\n",
      "This model's maximum context length is 4097 tokens, however you requested 9798 tokens (9598 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 576\n",
      "persisting on question 600\n",
      "This model's maximum context length is 4097 tokens, however you requested 6079 tokens (5879 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 649\n",
      "persisting on question 650\n",
      "persisting on question 700\n",
      "This model's maximum context length is 4097 tokens, however you requested 5153 tokens (4953 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 739\n",
      "persisting on question 750\n",
      "persisting on question 800\n",
      "persisting on question 850\n",
      "persisting on question 900\n",
      "This model's maximum context length is 4097 tokens, however you requested 5016 tokens (4816 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 916\n",
      "persisting on question 950\n",
      "persisting on question 1000\n",
      "persisting on question 1050\n",
      "persisting on question 1100\n",
      "persisting on question 1150\n",
      "This model's maximum context length is 4097 tokens, however you requested 9287 tokens (9087 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1172\n",
      "This model's maximum context length is 4097 tokens, however you requested 6736 tokens (6536 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1188\n",
      "persisting on question 1200\n",
      "persisting on question 1250\n",
      "This model's maximum context length is 4097 tokens, however you requested 4153 tokens (3953 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1288\n",
      "persisting on question 1300\n",
      "This model's maximum context length is 4097 tokens, however you requested 5820 tokens (5620 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1314\n",
      "persisting on question 1350\n",
      "persisting on question 1400\n",
      "persisting on question 1450\n",
      "persisting on question 1500\n",
      "This model's maximum context length is 4097 tokens, however you requested 9359 tokens (9159 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1504\n",
      "persisting on question 1550\n",
      "This model's maximum context length is 4097 tokens, however you requested 4756 tokens (4556 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1558\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    if row['Question_original_content_gpt_summary']:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        response = retry_with_backoff(\n",
    "            openai.Completion.create,\n",
    "            model='text-davinci-003',\n",
    "            prompt=question_prompt +\n",
    "            row['Question_original_content_preprocessed_text'] + '\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_questions.at[index, 'Question_original_content_gpt_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(f'{e} on question {index}')\n",
    "        \n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on question {index}')\n",
    "        df_questions.to_json(os.path.join(\n",
    "            path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')\n",
    "        \n",
    "    time.sleep(5)\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "# output unsuccesful summary requests\n",
    "for index, row in df_questions.iterrows():\n",
    "    if not row['Question_original_content_gpt_summary']:\n",
    "        print(row['Issue_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'))\n",
    "assert (df_questions.shape[0] == df_questions.dropna(\n",
    "    subset=['Question_original_content_gpt_summary']).shape[0])\n",
    "\n",
    "# output the number of asset-management-related discussion posts\n",
    "df_questions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size is based on the recommendation from https://www.calculator.net/sample-size-calculator.html\n",
    "\n",
    "sample_size = 368\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'))\n",
    "\n",
    "df_sample = df_questions.sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_sample.to_json(os.path.join(\n",
    "    path_labeling_question, 'sample.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# content filtering patterns\n",
    "regex_filter = r\"(<.*?>)|({.*?})|((!)?\\[.*?\\])|(\\(.*?\\))|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|([^\\s]*[<=>]=[^\\s]+)|(@[^\\s]+)|((https?:\\/)?\\/[^\\s]+)|([^\\s]*\\\\[^\\s]+)|([^\\s]+\\/[^\\s]+)|([^\\s]+\\.[^\\s]+)|([^\\s]+_[^\\s]+)|(_+[^\\s]+_*)|(_*[^\\s]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\-#*=~:{}\\(\\)\\[\\]]+)|(info(rmation)?)\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    for tag in soup(['code']):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(regex_filter, ' ', text, flags=re.S)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    title = row['Question_title'].lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "    body = row['Question_body'].lower().encode('ascii', errors='ignore').decode('ascii')    \n",
    "    content = 'Title: ' + preprocess_text(title) + '; Content: ' + preprocess_text(body)\n",
    "\n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, '')\n",
    "\n",
    "    df_questions.at[index, 'Question_preprocessed_content'] = ' '.join(content.split())\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"title\" and \"content\" from the content\n",
    "# remove \"The user\" from the beginning of the summary\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'))\n",
    "\n",
    "df_questions['Question_preprocessed_content'] = df_questions['Question_preprocessed_content'].apply(\n",
    "    lambda x: x.replace('Title: ', '').replace('Content: ', ''))\n",
    "df_questions['Question_original_content_preprocessed_text'] = df_questions['Question_original_content_preprocessed_text'].apply(\n",
    "    lambda x: x.replace('Title: ', '').replace('Content: ', ''))\n",
    "df_questions['Question_original_content_gpt_summary'] = df_questions['Question_original_content_gpt_summary'].apply(\n",
    "    lambda x: x.removeprefix('The user '))\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling_question, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create answer dataset\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_labeling_question, 'original.json'))\n",
    "df_answers = []\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    if row['Answer_body']:\n",
    "        df_answers.append(row)\n",
    "    elif row['Answer_list']:\n",
    "        df_answers.append(row)\n",
    "\n",
    "df_answers = pd.concat(df_answers, axis=1, ignore_index=True).T\n",
    "df_answers.to_json(os.path.join(path_labeling_answer, 'original.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add potential field to questions for later filling\n",
    "df_answers = pd.read_json(os.path.join(path_labeling_answer, 'original.json'))\n",
    "\n",
    "# Experiment 1: feed the original content to BerTopic\n",
    "df_answers['Answer_original_content_preprocessed_text'] = ''\n",
    "\n",
    "# Experiment 2: feed the original content to text-davinci-003 model and get the generated summary, then feed the summary to BerTopic\n",
    "df_answers['Answer_original_content_gpt_summary'] = ''\n",
    "\n",
    "# Experiment 3: feed the preprocessed content to BerTopic\n",
    "df_answers['Answer_preprocessed_content'] = ''\n",
    "\n",
    "df_answers.to_json(os.path.join(path_labeling_answer, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "\n",
    "with open(os.path.join(path_labeling_answer, 'topic_modeling.json'), encoding='utf8') as answer_file:\n",
    "    df_answers = json.load(answer_file)\n",
    "    \n",
    "    for row in df_answers:\n",
    "        answer = ''\n",
    "        if row['Answer_body']:\n",
    "            answer = row['Answer_body']\n",
    "        else:\n",
    "            if row['Question_has_accepted_answer']:\n",
    "                if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                    for comment in row['Answer_list']:\n",
    "                        if comment['Answer_has_accepted']:\n",
    "                            answer = comment['Answer_body']\n",
    "                            break\n",
    "                else:\n",
    "                    for comment in row['Answer_list']:\n",
    "                        if comment['accepted_answer']:\n",
    "                            answer = comment['cooked']\n",
    "                            break\n",
    "            elif 'Answer_body' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    answer += comment['Answer_body'] + '\\n'\n",
    "            elif 'cooked' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    answer += comment['cooked'] + '\\n'\n",
    "                    \n",
    "        answer = answer.lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "    \n",
    "        for tool_keyword in tools_keywords[row['Tool']]:\n",
    "            if tool_keyword in answer:\n",
    "                answer = answer.replace(tool_keyword, '')\n",
    "        \n",
    "        row['Answer_original_content_preprocessed_text'] = 'Answer: ' + ' '.join(answer.split())\n",
    "\n",
    "with open(os.path.join(path_labeling_answer, 'topic_modeling.json'), 'w') as outfile:\n",
    "    json_post_list = json.dumps(df_answers, indent='\\t')\n",
    "    outfile.write(json_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "\n",
    "import random\n",
    "\n",
    "answer_prompt = 'Please list the solutions (if any) from the following answer. For instance, you could begin with a sentence such as: \"There are three solutions together: [1]. XXX; [2]. YYY; [3]. ZZZ.\".\\n\"\"\"'\n",
    "\n",
    "def retry_with_backoff(fn, retries=2, backoff_in_seconds=1, *args, **kwargs):\n",
    "    x = 0\n",
    "\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except:\n",
    "            if x == retries:\n",
    "                raise\n",
    "\n",
    "            sleep = backoff_in_seconds * 2 ** x + random.uniform(0, 1)\n",
    "            time.sleep(sleep)\n",
    "            x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "\n",
    "df_answers = pd.read_json(os.path.join(\n",
    "    path_labeling_answer, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_answers.iterrows():\n",
    "    if row['Question_original_content_gpt_summary']:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        response = retry_with_backoff(\n",
    "            openai.Completion.create,\n",
    "            model='text-davinci-003',\n",
    "            prompt=question_prompt +\n",
    "            row['Answer_original_content_gpt_summary'] + '\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_answers.at[index, 'Question_original_content_gpt_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(f'{e} on answer {index}')\n",
    "        \n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on answer {index}')\n",
    "        df_answers.to_json(os.path.join(\n",
    "            path_labeling_answer, 'topic_modeling.json'), indent=4, orient='records')\n",
    "        \n",
    "    time.sleep(5)\n",
    "\n",
    "df_answers.to_json(os.path.join(\n",
    "    path_labeling_answer, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# content filtering patterns\n",
    "regex_filter = r\"(<.*?>)|({.*?})|((!)?\\[.*?\\])|(\\(.*?\\))|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|([^\\s]*[<=>]=[^\\s]+)|(@[^\\s]+)|((https?:\\/)?\\/[^\\s]+)|([^\\s]*\\\\[^\\s]+)|([^\\s]+\\/[^\\s]+)|([^\\s]+\\.[^\\s]+)|([^\\s]+_[^\\s]+)|(_+[^\\s]+_*)|(_*[^\\s]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\-#*=~:{}\\(\\)\\[\\]]+)|(info(rmation)?)\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    for tag in soup(['code']):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(regex_filter, ' ', text, flags=re.S)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6\n",
    "\n",
    "with open(os.path.join(path_labeling_answer, 'topic_modeling.json'), encoding='utf8') as answer_file:\n",
    "    df_answers = json.load(answer_file)\n",
    "    \n",
    "    for row in df_answers:\n",
    "        answer = ''\n",
    "        if row['Answer_body']:\n",
    "            answer = row['Answer_body']\n",
    "        else:\n",
    "            if row['Question_has_accepted_answer']:\n",
    "                if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                    for comment in row['Answer_list']:\n",
    "                        if comment['Answer_has_accepted']:\n",
    "                            answer = comment['Answer_body']\n",
    "                            break\n",
    "                else:\n",
    "                    for comment in row['Answer_list']:\n",
    "                        if comment['accepted_answer']:\n",
    "                            answer = comment['cooked']\n",
    "                            break\n",
    "            elif 'Answer_body' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    answer += comment['Answer_body'] + '\\n'\n",
    "            elif 'cooked' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    answer += comment['cooked'] + '\\n'\n",
    "        \n",
    "        answer = answer.lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "        answer = preprocess_text(answer)\n",
    "    \n",
    "        for tool_keyword in tools_keywords[row['Tool']]:\n",
    "            if tool_keyword in answer:\n",
    "                answer = answer.replace(tool_keyword, '')\n",
    "        \n",
    "        row['Answer_preprocessed_content'] = 'Answer: ' + ' '.join(answer.split())\n",
    "\n",
    "with open(os.path.join(path_labeling_answer, 'topic_modeling.json'), 'w') as outfile:\n",
    "    json_post_list = json.dumps(df_answers, indent='\\t')\n",
    "    outfile.write(json_post_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
