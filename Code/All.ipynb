{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2tag = {\n",
    "    'Amazon SageMaker': {'amazon-sagemaker', 'amazon-sagemaker-experiments'},\n",
    "    'Azure Machine Learning': {'azure-machine-learning-service', 'azure-machine-learning-studio', 'azure-machine-learning-workbench'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'Comet': {'comet-ml'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Kedro': {'kedro'},\n",
    "    'MLFlow': {'mlflow'},\n",
    "    'MLRun': {'mlrun'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Pachyderm': {'pachyderm'},\n",
    "    'Sacred': {'python-sacred'},\n",
    "    'Vertex AI': {'google-cloud-vertex-ai', 'vertex-ai-pipeline'},\n",
    "    'Weights & Biases': {'wandb'}\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "    'Amazon SageMaker',\n",
    "    'Azure Machine Learning',\n",
    "    'Vertex AI'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_so = os.path.join(path_dataset, 'Stack Overflow')\n",
    "path_to = os.path.join(path_dataset, 'Tool-specific Others')\n",
    "\n",
    "path_so_raw = os.path.join(path_so, 'Raw')\n",
    "path_to_raw = os.path.join(path_to, 'Raw')\n",
    "path_so_filtered = os.path.join(path_so, 'Filtered')\n",
    "path_to_filtered = os.path.join(path_to, 'Filtered')\n",
    "path_so_sampled = os.path.join(path_so, 'Sampled')\n",
    "path_to_sampled = os.path.join(path_to, 'Sampled')\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "if not os.path.isdir(path_so):\n",
    "    os.mkdir(path_so)\n",
    "\n",
    "if not os.path.isdir(path_to):\n",
    "    os.mkdir(path_to)\n",
    "\n",
    "if not os.path.isdir(path_so_raw):\n",
    "    os.mkdir(path_so_raw)\n",
    "\n",
    "if not os.path.isdir(path_to_raw):\n",
    "    os.mkdir(path_to_raw)\n",
    "\n",
    "if not os.path.isdir(path_so_filtered):\n",
    "    os.mkdir(path_so_filtered)\n",
    "\n",
    "if not os.path.isdir(path_to_filtered):\n",
    "    os.mkdir(path_to_filtered)\n",
    "\n",
    "if not os.path.isdir(path_so_sampled):\n",
    "    os.mkdir(path_so_sampled)\n",
    "\n",
    "if not os.path.isdir(path_to_sampled):\n",
    "    os.mkdir(path_to_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://my.guild.ai/'\n",
    "page_suffix = 'c/troubleshooting/6.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_time'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'Guild AI.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://community.wandb.ai/'\n",
    "page_suffix = 'c/w-b-support/36.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_time'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'Weights & Biases.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://community.sigopt.com/'\n",
    "page_suffix = 'c/general-discussion/9.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_time'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'SigOpt.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = -1\n",
    "base_url = 'https://discuss.dvc.org/'\n",
    "page_suffix = 'c/questions/9.json?page='\n",
    "post_list = []\n",
    "\n",
    "while True:\n",
    "    page = page + 1\n",
    "    page_url = base_url + page_suffix + str(page)\n",
    "    topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "    for topic in topic_list['topics']:\n",
    "        post_url = base_url + 't/' + \\\n",
    "            topic['slug'] + '/' + str(topic['id']) + '.json'\n",
    "\n",
    "        post = {}\n",
    "        post['Question_title'] = topic['title']\n",
    "        post['Question_link'] = post_url\n",
    "        post['Question_creation_time'] = topic['created_at']\n",
    "        post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "        post['Question_upvote_count'] = topic['like_count']\n",
    "        post['Question_view_count'] = topic['views']\n",
    "        post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "        comments = requests.get(post_url).json()['post_stream']['posts']\n",
    "        post['Question_body'] = comments[0]['cooked']\n",
    "        post['Answers'] = comments[1:]\n",
    "        post_list.append(post)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    if 'more_topics_url' not in topic_list.keys():\n",
    "        break\n",
    "\n",
    "json_post_list = json.dumps(post_list, indent='\\t')\n",
    "with open(os.path.join(path_to_raw, 'DVC.json'), 'w') as outfile:\n",
    "    outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to = pd.DataFrame()\n",
    "# exclude tool-specific posts with negative upvote count\n",
    "for file_name in glob.glob(os.path.join(path_to_raw, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    if 'Question_upvote_count' in repos.columns:\n",
    "        repos = repos[repos['Question_upvote_count'] > -1]\n",
    "    repos['Tool'] = os.path.split(file_name)[1].split('.')[0]\n",
    "    df_to = pd.concat([df_to, repos], ignore_index=True)\n",
    "df_to.to_json(os.path.join(path_to_filtered,\n",
    "              'non_negative_scored.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_answered = df_to[df_to['Question_answer_count'] > 0]\n",
    "for tool in df_to_answered['Tool'].unique().tolist():\n",
    "    number_accepted_answer = df_to_answered[df_to_answered['Tool']\n",
    "                                            == tool]['Question_has_accepted_answer'].sum()\n",
    "    if number_accepted_answer > 0:\n",
    "        df_to_answered = df_to_answered.drop(df_to_answered[(df_to_answered['Tool'] == tool) & (\n",
    "            df_to_answered['Question_has_accepted_answer'] == False)].index)\n",
    "df_to_answered.to_json(os.path.join(\n",
    "    path_to_filtered, 'completed_non_negative_scored.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>315</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>583</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker        528        167\n",
       "1  Azure Machine Learning       1435        343\n",
       "2                     DVC        315        300\n",
       "3                  Domino         13          4\n",
       "4                Guild AI        115        108\n",
       "5                  MLFlow        280        143\n",
       "6                Polyaxon         43         34\n",
       "7                  SigOpt         15          7\n",
       "8               Vertex AI        297         32\n",
       "9        Weights & Biases        583         92"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only posts with at least one answer\n",
    "df_to_summary = df_to.groupby('Tool').count()['Question_title'].reset_index()\n",
    "df_to_answered_summary = df_to_answered.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "\n",
    "df_to_summary.columns = ['Tool', '#Question']\n",
    "df_to_answered_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = df_to_summary.merge(df_to_answered_summary, on='Tool')\n",
    "\n",
    "df_summary.to_csv(os.path.join(path_to, 'summary.csv'), index=False)\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "      <th>#Sample Question</th>\n",
       "      <th>#Sample Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "      <td>223</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "      <td>304</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>315</td>\n",
       "      <td>300</td>\n",
       "      <td>174</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "      <td>168</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>583</td>\n",
       "      <td>92</td>\n",
       "      <td>232</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered  #Sample Question  \\\n",
       "0        Amazon SageMaker        528        167               223   \n",
       "1  Azure Machine Learning       1435        343               304   \n",
       "2                     DVC        315        300               174   \n",
       "3                  Domino         13          4                13   \n",
       "4                Guild AI        115        108                89   \n",
       "5                  MLFlow        280        143               163   \n",
       "6                Polyaxon         43         34                39   \n",
       "7                  SigOpt         15          7                15   \n",
       "8               Vertex AI        297         32               168   \n",
       "9        Weights & Biases        583         92               232   \n",
       "\n",
       "   #Sample Answered  \n",
       "0               117  \n",
       "1               182  \n",
       "2               169  \n",
       "3                 4  \n",
       "4                85  \n",
       "5               105  \n",
       "6                32  \n",
       "7                 7  \n",
       "8                30  \n",
       "9                75  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_to, 'summary.csv'))\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to = pd.read_json(os.path.join(\n",
    "    path_to_filtered, 'non_negative_scored.json'))\n",
    "df_to_answered = pd.read_json(os.path.join(\n",
    "    path_to_filtered, 'completed_non_negative_scored.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tool-specific posts accordingly\n",
    "df_question_samples = pd.DataFrame()\n",
    "df_answer_samples = pd.DataFrame()\n",
    "\n",
    "for index, row in df_summary.iterrows():\n",
    "    df_question_sample = df_to[df_to['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Question'], random_state=0)\n",
    "    df_answer_sample = df_to_answered[df_to_answered['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Answered'], random_state=0)\n",
    "    df_question_samples = pd.concat(\n",
    "        [df_question_samples, df_question_sample], ignore_index=True)\n",
    "    df_answer_samples = pd.concat(\n",
    "        [df_answer_samples, df_answer_sample], ignore_index=True)\n",
    "\n",
    "df_question_samples.to_json(os.path.join(\n",
    "    path_to_sampled, 'questions.json'), indent=4, orient='records')\n",
    "df_answer_samples.to_json(os.path.join(\n",
    "    path_to_sampled, 'answers.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question_samples = pd.read_json(\n",
    "    os.path.join(path_to_sampled, 'questions.json'))\n",
    "df_answer_samples = pd.read_json(os.path.join(path_to_sampled, 'answers.json'))\n",
    "df_question_samples.loc[lambda x: ~x['Tool'].isin(ignore_tools)].to_json(\n",
    "    os.path.join(path_to_sampled, 'lean_questions.json'), indent=4, orient='records')\n",
    "df_answer_samples.loc[lambda x: ~x['Tool'].isin(ignore_tools)].to_json(\n",
    "    os.path.join(path_to_sampled, 'lean_answers.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_time</th>\n",
       "      <th>Question_last_edit_time</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>Question_view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner_reputation</th>\n",
       "      <th>Owner_up_votes</th>\n",
       "      <th>Owner_down_votes</th>\n",
       "      <th>Owner_views</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_time</th>\n",
       "      <th>Answer_last_edit_time</th>\n",
       "      <th>Answer_score</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813663</td>\n",
       "      <td>Moving from SVN to ...?</td>\n",
       "      <td>&lt;p&gt;I'm currently working in a team where we're...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-05-01 23:10:59.753000+00:00</td>\n",
       "      <td>2009-09-03 16:11:28.613000+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>svn|git|version-control|mercurial|dvcs</td>\n",
       "      <td>779</td>\n",
       "      <td>...</td>\n",
       "      <td>8487</td>\n",
       "      <td>152</td>\n",
       "      <td>6</td>\n",
       "      <td>796</td>\n",
       "      <td>&lt;p&gt;If your team can't understand how to use su...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-02 01:43:50.463000+00:00</td>\n",
       "      <td>2009-05-02 18:09:13.013000+00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>960701</td>\n",
       "      <td>How can I always know about all tags in Mercur...</td>\n",
       "      <td>&lt;p&gt;I don't use Mercurial, but i'd like to star...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-06-06 22:27:13.100000+00:00</td>\n",
       "      <td>2012-01-31 22:15:15.020000+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>mercurial|tags|dvcs</td>\n",
       "      <td>3863</td>\n",
       "      <td>...</td>\n",
       "      <td>45209</td>\n",
       "      <td>1615</td>\n",
       "      <td>111</td>\n",
       "      <td>5992</td>\n",
       "      <td>&lt;p&gt;Versioning the &lt;code&gt;.hgtags&lt;/code&gt; file al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009-06-07 15:11:01.863000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10284208</td>\n",
       "      <td>Getting mercurial \"hg commit\" to work with Not...</td>\n",
       "      <td>&lt;p&gt;I just replaced notepad with notepad++ usin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-04-23 16:12:40.040000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>14</td>\n",
       "      <td>mercurial|notepad++|dvcs</td>\n",
       "      <td>1802</td>\n",
       "      <td>...</td>\n",
       "      <td>20932</td>\n",
       "      <td>3469</td>\n",
       "      <td>7</td>\n",
       "      <td>2823</td>\n",
       "      <td>&lt;p&gt;Try placing in your &lt;code&gt;%USERPROFILE%\\.hg...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-04-23 18:45:53.653000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51731086</td>\n",
       "      <td>Gremlin Coalesce To Add Multiple Vertices and ...</td>\n",
       "      <td>&lt;p&gt;Right now I am able to generate a query to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-08-07 16:02:32.170000+00:00</td>\n",
       "      <td>2021-07-09 09:48:56.313000+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>gremlin|tinkerpop3|amazon-neptune</td>\n",
       "      <td>5104</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;p&gt;You have a &lt;code&gt;fold()&lt;/code&gt; which is a &lt;...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-08-07 16:21:29.287000+00:00</td>\n",
       "      <td>2018-08-08 13:55:47.747000+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10236112</td>\n",
       "      <td>What is a practical workflow for keeping local...</td>\n",
       "      <td>&lt;p&gt;What I want to do is already described in &lt;...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-04-19 20:21:09.657000+00:00</td>\n",
       "      <td>2019-03-07 14:34:12.250000+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>git|version-control|dvcs</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>5795</td>\n",
       "      <td>1180</td>\n",
       "      <td>109</td>\n",
       "      <td>967</td>\n",
       "      <td>&lt;p&gt;You could try doing the following before yo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-04-19 20:26:55.353000+00:00</td>\n",
       "      <td>2020-06-20 09:12:55.060000+00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                                     Question_title  \\\n",
       "0       813663                            Moving from SVN to ...?   \n",
       "1       960701  How can I always know about all tags in Mercur...   \n",
       "2     10284208  Getting mercurial \"hg commit\" to work with Not...   \n",
       "3     51731086  Gremlin Coalesce To Add Multiple Vertices and ...   \n",
       "4     10236112  What is a practical workflow for keeping local...   \n",
       "\n",
       "                                       Question_body  Question_answer_count  \\\n",
       "0  <p>I'm currently working in a team where we're...                      9   \n",
       "1  <p>I don't use Mercurial, but i'd like to star...                      2   \n",
       "2  <p>I just replaced notepad with notepad++ usin...                      1   \n",
       "3  <p>Right now I am able to generate a query to ...                      1   \n",
       "4  <p>What I want to do is already described in <...                      1   \n",
       "\n",
       "   Question_comment_count           Question_creation_time  \\\n",
       "0                       2 2009-05-01 23:10:59.753000+00:00   \n",
       "1                       1 2009-06-06 22:27:13.100000+00:00   \n",
       "2                       1 2012-04-23 16:12:40.040000+00:00   \n",
       "3                       8 2018-08-07 16:02:32.170000+00:00   \n",
       "4                       2 2012-04-19 20:21:09.657000+00:00   \n",
       "\n",
       "           Question_last_edit_time  Question_score  \\\n",
       "0 2009-09-03 16:11:28.613000+00:00               4   \n",
       "1 2012-01-31 22:15:15.020000+00:00              16   \n",
       "2                              NaT              14   \n",
       "3 2021-07-09 09:48:56.313000+00:00               6   \n",
       "4 2019-03-07 14:34:12.250000+00:00              10   \n",
       "\n",
       "                            Question_tags  Question_view_count  ...  \\\n",
       "0  svn|git|version-control|mercurial|dvcs                  779  ...   \n",
       "1                     mercurial|tags|dvcs                 3863  ...   \n",
       "2                mercurial|notepad++|dvcs                 1802  ...   \n",
       "3       gremlin|tinkerpop3|amazon-neptune                 5104  ...   \n",
       "4                git|version-control|dvcs                  270  ...   \n",
       "\n",
       "  Owner_reputation Owner_up_votes Owner_down_votes  Owner_views  \\\n",
       "0             8487            152                6          796   \n",
       "1            45209           1615              111         5992   \n",
       "2            20932           3469                7         2823   \n",
       "3               95              2                0           22   \n",
       "4             5795           1180              109          967   \n",
       "\n",
       "                                         Answer_body  Answer_comment_count  \\\n",
       "0  <p>If your team can't understand how to use su...                   0.0   \n",
       "1  <p>Versioning the <code>.hgtags</code> file al...                   5.0   \n",
       "2  <p>Try placing in your <code>%USERPROFILE%\\.hg...                   3.0   \n",
       "3  <p>You have a <code>fold()</code> which is a <...                   5.0   \n",
       "4  <p>You could try doing the following before yo...                   3.0   \n",
       "\n",
       "              Answer_creation_time            Answer_last_edit_time  \\\n",
       "0 2009-05-02 01:43:50.463000+00:00 2009-05-02 18:09:13.013000+00:00   \n",
       "1 2009-06-07 15:11:01.863000+00:00                              NaT   \n",
       "2 2012-04-23 18:45:53.653000+00:00                              NaT   \n",
       "3 2018-08-07 16:21:29.287000+00:00 2018-08-08 13:55:47.747000+00:00   \n",
       "4 2012-04-19 20:26:55.353000+00:00 2020-06-20 09:12:55.060000+00:00   \n",
       "\n",
       "   Answer_score Question_favorite_count  \n",
       "0          20.0                     NaN  \n",
       "1          20.0                     7.0  \n",
       "2          21.0                     1.0  \n",
       "3          11.0                     2.0  \n",
       "4          10.0                     2.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(\n",
    "    path_so_raw, 'bq-results-20230116-040400-1673841891210.json'), lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag collection\n",
    "tags = []\n",
    "for key, value in tool2tag.items():\n",
    "    tags.extend(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags\n",
    "df['Question_valid_tags'] = [[] for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    row_tags = set(str(row['Question_tags']).strip().split('|'))\n",
    "    df.at[index, 'Question_valid_tags'] = list(row_tags.intersection(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with at least 1 tags has 5136 in total.\n",
      "Posts with at least 2 tags has 219 in total.\n",
      "Posts with at least 3 tags has 18 in total.\n"
     ]
    }
   ],
   "source": [
    "# count post number with different tags\n",
    "arity = 0\n",
    "while True:\n",
    "    post_number = df[df['Question_valid_tags'].map(len) > arity].shape[0]\n",
    "    if post_number < 1:\n",
    "        break\n",
    "    arity = arity + 1\n",
    "    print(f'Posts with at least {arity} tags has {post_number} in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhimi\\AppData\\Local\\Temp\\ipykernel_11552\\105066014.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['Question_link'] = df_valid['Question_id'].apply(\n"
     ]
    }
   ],
   "source": [
    "# exclude Stack Overflow posts with unrelated tags\n",
    "df_valid = df[df['Question_valid_tags'].map(len) > 0]\n",
    "df_valid['Question_link'] = df_valid['Question_id'].apply(\n",
    "    lambda x: f'https://stackoverflow.com/questions/{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Stack Overflow posts with negative upvote count\n",
    "df_qualified = df_valid[df_valid['Question_score'] > -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon SageMaker'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Amazon SageMaker'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Azure Machine Learning'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Azure Machine Learning'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Azure Machine Learning'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ClearML'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Comet'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'DVC'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Kedro'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'MLFlow'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'MLRun'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Neptune'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Pachyderm'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Sacred'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Vertex AI'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Vertex AI'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Weights & Biases'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a map from tag to tool\n",
    "tag2tool = {}\n",
    "for key, value in tool2tag.items():\n",
    "    for elem in value:\n",
    "        tag2tool.setdefault(elem, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Stack Overflow post collection with multiple tags based on the tool map\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = set()\n",
    "    for tag in row['Question_valid_tags']:\n",
    "        tags.add(tag2tool[tag])\n",
    "    df_qualified.at[index, 'Question_valid_tags'] = sorted(list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Amazon SageMaker, MLFlow]                 16\n",
       "[Azure Machine Learning, MLFlow]           11\n",
       "[Kedro, MLFlow]                             4\n",
       "[Azure Machine Learning, Kedro, MLFlow]     2\n",
       "[MLFlow, Sacred]                            1\n",
       "[DVC, Pachyderm]                            1\n",
       "[Kedro, Neptune]                            1\n",
       "[DVC, MLFlow]                               1\n",
       "Name: Question_valid_tags, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the posts with more than one tags look like\n",
    "df_multiply_tagged = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_multiply_tagged['Question_valid_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_time</th>\n",
       "      <th>Question_last_edit_time</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>Question_view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner_views</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_time</th>\n",
       "      <th>Answer_last_edit_time</th>\n",
       "      <th>Answer_score</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "      <th>Question_valid_tags</th>\n",
       "      <th>Question_link</th>\n",
       "      <th>Question_exclusive_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65112585</td>\n",
       "      <td>Pip installation stuck in infinite loop if unr...</td>\n",
       "      <td>&lt;p&gt;Pip installation is stuck in an infinite lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-12-02 16:54:05.387000+00:00</td>\n",
       "      <td>2020-12-23 16:06:48.113000+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>python|pip|azure-machine-learning-service</td>\n",
       "      <td>2146</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Workarounds:&lt;/p&gt;\\n&lt;p&gt;Local environment:\\nDo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-02 17:02:08.563000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Azure Machine Learning]</td>\n",
       "      <td>https://stackoverflow.com/questions/65112585</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69024005</td>\n",
       "      <td>How to use SageMaker Estimator for model train...</td>\n",
       "      <td>&lt;p&gt;The documentations of how to use SageMaker ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-02 04:01:47.170000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>27</td>\n",
       "      <td>amazon-web-services|amazon-sagemaker</td>\n",
       "      <td>6655</td>\n",
       "      <td>...</td>\n",
       "      <td>968</td>\n",
       "      <td>&lt;h1&gt;Answer&lt;/h1&gt;\\n&lt;p&gt;There is no one such resou...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-09-02 04:01:47.170000+00:00</td>\n",
       "      <td>2022-07-04 05:43:30.063000+00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Amazon SageMaker]</td>\n",
       "      <td>https://stackoverflow.com/questions/69024005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53609409</td>\n",
       "      <td>Automatically \"stop\" Sagemaker notebook instan...</td>\n",
       "      <td>&lt;p&gt;I have a Sagemaker Jupyter notebook instanc...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-04 09:18:11.383000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>19</td>\n",
       "      <td>amazon-web-services|aws-lambda|amazon-cloudwat...</td>\n",
       "      <td>12683</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>&lt;p&gt;You can use &lt;a href=\"https://aws.amazon.com...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-15 09:46:13.200000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[Amazon SageMaker]</td>\n",
       "      <td>https://stackoverflow.com/questions/53609409</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>62422682</td>\n",
       "      <td>sagemaker notebook instance Elastic Inference ...</td>\n",
       "      <td>&lt;p&gt;I am trying to replicate &lt;a href=\"https://g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-17 06:25:29.670000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2</td>\n",
       "      <td>tensorflow|amazon-sagemaker</td>\n",
       "      <td>350</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>&lt;p&gt;Solved it. The error I was getting is due t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-06-23 01:37:54.340000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Amazon SageMaker]</td>\n",
       "      <td>https://stackoverflow.com/questions/62422682</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60525454</td>\n",
       "      <td>Intel optimized Python on Machine Learning Ser...</td>\n",
       "      <td>&lt;p&gt;Is it possible to run a Python script or Es...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-04 11:54:09.310000+00:00</td>\n",
       "      <td>2020-03-04 20:46:17.670000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>azure-machine-learning-service</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;The Azure ML base images use &lt;a href=\"https...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-03-04 18:14:24.733000+00:00</td>\n",
       "      <td>2020-03-05 19:46:14.647000+00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Azure Machine Learning]</td>\n",
       "      <td>https://stackoverflow.com/questions/60525454</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793</th>\n",
       "      <td>34990561</td>\n",
       "      <td>Azure Machine Learning Request Response latency</td>\n",
       "      <td>&lt;p&gt;I have made an Azure Machine Learning Exper...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-25 10:40:39.993000+00:00</td>\n",
       "      <td>2016-01-27 16:15:36.527000+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>python|azure|azure-machine-learning-studio</td>\n",
       "      <td>1128</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>&lt;p&gt;First, I am assuming you are doing your tim...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016-01-26 18:20:06.127000+00:00</td>\n",
       "      <td>2016-01-27 16:10:48.927000+00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Azure Machine Learning]</td>\n",
       "      <td>https://stackoverflow.com/questions/34990561</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>49977679</td>\n",
       "      <td>upload data to S3 with sagemaker</td>\n",
       "      <td>&lt;p&gt;I have a problem with SageMaker when I try ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-23 09:31:28.687000+00:00</td>\n",
       "      <td>2018-12-06 22:53:27.193000+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>amazon-s3|amazon-sagemaker</td>\n",
       "      <td>9575</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>&lt;p&gt;It is exactly as the error say, the variabl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-23 16:25:22.233000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Amazon SageMaker]</td>\n",
       "      <td>https://stackoverflow.com/questions/49977679</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>55580232</td>\n",
       "      <td>Update SageMaker Jupyterlab environment</td>\n",
       "      <td>&lt;p&gt;How can I update my SageMaker notebook's ju...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-08 19:10:35.030000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon-sagemaker|jupyter-lab</td>\n",
       "      <td>1720</td>\n",
       "      <td>...</td>\n",
       "      <td>958</td>\n",
       "      <td>&lt;p&gt;Hi and thank you for using SageMaker!&lt;/p&gt;\\n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-04-11 18:28:36.017000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Amazon SageMaker]</td>\n",
       "      <td>https://stackoverflow.com/questions/55580232</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>58956459</td>\n",
       "      <td>How to run authentication on a mlFlow server?</td>\n",
       "      <td>&lt;p&gt;As I am logging my entire models and params...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 14:16:40.087000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>11</td>\n",
       "      <td>nginx|basic-authentication|mlflow</td>\n",
       "      <td>13870</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>&lt;p&gt;the problem here is that both &lt;code&gt;mlflow&lt;...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-12-13 16:37:32.617000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[MLFlow]</td>\n",
       "      <td>https://stackoverflow.com/questions/58956459</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>60355240</td>\n",
       "      <td>Pipeline can't find nodes in kedro</td>\n",
       "      <td>&lt;p&gt;I was following &lt;a href=\"https://kedro.read...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22 18:11:41.757000+00:00</td>\n",
       "      <td>2020-03-02 18:53:06.660000+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>python|kedro</td>\n",
       "      <td>2155</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>&lt;p&gt;I think it looks like you need to have the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-02-23 03:14:40.590000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Kedro]</td>\n",
       "      <td>https://stackoverflow.com/questions/60355240</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5008 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Question_id                                     Question_title  \\\n",
       "7        65112585  Pip installation stuck in infinite loop if unr...   \n",
       "8        69024005  How to use SageMaker Estimator for model train...   \n",
       "16       53609409  Automatically \"stop\" Sagemaker notebook instan...   \n",
       "18       62422682  sagemaker notebook instance Elastic Inference ...   \n",
       "31       60525454  Intel optimized Python on Machine Learning Ser...   \n",
       "...           ...                                                ...   \n",
       "6793     34990561    Azure Machine Learning Request Response latency   \n",
       "6801     49977679                   upload data to S3 with sagemaker   \n",
       "6803     55580232            Update SageMaker Jupyterlab environment   \n",
       "6806     58956459      How to run authentication on a mlFlow server?   \n",
       "6807     60355240                 Pipeline can't find nodes in kedro   \n",
       "\n",
       "                                          Question_body  \\\n",
       "7     <p>Pip installation is stuck in an infinite lo...   \n",
       "8     <p>The documentations of how to use SageMaker ...   \n",
       "16    <p>I have a Sagemaker Jupyter notebook instanc...   \n",
       "18    <p>I am trying to replicate <a href=\"https://g...   \n",
       "31    <p>Is it possible to run a Python script or Es...   \n",
       "...                                                 ...   \n",
       "6793  <p>I have made an Azure Machine Learning Exper...   \n",
       "6801  <p>I have a problem with SageMaker when I try ...   \n",
       "6803  <p>How can I update my SageMaker notebook's ju...   \n",
       "6806  <p>As I am logging my entire models and params...   \n",
       "6807  <p>I was following <a href=\"https://kedro.read...   \n",
       "\n",
       "      Question_answer_count  Question_comment_count  \\\n",
       "7                         1                       6   \n",
       "8                         1                       0   \n",
       "16                        4                       0   \n",
       "18                        1                       0   \n",
       "31                        1                       0   \n",
       "...                     ...                     ...   \n",
       "6793                      1                       0   \n",
       "6801                      1                       0   \n",
       "6803                      1                       0   \n",
       "6806                      4                       1   \n",
       "6807                      2                       0   \n",
       "\n",
       "               Question_creation_time          Question_last_edit_time  \\\n",
       "7    2020-12-02 16:54:05.387000+00:00 2020-12-23 16:06:48.113000+00:00   \n",
       "8    2021-09-02 04:01:47.170000+00:00                              NaT   \n",
       "16   2018-12-04 09:18:11.383000+00:00                              NaT   \n",
       "18   2020-06-17 06:25:29.670000+00:00                              NaT   \n",
       "31   2020-03-04 11:54:09.310000+00:00 2020-03-04 20:46:17.670000+00:00   \n",
       "...                               ...                              ...   \n",
       "6793 2016-01-25 10:40:39.993000+00:00 2016-01-27 16:15:36.527000+00:00   \n",
       "6801 2018-04-23 09:31:28.687000+00:00 2018-12-06 22:53:27.193000+00:00   \n",
       "6803 2019-04-08 19:10:35.030000+00:00                              NaT   \n",
       "6806 2019-11-20 14:16:40.087000+00:00                              NaT   \n",
       "6807 2020-02-22 18:11:41.757000+00:00 2020-03-02 18:53:06.660000+00:00   \n",
       "\n",
       "      Question_score                                      Question_tags  \\\n",
       "7                 13          python|pip|azure-machine-learning-service   \n",
       "8                 27               amazon-web-services|amazon-sagemaker   \n",
       "16                19  amazon-web-services|aws-lambda|amazon-cloudwat...   \n",
       "18                 2                        tensorflow|amazon-sagemaker   \n",
       "31                 0                     azure-machine-learning-service   \n",
       "...              ...                                                ...   \n",
       "6793               8         python|azure|azure-machine-learning-studio   \n",
       "6801               5                         amazon-s3|amazon-sagemaker   \n",
       "6803               4                       amazon-sagemaker|jupyter-lab   \n",
       "6806              11                  nginx|basic-authentication|mlflow   \n",
       "6807               4                                       python|kedro   \n",
       "\n",
       "      Question_view_count  ... Owner_views  \\\n",
       "7                    2146  ...           3   \n",
       "8                    6655  ...         968   \n",
       "16                  12683  ...         167   \n",
       "18                    350  ...          62   \n",
       "31                     81  ...           3   \n",
       "...                   ...  ...         ...   \n",
       "6793                 1128  ...          34   \n",
       "6801                 9575  ...         108   \n",
       "6803                 1720  ...         958   \n",
       "6806                13870  ...         118   \n",
       "6807                 2155  ...          91   \n",
       "\n",
       "                                            Answer_body Answer_comment_count  \\\n",
       "7     <p>Workarounds:</p>\\n<p>Local environment:\\nDo...                  2.0   \n",
       "8     <h1>Answer</h1>\\n<p>There is no one such resou...                  4.0   \n",
       "16    <p>You can use <a href=\"https://aws.amazon.com...                  1.0   \n",
       "18    <p>Solved it. The error I was getting is due t...                  2.0   \n",
       "31    <p>The Azure ML base images use <a href=\"https...                  5.0   \n",
       "...                                                 ...                  ...   \n",
       "6793  <p>First, I am assuming you are doing your tim...                 11.0   \n",
       "6801  <p>It is exactly as the error say, the variabl...                  1.0   \n",
       "6803  <p>Hi and thank you for using SageMaker!</p>\\n...                  1.0   \n",
       "6806  <p>the problem here is that both <code>mlflow<...                  3.0   \n",
       "6807  <p>I think it looks like you need to have the ...                  1.0   \n",
       "\n",
       "                 Answer_creation_time            Answer_last_edit_time  \\\n",
       "7    2020-12-02 17:02:08.563000+00:00                              NaT   \n",
       "8    2021-09-02 04:01:47.170000+00:00 2022-07-04 05:43:30.063000+00:00   \n",
       "16   2019-10-15 09:46:13.200000+00:00                              NaT   \n",
       "18   2020-06-23 01:37:54.340000+00:00                              NaT   \n",
       "31   2020-03-04 18:14:24.733000+00:00 2020-03-05 19:46:14.647000+00:00   \n",
       "...                               ...                              ...   \n",
       "6793 2016-01-26 18:20:06.127000+00:00 2016-01-27 16:10:48.927000+00:00   \n",
       "6801 2018-04-23 16:25:22.233000+00:00                              NaT   \n",
       "6803 2019-04-11 18:28:36.017000+00:00                              NaT   \n",
       "6806 2019-12-13 16:37:32.617000+00:00                              NaT   \n",
       "6807 2020-02-23 03:14:40.590000+00:00                              NaT   \n",
       "\n",
       "      Answer_score  Question_favorite_count       Question_valid_tags  \\\n",
       "7             12.0                      NaN  [Azure Machine Learning]   \n",
       "8             65.0                     14.0        [Amazon SageMaker]   \n",
       "16            26.0                      2.0        [Amazon SageMaker]   \n",
       "18            -1.0                      NaN        [Amazon SageMaker]   \n",
       "31            -1.0                      NaN  [Azure Machine Learning]   \n",
       "...            ...                      ...                       ...   \n",
       "6793           8.0                      5.0  [Azure Machine Learning]   \n",
       "6801           8.0                      1.0        [Amazon SageMaker]   \n",
       "6803           8.0                      NaN        [Amazon SageMaker]   \n",
       "6806           8.0                      3.0                  [MLFlow]   \n",
       "6807           8.0                      NaN                   [Kedro]   \n",
       "\n",
       "                                     Question_link Question_exclusive_tag  \n",
       "7     https://stackoverflow.com/questions/65112585                         \n",
       "8     https://stackoverflow.com/questions/69024005                         \n",
       "16    https://stackoverflow.com/questions/53609409                         \n",
       "18    https://stackoverflow.com/questions/62422682                         \n",
       "31    https://stackoverflow.com/questions/60525454                         \n",
       "...                                            ...                    ...  \n",
       "6793  https://stackoverflow.com/questions/34990561                         \n",
       "6801  https://stackoverflow.com/questions/49977679                         \n",
       "6803  https://stackoverflow.com/questions/55580232                         \n",
       "6806  https://stackoverflow.com/questions/58956459                         \n",
       "6807  https://stackoverflow.com/questions/60355240                         \n",
       "\n",
       "[5008 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhimi\\AppData\\Local\\Temp\\ipykernel_11552\\3348297299.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qualified.at[index, 'Question_exclusive_tag'] = tags[0]\n"
     ]
    }
   ],
   "source": [
    "# create Stack Overflow post collection with exclusive tags\n",
    "multiply_tagged_posts_split = []\n",
    "df_qualified.assign(Question_exclusive_tag='')\n",
    "\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = row['Question_valid_tags']\n",
    "    df_qualified.at[index, 'Question_exclusive_tag'] = tags[0]\n",
    "    if len(tags) > 1:\n",
    "        for tag in tags[1:]:\n",
    "            series = row.copy()\n",
    "            series['Question_exclusive_tag'] = tag\n",
    "            multiply_tagged_posts_split.append(series)\n",
    "\n",
    "df_multiply_tagged_posts_split = pd.DataFrame(multiply_tagged_posts_split)\n",
    "df_qualified_exclusive_tagged = pd.concat(\n",
    "    [df_qualified, df_multiply_tagged_posts_split], ignore_index=True)\n",
    "del df_qualified_exclusive_tagged['Question_valid_tags']\n",
    "df_qualified_exclusive_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'non_negative_scored_exclusively_tagged.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Stack Overflow posts with accepted answers\n",
    "df_qualified_exclusive_tagged_completed = df_qualified_exclusive_tagged.dropna(\n",
    "    subset=['Answer_body'])\n",
    "df_qualified_exclusive_tagged_completed.to_json(os.path.join(\n",
    "    path_so_filtered, 'completed_non_negative_scored_exclusively_tagged.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>149</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Question  #Answered\n",
       "0         Amazon SageMaker       2233        737\n",
       "1   Azure Machine Learning       1530        586\n",
       "2                  ClearML         40         20\n",
       "3                    Comet         10          4\n",
       "4                      DVC         91         49\n",
       "5                    Kedro        149         60\n",
       "6                   MLFlow        551        129\n",
       "7                  Neptune          8          3\n",
       "8                Pachyderm          7          2\n",
       "9                   Sacred         10          7\n",
       "10               Vertex AI        341        112\n",
       "11        Weights & Biases         77         22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_summary = df_qualified_exclusive_tagged.groupby(\n",
    "    'Question_exclusive_tag').count()['Question_id'].reset_index()\n",
    "df_so_answered_summary = df_qualified_exclusive_tagged_completed.groupby(\n",
    "    'Question_exclusive_tag').count()['Question_id'].reset_index()\n",
    "\n",
    "df_so_summary.columns = ['Tool', '#Question']\n",
    "df_so_answered_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_so_summary, df_so_answered_summary, on='Tool')\n",
    "df_summary.to_csv(os.path.join(path_so, 'summary.csv'), index=False)\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "      <th>#Sample Question</th>\n",
       "      <th>#Sample Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "      <td>328</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "      <td>308</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>149</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "      <td>227</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "      <td>181</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Question  #Answered  #Sample Question  \\\n",
       "0         Amazon SageMaker       2233        737               328   \n",
       "1   Azure Machine Learning       1530        586               308   \n",
       "2                  ClearML         40         20                37   \n",
       "3                    Comet         10          4                10   \n",
       "4                      DVC         91         49                74   \n",
       "5                    Kedro        149         60               108   \n",
       "6                   MLFlow        551        129               227   \n",
       "7                  Neptune          8          3                 8   \n",
       "8                Pachyderm          7          2                 7   \n",
       "9                   Sacred         10          7                10   \n",
       "10               Vertex AI        341        112               181   \n",
       "11        Weights & Biases         77         22                65   \n",
       "\n",
       "    #Sample Answered  \n",
       "0                253  \n",
       "1                233  \n",
       "2                 20  \n",
       "3                  4  \n",
       "4                 44  \n",
       "5                 53  \n",
       "6                 97  \n",
       "7                  3  \n",
       "8                  2  \n",
       "9                  7  \n",
       "10                87  \n",
       "11                21  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_so, 'summary.csv'))\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qualified_exclusive_tagged = pd.read_json(os.path.join(\n",
    "    path_so_filtered, 'non_negative_scored_exclusively_tagged.json'))\n",
    "df_qualified_exclusive_tagged_completed = pd.read_json(os.path.join(\n",
    "    path_so_filtered, 'completed_non_negative_scored_exclusively_tagged.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Stack Overflow posts accordingly\n",
    "df_question_samples = pd.DataFrame()\n",
    "df_answer_samples = pd.DataFrame()\n",
    "\n",
    "for index, row in df_summary.iterrows():\n",
    "    df_question_sample = df_qualified_exclusive_tagged[df_qualified_exclusive_tagged['Question_exclusive_tag'] == row['Tool']].sample(\n",
    "        n=row['#Sample Question'], random_state=0)\n",
    "    df_answer_sample = df_qualified_exclusive_tagged_completed[df_qualified_exclusive_tagged_completed['Question_exclusive_tag'] == row['Tool']].sample(\n",
    "        n=row['#Sample Answered'], random_state=0)\n",
    "    df_question_samples = pd.concat(\n",
    "        [df_question_samples, df_question_sample], ignore_index=True)\n",
    "    df_answer_samples = pd.concat(\n",
    "        [df_answer_samples, df_answer_sample], ignore_index=True)\n",
    "\n",
    "df_question_samples.to_json(os.path.join(\n",
    "    path_so_sampled, 'questions.json'), indent=4, orient='records')\n",
    "df_answer_samples.to_json(os.path.join(\n",
    "    path_so_sampled, 'answers.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question_samples = pd.read_json(\n",
    "    os.path.join(path_so_sampled, 'questions.json'))\n",
    "df_answer_samples = pd.read_json(os.path.join(path_so_sampled, 'answers.json'))\n",
    "df_question_samples.loc[lambda x: ~x['Question_exclusive_tag'].isin(ignore_tools)].to_json(\n",
    "    os.path.join(path_so_sampled, 'lean_questions.json'), indent=4, orient='records')\n",
    "df_answer_samples.loc[lambda x: ~x['Question_exclusive_tag'].isin(ignore_tools)].to_json(\n",
    "    os.path.join(path_so_sampled, 'lean_answers.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9e7b88a259684df50811b5249344f7cc06d54cdb1cf11111ce301ae44eac9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
