{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_so = os.path.join(path_dataset, 'Stack Overflow')\n",
    "path_ts = os.path.join(path_dataset, 'Tool-specific Others')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_so_raw = os.path.join(path_so, 'Raw')\n",
    "path_ts_raw = os.path.join(path_ts, 'Raw')\n",
    "path_so_filtered = os.path.join(path_so, 'Filtered')\n",
    "path_ts_filtered = os.path.join(path_ts, 'Filtered')\n",
    "\n",
    "path_labeling_question = os.path.join(path_labeling, 'Question')\n",
    "path_labeling_answer = os.path.join(path_labeling, 'Answer')\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "if not os.path.isdir(path_so):\n",
    "    os.mkdir(path_so)\n",
    "\n",
    "if not os.path.isdir(path_ts):\n",
    "    os.mkdir(path_ts)\n",
    "\n",
    "if not os.path.isdir(path_labeling):\n",
    "    os.mkdir(path_labeling)\n",
    "\n",
    "if not os.path.isdir(path_so_raw):\n",
    "    os.mkdir(path_so_raw)\n",
    "\n",
    "if not os.path.isdir(path_ts_raw):\n",
    "    os.mkdir(path_ts_raw)\n",
    "\n",
    "if not os.path.isdir(path_so_filtered):\n",
    "    os.mkdir(path_so_filtered)\n",
    "\n",
    "if not os.path.isdir(path_ts_filtered):\n",
    "    os.mkdir(path_ts_filtered)\n",
    "\n",
    "if not os.path.exists(path_labeling_question):\n",
    "    os.makedirs(path_labeling_question)\n",
    "\n",
    "if not os.path.exists(path_labeling_answer):\n",
    "    os.makedirs(path_labeling_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2tag = {\n",
    "    'Amazon SageMaker': {'amazon-sagemaker', 'amazon-sagemaker-experiments', 'amazon-sagemaker-studio'},\n",
    "    'Azure Machine Learning': {'azure-machine-learning-service', 'azure-machine-learning-studio', 'azure-machine-learning-workbench'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'Comet': {'comet-ml'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Kedro': {'kedro'},\n",
    "    'MLflow': {'mlflow'},\n",
    "    'MLRun': {'mlrun'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Sacred': {'python-sacred'},\n",
    "    'Vertex AI': {'google-cloud-vertex-ai'},\n",
    "    'Weights & Biases': {'wandb'}\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Amazon SageMaker': ['amazon sagemaker', 'aws sagemaker', 'sagemaker'],\n",
    "    'Azure Machine Learning': ['microsoft azure machine learning', 'azure machine learning', 'microsoft azure ml', 'microsoft azureml', 'azure ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'Comet': ['comet'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Vertex AI': ['google vertex ai', 'vertex ai'],\n",
    "    'Weights & Biases': ['weights & biases', 'weights and biases', 'wandb']\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# function to scrape the posts from the tool-specific discussion fora\n",
    "\n",
    "\n",
    "def scrape_post(base_url, page_suffix, file_name):\n",
    "    page = -1\n",
    "    post_list = []\n",
    "\n",
    "    while True:\n",
    "        page = page + 1\n",
    "        page_url = base_url + page_suffix + str(page)\n",
    "        topic_list = requests.get(page_url).json()['topic_list']\n",
    "\n",
    "        for topic in topic_list['topics']:\n",
    "            post_url = base_url + 't/' + \\\n",
    "                topic['slug'] + '/' + str(topic['id'])\n",
    "\n",
    "            post = {}\n",
    "            post['Question_title'] = topic['title']\n",
    "            post['Question_link'] = post_url\n",
    "            post['Question_creation_time'] = topic['created_at']\n",
    "            post['Question_answer_count'] = topic['posts_count'] - 1\n",
    "            post['Question_score'] = topic['like_count']\n",
    "            post['Question_view_count'] = topic['views']\n",
    "            post['Question_has_accepted_answer'] = topic['has_accepted_answer']\n",
    "            comments = requests.get(\n",
    "                post_url + '.json').json()['post_stream']['posts']\n",
    "            post['Question_body'] = comments[0]['cooked']\n",
    "            \n",
    "            answer_list = []\n",
    "            for comment in comments[1:]:\n",
    "                answer = {}\n",
    "                answer['Answer_creation_time'] = comment['created_at']\n",
    "                answer['Answer_body'] = comment['cooked']\n",
    "                answer['Answer_score'] = comment['score']\n",
    "                answer['Answer_has_accepted'] = comment['accepted_answer']\n",
    "                answer_list.append(answer)                \n",
    "            post['Answer_list'] = answer_list\n",
    "            \n",
    "            post_list.append(post)\n",
    "            time.sleep(5)\n",
    "\n",
    "        if 'more_topics_url' not in topic_list.keys():\n",
    "            break\n",
    "\n",
    "    with open(os.path.join(path_ts_raw, file_name), 'w') as outfile:\n",
    "        json_post_list = json.dumps(post_list, indent='\\t')\n",
    "        outfile.write(json_post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Guild AI\n",
    "base_url = 'https://my.guild.ai/'\n",
    "page_suffix = 'c/troubleshooting/6.json?page='\n",
    "file_name = 'Guild AI.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from Weights & Biases\n",
    "base_url = 'https://community.wandb.ai/'\n",
    "page_suffix = 'c/w-b-support/36.json?page='\n",
    "file_name = 'Weights & Biases.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from SigOpt\n",
    "base_url = 'https://community.sigopt.com/'\n",
    "page_suffix = 'c/general-discussion/9.json?page='\n",
    "file_name = 'SigOpt.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape posts from DVC\n",
    "base_url = 'https://discuss.dvc.org/'\n",
    "page_suffix = 'c/questions/9.json?page='\n",
    "file_name = 'DVC.json'\n",
    "scrape_post(base_url, page_suffix, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# exclude tool-specific posts with negative upvote count\n",
    "df_ts_questions = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_ts_raw, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    if 'Question_score' in repos.columns:\n",
    "        repos = repos[repos['Question_score'] > -1]\n",
    "    repos['Tool'] = os.path.split(file_name)[1].split('.')[0]\n",
    "    df_ts_questions = pd.concat([df_ts_questions, repos], ignore_index=True)\n",
    "\n",
    "df_ts_questions.to_json(os.path.join(path_ts_filtered,\n",
    "                                     'questions.json'), orient='records', indent=4)\n",
    "\n",
    "# keep only posts with at least one answer\n",
    "df_ts_answers = df_ts_questions[df_ts_questions['Question_answer_count'] > 0]\n",
    "\n",
    "for tool in df_ts_answers['Tool'].unique().tolist():\n",
    "    number_accepted_answer = df_ts_answers[df_ts_answers['Tool']\n",
    "                                           == tool]['Question_has_accepted_answer'].sum()\n",
    "    if number_accepted_answer > 0:\n",
    "        df_ts_answers = df_ts_answers.drop(df_ts_answers[(df_ts_answers['Tool'] == tool) & (\n",
    "            df_ts_answers['Question_has_accepted_answer'] == False)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>528</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1435</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DVC</td>\n",
       "      <td>348</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domino</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>280</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>735</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  #Question  #Answered\n",
       "0        Amazon SageMaker        528        167\n",
       "1  Azure Machine Learning       1435        343\n",
       "2                     DVC        348        330\n",
       "3                  Domino         13          4\n",
       "4                Guild AI        118        109\n",
       "5                  MLFlow        280        143\n",
       "6                Polyaxon         43         34\n",
       "7                  SigOpt         15          7\n",
       "8               Vertex AI        297         32\n",
       "9        Weights & Biases        735        117"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_question_summary = df_ts_questions.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "df_ts_answer_summary = df_ts_answers.groupby(\n",
    "    'Tool').count()['Question_title'].reset_index()\n",
    "\n",
    "df_ts_question_summary.columns = ['Tool', '#Question']\n",
    "df_ts_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_ts_question_summary, df_ts_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Question_body</th>\n",
       "      <th>Question_answer_count</th>\n",
       "      <th>Question_comment_count</th>\n",
       "      <th>Question_creation_time</th>\n",
       "      <th>Question_favorite_count</th>\n",
       "      <th>Question_score</th>\n",
       "      <th>Question_tags</th>\n",
       "      <th>Question_view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner_up_votes</th>\n",
       "      <th>Owner_down_votes</th>\n",
       "      <th>Owner_views</th>\n",
       "      <th>Answer_body</th>\n",
       "      <th>Answer_comment_count</th>\n",
       "      <th>Answer_creation_time</th>\n",
       "      <th>Answer_score</th>\n",
       "      <th>Owner_location</th>\n",
       "      <th>Question_last_edit_time</th>\n",
       "      <th>Answer_last_edit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70098779</td>\n",
       "      <td>How to connect to MLFlow tracking server that ...</td>\n",
       "      <td>&lt;p&gt;I want to connect to remote tracking server...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-24 15:30:11.310000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[authorization, tracking, mlflow]</td>\n",
       "      <td>2102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://mlflow.org/docs/latest/tra...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-11-24 17:01:13.483000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38927230</td>\n",
       "      <td>Panda AssertionError columns passed, passed da...</td>\n",
       "      <td>&lt;p&gt;I am working on Azure ML implementation on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-12 22:23:17.197000+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>[python, pandas, dataframe, nltk, azure-machin...</td>\n",
       "      <td>48200</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>55</td>\n",
       "      <td>339</td>\n",
       "      <td>&lt;p&gt;Try this:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;dataframe_outpu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-08-12 22:26:09.603000+00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Toronto, ON, Canada</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68773463</td>\n",
       "      <td>AccessDeniedException on sagemaker:CreateDomai...</td>\n",
       "      <td>&lt;p&gt;I am trying to use the AWS SageMaker Studio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-13 13:49:08.683000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[amazon-web-services, amazon-iam, amazon-sagem...</td>\n",
       "      <td>366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67701971</td>\n",
       "      <td>How to label a text with multiple paragraphs i...</td>\n",
       "      <td>&lt;p&gt;I was trying setup a single label labeling ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-26 09:16:33.420000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[amazon-web-services, text, amazon-sagemaker, ...</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zürich, Suïssa</td>\n",
       "      <td>2021-05-26 11:54:00.030000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48398509</td>\n",
       "      <td>How to Invoke AWS Sagemaker API with c# .NET?</td>\n",
       "      <td>&lt;p&gt;I have trained and deployed a model in AWS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-23 09:42:48.607000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[c#, asp.net, amazon-web-services, aws-sdk, am...</td>\n",
       "      <td>743</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pune India</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                                     Question_title  \\\n",
       "0     70098779  How to connect to MLFlow tracking server that ...   \n",
       "1     38927230  Panda AssertionError columns passed, passed da...   \n",
       "2     68773463  AccessDeniedException on sagemaker:CreateDomai...   \n",
       "3     67701971  How to label a text with multiple paragraphs i...   \n",
       "4     48398509      How to Invoke AWS Sagemaker API with c# .NET?   \n",
       "\n",
       "                                       Question_body  Question_answer_count  \\\n",
       "0  <p>I want to connect to remote tracking server...                      1   \n",
       "1  <p>I am working on Azure ML implementation on ...                      1   \n",
       "2  <p>I am trying to use the AWS SageMaker Studio...                      1   \n",
       "3  <p>I was trying setup a single label labeling ...                      0   \n",
       "4  <p>I have trained and deployed a model in AWS ...                      1   \n",
       "\n",
       "   Question_comment_count           Question_creation_time  \\\n",
       "0                       0 2021-11-24 15:30:11.310000+00:00   \n",
       "1                       0 2016-08-12 22:23:17.197000+00:00   \n",
       "2                       0 2021-08-13 13:49:08.683000+00:00   \n",
       "3                       2 2021-05-26 09:16:33.420000+00:00   \n",
       "4                       0 2018-01-23 09:42:48.607000+00:00   \n",
       "\n",
       "   Question_favorite_count  Question_score  \\\n",
       "0                      1.0               1   \n",
       "1                      3.0               7   \n",
       "2                      NaN               0   \n",
       "3                      NaN               1   \n",
       "4                      NaN               0   \n",
       "\n",
       "                                       Question_tags  Question_view_count  \\\n",
       "0                  [authorization, tracking, mlflow]                 2102   \n",
       "1  [python, pandas, dataframe, nltk, azure-machin...                48200   \n",
       "2  [amazon-web-services, amazon-iam, amazon-sagem...                  366   \n",
       "3  [amazon-web-services, text, amazon-sagemaker, ...                  161   \n",
       "4  [c#, asp.net, amazon-web-services, aws-sdk, am...                  743   \n",
       "\n",
       "   ... Owner_up_votes Owner_down_votes  Owner_views  \\\n",
       "0  ...              0                0           11   \n",
       "1  ...            136               55          339   \n",
       "2  ...              0                0           11   \n",
       "3  ...             75               10          147   \n",
       "4  ...             34                1          124   \n",
       "\n",
       "                                         Answer_body  Answer_comment_count  \\\n",
       "0  <p><a href=\"https://mlflow.org/docs/latest/tra...                   2.0   \n",
       "1  <p>Try this:</p>\\n\\n<pre><code>dataframe_outpu...                   0.0   \n",
       "2                                                NaN                   NaN   \n",
       "3                                                NaN                   NaN   \n",
       "4                                                NaN                   NaN   \n",
       "\n",
       "              Answer_creation_time Answer_score       Owner_location  \\\n",
       "0 2021-11-24 17:01:13.483000+00:00          2.0                  NaN   \n",
       "1 2016-08-12 22:26:09.603000+00:00         13.0  Toronto, ON, Canada   \n",
       "2                              NaT          NaN                  NaN   \n",
       "3                              NaT          NaN       Zürich, Suïssa   \n",
       "4                              NaT          NaN           Pune India   \n",
       "\n",
       "           Question_last_edit_time  Answer_last_edit_time  \n",
       "0                              NaT                    NaT  \n",
       "1                              NaT                    NaT  \n",
       "2                              NaT                    NaT  \n",
       "3 2021-05-26 11:54:00.030000+00:00                    NaT  \n",
       "4                              NaT                    NaT  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(\n",
    "    path_so_raw, 'bq-results-20230201-032754-1675222092237.json'), lines=True)\n",
    "df['Question_tags'] = df['Question_tags'].str.split('|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag collection\n",
    "tags = set()\n",
    "for key, value in tool2tag.items():\n",
    "    tags = tags.union(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags\n",
    "df['Question_valid_tags'] = [[] for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'Question_valid_tags'] = list(\n",
    "        tags.intersection(set(row['Question_tags'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with at least 1 tags has 5130 in total.\n",
      "Posts with at least 2 tags has 220 in total.\n",
      "Posts with at least 3 tags has 18 in total.\n"
     ]
    }
   ],
   "source": [
    "# count post number with different tags\n",
    "arity = 0\n",
    "while True:\n",
    "    post_number = df[df['Question_valid_tags'].map(len) > arity].shape[0]\n",
    "    if post_number < 1:\n",
    "        break\n",
    "    arity = arity + 1\n",
    "    print(f'Posts with at least {arity} tags has {post_number} in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-8534f91f27f9>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['Question_link'] = df_valid['Question_id'].apply(\n"
     ]
    }
   ],
   "source": [
    "# exclude Stack Overflow posts with unrelated tags\n",
    "df_valid = df[df['Question_valid_tags'].map(len) > 0]\n",
    "df_valid['Question_link'] = df_valid['Question_id'].apply(\n",
    "    lambda x: f'https://stackoverflow.com/questions/{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Stack Overflow posts with negative upvote count\n",
    "df_qualified = df_valid[df_valid['Question_score'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map from tag to tool\n",
    "tag2tool = dict()\n",
    "for key, value in tool2tag.items():\n",
    "    for elem in value:\n",
    "        tag2tool.setdefault(elem, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Stack Overflow post collection with multiple tags based on the tool map\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = set()\n",
    "    for tag in row['Question_valid_tags']:\n",
    "        tags.add(tag2tool[tag])\n",
    "    df_qualified.at[index, 'Question_valid_tags'] = sorted(list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Amazon SageMaker, MLFlow]                 16\n",
       "[Azure Machine Learning, MLFlow]           11\n",
       "[Kedro, MLFlow]                             4\n",
       "[Azure Machine Learning, Kedro, MLFlow]     2\n",
       "[DVC, MLFlow]                               1\n",
       "[MLFlow, Sacred]                            1\n",
       "[Kedro, Neptune]                            1\n",
       "Name: Question_valid_tags, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the posts with more than one tags look like\n",
    "df_multiply_tagged = df_qualified[df_qualified['Question_valid_tags'].map(\n",
    "    len) > 1]\n",
    "df_multiply_tagged['Question_valid_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-9867e953fe3c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qualified.at[index, 'Tool'] = tags[0]\n"
     ]
    }
   ],
   "source": [
    "# create Stack Overflow post collection with exclusive tags\n",
    "multiply_tagged_posts_split = []\n",
    "df_qualified.assign(Tool='')\n",
    "\n",
    "for index, row in df_qualified.iterrows():\n",
    "    tags = row['Question_valid_tags']\n",
    "    df_qualified.at[index, 'Tool'] = tags[0]\n",
    "    if len(tags) > 1:\n",
    "        for tag in tags[1:]:\n",
    "            series = row.copy()\n",
    "            series['Tool'] = tag\n",
    "            multiply_tagged_posts_split.append(series)\n",
    "\n",
    "df_multiply_tagged_posts_split = pd.DataFrame(multiply_tagged_posts_split)\n",
    "df_qualified_exclusive_tagged = pd.concat(\n",
    "    [df_qualified, df_multiply_tagged_posts_split], ignore_index=True)\n",
    "del df_qualified_exclusive_tagged['Question_valid_tags']\n",
    "\n",
    "# keep Stack Overflow posts with accepted answers\n",
    "df_qualified_exclusive_tagged_completed = df_qualified_exclusive_tagged.dropna(\n",
    "    subset=['Answer_body'])\n",
    "\n",
    "df_qualified_exclusive_tagged.to_json(os.path.join(\n",
    "    path_so_filtered, 'questions.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Question</th>\n",
       "      <th>#Answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2233</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>1530</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>149</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLFlow</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Question  #Answered\n",
       "0         Amazon SageMaker       2233        737\n",
       "1   Azure Machine Learning       1530        586\n",
       "2                  ClearML         40         20\n",
       "3                    Comet         10          4\n",
       "4                      DVC         91         49\n",
       "5                    Kedro        149         60\n",
       "6                   MLFlow        551        129\n",
       "7                  Neptune          8          3\n",
       "8                   Sacred         10          7\n",
       "9                Vertex AI        341        112\n",
       "10        Weights & Biases         77         22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_question_summary = df_qualified_exclusive_tagged.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "df_so_answer_summary = df_qualified_exclusive_tagged_completed.groupby(\n",
    "    'Tool').count()['Question_id'].reset_index()\n",
    "\n",
    "df_so_question_summary.columns = ['Tool', '#Question']\n",
    "df_so_answer_summary.columns = ['Tool', '#Answered']\n",
    "\n",
    "df_summary = pd.merge(df_so_question_summary, df_so_answer_summary, on='Tool')\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create question dataset\n",
    "\n",
    "df_question_so = pd.read_json(os.path.join(path_so_filtered, 'questions.json'))\n",
    "df_question_ts = pd.read_json(os.path.join(path_ts_filtered, 'questions.json'))\n",
    "\n",
    "df_question_so['Platform'] = 'Stack Overflow'\n",
    "df_question_ts['Platform'] = 'Tool-specific'\n",
    "\n",
    "df_questions = pd.concat([df_question_so, df_question_ts], ignore_index=True)\n",
    "del df_questions['Question_tags']\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'original.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add potential field to questions for later filling\n",
    "df_questions = pd.read_json(os.path.join(path_labeling, 'original.json'))\n",
    "\n",
    "# Experiment 1: feed the original content to BerTopic\n",
    "df_questions['Question_original_content'] = ''\n",
    "\n",
    "# Experiment 2: feed the original content to text-davinci-003 model and get the generated summary, then feed the summary to BerTopic\n",
    "df_questions['Question_original_content_gpt_summary'] = ''\n",
    "\n",
    "# Experiment 3: feed the preprocessed content to BerTopic\n",
    "df_questions['Question_preprocessed_content'] = ''\n",
    "\n",
    "# Experiment 4: feed the original content to BerTopic\n",
    "df_questions['Answer_original_content'] = ''\n",
    "\n",
    "# Experiment 5: feed the original content to text-davinci-003 model and get the generated summary, then feed the summary to BerTopic\n",
    "df_questions['Answer_original_content_gpt_summary'] = ''\n",
    "\n",
    "# Experiment 6: feed the preprocessed content to BerTopic\n",
    "df_questions['Answer_preprocessed_content'] = ''\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_questions = pd.read_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'))\n",
    "# df_answers = pd.read_json(os.path.join(\n",
    "#     path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "# del df_questions['Question_tags']\n",
    "# del df_questions['Question_topic']\n",
    "# del df_answers['Question_tags']\n",
    "# del df_answers['Question_topic']\n",
    "\n",
    "# import ast\n",
    "# # df_questions[\"Question_tags\"]= df_questions[\"Question_tags\"].map(str)\n",
    "# df_questions[\"Answer_list\"]= df_questions[\"Answer_list\"].map(str)\n",
    "# # df_questions[\"Question_topic\"]= df_questions[\"Question_topic\"].map(str)\n",
    "# # df_answers[\"Question_tags\"]= df_answers[\"Question_tags\"].map(str)\n",
    "# df_answers[\"Answer_list\"]= df_answers[\"Answer_list\"].map(str)\n",
    "# # df_answers[\"Question_topic\"]= df_answers[\"Question_topic\"].map(str)\n",
    "\n",
    "# dfinal = df_questions.merge(df_answers, on=['Question_title', 'Question_id', 'Question_body', 'Question_answer_count', 'Question_comment_count', 'Question_creation_time', 'Question_favorite_count', 'Question_score', 'Question_view_count', 'Owner_creation_time', 'Owner_last_access_time', 'Owner_reputation', 'Owner_up_votes', 'Owner_up_votes', 'Owner_down_votes', 'Owner_views', 'Answer_body', 'Answer_comment_count', 'Answer_creation_time', 'Answer_score', 'Owner_location', 'Question_last_edit_time', 'Answer_last_edit_time', 'Question_link', 'Tool', 'Platform', 'Question_has_accepted_answer', 'Answer_list', 'Question_follower_count', 'Question_converted_from_issue'], how = 'left')\n",
    "\n",
    "\n",
    "# # dfinal[\"Question_tags\"]= dfinal[\"Question_tags\"].map(ast.literal_eval)\n",
    "# dfinal[\"Answer_list\"]= dfinal[\"Answer_list\"].map(ast.literal_eval)\n",
    "# # dfinal[\"Question_topic\"]= dfinal[\"Question_topic\"].map(ast.literal_eval)\n",
    "\n",
    "# dfinal.shape[0]\n",
    "# dfinal.to_json(os.path.join(path_labeling, 'all.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# content filtering patterns\n",
    "regex_filter = r\"(<.*?>)|({.*?})|((!)?\\[.*?\\])|(\\(.*?\\))|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|([^\\s]*[<=>]=[^\\s]+)|(@[^\\s]+)|((https?:\\/)?\\/[^\\s]+)|([^\\s]*\\\\[^\\s]+)|([^\\s]+\\/[^\\s]+)|([^\\s]+\\.[^\\s]+)|([^\\s]+_[^\\s]+)|(_+[^\\s]+_*)|(_*[^\\s]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\-#*=~:{}\\(\\)\\[\\]]+)\"\n",
    "\n",
    "\n",
    "def preprocess_text(text, remove_code=False):\n",
    "    text = text.lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    remove_tags = ['script', 'style']\n",
    "    remove_tags.append('code') if remove_code else None\n",
    "    for tag in soup(remove_tags):\n",
    "        tag.decompose()\n",
    "    text = re.sub(regex_filter, ' ', text, flags=re.S) if remove_code else None\n",
    "    text = soup.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt for gpt model\n",
    "prompt_question = 'Please write a one-sentence summary of the user\\'s encountered challenges. For instance, you could begin with a sentence such as: \"The user XXXX\".\\n\"\"\"'\n",
    "prompt_answer = 'Below is a question-and-answer pair. Given the context of the question, extract any possible solutions from the answer in concise summaries (one sentence for each), and explain the code if necessary.\\n\"\"\"'\n",
    "import random\n",
    "\n",
    "def retry_with_backoff(fn, retries=2, backoff_in_seconds=1, *args, **kwargs):\n",
    "    x = 0\n",
    "\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except:\n",
    "            if x == retries:\n",
    "                raise\n",
    "\n",
    "            sleep = backoff_in_seconds * 2 ** x + random.uniform(0, 1)\n",
    "            time.sleep(sleep)\n",
    "            x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    title = row['Question_title'].lower()\n",
    "    body = str(row['Question_body']).lower()\n",
    "    content = 'Title: ' + title + '; Content: ' + body\n",
    "\n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, '')\n",
    "\n",
    "    content = preprocess_text(content)\n",
    "    df_questions.at[index, 'Question_original_content'] = ' '.join(\n",
    "        content.split())\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling_question,\n",
    "                     'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens, however you requested 5408 tokens (5208 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 237\n",
      "This model's maximum context length is 4097 tokens, however you requested 4328 tokens (4128 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 328\n",
      "This model's maximum context length is 4097 tokens, however you requested 5368 tokens (5168 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 427\n",
      "This model's maximum context length is 4097 tokens, however you requested 8260 tokens (8060 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 443\n",
      "This model's maximum context length is 4097 tokens, however you requested 8687 tokens (8487 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 576\n",
      "This model's maximum context length is 4097 tokens, however you requested 5300 tokens (5100 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 649\n",
      "This model's maximum context length is 4097 tokens, however you requested 4345 tokens (4145 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 739\n",
      "This model's maximum context length is 4097 tokens, however you requested 4157 tokens (3957 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 916\n",
      "This model's maximum context length is 4097 tokens, however you requested 7591 tokens (7391 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1172\n",
      "This model's maximum context length is 4097 tokens, however you requested 5629 tokens (5429 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1188\n",
      "This model's maximum context length is 4097 tokens, however you requested 6601 tokens (6401 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1504\n",
      "This model's maximum context length is 4097 tokens, however you requested 4636 tokens (4436 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1668\n",
      "This model's maximum context length is 4097 tokens, however you requested 5757 tokens (5557 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 1681\n",
      "This model's maximum context length is 4097 tokens, however you requested 7664 tokens (7464 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 3169\n",
      "This model's maximum context length is 4097 tokens, however you requested 5247 tokens (5047 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 3303\n",
      "This model's maximum context length is 4097 tokens, however you requested 9552 tokens (9352 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 3349\n",
      "This model's maximum context length is 4097 tokens, however you requested 20906 tokens (20706 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 5809\n",
      "This model's maximum context length is 4097 tokens, however you requested 7064 tokens (6864 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 5840\n",
      "This model's maximum context length is 4097 tokens, however you requested 8466 tokens (8266 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 5863\n",
      "This model's maximum context length is 4097 tokens, however you requested 4120 tokens (3920 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6063\n",
      "This model's maximum context length is 4097 tokens, however you requested 8571 tokens (8371 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6101\n",
      "This model's maximum context length is 4097 tokens, however you requested 4338 tokens (4138 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6331\n",
      "This model's maximum context length is 4097 tokens, however you requested 6693 tokens (6493 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6395\n",
      "This model's maximum context length is 4097 tokens, however you requested 4327 tokens (4127 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6549\n",
      "This model's maximum context length is 4097 tokens, however you requested 4207 tokens (4007 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6564\n",
      "This model's maximum context length is 4097 tokens, however you requested 4419 tokens (4219 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 6710\n",
      "This model's maximum context length is 4097 tokens, however you requested 4785 tokens (4585 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 7020\n",
      "This model's maximum context length is 4097 tokens, however you requested 4933 tokens (4733 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 7041\n",
      "This model's maximum context length is 4097 tokens, however you requested 5323 tokens (5123 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 7097\n",
      "This model's maximum context length is 4097 tokens, however you requested 154526 tokens (154326 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 7638\n",
      "This model's maximum context length is 4097 tokens, however you requested 10059 tokens (9859 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 8092\n",
      "This model's maximum context length is 4097 tokens, however you requested 4925 tokens (4725 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 8150\n",
      "This model's maximum context length is 4097 tokens, however you requested 7437 tokens (7237 in your prompt; 200 for the completion). Please reduce your prompt; or completion length. on question 8191\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    if row['Question_original_content_gpt_summary']:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = retry_with_backoff(\n",
    "            openai.Completion.create,\n",
    "            model='text-davinci-003',\n",
    "            prompt=prompt_question +\n",
    "            row['Question_original_content'] + '\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_questions.at[index,\n",
    "                        'Question_original_content_gpt_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(f'{e} on question {index}')\n",
    "\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on question {index}')\n",
    "        df_questions.to_json(os.path.join(\n",
    "            path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/56046428\n",
      "https://stackoverflow.com/questions/63339703\n",
      "https://stackoverflow.com/questions/65577286\n",
      "https://stackoverflow.com/questions/51064366\n",
      "https://stackoverflow.com/questions/68150444\n",
      "https://stackoverflow.com/questions/59762829\n",
      "https://stackoverflow.com/questions/62813017\n",
      "https://stackoverflow.com/questions/62836278\n",
      "https://stackoverflow.com/questions/69466354\n",
      "https://stackoverflow.com/questions/68489311\n",
      "https://stackoverflow.com/questions/73085199\n",
      "https://stackoverflow.com/questions/70567307\n",
      "https://stackoverflow.com/questions/73462205\n",
      "https://stackoverflow.com/questions/63116338\n",
      "https://stackoverflow.com/questions/66561959\n",
      "https://stackoverflow.com/questions/68090119\n",
      "https://learn.microsoft.com/answers/questions/925083/az-ml-designer-swagger-file-missing-on-deployment.html\n",
      "https://learn.microsoft.com/answers/questions/873192/web-service-rest-type-post-in-azure-machine-learni.html\n",
      "https://learn.microsoft.com/answers/questions/889212/how-should-i-create-a-scoring-script-for-object-de.html\n",
      "https://learn.microsoft.com/answers/questions/771372/multiple-new-errors-when-deploying-to-aci-webservi.html\n",
      "https://learn.microsoft.com/answers/questions/742817/deploying-from-azure-ml-studio-designer-is-giving.html\n",
      "https://learn.microsoft.com/answers/questions/557185/import-data-error-2.html\n",
      "https://learn.microsoft.com/answers/questions/514710/cuda-not-compatible-with-pytorch-installation-erro.html\n",
      "https://learn.microsoft.com/answers/questions/390003/azure-ml-pipeline-fails-giving-no-error.html\n",
      "https://learn.microsoft.com/answers/questions/373687/ml-model-deployement-issue.html\n",
      "https://learn.microsoft.com/answers/questions/255760/azure-error-httpsconnectionpoolhost39westus2apiazu.html\n",
      "https://discuss.dvc.org/t/error-unexpected-error-errno-2-no-such-file-or-directory/1381\n",
      "https://discuss.dvc.org/t/ssh-remote-unexpected-error-permission-denied/1300\n",
      "https://discuss.dvc.org/t/unexpected-error-when-push-to-ssh-remote/1105\n",
      "https://groups.google.com/g/mlflow-users/c/GrCd-t0gx8U\n",
      "https://community.wandb.ai/t/windows-11-wandb-sweep-gives-connectionreseterror-winerror-10054/3217\n",
      "https://community.wandb.ai/t/problem-with-sweep-how-to-use-run-finish-and-log-without-error-question-about-defined-metric/3260\n",
      "https://community.wandb.ai/t/how-to-install-wandb-on-a-docker-image-for-arm/3080\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2\n",
    "\n",
    "# output unsuccesful summary requests\n",
    "for index, row in df_questions.iterrows():\n",
    "    if not row['Question_original_content_gpt_summary']:\n",
    "        print(row['Question_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "assert (df_questions.shape[0] == df_questions.dropna(\n",
    "    subset=['Question_original_content_gpt_summary']).shape[0])\n",
    "\n",
    "# output the number of asset-management-related discussion posts\n",
    "df_questions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size is based on the recommendation from https://www.calculator.net/sample-size-calculator.html\n",
    "\n",
    "sample_size = 369\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "df_sample = df_questions.sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_sample.to_json(os.path.join(\n",
    "    path_labeling, 'sample.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    title = row['Question_title'].lower().encode(\n",
    "        'ascii', errors='ignore').decode('ascii')\n",
    "    body = row['Question_body'].lower().encode(\n",
    "        'ascii', errors='ignore').decode('ascii')\n",
    "    content = 'Title: ' + preprocess_text(title, remove_code=True) + \\\n",
    "        '; Content: ' + preprocess_text(body, remove_code=True)\n",
    "\n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, '')\n",
    "\n",
    "    df_questions.at[index, 'Question_preprocessed_content'] = ' '.join(\n",
    "        content.split())\n",
    "\n",
    "df_questions.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    answer = ''\n",
    "    if row['Answer_body']:\n",
    "        answer = row['Answer_body']\n",
    "    elif row['Answer_list']:\n",
    "        if row['Question_has_accepted_answer']:\n",
    "            if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    if comment['Answer_has_accepted']:\n",
    "                        answer = comment['Answer_body']\n",
    "                        break\n",
    "        elif 'Answer_body' in row['Answer_list'][0]:\n",
    "            for comment in row['Answer_list']:\n",
    "                answer += comment['Answer_body'] + '\\n'\n",
    "\n",
    "    answer = preprocess_text(answer)\n",
    "\n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in answer:\n",
    "            answer = answer.replace(tool_keyword, '')\n",
    "\n",
    "    df_questions.at[index, 'Answer_original_content'] = ' '.join(answer.split())\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Hello there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Experiment 5\n",
    "\n",
    "from revChatGPT.V1 import Chatbot\n",
    "\n",
    "chatbot = Chatbot(config={\n",
    "  # \"email\": os.getenv(\"CHATBOT_EMAIL\"),\n",
    "  # \"password\": os.getenv(\"CHATBOT_PASSWORD\"),\n",
    "  # \"access_token\": \"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\",\n",
    "  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6Ik1UaEVOVUpHTkVNMVFURTRNMEZCTWpkQ05UZzVNRFUxUlRVd1FVSkRNRU13UmtGRVFrRXpSZyJ9.eyJodHRwczovL2FwaS5vcGVuYWkuY29tL3Byb2ZpbGUiOnsiZW1haWwiOiJzdXBlcnNreXl5QG91dGxvb2suY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImdlb2lwX2NvdW50cnkiOiJDQSJ9LCJodHRwczovL2FwaS5vcGVuYWkuY29tL2F1dGgiOnsidXNlcl9pZCI6InVzZXItMHNVdE01RUFVOXd4ekhJWjVMTWQ5eWlWIn0sImlzcyI6Imh0dHBzOi8vYXV0aDAub3BlbmFpLmNvbS8iLCJzdWIiOiJhdXRoMHw2MzhlMzZlMmM4YmVjZGY0NGVkYzdlNjMiLCJhdWQiOlsiaHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MSIsImh0dHBzOi8vb3BlbmFpLm9wZW5haS5hdXRoMGFwcC5jb20vdXNlcmluZm8iXSwiaWF0IjoxNjc3MDI0MTgyLCJleHAiOjE2NzgyMzM3ODIsImF6cCI6IlRkSkljYmUxNldvVEh0Tjk1bnl5d2g1RTR5T282SXRHIiwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCBtb2RlbC5yZWFkIG1vZGVsLnJlcXVlc3Qgb3JnYW5pemF0aW9uLnJlYWQgb2ZmbGluZV9hY2Nlc3MifQ.dRHBQ0fO6PnEZ-UShmqnnGVQeE7MUvH_4fUjiNvu1DG6-QbNmPn5CzeRqRAebXHzr5eubxdi1QCVJcEhTwPJaNNG_7ZG43a5oZf7UZVRrHZ9ppI9Wv11De8FT6zvMtjtCFv0Vp22-WN7PzqU9xgBadDUbpgIA2HDKEDW4Z1v7a7m1-L-WSklwVDvwvB41s9uk5Fziiuo3Pscld_vM0YDoMhn0wBLosHSuN8_qSKEBT3DdtxroN8FHl2UGNN9b4pDvsB6RKyHbTp-9CGM6NfShLeQzllNTNNE-c9zDYKSu8yKedotv_P36Sw9jLrM8727lm5jsuIyPBPMXMifkx3-aQ\"\n",
    "})\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "  question = prompt_answer + row['Answer_original_content'] + '\"\"\"\\n',\n",
    "  for data in chatbot.ask(question):\n",
    "    summary = data['message']\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "\n",
    "df_answers = pd.read_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_answers.iterrows():\n",
    "    if row['Question_original_content_gpt_summary']:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = retry_with_backoff(\n",
    "            openai.Completion.create,\n",
    "            model='text-davinci-003',\n",
    "            prompt=prompt_question +\n",
    "            row['Answer_original_content_gpt_summary'] + '\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_answers.at[index, 'Question_original_content_gpt_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(f'{e} on answer {index}')\n",
    "\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on answer {index}')\n",
    "        df_answers.to_json(os.path.join(\n",
    "            path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "df_answers.to_json(os.path.join(\n",
    "    path_labeling, 'topic_modeling.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_labeling, 'topic_modeling.json'))\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    answer = ''\n",
    "    if row['Answer_body']:\n",
    "        answer = row['Answer_body']\n",
    "    elif row['Answer_list']:\n",
    "        if row['Question_has_accepted_answer']:\n",
    "            if 'Answer_has_accepted' in row['Answer_list'][0]:\n",
    "                for comment in row['Answer_list']:\n",
    "                    if comment['Answer_has_accepted']:\n",
    "                        answer = comment['Answer_body']\n",
    "                        break\n",
    "        elif 'Answer_body' in row['Answer_list'][0]:\n",
    "            for comment in row['Answer_list']:\n",
    "                answer += comment['Answer_body'] + '\\n'\n",
    "\n",
    "    answer = preprocess_text(answer, remove_code=True)\n",
    "\n",
    "    for tool_keyword in tools_keywords[row['Tool']]:\n",
    "        if tool_keyword in answer:\n",
    "            answer = answer.replace(tool_keyword, '')\n",
    "\n",
    "    df_questions.at[index, 'Answer_original_content'] = ' '.join(answer.split())\n",
    "\n",
    "df_questions.to_json(os.path.join(path_labeling, 'topic_modeling.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
