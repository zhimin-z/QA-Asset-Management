[
    {
        "Question_id":68547133,
        "Question_title":"Using pytorch_lightning.loggers.MLFlowLogger with azure machine learning studio raises exception mlflow.exceptions.RestException: BAD_REQUEST",
        "Question_body":"<p>I'm trying to locally train pytorch_lightning model and log metrics using  pytorch_lightning.loggers.MLFlowLogger.<\/p>\n<p>It was working fine until last weekend. Now training crashes with error:<\/p>\n<pre><code>mlflow.exceptions.RestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Metric once published using sync API should always use sync API to publish following metrics', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '', 'request': ''}, 'Environment': 'northeurope', 'Location': 'northeurope', 'Time': '2021-07-27T14:06:23.7035319+00:00', 'ComponentName': 'run-history', 'error_code': 'BAD_REQUEST'}\n<\/code><\/pre>\n<p>How to fix this issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-27 14:52:11.183000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|mlflow|pytorch-lightning",
        "Question_view_count":176,
        "Owner_creation_date":"2021-07-06 14:42:05.933000 UTC",
        "Owner_last_access_date":"2022-07-01 12:54:17.217000 UTC",
        "Owner_location":"Krak\u00f3w, Poland",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "azure-machine-learning-studio",
            "mlflow"
        ]
    },
    {
        "Question_id":70338955,
        "Question_title":"Use an Azure ML compute cluster to run Kedro + Mlflow pipeline",
        "Question_body":"<p>I want to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow.<\/p>\n<p>Here's the code snippet (hooks.py) that integrates experiment tracking using Mlflow and Azure ML as backend\/artifact stores.<\/p>\n<pre><code>&quot;&quot;&quot;Project hooks.&quot;&quot;&quot;\nfrom typing import Any, Dict, Iterable, Optional\nimport git\nimport os\nimport mlflow\nimport mlflow.sklearn\nfrom kedro.config import ConfigLoader\nfrom kedro.framework.hooks import hook_impl\nfrom kedro.io import DataCatalog\nfrom kedro.pipeline.node import Node\nfrom kedro.versioning import Journal\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\n\nclass ProjectHooks:\n    @hook_impl\n    def register_config_loader(\n        self,\n        conf_paths: Iterable[str],\n        env: str,\n        extra_params: Dict[str, Any],\n    ) -&gt; ConfigLoader:\n        return ConfigLoader(conf_paths)\n\n    @hook_impl\n    def register_catalog(\n        self,\n        catalog: Optional[Dict[str, Dict[str, Any]]],\n        credentials: Dict[str, Dict[str, Any]],\n        load_versions: Dict[str, str],\n        save_version: str,\n        journal: Journal,\n    ) -&gt; DataCatalog:\n        return DataCatalog.from_config(\n            catalog, credentials, load_versions, save_version, journal\n        )\n\n\nclass ModelTrackingHooks:\n    &quot;&quot;&quot;Namespace for grouping all model-tracking hooks with MLflow together.&quot;&quot;&quot;\n\n    @hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n\n        # Get Azure workspace\n        ws = Workspace.get(name=workspace_name,\n                           subscription_id=subscription_id,\n                           resource_group=resource_group)\n\n        # Set tracking uri\n        mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n\n        # Create an Azure ML experiment in the workspace\n        experiment = Experiment(workspace=ws, name='kedro-mlflow-experiment')\n        mlflow.set_experiment(experiment.name)\n\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n\n    @hook_impl\n    def after_node_run(\n        self, node: Node, outputs: Dict[str, Any], inputs: Dict[str, Any]\n    ) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to add model tracking after some node runs.\n        In this example, we will:\n        * Log the parameters after the data splitting node runs.\n        * Log the model after the model training node runs.\n        * Log the model's metrics after the model evaluating node runs.\n        &quot;&quot;&quot;\n        if node._func_name == &quot;function_name&quot;:\n            mlflow.log_metrics(...)\n\n    @hook_impl\n    def after_pipeline_run(self) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to end the MLflow run\n        after the Kedro pipeline finishes.\n        &quot;&quot;&quot;\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This works well on a <strong>compute instance<\/strong> that I created in my Azure ML workspace, simply by doing the following :<\/p>\n<ol>\n<li><code>git clone<\/code> the source code into the Azure ML compute instance<\/li>\n<li>Do a <code>kedro run<\/code> in the compute instance Terminal<\/li>\n<\/ol>\n<p>That's ok but what I really want is to use <strong>compute clusters<\/strong> to deal with hyperparameter tuning and other heavy workloads... I Just want to mention here that I still want to git clone to the compute instance and submit the run to the compute cluster from within the compute instance (but if anyone has a better approach, please feel free to share).<\/p>\n<p>I know of two ways (listed below) to specify a compute cluster as a compute target in Azure ML but both require to pass a <code>script<\/code> parameter.<\/p>\n<ol>\n<li>Pure Azure ML <code>ScriptRunConfig()<\/code> method to submit experiments by specifying <code>script<\/code> and <code>compute_target<\/code> parameters. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Submit remote run with Azure Ml<\/a><\/li>\n<li>Mlflow integration with Azure ML : that requires to add an MLproject file to the project folder. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-mlflow-projects\" rel=\"nofollow noreferrer\">Submit an mlflow project run<\/a>.<\/li>\n<\/ol>\n<p>I tried for quite some time now to figure out how to do that within the Kedro structure but without success. So my question here, what's the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters?<\/p>\n<p>Thank you in advance for your help !<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-13 17:56:35.970000 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-12-14 08:40:44.520000 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|mlflow|azure-machine-learning-service|kedro",
        "Question_view_count":271,
        "Owner_creation_date":"2020-04-10 11:23:52.390000 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.330000 UTC",
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "azure-machine-learning-service",
            "mlflow"
        ]
    },
    {
        "Question_id":55593128,
        "Question_title":"How to run the mlflow web-based user interface from Amazon SageMaker?",
        "Question_body":"<p>I want to use the mlflow web-based user interface from a notebook on Amazon SageMaker. But the given address <a href=\"http:\/\/127.0.0.1:5000\" rel=\"noreferrer\">http:\/\/127.0.0.1:5000<\/a> doesn't seeem to work.<\/p>\n\n<p>I have installed mlflow on a SageMaker notebook.<\/p>\n\n<p>This code runs nicely:<\/p>\n\n<pre><code>import mlflow\nmlflow.start_run()\nmlflow.log_param(\"my\", \"param\")\nmlflow.log_metric(\"score\", 100)\nmlflow.end_run()\n<\/code><\/pre>\n\n<p>And then if I run <\/p>\n\n<pre><code>! mlflow ui\n<\/code><\/pre>\n\n<p>I get the expected result: <\/p>\n\n<pre><code>[2019-04-09 11:15:52 +0000] [17980] [INFO] Starting gunicorn 19.9.0\n[2019-04-09 11:15:52 +0000] [17980] [INFO] Listening at: http:\/\/127.0.0.1:5000 (17980)\n[2019-04-09 11:15:52 +0000] [17980] [INFO] Using worker: sync\n[2019-04-09 11:15:52 +0000] [17983] [INFO] Booting worker with pid: 17983\n<\/code><\/pre>\n\n<p>However, after that when going to <code>http:\/\/127.0.0.1:5000<\/code> in my browser, nothing loads. <\/p>\n\n<p>My guess it that <code>127.0.0.1<\/code> is not the right address, but how can I know which address to use instead?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-04-09 12:40:21.920000 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":8,
        "Question_tags":"amazon-sagemaker|mlflow",
        "Question_view_count":1359,
        "Owner_creation_date":"2019-04-09 11:30:39.983000 UTC",
        "Owner_last_access_date":"2021-01-26 11:37:19.970000 UTC",
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "amazon-sagemaker",
            "mlflow"
        ]
    },
    {
        "Question_id":61644716,
        "Question_title":"MlflowException: API request to ...URL... failed to return code 200 after 3 tries",
        "Question_body":"<p>I am currently trying to track my machine learning model metrics using the MLFlow API in Azure Databricks.<\/p>\n\n<p>I registered the experiment under my team's machine learning workspace and had tried a few metric log commands that worked but were simply used as a test.<\/p>\n\n<p>My notebook ran a for loop logging metrics per calculation within the loop.\nIt took a while (3-5 seconds) before sending out the error.<\/p>\n\n<p>I tried to look at the experiment metrics and it seems to have logged a bit of the for loop's metrics before crashing.<\/p>\n\n<p>Not sure as to why it does it and now it throws the exception to my earlier test calls to log metrics.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-06 20:25:38.017000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-databricks|mlflow|azure-machine-learning-service",
        "Question_view_count":696,
        "Owner_creation_date":"2019-10-19 18:12:14.813000 UTC",
        "Owner_last_access_date":"2020-08-17 16:11:58.507000 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "azure-machine-learning-service",
            "mlflow"
        ]
    },
    {
        "Question_id":63116338,
        "Question_title":"Serving models from mlflow registry to sagemaker",
        "Question_body":"<p>I have an mlflow server running locally and being exposed at port 80. I also have a model in the mlflow registry and I want to deploy it using the <code>mlflow sagemaker run-local<\/code> because after testing this locally, I am going to deploy everything to AWS and Sagemaker. My problem is that when I run:<\/p>\n<pre><code>export MODEL_PATH=models:\/churn-lgb-test\/2\nexport LOCAL_PORT=8000\nmlflow sagemaker run-local -m $MODEL_PATH -p $LOCAL_PORT -f python_function -i splicemachine\/mlflow-pyfunc:1.6.0\n<\/code><\/pre>\n<p>it starts the container and I immediately get this error:<\/p>\n<pre><code>2020-07-27 13:02:13 +0000] [827] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:13 +0000] [828] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:13 +0000] [828] [INFO] Worker exiting (pid: 828)\n[2020-07-27 13:02:13 +0000] [827] [INFO] Worker exiting (pid: 827)\n[2020-07-27 13:02:13 +0000] [829] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:13 +0000] [829] [INFO] Worker exiting (pid: 829)\n[2020-07-27 13:02:13 +0000] [830] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:13 +0000] [830] [INFO] Worker exiting (pid: 830)\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 209, in run\n    self.sleep()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 357, in sleep\n    ready = select.select([self.PIPE[0]], [], [], 1.0)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 242, in handle_chld\n    self.reap_workers()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 525, in reap_workers\n    raise HaltServer(reason, self.WORKER_BOOT_ERROR)\ngunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/bin\/gunicorn&quot;, line 8, in &lt;module&gt;\n    sys.exit(run())\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in run\n    WSGIApplication(&quot;%(prog)s [OPTIONS] [APP_MODULE]&quot;).run()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 228, in run\n    super().run()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 72, in run\n    Arbiter(self).run()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 229, in run\n    self.halt(reason=inst.reason, exit_status=inst.exit_status)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 342, in halt\n    self.stop()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 393, in stop\n    time.sleep(0.1)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 242, in handle_chld\n    self.reap_workers()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 525, in reap_workers\n    raise HaltServer(reason, self.WORKER_BOOT_ERROR)\ngunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;\ncreating and activating custom environment\nGot sigterm signal, exiting.\n[2020-07-27 13:02:13 +0000] [831] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:13 +0000] [831] [INFO] Worker exiting (pid: 831)\n[2020-07-27 13:02:14 +0000] [833] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:14 +0000] [833] [INFO] Worker exiting (pid: 833)\n[2020-07-27 13:02:14 +0000] [832] [ERROR] Exception in worker process\nTraceback (most recent call last):\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py&quot;, line 162, in init_process\n    super().init_process()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 358, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py&quot;, line 3, in &lt;module&gt;\n    app = scoring_server.init(pyfunc.load_model(&quot;\/opt\/ml\/model\/&quot;))\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 292, in load_model\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 219, in _load_pyfunc\n    return _load_model_from_local_file(path)\n  File &quot;\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py&quot;, line 206, in _load_model_from_local_file\n    with open(path, &quot;rb&quot;) as f:\nIsADirectoryError: [Errno 21] Is a directory: '\/opt\/ml\/model'\n[2020-07-27 13:02:14 +0000] [832] [INFO] Worker exiting (pid: 832)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-27 13:26:19.060000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"amazon-sagemaker|mlflow",
        "Question_view_count":429,
        "Owner_creation_date":"2020-06-05 19:27:43.857000 UTC",
        "Owner_last_access_date":"2020-11-19 23:45:52.310000 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "amazon-sagemaker",
            "mlflow"
        ]
    },
    {
        "Question_id":69182023,
        "Question_title":"cmd: mlflow sagemaker build-and-push-container gives FileNotFoundError:",
        "Question_body":"<p>I don't understand what type of files I missing<\/p>\n<blockquote>\n<p>and I used this code to connect AWS ECR<\/p>\n<\/blockquote>\n<pre><code>setx AWS_ACCESS_KEY_ID AKIAIOSFODNN7EXAMPLE\nsetx AWS_SECRET_ACCESS_KEY wJalrXUtnFEMI\/K7MDENG\/bPxRfiCYEXAMPLEKEY\nsetx AWS_DEFAULT_REGION us-west-2\n<\/code><\/pre>\n<blockquote>\n<p>at mlflow artifact directory shown below and here python isn't a python.exe it's just a file name<\/p>\n<\/blockquote>\n<pre><code>(deploy_ml) D:\\****\\Python\\mlruns\\1\\2877b0a860934a179723fd11ed946589\\artifacts\\random-forest-model&gt;\n\n\n(deploy_ml) D:\\***\\Python\\mlruns\\1\\2877b0a86093***723fd11ed946589\\artifacts\\random-forest-model&gt;mlflow sagemaker  build-and-push-container\n2021\/09\/14 22:22:13 INFO mlflow.models.docker_utils: Building docker image with name mlflow-pyfunc\nFIND: Parameter format not correct\nTraceback (most recent call last):\n  File &quot;c:\\users\\s***\\anaconda3\\envs\\deploy_ml\\lib\\runpy.py&quot;, line 193, in _run_module_as_main\n    &quot;__main__&quot;, mod_spec)\n  File &quot;c:\\users\\s***\\anaconda3\\envs\\deploy_ml\\lib\\runpy.py&quot;, line 85, in _run_code\n    exec(code, run_globals)\n  File &quot;C:\\Users\\s***\\Anaconda3\\envs\\deploy_ml\\Scripts\\mlflow.exe\\__main__.py&quot;, line 7, in &lt;module&gt;\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 1137, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 1062, in main\n    rv = self.invoke(ctx)\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 1668, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 1668, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;c:\\users\\***\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;c:\\users\\***\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\click\\core.py&quot;, line 763, in invoke\n    return __callback(*args, **kwargs)\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\mlflow\\sagemaker\\cli.py&quot;, line 280, in build_and_push_container\n    custom_setup_steps_hook=setup_container,\n  File &quot;c:\\users\\s***\\anaconda3\\envs\\deploy_ml\\lib\\site-packages\\mlflow\\models\\docker_utils.py&quot;, line 114, in _build_image\n    universal_newlines=True,\n  File &quot;c:\\users\\s***\\anaconda3\\envs\\deploy_ml\\lib\\subprocess.py&quot;, line 729, in __init__\n    restore_signals, start_new_session)\n  File &quot;c:\\users\\s****\\anaconda3\\envs\\deploy_ml\\lib\\subprocess.py&quot;, line 1017, in _execute_child\n    startupinfo)\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-14 17:16:10.420000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"amazon-web-services|docker|amazon-sagemaker|amazon-ecr|mlflow",
        "Question_view_count":173,
        "Owner_creation_date":"2021-08-03 07:46:47.183000 UTC",
        "Owner_last_access_date":"2021-12-03 06:36:36.860000 UTC",
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "amazon-sagemaker",
            "mlflow"
        ]
    },
    {
        "Question_id":70680222,
        "Question_title":"Does MLflow allow to log artifacts from remote locations like S3?",
        "Question_body":"<h2>My setting<\/h2>\n<p>I have developed an environment for ML experiments that looks like the following: training happens in the AWS cloud with SageMaker Training Jobs. The trained model is stored in the <code>\/opt\/ml\/model<\/code> directory, <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-output.html\" rel=\"nofollow noreferrer\">which is reserved by SageMaker to pack models<\/a> as a <code>.tar.gz<\/code> in SageMaker's own S3 bucket. Several evaluation metrics are computed during training and testing, and recorded to an MLflow infrastructure consisting of an S3-based artifact store (see <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\" rel=\"nofollow noreferrer\">Scenario 4<\/a>). Note that this is a different S3 bucket than SageMaker's.<\/p>\n<p>A very useful feature from MLflow is that any model artifacts can be logged to a training run, so data scientists have access to both metrics and more complex outputs through the UI. These outputs include (but are not limited to) the trained model itself.<\/p>\n<p>A limitation is that, as I understand it, the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"nofollow noreferrer\">MLflow API for logging artifacts<\/a> only accepts as input a local path to the artifact itself, and will always upload it to its artifact store. This is suboptimal when the artifacts are stored somewhere outside MLflow, as you have to store them twice. A transformer model may weigh more than 1GB.<\/p>\n<h2>My questions<\/h2>\n<ul>\n<li>Is there a way to pass an S3 path to MLflow and make it count as an artifact, without having to download it locally first?<\/li>\n<li>Is there a way to avoid pushing a copy of an artifact to the artifact store? If my artifacts already reside in another remote location, it would be ideal to just have a link to such location in MLflow and not a copy in MLflow storage.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-12 10:49:12.913000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-s3|amazon-sagemaker|mlflow|mlops",
        "Question_view_count":533,
        "Owner_creation_date":"2016-01-08 20:55:48.080000 UTC",
        "Owner_last_access_date":"2022-09-23 10:18:38.030000 UTC",
        "Owner_location":"Madrid, Spain",
        "Owner_reputation":118,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "amazon-sagemaker",
            "mlflow"
        ]
    },
    {
        "Question_id":72684326,
        "Question_title":"How to change Sklearn flavors version in mlflow on azure machine learning?",
        "Question_body":"<p>I need to change the flavors &quot;sklearn_version&quot; in mlflow from &quot;0.22.1&quot; to &quot;1.0.0&quot; on azure machine learning when I log my trained model, since this model will be incompatible with the sklearn version that I am using for deployment during inference. I could change the version of sklearn in conda.yml file by setting &quot;conda_env&quot; in<\/p>\n<p><code>mlflow.sklearn.log_model(conda_env= 'my_env')<\/code><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/URygm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/URygm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>here is the screen shot of requirements.txt\n<a href=\"https:\/\/i.stack.imgur.com\/8us2o.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8us2o.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>however, sklearn version under flavors in MLmodel file remains unchanged and that is the file that causes problem:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/XfWvJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XfWvJ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and here is script that I use to create this mlflow experiment in azure machine learning notebooks.<\/p>\n<pre><code>import mlflow\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.mlflow import register_model\n\n\ndef run_model(ws, experiment_name, run_name, x_train, y_train):\n    \n    # set up MLflow to track the metrics\n    mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n    mlflow.set_experiment(experiment_name)  \n    \n    with mlflow.start_run(run_name=run_name) as run:\n        \n        # fit model\n        regression_model = DecisionTreeRegressor()\n        regression_model.fit(x_train, y_train)\n    \n        # log training score \n        training_score = regression_model.score(x_train, y_train)\n        mlflow.log_metric(&quot;Training score&quot;, training_score)\n\n        my_conda_env = {\n                    &quot;name&quot;: &quot;mlflow-env&quot;,\n                    &quot;channels&quot;: [&quot;conda-forge&quot;],\n                    &quot;dependencies&quot;: [\n                        &quot;python=3.8.5&quot;,\n                        {\n                            &quot;pip&quot;: [\n                                &quot;pip&quot;,\n                                &quot;scikit-learn~=1.0.0&quot;,\n                                &quot;uuid==1.30&quot;,\n                                &quot;lz4==4.0.0&quot;,\n                                &quot;psutil==5.9.0&quot;,\n                                &quot;cloudpickle==1.6.0&quot;,\n                                &quot;mlflow&quot;,\n                            ],\n                        },\n                    ],\n                }\n\n        \n        # register the model\n        mlflow.sklearn.log_model(regression_model, &quot;model&quot;, conda_env=my_conda_env)\n\n    model_uri = f&quot;runs:\/{run.info.run_id}\/model&quot;\n    model = mlflow.register_model(model_uri, &quot;sklearn_regression_model&quot;)\n\nif __name__ == '__main__':\n\n    # connect to your workspace\n    ws = Workspace.from_config()\n\n    # create experiment and start logging to a new run in the experiment\n    experiment_name = &quot;exp_name&quot;\n\n    # mlflow run name\n    run_name= '1234'\n\n  \n    # get train data\n    x_train, y_train  = get_train_data()\n    \n    run_model(ws, experiment_name, run_name, x_train, y_train)\n<\/code><\/pre>\n<p>Any idea how can change the flavor sklearn version in MLmodel file from <strong>&quot;0.22.1&quot;<\/strong> to <strong>&quot;1.0.0&quot;<\/strong> in my script?<\/p>\n<p>With many thanks in advance!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-20 08:38:43.913000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-20 13:14:39.310000 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|scikit-learn|azure-machine-learning-service|mlflow",
        "Question_view_count":102,
        "Owner_creation_date":"2017-01-16 23:04:42.440000 UTC",
        "Owner_last_access_date":"2022-09-23 06:48:12.703000 UTC",
        "Owner_location":null,
        "Owner_reputation":83,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "azure-machine-learning-service",
            "mlflow"
        ]
    },
    {
        "Question_id":73051157,
        "Question_title":"Using MLflow and Sagemaker with preprocessing steps",
        "Question_body":"<p>I'm deploying my models to Sagemaker using MLflow integration. However, my ML pipeline includes some basic preprocessing steps, such as scalers, and I need it to be part of my inference endpoint. Is there a way to do that with MLflow? I looked in the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html\" rel=\"nofollow noreferrer\">mlflow_pyfunc<\/a> is closer to what I want, but I'm not sure if it is compatible with Sagemaker.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-20 11:52:22.350000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-sagemaker|mlflow",
        "Question_view_count":34,
        "Owner_creation_date":"2016-10-17 11:39:35.777000 UTC",
        "Owner_last_access_date":"2022-07-28 17:26:21.417000 UTC",
        "Owner_location":null,
        "Owner_reputation":109,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "amazon-sagemaker",
            "mlflow"
        ]
    },
    {
        "Question_id":64480876,
        "Question_title":"Registering models from Databricks to Azure ML and save Azure ML image into provided ACR(Non Default ACR of AML Workspace)",
        "Question_body":"<p>I'm trying to register a data bricks model tp <code>Azure ML<\/code> workspace with <code>mlflow.azure.base_image<\/code> model. But with this method, we can save the <code>Azure ML<\/code> image to default <code>ACR<\/code> connected to the <code>Azure ML<\/code> workspace.<\/p>\n<p>But I want to save the <code>Azure ML<\/code> image to another existing <code>ACR<\/code>. Need help in figuring out the design.<\/p>\n<p>The method I'm using is as follows<\/p>\n<pre><code>    workspace = Workspace.create(name = workspace_name,\n                                 location = workspace_location,\n                                 resource_group = resource_group,\n                                 subscription_id = subscription_id,\n                                 auth=svc_pr,\n                                 exist_ok=True)\n\n    import mlflow.azureml\n\n    model_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                          workspace=workspace,\n                                                          model_name=&quot;winequality&quot;,\n                                                          image_name=&quot;winequality&quot;,\n                                                          description=&quot;Sklearn ElasticNet image for predicting wine quality&quot;,\n                                                          synchronous=True)\n\n    #model_image.wait_for_creation(show_output=True)\n    print(&quot;Access the following URI for build logs: {}&quot;.format(model_image.image_build_log_uri))                                    \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-22 11:02:29.390000 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-22 11:10:53.553000 UTC",
        "Question_score":0,
        "Question_tags":"docker|azure-databricks|mlflow|azure-machine-learning-service",
        "Question_view_count":158,
        "Owner_creation_date":"2018-10-30 10:19:53.043000 UTC",
        "Owner_last_access_date":"2022-09-22 15:34:05.270000 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":75,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_valid_tags":[
            "azure-machine-learning-service",
            "mlflow"
        ]
    }
]