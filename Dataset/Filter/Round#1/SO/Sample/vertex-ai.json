[
	{
		"Question_id": 70838510,
		"Question_title": "Is it possible to request a Vertex AI endpoint from another GCP project?",
		"Question_body": "<p>I trained a model on GCP Vertex AI, and deployed it on an endpoint.</p>\n<p>I am able to execute predictions from a sample to my model with this python code <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-automl#aiplatform_predict_image_classification_sample-python\" rel=\"nofollow noreferrer\">https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-automl#aiplatform_predict_image_classification_sample-python</a></p>\n<p>It works within my GCP project.</p>\n<p>My question is, is it possible to request this endpoint from another GCP project ? If I set a service account and set IAM role in both projects ?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-01-24 18:12:06.007000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python-3.x|google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 417,
		"Owner_creation_date": "2020-08-31 11:39:36.143000 UTC",
		"Owner_last_access_date": "2022-09-18 19:46:19.503000 UTC",
		"Owner_location": "Versailles, France",
		"Owner_reputation": 140,
		"Owner_up_votes": 9,
		"Owner_down_votes": 0,
		"Owner_views": 7,
		"Answer_body": "<p>Yes it is possible. For example you have Project A and Project B, assuming that Project A hosts the model.</p>\n<ul>\n<li><p>Add service account of Project B in Project A and provide at least <code>roles/aiplatform.user</code> predefined role. See <a href=\"https://cloud.google.com/vertex-ai/docs/general/access-control#predefined-roles\" rel=\"nofollow noreferrer\">predefined roles</a> and look for <code>roles/aiplatform.user</code> to see complete roles it contains.</p>\n</li>\n<li><p>This role contains <strong>aiplatform.endpoints.</strong>* and <strong>aiplatform.batchPredictionJobs.</strong>* as these are the roles needed to run predictions.</p>\n<blockquote>\n<p>See <a href=\"https://cloud.google.com/vertex-ai/docs/general/iam-permissions\" rel=\"nofollow noreferrer\">IAM permissions for Vertex AI</a></p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Resource</th>\n<th>Operation</th>\n<th>Permissions needed</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>batchPredictionJobs</td>\n<td>Create a batchPredictionJob</td>\n<td>aiplatform.batchPredictionJobs.create (permission needed on the parent resource)</td>\n</tr>\n<tr>\n<td>endpoints</td>\n<td>Predict an endpoint</td>\n<td>aiplatform.endpoints.predict (permission needed on the endpoint resource)</td>\n</tr>\n</tbody>\n</table>\n</div></blockquote>\n</li>\n</ul>\n<p>With this set up, Project B will be able to use the model in Project A to run predictions.</p>\n<p>NOTE: Just make sure that the script of Project B points to the resources in Project A like <code>project_id</code> and <code>endpoint_id</code>.</p>",
		"Answer_comment_count": 1.0,
		"Answer_creation_date": "2022-01-25 03:21:58.690000 UTC",
		"Answer_last_edit_date": "2022-01-25 03:35:51.060000 UTC",
		"Answer_score": 1.0,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72423143,
		"Question_title": "How to load images from Vertex AI managed dataset inside Python training code?",
		"Question_body": "<p>I am trying to create a <strong>custom training job</strong> in Vertex AI. I created a managed dataset stored in the same bucket I am exporting the training code to.\nI have a Python code that looks like this:</p>\n<pre><code>#Defining paths \nTRAIN_PATH = os.environ['AIP_TRAINING_DATA_URI']\nVAL_PATH = os.environ['AIP_VALIDATION_DATA_URI']\n\n#skipped model definition#\n\ntrain_datagen = image.ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2, horizontal_flip = True)\n\ntest_dataset = image.ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_PATH,\n    target_size = (224,224),\n    batch_size = 32,\n    class_mode = 'binary')\nvalidation_generator = test_dataset.flow_from_directory(\n    VAL_PATH,\n    target_size = (224,224),\n    batch_size = 32,\n    class_mode = 'binary')\n\nhist_new = model.fit(\n     train_generator, ...)\n</code></pre>\n<p>The question is, how do I load the images so the ImageDataGenerator can use them?\nThe error I get when starting the training job is:</p>\n<pre><code> No such file or directory: 'gs://(bucket name)/dataset-5820440723492700160-image_classification_multi_label-2022-05-29T10:53:33.245485Z/training-*'\n</code></pre>",
		"Question_answer_count": 2,
		"Question_comment_count": 1,
		"Question_creation_date": "2022-05-29 11:14:59.060000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|machine-learning|google-cloud-vertex-ai",
		"Question_view_count": 98,
		"Owner_creation_date": "2019-01-04 19:50:49.567000 UTC",
		"Owner_last_access_date": "2022-07-31 14:05:54.170000 UTC",
		"Owner_location": null,
		"Owner_reputation": 51,
		"Owner_up_votes": 7,
		"Owner_down_votes": 0,
		"Owner_views": 17,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69543552,
		"Question_title": "Vertex Pipeline Metric values not being added to metrics artifact?",
		"Question_body": "<p>We are trying to return some metrics from our Vertex Pipeline, such that they are visible in the Run Comparison and Metadata tools in the Vertex UI.</p>\n<p>I saw <a href=\"https://codelabs.developers.google.com/vertex-mlmd-pipelines#4\" rel=\"nofollow noreferrer\">here</a> that we can use this output type <code>Output[Metrics]</code>, and the subsequent <code>metrics.log_metric(&quot;metric_name&quot;, metric_val)</code> method to add the metrics, and it seemed from the available documentation that this would be enough.</p>\n<p>We want to use the reusable component method as opposed to python function based components, around which the example is based. So we implemented it within our component code like so:</p>\n<p>We added the output in the component.yaml:</p>\n<pre><code>outputs:\n    - name: metrics\n      type: Metrics\n      description: evaluation metrics path\n</code></pre>\n<p>then added the output to the command in the implemenation:</p>\n<pre><code>        command: [\n            python3, main.py,\n            --gcs-test-data-path,       {inputValue: gcs_test_data_path},\n            --gcs-model-path,  {inputValue: gcs_model_path},\n            --gcs-output-bucket-id,  {inputValue: gcs_output_bucket_id},\n            --project-id, {inputValue: project_id},\n            --timestamp, {inputValue: timestamp},\n            --batch-size, {inputValue: batch_size},\n            --img-height, {inputValue: img_height},\n            --img-width,  {inputValue: img_width},\n            --img-depth,  {inputValue: img_depth},\n            --metrics,  {outputPath: metrics},\n        ]\n</code></pre>\n<p>Next in the components main python script, we parse this argument with argparse:</p>\n<pre><code>PARSER.add_argument('--metrics',\n                    type=Metrics,\n                    required=False,\n                    help='evaluation metrics output')\n</code></pre>\n<p>and pass it to the components main function:</p>\n<pre><code>if __name__ == '__main__':\n    ARGS = PARSER.parse_args()\n    evaluation(gcs_test_data_path=ARGS.gcs_test_data_path,\n               gcs_model_path=ARGS.gcs_model_path,\n               gcs_output_bucket_id=ARGS.gcs_output_bucket_id,\n               project_id=ARGS.project_id,\n               timestamp=ARGS.timestamp,\n               batch_size=ARGS.batch_size,\n               img_height=ARGS.img_height,\n               img_width=ARGS.img_width,\n               img_depth=ARGS.img_depth,\n               metrics=ARGS.metrics,\n               )\n</code></pre>\n<p>in the declaration of the component function, we then typed this metrics parameter as <code>Output[Metrics]</code></p>\n<pre><code>from kfp.v2.dsl import Output, Metrics\n\ndef evaluation(gcs_test_data_path: str,\n               gcs_model_path: str,\n               gcs_output_bucket_id: str,\n               metrics: Output[Metrics],\n               project_id: str,\n               timestamp: str,\n               batch_size: int,\n               img_height: int,\n               img_width: int,\n               img_depth: int):\n</code></pre>\n<p>finally, we implement the log_metric method within this evaluation function:</p>\n<pre><code>    metrics.log_metric('accuracy', acc)\n    metrics.log_metric('precision', prec)\n    metrics.log_metric('recall', recall)\n    metrics.log_metric('f1-score', f_1)\n</code></pre>\n<p>When we run this pipeline, we can see this metric artifact materialised in the DAG:</p>\n<p><a href=\"https://i.stack.imgur.com/TG5cr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/TG5cr.png\" alt=\"Metrics artifact visible in the DAG\" /></a></p>\n<p>And Metrics Artifacts are listed in the Metadata UI in Vertex:</p>\n<p><a href=\"https://i.stack.imgur.com/jehCH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jehCH.png\" alt=\"Metrics Artifacts are listed in the metadata UI\" /></a></p>\n<p>However, clicking through to view the artifacts JSON, there is no Metadata listed:</p>\n<p><a href=\"https://i.stack.imgur.com/E3IFE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/E3IFE.png\" alt=\"No Metadata attached to artifact\" /></a></p>\n<p>In addition, No Metadata is visible when comparing runs in the pipeline UI:</p>\n<p><a href=\"https://i.stack.imgur.com/qZPD2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qZPD2.png\" alt=\"No Metadata in the pipeline UI\" /></a></p>\n<p>Finally, navigating to the Objects URI in GCS, we are met with 'Requested entity was not found.', which I assume indicates that nothing was written to GCS:</p>\n<p><a href=\"https://i.stack.imgur.com/6z7pJ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6z7pJ.png\" alt=\"No Object in GCS\" /></a></p>\n<p>Are we doing something wrong with this implementation of metrics in the reusable components? From what I can tell, this all seems right to me, but it's hard to tell given the docs at this point seem to focus primarily on examples with Python Function based components.</p>\n<p>Do we perhaps need to proactively write this Metrics object to an OutputPath?</p>\n<p>Any helps is appreciated.</p>\n<p>----- UPDATE ----</p>\n<p>I have since been able to get artifact metadata and URI To update. In the end we used kfp sdk to generate a yaml file based on a @component decorated python function, we then adapted this format for our reusable components.\nOur component.yaml now looks like this:</p>\n<pre><code>name: predict\ndescription: Prepare and create predictions request\nimplementation:\n    container:\n      args:\n      - --executor_input\n      - executorInput: null\n      - --function_to_execute\n      - predict\n      command:\n      - python3\n      - -m\n      - kfp.v2.components.executor_main\n      - --component_module_path\n      - predict.py\n      image: gcr.io/PROJECT_ID/kfp/components/predict:latest\ninputs: \n    - name: input_1\n      type: String\n    - name: intput_2\n      type: String\noutputs:\n    - name: output_1\n      type: Dataset\n    - name: output_2\n      type: Dataset\n</code></pre>\n<p>with this change to the yaml, we can now successfully update the artifacts metadata dictionary, and uri through <code>artifact.path = '/path/to/file'</code>. These updates are displayed in the Vertex UI.</p>\n<p>I am still unsure why the <a href=\"https://www.kubeflow.org/docs/components/pipelines/sdk/v2/component-development/#creating-a-component-specification\" rel=\"nofollow noreferrer\">component.yaml format specified in the Kubeflow documentation</a> does not work - I think this may be a bug with Vertex Pipelines.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-10-12 15:52:31.997000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2021-11-01 14:48:10.490000 UTC",
		"Question_score": 0,
		"Question_tags": "google-cloud-ml|google-cloud-vertex-ai",
		"Question_view_count": 355,
		"Owner_creation_date": "2021-07-12 12:40:50.203000 UTC",
		"Owner_last_access_date": "2022-08-18 15:04:10.047000 UTC",
		"Owner_location": null,
		"Owner_reputation": 41,
		"Owner_up_votes": 2,
		"Owner_down_votes": 0,
		"Owner_views": 12,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72254372,
		"Question_title": "GCP's Vertex AI(AI Platform) PipelineServiceClient gives unimplemented error",
		"Question_body": "<p>When trying to list pipelines with <code>PipelineServiceClient</code> <code>list_pipeline_jobs</code> method as given <a href=\"https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.pipeline_service.PipelineServiceClient#google_cloud_aiplatform_v1_services_pipeline_service_PipelineServiceClient_list_pipeline_jobs\" rel=\"nofollow noreferrer\">here</a>, I get the following error:</p>\n<pre><code>_InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:\nstatus = StatusCode.UNIMPLEMENTED\ndetails = &quot;Received http2 header with status: 404&quot;\n...\n</code></pre>\n<p>How is the API unimplemented, how do I resolve this?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-05-16 05:06:48.807000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 143,
		"Owner_creation_date": "2019-02-17 05:09:55.090000 UTC",
		"Owner_last_access_date": "2022-09-21 08:01:13.577000 UTC",
		"Owner_location": null,
		"Owner_reputation": 434,
		"Owner_up_votes": 106,
		"Owner_down_votes": 34,
		"Owner_views": 13,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 70001381,
		"Question_title": "creating custom model on Google vertex ai",
		"Question_body": "<p>I should use Google\u2019s managed ML platform Vertex AI to build an end-to-end machine learning workflow for an internship. Although I completely follow the tutorial, when I run a training job, I see this error message:</p>\n<pre><code>Training pipeline failed with error message: There are no files under &quot;gs://dps-fuel-bucket/mpg/model&quot; to copy.\n</code></pre>\n<p>based on the tutorial, we should not have a /model directory in the bucket. And the model should create this directory and save the final result there.</p>\n<pre><code># Export model and save to GCS\nmodel.save(BUCKET + '/mpg/model')\n</code></pre>\n<p>I added this directory but still face this error.\nDoes anybody have any idea, thanks in advance :)</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-11-17 08:56:13.937000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "google-cloud-platform|google-cloud-vertex-ai|google-bucket",
		"Question_view_count": 132,
		"Owner_creation_date": "2021-11-17 08:37:31.163000 UTC",
		"Owner_last_access_date": "2022-03-17 11:22:27.090000 UTC",
		"Owner_location": null,
		"Owner_reputation": 1,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 1,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 68703802,
		"Question_title": "Simplest GUI frontend to demo GCP Vertex AutomML Image Classification",
		"Question_body": "<p>I've built a GCP Vertex AutoML Image Classification model and deployed to endpoint. It works great from the Deploy and Test tab. What's the simplest way to let others without access to the project try it via a GUI? The required functionality is to upload an image from your computer and let the model output the predicted class.</p>\n<p>Is there an existing tool I can use (has to be a GUI, not command line)? If not what's the simplest way to build such frontend?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-08-08 18:49:05.480000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 1,
		"Question_tags": "vertex|google-cloud-automl|automl|google-cloud-vertex-ai|gpc",
		"Question_view_count": 79,
		"Owner_creation_date": "2016-01-09 01:34:07.890000 UTC",
		"Owner_last_access_date": "2022-02-26 19:24:23.073000 UTC",
		"Owner_location": null,
		"Owner_reputation": 11,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 1,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69977440,
		"Question_title": "How to use kfp Artifact with sklearn?",
		"Question_body": "<p>I'm trying to develop a custom pipeline with kubeflow pipeline (kfp) components inside Vertex AI (Google Cloud Platform). The steps of the pipeline are:</p>\n<ol>\n<li>read data from a big query table</li>\n<li>create a pandas <code>DataFrame</code></li>\n<li>use the <code>DataFrame</code> to train a K-Means model</li>\n<li>deploy the model to an endpoint</li>\n</ol>\n<p>Here there is the code of the step 2. I had to use <code>Output[Artifact]</code> as output because <code>pd.DataFrame</code> type that I found <a href=\"https://stackoverflow.com/questions/43890844/pythonic-type-hints-with-pandas\">here</a> did not work.</p>\n<pre class=\"lang-py prettyprint-override\"><code>@component(base_image=&quot;python:3.9&quot;, packages_to_install=[&quot;google-cloud-bigquery&quot;,&quot;pandas&quot;,&quot;pyarrow&quot;])\ndef create_dataframe(\n    project: str,\n    region: str,\n    destination_dataset: str,\n    destination_table_name: str,\n    df: Output[Artifact],\n):\n    \n    from google.cloud import bigquery\n    \n    client = bigquery.Client(project=project, location=region)\n    dataset_ref = bigquery.DatasetReference(project, destination_dataset)\n    table_ref = dataset_ref.table(destination_table_name)\n    table = client.get_table(table_ref)\n\n    df = client.list_rows(table).to_dataframe()\n</code></pre>\n<p>Here the code of the step 3:</p>\n<pre class=\"lang-py prettyprint-override\"><code>@component(base_image=&quot;python:3.9&quot;, packages_to_install=['sklearn'])\ndef kmeans_training(\n        dataset: Input[Artifact],\n        model: Output[Model],\n        num_clusters: int,\n):\n    from sklearn.cluster import KMeans\n    model = KMeans(num_clusters, random_state=220417)\n    model.fit(dataset)\n</code></pre>\n<p>The run of the pipeline is stopped due to the following error:</p>\n<pre class=\"lang-py prettyprint-override\"><code>TypeError: float() argument must be a string or a number, not 'Artifact'\n</code></pre>\n<p>Is it possible to convert Artifact to <code>numpy array</code> or <code>Dataframe</code>?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-11-15 16:10:03.783000 UTC",
		"Question_favorite_count": 1.0,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|google-cloud-platform|google-cloud-ml|google-cloud-vertex-ai|kfp",
		"Question_view_count": 339,
		"Owner_creation_date": "2021-03-24 12:34:53.617000 UTC",
		"Owner_last_access_date": "2022-09-22 15:26:12.103000 UTC",
		"Owner_location": "Alatri, Frosinone, FR",
		"Owner_reputation": 67,
		"Owner_up_votes": 3,
		"Owner_down_votes": 0,
		"Owner_views": 33,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71101070,
		"Question_title": "How to properly extract endpoint id from gcp_resources of a Vertex AI pipeline on GCP?",
		"Question_body": "<p>I am using GCP Vertex AI pipeline (KFP) and using <code>google-cloud-aiplatform==1.10.0</code>, <code>kfp==1.8.11</code>, <code>google-cloud-pipeline-components==0.2.6</code>\nIn a component I am getting a gcp_resources <a href=\"https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md\" rel=\"nofollow noreferrer\">documentation</a> :</p>\n<pre><code>gcp_resources (str):\n            Serialized gcp_resources proto tracking the create endpoint's long running operation.\n</code></pre>\n<p>To extract the endpoint_id to do online prediction of my deployed model, I am doing:</p>\n<pre><code>from google_cloud_pipeline_components.proto.gcp_resources_pb2 import GcpResources\nfrom google.protobuf.json_format import Parse\ninput_gcp_resources = Parse(endpoint_ressource_name, GcpResources())\ngcp_resources=input_gcp_resources.resources.__getitem__(0).resource_uri.split('/')\nendpoint_id=gcp_resources[gcp_resources.index('endpoints')+1]\n</code></pre>\n<p>Is there a better/native way of extracting such info ?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-02-13 13:26:50.230000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 1,
		"Question_tags": "google-cloud-vertex-ai",
		"Question_view_count": 225,
		"Owner_creation_date": "2016-06-06 14:08:12.253000 UTC",
		"Owner_last_access_date": "2022-09-22 14:59:43.617000 UTC",
		"Owner_location": "Z\u00fcrich, Switzerland",
		"Owner_reputation": 1414,
		"Owner_up_votes": 258,
		"Owner_down_votes": 3,
		"Owner_views": 478,
		"Answer_body": "<p>In this case is the best way to extract the information. But, I recommend using the <a href=\"http://ttps://github.com/aio-libs/yarl\" rel=\"nofollow noreferrer\">yarl</a> library for complex uri to parse.</p>\n<p>You can see this example:</p>\n<pre><code>&gt;&gt;&gt; from yarl import URL\n&gt;&gt;&gt; url = URL('https://www.python.org/~guido?arg=1#frag')\n&gt;&gt;&gt; url\nURL('https://www.python.org/~guido?arg=1#frag')\n</code></pre>\n<p>All URL parts can be accessed by these properties.</p>\n<pre><code>&gt;&gt;&gt; url.scheme\n'https'\n&gt;&gt;&gt; url.host\n'www.python.org'\n&gt;&gt;&gt; url.path\n'/~guido'\n&gt;&gt;&gt; url.query_string\n'arg=1'\n&gt;&gt;&gt; url.query\n&lt;MultiDictProxy('arg': '1')&gt;\n&gt;&gt;&gt; url.fragment\n'frag'\n</code></pre>",
		"Answer_comment_count": 0.0,
		"Answer_creation_date": "2022-02-14 21:24:49.257000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 1.0,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69316032,
		"Question_title": "Custom Container deployment in vertex ai",
		"Question_body": "<p>I am trying to deploy my custom container in vertex ai endpoint for predictions. The contents of the application are as follows.</p>\n<ol>\n<li>Flask - app.py</li>\n</ol>\n<pre><code>import pandas as pd\nfrom flask import Flask, jsonify,request\nimport tensorflow\nimport pre_process\nimport post_process\n\n\napp = Flask(__name__)\n\n\n@app.route('/predict',methods=['POST'])\ndef predict():\n    req = request.json.get('instances')\n    \n    input_data = req[0]['email']\n\n    #preprocessing\n    text = pre_process.preprocess(input_data)\n    vector = pre_process.preprocess_tokenizing(text)\n\n    model = tensorflow.keras.models.load_model('model')\n\n    #predict\n    prediction = model.predict(vector)\n\n    #postprocessing\n    value = post_process.postprocess(list(prediction[0])) \n    \n    return jsonify({'output':{'doc_class':value}})\n\n\nif __name__=='__main__':\n    app.run(host='0.0.0.0')\n</code></pre>\n<ol start=\"2\">\n<li>Dockerfile</li>\n</ol>\n<pre><code>FROM python:3.7\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --trusted-host pypi.python.org -r requirements.txt \n\n\nCMD [&quot;gunicorn&quot;, &quot;--bind&quot;, &quot;0.0.0.0:5000&quot;, &quot;app:app&quot;]\n\nEXPOSE 5050\n</code></pre>\n<ol start=\"3\">\n<li>pre_process.py</li>\n</ol>\n<pre><code>#import \nimport pandas as pd\nimport pickle\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\ndef preprocess(text):\n    &quot;&quot;&quot;Do all the Preprocessing as shown above and\n    return a tuple contain preprocess_email,preprocess_subject,preprocess_text for that Text_data&quot;&quot;&quot;\n         \n    \n    #After you store it in the list, Replace those sentances in original text by space.\n    text = re.sub(&quot;(Subject:).+&quot;,&quot; &quot;,text,re.I)\n    \n    #Delete all the sentances where sentence starts with &quot;Write to:&quot; or &quot;From:&quot;.\n    text = re.sub(&quot;((Write to:)|(From:)).+&quot;,&quot;&quot;,text,re.I)\n    \n    #Delete all the tags like &quot;&lt; anyword &gt;&quot;\n    text = re.sub(&quot;&lt;[^&gt;&lt;]+&gt;&quot;,&quot;&quot;,text)\n    \n    #Delete all the data which are present in the brackets.\n    text = re.sub(&quot;\\([^()]+\\)&quot;,&quot;&quot;,text)\n    \n    #Remove all the newlines('\\n'), tabs('\\t'), &quot;-&quot;, &quot;&quot;.\n    text = re.sub(&quot;[\\n\\t\\\\-]+&quot;,&quot;&quot;,text)\n    \n    #Remove all the words which ends with &quot;:&quot;.\n    text = re.sub(&quot;(\\w+:)&quot;,&quot;&quot;,text)\n    \n    #Decontractions, replace words like below to full words.\n\n    lines = re.sub(r&quot;n\\'t&quot;, &quot; not&quot;, text)\n    lines = re.sub(r&quot;\\'re&quot;, &quot; are&quot;, lines)\n    lines = re.sub(r&quot;\\'s&quot;, &quot; is&quot;, lines)\n    lines = re.sub(r&quot;\\'d&quot;, &quot; would&quot;, lines)\n    lines = re.sub(r&quot;\\'ll&quot;, &quot; will&quot;, lines)\n    lines = re.sub(r&quot;\\'t&quot;, &quot; not&quot;, lines)\n    lines = re.sub(r&quot;\\'ve&quot;, &quot; have&quot;, lines)\n    lines = re.sub(r&quot;\\'m&quot;, &quot; am&quot;, lines)\n    text = lines\n    \n        #replace numbers with spaces\n    text = re.sub(&quot;\\d+&quot;,&quot; &quot;,text)\n    \n        # remove _ from the words starting and/or ending with _\n    text = re.sub(&quot;(\\s_)|(_\\s)&quot;,&quot; &quot;,text)\n    \n        #remove 1 or 2 letter word before _\n    text = re.sub(&quot;\\w{1,2}_&quot;,&quot;&quot;,text)\n    \n        #convert all letters to lowercase and remove the words which are greater \n        #than or equal to 15 or less than or equal to 2.\n    text = text.lower()\n    \n    text =&quot; &quot;.join([i for i in text.split() if len(i)&lt;15 and len(i)&gt;2])\n    \n    #replace all letters except A-Z,a-z,_ with space\n    preprocessed_text = re.sub(&quot;\\W+&quot;,&quot; &quot;,text)\n\n    return preprocessed_text\n\ndef preprocess_tokenizing(text):\n        \n    #from tf.keras.preprocessing.text import Tokenizer\n    #from tf.keras.preprocessing.sequence import pad_sequences\n    \n    tokenizer = pickle.load(open('tokenizer.pkl','rb'))\n\n    max_length = 1019\n    tokenizer.fit_on_texts([text])\n    encoded_docs = tokenizer.texts_to_sequences([text])\n    text_padded = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n    \n    return text_padded\n</code></pre>\n<ol start=\"4\">\n<li>post_process.py</li>\n</ol>\n<pre><code>def postprocess(vector):\n    index = vector.index(max(vector))\n    classes = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n    return classes[index]\n</code></pre>\n<ol start=\"4\">\n<li>requirements.txt</li>\n</ol>\n<pre><code>gunicorn\npandas==1.3.3\nnumpy==1.19.5\nflask\nflask-cors\nh5py==3.1.0\nscikit-learn==0.24.2\ntensorflow==2.6.0\n\n</code></pre>\n<ol start=\"5\">\n<li><p>model</p>\n</li>\n<li><p>tokenizer.pkl</p>\n</li>\n</ol>\n<p>I am following this blog <a href=\"https://medium.com/mlearning-ai/serverless-prediction-at-scale-part-2-custom-container-deployment-on-vertex-ai-103a43d0a290\" rel=\"nofollow noreferrer\">vertex ai deployment</a> for gcloud console commands to containerise and deploy the model to endpoint.But the model is taking forever to get deployed and ultimately fails to get deployed.</p>\n<p>After running the container in local host, it runs as expected but it is not getting deployed into vertex ai endpoint. I don't understand whether the problem is in flask app.py or Dockerfile or whether the problem lies somewhere else.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 2,
		"Question_creation_date": "2021-09-24 13:42:01.653000 UTC",
		"Question_favorite_count": 2.0,
		"Question_last_edit_date": null,
		"Question_score": 3,
		"Question_tags": "flask|dockerfile|google-cloud-vertex-ai",
		"Question_view_count": 629,
		"Owner_creation_date": "2021-09-08 09:22:34.063000 UTC",
		"Owner_last_access_date": "2022-05-19 04:33:00.303000 UTC",
		"Owner_location": null,
		"Owner_reputation": 111,
		"Owner_up_votes": 4,
		"Owner_down_votes": 0,
		"Owner_views": 12,
		"Answer_body": "<p>I was able to resolve this issue by adding health route to http server. I added the following piece of code in my flask app.</p>\n<pre><code>@app.route('/healthz')\ndef healthz():\n    return &quot;OK&quot;\n</code></pre>",
		"Answer_comment_count": 1.0,
		"Answer_creation_date": "2021-09-28 05:16:11.387000 UTC",
		"Answer_last_edit_date": "2021-09-28 06:36:09.573000 UTC",
		"Answer_score": 4.0,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69565796,
		"Question_title": "When can one find logs for Vertex AI Batch Prediction jobs?",
		"Question_body": "<p>I couldn't find relevant information in the Documentation. I have tried all options and links in the batch transform pages.</p>",
		"Question_answer_count": 2,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-10-14 06:08:05.233000 UTC",
		"Question_favorite_count": 2.0,
		"Question_last_edit_date": null,
		"Question_score": 4,
		"Question_tags": "google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 492,
		"Owner_creation_date": "2021-10-14 05:56:24.710000 UTC",
		"Owner_last_access_date": "2022-09-23 07:04:34.437000 UTC",
		"Owner_location": null,
		"Owner_reputation": 41,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 2,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71038823,
		"Question_title": "Cannot construct an Explanation object",
		"Question_body": "<p>Trying to construct an <code>Explanation</code> object for a unit test, but can't seem to get it to work. Here's what I'm trying:</p>\n<pre><code>from google.cloud import aiplatform\n\naiplatform.compat.types.explanation_v1.Explanation(\n    attributions=aiplatform.compat.types.explanation_v1.Attribution(\n        {\n            &quot;approximation_error&quot;: 0.010399332817679649,\n            &quot;baseline_output_value&quot;: 0.9280818700790405,\n            &quot;feature_attributions&quot;: {\n                &quot;feature_1&quot;: -0.0410824716091156,\n                &quot;feature_2&quot;: 0.01155053575833639,\n            },\n            &quot;instance_output_value&quot;: 0.6717480421066284,\n            &quot;output_display_name&quot;: &quot;true&quot;,\n            &quot;output_index&quot;: [0],\n            &quot;output_name&quot;: &quot;scores&quot;,\n        }\n    )\n)\n</code></pre>\n<p>which gives:</p>\n<pre><code>&quot;.venv/lib/python3.7/site-packages/proto/message.py&quot;, line 521, in __init__\n    super().__setattr__(&quot;_pb&quot;, self._meta.pb(**params))\nTypeError: Value must be iterable\n</code></pre>\n<p>I found <a href=\"https://github.com/googleapis/gapic-generator-python/issues/413#issuecomment-872094378\" rel=\"nofollow noreferrer\">this</a> on github, but I'm not sure how to apply that workaround here.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-02-08 18:13:44.883000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|protocol-buffers|google-cloud-vertex-ai",
		"Question_view_count": 74,
		"Owner_creation_date": "2018-03-01 19:41:46.780000 UTC",
		"Owner_last_access_date": "2022-09-25 03:26:23.160000 UTC",
		"Owner_location": null,
		"Owner_reputation": 3576,
		"Owner_up_votes": 42,
		"Owner_down_votes": 7,
		"Owner_views": 203,
		"Answer_body": "<p>As the error mentioned value to be passed at <code>attributions</code> should be <strong>iterable</strong>. See <a href=\"https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.Explanation\" rel=\"nofollow noreferrer\">Explanation attributes documentation</a>.</p>\n<p>I tried your code and placed the <code>Attribution</code> object in a list and the error is gone. I assigned your objects in variables just so the code is readable.</p>\n<p>See code and testing below:</p>\n<pre><code>from google.cloud import aiplatform\n\ntest = {\n            &quot;approximation_error&quot;: 0.010399332817679649,\n            &quot;baseline_output_value&quot;: 0.9280818700790405,\n            &quot;feature_attributions&quot;: {\n                &quot;feature_1&quot;: -0.0410824716091156,\n                &quot;feature_2&quot;: 0.01155053575833639,\n            },\n            &quot;instance_output_value&quot;: 0.6717480421066284,\n            &quot;output_display_name&quot;: &quot;true&quot;,\n            &quot;output_index&quot;: [0],\n            &quot;output_name&quot;: &quot;scores&quot;,\n        }\n\nattributions=aiplatform.compat.types.explanation_v1.Attribution(test)\nx  = aiplatform.compat.types.explanation_v1.Explanation(\n    attributions=[attributions]\n)\nprint(x)\n</code></pre>\n<p>Output:</p>\n<pre><code>attributions {\n  baseline_output_value: 0.9280818700790405\n  instance_output_value: 0.6717480421066284\n  feature_attributions {\n    struct_value {\n      fields {\n        key: &quot;feature_1&quot;\n        value {\n          number_value: -0.0410824716091156\n        }\n      }\n      fields {\n        key: &quot;feature_2&quot;\n        value {\n          number_value: 0.01155053575833639\n        }\n      }\n    }\n  }\n  output_index: 0\n  output_display_name: &quot;true&quot;\n  approximation_error: 0.010399332817679649\n  output_name: &quot;scores&quot;\n}\n</code></pre>",
		"Answer_comment_count": 0.0,
		"Answer_creation_date": "2022-02-09 05:52:12.890000 UTC",
		"Answer_last_edit_date": "2022-02-09 06:15:44.880000 UTC",
		"Answer_score": 1.0,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71986344,
		"Question_title": "VertexAI Batch Inference Failing for Custom Container Model",
		"Question_body": "<p>I'm having trouble executing VertexAI's batch inference, despite endpoint deployment and inference working perfectly. My TensorFlow model has been trained in a custom Docker container with the following arguments:</p>\n<pre><code>aiplatform.CustomContainerTrainingJob(\n        display_name=display_name,\n        command=[&quot;python3&quot;, &quot;train.py&quot;],\n        container_uri=container_uri,\n        model_serving_container_image_uri=container_uri,\n        model_serving_container_environment_variables=env_vars,\n        model_serving_container_predict_route='/predict',\n        model_serving_container_health_route='/health',\n        model_serving_container_command=[\n            &quot;gunicorn&quot;,\n            &quot;src.inference:app&quot;,\n            &quot;--bind&quot;,\n            &quot;0.0.0.0:5000&quot;,\n            &quot;-k&quot;,\n            &quot;uvicorn.workers.UvicornWorker&quot;,\n            &quot;-t&quot;,\n            &quot;6000&quot;,\n        ],\n        model_serving_container_ports=[5000],\n)\n</code></pre>\n<p>I have a Flask endpoint defined for predict and health essentially defined below:</p>\n<pre><code>@app.get(f&quot;/health&quot;)\ndef health_check_batch():\n    return 200\n\n@app.post(f&quot;/predict&quot;)\ndef predict_batch(request_body: dict):\n    pred_df = pd.DataFrame(request_body['instances'],\n                           columns = request_body['parameters']['columns'])\n    # do some model inference things\n    return {&quot;predictions&quot;: predictions.tolist()}\n</code></pre>\n<p>As described, when training a model and deploying to an endpoint, I can successfully hit the API with JSON schema like:</p>\n<pre><code>{&quot;instances&quot;:[[1,2], [1,3]], &quot;parameters&quot;:{&quot;columns&quot;:[&quot;first&quot;, &quot;second&quot;]}}\n</code></pre>\n<p>This also works when using the endpoint Python SDK and feeding in instances/parameters as functional arguments.</p>\n<p>However, I've tried performing batch inference with a CSV file and a JSONL file, and every time it fails with an Error Code 3. I can't find logs on why it failed in Logs Explorer either. I've read through all the documentation I could find and have seen other's successfully invoke batch inference, but haven't been able to find a guide. Does anyone have recommendations on batch file structure or the structure of my APIs? Thank you!</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 1,
		"Question_creation_date": "2022-04-24 07:29:05.693000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 111,
		"Owner_creation_date": "2016-06-28 17:55:10.360000 UTC",
		"Owner_last_access_date": "2022-05-23 21:53:23.470000 UTC",
		"Owner_location": null,
		"Owner_reputation": 33,
		"Owner_up_votes": 3,
		"Owner_down_votes": 0,
		"Owner_views": 7,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71132848,
		"Question_title": "Google.Cloud.AIPlatform.V1 Received http2 header with status: 404",
		"Question_body": "<p>We are trying to call the Google.Cloud.AIPlatform.V1 predict API using the .Net client and keep getting the following error:   Received http2 header with status: 404</p>\n<p>We setup credentials using the API key and environment variable:  GOOGLE_APPLICATION_CREDENTIALS</p>\n<p>Here is the code to call the vertex AI predict API:</p>\n<pre><code>const string projectId = &quot;xxxxxx&quot;;\nconst string location = &quot;us-central1&quot;; \nconst string endpointId = &quot;xxxxxx&quot;;  \n\nPredictionServiceClient client = PredictionServiceClient.Create();\n\nvar structVal = Google.Protobuf.WellKnownTypes.Value.ForStruct(new Struct\n{\n    Fields =\n    {\n    [&quot;mimeType&quot;] = Google.Protobuf.WellKnownTypes.Value.ForString(&quot;text/plain&quot;),\n    // Sample contents is a string constant defined in a separate file\n    [&quot;content&quot;] = Google.Protobuf.WellKnownTypes.Value.ForString(Consts.SampleContents)\n    }\n});\n\nPredictRequest req = new PredictRequest()\n{\n    EndpointAsEndpointName = EndpointName.FromProjectLocationEndpoint(projectId, location, endpointId),\n    Instances = { structVal }\n};\n\nPredictResponse response = client.Predict(req);\n</code></pre>\n<p>The full error returned:</p>\n<p>Status(StatusCode=&quot;Unimplemented&quot;, Detail=&quot;Received http2 header with status: 404&quot;, DebugException=&quot;Grpc.Core.Internal.CoreErrorDetailException: {&quot;created&quot;:&quot;@1644947338.412000000&quot;,&quot;description&quot;:&quot;Received http2 :status header with non-200 OK status&quot;,&quot;file&quot;:&quot;......\\src\\core\\ext\\filters\\http\\client\\http_client_filter.cc&quot;,&quot;file_line&quot;:134,&quot;grpc_message&quot;:&quot;Received http2 header with status: 404&quot;,&quot;grpc_status&quot;:12,&quot;value&quot;:&quot;404&quot;}&quot;)</p>\n<p>I validate the same call using CURL and was able to successfully make the call.</p>\n<pre><code>curl -X POST -H &quot;Authorization: Bearer XXXXX&quot; -H &quot;Content-Type: application/json&quot; https://us-central1-aiplatform.googleapis.com/ui/projects/XXXXXX/locations/us-central1/endpoints/XXXXXX:predict -d @payload.json\n</code></pre>\n<p>Any help would be greatly appreciated.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-02-15 20:18:14.297000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "c#|google-cloud-vertex-ai",
		"Question_view_count": 204,
		"Owner_creation_date": "2018-12-26 14:50:25.527000 UTC",
		"Owner_last_access_date": "2022-09-24 17:43:12.653000 UTC",
		"Owner_location": null,
		"Owner_reputation": 1,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 6,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 70729582,
		"Question_title": "Batch prediction Input",
		"Question_body": "<p>I have a tensorflow model deployed on Vertex AI of Google Cloud. The model definition is:</p>\n<pre><code>item_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=item_vocab, mask_token=None),\n  tf.keras.layers.Embedding(len(item_vocab) + 1, embedding_dim)\n])\n\nuser_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=user_vocab, mask_token=None),\n  # We add an additional embedding to account for unknown tokens.\n  tf.keras.layers.Embedding(len(user_vocab) + 1, embedding_dim)\n])\n\n\nclass NCF_model(tf.keras.Model):\n    def __init__(self,user_model, item_model):\n        super(NCF_model, self).__init__()\n        # define all layers in init\n        \n        self.user_model = user_model\n        self.item_model  = item_model\n        self.concat_layer   = tf.keras.layers.Concatenate()\n        self.feed_forward_1 = tf.keras.layers.Dense(32,activation= 'relu')\n        self.feed_forward_2 = tf.keras.layers.Dense(64,activation= 'relu')\n        self.final = tf.keras.layers.Dense(1,activation= 'sigmoid')\n\n\n    def call(self, inputs ,training=False):\n        user_id , item_id = inputs[:,0], inputs[:,1]\n        x = self.user_model(user_id)\n        y = self.item_model(item_id)\n\n        x = self.concat_layer([x,y])\n        x = self.feed_forward_1(x)\n        x = self.feed_forward_2(x)\n        x = self.final(x)\n\n\n        return x\n</code></pre>\n<p>The model has two string inputs and it outputs a probability value.\nWhen I use the following input in the batch prediction file, I get an empty prediction file.\nSample of csv input file:</p>\n<pre><code>userid,itemid\nyuu,190767\nyuu,364\nyuu,154828\nyuu,72998\nyuu,130618\nyuu,183979\nyuu,588\n</code></pre>\n<p>When I use a jsonl file with the following input.</p>\n<pre><code>{&quot;input&quot;:[&quot;yuu&quot;, &quot;190767&quot;]}\n</code></pre>\n<p>I get the following error.</p>\n<pre><code>('Post request fails. Cannot get predictions. Error: Exceeded retries: Non-OK result 400 ({\\n    &quot;error&quot;: &quot;Failed to process element: 0 key: input of \\'instances\\' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: input&quot;\\n}) from server, retry=3.', 1)\n</code></pre>\n<p>What seems to be going wrong with these inputs?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 1,
		"Question_creation_date": "2022-01-16 11:25:44.157000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "google-cloud-platform|google-ai-platform|google-cloud-vertex-ai",
		"Question_view_count": 323,
		"Owner_creation_date": "2015-04-20 12:22:18.823000 UTC",
		"Owner_last_access_date": "2022-09-24 14:16:22.667000 UTC",
		"Owner_location": "Gurugram, Haryana, India",
		"Owner_reputation": 363,
		"Owner_up_votes": 26,
		"Owner_down_votes": 0,
		"Owner_views": 32,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72917441,
		"Question_title": "Vertex AI Object Tracking with only one label",
		"Question_body": "<p>I want to train an object tracking model in Vertex AI for one type of object. The &quot;Train New Model&quot; button says &quot;To train a model, you must have at least two labels and each label included in training must have at least 15 videos assigned to it.&quot; I do not find any explanation of this requirement in the documentation. Does anyone know why I must have two labels?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-07-08 22:06:40.823000 UTC",
		"Question_favorite_count": 1.0,
		"Question_last_edit_date": "2022-07-08 23:34:38.527000 UTC",
		"Question_score": 1,
		"Question_tags": "google-cloud-automl|google-cloud-vertex-ai|object-tracking",
		"Question_view_count": 88,
		"Owner_creation_date": "2021-10-08 15:45:59.980000 UTC",
		"Owner_last_access_date": "2022-09-23 19:31:28.020000 UTC",
		"Owner_location": null,
		"Owner_reputation": 21,
		"Owner_up_votes": 4,
		"Owner_down_votes": 0,
		"Owner_views": 7,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 73731002,
		"Question_title": "Why do I get There are no registered serializers for type \"google.VertexEndpoint\"",
		"Question_body": "<p>I am trying to deploy a model using <code>ModelDeployOp</code> in a Vertex AI pipeline component. My code is:</p>\n<pre><code>parent = client.common_location_path(project=project, location=location)\nrequest = aiplatform_v1.ListEndpointsRequest(parent=parent)\n\npage_result = client.list_endpoints(request=request)\nfor response in page_result:\n     latest_endpoint=response\n\n\ndeploy_op=gcc_aip.ModelDeployOp(\nmodel=model_name,\nendpoint=latest_endpoint,\ndedicated_resources_min_replica_count=1,\ndedicated_resources_max_replica_count=1,\ndedicated_resources_machine_type=&quot;n1-standard-4&quot;,\n)\n</code></pre>\n<p>but i get:</p>\n<pre><code>TypeError: There are no registered serializers for type &quot;google.VertexEndpoint&quot;.\n</code></pre>\n<p>How can I fix this or maybe find a better way of getting the endpoint?</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-09-15 12:17:30.463000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "google-cloud-platform|google-cloud-vertex-ai|kfp",
		"Question_view_count": 9,
		"Owner_creation_date": "2012-10-25 08:48:34.717000 UTC",
		"Owner_last_access_date": "2022-09-23 10:10:32.783000 UTC",
		"Owner_location": null,
		"Owner_reputation": 2564,
		"Owner_up_votes": 304,
		"Owner_down_votes": 8,
		"Owner_views": 451,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69936296,
		"Question_title": "Vertex AI custom container batch prediction",
		"Question_body": "<p>I have created a custom container for prediction and successfully uploaded the model to Vertex AI. I was also able to deploy the model to an endpoint and successfully request predictions from the endpoint. Within the custom container code, I use the <code>parameters</code> field as described <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#prediction\" rel=\"nofollow noreferrer\">here</a>, which I then supply later on when making an online prediction request.\nMy questions are regarding requesting batch predictions from a custom container for prediction.</p>\n<ol>\n<li><p>I cannot find any documentation that describes what happens when I request a batch prediction. Say, for example, I use the <code>my_model.batch_predict</code> function from the Python SDK and set the <code>instances_format</code> to &quot;csv&quot; and provide the <code>gcs_source</code>. Now, I have setup my custom container to expect prediction requests at <code>/predict</code> as described in this <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements\" rel=\"nofollow noreferrer\">documentation</a>. Does Vertex AI make a POST request to this path, converting the cvs data into the appropriate POST body?</p>\n</li>\n<li><p>How do I specify the <code>parameters</code> field for batch prediction as I did for online prediction?</p>\n</li>\n</ol>",
		"Question_answer_count": 1,
		"Question_comment_count": 2,
		"Question_creation_date": "2021-11-11 23:44:50.160000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 3,
		"Question_tags": "google-cloud-platform|google-ai-platform|google-cloud-vertex-ai",
		"Question_view_count": 808,
		"Owner_creation_date": "2016-08-15 20:29:46.790000 UTC",
		"Owner_last_access_date": "2022-09-24 22:22:50.413000 UTC",
		"Owner_location": null,
		"Owner_reputation": 700,
		"Owner_up_votes": 17,
		"Owner_down_votes": 1,
		"Owner_views": 90,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 73251212,
		"Question_title": "How do I retrieve a model in Vertex AI?",
		"Question_body": "<p>I defined a training job:</p>\n<pre><code>job = aiplatform.AutoMLTextTrainingJob(...\n</code></pre>\n<p>then I created a model by running the job:</p>\n<pre><code>model = job.run(...\n</code></pre>\n<p>It worked fine but it is now the next day and the variable <code>model</code> was in a Jupyter notebook and no longer exists. I have tried to get it back with:</p>\n<pre><code>from google.cloud import aiplatform_v1beta1\n\ndef sample_get_model():\n    client = aiplatform_v1beta1.ModelServiceClient()\n\n    model_id=id_of_training_pipeline\n    name= f'projects/{PROJECT}/locations/{REGION}/models/{model_id}'\n    \n    request = aiplatform_v1beta1.GetModelRequest(name=name)\n    response = client.get_model(request=request)\n    print(response)\n\nsample_get_model()\n</code></pre>\n<p>I have also tried the id of v1 of the model created in place of <code>id_of_training_pipeline</code> and I have tried <code>/pipelines/pipeline_id</code></p>\n<p>but I get:\n<code>E0805 15:12:36.784008212   28406 hpack_parser.cc:1234]       Error parsing metadata: error=invalid value key=content-type value=text/html; charset=UTF-8</code></p>\n<p>(<code>PROJECT</code> and <code>REGION</code> are set correctly).</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-08-05 14:19:46.783000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "google-cloud-vertex-ai",
		"Question_view_count": 45,
		"Owner_creation_date": "2012-10-25 08:48:34.717000 UTC",
		"Owner_last_access_date": "2022-09-23 10:10:32.783000 UTC",
		"Owner_location": null,
		"Owner_reputation": 2564,
		"Owner_up_votes": 304,
		"Owner_down_votes": 8,
		"Owner_views": 451,
		"Answer_body": "<p>Found <a href=\"https://cloud.google.com/vertex-ai/docs/samples/aiplatform-get-model-sample#aiplatform_get_model_sample-python\" rel=\"nofollow noreferrer\">this</a> Google code which works.</p>",
		"Answer_comment_count": 0.0,
		"Answer_creation_date": "2022-08-05 15:18:48.223000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 0.0,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72444116,
		"Question_title": "Model artifact must be in the same region as your model error gcp",
		"Question_body": "<p>i want to deploy my model(tensorflow) in vertex ai,GCP. steps that I've taken are such :</p>\n<ol>\n<li>Create a new bucket in google cloud storage with region <code>asia-southeast1(singapore)</code>.</li>\n<li>In that bucket, I've uploaded my tensorflow model folder (pb extension).</li>\n<li>I tried to import my tensorflow model in vertex ai with region <code>asia-southeast1(singapore)</code>.</li>\n<li>for the model artifact location, I've inputted the correct path. However I got the following error :</li>\n</ol>\n<pre><code>Model artifact must be in the same region as your model (asia-southeast1).\n</code></pre>\n<p>am i missing something here? If you need additional information, feel free to comment below</p>\n<p><a href=\"https://i.stack.imgur.com/leGa8.png\" rel=\"nofollow noreferrer\">screenshot of my vertexai gcp</a><br />\n<a href=\"https://i.stack.imgur.com/XLk81.png\" rel=\"nofollow noreferrer\">screenshot of my google cloud storage bucket</a></p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-05-31 07:59:11.697000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2022-05-31 07:59:59.167000 UTC",
		"Question_score": 0,
		"Question_tags": "google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 189,
		"Owner_creation_date": "2022-05-28 13:28:11.383000 UTC",
		"Owner_last_access_date": "2022-08-27 11:21:51.827000 UTC",
		"Owner_location": null,
		"Owner_reputation": 1,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 0,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71468270,
		"Question_title": "How to make a prediction to a private Vertex AI endpoint with Node.js client libraries?",
		"Question_body": "<p>Documentation on this is a bit vague at the time of posting <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints#sending-prediction-to-private-endpoint\" rel=\"nofollow noreferrer\">https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints#sending-prediction-to-private-endpoint</a> , they only mention how to do it with curl.</p>\n<p>I would like to use the node.js client library if possible, but I've only managed to find examples that don't use a private endpoint ie: <a href=\"https://github.com/googleapis/nodejs-ai-platform/blob/main/samples/predict-custom-trained-model.js\" rel=\"nofollow noreferrer\">https://github.com/googleapis/nodejs-ai-platform/blob/main/samples/predict-custom-trained-model.js</a> .</p>\n<p>I've read through the type definitions of <code>PredictionServiceClient</code> imported from <code>@google-cloud/aiplatform</code> and didn't find a way to plug in my private endpoint. I've tried making the request anyway by simply specifying the resource name by doing <code>const endpoint = projects/${project}/locations/${location}/endpoints/${endpointId}</code> but this leads to the following error:</p>\n<pre><code>Error: 13 INTERNAL: Received RST_STREAM with code 0\n    at Object.callErrorFromStatus (/home/vitor/vertexai/node_modules/@grpc/grpc-js/src/call.ts:81:24)\n    at Object.onReceiveStatus (/home/vitor/vertexai/node_modules/@grpc/grpc-js/src/client.ts:343:36)\n    at Object.onReceiveStatus (/home/vitor/vertexai/node_modules/@grpc/grpc-js/src/client-interceptors.ts:462:34)\n    at Object.onReceiveStatus (/home/vitor/vertexai/node_modules/@grpc/grpc-js/src/client-interceptors.ts:424:48)\n    at /home/vitor/vertexai/node_modules/@grpc/grpc-js/src/call-stream.ts:323:24\n    at processTicksAndRejections (node:internal/process/task_queues:78:11) {\n  code: 13,\n  details: 'Received RST_STREAM with code 0',\n  metadata: Metadata { internalRepr: Map(0) {}, options: {} }\n}\n</code></pre>\n<p>My code looks like this:</p>\n<pre><code>(async () =&gt; {\n        const client = new v1beta1.PredictionServiceClient();\n        const location = &quot;****&quot;;\n        const project = &quot;****&quot;;\n        const endpointId = &quot;****&quot;\n        const endpoint = `projects/${project}/locations/${location}/endpoints/${endpointId}`;\n\n        const parameters = {\n            structValue: {\n                fields: {},\n            },\n        };\n\n        const toInstance = (obj: any) =&gt; (\n            {\n                structValue: {\n                    fields: {\n                        ****\n                    }\n                }\n            });\n\n        const instance = toInstance(****);\n        const instances = [instance];\n\n        const res = await client.predict({\n            instances,\n            endpoint,\n            parameters\n        });\n        console.log(res);\n    })();\n</code></pre>\n<p>Is it possible to make this kind of request atm?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 10,
		"Question_creation_date": "2022-03-14 13:05:35.233000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 1,
		"Question_tags": "node.js|google-cloud-platform|google-cloud-vertex-ai",
		"Question_view_count": 676,
		"Owner_creation_date": "2020-02-15 20:36:26.270000 UTC",
		"Owner_last_access_date": "2022-09-08 19:19:18.530000 UTC",
		"Owner_location": null,
		"Owner_reputation": 185,
		"Owner_up_votes": 9,
		"Owner_down_votes": 0,
		"Owner_views": 12,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "vertex-ai",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	}
]