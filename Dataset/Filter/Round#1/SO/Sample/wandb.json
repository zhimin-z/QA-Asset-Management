[
	{
		"Question_id": 71916491,
		"Question_title": "WANDB run initialization",
		"Question_body": "<p>I wanted to try using wandb to log runs of my ML experiments for a project; but I am not able to initialize the run itself.\nI tried:</p>\n<p><code>run = wandb.init(project=&quot;name&quot;,entity=&quot;username&quot;,name=&quot;classification&quot;)</code></p>\n<p>This results in:\nwandb: W&amp;B API key is configured (use <code>wandb login --relogin</code> to force relogin)</p>\n<p>wandb: Network error (ConnectTimeout), entering retry loop.</p>\n<p>wandb: Network error (ConnectTimeout), entering retry loop.</p>\n<p>What can I do to fix this? (I did login through the terminal before launching this cell idk what else to try)</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 2,
		"Question_creation_date": "2022-04-18 19:58:49.900000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2022-04-18 20:13:21.033000 UTC",
		"Question_score": 0,
		"Question_tags": "python|jupyter-notebook|wandb",
		"Question_view_count": 337,
		"Owner_creation_date": "2022-04-18 19:51:31.997000 UTC",
		"Owner_last_access_date": "2022-06-02 19:16:00.160000 UTC",
		"Owner_location": null,
		"Owner_reputation": 1,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 0,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72729259,
		"Question_title": "wandb.Table raises error: AssertionError: columns argument expects a `list` object",
		"Question_body": "<p>I'm very beginner with wandb , so this is very basic question.\nI have dataframe which has my x features and y values.\nI'm tryin to follow <a href=\"https://docs.wandb.ai/examples\" rel=\"nofollow noreferrer\">this tutorial</a>  to train model from my pandas dataframe . However, when I try to create wandb table from my pandas dataframe, I get an error:</p>\n<pre><code>\nwandb.init(project='my-xgb', config={'lr': 0.01})\n\n#the log didn't work  so I haven't run it at the moment (the log 'loss') \n#wandb.log({'loss': loss, ...})\n\n\n# Create a W&amp;B Table with your pandas dataframe\ntable = wandb.Table(df1)\n</code></pre>\n<blockquote>\n<p>AssertionError: columns argument expects a <code>list</code> object</p>\n</blockquote>\n<p>I have no idea why is this happen, and why it excpect a list. In the tutorial it doesn't look like the dataframe is list.</p>\n<p>My end goal - to be able to create wandb table.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-06-23 11:18:13.280000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|pandas|dataframe|wandb",
		"Question_view_count": 63,
		"Owner_creation_date": "2019-10-28 09:51:58.027000 UTC",
		"Owner_last_access_date": "2022-09-20 12:29:28.963000 UTC",
		"Owner_location": "Israel",
		"Owner_reputation": 1387,
		"Owner_up_votes": 955,
		"Owner_down_votes": 16,
		"Owner_views": 224,
		"Answer_body": "<p><strong>Short answer</strong>: <code>table = wandb.Table(dataframe=my_df)</code>.</p>\n<p>The explanation of your specific case is at the bottom.</p>\n<hr />\n<p><strong>Minimal example</strong> of using <code>wandb.Table</code> with a DataFrame:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import wandb\nimport pandas as pd\n\niris_path = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\niris = pd.read_csv(iris_path)\ntable = wandb.Table(dataframe=iris)\nwandb.log({'dataframe_in_table': table})\n</code></pre>\n<p>(Here the dataset is called the Iris dataset that consists of &quot;3 different types of irises\u2019 (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray&quot;)</p>\n<p>There are two ways of creating W&amp;B <code>Table</code>s according to <a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#create-tables\" rel=\"nofollow noreferrer\">the official documentation</a>:</p>\n<ul>\n<li><strong>List of Rows</strong>: Log named columns and rows of data. For example: <code>wandb.Table(columns=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], data=[[&quot;1a&quot;, &quot;1b&quot;, &quot;1c&quot;], [&quot;2a&quot;, &quot;2b&quot;, &quot;2c&quot;]])</code> generates a table with two rows and three columns.</li>\n<li><strong>Pandas DataFrame</strong>: Log a DataFrame using <code>wandb.Table(dataframe=my_df)</code>. Column names will be extracted from the DataFrame.</li>\n</ul>\n<hr />\n<p><strong>Explanation</strong>: Why <code>table = wandb.Table(my_df)</code> gives error &quot;columns argument expects a <code>list</code> object&quot;? Because <code>wandb.Table</code>'s init function looks like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def __init__(\n        self,\n        columns=None,\n        data=None,\n        rows=None,\n        dataframe=None,\n        dtype=None,\n        optional=True,\n        allow_mixed_types=False,\n    ):\n</code></pre>\n<p>If one passes a DataFrame without telling it's a DataFrame, <code>wandb.Table</code> will assume the argument is <code>columns</code>.</p>",
		"Answer_comment_count": 2.0,
		"Answer_creation_date": "2022-06-23 11:28:00.023000 UTC",
		"Answer_last_edit_date": "2022-06-23 12:04:19.240000 UTC",
		"Answer_score": 2.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72555212,
		"Question_title": "wandb pytorch: top1 accuracy per class",
		"Question_body": "<p>I have 5 classes in validation set and i want to draw a graph based on top1 results per class in validation loop using wandb . I have tried a single accuracy graph based on the average of 5 classes and it works fine but i want to do a separate way like top1 accuracy for each class. I am unable to achieve, are there any way to achieve it?</p>\n<p><strong>Validation Loader</strong></p>\n<pre><code> val_loaders = []\n    for nuisance in val_nuisances:\n        val_loaders.append((nuisance, torch.utils.data.DataLoader(\n            datasets.ImageFolder(os.path.join(valdir, nuisance), transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                normalize,\n            ])),\n            batch_size=args.batch_size, shuffle=False,\n            num_workers=args.workers, pin_memory=True,\n        )))\n\n\nval_nuisances = ['shape', 'pose', 'texture', 'context', 'weather']\n</code></pre>\n<p><strong>Validation Loop</strong></p>\n<pre><code>def validate(val_loaders, model, criterion, args):\n    overall_top1 = 0\n    for nuisance, val_loader in val_loaders:\n        batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)\n        losses = AverageMeter('Loss', ':.4e', Summary.NONE)\n        top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)\n        top5 = AverageMeter('Acc@5', ':6.2f', Summary.AVERAGE)\n        progress = ProgressMeter(\n            len(val_loader),\n            [batch_time, losses, top1, top5],\n            prefix=f'Test {nuisance}: ')\n\n        # switch to evaluate mode\n        model.eval()\n\n        with torch.no_grad():\n            end = time.time()\n            for i, (images, target) in enumerate(val_loader):\n                if args.gpu is not None:\n                    images = images.cuda(args.gpu, non_blocking=True)\n                if torch.cuda.is_available():\n                    target = target.cuda(args.gpu, non_blocking=True)\n\n                # compute output\n                output = model(images)\n                loss = criterion(output, target)\n\n                # measure accuracy and record loss\n                acc1, acc5 = accuracy(output, target, topk=(1, 5))\n                losses.update(loss.item(), images.size(0))\n                top1.update(acc1[0], images.size(0))\n                top5.update(acc5[0], images.size(0))\n\n                # measure elapsed time\n                batch_time.update(time.time() - end)\n                end = time.time()\n\n                if i % args.print_freq == 0:\n                    progress.display(i)\n\n            progress.display_summary()\n        overall_top1 += top1.avg\n    overall_top1 /= len(val_loaders)\n    return top1.avg\n</code></pre>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-06-09 05:42:03.610000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "pytorch|wandb",
		"Question_view_count": 71,
		"Owner_creation_date": "2015-01-05 16:22:18.783000 UTC",
		"Owner_last_access_date": "2022-09-23 07:10:40.323000 UTC",
		"Owner_location": "Seoul, South Korea",
		"Owner_reputation": 2201,
		"Owner_up_votes": 186,
		"Owner_down_votes": 3,
		"Owner_views": 556,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72972876,
		"Question_title": "YOLOv5 Evolution Results Not Reproducible wandb",
		"Question_body": "<p>I am running YOLOv5 in a sagemaker notebook.\nThe 10 epoch runs are using the following notebook script making use of the --evolve flag for hyperparameters.</p>\n<pre><code>!export WANDB_RUN_GROUP=&quot;evolution&quot; &amp;&amp; python ./deepsea-yolov5/yolov5/train.py\n--img=640\n--data=./deepsea-yolov5/opt/ml/custom_config.yaml\n--batch=2\n--weights=yolov5s.pt\n--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml\n--project=&quot;902005-vaa&quot;\n--cache\n--epochs=10\n--evolve=30\n</code></pre>\n<p>Evolution runs only output one point on the graph at the end of 10 epochs and the outputted hyperparameters do not show reproducible results when running in a 50 epoch run. The blue 50 epoch line showcases using the optimal hyperparameters which should intersect with the highest 10 epoch run, but it doesn't reach anywhere close.\n<a href=\"https://i.stack.imgur.com/sW0KX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sW0KX.png\" alt=\"enter image description here\" /></a></p>\n<p>After finding the optimal hyperparameters I ran a 50 epoch run using those parameters using the following command.</p>\n<pre><code>!export WANDB_RUN_GROUP=&quot;hyperparam&quot; &amp;&amp; python ./deepsea-yolov5/yolov5/train.py\n--img=640\n--data=./deepsea-yolov5/opt/ml/custom_config.yaml\n--batch=2\n--weights=yolov5s.pt\n--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml\n--hyp=./deepsea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml\n--project=&quot;902005-vaa&quot;\n--cache\n--epochs=50\n</code></pre>\n<p>However as shown in the picture above, the runs do not intersect with the best-performing hyperparameter run.</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-07-13 21:33:50.047000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|yolov5|wandb",
		"Question_view_count": 63,
		"Owner_creation_date": "2017-06-21 00:38:30.443000 UTC",
		"Owner_last_access_date": "2022-09-20 05:17:02.003000 UTC",
		"Owner_location": "California, USA",
		"Owner_reputation": 11,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 10,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69640534,
		"Question_title": "How to log artifacts in wandb while using saimpletransformers?",
		"Question_body": "<p>I am creating a Question Answering model using <a href=\"https://simpletransformers.ai/docs/qa-specifics/\" rel=\"nofollow noreferrer\">simpletransformers</a>. I would also like to use wandb to track model artifacts. As I understand from <a href=\"https://docs.wandb.ai/guides/integrations/other/simpletransformers\" rel=\"nofollow noreferrer\">wandb docs</a>, there is an integration touchpoint for simpletransformers but there is no mention of logging artifacts.</p>\n<p>I would like to log artifacts generated at the train, validation, and test phase such as train.json, eval.json, test.json, output/nbest_predictions_test.json and best performing model.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-10-20 04:55:43.473000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "nlp-question-answering|simpletransformers|wandb",
		"Question_view_count": 53,
		"Owner_creation_date": "2018-06-12 01:08:24.783000 UTC",
		"Owner_last_access_date": "2021-10-29 05:38:36.997000 UTC",
		"Owner_location": "Ahmedabad, Gujarat, India",
		"Owner_reputation": 13,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 1,
		"Answer_body": "<p>Currently simpleTransformers doesn't support logging artifacts within the training/testing scripts. But you can do it manually:</p>\n<pre><code>import os \n\nwith wandb.init(id=model.wandb_run_id, resume=&quot;allow&quot;, project=wandb_project) as training_run:\n    for dir in sorted(os.listdir(&quot;outputs&quot;)):\n        if &quot;checkpoint&quot; in dir:\n            artifact = wandb.Artifact(&quot;model-checkpoints&quot;, type=&quot;checkpoints&quot;)\n            artifact.add_dir(&quot;outputs&quot; + &quot;/&quot; + dir)\n            training_run.log_artifact(artifact)\n</code></pre>\n<p>For more info, you can follow along with the W&amp;B notebook in the SimpleTransofrmer's README.md</p>",
		"Answer_comment_count": 1.0,
		"Answer_creation_date": "2021-10-20 11:26:44.573000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 0.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71191185,
		"Question_title": "Pip installations on Colab from local",
		"Question_body": "<p>I'd like to use wandb on Colab, and I've installed it through pip on the command line. However, the import isn't recognized on Colab, so I have to run <code>!pip install wandb</code> each time.</p>\n<p>How can I install <code>wandb</code> locally so that I don't have to install it on the Colab notebook each time?</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 4,
		"Question_creation_date": "2022-02-20 03:36:27.297000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|pip|google-colaboratory|wandb",
		"Question_view_count": 516,
		"Owner_creation_date": "2019-05-19 03:48:33.157000 UTC",
		"Owner_last_access_date": "2022-09-23 15:43:15.227000 UTC",
		"Owner_location": null,
		"Owner_reputation": 421,
		"Owner_up_votes": 20,
		"Owner_down_votes": 5,
		"Owner_views": 33,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 64093979,
		"Question_title": "Weights and Biases: Login and network errors",
		"Question_body": "<p>I recently installed Weights and Biases (wandb) for recording the metrics of my machine learning projects. Everything worked fine when connected to wandb cloud instance or when I used a local docker image. Now, when I tried to access my local wandb instance from over the network, I started to get API error messages. However, I also noticed that wandb was trying to access my server using port 80, instead of 8080. I installed wandb client on a new cloud server and tried to access my server from there. Still, same error message shown below.</p>\n<p>This error happens when I use the command: <code>wandb login host=https://api.wandb.ai</code>\nI have tried to delete the .netrc file where the api settings are stored and re-installed wandb. Still same error. Using wandb version 0.10.2 on Ubuntu 18.04; Also, tried downgrading to version 0.8.36, no change.\nIf I try the command: <code>wandb login --relogin</code>, I get the same error.</p>\n<p>Is there some way to reset wandb so it forgets all these settings, or to resolve this issue directly?</p>\n<p>Many thanks</p>\n<p>Best Regards,</p>\n<p>Adeel</p>\n<pre><code>Retry attempt failed:\nTraceback (most recent call last):\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 160, in _new_conn\n    (self._dns_host, self.port), self.timeout, **extra_kw\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/util/connection.py&quot;, line 84, in create_connection\n    raise err\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/util/connection.py&quot;, line 74, in create_connection\n    sock.connect(sa)\nConnectionRefusedError: [Errno 111] Connection refused\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 677, in urlopen\n    chunked=chunked,\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 392, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/http/client.py&quot;, line 1277, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/http/client.py&quot;, line 1323, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/http/client.py&quot;, line 1272, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/http/client.py&quot;, line 1032, in _send_output\n    self.send(msg)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/http/client.py&quot;, line 972, in send\n    self.connect()\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 187, in connect\n    conn = self._new_conn()\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 172, in _new_conn\n    self, &quot;Failed to establish a new connection: %s&quot; % e\nurllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f0a26b54c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/adapters.py&quot;, line 449, in send\n    timeout=timeout\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 727, in urlopen\n    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/urllib3/util/retry.py&quot;, line 439, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='34.71.47.117', port=80): Max retries exceeded with url: /graphql (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f0a26b54c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/old/retry.py&quot;, line 96, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/internal/internal_api.py&quot;, line 128, in execute\n    return self.client.execute(*args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/client.py&quot;, line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/client.py&quot;, line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py&quot;, line 38, in execute\n    request = requests.post(self.url, **post_args)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/api.py&quot;, line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/api.py&quot;, line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/sessions.py&quot;, line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/sessions.py&quot;, line 643, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/requests/adapters.py&quot;, line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='34.71.47.117', port=80): Max retries exceeded with url: /graphql (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f0a26b54c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\nwandb: Network error (ConnectionError), entering retry loop. See wandb/debug-internal.log for full traceback.\nTraceback (most recent call last):\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/bin/wandb&quot;, line 8, in &lt;module&gt;\n    sys.exit(cli())\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/click/core.py&quot;, line 829, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/click/core.py&quot;, line 782, in main\n    rv = self.invoke(ctx)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/click/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/click/core.py&quot;, line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/click/core.py&quot;, line 610, in invoke\n    return callback(*args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/cli/cli.py&quot;, line 72, in wrapper\n    return func(*args, **kwargs)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/cli/cli.py&quot;, line 212, in login\n    wandb.login(relogin=relogin, key=key, anonymous=anon_mode, host=host, force=True)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/sdk/wandb_login.py&quot;, line 29, in login\n    anonymous=anonymous, key=key, relogin=relogin, host=host, force=force\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/sdk/wandb_login.py&quot;, line 128, in _login\n    apikey.write_key(settings, key)\n  File &quot;/media/adeel/Space/AI/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/wandb/lib/apikey.py&quot;, line 223, in write_key\n    raise ValueError(&quot;API key must be 40 characters long, yours was %s&quot; % len(key))\nValueError: API key must be 40 characters long, yours was 26\n</code></pre>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2020-09-27 22:41:51.380000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2022-08-30 08:58:42.333000 UTC",
		"Question_score": 4,
		"Question_tags": "python|wandb",
		"Question_view_count": 6277,
		"Owner_creation_date": "2015-10-28 00:01:57.173000 UTC",
		"Owner_last_access_date": "2022-09-24 01:20:28.387000 UTC",
		"Owner_location": "Sydney, New South Wales, Australia",
		"Owner_reputation": 689,
		"Owner_up_votes": 57,
		"Owner_down_votes": 0,
		"Owner_views": 87,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71227518,
		"Question_title": "Connecting Julia to Weights & Biases over Python",
		"Question_body": "<p>I am trying to use weights&amp;biases for my models written in Julia. I am using <code>WeightsAndBiasLogger.jl</code> and try to test their demo code:</p>\n<pre><code>using Logging, WeightsAndBiasLogger\n\nargs = (n_epochs=1_000, lr=1e-3)\nlogger = WBLogger(project=&quot;sample-project&quot;)\nconfig!(logger, args)\n\nwith(logger) do\n    loss = 0\n    for i in 1:args.n_epochs\n        loss += randn() * args.lr\n        @info &quot;train&quot; i=i loss=loss\n    end\nend\n</code></pre>\n<p>I receive an error: <strong>&quot;ArgumentError: ref of NULL PyObject&quot;</strong> (considering the line: logger = WBLogger(project=&quot;sample-project&quot;)\n)</p>\n<p>Then I tried to fix this with the following command:</p>\n<pre><code>using Logging, WeightsAndBiasLogger, PyCall\n\nargs = (n_epochs=1_000, lr=1e-3)\n\nconst logger = PyNULL()\nfunction __init__()\n    copy!(logger, WBLogger(project=&quot;sample-project&quot;))\nend\n\nconfig!(logger, args)\n\nwith(logger) do\n    loss = 0\n    for i in 1:args.n_epochs\n        loss += randn() * args.lr\n        @info &quot;train&quot; i=i loss=loss\n    end\nend\n</code></pre>\n<p>It creates the <code>logger</code> object, but now the error is:</p>\n<p><strong>MethodError: no method matching config!(::PyObject, ::NamedTuple{(:n_epochs, :lr), Tuple{Int64, Float64}})\nClosest candidates are: config!(!Matched::WBLogger, ::Any; kwargs...)</strong> (this consider the line: config!()...</p>\n<p>So, does anyone know how to solve the issue? Obviously, I am new to Julia, thus I apologize if asking something very stupid. In addition, if you know a better solution to integrate Julia into W&amp;B or any good alternatives, I would be glad to hear it.</p>\n<p>PS: Julia ver 1.7.2</p>",
		"Question_answer_count": 0,
		"Question_comment_count": 2,
		"Question_creation_date": "2022-02-22 19:53:40.073000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 2,
		"Question_tags": "python|julia|pycall|wandb",
		"Question_view_count": 102,
		"Owner_creation_date": "2018-09-03 01:38:16.457000 UTC",
		"Owner_last_access_date": "2022-09-24 20:59:24.283000 UTC",
		"Owner_location": "Roskilde, Denmark",
		"Owner_reputation": 1443,
		"Owner_up_votes": 339,
		"Owner_down_votes": 26,
		"Owner_views": 122,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 72079835,
		"Question_title": "Pytorch lightning callback for switching dataloader_idx",
		"Question_body": "<p>Is there a callback or something similar used when incrementing the dataloader index? The reason is that I have defined multiple dataloaders and I would like to start a new run with weight and biases for each dataloader.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-05-01 19:32:08.283000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "pytorch-lightning|wandb",
		"Question_view_count": 146,
		"Owner_creation_date": "2021-01-01 15:57:22.837000 UTC",
		"Owner_last_access_date": "2022-09-24 21:04:49.570000 UTC",
		"Owner_location": null,
		"Owner_reputation": 2789,
		"Owner_up_votes": 102,
		"Owner_down_votes": 1,
		"Owner_views": 304,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 73165796,
		"Question_title": "Wandb first run start time is delayed",
		"Question_body": "<p>I wanted to compare the execution speeds of three data types. The runs were organized in sequence of <code>Original</code>, <code>DictList</code>, <code>DataFrame</code>. So <code>Original</code> was the first run. The x-axis is set as <code>Relative Time (Process)</code></p>\n<p>Problem is that each runs starting time is all different! How can I make sure that they all start at time 0?</p>\n<p><a href=\"https://i.stack.imgur.com/PotUf.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PotUf.png\" alt=\"Loss Graph\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/rwBf4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rwBf4.png\" alt=\"Elapsed Steps Graph\" /></a></p>\n<p>I can't post the entire code. I'll post every point where <code>wandb</code> API is called.</p>\n<pre><code>import wandb\nif __name__ == &quot;__main__&quot;:\n    wandb.login()\n    datatypes = {&quot;Original&quot;: Original, &quot;DictList&quot;: DictList, &quot;DataFrame&quot;: DataFrame}\n    for type_name, datatype in datatypes.items():\n        wandb_run = wandb.init(project=&quot;Compare&quot;, name=type_name, reinit=True)\n        with wandb_run:\n            # Initialize RL training session\n            storage = datatype()\n            # Run RL training session\n            # Log (loss, elapsed_steps, etc.)    \n</code></pre>",
		"Question_answer_count": 0,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-07-29 11:12:40.443000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "pytorch|wandb",
		"Question_view_count": 13,
		"Owner_creation_date": "2017-08-16 10:35:04.843000 UTC",
		"Owner_last_access_date": "2022-09-25 02:02:10.100000 UTC",
		"Owner_location": "South Korea",
		"Owner_reputation": 1248,
		"Owner_up_votes": 800,
		"Owner_down_votes": 23,
		"Owner_views": 221,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 67495547,
		"Question_title": "wandb logging PermissionError and OSError",
		"Question_body": "<p>Description:</p>\n<ul>\n<li><p>When running experiments using <code>Weights and Biases</code> (wandb), I\noccasionally get a <code>PermissionError</code> for Python's <code>logging</code> library\nand <code>OSError</code> for accessing the TLS CA cert.</p>\n</li>\n<li><p>I had the following stacktrace, repeated many times with different\ntypes of &quot;message&quot;. I can't discern the order of operations, but I'm\nguessing the cert can't be accessed and that causes the script to\ncrash, but I don't know why it only happens sometimes.</p>\n</li>\n<li><p>If it is relevant, I ran the experiments on an Ubuntu server, authenticated via Kerberos.</p>\n</li>\n</ul>\n<p>What I've tried:</p>\n<ul>\n<li>I have manually checked the CA cert, and more than half the time I can successfully run experiments. As such I don't think it's the same as <a href=\"https://stackoverflow.com/questions/49100986/certbot-could-not-find-a-suitable-tls-ca-certificate-bundle-archlinux\">this</a> or <a href=\"https://stackoverflow.com/questions/46119901/python-requests-cant-find-a-folder-with-a-certificate-when-converted-to-exe\">this</a>.</li>\n</ul>\n<p>Stacktrace</p>\n<pre><code>Message: 'handle_request: stop_status'                                                                                                                                      [854/1967]Arguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/logging/__init__.py&quot;, line 1085, in emit\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/logging/__init__.py&quot;, line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/threading.py&quot;, line 890, in _bootstrap\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/threading.py&quot;, line 932, in _bootstrap_inner\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 54, in run\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 95, in _run\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py&quot;, line 280, in _process\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py&quot;, line 175, in send\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py&quot;, line 183, in send_request\nMessage: 'send_request: stop_status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/apis/normalize.py&quot;, line 24, in wrapper\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py&quot;, line 681, in check_stop_requested\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 102, in __call__\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py&quot;, line 127, in execute\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py&quot;, line 52, in execute\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py&quot;, line 60, in _get_result\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py&quot;, line 38, in execute\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/api.py&quot;, line 119, in post\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/api.py&quot;, line 61, in request\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/sessions.py&quot;, line 530, in request\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/sessions.py&quot;, line 643, in send\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/adapters.py&quot;, line 416, in send\n  File &quot;/home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/requests/adapters.py&quot;, line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /home/some_user/miniconda3/envs/part_ii_dev-conda/lib/python3.8/site-packages/certifi/cacert.pem\n</code></pre>",
		"Question_answer_count": 0,
		"Question_comment_count": 4,
		"Question_creation_date": "2021-05-11 23:32:27.520000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python-requests|ssl-certificate|kerberos|wandb",
		"Question_view_count": 468,
		"Owner_creation_date": "2018-02-19 09:03:52.163000 UTC",
		"Owner_last_access_date": "2022-09-20 11:32:24.740000 UTC",
		"Owner_location": null,
		"Owner_reputation": 496,
		"Owner_up_votes": 47,
		"Owner_down_votes": 5,
		"Owner_views": 16,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 68952727,
		"Question_title": "wandb: get a list of all artifact collections and all aliases of those artifacts",
		"Question_body": "<p>The wandb documentation doesn't seem to explain how to do this - but it should be a fairly common use case I'd imagine?</p>\n<p>I achieved mostly (but not completely) what I wanted like this, but it seems a bit clunky? I'd have expected to have an <code>self.aliases</code> property on the <code>ArtifactCollection</code> instances?</p>\n<pre class=\"lang-py prettyprint-override\"><code>ENTITY = os.environ.get(&quot;WANDB_ENTITY&quot;)\nAPI_KEY = os.environ.get(&quot;WANDB_API_KEY&quot;)\n\ndef get_model_artifacts(key=None):\n    wandb.login(key=key if key is not None else API_KEY)\n    api = wandb.Api(overrides={&quot;entity&quot;: ENTITY})\n    model_names = [\n        i\n        for i in api.artifact_type(\n            type_name=&quot;models&quot;, project=&quot;train&quot;\n        ).collections()\n    ]\n    for model in model_names:\n        artifact = api.artifact(&quot;train/&quot; + model.name + &quot;:latest&quot;)\n        model._attrs.update(artifact._attrs)\n        model._attrs[&quot;metadata&quot;] = json.loads(model._attrs[&quot;metadata&quot;])\n        model.aliases = [x[&quot;alias&quot;] for x in model._attrs[&quot;aliases&quot;]]\n    return model_names\n</code></pre>\n<p>I guess I could possibly look into writing a custom graph-ql query if needed or just use this clunky method.</p>\n<p>Am I missing something? Is there a cleaner way to do this?</p>\n<p>The one thing this clunky method is missing is any old aliases - it only shows the latest model and then any aliases of that (let's say &quot;latest&quot; and also &quot;v4&quot; etc.) - not sure how this would/should be displayed but I'd have hoped to be able to get old aliases as well (i.e. aliases that point to old versions of the artifact). Although, this is less important.</p>\n<p><strong>EDIT</strong> - after a few hours looking through their sdk code, I have this (still not that happy with how clunky it is):</p>\n<pre class=\"lang-py prettyprint-override\"><code>ENTITY = os.environ.get(&quot;WANDB_ENTITY&quot;)\nAPI_KEY = os.environ.get(&quot;WANDB_API_KEY&quot;)\n\ndef get_model_artifacts(key=None):\n    wandb.login(key=key if key is not None else API_KEY)\n    api = wandb.Api(overrides={&quot;entity&quot;: ENTITY})\n    model_artifacts = [\n        a\n        for a in api.artifact_type(\n            type_name=&quot;models&quot;, project=&quot;train&quot;\n        ).collections()\n    ]\n\n    def get_alias_tuple(artifact_version):\n        version = None\n        aliases = []\n        for a in artifact_version._attrs[&quot;aliases&quot;]:\n            if re.match(r&quot;^v\\d+$&quot;, a[&quot;alias&quot;]):\n                version = a[&quot;alias&quot;]\n            else:\n                aliases.append(a[&quot;alias&quot;])\n        return version, aliases\n\n    for model in model_artifacts:\n        # artifact = api.artifact(&quot;train/&quot; + model.name + &quot;:latest&quot;)\n        # model._attrs.update(artifact._attrs)\n        # model._attrs[&quot;metadata&quot;] = json.loads(model._attrs[&quot;metadata&quot;])\n        versions = model.versions()\n        version_dict = dict(get_alias_tuple(version) for version in versions)\n        model.version_dict = version_dict\n        model.aliases = [\n            x for key, val in model.version_dict.items() for x in [key] + val\n        ]\n    return model_artifacts\n</code></pre>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-08-27 11:34:22.593000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2021-08-30 21:05:43.657000 UTC",
		"Question_score": 1,
		"Question_tags": "python|wandb",
		"Question_view_count": 363,
		"Owner_creation_date": "2018-05-15 07:21:25.180000 UTC",
		"Owner_last_access_date": "2022-09-23 17:35:59.473000 UTC",
		"Owner_location": "Munich, Germany",
		"Owner_reputation": 3944,
		"Owner_up_votes": 574,
		"Owner_down_votes": 47,
		"Owner_views": 217,
		"Answer_body": "<p>I'm Annirudh. I'm an engineer at W&amp;B who helped build artifacts. Your solution is really close, but by using the <code>latest</code> alias when fetching the artifact we're only going to be considering the aliases from that one artifact instead of all the versions. You could get around that by looping over the versions:</p>\n<pre><code>api = wandb.Api()\ncollections = [\n    coll for coll in api.artifact_type(type_name=TYPE, project=PROJECT).collections()\n]\n\n\naliases = set()\nfor coll in collections:\n    for artifact in coll.versions():\n        aliases.update(artifact.aliases)\n\nprint(collections)\nprint(aliases)\n</code></pre>\n<p>Currently, the documentation is spare on collections but we're polishing them up in the public API and will release some docs around it shortly. These APIs aren't quite release ready yet -- so apologies for the rough edges.</p>\n<p>Please feel free to reach out to me directly in the future if you have any other questions regarding artifacts. Always happy to help.</p>",
		"Answer_comment_count": 14.0,
		"Answer_creation_date": "2021-08-28 03:42:13.813000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 2.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 68504577,
		"Question_title": "wandb.wandb_agent - ERROR - Detected 5 failed runs in a row, shutting down",
		"Question_body": "<p>While trying to setup <a href=\"https://wandb.ai/home\" rel=\"nofollow noreferrer\">wandb</a>, I am facing the following error:</p>\n<pre><code>wandb: WARNING Calling wandb.login() after wandb.init() has no effect.                                                                                                            \n2021-07-23 19:19:32,639 - wandb.wandb_agent - INFO - Running runs: []                                                                                                             \n2021-07-23 19:19:32,824 - wandb.wandb_agent - INFO - Agent received command: run                                                                                                  \n2021-07-23 19:19:32,825 - wandb.wandb_agent - INFO - Agent starting run with config:                                                                                              \n        lr: 0.01                                                                                                                                                                  \n        optimizer: Adam                                                                                                                                                           \n2021-07-23 19:19:32,826 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python  --lr=0.01 --optimizer=Adam                                                        \n/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python: can't find '__main__' module in ''                                                                                     \n2021-07-23 19:19:37,945 - wandb.wandb_agent - INFO - Running runs: ['e8ff7j11']                                                                                                   \n2021-07-23 19:19:37,946 - wandb.wandb_agent - INFO - Cleaning up finished run: e8ff7j11\n\n------4 more runs for different hyperparamters-------\n\n2021-07-23 19:19:59,139 - wandb.wandb_agent - ERROR - Detected 5 failed runs in a row, shutting down.\n2021-07-23 19:19:59,139 - wandb.wandb_agent - INFO - To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val\nwandb: Terminating and syncing runs. Press ctrl-c to kill.\n\n</code></pre>\n<p>Code:</p>\n<p><code>base_config.py</code></p>\n<pre><code>class base_config:\n    def __init__(self):\n        self.epochs = 10\n        self.sweep_config = {\n            'method': 'grid',\n            'metric': {\n              'name': 'val_F1@M',\n              'goal': 'maximize'  \n            },\n            'parameters': {\n                'lr': {\n                    'values': [1e-2, 1e-3, 1e-4]\n                },\n                'optimizer': {\n                    'values': ['Adam', 'SM3']\n                },\n            }\n        }\n        self.config_defaults = {\n            'lr': 1e-2,\n            'optimizer': 'Adam',\n        }\n</code></pre>\n<p><code>train.py</code></p>\n<pre><code>import wandb\ndef run(args, config):\n    # wandb.log()\n\ndef run_and_collect_results(args, config):\n    wandb.init(config=config['config_defaults'])\n    config.update({k: v for k, v in wandb.config.items()})\n    run(args, config)\n\nif __name__ == '__main__':\n    # load config from config file\n    # load args\n    sweep_id = wandb.sweep(config['sweep_config'], project=&quot;Pytorch-sweeps&quot;)\n    wandb.agent(sweep_id, run_and_collect_results(args, config))\n</code></pre>\n<p>I am not sure what is the correct way to write the <code>agent</code> for <code>wandb</code>. The current code ends up with logs like <code>python  --lr=0.01 --optimizer=Adam </code>. The file name seems missing. In that case, would I need to write <code>wandb.agent</code> in a separate file or use CLI interface? I was expecting the behavior that <code>wandb.agent</code> would call function <code>run_and_collect_results</code> for different hyperaparameters.</p>",
		"Question_answer_count": 2,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-07-23 20:09:18.300000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 1,
		"Question_tags": "python|hyperparameters|wandb",
		"Question_view_count": 895,
		"Owner_creation_date": "2014-02-13 12:57:24.357000 UTC",
		"Owner_last_access_date": "2022-09-24 20:22:35.010000 UTC",
		"Owner_location": "Chicago, IL, USA",
		"Owner_reputation": 1020,
		"Owner_up_votes": 278,
		"Owner_down_votes": 17,
		"Owner_views": 206,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71106179,
		"Question_title": "Log two model runs with Keras wandb",
		"Question_body": "<p>I am training multiple models in the same Colab notebook to compare some results. I've written a function to avoid repeating code, and I've added WandbCallback() in the list of callbacks for model_name.fit().</p>\n<pre class=\"lang-py prettyprint-override\"><code>def generic_FE_trainer(model_name, checkpoint_filename, min_lr=1e-7):\n    earlystop = callbacks.EarlyStopping(monitor=&quot;val_loss&quot;,\n                                    patience=11, \n                                    verbose=1)\n    lr_reduction = callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n                                           patience=5, \n                                           verbose=1, \n                                           factor=0.8, \n                                           min_lr=min_lr)\n    checkpoint_dir = os.path.join(save_dir, checkpoint_filename)\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n    checkpoint = callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_dir, checkpoint_filename+'.h5'), \n                                           monitor=&quot;val_loss&quot;,\n                                           verbose=1,\n                                           save_best_only=True,\n                                           save_weights_only=False)\n    return model_name.fit(train_gen, \n                          epochs=40,\n                          batch_size=4,\n                          verbose=1,\n                          callbacks=[earlystop, checkpoint, lr_reduction, WandbCallback()],\n                          validation_data=val_gen)\n</code></pre>\n<p>I call them with something like the code below, but then my project dashboard puts the data for both on the same graphs, where I've attached a graph for epochs (although it's not particularly useful) to show as an example.</p>\n<pre><code>history1 = generic_FE_trainer(model1, 'model1')\nhistory2 = generic_FE_trainer(model2, 'model2')\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/WnPbz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WnPbz.png\" alt=\"wandb epochs\" /></a></p>\n<p>This is the same for all my metrics, so how can I have wandb plot these graphs separately? I would like them to be in different runs, if that's possible.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-02-14 01:03:40.883000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2022-02-14 02:45:22.730000 UTC",
		"Question_score": 0,
		"Question_tags": "python|machine-learning|keras|wandb",
		"Question_view_count": 232,
		"Owner_creation_date": "2019-05-19 03:48:33.157000 UTC",
		"Owner_last_access_date": "2022-09-23 15:43:15.227000 UTC",
		"Owner_location": null,
		"Owner_reputation": 421,
		"Owner_up_votes": 20,
		"Owner_down_votes": 5,
		"Owner_views": 33,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 70644326,
		"Question_title": "wandb.plot.line does not work and it just shows a table",
		"Question_body": "<p>I used this example that was provided by WandB. However, the web interface just shows a table instead of a figure.</p>\n<pre><code>data = [[i, random.random() + math.sin(i / 10)] for i in range(100)]\n        table = wandb.Table(data=data, columns=[&quot;step&quot;, &quot;height&quot;])\n        wandb.log({'line-plot1': wandb.plot.line(table, &quot;step&quot;, &quot;height&quot;)})\n</code></pre>\n<p>This is a screenshot from WandB's web interface:\n<a href=\"https://i.stack.imgur.com/INmPU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/INmPU.png\" alt=\"enter image description here\" /></a></p>\n<p>Also, I have the same problem with other kinds of figures and charts that use a table.</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-01-09 18:36:40.317000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|deep-learning|pytorch|wandb",
		"Question_view_count": 184,
		"Owner_creation_date": "2015-10-24 20:44:04.550000 UTC",
		"Owner_last_access_date": "2022-09-24 23:10:59.603000 UTC",
		"Owner_location": "Iran, Canada",
		"Owner_reputation": 331,
		"Owner_up_votes": 113,
		"Owner_down_votes": 3,
		"Owner_views": 40,
		"Answer_body": "<blockquote>\n<p>X-Post from the wandb forum</p>\n</blockquote>\n<p><a href=\"https://community.wandb.ai/t/wandb-plot-confusion-matrix-just-show-a-table/1744\" rel=\"nofollow noreferrer\">https://community.wandb.ai/t/wandb-plot-confusion-matrix-just-show-a-table/1744</a></p>\n<p>If you click the section called \u201cCustom Charts\u201d above the Table, it\u2019ll show the line plot that you\u2019ve logged.</p>\n<p>Logging the Table also is expected behaviour, because this will allow users to interactively explore the logged data in a W&amp;B Table after logging it.</p>",
		"Answer_comment_count": 0.0,
		"Answer_creation_date": "2022-01-10 10:14:57.277000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 0.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71223654,
		"Question_title": "How to get wandb to pass arguments by position?",
		"Question_body": "<p>I am trying to explore the results of different parameter settings on my python script &quot;train.py&quot;. For that, I use a wandb sweep. Each wandb agent executes the file &quot;train.py&quot; and passes some parameters to it. As per the wandb documentation (<a href=\"https://docs.wandb.ai/guides/sweeps/configuration#command\" rel=\"nofollow noreferrer\">https://docs.wandb.ai/guides/sweeps/configuration#command</a>), in case of e.g. two parameters &quot;param1&quot; and &quot;param2&quot; each agents starts the file with the command</p>\n<pre><code>/usr/bin/env python train.py --param1=value1 --param2=value2\n</code></pre>\n<p>However, &quot;train.py&quot; expects</p>\n<pre><code>/usr/bin/env python train.py value1 value2\n</code></pre>\n<p>and parses the parameter values by position. I did not write train.py and would like to not change it if possible. How can I get wandb to pass the values without &quot;--param1=&quot; in front?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-02-22 15:07:04.610000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|python-3.x|wandb",
		"Question_view_count": 270,
		"Owner_creation_date": "2015-08-24 11:16:20.200000 UTC",
		"Owner_last_access_date": "2022-02-23 15:36:22.560000 UTC",
		"Owner_location": "Germany",
		"Owner_reputation": 5,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 12,
		"Answer_body": "<p>Don't think you can get positional arguments from W&amp;B Sweeps. However, there's a little work around you can try that won't require you touching the <code>train.py</code> file.</p>\n<p>You can create an invoker file, let's call it <code>invoke.py</code>. Now, you can use it get rid of the keyword argument names. Something like this might work:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport subprocess\n\nif len(sys.argv[0]) &lt;= 1:\n  print(f&quot;{sys.argv[0]} program_name param0=&lt;param0&gt; param1=&lt;param1&gt; ...&quot;)\n  sys.exit(0)\n\nprogram = sys.argv[1]\nparams = sys.argv[2:]\n\nposparam = []\nfor param in params:\n  _, val = param.split(&quot;=&quot;)\n  posparam.append(val)\n\ncommand = [sys.executable, program, *posparam]\nprocess = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\nout, err = process.communicate()\nsys.stdout.write(out.decode())\nsys.stdout.flush()\nsys.stderr.write(err.decode())\nsys.stderr.flush()\nsys.exit(process.returncode)\n</code></pre>\n<p>This allows you to invoke your <code>train.py</code> file as follows:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ python3 invoke.py /path/to/train.py param0=0.001 param1=20 ...\n</code></pre>\n<p>Now to perform W&amp;B sweeps you can create a <code>command:</code> section (<a href=\"https://docs.wandb.ai/guides/sweeps/configuration#command\" rel=\"nofollow noreferrer\">reference</a>) in your <code>sweeps.yaml</code> file while sweeping over the parameters <code>param0</code> and <code>param1</code>. For example:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>program: invoke.py\n...\nparameters:\n  param0:\n    distribution: uniform\n    min: 0\n    max: 1\n  param1:\n    distribution: categorical\n    values: [10, 20, 30]\ncommand:\n - ${env}\n - ${program}\n - /path/to/train.py\n - ${args_no_hyphens}\n</code></pre>",
		"Answer_comment_count": 3.0,
		"Answer_creation_date": "2022-02-22 16:51:46.457000 UTC",
		"Answer_last_edit_date": "2022-02-22 16:56:56.653000 UTC",
		"Answer_score": 1.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 69425994,
		"Question_title": "is there any way to scale axis of plots in wandb?",
		"Question_body": "<p>I am working with weight and bias(wandb).<br />\nHowever, it logs by step. And that makes plot disturbing when comparing runs.<br />\nFor example, I have a run A and run B(assume that they run with same dataset).<br />\nrun A: 30epochs, 4 batch, 200step/epoch<br />\nrun B: 30epochs, 8 batch, 100step/epoch</p>\n<p>then, the plot of run A gets longer(double, in this case) in axis x when it shows with run B.</p>\n<p>How can I scale x axis depend to runs AFTER training?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2021-10-03 14:53:08.153000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 1,
		"Question_tags": "wandb",
		"Question_view_count": 604,
		"Owner_creation_date": "2020-10-22 15:00:31.587000 UTC",
		"Owner_last_access_date": "2022-09-19 00:28:34.893000 UTC",
		"Owner_location": null,
		"Owner_reputation": 161,
		"Owner_up_votes": 10,
		"Owner_down_votes": 0,
		"Owner_views": 29,
		"Answer_body": "<p>You can change the x-axis used via the chart settings by clicking on the pencil icon and then selecting a different x-axis. E.g. in your case you could select &quot;epoch&quot; instead of &quot;steps&quot;. Just make sure to log &quot;epoch&quot; to your charts, something like:</p>\n<pre><code>steps_per_epoch = n_samples / batch_size\nepoch = current_step / steps_per_epoch\nwandb.log({&quot;epoch&quot;:epoch, ...})\n</code></pre>",
		"Answer_comment_count": 0.0,
		"Answer_creation_date": "2021-10-04 11:02:55.677000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 4.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 73373004,
		"Question_title": "is there any symbols forbidden in run_id?",
		"Question_body": "<p>I just started working with wandb. I am curious if there is any requirement in the format of the run_id (e.g. cannot contain brackets '[]' or '()')</p>\n<p>the reason why I am asking is that I cannot log my runs (image data) properly after adding a '[..]' prefix to my run_id. There is no modification in the code which could lead to this problem and the wandb version remain the same.</p>\n<p>Would be great if anyone could gives some clue in this.</p>\n<p>Many thanks</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-08-16 11:08:11.100000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "wandb",
		"Question_view_count": 25,
		"Owner_creation_date": "2022-08-16 11:02:23.310000 UTC",
		"Owner_last_access_date": "2022-09-22 10:35:05.063000 UTC",
		"Owner_location": null,
		"Owner_reputation": 1,
		"Owner_up_votes": 0,
		"Owner_down_votes": 0,
		"Owner_views": 0,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 71432453,
		"Question_title": "getting aligned val_loss and train_loss plots for each epoch using WandB rather than separate plots",
		"Question_body": "<p>I have the following code for logging the train and val loss in each epoch using WandB API. I am not sure though why I am not getting val loss and train loss in the same epoch. Any idea how that could be fixed?</p>\n<pre><code>wandb.log({&quot;train loss&quot;: train_epoch_loss,\n           &quot;val loss&quot;: val_epoch_loss,\n           &quot;epoch&quot;: epoch})\n\nwandb.log({&quot;train acc&quot;: train_epoch_acc,\n           &quot;val acc&quot;: val_epoch_acc,\n           &quot;epoch&quot;: epoch})\n\nwandb.log({&quot;best val acc&quot;: best_acc, &quot;epoch&quot;: epoch})\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/w6JBF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/w6JBF.png\" alt=\"enter image description here\" /></a></p>\n<p>As you see, val loss vs epochs and train loss vs epochs are two completely separate entities while I would like to have both of them in one plot in WandB.\n<a href=\"https://i.stack.imgur.com/cqSkl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cqSkl.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/ZSMye.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZSMye.png\" alt=\"enter image description here\" /></a></p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-03-11 00:46:51.130000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": null,
		"Question_score": 0,
		"Question_tags": "python|machine-learning|deep-learning|wandb",
		"Question_view_count": 463,
		"Owner_creation_date": "2013-05-23 18:56:17.410000 UTC",
		"Owner_last_access_date": "2022-06-28 18:22:36.490000 UTC",
		"Owner_location": "Boston, MA, United States",
		"Owner_reputation": 31183,
		"Owner_up_votes": 4284,
		"Owner_down_votes": 32,
		"Owner_views": 18708,
		"Answer_body": null,
		"Answer_comment_count": null,
		"Answer_creation_date": null,
		"Answer_last_edit_date": null,
		"Answer_score": null,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	},
	{
		"Question_id": 73244442,
		"Question_title": "HuggingFace Trainer() cannot report to wandb",
		"Question_body": "<p>I am trying to set trainer with arguments <code>report_to</code> to <code>wandb</code>, refer to <a href=\"https://docs.wandb.ai/guides/integrations/huggingface#getting-started-track-experiments\" rel=\"nofollow noreferrer\">this docs</a>\nwith config:</p>\n<pre><code>training_args = TrainingArguments(\n    output_dir=&quot;test_trainer&quot;,\n    evaluation_strategy=&quot;steps&quot;,\n    learning_rate=config.learning_rate,\n    num_train_epochs=config.epochs,\n    weight_decay=config.weight_decay,\n    logging_dir=config.logging_dir,\n    report_to=&quot;wandb&quot;,\n    save_total_limit=1,\n    per_device_train_batch_size=config.batch_size,\n    per_device_eval_batch_size=config.batch_size,\n    fp16=True,\n    load_best_model_at_end=True,\n    seed=42\n)\n</code></pre>\n<p>yet when I set trainer with:</p>\n<pre><code>trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics\n)\n</code></pre>\n<p>it shows:</p>\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-68-b009351ab52d&gt; in &lt;module&gt;\n      4     train_dataset=train_dataset,\n      5     eval_dataset=eval_dataset,\n----&gt; 6     compute_metrics=compute_metrics\n      7 )\n\n~/.virtualenvs/transformers_lab/lib/python3.7/site-packages/transformers/trainer.py in __init__(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\n    286                 &quot;You should subclass `Trainer` and override the `create_optimizer_and_scheduler` method.&quot;\n    287             )\n--&gt; 288         default_callbacks = DEFAULT_CALLBACKS + get_reporting_integration_callbacks(self.args.report_to)\n    289         callbacks = default_callbacks if callbacks is None else default_callbacks + callbacks\n    290         self.callback_handler = CallbackHandler(\n\n~/.virtualenvs/transformers_lab/lib/python3.7/site-packages/transformers/integrations.py in get_reporting_integration_callbacks(report_to)\n    794         if integration not in INTEGRATION_TO_CALLBACK:\n    795             raise ValueError(\n--&gt; 796                 f&quot;{integration} is not supported, only {', '.join(INTEGRATION_TO_CALLBACK.keys())} are supported.&quot;\n    797             )\n    798     return [INTEGRATION_TO_CALLBACK[integration] for integration in report_to]\n\nValueError: w is not supported, only azure_ml, comet_ml, mlflow, tensorboard, wandb are supported.\n</code></pre>\n<p>Have anyone got same error before?</p>",
		"Question_answer_count": 1,
		"Question_comment_count": 0,
		"Question_creation_date": "2022-08-05 03:48:25.703000 UTC",
		"Question_favorite_count": null,
		"Question_last_edit_date": "2022-08-09 08:29:23.877000 UTC",
		"Question_score": 0,
		"Question_tags": "python|huggingface-transformers|wandb",
		"Question_view_count": 47,
		"Owner_creation_date": "2020-04-18 05:07:48.850000 UTC",
		"Owner_last_access_date": "2022-09-23 07:29:12.847000 UTC",
		"Owner_location": "Taipei, Taiwan R.O.C",
		"Owner_reputation": 163,
		"Owner_up_votes": 13,
		"Owner_down_votes": 0,
		"Owner_views": 15,
		"Answer_body": "<p>Although the documentation states that the <code>report_to</code> parameter can receive both <code>List[str]</code> or <code>str</code> I have always used a list with 1! element for this purpose.</p>\n<p>Therefore, even if you report only to wandb, the solution to your problem is to replace:</p>\n<pre><code> report_to = 'wandb'\n</code></pre>\n<p>with</p>\n<pre><code>report_to = [&quot;wandb&quot;]\n</code></pre>",
		"Answer_comment_count": 2.0,
		"Answer_creation_date": "2022-08-06 10:28:14.627000 UTC",
		"Answer_last_edit_date": null,
		"Answer_score": 1.0,
		"Question_valid_tags": "wandb",
		"id": null,
		"taxonomy": null,
		"annotator": null,
		"annotation_id": null,
		"created_at": null,
		"updated_at": null,
		"lead_time": null
	}
]