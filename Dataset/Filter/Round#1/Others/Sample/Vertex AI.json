[
	{
		"Question_title": "Being told to contact Vertex AI support but we don't have a support contract?!",
		"Question_creation_date": "2022-03-08T11:34:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Being-told-to-contact-Vertex-AI-support-but-we-don-t-have-a/td-p/401449/jump-to/first-unread-message",
		"Question_topic": [
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 51,
		"Question_body": "Getting an internal error when training a model on Vertex AI.I have gotten repeated emails from Google telling me to contact Vertex AI support about this.We don't pay for a support contract.It seems odd that there is no way to report issues like this to Vertex AI without a support contract.",
		"Answers": [
			{
				"Answer_creation_date": "2022-03-08T11:34:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Getting an internal error when training a model on Vertex AI.\n\nI have gotten repeated emails from Google telling me to contact Vertex AI support about this.\n\nWe don't pay for a support contract.\n\nIt seems odd that there is no way to report issues like this to Vertex AI without a support contract."
			}
		]
	},
	{
		"Question_title": "Imbalance DataSet for Tabular AutoML",
		"Question_creation_date": "2022-04-18T10:26:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Imbalance-DataSet-for-Tabular-AutoML/td-p/414630/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform",
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 3,
		"Question_upvote_count": 0,
		"Question_view_count": 182,
		"Question_body": "Hi, I would like to know if in case of having a tabular database,  with binary data (class 0 and Class 1), that has an imbalance between class 0 and class 1, as it occurs in scenarios of fraud in financial transactions.Does AutoML solves automatically the imbalance situation? Or is it possible to add SMOTE or ADASYN to the AutoML model?  Any comments to advice more than appreciated",
		"Answers": [
			{
				"Answer_creation_date": "2022-04-21T09:42:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "There are several ways of handling imbalanced datasets:\n\nUpsampling and/or Downsampling: In case of Upsampling, instances from the minority classes are duplicated in the training dataset at random. In case of Downsampling, certain instances of the majority classes are randomly left out of the training dataset. Upsampling of minority class and downsampling of the majority class can be done at the same time.\n\n\nUpweighting and/or Downweighting: In Upweighting, sample weight greater than 1 is given to instances from the minority classes. In case of Downweighting, sample weight less than 1 is given to instances from the majority classes. The sample weights are taken into account when computing the loss function. Upweighting and Downweighting can be used together.\n\n\nData Augmentation: In this approach, data augmentation techniques are used to generate synthetic instances of the minority class to better balance the training dataset."
			},
			{
				"Answer_creation_date": "2022-05-02T06:46:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Jos\u00e9 hi, thanks for your answer but is not very clear.....\n\nThe question is if I can upload a data set with imbalance situation to AutoML or I need to fix somehow the situation before uploading the data into AutoML or AutoML can handle in very good way Imbalance data sets?"
			},
			{
				"Answer_creation_date": "2022-05-20T04:14:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "I am also interested in the same question."
			}
		]
	},
	{
		"Question_title": "AutoML Features",
		"Question_creation_date": "2022-05-12T12:36:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/AutoML-Features/td-p/422551/jump-to/first-unread-message",
		"Question_topic": [
			"AI Platform",
			"AutoML",
			"Vertex AI Model Registry"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 42,
		"Question_body": "HiAssume that I create a model using AutoML with 50 features from the Vertex AI Feature Store and after training I found that from the 50 original features, 10 has a very low incidence over the model.Looking to increase the accuracy, reduce the consumption of resources and increase the speed of the model:Do I need to remove the 10 features from the Feature Store and deploy the model to the endpoint?Should I retrain the model with the 40 features and deploy it to the end point?Any comments more than appreciated",
		"Answers": [
			{
				"Answer_creation_date": "2022-05-17T08:24:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "I wouldn't delete the features because there are some features that can be used to share, discover, and re-use ML features at scale, which can increase the velocity of developing and deploying new ML applications."
			}
		]
	},
	{
		"Question_title": "Using Vison ML via REST API",
		"Question_creation_date": "2022-07-06T02:03:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Using-Vison-ML-via-REST-API/td-p/438619/jump-to/first-unread-message",
		"Question_topic": [
			"Cloud Vision API"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 2,
		"Question_upvote_count": 0,
		"Question_view_count": 185,
		"Question_body": "I'm taking my first steps with Vision ML and using the REST interface (https://vision.googleapis.com/v1/files:annotate). As API key I provide the key from the Firebase project settings. In the Authorization Bearer, I supply the token from Firebase-Auth after sign-in.When accessing Annotate I get a 403 (Permission_Denied) error message back:\nError opening file: gs://######.appspot.com/MyFile.tiff.The object is available in the corresponding bucket and it is not blocked due to the Firebase Storage rules.Can I pass a Firebase token in this REST interface at all?How do I make sure that the service account can access the storage?\n\nThank you for any hint\n\nAuthor of FB4D GitHub Project (A Delphi Library for access Firebase Services via REST).",
		"Answers": [
			{
				"Answer_creation_date": "2022-07-11T10:07:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "The issue seems to be with the permissions or the Firebase rules that are being used. Could you please share the permissions and Firebase rules that you are using?\u00a0\u00a0\u00a0\n\nHere is document that you can use for the Firebase security rules:\n\nhttps://firebase.google.com/docs/storage/security\u00a0\n\nhttps://stackoverflow.com/questions/38671444/user-does-not-have-permission-to-access-this-object-fir...\n\nHere is another document that you can use for the IAM permissions:\n\nhttps://cloud.google.com/storage/docs/access-control/iam-permissions\u00a0\n\nYou can also use a service account to authenticate to Firebase storage:\n\nhttps://stackoverflow.com/questions/72565059/cloud-api-product-search-asked-for-storing-the-images-i..."
			},
			{
				"Answer_creation_date": "2022-07-12T01:00:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "That was also my first thought, so I have the rule that only a known user can use the storage, removed for all types of readers released.\n\nrules_version = '2';\nservice firebase.storage {\n  match /b/{bucket}/o {\n    match /testML/{img} {\n      allow read: if true; // if request.auth != null;\n      allow write: if request.auth != null;\n    }\n  }\n}\n\nI suppose this rules out your first assumption.\n\nOn the second point, yes, I've also tried giving more privileges to the executing service account. In the Google Cloud Console, I see three other principals in addition to my email address as the owner. Which one is used by the ML vision Service?\n\n<ProjectID>@appspot.gserviceaccount.com\nfirebase-adminsdk-zog2s@<ProjectID>.iam.gserviceaccount.com\nfirebase-service-account@firebase-sa-management.iam.gserviceaccount.com\n\nI have already assigned \"Storage admin\" rights to all these 3 accounts. Unfortunately, this did not solve the problem.\n\nThank you for a further hint."
			}
		]
	},
	{
		"Question_title": "Text-to-Speech",
		"Question_creation_date": "2022-05-25T02:27:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Text-to-Speech/td-p/425961/jump-to/first-unread-message",
		"Question_topic": [
			"Text-to-Speech"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 1,
		"Question_view_count": 56,
		"Question_body": "Hi every one, Google Text-to-Speech seems not to be working again",
		"Answers": [
			{
				"Answer_creation_date": "2022-05-26T06:03:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "That's right.\n\nThe language tab is not clickable"
			}
		]
	},
	{
		"Question_title": "AutoML - pre-trained models?",
		"Question_creation_date": "2021-07-01T12:49:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/AutoML-pre-trained-models/td-p/162864/jump-to/first-unread-message",
		"Question_topic": [
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 1,
		"Question_view_count": 496,
		"Question_body": "I know that for AutoML, the user has to train the model. But are there existing \"pre-trained\" models that you can leverage to identify sentiments or classifications like profanity, irony, and bullying? ",
		"Answers": [
			{
				"Answer_creation_date": "2021-07-01T23:46:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Can you please add more details about the sample text/document that you are trying?. The powerful pre-trained models of the\u00a0Natural Language API\u00a0\u00a0empowers developers to easily apply natural language understanding (NLU) to their applications with features including sentiment analysis, entity analysis, entity sentiment analysis, content classification, and syntax analysis.\n\nSamples: https://cloud.google.com/natural-language/automl/docs/samples"
			}
		]
	},
	{
		"Question_title": "Translate service error - Unsupported language pair",
		"Question_creation_date": "2022-08-25T04:38:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Translate-service-error-Unsupported-language-pair/td-p/459774/jump-to/first-unread-message",
		"Question_topic": [
			"Cloud Translation API"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 13,
		"Question_upvote_count": 3,
		"Question_view_count": 526,
		"Question_body": "Our application started to have some strange error from 25th of August which was working properly until today. Some very basic translation requests get the \"Status(StatusCode=\"InvalidArgument\", Detail=\"Unsupported language pair.\" error. For example the words \"loan\", \"excellent\", \"wonderful\" get the errors from service. I checked the release notes of the service but found nothing. Could you please help about the issue?",
		"Answers": [
			{
				"Answer_creation_date": "2022-08-25T05:20:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We get the same error for order numbers ABC123 for example will return \"Unsupported language pair.\" But\u00a0ABC1234 works, ABC12 works, ABC123 return error, ABC1233 return error."
			},
			{
				"Answer_creation_date": "2022-08-25T23:49:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Our company also has the same problem unfortunately, one of our internal tools basically cannot be used at all since yesterday."
			},
			{
				"Answer_creation_date": "2022-08-26T00:51:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We have a similar problem\n\ncode = InvalidArgument desc = Unsupported language pair."
			},
			{
				"Answer_creation_date": "2022-08-26T06:57:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We are having similar problems with specific language pairs."
			},
			{
				"Answer_creation_date": "2022-08-26T09:45:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We're having this issue since August, 24 at 01:07 AM.\n\nGoogle.GoogleApiException: Google.Apis.Requests.RequestError\nBad language pair: {0} [400]\nErrors [\n    Message[Bad language pair: {0}] Location[ - ] Reason[badRequest] Domain[global]\n]\nat Google.Apis.Requests.ClientServiceRequest`1.ParseResponse(HttpResponseMessage response)\nat Google.Apis.Requests.ClientServiceRequest`1.ExecuteAsync(CancellationToken cancellationToken)\nat Google.Cloud.Translation.V2.TranslationClientImpl.TranslateHtmlAsync(IEnumerable`1 htmlItems, String targetLanguage, String sourceLanguage, Nullable`1 model, CancellationToken cancellationToken)"
			},
			{
				"Answer_creation_date": "2022-08-29T12:37:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Has this been corrected?"
			},
			{
				"Answer_creation_date": "2022-08-29T22:04:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "I believe so, I tested yesterday and had no issues."
			},
			{
				"Answer_creation_date": "2022-09-01T03:19:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "The same error!\n\nExample of translated text: \"\u041c\u0430\u0441\u043b\u043e MITASU 5W30 PLATINUM PAO SN Dexos2 1L\"\n\nTranslation to Romanian from autodetect using NeuralMachineTranslation.\n\nif the word \"PAO\" is removed, it translate ok."
			},
			{
				"Answer_creation_date": "2022-09-07T06:40:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "It has been fixed. Thanks"
			},
			{
				"Answer_creation_date": "2022-09-07T21:17:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Issue still exist for English to Romanian translation. appreciate any thoughts."
			},
			{
				"Answer_creation_date": "2022-09-09T01:47:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Unfortunately we started to get same exception (Unsupported language pair.)\u00a0 with the following inputs while translating to English (en-US) Is there any new deployment to the service? Could you please check?\n\nSome Sample Problematic Inputs :\u00a0\"Ok\" , \"1000\", \"wonderful\""
			},
			{
				"Answer_creation_date": "2022-09-09T12:24:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Unclear if it's related, but a well known Trados plug-in for Google AutoML machine translation engine is also failing with the same error and this is also new.\u00a0 See\u00a0https://community.rws.com/product-groups/trados-portfolio/rws-appstore/f/rws-appstore/43110/mt-enhan....\u00a0 \u00a0This is with V3 Advanced API, but looks like what is reported her is happening with V2 Basic API."
			},
			{
				"Answer_creation_date": "2022-09-13T13:47:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We found a solution for this issue.\n\nFor OpenSay, when we used Cloud Translation's REST API's analyzeText method with an English content and a target language type 'en-US' it failed with \"Unsupported language pair.\".\u00a0\n\nIt took some tinkering, but eventually we changed the 'en-US' to 'en' and it worked."
			}
		]
	},
	{
		"Question_title": "Recommendations AI - catalog update not reflecting in console",
		"Question_creation_date": "2021-11-02T22:58:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Recommendations-AI-catalog-update-not-reflecting-in-console/td-p/174619/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform",
			"Recommendations AI"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 319,
		"Question_body": "In Recommendations AI, I tried uploading the catalog from GCS. On uploading the catalog, I could see the catalog products showing up in the console but there is a warning notification stating the catalog is not integrated and the total product count is always zero.I have tried both recommended methods of uploading the catalog data from GCS directly through the GCP console and also through the CLI but still, this issue persists. I have followed every instruction provided in this GCP documentation but still, I couldn't figure out the actual issue and not much information is available in the public domain as well \n\nCan someone help with this??\nThanks ",
		"Answers": [
			{
				"Answer_creation_date": "2021-11-04T18:30:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hello,\n\nCan you go over the troubleshooting guide\u00a0and see if you can get more details on the issue from the Cloud logging logs or from any API errors there might be?\n\nYou might also try to inspect your browser's log network activity when retrying to upload the catalog with the console method."
			}
		]
	},
	{
		"Question_title": "Manage Labeling Assignments on DataCompute",
		"Question_creation_date": "2021-11-11T20:14:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Manage-Labeling-Assignments-on-DataCompute/td-p/175499/jump-to/first-unread-message",
		"Question_topic": [
			"AI Platform"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 1,
		"Question_view_count": 416,
		"Question_body": "Our team has started to use the DataCompute console to assign labelers to labeling tasks created in Vertex AI. Currently, the Assignments tab requires the Labeling Manager to Populate the Specialists Column and Populate the Tasks Column I wanted to highlight some issues we are facing and ask if there's any plan to implement fixes.Issues: 1. The dropdown for task selection does not order the tasks alphabetically so it is difficult to find a specific task.2. There's no \"Select All\" option, instead, the manager must select each task individually.3. There is no drop down for the specialist emails even though they are available under the Specialists tab.Generally, it would be nice to see the entire assignment table by default rather than nothing on this page.Let me know if some of these issues can be addressed! ",
		"Answers": [
			{
				"Answer_creation_date": "2021-11-25T15:25:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Thank you for your input. Can you provide the reproduction steps so we can update it on this thread\u00a0\nPlease note that such issues are usually submitted and handled by the product teams via Public Issue Tracker. Therefore, I just submitted your request to the Vertex AI product team on\u00a0this thread, and I recommend you to star it as all future updates will occur there."
			}
		]
	},
	{
		"Question_title": "Unable to create model",
		"Question_creation_date": "2022-08-04T02:08:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Unable-to-create-model/td-p/450348/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform",
			"AutoML"
		],
		"Question_has_accepted_answer": true,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 75,
		"Question_body": "I am working on demand forecasting where my timestamp duration is 15 minutes and i have attached sample output to below documents.The issue i am facing is despite setting DATA_FREQUENCY = [AUTO_FREQUENCY].ii am getting the error \"Invalid time series: the finest data frequency supported is PER_MINUTE. All input time intervals must be at least one minute\" and the query for create model is given below  ",
		"Answers": [
			{
				"Answer_creation_date": "2022-08-08T15:48:00",
				"Answer_accepted": true,
				"Answer_upvote_count": 0,
				"Answer_body": "What is happening is that using \u201cAUTO_FREQUENCY\u201d is trying to send the Information as \u201cPER_MINUTE\u201d because of your data, and this needs to have an interval value per minute in each HOUR. You could try with \u201cHOURLY\u201d instead of \u201cAUTO_FREQUENCY\u201d, and it should work.\n\nInstead of:\nDATA_FREQUENCY = 'AUTO_FREQUENCY'\n\nUse \u201cHOURLY\u201d or any other DATA_FREQUENCY:\u00a0\n\nDATA_FREQUENCY = 'HOURLY'\n\nView solution in original post"
			},
			{
				"Answer_creation_date": "2022-08-08T15:48:00",
				"Answer_accepted": true,
				"Answer_upvote_count": 0,
				"Answer_body": "What is happening is that using \u201cAUTO_FREQUENCY\u201d is trying to send the Information as \u201cPER_MINUTE\u201d because of your data, and this needs to have an interval value per minute in each HOUR. You could try with \u201cHOURLY\u201d instead of \u201cAUTO_FREQUENCY\u201d, and it should work.\n\nInstead of:\nDATA_FREQUENCY = 'AUTO_FREQUENCY'\n\nUse \u201cHOURLY\u201d or any other DATA_FREQUENCY:\u00a0\n\nDATA_FREQUENCY = 'HOURLY'"
			}
		]
	},
	{
		"Question_title": "Due to an error, Vertex AI was unable to train model \"some_model",
		"Question_creation_date": "2022-10-09T07:53:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Due-to-an-error-Vertex-AI-was-unable-to-train-model-quot-some/td-p/476128/jump-to/first-unread-message",
		"Question_topic": [
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 61,
		"Question_body": "Hi Team\nWe are trying to train the model, but we are getting the below error after running 2 hrs.Region       : us-centerl1(IOWA) Algorithm : AutoML\nObjective  : Image classification (Single-label)\nData split:   Randomly assigned (80/10/10)Due to an error, Vertex AI was unable to train model \"some_model\".\nAdditional Details:\nOperation State: Failed with errors\nResource Name: \nprojects/1096088445304/locations/us-central1/trainingPipelines/8154185764406558720\nError Messages: INTERNALKindly help us to resolve the issue. \nThanks & Regards\nJambu ",
		"Answers": [
			{
				"Answer_creation_date": "2022-10-11T08:14:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Could you please share more information on the error message that you are receiving, since the information you are sharing isn\u2019t enough to properly help with the issue you are facing.\n\nThe internal errors occur when there\u2019s an issue with your system. The error could be transient, try to resubmit the CustomJob, HyperparameterTuningJob or TrainingPipeline, if the error persists what is recommended that you do is to contact support."
			}
		]
	},
	{
		"Question_title": "Over fitting during RL or DRL when using tabular data",
		"Question_creation_date": "2022-04-18T10:53:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Over-fitting-during-RL-or-DRL-when-using-tabular-data/td-p/414640/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform",
			"AutoML",
			"Document AI",
			"Vertex AI Model Registry"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 73,
		"Question_body": "HiI will like to know how the Vertex Api handles or warns about models with over fitting conditions when using Reinforcement Learning or Deep Reinforcement Learning ? If so can you help me with the documents where you explain this situations when using the Vertex Api for tabular dataframes?",
		"Answers": [
			{
				"Answer_creation_date": "2022-04-18T10:53:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi\n\nI will like to know how the Vertex Api handles or warns about models with over fitting conditions when using Reinforcement Learning or Deep Reinforcement Learning ? If so can you help me with the documents where you explain this situations when using the Vertex Api for tabular dataframes?"
			}
		]
	},
	{
		"Question_title": "Can we Download an AutoML Model after training?",
		"Question_creation_date": "2021-08-05T11:38:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Can-we-Download-an-AutoML-Model-after-training/td-p/166258/jump-to/first-unread-message",
		"Question_topic": [],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 273,
		"Question_body": "Is there a way to Download the AutoML Model after training?",
		"Answers": [
			{
				"Answer_creation_date": "2021-08-05T11:38:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Is there a way to Download the AutoML Model after training?"
			}
		]
	},
	{
		"Question_title": "Recover deleted Vertex AI resources",
		"Question_creation_date": "2022-03-22T22:23:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Recover-deleted-Vertex-AI-resources/td-p/405934/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 210,
		"Question_body": "Hi,In order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.Is there a way I can recover them??",
		"Answers": [
			{
				"Answer_creation_date": "2022-03-22T22:23:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi,\n\nIn order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.\n\nIs there a way I can recover them??"
			}
		]
	},
	{
		"Question_title": "No more Wavenet for fr-FR lang",
		"Question_creation_date": "2022-02-09T00:32:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/No-more-Wavenet-for-fr-FR-lang/td-p/391415/jump-to/first-unread-message",
		"Question_topic": [
			"Text-to-Speech"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 60,
		"Question_body": "Hi,I have been using Google cloud API for text-to-speech to generate audio based on text for some days using the Wavenet voices and it worked great. The vast majority of my text is French and I have been using the fr-FR-Wavenet-C voice for it. I can't find it anymore. Even the page https://cloud.google.com/text-to-speech/ doesn't show up in the demo section. That's seems to be the case for all fr-FR-Wavenet voices. Have they been deleted?",
		"Answers": [
			{
				"Answer_creation_date": "2022-02-09T00:32:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi,\n\nI have been using Google cloud API for text-to-speech to generate audio based on text for some days using the Wavenet voices and it worked great. The vast majority of my text is French and I have been using the fr-FR-Wavenet-C voice for it. I can't find it anymore. Even the page https://cloud.google.com/text-to-speech/ doesn't show up in the demo section. That's seems to be the case for all fr-FR-Wavenet voices. Have they been deleted?"
			}
		]
	},
	{
		"Question_title": "How would you model a list of an unknown number of items in DialogFlow CX?",
		"Question_creation_date": "2022-11-21T19:25:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/How-would-you-model-a-list-of-an-unknown-number-of-items-in/td-p/491605/jump-to/first-unread-message",
		"Question_topic": [
			"Dialogflow CX"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 35,
		"Question_body": "Hi,Taking from the example at Dialogflow CX: Build a retail virtual agent , if you were to build a shopping cart where users could add unlimited items to purchase. How would you model a solution for this?That is, instead of having:Can we have something equivalent to:How?",
		"Answers": [
			{
				"Answer_creation_date": "2022-11-22T10:23:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi,\n\nYou might want to see this example where the user created a shopping cart based using Dialogflow CX."
			}
		]
	},
	{
		"Question_title": "Emotional mobiles",
		"Question_creation_date": "2022-09-26T23:12:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Emotional-mobiles/td-p/471342/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 18,
		"Question_body": "My idea is to create emotional mobiles. Were we cannot buy mobiles with only money,mobile must choose us for buy and unique emotional between specific person and his new mobile . An intimacy between mobile and human. Like a puppy or understanding couples mobile and human sinking using AI. ",
		"Answers": [
			{
				"Answer_creation_date": "2022-09-26T23:12:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "My idea is to create emotional mobiles. Were we cannot buy mobiles with only money,mobile must choose us for buy and unique emotional between specific person and his new mobile . An intimacy between mobile and human. Like a puppy or understanding couples mobile and human sinking using AI."
			}
		]
	},
	{
		"Question_title": "Translating streaming audio into text",
		"Question_creation_date": "2022-04-11T14:33:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Translating-streaming-audio-into-text/td-p/412679/jump-to/first-unread-message",
		"Question_topic": [
			"Speech-to-Text"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 33,
		"Question_body": "Hi, I'm using @Google-cloud/media-translation in node with express js server. I want to translate media file (\".wav\" format) with media-translation. At first, i got an error because of authentication and I fixed it with env variable as specified in documentation, I followed each and every step exactly told in the documentation but I'm getting no response from server. When i looked into APIs & Services tab it only recorded my failed auth attempts no other API calls are recorded. Please help because there is no help available online about this product and it doesn't even send error responses so i can debug. ",
		"Answers": [
			{
				"Answer_creation_date": "",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi,\n\nWould you please share with us the error message ? Please make sure there are PII in it.\n\nYou can also share the reproduction steps?\n\nThanks"
			}
		]
	},
	{
		"Question_title": "AI Augmented Sensory Headset",
		"Question_creation_date": "2022-10-07T20:18:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/AI-Augmented-Sensory-Headset/td-p/475836/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 20,
		"Question_body": "Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?",
		"Answers": [
			{
				"Answer_creation_date": "2022-10-07T20:18:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?"
			}
		]
	},
	{
		"Question_title": "Google cloud text to speech",
		"Question_creation_date": "2021-09-26T06:11:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Google-cloud-text-to-speech/td-p/171231/jump-to/first-unread-message",
		"Question_topic": [
			"Speech-to-Text",
			"Text-to-Speech"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 771,
		"Question_body": "I registered myself for the google cloud text-to-speech service recently. Speech Studio worked just fine for the first few days, but today, to my dismay, there is distortion in the text reader's voice.What can I do about it?Thanks.  ",
		"Answers": [
			{
				"Answer_creation_date": "2021-10-01T14:27:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Speech Studio is not a Google product. TTS voices are always the same though and do not change over time if the same one is selected."
			}
		]
	},
	{
		"Question_title": "Google Cloud Vision broken for English?",
		"Question_creation_date": "2022-11-12T13:13:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Google-Cloud-Vision-broken-for-English/td-p/488836/jump-to/first-unread-message",
		"Question_topic": [
			"Cloud Vision API"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 40,
		"Question_body": "Has anyone else noticed that the Google Cloud Vision OCR that processes the text in images operates starting top to bottom, then left to right for English?  And that it didn't used to?\n\nThe problem with this is generally:\n\nWe write in English like this.\nSo we want to read the lines from left to right, top to bottom.We          write\ndo           english\nnot         like\nreally      thisTop to bottom, left to right.  Which is how you're reading it.",
		"Answers": [
			{
				"Answer_creation_date": "2022-11-14T15:49:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "To report an issue, it is better to do it at Issue Tracker, rather than write a post at this forum.\n\nYou can submit your report here:\n\nCreate new Cloud Vision issue\nIssue reports\n\nGoogle reviews every new issue report submitted by users. Sometimes one of our staff will ask for clarification or followup. After we're able to replicate the issue, we'll tell you that it's been forwarded to the appropriate team.\n\nDepending on the circumstances, we may be able to provide periodic updates while an issue is being looked at, but usually we cannot provide too many specifics about the exact cause of an issue, or when it will be fixed.\n\nWhen we've fixed an issue in production, we'll indicate this and then we'll close the issue.\n\nSee also:\n\nWhat to expect after you've opened an issue."
			}
		]
	},
	{
		"Question_title": "Just curious, can I use cloud bigtable as a feature store instead of using vertex AI feature store?",
		"Question_creation_date": "2022-06-28T03:43:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Just-curious-can-I-use-cloud-bigtable-as-a-feature-store-instead/td-p/435633/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 237,
		"Question_body": "I am trying to migrate my features table stored in bigquery to a feature store with lower latency. I'm choosing whether I should make use of vertex AI feature store or just cloud bigtable.My features tables are <10MB, and it is used for real time prediction hence a database with low latency is sufficient.Im just wondering aside from pricing, and ease of exporting data (bigtable requires more steps than vertex ai feature store), what is the difference between the 2 options?Also, what type of database (eg: bigtable or redis?) is vertex AI feature store behind the scenes, when I am creating the feature store using the web UI?  ",
		"Answers": [
			{
				"Answer_creation_date": "2022-07-04T15:45:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi, Chiayi,\n\nThe main difference between these 2, is that Vertex AI Feature Store is not considered a database as such, it is more like a product that provides a centralized repository for organizing, storing, and serving ML features [1]. In the other hand, Cloud Bigtable is a scalable NoSQL database service for large analytical and operational workloads [2]. More about [1][2].\n\n[1] https://cloud.google.com/vertex-ai/docs/featurestore/overview\n[2] https://cloud.google.com/bigtable/docs/overview"
			}
		]
	},
	{
		"Question_title": "Save audio file from speech to text stream",
		"Question_creation_date": "2022-03-03T07:35:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Save-audio-file-from-speech-to-text-stream/td-p/398993/jump-to/first-unread-message",
		"Question_topic": [
			"Speech-to-Text",
			"Text-to-Speech"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 57,
		"Question_body": "I am using @Google-cloud/speech for streaming audio from the browser to my nodejs backend.\nI would like to save the recorded audio.\nI see no option to do so. Any suggestions? Thanks.",
		"Answers": [
			{
				"Answer_creation_date": "2022-03-08T13:17:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hey,\u00a0\n\nYou shall probably use other packages for recording such as recordrtc as mentioned at [1].\u00a0\u00a0\n\n[1]\u00a0https://www.leeboonstra.dev/chatbots/building-your-own-voice-ai-3/"
			}
		]
	},
	{
		"Question_title": "How to assign specialist for specialist",
		"Question_creation_date": "2022-07-27T09:01:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/How-to-assign-specialist-for-specialist/td-p/447380/jump-to/first-unread-message",
		"Question_topic": [
			"Document AI"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 2,
		"Question_upvote_count": 0,
		"Question_view_count": 51,
		"Question_body": "Hello,I configured Document AI processor with HITL, No filter(self-validate). Using a python code, I am sending specific document to hitl queue to be processed by a specialist.I can clearly see that there are documents to be reviewed as \"Queued for review\" column with 2 documents.I also configured the specialist assignment assigning to all tasks (P0, audit, P1) to all the available specialists as it is shown in the image:Howevere, accesing to specialist platform, I cannot see any of the documents in the queue.What am I missing here?Thanks for your help. ",
		"Answers": [
			{
				"Answer_creation_date": "2022-08-02T13:56:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Follow the steps from 4 to 7 from the following codelab."
			},
			{
				"Answer_creation_date": "2022-08-02T14:49:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Thanks"
			}
		]
	},
	{
		"Question_title": "vertex AI Workbench is hanging with error \"Opening notebook with JupyterLab\" for more than a day",
		"Question_creation_date": "2022-09-08T08:12:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/vertex-AI-Workbench-is-hanging-with-error-quot-Opening-notebook/td-p/464300/jump-to/first-unread-message",
		"Question_topic": [
			"AI Platform",
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 3,
		"Question_upvote_count": 0,
		"Question_view_count": 112,
		"Question_body": "I am trying to follow instructions in https://cloud.google.com/vertex-ai/docs/tutorials/jupyter-notebooks (vertex AI Jupyter Notebooks tutorials). Steps done1. For the first notebook \"Text Classification model\" I have clicked on \"Vertex AI Workbench\". It takes me to GCP console & workbench.2. I am supposed to click on the \"Create\" button, which I did.3. THen the message \"Opening notebook with JupyterLab\" will come. But it is there for past 1 day, and still it hasn't finished creating. So I canceled the same. I tried once more the same thing happens. Not sure why?I have screen shots, but can't see anywhere to attach.Have anyone tried this tutorial, especially in workbench? Thanks,",
		"Answers": [
			{
				"Answer_creation_date": "2022-09-08T22:12:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hello,\u00a0\n\nAnybody active on these forums?\n\nIdeally some GCP reps should be there. Especially with newer offering like vertexAI - fundamental issues should be easy to solve!!"
			},
			{
				"Answer_creation_date": "2022-09-09T00:01:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Today I have retried the same. It worked at least creation of notebook.\n\nBut when executing step\n\nInstall additional packages\n\nInstall the following packages for executing this notebook.\n\nI am getting error:\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-recommendations-ai 0.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.8.1 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 9.0.0 which is incompatible.\n\n\u00a0\n\nAny help?"
			},
			{
				"Answer_creation_date": "2022-09-20T14:32:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "After searching for a solution for your case, it seems to be more an issue of the package version.\n\nI found a GitHub repository dealing with a similar problem to yours; there, you will likely find solutions to resolve it."
			}
		]
	},
	{
		"Question_title": "Issues with Handover Protocols - Facebook & Dialogflow",
		"Question_creation_date": "2021-09-29T18:02:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Issues-with-Handover-Protocols-Facebook-amp-Dialogflow/td-p/171609/jump-to/first-unread-message",
		"Question_topic": [
			"Dialogflow CX"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 0,
		"Question_upvote_count": 0,
		"Question_view_count": 343,
		"Question_body": "",
		"Answers": [
			{
				"Answer_creation_date": "2021-09-29T18:02:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "We're currently experiencing an ongoing issue where Bot conversations in our Facebook inbox are moving from \u2018Main\u2019 to \u2018Done\u2019 without any manual agent involvement. This means that conversations being escalated to the Main folder from the Bot will revert to the Done folder and the Bot will answer again.\n\u00a0\nOnce the conversation with the bot has been escalated to a human, there should be no further Bot involvement.\n\u00a0\nThis issue originally started after we noticed a failed payment on our Dialogflow account, where we went in, updated payment information and successfully charged the card to resume services. However, once we initiated a few test conversations, we noticed the above.. any advice or suggestions?"
			}
		]
	},
	{
		"Question_title": "Vertex AI endpoint deployment",
		"Question_creation_date": "2022-11-04T04:53:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Vertex-AI-endpoint-deployment/td-p/485783/jump-to/first-unread-message",
		"Question_topic": [
			"AI ML General",
			"AI Platform",
			"AutoML",
			"Video Intelligence API"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 4,
		"Question_upvote_count": 0,
		"Question_view_count": 77,
		"Question_body": "How can I utilize the mega GPU during endpoint deployment  for vertex ai work? Are there any model for examples or other resources that I can use to better grasp this?",
		"Answers": [
			{
				"Answer_creation_date": "2022-11-07T11:00:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "What kind of model are you deploying on the endpoint? Can you clarify on what you mean in this statement \"utilizing the GPU during endpoint deployment\"?"
			},
			{
				"Answer_creation_date": "2022-11-08T00:25:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Thank you for responding. It is a simple tensorflow tabular classification model, and deployment takes about 18-20 minutes after model registration. I decided to use a mega GPU since I want to shorten this time as much as I can; perhaps this decision will shorten the time for deployment."
			},
			{
				"Answer_creation_date": "2022-11-08T09:25:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Thank you for clarifying. As far as I know the deployment of an endpoint is handled at the backend of GCP so it is not possible to use a GPU in order to shorten the deployment time."
			},
			{
				"Answer_creation_date": "2022-11-08T11:45:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "okay thanks , but when I use another account for the same , it's done within 2-3 min only !!!!"
			}
		]
	},
	{
		"Question_title": "Vertex AI - Slow Batch Predictions",
		"Question_creation_date": "2022-01-20T06:40:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Vertex-AI-Slow-Batch-Predictions/td-p/184803/jump-to/first-unread-message",
		"Question_topic": [
			"AI Platform",
			"AutoML"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 2,
		"Question_upvote_count": 2,
		"Question_view_count": 626,
		"Question_body": "Hi, I've been running a Vertex AI Tabular batch prediction job for about 500k rows (50MB BQ table) for nearly 5 hours now, and I can't see any reference to how it's performing anywhere. Is there an estimate for how long this should take? Or where I should look for progress?",
		"Answers": [
			{
				"Answer_creation_date": "2022-01-21T14:01:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi Liam,\u00a0\n\nYou might be able to check results in BigQuery or Cloud Storage [1] to estimate the progress on it. If this does not meet your demand, you might consider filing a feature request per instructions at [2].\u00a0\u00a0\n\n[1]\u00a0https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions#retrieve_batch_prediction_resu...\n[2]\u00a0https://cloud.google.com/support/docs/issue-trackers"
			},
			{
				"Answer_creation_date": "2022-11-20T11:11:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hello,\u00a0\n\nIt's not possible to check progress by checking the GCS output location. The output files only get uploaded after the job ends."
			}
		]
	},
	{
		"Question_title": "Unstructured data in Vertex AI feature store",
		"Question_creation_date": "2021-11-30T16:34:00",
		"Question_link": "https://www.googlecloudcommunity.com/gc/AI-ML/Unstructured-data-in-Vertex-AI-feature-store/td-p/176796/jump-to/first-unread-message",
		"Question_topic": [
			"AI Platform"
		],
		"Question_has_accepted_answer": false,
		"Question_answer_count": 1,
		"Question_upvote_count": 0,
		"Question_view_count": 312,
		"Question_body": "Does Vertex AI feature store support ingestion, transformation and storage of unstructured data like images and audio?",
		"Answers": [
			{
				"Answer_creation_date": "2021-12-01T13:50:00",
				"Answer_accepted": false,
				"Answer_upvote_count": 0,
				"Answer_body": "Hi,\n\nAs per source data requirements [1] regarding Vertex AI Feature Store, it does not look like that you'll be able to ingest unstructured data.\n\n\"Vertex AI Feature Store can ingest data from tables in BigQuery or files in Cloud Storage. For files in Cloud Storage, they must be in the Avro or CSV format.\"\n\n[1]\u00a0https://cloud.google.com/vertex-ai/docs/featurestore/source-data"
			}
		]
	}
]