[
    {
        "Question_title":"How to maintain a static key for azure managed endpoints ?",
        "Question_created_time":1684956609463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291178\/how-to-maintain-a-static-key-for-azure-managed-end",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Every time i deploy my model on the azure managed endpoint the primary key changes every time which is causing problems for us as I have to send new credentials to the backend developer. <\/p>\n<p>The website is deployed on AWS. I'd like to have such a setup for my azure endpoint so that I could just make changes and push it. It shouldn't regenerate keys so that I don't have to reach out to him for every time i make changes to the model.<\/p>\n<p>My setup:  <br \/>\nI'm using azure managed endpoints to deploy the model and sending over the rest endpoint and the primary key to the backend developer to make inference calls. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure databrick",
        "Question_created_time":1685391410183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293763\/azure-databrick",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>can I connect my Azure machine learning workspace to databrick, is it possible? How can I achieve it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there any function support deep learning in machine learning service",
        "Question_created_time":1685391233180,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293761\/is-there-any-function-support-deep-learning-in-mac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a deep learning project but I am confused about WM and compute, is there anything support in deep learning in Azure<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Which Azure service to host this ML model",
        "Question_created_time":1685375781666,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293665\/which-azure-service-to-host-this-ml-model",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>Hi.<\/p>\n<p>I need to execute this model <a href=\"https:\/\/github.com\/obss\/sahi\">https:\/\/github.com\/obss\/sahi<\/a> upon an HTTP request. I will need between 32GB and 128GB of RAM (depending on the request). Also, I will only receive this request once or twice a week (they are not predefined dates). Each process may take a few hours.<\/p>\n<p>I have discarded Azure Functions since it has 10min execution limit (for Consumption Plan), and because it scales horizontally. I do not need multiple instances of the Functions, instead I need a powerful machine to run the model.<\/p>\n<p>I am trying to understand if I can achieve my needs with Azure Machine Learning, Azure Batch or Azure VM, considering I want something that doesn't stay up 24\/7 charging costs. I need something that can run when needed, and then free resources after that. Cold start is not a concern.<\/p>\n<p>Any advice is appreciated. Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to create diff environments for different python packages in production",
        "Question_created_time":1685288180313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293107\/how-to-create-diff-environments-for-different-pyth",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p> We have couple of libraries which are created to be used by user while working on their azure ML workspace. <\/p>\n<p>Now, both of these libraries have diff packages which could be different then what a user is using. Eg : User might be using an environment which is using numpy x.1 but package A might be using x.2 and package B needs x.3. This is a possibility since all these packages are developed by different teams.<\/p>\n<p>Now, what could be the best way to handle this problem in real world. So far, I am able to come up with below approaches :<\/p>\n<ol>\n<li> Install these files in different docker container where the needed packages are installed. And get the desired output done in separate environments.<\/li>\n<li> Use Custom Environment options provided by Azure itself. And run the incompatibles ones in different environment.<\/li>\n<\/ol>\n<p>So, I wanted to know if there is any right way of doing this in real world. I see that we should create a different environment for each project but what about the case when we have different packages which needs different versions of common dependencies. How to handle such case?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hi I have trained classification model using azure automl. Now I want to test the model on validation dataset, but got the package issue.",
        "Question_created_time":1685350572853,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293464\/hi-i-have-trained-classification-model-using-azure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team, <\/p>\n<p>I am currently working as a data scientist at a European bank.<\/p>\n<p>I have trained the model using AutoML. Now I want to test the model on the validation dataset.<\/p>\n<p>I have used the following code for training and downloading the model but I got the following error :<\/p>\n<pre><code>ImportError: cannot import name 'HoltWintersResultsWrapper' from 'statsmodels.tsa.holtwinters' (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/statsmodels\/tsa\/holtwinters\/__init__.py)\n<\/code><\/pre>\n<p>It is very critical now for me as it took significant amount of time, can you please help me by resolving this issue?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/f377399e-066d-4970-ae8f-b2ecb6ce96ca?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/1ee30d8b-6570-49b2-a0b1-b713c978f350?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"regression model learning path, error: failed to mount datastore",
        "Question_created_time":1685373922706,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293659\/regression-model-learning-path-error-failed-to-mou",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to go through this learning path (<a href=\"https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html\">https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html<\/a>), but when I get to the step to submit the model, I am getting the following error. I've updated authentication on my workspace blob storage, and on the azureml_globaldatasets. Not sure what to do?<\/p>\n<pre><code>UserErrorException:\n\tMessage: Failed to mount datastore 'azureml_globaldatasets' for DataReference 'INPUT_Dataset'. Datastore 'azureml_globaldatasets' has credential type 'Sas'. Please make sure the valid sas token is registered in this Datastore..\n\tInnerException None\n\tErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Failed to mount datastore 'azureml_globaldatasets' for DataReference 'INPUT_Dataset'. Datastore 'azureml_globaldatasets' has credential type 'Sas'. Please make sure the valid sas token is registered in this Datastore..&quot;\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Telemetry item length must not exceed 65536",
        "Question_created_time":1685361959656,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293542\/telemetry-item-length-must-not-exceed-65536",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is there any update is Azure Machine learning portal?<\/p>\n<p>I have deployed my model previously, It worked. I use the ML endpoint and used that model.<\/p>\n<p>But now, without any changes this endpoint is not working. In the deployment logs I see the error as like in attached screenshot.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/412f8cbf-f065-4ab8-9829-5fbb4c7c1d47?platform=QnA\" alt=\"image\" \/><\/p>\n<p>Is there any update from Azure Machine learning? Please help me to solve this issue.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Facing problem while deploying model on Azure ML as online endpoints",
        "Question_created_time":1685010288203,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291498\/facing-problem-while-deploying-model-on-azure-ml-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>MLflow version<\/p>\n<p>channels:<\/p>\n<p>conda-forge  <br \/>\ndependencies:<\/p>\n<p>pip:<\/p>\n<ul>\n<li> 'inference-schema[numpy-support]==1.5.0'<\/li>\n<li> xlrd==2.0.1<\/li>\n<li> mlflow== 1.26.1<\/li>\n<li> azureml-mlflow==1.42.0<\/li>\n<li> tqdm==4.63.0<\/li>\n<li> pytorch-transformers==1.2.0<\/li>\n<li> pytorch-lightning==2.0.2<\/li>\n<li> seqeval==1.2.2<\/li>\n<li> azureml-inference-server-http==0.8.0  <br \/>\nname: model-env<\/li>\n<\/ul>\n<p>System information<\/p>\n<ul>\n<li> python=3.9<\/li>\n<li> pip=22.1.2<\/li>\n<li> numpy=1.21.2<\/li>\n<li> scikit-learn=0.24.2<\/li>\n<li> scipy=1.7.1<\/li>\n<li> 'pandas&gt;=1.1,&lt;1.2'<\/li>\n<li> pytorch=1.10.0<\/li>\n<\/ul>\n<p>Describe the problem<\/p>\n<p>Trained the model and pipeline on GPU instances in Azure ML.  <br \/>\nWhen trying to load the model using this code -<\/p>\n<p>*How and where can I update map_location=torch.device('cpu') ?<\/p>\n<p>Why does it say that run() I'm my custom socre.py is not decorated when I have clearly added some lines there.**<\/p>\n<pre><code>model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;use-case1-model&quot;)\nmodel = mlflow.pyfunc.load_model(model_path)\n<\/code><\/pre>\n<p>score.py<\/p>\n<pre><code>\nimport logging\nimport os\nimport json\nimport mlflow\nfrom io import StringIO\nfrom mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\nimport sys\nfrom time import strftime, localtime\nfrom collections import Counter\nfrom pytorch_transformers import BertTokenizer\nimport random\nimport numpy as np \nimport torch \nfrom tqdm import tqdm\n\ndef init():\n    global model\n    # &quot;model&quot; is the path of the mlflow artifacts when the model was registered. For automl\n    # models, this is generally &quot;mlflow-model&quot;.\n    model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;use-case1-model&quot;)\n    model = mlflow.pyfunc.load_model(model_path)\n    logging.info(&quot;Init complete&quot;)\n\n\ndef run(raw_data):\n    data = json.loads(raw_data)\n    title = json.dumps(data[&quot;title&quot;])\n    att = json.dumps(data[&quot;attributes&quot;])\n\n    output = model.predict([tensor_t,tensor_a])\n\n    predict_list = output.tolist()[0]\n    \n    result = StringIO()\n    predictions_to_json(predict_list,result)\n    return result.getvalue()\n<\/code><\/pre>\n<p>`Other info \/ logs<\/p>\n<pre><code>\nInitializing logger\n2023-05-25 09:36:19,602 I [66] azmlinfsrv - Starting up app insights client\n2023-05-25 09:36:22,449 I [66] azmlinfsrv.user_script - Found user script at \/var\/azureml-app\/dependencies\/score.py\n2023-05-25 09:36:22,449 I [66] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n2023-05-25 09:36:22,449 I [66] azmlinfsrv.user_script - Invoking user's init function\n2023\/05\/25 09:36:22 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.8.16`, differs from the version of Python that is currently running, `Python 3.9.16`, and may be incompatible\n2023-05-25 09:36:22,742 E [66] azmlinfsrv - User's init function failed\n2023-05-25 09:36:22,744 E [66] azmlinfsrv - Encountered Exception Traceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 117, in invoke_init\n    self._user_init()\n  File &quot;\/var\/azureml-app\/dependencies\/score.py&quot;, line 21, in init\n    model = mlflow.pyfunc.load_model(model_path)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 735, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 735, in _load_pyfunc\n    return _PyTorchWrapper(_load_model(path, **kwargs))\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 643, in _load_model\n    return torch.load(model_path, **kwargs)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 809, in load\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 1172, in _load\n    result = unpickler.load()\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 1142, in persistent_load\n    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 1116, in load_tensor\n    wrap_storage=restore_location(storage, location),\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 217, in default_restore_location\n    result = fn(storage, location)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 182, in _cuda_deserialize\n    device = validate_cuda_device(location)\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 166, in validate_cuda_device\n    raise RuntimeError('Attempting to deserialize object on a CUDA '\nRuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 111, in setup\n    self.user_script.invoke_init()\n  File &quot;\/azureml-envs\/azureml_9a3b1e0a66d72d612aebc12b4a285f72\/lib\/python3.9\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 119, in invoke_init\n    raise UserScriptException(ex) from ex\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Need GPU (cuda) access while deploying the model",
        "Question_created_time":1685356186823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293499\/need-gpu-(cuda)-access-while-deploying-the-model",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I need assistance with deploying a pre-trained model. I have created a custom score.py file for the deployment process. However, the docker created on the CPU instance does not provide access to the GPU, which poses a problem for predicting with PyTorch or TensorFlow models as they require input to be converted to tensors loaded on the GPU. Can you suggest a solution?<\/p>\n<p>My score.py script -<\/p>\n<pre><code>import something\nimport os\nimport json\nimport mlflow\nfrom io import StringIO\nfrom mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\nimport sys\nfrom time import strftime, localtime\nfrom collections import Counter\nfrom pytorch_transformers import BertTokenizer\nimport random\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n#from unittest import mock\nimport torch\n\n# original = torch.load\n\n\n# def load(*args):\n#     return torch.load(*args, map_location=torch.device(&quot;cpu&quot;),pickle_module=None)\n\n\n# def init():\n#     global model\n#     model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;use-case1-model&quot;)\n#     # &quot;model&quot; is the path of the mlflow artifacts when the model was registered. For automl\n#     # models, this is generally &quot;mlflow-model&quot;.\n\n#     with mock.patch(&quot;torch.load&quot;, load):\n#         model = mlflow.pyfunc.load_model(model_path)\n\n#     logging.info(&quot;Init complete&quot;)\n\ndef init():\n    global model\n\n    model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;use-case1-model&quot;)\n\n    model = mlflow.pytorch.load_model(model_path, map_location=torch.device('cpu'))\n    logging.info(&quot;Init complete&quot;)\n\n\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\n            \n\ndef run(data):\n\n    json_data = json.loads(data) \n\n    title = json_data[&quot;input_data&quot;][&quot;title&quot;]\n    att = json_data[&quot;input_data&quot;][&quot;attributes&quot;]\n    \n    result = {}\n\n    for i in range(len(title)):\n\n        my_dict = {}\n        for j in range(len(att)):\n            \n            attr = att[i][j]\n\n            t, a = nobert4token(tokenizer, title[i].lower(), attr)\n\n            x = X_padding(t)\n            y = tag_padding(a)\n\n            tensor_a = torch.tensor(y, dtype=torch.int32)\n            tensor_a = torch.unsqueeze(tensor_a, dim=0).to(&quot;cuda&quot;)\n\n            tensor_t = torch.tensor(x, dtype=torch.int32)\n            tensor_t = torch.unsqueeze(tensor_t, dim=0).to(&quot;cuda&quot;)\n\n            output = model([tensor_t, tensor_a])\n\n            predict_list = output.tolist()[0]\n            \n            my_dict[attr] = &quot; &quot;.join(words_p)\n\n        result[title[i]] = my_dict\n\n\n    return result\n\n\n<\/code><\/pre>\n<p>My invoke script-<\/p>\n<pre><code>ml_client.online_endpoints.invoke(\n    endpoint_name=endpoint_result.name,\n    deployment_name=green_deployment_uc1.name,\n    request_file=os.path.join(&quot;.\/dependencies&quot;, &quot;sample.json&quot;),\n)\n\n<\/code><\/pre>\n<p>My conda.yaml-<\/p>\n<pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pip=22.1.2\n  - numpy=1.21.2\n  - scikit-learn=0.24.2\n  - scipy=1.7.1\n  - 'pandas&gt;=1.1,&lt;1.2'\n  - pytorch=1.10.0\n  - pip:\n      - 'inference-schema[numpy-support]==1.5.0'\n      - xlrd==2.0.1\n      - mlflow== 1.26.1\n      - azureml-mlflow==1.42.0\n      - tqdm==4.63.0\n      - pytorch-transformers==1.2.0\n      - pytorch-lightning==2.0.2\n      - seqeval==1.2.2\n      - azureml-inference-server-http==0.8.0\nname: model-env\n\n<\/code><\/pre>\n<p>Error that I am getting -<\/p>\n<pre><code>127.0.0.1 - - [29\/May\/2023:10:03:32 +0000] &quot;GET \/ HTTP\/1.0&quot; 200 7 &quot;-&quot; &quot;kube-probe\/1.18&quot;\n2023-05-29 10:03:34,291 E [70] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 130, in invoke_run\n    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 154, in &lt;lambda&gt;\n    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n  File &quot;\/var\/azureml-app\/dependencies\/score.py&quot;, line 129, in run\n    tensor_a = torch.unsqueeze(tensor_a, dim=0).to(&quot;cuda&quot;)\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/torch\/cuda\/__init__.py&quot;, line 247, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http:\/\/www.nvidia.com\/Download\/index.aspx\n\nThe above exception was the direct cause of the following exception:\n\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I attach a managed disk to a Machine  Learning Compute instance?",
        "Question_created_time":1601637154150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/115201\/how-can-i-attach-a-managed-disk-to-a-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello experts,  <\/p>\n<p>I would like to attach a managed disk to my machine learning compute instance. Is that possible?  <\/p>\n<p>There is a possible overlap to the question <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/2ee51daa-2ec8-430f-a4ca-ec50a30d0321\/attach-disk-to-virtual-machine?forum=WAVirtualMachinesforWindows\">Attach Disk to Virtual Machine<\/a>, but steps doesn't seem to apply to ML compute instances.  <\/p>\n<p>Thanks in advance,  <\/p>",
        "Question_closed_time":1604477155917,
        "Answer_score_count":0.0,
        "Answer_comment_count":6.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>You can attach your managed disk by following steps in Azure portal:    <br \/>\n<img src=\"\/answers\/storage\/temp\/37296-image.png\" alt=\"37296-image.png\" \/>    <\/p>\n<p>More details and limitation please see:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target#azure-machine-learning-compute-managed\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target#azure-machine-learning-compute-managed<\/a>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"I am having trouble accessing the datastore data.",
        "Question_created_time":1681750041930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1242662\/i-am-having-trouble-accessing-the-datastore-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to create a dataset from datastore using the following code in Azure ML Notebooks:<\/p>\n<pre><code>  workspace = Workspace.from_config()   \n\n  dataset = Dataset.get_by_name(workspace, name='Dataset')  \n\n<\/code><\/pre>\n<p>And I am getting the following error:<\/p>\n<pre><code>Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Stuck on Azure AI Fundamentals course",
        "Question_created_time":1684995150610,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291402\/stuck-on-azure-ai-fundamentals-course",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am currently pursuing 'Microsoft Azure AI Fundamentals' course and I am currently stuck on unit 6 of 8 (titled-Explore automated machine learning in azure ML) as I am unable to find the administrative access into azure ML to create the resource and I am getting redirected to payment page for subscription. Please help me to get into Azure ML using administrative access. <\/p>",
        "Question_closed_time":1685005009496,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=eb5a735f-18f5-4565-8bc6-44e2094e0255\">@Soumyadeep Podder  <\/a>Thanks for the question. If you\u2019re being redirected to the payment page for subscription, it could mean that you don\u2019t have an active Azure subscription. You can try signing up for a free trial of Azure.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"TypeError when creating Data Asset with Python",
        "Question_created_time":1685104254456,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1292188\/typeerror-when-creating-data-asset-with-python",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to register data from a datastore programatically (via Python SDK v2). I need to do it this way since the final output will be a scheduled AzureML Pipeline that does preprocessing for an NLP module. Further, as time progresses, the source files will also be updated. I'm attempting to run the following script:<\/p>\n<pre><code class=\"lang-python\">from azure.ai.ml.entities  import Data\nfrom azure.ai.ml.constants import AssetTypes\n\ndata_path = &quot;azureml:\/\/\n\/datastores\/[name-of-datastore]\/paths\/[filename].csv\n&quot;\n\n\ndata_asset = Data(\n    path = data_path,\n    type = AssetTypes.URI_FILE,\n    description= 'description',\n    name = 'data_name'\n)\n\nml_client.data.create_or_update(asset)\n\n\n\n<\/code><\/pre>\n<p>However, running that prompts me with the error<\/p>\n<p>TypeError: Please refer to create_or_update docstring for valid input types.<\/p>\n<p>I'm not sure why I'm getting this error and would like to ask for all the help I can get. <\/p>\n<p>While the example shows an excel file, I have more files I wish to register this way, some being excel sheets.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to use compute cluster in Azure ML",
        "Question_created_time":1685078105436,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291984\/unable-to-use-compute-cluster-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm using Azure for students and I keep getting this error in compute cluster: <\/p>\n<p><strong>Provisioning error<\/strong>  <br \/>\nThe specified subscription has a total vCPU quota of 0 and cannot accomodate for at least 1 requested managed compute node which maps to 2 vCPUs. Talk to your Subscription Admin or refer to <a href=\"https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-manage-quotas#request-quota-increases\">https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-manage-quotas#request-quota-increases<\/a> to increase the total quota<\/p>\n<p>I have also checked that there is no other resource group using compute resources and the usage in quota page of VM is 0 cores used.<\/p>\n<p>Can you please help me to fix this error?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/892eb683-65c8-4365-9208-ce5186775ce5?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure OpenAI service capabilities",
        "Question_created_time":1663989341807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1021561\/azure-openai-service-capabilities",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>How do I get access to the Azure OpenAI service to evaluate it's capabilities?<\/p>",
        "Question_closed_time":1664001167767,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. It is a Limited Access service so you have to apply for it <a href=\"https:\/\/aka.ms\/oai\/access\">https:\/\/aka.ms\/oai\/access<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"sdkv2 job on local compute fails with registry authentication error",
        "Question_created_time":1685035632663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291779\/sdkv2-job-on-local-compute-fails-with-registry-aut",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Steps to reproduce:<\/p>\n<p>Run code from: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-local-runs?view=azureml-api-2\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-local-runs?view=azureml-api-2<\/a><\/p>\n<pre><code class=\"lang-python\">#import required libraries\nfrom azure.ai.ml import MLClient, command\nfrom azure.ai.ml.entities import Environment\nfrom azure.identity import DefaultAzureCredential\n\n#connect to the workspace\nml_client = MLClient.from_config(DefaultAzureCredential())\n\n# set up pytorch environment\nenv = Environment(\n    image='mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04',\n    conda_file='pytorch-env.yml',\n    name='pytorch-env'\n)\n\n# define the command\ncommand_job = command(\n    code='.\/src',\n    command='train.py',\n    environment=env,\n    compute='local',\n)\n\nreturned_job = ml_client.jobs.create_or_update(command_job)\nreturned_job\n\n<\/code><\/pre>\n<p><strong>Expected<\/strong>: Job runs<\/p>\n<p><strong>Actual<\/strong>:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;test.py&quot;, line 23, in &lt;module&gt;\n    returned_job = ml_client.jobs.create_or_update(command_job)\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/core\/tracing\/decorator.py&quot;, line 76, in wrapper_use_tracer\n    return func(*args, **kwargs)\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_telemetry\/activity.py&quot;, line 337, in wrapper\n    return_value = f(*args, **kwargs)\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_job_operations.py&quot;, line 609, in create_or_update\n    raise ex\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_job_operations.py&quot;, line 573, in create_or_update\n    snapshot_id = start_run_if_local(\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_local_job_invoker.py&quot;, line 415, in start_run_if_local\n    cr_helper.get_bootstrapper_binary(bootstrapper_info)\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_local_job_invoker.py&quot;, line 310, in get_bootstrapper_binary\n    docker_client = self.get_docker_client(registry)\n  File &quot;\/home\/uberj\/anaconda3\/envs\/mlopspython_ci\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_local_job_invoker.py&quot;, line 232, in get_docker_client\n    if registry:\nRuntimeError: Login to Docker registry 'mcr.microsoft.com' failed. See error message: 'username'\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hello , I have a question i wanted to know if is it possible to use  dataset as parameter in azure ml pipeline",
        "Question_created_time":1684508723400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287951\/hello-i-have-a-question-i-wanted-to-know-if-is-it",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p> I mean  after submittting it and deploying it is it possible to use different data with different schema if no how can I reach that ??<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio \/ Deleted repo with execute_python_script.yaml",
        "Question_created_time":1685025322030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291675\/azure-ml-studio-deleted-repo-with-execute-python-s",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hello, I'm trying to use the designer tool from Azure ML Studio and more specifically the Execture_Python_Script bloc.   <br \/>\nHowever, I deleted in the blobstorage the <\/p>\n<p>deleted the repository repository with the execute_python_script.yaml for this bloc and I get the following error : <\/p>\n<p>Failed to download snapshot from storage using SAS url. Error message: The specified blob does not exist. RequestId:b3161801-201e-0046-2c0f-8f66a4000000 Time:2023-05-25T13:51:07.4844312Z, Storage account name: ********, Storage error code: BlobNotFound, Storage pat<em>h:<\/em>  path\/execute_python_script.yaml. Tip: Please try to re-upload the snapshot. To do so, edit any content in the local source directory and resubmit the run.  <\/p>\n<p>Can you help me with this error ?   <\/p>\n<p>Thanks a lot  <\/p>\n<p>Ga\u00ebl<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Arc K8s cluster error: ClusterUnreachable: The underlying cluster is unreachable.",
        "Question_created_time":1683953222436,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283586\/azure-arc-k8s-cluster-error-clusterunreachable-the",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I have connected my on-premise K8s cluster via Azure Arc. The setup seems to work ok as I can paste in the bearer token and see all namespaces, pods, etc. <\/p>\n<p>Now I want to use this arc-enabled K8s cluster as a target within my Azure Machine Learning Workspace. <\/p>\n<p>I added it as attached compute in the workspace. Allocation Stats says &quot;Succeeded&quot;. <\/p>\n<p>But at the top, in a yellow information bar it says: <em>&quot;<strong>ClusterUnreachable<\/strong>:\u00a0The underlying cluster is unreachable.&quot;<\/em><\/p>\n<p>As a result I am unable to deploy any endpoints to my on-premise K8s cluster. <\/p>\n<p>What might the issue be?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/2328141a-5198-4585-a575-8f79ff04ac35?platform=QnA\" alt=\"Capture\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting error code 403 when trying to connect to or register an Environment from a notebook in azure workspace",
        "Question_created_time":1685037226110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291786\/getting-error-code-403-when-trying-to-connect-to-o",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm getting this error when trying to use an existing python environment from Environments in my notebook or when trying to register an environment created in the notebook:<\/p>\n<p>Exception: Error retrieving the environment definition. Code: 403 : &lt;html&gt; &lt;head&gt;&lt;title&gt;403 Forbidden&lt;\/title&gt;&lt;\/head&gt; &lt;body&gt; &lt;center&gt;&lt;h1&gt;403 Forbidden&lt;\/h1&gt;&lt;\/center&gt; &lt;hr&gt;&lt;center&gt;nginx&lt;\/center&gt; &lt;\/body&gt; &lt;\/html&gt;<\/p>\n<p>Any idea what kind of permission settings need to be adjusted by admin to get this working?   <br \/>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning studio for big data use",
        "Question_created_time":1684798115123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289669\/azure-machine-learning-studio-for-big-data-use",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello expert: <\/p>\n<p>I am curious about if that possible to use Azure machine learning as a big data development platform, I found very less information for that, please guide me. <\/p>",
        "Question_closed_time":1684799360590,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello @Louis   <\/p>\n<p>Thanks for reaching out to us, yes, Azure Machine Learning can be used as a big data development platform. Azure Machine Learning provides a number of features that can help you develop and deploy big data solutions, including:<\/p>\n<p>Data preparation and transformation: Azure Machine Learning provides tools for data preparation and transformation, including data cleaning, feature engineering, and data normalization. You can use these tools to prepare your data for analysis and modeling.<\/p>\n<p>Distributed computing: Azure Machine Learning supports distributed computing using technologies such as Apache Spark and Dask. You can use these technologies to process large datasets in parallel across multiple nodes.<\/p>\n<p>Machine learning algorithms: Azure Machine Learning provides a wide range of machine learning algorithms that can be used for big data analysis, including deep learning algorithms for image and text analysis.<\/p>\n<p>Model deployment: Azure Machine Learning provides tools for deploying machine learning models as web services, which can be used to serve predictions on large datasets in real-time.<\/p>\n<p>Integration with other Azure services: Azure Machine Learning integrates with other Azure services such as Azure Data Factory, Azure Databricks, and Azure HDInsight, which can be used to build end-to-end big data solutions.<\/p>\n<p>If you want to work with Scala and Spark, I would recommend you to read below document - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/data-science-process\/scala-walkthrough\">https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/data-science-process\/scala-walkthrough<\/a><\/p>\n<p>It may make more sense to big data development only. If you are willing to share more details about your scenario, we can provide more details about it.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful and vote 'Yes' to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Container does not exist error when trying to invoke ML Batch Endpoint",
        "Question_created_time":1685008129136,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291488\/container-does-not-exist-error-when-trying-to-invo",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>So I have a Batch Endpoint deployed in ML studio.<\/p>\n<p>I am able to run a job successfully when manually creating a job for this endpoint from within the portal using a datastore, which is just a mounted container of images in ML studio.<\/p>\n<p>I have been attempting to invoke this endpoint using both the python SDK as well as through the rest API with .NET, however in both scenarios the job fails with the following error.<\/p>\n<p><code>Failed to download snapshot from storage using SAS url. Error message: The specified container does not exist.<\/code>  <br \/>\n<code>RequestId:563bdada-501e-0078-4ee1-8e27c8000000<\/code>  <br \/>\n<code>Time:2023-05-25T08:21:05.1296437Z, Storage account name: mystorageaccount, Storage error code: ContainerNotFound, Storage path: https:\/\/mystorageaccount.blob.core.windows.net\/132fbb23-7-a6c501d9-9a17-5ec2-a46a-80dee62dee15\/script\/__pycache__\/score.cpython-37.pyc. Storage container does not exist for storage account name: mystorageaccount, container name: 132fbb23-7-a6c501d9-9a17-5ec2-a46a-80dee62dee14 Tip: Please try to re-upload the snapshot. To do so, edit any content in the local source directory and resubmit the run.<\/code><\/p>\n<p>To clarify, the container referenced in the url above is nothing like the url I send. <\/p>\n<p>I am invoking the endpoint as per documentation like this:<\/p>\n<pre><code>job = ml_client.batch_endpoints.invoke(\n   endpoint_name=endpoint_name,\n   input= Input(type=AssetTypes.URI_Folder, path='https:\/\/mystorageaccount.blob.core.windows.net\/test-batch-images')\n)\n<\/code><\/pre>\n<p>The container does exist, and I have tried this on multiple containers with the same error. I have also tried setting the public access level to both blob as well as container and still receive the same error.<\/p>\n<p>I have ensured I have followed the authentication principles lined out here: <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=cli<\/a> under 'Security considerations when reading data', where my compute cluster has a managed Identity associated with it that has the correct access to the storage account.<\/p>\n<p>I have also tried generating an sas url for the container and passing that as an argument, but this returns an error when invoking saying 'URL contains secrets, must store secrets in datastore.'<\/p>\n<p>There's nothing in the documentation about invoking an endpoint with a secret for the attached data. I would have assumed this was managed behind the scenes given that you have to add a managed identity to the compute cluster to access containers.<\/p>\n<p>AM I missing something? is there a way to separately authenticate the created docker container running the batch?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In Microsoft Learn on exercise \"Explore clustering with Azure Machine Learning Designer\" it is not possible to deploy the endpoint.",
        "Question_created_time":1683576859973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1280102\/in-microsoft-learn-on-exercise-explore-clustering",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>In Microsoft Learn on the exercise &quot;Explore clustering with Azure Machine Learning Designer&quot; it is not possible to deploy the endpoint. Point 4 in the &quot;Deploy a service&quot; section in the following instructions: <a href=\"https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02c-create-clustering-model.html\">https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02c-create-clustering-model.html<\/a><\/p>\n<p>When I press the button &quot;Deploy&quot; nothing happens. the form stays there, and the service is not deployed and no error message appears. There is no reaction of the platform whatsoever. As I am new to this I might be committing some very basic mistake, in any case, it would be nice if the platform gave some error message as to what step I might be missing. Here is a screenshot:   <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/7e070cce-1105-447e-ab52-a5704e2fd523?platform=QnA\" alt=\"Screenshot 2023-05-08 at 20.56.44\" \/><\/p>\n<p>Once the &quot;Deploy&quot; button is pressed nothing happens. Thanks in advance for your help! . <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When starting azure ml experiment I get a failed to extract subscription information error",
        "Question_created_time":1684549394923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1288277\/when-starting-azure-ml-experiment-i-get-a-failed-t",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have a folder in a blob storage with training data for an experiment but when I run the script for training with <\/p>\n<pre><code class=\"lang-python\">\nimport azureml.core\nfrom azureml.core.workspace import Workspace\nfrom azureml.core import Environment\nfrom azureml.core.environment import CondaDependencies\nfrom azureml.core import ScriptRunConfig, Experiment\n\nfrom azure.ai.ml import MLClient\nfrom azureml.core.workspace import Workspace\nfrom azure.identity import DefaultAzureCredential\nfrom azureml.core import Dataset\nfrom azure.ai.ml.constants import AssetTypes\nfrom azure.ai.ml import command, Input\n\nws = Workspace.from_config()\n\nml_client = MLClient.from_config(credential=DefaultAzureCredential())\n\ndataSet = Dataset.File.from_files(['https:\/\/&lt;filepath&gt;])\ndataSet = dataSet.as_named_input('data_path').as_download()\n\nmyexp = Experiment(workspace=ws, name = &quot;Yolo-experiment&quot;)\ncurated_env = Environment.get(workspace=ws, name=&quot;AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu&quot;)\nconfig = ScriptRunConfig(source_directory=&quot;.&quot;,\n                      script=&quot;resnet18-trainer.py&quot;,\n                      compute_target=&quot;local&quot;,\n                      environment=curated_env,\n                      arguments=[dataSet]\n                      )\n\nrun = myexp.submit(config=config)\n\n<\/code><\/pre>\n<p>I get a <\/p>\n<blockquote>\n<p>Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'<\/p>\n<\/blockquote>\n<p>error that pops up 8 times, and while the job starts, it hangs for a few minutes before dying. <\/p>\n<p>The error message seems to be caused by the myexp.submit() line, there is no stack trace or explanation of why this is happening. I have found other posts saying to install the azure-ml-api-sdk pip package, however this has not fixed it for me.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Child job in Azure SDK2",
        "Question_created_time":1684786541320,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289611\/child-job-in-azure-sdk2",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, Could you explain how can we have child job in sdk2?<\/p>\n<p>I'm using child job in sdk1 to predict my test data but I couldn't find it in sdk2<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to publish a pipeline in AML Studio",
        "Question_created_time":1683679871246,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1281240\/how-to-publish-a-pipeline-in-aml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>There used to be a 'Publish' button to publish pipelines in AML Studio but seems like it is gone. How should we publish pipelines now?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/fa5b8ccf-2ffe-4021-a776-550e885b903b?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"hide messages \"This is an experimental class\"",
        "Question_created_time":1683686293646,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1281330\/hide-messages-this-is-an-experimental-class",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>when I run<\/p>\n<pre><code class=\"lang-python\">from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient.from_config(credential=DefaultAzureCredential(), enable_telemetry=False)\n<\/code><\/pre>\n<p>I get the following messages<\/p>\n<p>Found the config file in: <a href=\"https:\/\/vscode-remote+amlext-002b2f737562736372697074696f6e732f32316164386262372d633338382d343161352d613931612d6362336539323161356439612f7265736f7572636547726f7570732f6b6a667171736572356264386576612d636f6d6d6f6e2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6b6a667171736572356264386576612d616d6c2f636f6d70757465732f766e2d6436347376332d6930.vscode-resource.vscode-cdn.net\/config.json\">\/config.json<\/a> Class FeatureStoreOperations: This is an experimental class, and may change at any time. Please see <a href=\"https:\/\/aka.ms\/azuremlexperimental\">https:\/\/aka.ms\/azuremlexperimental<\/a> for more information. Class FeatureSetOperations: This is an experimental class, and may change at any time. Please see <a href=\"https:\/\/aka.ms\/azuremlexperimental\">https:\/\/aka.ms\/azuremlexperimental<\/a> for more information. Class FeatureStoreEntityOperations: This is an experimental class, and may change at any time. Please see <a href=\"https:\/\/aka.ms\/azuremlexperimental\">https:\/\/aka.ms\/azuremlexperimental<\/a> for more information.<\/p>\n<p>how can I hide these messages?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning \/ Data Science",
        "Question_created_time":1589856030190,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/27823\/machine-learning-data-science",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Qual curso e indicado para iniciantes em Machine Learning e Data Science?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating a Low Priority Server in ML Studio",
        "Question_created_time":1684925720356,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1290634\/creating-a-low-priority-server-in-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>What are the steps to create a low priority server in ML Studio? Is it possible to create one? Please provide any documentation or code snippets that may be helpful.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use a private custom docker image as environment in AzureML using the Python SDK v2",
        "Question_created_time":1684920099626,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1290456\/how-to-use-a-private-custom-docker-image-as-enviro",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I have used the Python SDK v1 for submitting job to my compute cluster on AzureML. I am now trying to migrate to SDK v2 but are having some issues with using a private custom docker image as my environment for the job.<\/p>\n<p>In v1 it looks like this:<\/p>\n<pre><code class=\"lang-python\"> \nfrom azureml.core import Environment \nfrom azureml.core.runconfig import DockerConfiguration\n# luckily they are compatible (v1 and v2\n\nenv = Environment(name=&quot;environment&quot;)\nenv.python.user_managed_dependencies = True\nenv.docker.base_image = &quot;ghcr.io\/user\/repo:latest&quot;\n\ndocker_config = DockerConfiguration(use_docker=True)\n\nenv.docker.base_image_registry.address= &quot;ghcr.io&quot;\nenv.docker.base_image_registry.username = &quot;USER&quot;\nenv.docker.base_image_registry.password = &quot;PW&quot;\n<\/code><\/pre>\n<p>and the experiment and config are the following:<\/p>\n<pre><code class=\"lang-python\">from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\nws = Workspace.from_config()\n# define and configure the experiment\nexperiment = Experiment(workspace=ws, name='day1-experiment-train')\nconfig = ScriptRunConfig(source_directory='.\/src',\n                            script='models\/train.py', \n                            compute_target='cpu-cluster',\n                            environment=env,\n                            docker_runtime_config=docker_config)\n\n#config.run_config.environment = env\n\nrun = experiment.submit(config)\n<\/code><\/pre>\n<p>How do I create a custom environment using my image from the github registry? I can't see any documentation of creating custom environment in the v2 - only in v1.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to save or log pytorch model using MLflow?",
        "Question_created_time":1684948211753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1291132\/how-to-save-or-log-pytorch-model-using-mlflow",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am in main.py at the root directory and  at main.py calling the model script to train the model. The directory looks like this<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a2de35fd-953e-4299-be3b-0c41dd09d97c?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>But I am getting an error while saving the code paths saying the directory is not found.<\/p>\n<pre><code>\n# Registering the model to the workspace\n    mlflow.pytorch.log_model(\n        pytorch_model= model,\n        registered_model_name=&quot;use-case1-model&quot;,\n        artifact_path=&quot;use-case1-model&quot;,\n        input_example=df[['Title', 'Attributes']],\n        conda_env=os.path.join(&quot;.\/dependencies&quot;, &quot;conda.yaml&quot;),\n        code_paths=&quot;.\/models&quot;\n        ]\n        \n    )\n\n    # Saving the model to a file\n    mlflow.pytorch.save_model(\n        pytorch_model= model,\n        conda_env=os.path.join(&quot;.\/dependencies&quot;, &quot;conda.yaml&quot;),\n        input_example=df[['Title', 'Attributes']],\n        path=os.path.join(args.model, &quot;use-case1-model&quot;),\n        code_paths=&quot;.\/models&quot;\n    )\n<\/code><\/pre>\n<p>Qu`estion 1: is there a need to save the code paths and extra files parameter in my case? <\/p>\n<p>Question 2: What's the right way to save the code paths directory for code_paths and extra_files parameters?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Azure ML notebook can't get tensorflow to work",
        "Question_created_time":1684382090586,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1286972\/using-azure-ml-notebook-cant-get-tensorflow-to-wor",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<pre><code>2023-05-18 03:46:51.028547: I tensorflow\/core\/platform\/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.2023-05-18 03:46:51.905585: W tensorflow\/compiler\/tf2tensorrt\/utils\/py_utils.cc:38] TF-TRT Warning: Could not find TensorR\n<\/code><\/pre>\n<p>I run into this error every time I try to import TensorFlow and when I run the model I get errors like this. <\/p>\n<pre><code>2023-05-18 03:47:15.694174: W tensorflow\/core\/framework\/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow\/compiler\/xla\/service\/gpu\/gpu_compiler.cc:618) dnn != nullptr \n<\/code><\/pre>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/0df00fff-8c14-4cf6-b693-4bb1e20a01c0?platform=QnA\">Screen Shot 2023-05-17 at 11.50.22 PM.png<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Auth problems in executing published pipelines in azure machine learning studio",
        "Question_created_time":1684911397100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1290351\/auth-problems-in-executing-published-pipelines-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have a Logic App that is triggering a published pipeline in Azure Machine Learning Studio. It is working with Azure ML Data Scientist role.<\/p>\n<p>However, I recently created a new logic app to trigger another published pipeline. The Azure ML Data Scientist or Contributor role assignment is not working anymore.<\/p>\n<p>Can you guys investigate?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy the trained model using Azure SDK v2",
        "Question_created_time":1684841540626,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289915\/unable-to-deploy-the-trained-model-using-azure-sdk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>And lastly deployment logs shows this:<\/p>\n<pre><code>Instance status:\nSystemSetup: Succeeded\nUserContainerImagePull: Succeeded\nModelDownload: Succeeded\nUserContainerStart: InProgress\n\nContainer events:\nKind: Pod, Name: Pulling, Type: Normal, Time: 2023-05-23T01:17:31.726303Z, Message: Start pulling container image\nKind: Pod, Name: Downloading, Type: Normal, Time: 2023-05-23T01:17:32.697829Z, Message: Start downloading models\nKind: Pod, Name: Pulled, Type: Normal, Time: 2023-05-23T01:20:06.535632Z, Message: Container image is pulled successfully\nKind: Pod, Name: Downloaded, Type: Normal, Time: 2023-05-23T01:20:06.535632Z, Message: Models are downloaded successfully\nKind: Pod, Name: Created, Type: Normal, Time: 2023-05-23T01:20:06.691742Z, Message: Created container inference-server\nKind: Pod, Name: Started, Type: Normal, Time: 2023-05-23T01:20:06.755508Z, Message: Started container inference-server\n\nContainer logs:\n2023-05-23T01:20:06,767937802+00:00 - rsyslog\/run \n2023-05-23T01:20:06,772188056+00:00 - gunicorn\/run \n2023-05-23T01:20:06,773563973+00:00 - nginx\/run \n2023-05-23T01:20:06,774047779+00:00 | gunicorn\/run | \n2023-05-23T01:20:06,775608299+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:06,777286120+00:00 | gunicorn\/run | AzureML Container Runtime Information\n2023-05-23T01:20:06,779026742+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:06,780637662+00:00 | gunicorn\/run | \n2023-05-23T01:20:06,782440485+00:00 | gunicorn\/run | \n2023-05-23T01:20:06,786468236+00:00 | gunicorn\/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-05-23T01:20:06,788041356+00:00 | gunicorn\/run | \n2023-05-23T01:20:06,789705877+00:00 | gunicorn\/run | \n2023-05-23T01:20:06,791375398+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n2023-05-23T01:20:06,793025919+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n2023-05-23T01:20:06,794927543+00:00 | gunicorn\/run | \n2023-05-23T01:20:07,287148945+00:00 | gunicorn\/run | CONDAPATH environment variable: \/opt\/miniconda\n\n# conda environments:\n#\n                      *  \/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\nbase                     \/opt\/miniconda\n\n2023-05-23T01:20:08,175873674+00:00 | gunicorn\/run | \n2023-05-23T01:20:08,177405680+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\naiohttp==3.8.4\naiosignal==1.3.1\nalembic==1.11.1\nargcomplete==2.1.2\nasync-timeout==4.0.2\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.22.1\nazure-graphrbac==0.61.1\nazure-identity==1.13.0\nazure-mgmt-authorization==2.0.0\nazure-mgmt-containerregistry==9.1.0\nazure-mgmt-core==1.3.0\nazure-mgmt-keyvault==9.3.0\nazure-mgmt-resource==21.0.0\nazure-mgmt-storage==20.0.0\nazureml-core==1.42.0.post1\nazureml-inference-server-http==0.8.0\nazureml-mlflow==1.42.0\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\nboto3==1.26.138\nbotocore==1.29.138\ncachetools==5.3.0\ncertifi==2023.5.7\ncffi @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/cffi_1671179356964\/work\ncharset-normalizer==3.1.0\nclick==8.1.3\ncloudpickle==2.2.1\ncmake==3.26.3\ncontextlib2==21.6.0\ncryptography==36.0.2\ndatabricks-cli==0.17.7\ndocker==5.0.3\nentrypoints==0.4\nfilelock==3.12.0\nFlask==2.2.5\nFlask-Cors==3.0.10\nfrozenlist==1.3.3\nfsspec==2023.5.0\nfuture @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/future_1673596611778\/work\ngitdb==4.0.10\nGitPython==3.1.31\ngoogle-api-core==2.11.0\ngoogle-auth==2.18.1\ngoogleapis-common-protos==1.59.0\ngreenlet==2.0.2\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==6.6.0\nimportlib-resources==5.12.0\ninference-schema==1.5\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.0\njoblib @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/joblib_1663332044897\/work\njsonpickle==2.2.0\nknack==0.9.0\nlightning-utilities==0.8.0\nlit==16.0.5\nMako==1.2.4\nMarkupSafe==2.1.2\nmlflow==1.26.1\nmlflow-skinny==2.3.2\nmpmath==1.3.0\nmsal==1.22.0\nmsal-extensions==1.0.0\nmsrest==0.6.21\nmsrestazure==0.6.4\nmultidict==6.0.4\nndg-httpsclient==0.5.1\nnetworkx==3.1\nnumpy @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/numpy_1629092056723\/work\nnvidia-cublas-cu11==11.10.3.66\nnvidia-cuda-cupti-cu11==11.7.101\nnvidia-cuda-nvrtc-cu11==11.7.99\nnvidia-cuda-runtime-cu11==11.7.99\nnvidia-cudnn-cu11==8.5.0.96\nnvidia-cufft-cu11==10.9.0.58\nnvidia-curand-cu11==10.2.10.91\nnvidia-cusolver-cu11==11.4.0.1\nnvidia-cusparse-cu11==11.7.4.91\nnvidia-nccl-cu11==2.14.3\nnvidia-nvtx-cu11==11.7.91\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==21.3\npandas==1.1.5\nparamiko==2.12.0\npathspec==0.11.1\npkginfo==1.9.6\nportalocker==2.7.0\nprometheus-client==0.16.0\nprometheus-flask-exporter==0.22.4\nprotobuf==4.23.1\npsutil==5.9.5\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/pycparser_1636257122734\/work\npydantic==1.10.7\nPygments==2.15.1\nPyJWT==2.7.0\nPyNaCl==1.5.0\npyOpenSSL==22.0.0\npyparsing==3.0.9\nPySocks==1.7.1\npython-dateutil @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/python-dateutil_1626286286081\/work\npytorch-lightning==2.0.2\npytorch-transformers==1.2.0\npytz @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/pytz_1680088766131\/work\nPyYAML==6.0\nquerystring-parser==1.2.4\nregex==2023.5.5\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrsa==4.9\ns3transfer==0.6.1\nsacremoses==0.0.53\nscikit-learn @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/scikit-learn_1630910537183\/work\nscipy @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/scipy_1628206382406\/work\nSecretStorage==3.3.3\nsentencepiece==0.1.99\nseqeval==1.2.2\nsix @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work\nsmmap==5.0.0\nSQLAlchemy==2.0.15\nsqlparse==0.4.4\nsympy==1.12\ntabulate==0.9.0\nthreadpoolctl @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/threadpoolctl_1643647933166\/work\ntorch==2.0.1\ntorchmetrics==0.11.4\ntqdm==4.63.0\ntriton==2.0.0\ntyping_extensions @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/typing_extensions_1678559861143\/work\nurllib3==1.26.9\nwebsocket-client==1.5.2\nWerkzeug==2.3.4\nwrapt==1.12.1\nxlrd==2.0.1\nyarl==1.9.2\nzipp==3.15.0\n\n2023-05-23T01:20:08,836735094+00:00 | gunicorn\/run | \n2023-05-23T01:20:08,838657201+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:08,840420508+00:00 | gunicorn\/run | Checking if the Python package azureml-inference-server-http is installed\n2023-05-23T01:20:08,842133215+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:08,843869922+00:00 | gunicorn\/run | \n2023-05-23T01:20:09,830826034+00:00 | gunicorn\/run | \n2023-05-23T01:20:09,832438140+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:09,833918246+00:00 | gunicorn\/run | AzureML Inference Server\n2023-05-23T01:20:09,835327752+00:00 | gunicorn\/run | ###############################################\n2023-05-23T01:20:09,836711457+00:00 | gunicorn\/run | \n2023-05-23T01:20:10,875997877+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.\n2023-05-23 01:20:11,049 I [10] azmlinfsrv - Loaded logging config from \/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/logging.json\n2023-05-23 01:20:11,143 I [10] gunicorn.error - Starting gunicorn 20.1.0\n2023-05-23 01:20:11,144 I [10] gunicorn.error - Listening at: http:\/\/0.0.0.0:31311 (10)\n2023-05-23 01:20:11,144 I [10] gunicorn.error - Using worker: sync\n2023-05-23 01:20:11,146 I [70] gunicorn.error - Booting worker with pid: 70\n\nAzure ML Inferencing HTTP server v0.8.0\n\n\nServer Settings\n---------------\nEntry Script Name: \/var\/azureml-app\/dependencies\/score.py\nModel Directory: \/var\/azureml-app\/azureml-models\/use-case1-model\/3\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv\/0.8.0\nCORS for the specified origins: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311\/\nScore:          POST  127.0.0.1:31311\/score\n\nInitializing logger\n2023-05-23 01:20:11,423 I [70] azmlinfsrv - Starting up app insights client\n2023-05-23 01:20:12,970 E [70] azmlinfsrv - Traceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 74, in load_script\n    main_module_spec.loader.exec_module(user_module)\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 843, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/var\/azureml-app\/dependencies\/score.py&quot;, line 10, in &lt;module&gt;\n    from config import opt\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/config.py&quot;, line 8, in &lt;module&gt;\n    from ..constants import DEFAULT_APP_ROOT\nImportError: attempted relative import with no known parent package\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 88, in setup\n    self.user_script.load_script(config.app_root)\n  File &quot;\/azureml-envs\/azureml_d587e0800be72e17d773ddca63762cd1\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 76, in load_script\n    raise UserScriptImportException(ex) from ex\nazureml_inference_server_http.server.user_script.UserScriptImportException: Failed to import user script because it raised an unhandled exception\n\n2023-05-23 01:20:12,970 I [70] gunicorn.error - Worker exiting (pid: 70)\n2023-05-23 01:20:13,162 I [10] gunicorn.error - Shutting down: Master\n2023-05-23 01:20:13,163 I [10] gunicorn.error - Reason: Worker failed to boot.\n\nAzure ML Inferencing HTTP server v0.8.0\n\n\nServer Settings\n---------------\nEntry Script Name: \/var\/azureml-app\/dependencies\/score.py\nModel Directory: \/var\/azureml-app\/azureml-models\/use-case1-model\/3\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv\/0.8.0\nCORS for the specified origins: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311\/\nScore:          POST  127.0.0.1:31311\/score\n\n2023-05-23T01:20:13,206072314+00:00 - gunicorn\/finish 3 0\n2023-05-23T01:20:13,207564233+00:00 - Exit code 3 is not normal. Killing image.\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"HOW to fix [Reconnection failed, terminal is closed. Please close tab and retry.] in machine learning",
        "Question_created_time":1684582171723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1288496\/how-to-fix-(reconnection-failed-terminal-is-closed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>HOW to fix [Reconnection failed, terminal is closed. Please close tab and retry.] in machine learning when i do traing in machine learning  after some random time i get [Reconnection failed, terminal is closed. Please close tab and retry.]<\/p>\n<p>which in return closes any running  python script and close running session<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Batch Endpoint: Configuring the output",
        "Question_created_time":1684757554160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289408\/azure-ml-batch-endpoint-configuring-the-output",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,<\/p>\n<p>I created a batch endpoint in Machine Learning Workspace and I would like to configure the output path. I follow the tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-custom-output?view=azureml-api-2&amp;tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-custom-output?view=azureml-api-2&amp;tabs=python<\/a> and under the part <strong>Creating a scoring script<\/strong>, it shows how the environment variable <strong>AZUREML_BI_OUTPUT_PATH<\/strong> is used to get the output bath. And in the part <strong>Creating the deployment<\/strong>, <strong>output_action<\/strong> is set to <strong>BatchDeploymentOutputAction.SUMMARY_ONLY<\/strong> which means that the user script will store the output. I run a sample job with this configuration and the results is written somewhere in <strong>workspaceblobstore<\/strong>. But I would like to write the results to another Storage Account. My question can I write output to another blob storage or Data Lake Storage? If so how? If this is not possible, can I somehow overwrite the environment variable <strong>AZUREML_BI_OUTPUT_PATH<\/strong> so that I can write to a specific place that I want in <strong>workspaceblobstore<\/strong>?<\/p>\n<p>Thank you for your time and help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do i know the reason about inconsistent execution times for the same code running in Azure ML Studio ?",
        "Question_created_time":1684777895253,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289578\/how-do-i-know-the-reason-about-inconsistent-execut",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<pre><code>I was trying to optimize my code using multiprocessing in python. I was successful as well in doing so, and the code which initially took 6 hours to run, was now brought down to 1hr 15mins. However that happened only on one particular day, and after that since the last two days it is again taking 5 hours to run in Azure ML studio. I am new to this platform and not able to find the reason for this inconsistency in time taken by the code to run. I have checked on the following points  - \n<\/code><\/pre>\n<ol>\n<li> No notifications or alerts from Azure regarding performance issue.<\/li>\n<li> Enough resources allocated to run my job.<\/li>\n<li> No network issue.<\/li>\n<li> No other workload is running concurrently.<\/li>\n<\/ol>\n<pre><code>I am attaching a part of my code here ..\n\n\nimport time\nimport multiprocessing as mp\nnew_df_to_pred = pd.DataFrame()\n\ndef process_data(i):\n     \n    The function running from 0 to 40000\n\n\nif __name__ == &quot;__main__&quot;:\n    start_time = time.time()\n\n    # Create a pool of workers\n    num_workers = 4\n    pool = mp.Pool(num_workers)\n\n    # Submit jobs to the pool\n    results = pool.map(process_data, range(0, 1000, 1))\n\n    # Wait for all jobs to finish\n    pool.close()\n    pool.join()\n\n    # Get the results from the jobs\n    new_df_to_pred = pd.concat(results, ignore_index=True)\n\n    end_time = time.time()\n\n    execution_time = end_time - start_time\n<\/code><\/pre>\n<p>Can someone help me on this ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to register 2 ML flow models(encoder model and xg-boost\/or any model) under one model name",
        "Question_created_time":1684397511316,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287083\/how-to-register-2-ml-flow-models(encoder-model-and",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>How can I register onehot encoder pickle file and the xg-boost model under a single model name using MLFlow?(or what is the right approach to handle encoding and then model training)<\/p>\n<p>mlflow.register_model(model_uri, args.model_name) - this registers single model under model name<\/p>\n<p>I am able to dump 2 pickle file under one model as below: <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/01806120-f412-4160-913c-f97dbc7de994?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Using MLflow, how can I register 2 models under one model name?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/06b7eb79-6ced-4788-857f-cbe9e5c67574?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No option for Idle Shutdown for Compute Instance in the ML extension or YAML definition",
        "Question_created_time":1684748875990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289364\/no-option-for-idle-shutdown-for-compute-instance-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Due to the fact I need to spin up a compute instance with no public IP - I have to use the ML extension of Azure CLI to provision it. See here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289333\/no-options-for-setting-no-public-ip-address-flag-f\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289333\/no-options-for-setting-no-public-ip-address-flag-f<\/a><\/p>\n<p>Using the ML extension and\/or the YAML schema definition for a compute instance - there is no switch to use the Idle Shutdown option I can find. This needs to be enabled somewhere please, either a command line switch for ML or in the YAML definition <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/reference-yaml-compute-instance?view=azureml-api-2\">https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/reference-yaml-compute-instance?view=azureml-api-2<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/707ed5f6-9f73-45d5-b722-46cdfca8e448?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When running my experiment I have a failure",
        "Question_created_time":1684788456923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289626\/when-running-my-experiment-i-have-a-failure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to carry out such an experiment:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/be3a8740-2161-413d-aad5-21271db530fe?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>But &quot;Select columns in dataset&quot; does't work. Previous step is ok and I can see the results of it. I don't understand why running fails exactly on &quot;Select columns in dataset&quot; . I need help in this question.<\/p>\n<p>P.S A few steps earlier &quot;Select columns in dataset&quot; also worked.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No options for setting no public IP address flag for Compute options in ARM\/Bicep templates",
        "Question_created_time":1684744346850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289333\/no-options-for-setting-no-public-ip-address-flag-f",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>From here: <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-training-vnet?view=azureml-api-2&amp;tabs=cli%2Crequired#compute-instancecluster-with-no-public-ip\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-training-vnet?view=azureml-api-2&amp;tabs=cli%2Crequired#compute-instancecluster-with-no-public-ip<\/a><\/p>\n<p>The command to create either a AMLCompute or Compute Instance contains the flag option using the (az ml command) for <code>--set enable_node_public_ip=False<\/code><\/p>\n<p>This option isn't available in ARM, Bicep or Terraform (AzAPI provider) templates - and it really needs to be for Infrastructure-as-Code provisioning<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?pivots=deployment-language-terraform\">https:\/\/learn.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?pivots=deployment-language-terraform<\/a><\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1684750280333,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>The second link you provided in the question shows how to set this flag in Bicep\/Arm\/Terraform<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?pivots=deployment-language-bicep#amlcomputeproperties\">https:\/\/learn.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?pivots=deployment-language-bicep#amlcomputeproperties<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/652a27eb-d7f4-41e6-bd28-0750b1ac5ced?platform=QnA\" alt=\"User's image\" \/><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I resolve the error ScriptExecution.DatabaseQuery.TimeoutExpired on Azure ML?",
        "Question_created_time":1680791881790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1200144\/how-do-i-resolve-the-error-scriptexecution-databas",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to implement predictive modelling to my dataset. However, when I select dataset on Automated ML Job i'm receiving this error. I have increased the time out on the data asset it self but still receiving the same error.  <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/97d725a0-d65b-4618-b5ea-817051de47dc?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the Learning path to Became a data scientist?",
        "Question_created_time":1684303074093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1286478\/what-is-the-learning-path-to-became-a-data-scienti",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>What are the learning paths in MS Learn for Data Science, Machine Learning, and Deep Learning with Python as the base programming language? How to get the Microsoft Certification.<\/p>",
        "Question_closed_time":1684304707873,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The certification path for Data Scientist includes 6 exams. <a href=\"https:\/\/learn.microsoft.com\/en-us\/certifications\/browse\/?roles=data-scientist\">https:\/\/learn.microsoft.com\/en-us\/certifications\/browse\/?roles=data-scientist<\/a><\/p>\n<p>Of these 6, the core exam is DP-100, passing it will earn you <strong>Microsoft Certified: Azure Data Scientist Associate<\/strong>.<\/p>\n<p>The DP-100 exam page features the Learning path collection with all of the modules to prepare for the exam; <a href=\"https:\/\/learn.microsoft.com\/en-us\/certifications\/azure-data-scientist\/\">https:\/\/learn.microsoft.com\/en-us\/certifications\/azure-data-scientist\/<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Microsoft Learn Explore regression with Azure Machine Learning Designer - Inference Pipeline",
        "Question_created_time":1683765347183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282292\/microsoft-learn-explore-regression-with-azure-mach",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am following the Microsoft Learning lab  <a href=\"https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html\">https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html<\/a> and am getting an error <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/df8bb021-8af2-4025-8508-81fcd754af4c?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/c89fded9-db11-4378-b18d-c4e575e7ce69?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I think the lab is several versions as Azure old and something is missing<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to integrate live stream end point and machine learning end point?",
        "Question_created_time":1684676888206,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1289015\/how-to-integrate-live-stream-end-point-and-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an azure media services - live stream - end points playback url. On the other end I have a model deployed and registered on Azure Machine Learning end point via automated ML. I want to use this model to perform object detection on the live stream and show the visualization of bounding boxes. <\/p>\n<p>Im new to azure and working on this since a while but i am not able to integrate these. <\/p>\n<p>Can anyone help with steps on how to solve this ? or is there any better way to perform object detection on live stream?<\/p>\n<p>I would prefer to stick to YoloV5s model.<\/p>\n<p>Thankyou in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data import for Azure ML",
        "Question_created_time":1684570198686,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1288431\/data-import-for-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Undergoing Data science for managers course from EDX, there given a link of google doc file to be imported on azure while using AzureML studio (classic) but import data is giving error and not importing, please help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating a handle not connect to the workspace",
        "Question_created_time":1684445274006,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287364\/creating-a-handle-not-connect-to-the-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using below code to connect to my workspace but it failed -<\/p>\n<p>Any idea what I missed?<\/p>\n<pre><code>from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n# # Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=&quot;&lt;SUBSCRIPTION_ID&gt;&quot;,\n    resource_group_name=&quot;&lt;RESOURCE_GROUP&gt;&quot;,\n    workspace_name=&quot;&lt;AML_WORKSPACE_NAME&gt;&quot;,\n)\n\n<\/code><\/pre>",
        "Question_closed_time":1684460862600,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=edebe9f5-ae1e-44d4-a89d-d7af3c288565\">@Ammar Huss  <\/a><\/p>\n<p>Thanks for reaching out to us. Have you tried to make a call? As the document describes -<\/p>\n<p>Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell).<\/p>\n<p>Please call it at least once to make the connection.<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace<\/a><\/p>\n<p>I hope this helps. Please let me know if that happened after you make a call but still not succeed. <\/p>\n<p>Thanks,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Problems submittimg azure machine learning pipelines",
        "Question_created_time":1653665897827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/867306\/problems-submittimg-azure-machine-learning-pipelin",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>I have a problem submitting my azure machine learning pipeline. I used the Import Data model to import data from a <strong>ULR via HTTP<\/strong>. When I clicked on submit, it submitted successfully with no green vertical line indication usually on the left side of the rectangular Import <strong>Data model<\/strong>. However, I got a green tick on the left pain that the job is completed. To continue building the pipeline, I added <strong>Select Columns in Dataset<\/strong> model to select the required columns. But as you can see from the screen shots, the select columns by name option is disabled and there are no names to select from.     <br \/>\nWhen I click the <strong>job details<\/strong> on the left pain on the Authoring page, it opens a read-only pipeline which cannot be edited. When I clone it, I am able to edit it but I am unable to add Select Columns in Dataset model to select the required columns as previously.     <br \/>\nI never experienced this problem with the Azure machine learning (Classic) or earlier versions of the Microsoft Azure Machine Learning Studio. I started experiencing this as soon as Microsoft changed the interface recently. Can someone please help me?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206236-image.png?platform=QnA\" alt=\"206236-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206250-image.png?platform=QnA\" alt=\"206250-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206130-image.png?platform=QnA\" alt=\"206130-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206190-image.png?platform=QnA\" alt=\"206190-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio - Turn Off Tooltips",
        "Question_created_time":1680705339303,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1198293\/azure-machine-learning-studio-turn-off-tooltips",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>How do I turn off tooltips and code completion suggestions in Azure Machine Learning Studio (.ipynb)? \nMore generally, I'd be interested in activating a catch-all &quot;Don't Help Me&quot; option. If there isn't already such a setting, consider this a formal request for one.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Child job failed in a pipeline - Could not resolve URIS of type data for assets",
        "Question_created_time":1683060744250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275231\/child-job-failed-in-a-pipeline-could-not-resolve-u",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I tried to create a pipeline based on the examples provided in the notebook 'Run a pipeline job.ipynb' under Labs\/09\/ of the repo <a href=\"https:\/\/github.com\/MicrosoftLearning\/mslearn-azure-ml.git\">https:\/\/github.com\/MicrosoftLearning\/mslearn-azure-ml.git<\/a> as mentioned in <a href=\"https:\/\/microsoftlearning.github.io\/mslearn-azure-ml\/Instructions\/09-Run-pipelines.html.%C2%A0\">https:\/\/microsoftlearning.github.io\/mslearn-azure-ml\/Instructions\/09-Run-pipelines.html.\u00a0<\/a><\/p>\n<p>However I am getting the following error message with one of the child jobs 'clean_data' :<\/p>\n<p>&quot; Could not resolve uris of type data for assets azureml:\/\/locations\/eastus\/workspaces\/{guid}\/data\/diabetes-data\/versions\/1 for run with runId {runid}&quot; Kindly assist how to resolve it.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Structure of job url in Azure Machine learning studio",
        "Question_created_time":1683771334800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282310\/structure-of-job-url-in-azure-machine-learning-stu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,<\/p>\n<p>Could you explain me what is the string - <strong>experiments\/id\/fb7d2a7b-f1ce-425d-a1a0-3292f3046f2a<\/strong> in the URL of a job in ML studio (given below) . <\/p>\n<p>In which of Azure monitor log tables, I can find above data for a given machine learning job in ML studio.<\/p>\n<p>Url:<\/p>\n<p><a href=\"https:\/\/ml.azure.com\/**experiments\/id\/fb7d2a7b-f1ce-425d-a1a0-3292f3046f2a**?wsid=\/subscriptions\/83b7d931-4059-4f8a-a873-47316b0cb181\/resourcegroups\/rg-csc-entsys-dev-da-ml\/providers\/Microsoft.MachineLearningServices\/workspaces\/wp-csc-entsys-dev-azure-ml&amp;tid=a0a180f0-657a-438b-891f-49417a6dd8bc\">https:\/\/ml.azure.com\/**experiments\/id\/fb7d2a7b-f1ce-425d-a1a0-3292f3046f2a**?wsid=\/subscriptions\/83b7d931-4059-4f8a-a873-47316b0cb181\/resourcegroups\/rg-csc-entsys-dev-da-ml\/providers\/Microsoft.MachineLearningServices\/workspaces\/wp-csc-entsys-dev-azure-ml&amp;tid=a0a180f0-657a-438b-891f-49417a6dd8bc<\/a><\/p>\n<p>Regards,<\/p>\n<p>Siva<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - V2 - yaml code for live traffic allocation for managed online endpoints (safe roll out)",
        "Question_created_time":1683041251683,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275110\/azure-ml-v2-yaml-code-for-live-traffic-allocation",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>The below CLI command allots the ML managed online endpoint &quot;blue&quot; 90% of traffic and green 10%. <\/p>\n<p><strong>I want equivalent of below code CLI code in YML file<\/strong>(safe roll out). I am able to find sample code for safe roll out traffic allocation in SDK and CLI but not YAML.<\/p>\n<ul>\n<li> az ml online-endpoint update --name $ENDPOINT_NAME --traffic &quot;blue=90 green=10&quot;<\/li>\n<\/ul>\n<p>( I am trying to automate the training\/managed endpoint deployment and allocating the traffic in yaml file, I referred below links to create online deployment but need yaml code sample to allot traffic to blue &amp; green online endpoint<\/p>\n<ul>\n<li> blue &amp; green deployment yaml (this code does not do traffic allocation) <strong>-<\/strong> <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/endpoints\/online\/managed\/sample\">https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/endpoints\/online\/managed\/sample<\/a><\/li>\n<li> safe roll out via SDK v2 - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/sdk\/python\/endpoints\/online\/managed\/online-endpoints-safe-rollout.ipynb\">https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/sdk\/python\/endpoints\/online\/managed\/online-endpoints-safe-rollout.ipynb<\/a>)<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem creating a workspace in Azure Mchine Learning Studio",
        "Question_created_time":1684438610603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287335\/problem-creating-a-workspace-in-azure-mchine-learn",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>New user who is signed up for initial Free account to get started. Trying to create a workspace in Azure Machine Learning Studio. First page has an user entry for workspace name and 3 drop lists. I cannot get the &quot;Create&quot; button to come active. What is the problem here?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to resolve the error of Compute target \/subscriptions\/a6aa5d8b-30aa-4a39-8403-b168de70bab1\/resourceGroups\/mltrial\/providers\/Microsoft.MachineLearningServices\/workspaces\/trial1\/computes\/cpu-cluster is in failed state and thus not ready for runs.",
        "Question_created_time":1684487281700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287723\/how-to-resolve-the-error-of-compute-target-subscri",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/09bb97f6-46e0-49bc-9f15-e7d3947f6ad9?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/03210314-a861-43a9-be04-811d33bb0c71?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Notebook Spark Serverless Not Working",
        "Question_created_time":1684062459113,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1284361\/azureml-notebook-spark-serverless-not-working",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Having issues trying to run Spark on my notebook. The number of executors I'm allowed seems to always stay negative and changes randomly.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/292fc7ba-a7b2-46c2-ad9d-b47e5f0c1b95?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/d0a8e907-36c0-4bc3-9562-74a8ef8b9a4e?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p> Getting the error message below when I apply these settings<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60cf0d7e-ac3f-4a4d-a8a8-5cc61bf837b8?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to split a larger-than-disk file using Azure ML?",
        "Question_created_time":1684417574803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287222\/how-to-split-a-larger-than-disk-file-using-azure-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Using Azure ML components and pipelines: How to split a larger-than-disk (PGN) file into shards and save the output files to a designated <code>uri_folder<\/code> on a blob storage? Feel free to provide any best-practices to achieve the goal.<\/p>\n<p>I set up a component and a pipeline with the following <code>yml<\/code> configuration files:<\/p>\n<p><strong>Component<\/strong><\/p>\n<pre><code>$schema: [https:\/\/azuremlschemas.azureedge.net\/latest\/commandComponent.schema.json]()\nname: split_file_to_shards\ndisplay_name: Split file to shards\nversion: 0.0.9\ntype: command\n\ninputs:\n  input_data_file:\n\ntype: uri_file\nmode: ro_mount\n\noutputs:\n  output_data_dir:\n\ntype: uri_folder\nmode: rw_mount\n\nenvironment:\n  image: mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu20.04:latest\n\ncode: .\/\ncommand: &gt;-\n  split -u -n r\/100 --verbose ${{inputs.input_data_file}} ${{outputs.output_data_dir}}\n<\/code><\/pre>\n<p><strong>Pipeline<\/strong><\/p>\n<pre><code>$schema: [https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json]()\ntype: pipeline\nexperiment_name: sample-experiment\n\ncompute: azureml:vm-cluster-cpu\n\ninputs:\n  input_data_file:\n\ntype: uri_file\npath: azureml:larger-than-disk-file@latest\n\noutputs:\n  output_data_dir:\n\ntype: uri_folder\npath: azureml:\/\/datastores\/&lt;blob_storage_name&gt;\/paths\/&lt;path_to_folder&gt;\/\n\njobs:\n  split_pgn_to_shards:\n\ntype: command\ncomponent: azureml:split_file_to_shards@latest\ninputs:\n  input_data_file: ${{parent.inputs.input_data_file}}\noutputs:\n  output_data_dir: ${{parent.outputs.output_data_dir}}\n<\/code><\/pre>\n<p><strong>Run commands<\/strong><\/p>\n<pre><code>&gt; az ml component create -f component.yml\n&gt; az ml job create -f pipeline.yml\n&gt; az ml job create -f pipeline.yml\n<\/code><\/pre>\n<p>I expect Azure ML to mount the input file on a <code>ro_mount<\/code> and write the processed files to <code>rw_mount<\/code>. I understood the remaining options <code>download<\/code> and <code>upload<\/code> to actively download the file to the VM's local disk and upload the files after processing to the mount, respectively, which is not what I want.<\/p>\n<p>The command argument <code>-u<\/code> in <code>split<\/code> is used for unbuffered write to output.<\/p>\n<p>From the monitoring Network I\/O I unexpectedly see the file being downloaded to disk.\nIn addition, I get the following error from the component:<\/p>\n<pre><code>Disk full while running job. Please consider reducing amount of data accessed, or upgrading VM SKU.\nTotal space: 6958 MB, available space: 1243 MB (under AZ_BATCH_NODE_ROOT_DIR).\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Endpoint Deployment Error (No matching distribution found for en-core-web-sm==2.1.0)",
        "Question_created_time":1678794182460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1189423\/azure-ml-endpoint-deployment-error-(no-matching-di",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have trained a model with Automated ML. When deploying the model to an endpoint, I came across with this issue: <\/p>\n<blockquote>\n<p><strong>ResourceOperationFailure<\/strong>:\u00a0ResourceNotReady: User container has crashed or terminated. Please see troubleshooting guide, available here: <a href=\"https:\/\/aka.ms\/oe-tsg#error-resourcenotready\">https:\/\/aka.ms\/oe-tsg#error-resourcenotready <\/a><em><a href=\"https:\/\/aka.ms\/oe-tsg#error-resourcenotready\">\uf35f<\/a><\/em><\/p>\n<\/blockquote>\n<p>When checking the deployment log I got the following error:<\/p>\n<pre><code>alling pip dependencies: ...working... Ran pip subprocess with arguments:['\/opt\/miniconda\/envs\/userenv\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/tmp\/condaenv.n3tlurp8.requirements.txt']Pip subprocess output:Collecting adal==1.2.7  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)Pip subprocess error:ERROR: Ignored the following versions that require a different python version: 0.7 Requires-Python &gt;=3.6, &lt;3.7; 0.8 Requires-Python &gt;=3.6, &lt;3.7; 1.19.0 Requires-Python &gt;=3.5,&lt;3.8; 1.20.0 Requires-Python &gt;=3.5,&lt;3.8; 1.20.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.21.0 Requires-Python &gt;=3.5,&lt;3.8; 1.21.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post2 Requires-Python &gt;=3.6,&lt;3.8; 1.23.0 Requires-Python &gt;=3.5,&lt;3.8; 1.23.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.24.0 Requires-Python &gt;=3.5,&lt;3.8; 1.25.0 Requires-Python &gt;=3.5,&lt;3.8; 1.25.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.26.0 Requires-Python &gt;=3.5,&lt;3.8; 1.26.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.29.0 Requires-Python &gt;=3.6,&lt;3.8; 1.29.0.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.30.0 Requires-Python &gt;=3.6,&lt;3.8; 1.31.0 Requires-Python &gt;=3.6,&lt;3.8; 1.32.0 Requires-Python &gt;=3.6,&lt;3.8; 1.33.0 Requires-Python &gt;=3.6,&lt;3.8; 1.33.1 Requires-Python &gt;=3.6,&lt;3.8; 1.33.1.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.0 Requires-Python &gt;=3.6,&lt;3.8; 1.34.0.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.1.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.35.0 Requires-Python &gt;=3.6,&lt;3.8; 1.35.1 Requires-Python &gt;=3.6,&lt;3.8; 1.36.0 Requires-Python &gt;=3.6,&lt;3.8; 1.36.1 Requires-Python &gt;=3.6,&lt;3.8; 1.37.0 Requires-Python &gt;=3.6,&lt;3.8; 1.38.0 Requires-Python &gt;=3.6,&lt;3.8\nERROR: Could not find a version that satisfies the requirement en-core-web-sm==2.1.0 (from versions: none)\nERROR: No matching distribution found for en-core-web-sm==2.1.0\n<\/code><\/pre>\n<p>I'm wondering if anyone had the same issue? How can I change the requirements.txt in an automated ML model? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error code 0058 on permutation feature importance model",
        "Question_created_time":1684368946973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1286906\/error-code-0058-on-permutation-feature-importance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, <\/p>\n<p>First off I have read the other threads on this error and seem to still have issues. I am currently attending a ML class using the Micrsoft Machine learning tool. This is my second week of this class and I have follow the instructions to build this experiment and the permutation feature importance will not run and errors out with 0058 with exit error 2. <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39af9e02-401d-4688-8689-39b1e6d53863?platform=QnA\">PFeatureImportanceError.png<\/a><\/p>\n<p>I am not sure what I am doing wrong here provided I am just following instructions with no mention of getting this error. I have also tried cleaning any missing data, still produces the result. <\/p>\n<p>The readmi class column is what I am using in the train model. <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/4f1e92d2-c51e-4cf9-8155-739a6e51b7b0?platform=QnA\">TrainModel.png<\/a><\/p>\n<p>Thank you. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to Create calculated column",
        "Question_created_time":1598247159813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/74771\/how-to-create-calculated-column",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I want to create calculated column. i have text probability field and estimated revenue field. i want to multiple estimated value with probability field. probability field has value like 10, 20, 5 etc.  <\/p>\n<p>pls guide how to create calculated column to perform these calculation.  <\/p>\n<p>thx<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Set up SSH key after compute instance was created with Advanced option \"Set up an SSH key later\"",
        "Question_created_time":1684276681760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1286303\/set-up-ssh-key-after-compute-instance-was-created",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Inside Azure ML Workspace I run Compute instance creation wizard.<\/p>\n<p>On the Advanced settings tab if one selects &quot;Enable SSH access&quot; there is a required field &quot;SSH public key source&quot;.<\/p>\n<p>There are 4 option and one of them is &quot;Set up an SSH key later&quot;. This option is not documented at all. It's not obvious what it actually does and how to set up this SSH key later after the instance was created.<\/p>\n<p>If I add my SSH public key to ~\/.ssh\/authorized_keys it remains there only until the instance is shut dow. When I start it again my public SSH key is gone and need to add again to the ~\/.ssh\/authorized_keys to be able to connect via SSH.<\/p>\n<p>What is the proper way to add SSH public key after the instance was created with Advanced option &quot;Set up an SSH key later&quot;?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Facing Trouble with Evaluate Model in Azure Machine Learning Designer",
        "Question_created_time":1662807677703,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1001826\/facing-trouble-with-evaluate-model-in-azure-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_body":"<p>Hi Everyone,    <\/p>\n<p>I'm trying to run a MNIST prediction model on the ML Designer similar to the Image Classification sample given. All my components are working except the final evaluate model. It shows an error:    <br \/>\nazureml.studio.common.error.NotScoredDatasetError: There is no score column in dataset.    <\/p>\n<p>The scored dataset to the evaluate model component is exactly the same as given in the sample pipeline. I don't know what this issue is.     <br \/>\nCould anyone help me out with the same? I'll be thankful    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ARM Template for Azure ML Workspace",
        "Question_created_time":1683812531450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282770\/arm-template-for-azure-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team<\/p>\n<p>How to enable &quot;<strong>Enable idle shutdown<\/strong>&quot; feature which is available in Azure ML Compute instance using ARM template. Is it possible to enable this feature at workspace level or only at Compute Instance level? In the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=python&amp;view=azureml-api-2#enable-idle-shutdown\">Microsoft documentation<\/a> only one line is mentioned about ARM template. I would like to give only workspace and then all the compute instances inside workspace should enable above feature using ARM template.<\/p>\n<p>Thanks in advance.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16433bbe-52e6-4cd4-9e48-42d77c8ef660?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to create an instance with SSH enabled and set and transfer the instance to another user?",
        "Question_created_time":1684277236690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1286308\/is-it-possible-to-create-an-instance-with-ssh-enab",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Inside Azure ML Workspace I run Compute instance creation wizard.<\/p>\n<p>On the Advanced settings tab if one selects &quot;Enable SSH access&quot; there is a required field &quot;SSH public key source&quot;.<\/p>\n<p>If one selects any of the options:<\/p>\n<ul>\n<li> Generate new key pair<\/li>\n<li> Use existing public key stored in Azure<\/li>\n<li> Use existing public key<\/li>\n<\/ul>\n<p> and provides an SSH key and, <strong>at the same time, selects &quot;Assign to another user&quot;<\/strong>, the wizard will fail.  <br \/>\nThe only option is to select &quot;Set up an SSH key later&quot;.<\/p>\n<p>The error is &quot;UserError: Setting SSH key at creation time is not allowed when compute instance is provisioned on behalf of another user.&quot;<\/p>\n<p>Is it possible to create an instance with SSH enabled and set and transfer the instance to another user?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio. UI. How to retrive custom model in custom component?",
        "Question_created_time":1684192925410,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1285500\/azure-ml-studio-ui-how-to-retrive-custom-model-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello. <\/p>\n<p>I work in Designer for create Pipeline. I am using my custom components in Python.  Also I registered Custom model in block Models.<\/p>\n<p>I designer I connect to blocks my model and  components (out-in)<\/p>\n<p>I use args for reading outposts.<\/p>\n<p>like path_model = args.models_output<\/p>\n<p>kmeans=joblib.load(path_model)<\/p>\n<p>But Error model does exist. <\/p>\n<p>How can I read my model correct?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML CLI v2 update environment not usable",
        "Question_created_time":1684213336220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1285691\/ml-cli-v2-update-environment-not-usable",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am using the Azure Machine Learning CLI v2 extensions<\/p>\n<p>The update environment command <code>az ml environment update<\/code> require 3 arguments <code>--name<\/code>, <code>--version<\/code>, <code>--label<\/code> but when specify all three arguments the command return an error:<\/p>\n<p><code>cli.azure.cli.core.azclierror: Cannot specify both version and label.<\/code><\/p>\n<p>When missing one of the arguments the command will return an error that require that argument<\/p>\n<p><code>cli.azure.cli.core.azclierror: the following arguments are required: --label\/-l<\/code>\n<code>cli.azure.cli.core.azclierror: the following arguments are required: --version\/-v<\/code><\/p>\n<p>This conflict makes the command unusable. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Batch Endpoint, using datastore to access an external data storage",
        "Question_created_time":1684230280513,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1285828\/ml-batch-endpoint-using-datastore-to-access-an-ext",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>I created a batch endpoint, deployment and now creating deployment job in Machine Learning Workspace. I am providing the input data via datastore to read data from an external data storage. I followed the following tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=sdk\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=sdk<\/a> and under the title <strong>Security considerations when reading data<\/strong> within the table, in the second row, identity of the job should be enough. But I am still getting authorization error when I try to read the data. Is it because I want to read from an external storage account, meaning that compute cluster should be authenticated by the external storage account as well? <\/p>\n<p>Thank you for your time and help.<\/p>",
        "Question_closed_time":1684230604866,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Yes, you are correct. In order to read data from an external storage account, the compute cluster must be authenticated by the external storage account as well. This is because the compute cluster needs to have permission to access the data in the external storage account.<\/p>\n<p>There are a few ways to authenticate the compute cluster with the external storage account. One way is to use a service principal. A service principal is an identity that can be used to access Azure resources. To create a service principal, you can use the Azure portal or the Azure CLI.<\/p>\n<p>Once you have created a service principal, you need to grant it access to the external storage account. You can do this by assigning the service principal a role in the external storage account. The role that you assign will determine what level of access the service principal has to the external storage account.<\/p>\n<p>Once you have granted the service principal access to the external storage account, you need to configure the compute cluster to use the service principal. You can do this by setting the <code>AZURE_STORAGE_ACCOUNT_CONNECTION_STRING<\/code> environment variable on the compute cluster. The value of this environment variable should be the connection string for the external storage account.<\/p>\n<p>Once you have configured the compute cluster to use the service principal, you should be able to read data from the external storage account. If you are still getting an authorization error, you can try the following:<\/p>\n<ul>\n<li> Make sure that the service principal has the correct permissions to access the external storage account.<\/li>\n<li> Make sure that the <code>AZURE_STORAGE_ACCOUNT_CONNECTION_STRING<\/code> environment variable is set correctly on the compute cluster.<\/li>\n<li> Restart the compute cluster.<\/li>\n<\/ul>\n<p>If you are still having trouble, you can contact Azure support for help.<\/p>\n<p>Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/><\/p>\n<p>and upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/><\/p>\n<p>button if you find this helpful.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"create mltable from azure blob storage using python sdk v2",
        "Question_created_time":1683877461013,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283123\/create-mltable-from-azure-blob-storage-using-pytho",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>we need an end-to-end python code for creating MLTable data asset which will be used an input for azure autoML pipeline. currently we are facing issue creating the said data asset from python sdk v2(azure-ai-ml) and reading it during autoML run. We are not able figure if the issue is with data format or way we are creating the data asset. Please help us resolve the issue.<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What should be the format for input-data while Testing the endpoints of deployed Prophet Time-series model in Azure-ML?",
        "Question_created_time":1679544037806,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1192372\/what-should-be-the-format-for-input-data-while-tes",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have trained and <strong>deployed a<\/strong> <strong>FbProphet Time-series model using Mlflow in the Azure-ML<\/strong> . The model was properly registered and logged with all the required entities. I was able to deploy the model in Azure-ML and generate the endpoints. <\/p>\n<p>My training Dataframe (which i used for training the Prophet mode) looks like :<\/p>\n<pre><code class=\"lang-python\">\ndf =  pd.DataFrame({'ds': ['2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00', '2023-01-01 03:00:00'],\n            'y': [20, 21, 19, 18]})\n<\/code><\/pre>\n<p>Now I want to test those endpoints. Under the testing-section, I see error while trying to give input. The interface for taking input looks like :<\/p>\n<pre><code>{\n  &quot;input_data&quot; : \n}\n<\/code><\/pre>\n<p>I am unable to figure out,<\/p>\n<p>exactly <em><strong>what data (please provide example) and in which format should be entered here to test my time-series prophet model.?<\/strong><\/em><\/p>\n<p>P.S. -  <strong>I know that for prediction<\/strong> <strong>prophet takes Dataframe<\/strong> (which contains dates in the column named as 'ds') as an input to predict the future values. But in the Azure-testing interface there is no provision to enter a Dataframe (or if there, i do not know how to do it). <\/p>\n<p><em>Also even for utilizing the end-points in the code I need to know the type and format of input_data required for consumption of end-points.<\/em><\/p>\n<p>I have tried many combinations and every time I am getting error. <\/p>\n<p>for e.g.<\/p>\n<ol>\n<li> using json on the data<\/li>\n<\/ol>\n<p>json.dumps({'data': df.to_dict(orient='records')})<\/p>\n<p>and feeding the its output here as :<\/p>\n<pre><code>{\n      &quot;input_data&quot;:[{&quot;ds&quot;: &quot;2021-01-01 00:00:00&quot;, &quot;y&quot;: 23.55}, {&quot;ds&quot;: &quot;2021-01-01 01:00:00&quot;, &quot;y&quot;: 26.28}]\n    }\n<\/code><\/pre>\n<p>Error - Failed to test real-time endpoint {&quot;message&quot;:&quot;only integers, slices (:), ellipsis (...), numpy.newaxis (None) and integer or boolean arrays are valid indices&quot;}<\/p>\n<p><strong>2-<\/strong> trying other combinations<\/p>\n<pre><code>{\n  &quot;input_data&quot; :{&quot;ds&quot;:{&quot;1&quot;:&quot;2023-04-01 22:00:00&quot;, &quot;2&quot;: &quot;2023-04-01 23:00:00&quot;}\n}\n<\/code><\/pre>\n<p>Error: Failed to test real-time endpoint {&quot;message&quot;:&quot;POST body could not be decoded as JSON: Expecting ',' delimiter: line 3 column 2 (char 81)&quot;}<\/p>\n<p>3- feeding only dates<\/p>\n<pre><code>{\n  &quot;input_data&quot; :[&quot;2023-04-01 22:00:00&quot;,&quot;2023-04-01 23:00:00&quot;]\n}\n<\/code><\/pre>\n<p>then<\/p>\n<p>{<\/p>\n<p>  &quot;input_data&quot; :[[1,2], [&quot;2023-04-01 22:00:00&quot;,&quot;2023-04-01 23:00:00&quot;]]<\/p>\n<p>}<\/p>\n<p>Error : Failed to test real-time endpoint {&quot;message&quot;:&quot;only integers, slices (:), ellipsis (...), numpy.newaxis (None) and integer or boolean arrays are valid indices&quot;}<\/p>\n<p><em><strong>And likewise, i tried many more ways. But not able to figure out my mistake. Please help me, what i am missing-out ? I am new to deploying a Time-Series model.<\/strong><\/em><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Submit azureml job in docker",
        "Question_created_time":1683935514566,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283400\/submit-azureml-job-in-docker",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello! I'm newbie here, so sorry if i'm askinf some silly questions!  <\/p>\n<p>I'm trying to submit a job using Azure ML in Environment which is based on my docker container which is stored in Azure Container Registry.  So the problem is that my program doesnt start in the chosen docker, it starts somewhere else as I see it. The thing is that using code below it actually creates an Environment which builds provided docker image and then in this Environment (on Azure Portal) I can see docker logs and etc, and if I want to view this Environment in code editor I can also see correct docker: <\/p>\n<pre><code>{\n    &quot;assetId&quot;: null,\n    &quot;databricks&quot;: {\n        &quot;eggLibraries&quot;: [],\n        &quot;jarLibraries&quot;: [],\n        &quot;mavenLibraries&quot;: [],\n        &quot;pypiLibraries&quot;: [],\n        &quot;rcranLibraries&quot;: []\n    },\n    &quot;docker&quot;: {  #essentially docker which  runs everything locally\n        &quot;arguments&quot;: [],\n        &quot;baseDockerfile&quot;: null,\n        &quot;baseImage&quot;: &quot;somename&quot;,\n        &quot;baseImageRegistry&quot;: {\n            &quot;address&quot;: &quot;somevalue&quot;,\n            &quot;password&quot;: &quot;somevalue&quot;,\n            &quot;registryIdentity&quot;: null,\n            &quot;username&quot;: &quot;somevalue&quot;\n        },\n        &quot;buildContext&quot;: null,\n        &quot;enabled&quot;: true,\n        &quot;platform&quot;: {\n            &quot;architecture&quot;: &quot;amd64&quot;,\n            &quot;os&quot;: &quot;Linux&quot;\n        },\n        &quot;sharedVolumes&quot;: true,\n        &quot;shmSize&quot;: &quot;2g&quot;\n    },\n    &quot;environmentVariables&quot;: {\n        &quot;EXAMPLE_ENV_VAR&quot;: &quot;EXAMPLE_VALUE&quot;\n    },\n    &quot;inferencingStackVersion&quot;: null,\n    &quot;name&quot;: &quot;somename&quot;,\n    &quot;python&quot;: {\n        &quot;baseCondaEnvironment&quot;: null,\n        &quot;condaDependencies&quot;: {\n            &quot;channels&quot;: [\n                &quot;anaconda&quot;,\n                &quot;conda-forge&quot;\n            ],\n            &quot;dependencies&quot;: [\n                &quot;python=3.8.13&quot;,\n                {\n                    &quot;pip&quot;: [\n                        &quot;azureml-defaults&quot;\n                    ]\n                }\n            ],\n            &quot;name&quot;: &quot;project_environment&quot;\n        },\n        &quot;condaDependenciesFile&quot;: null,\n        &quot;interpreterPath&quot;: &quot;python&quot;,\n        &quot;userManagedDependencies&quot;: false\n    },\n    &quot;r&quot;: null,\n    &quot;spark&quot;: {\n        &quot;packages&quot;: [],\n        &quot;precachePackages&quot;: true,\n        &quot;repositories&quot;: []\n    },\n    &quot;version&quot;: null\n}\n\n<\/code><\/pre>\n<p>I use this container  locally to run the code, but for some reason when i'm trying to run the code in Azure ML it doesnt work for me. (it tell me that pandas is not installed, while it is installed in the provided docker) Below you can find code which I'm using. <\/p>\n<pre><code>docker_env = Environment(&quot;example&quot;)\n\ndocker_env.docker.enabled = True\ndocker_env.docker.base_image = docker_image_name\ndocker_env.docker.base_image_registry.address = docker_registry_address\ndocker_env.docker.base_image_registry.username = docker_registry_username\ndocker_env.docker.base_image_registry.password = docker_registry_password\ndocker_env.register(workspace=ws)\n\ncompute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6s_v3',)\n# create the cluster\ncompute_target = ComputeTarget.create(ws, cluster_name, compute_config)\ncompute_target.wait_for_completion(show_output=True)\n\n# Create an experiment\nexperiment_name = 'example'\nexperiment = Experiment(ws, name=experiment_name)\n\n# Set up for training script and parameters\nscript_folder = script_folder\n\n# Instantiate PyTorch estimator with upload of final model to a specified blob storage container (this can be anything)\nestimator = ScriptRunConfig(\n    source_directory=script_folder,\n    compute_target=compute_target,\n    command='.\/train_cloud.sh',\n    environment=docker_env,\n)\n\nrun = experiment.submit(estimator)\nprint(run.get_details())\n<\/code><\/pre>",
        "Question_closed_time":1684003046146,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>It seems like your Azure ML job is not recognizing the environment you've defined and hence, not finding the required libraries like Pandas inside your Docker image.<\/p>\n<p>You've registered the environment with docker_env.register(workspace=ws). Ensure that this registration is successful and the environment is indeed available in your workspace.<\/p>\n<p>In the environment definition, userManagedDependencies is set to False. This means Azure ML is expecting to manage the Python dependencies for you. Since you are providing a Docker image with dependencies pre-installed, try setting userManagedDependencies to True:<\/p>\n<pre><code>docker_env.python.userManagedDependencies = True\n<\/code><\/pre>\n<p>You're also providing a conda dependencies file. This could be conflicting with the libraries in your Docker image. If your Docker image already includes all the necessary dependencies, try removing the python field from the environment definition or setting baseCondaEnvironment to None:<\/p>\n<pre><code>docker_env.python.baseCondaEnvironment = None\n\n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error 500 when publishing experiments on machine learning studio",
        "Question_created_time":1684032099736,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283895\/error-500-when-publishing-experiments-on-machine-l",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>whenever I try to publish experiments to the gallery on machine learning studio I keep receiving this error <\/p>\n<p>Service call failed. Error 500 (InternalServerError) when requesting \/packages?api-version=2.0&amp;experimentId=7094971d402a41b88dc458a25a989fa4.f-id.a555478e991f4c5cb89b7fec31ae6fa1&amp;clearCredentials=true&amp;newExperimentName=HW%237.1%20FBFS&amp;forCommunity=true<\/p>\n<p>I've tried on a new browser, a different device and remaking the experiment and I'm still getting the error.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is Azure Machine Learning Python SDK v1 still supported",
        "Question_created_time":1683743681150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282220\/is-azure-machine-learning-python-sdk-v1-still-supp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I followed this page and example (section &quot;Service Principal Authentication&quot;)<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb<\/a><\/p>\n<pre><code>import os\nfrom azureml.core.authentication import ServicePrincipalAuthentication\n\nsvc_pr_password = os.environ.get(&quot;AZUREML_PASSWORD&quot;)\n\nsvc_pr = ServicePrincipalAuthentication(\n    tenant_id=&quot;my-tenant-id&quot;,\n    service_principal_id=&quot;my-application-id&quot;,\n    service_principal_password=svc_pr_password)\n\n\nws = Workspace(\n    subscription_id=&quot;my-subscription-id&quot;,\n    resource_group=&quot;my-ml-rg&quot;,\n    workspace_name=&quot;my-ml-workspace&quot;,\n    auth=svc_pr\n    )\n\nprint(&quot;Found workspace {} at location {}&quot;.format(ws.name, ws.location))\n<\/code><\/pre>\n<p>The print works fine. However, when I try to get datastore like below, it times out after 60sec. Why is that? <\/p>\n<pre><code>print(ws.datastores)\n\n&gt;&gt;&gt;\n.\n.\n\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/core\/workspace.py&quot;, line 1102, in datastores\n    datastore.name: datastore for datastore in _DatastoreClient.list(self)}\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/data\/datastore_client.py&quot;, line 668, in list\n    dss, ct = _DatastoreClient._list(workspace, ct, 100)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/data\/_exception_handler.py&quot;, line 16, in decorated\n    return f(*args, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/data\/datastore_client.py&quot;, line 938, in _list\n    client = _DatastoreClient._get_client(ws, auth, host)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/data\/datastore_client.py&quot;, line 977, in _get_client\n    host = host or host_env or get_service_url(\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 120, in get_service_url\n    return cached_service_object.get_cached_service_url(workspace_scope, service_name,\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 282, in get_cached_service_url\n    return self.get_cached_services_uris(arm_scope, service_name, unique_id=unique_id,\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 182, in wrapper\n    return test_function(self, *args, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 257, in get_cached_services_uris\n    cache[cache_key][DEFAULT_FLIGHT] = super(CachedServiceDiscovery, self).discover_services_uris_from_arm_scope(arm_scope, discovery_url)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 138, in discover_services_uris_from_arm_scope\n    return self.discover_services_uris(discovery_url)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_base_sdk_common\/service_discovery.py&quot;, line 141, in discover_services_uris\n    status = ClientBase._execute_func(requests.get, discovery_url)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 375, in _execute_func\n    return cls._execute_func_internal(\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 368, in _execute_func_internal\n    left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 400, in _handle_retry\n    raise error\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 359, in _execute_func_internal\n    response = func(*args, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/requests\/api.py&quot;, line 73, in get\n    return request(&quot;get&quot;, url, params=params, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/requests\/api.py&quot;, line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/requests\/sessions.py&quot;, line 587, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/requests\/sessions.py&quot;, line 701, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;\/opt\/anaconda3\/lib\/python3.9\/site-packages\/requests\/adapters.py&quot;, line 547, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError(60, 'Operation timed out'))\n<\/code><\/pre>\n<p>I tried SDK v2 and I can access datastore. Configuration like tenant_id, service principal id\/password, subscriptionid, resourcegroup, workspace_name are the same.<\/p>\n<pre><code>\nml_client = MLClient.from_config(credential=credential)\n.\n.\nprint(ml_client.datastores.get(&quot;workspaceblobstore&quot;))\n\n&gt;&gt;&gt;\nAzureBlobDatastore({'type': &lt;DatastoreType.AZURE_BLOB: 'AzureBlob'&gt;, 'name': 'workspaceblobstore', 'descriptio\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Forecasting issue with AutoML",
        "Question_created_time":1683797061180,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282464\/forecasting-issue-with-automl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to forecast points over a dataset. One of my column is &quot;home&quot;, a column full of 0 or 1 (boolean). I receive the error of having only defined values at the end of the dataset for this column while it is false since I checked over it and I got a value (0 or 1) for each row of my dataset. This column is the only boolean type of my dataset. <\/p>\n<p>Anyone has an idea on why I am receiving this error ? The tip to fix it is to remove the column but I am loosing key information for prediction later on...  <\/p>\n<p>Error message:<\/p>\n<p>The dataset contains column(s) which have values only at the end of the dataset: ['home']. Please remove these column(s) and run the AutoML experiment again.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data Science Learning Path",
        "Question_created_time":1596221270310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/56400\/data-science-learning-path",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>What are the learning paths in MS Learn for Data Science, Machine Learning, Deep Learning with Python as the base programming language<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error loading workspace - Service temporarily unavailable",
        "Question_created_time":1683768214506,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282302\/error-loading-workspace-service-temporarily-unavai",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>When I tried to open a newly created workspace hrml-001 from the Machine Learning Studio, it failed with the following error:<\/p>\n<p>Error loading workspace  <br \/>\nService temporarily unavailable. Please try again later  <br \/>\n<strong>Trace ID\u00a0:<\/strong>\u00a0fb772df3-9119-416f-a0f7-21b0cc7fc55b<strong>Client request ID\u00a0:<\/strong>\u00a0f711f51e-1fa0-4bdf-8e1b-c4f271a5cbef<\/p>\n<p>I also found there was another workspace hrml01, which had already been deleted from the Azure Portal but still existing in the Machine Learning Studio. The issue happened since I deleted the hrml01. Not sure if it was the cause of the problem. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to parse the response from the Azure ML Web Service in Azure Stream Analytics",
        "Question_created_time":1664971317523,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1036188\/unable-to-parse-the-response-from-the-azure-ml-web",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_body":"<p>Hi, using Azure ML Studio I have created an endpoint for a model generated with automated ML. The model works fine in test (consume) - provides an expected outcome. Then I created a Stream Analytics query using the function to consume the same ML endpoint. However when I test the Stream Analytics query I receive the following error:    <\/p>\n<p>&quot;Callout failed within query runner. An error was encountered while calling the Azure ML web service. An error occurred when parsing the Azure ML web service response. Please check your Azure ML web service and data model. The content of the response from the ML web service should be a JSON array. The response received from the Web Service is: {&quot;Results&quot;: [&quot;none&quot;, &quot;none&quot;, &quot;none&quot;]} Parameter name: result&quot;    <\/p>\n<p>The result I am getting is fine - as expected - but the problem seems to be with parsing the result.    <br \/>\nSo by reading the docs I understand the desired output format from ML endpoint is JSON Array like this [&quot;none&quot;, &quot;none&quot;, &quot;none&quot;], while I am getting a JSON object. {&quot;Results&quot;: [&quot;none&quot;, &quot;none&quot;, &quot;none&quot;]}     <br \/>\nThe question is, can I (how I) modify the output format (swagger?) to have it return the json array? The model was calculated by automated ML (no-code)     <\/p>\n<p>For the record the Stream Analytics query is like this:    <\/p>\n<p>SELECT udf.pdmpredict(TRY_CAST(inputArray AS record))    <br \/>\nINTO [pdm-predict-data]    <br \/>\nFROM ModelInput    <br \/>\nWHERE inputArray is not null    <\/p>\n<p>udf.pdmpredict is my ASA ML function created in accordance to this article: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf\">https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf<\/a>    <\/p>\n<p>Any ideas will be greatly appreciated!    <br \/>\nThanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Local run in azureml sdk2",
        "Question_created_time":1683956536416,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283590\/local-run-in-azureml-sdk2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to upgrade local run of my project to sdk2 based on the link below: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-local-runs?view=azureml-api-2\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-local-runs?view=azureml-api-2<\/a><\/p>\n<pre><code class=\"lang-python\">from azure.ai.ml.entities import Environment\nfrom azureml.core.runconfig import RunConfiguration\n\nif run_type == &quot;local&quot;:\n    custom_env_name = 'azure_ml_sdk2'\n    myenv = Environment(\n    image='mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04',\n    conda_file='conda.yml',\n    name=custom_env_name,\n\n  )\n<\/code><\/pre>\n<p>but i get this error:<\/p>\n<pre><code>Docker was not found on the target, check that it is installed and on the path.\n\n[2023-05-08T15:16:21.404591] Logging error in history service: SystemExit: 1 \n<\/code><\/pre>\n<p>I checked both the installation and the path, but I don't know what the problem is<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"maximum of 1 core available for compute cluster in Azure Machine Learning Studio",
        "Question_created_time":1683934877780,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1283397\/maximum-of-1-core-available-for-compute-cluster-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am trying to create an auto-ml job on azure ml studio. However, I see that there is a maximum of 1 core available for compute cluster. Is it supposed to be that way or can I increase the cores?  <br \/>\nThanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to rerun successful AzureML Pipeline",
        "Question_created_time":1683842694076,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282954\/how-to-rerun-successful-azureml-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a successful pipeline that writes files to Blob storage. If I delete the files in blob storage and try to rerun the pipeline, the pipeline run is cached so the pipeline doesn't actually rerun. Is there a way to force rerun the pipeline?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure - VS Code -  'No subscriptions were found'",
        "Question_created_time":1620124730477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/382060\/azure-vs-code-no-subscriptions-were-found",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to run an experiment with Azure Machine Learning and using Visual Studio Code.  <\/p>\n<p>I am on a free trial subscription which is still in effect - my subscription is not empty as I have created resource groups to experiment with Azure Machine Learning service.  <\/p>\n<p>I have installed 'Azure Machine Learning' visual studio code extension, I can sign in (email address of my Azure account appears in the Status Bar) BUT the subscription does not appear in the Azure explorer, neither can I choose a subscription. I get an error 'No subscriptions were found. Set up your account at http..'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Missing ODBC drivers in Azure ML Compute Instances",
        "Question_created_time":1683744684393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282225\/missing-odbc-drivers-in-azure-ml-compute-instances",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Trying to connect via ODBC to a synapse dedicated SQL pool using python SQL Alchemy.  <\/p>\n<p>The connection string for the dedicated SQL pool specifies 'ODBC Driver 13 for SQL Server', which produces the errorr 'Can't open lib 'ODBC Driver 13 for SQL Server' : file not found'.  <\/p>\n<p>If I use 'ODBC Driver 17 for SQL Server', the compute can find the driver but there is a login timeout error. This might be from the different driver.  <\/p>\n<p>How do I install the 'ODBC Driver 13 for SQL Server' onto the remote compute instance?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issues for implementing a real-time inference pipeline! The DEPLOY button does nothing!",
        "Question_created_time":1683692664093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1281429\/issues-for-implementing-a-real-time-inference-pipe",
        "Question_score_count":5,
        "Question_answer_count":1,
        "Question_comment_count":11,
        "Question_body":"<p>Microsoft Azure Support,<\/p>\n<p>I am currently learning to use Azure Cloud, specifically Microsoft Azure Machine Learning Studio. I am using the example dataset &quot;Automobile price data&quot; and have successfully completed a classic training pipeline, which includes the following blocks: &quot;Select Columns in Dataset&quot;, &quot;Clean Missing Data&quot;, &quot;Normalize Data&quot;, &quot;Split Data&quot;, &quot;Linear Regression&quot;, &quot;Train Model&quot;, &quot;Score Model&quot;, and &quot;Evaluate Model&quot;. I have also successfully created a real-time inference pipeline, which includes an &quot;Enter Data Manually&quot; block, a &quot;Web Service Input&quot; block, an &quot;Execute Python Script&quot; block code, and a &quot;Web Service Output&quot; block.<\/p>\n<p>However, I am encountering an issue when I try to deploy the pipeline for inference using the &quot;Set up real-time endpoint&quot; window. Specifically, when I click on the &quot;Deploy&quot; button, nothing happens and the same window remains open. My setup is &quot;Deploy new real-time endpoint&quot; with the following details: Name: predict-auto-price, Description: Auto Price Regression, Compute type: Azure Container Instance.<\/p>\n<p>I have tried creating a new Workspace, as well as checking the access policies and permissions on the resources used in the pipeline and deployment, but the issue persists. I am using an Azure Free Account with 200 USD of credit, and I still have more than 190 USD of credit remaining.<\/p>\n<p>I would greatly appreciate your help in resolving this issue, as my goal is to finish the Coursera DP-100 specialization and apply for the Data Science Azure Certification.<\/p>\n<p>Thank you for your attention to this matter.<\/p>\n<p>--<\/p>\n<p>Carlos Alanis<\/p>\n<p>Attach some images: <\/p>\n<p><strong>Pipeline Completed without errors:<\/strong><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85dc896d-a94e-4372-8249-0b2de8dc9438?platform=QnA\" alt=\"real time inference pipeline completed\" \/><\/p>\n<p><strong>Coursera Instructions:<\/strong><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/e1482fa9-bca7-44c0-a85a-4482807cbb95?platform=QnA\" alt=\"Coursera instructions\" \/><\/p>\n<p><strong>Set up real-time endpoint WINDOW:<\/strong> <\/p>\n<p><strong>DEPLOY BUTTON UNPRESSED:<\/strong> <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/75d73443-c414-4064-9a55-3589092a87c1?platform=QnA\" alt=\"set up real time endpoint - unpressed button\" \/><\/p>\n<p><strong>DEPLOY BUTTON PRESSED:<\/strong><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/3f429b37-2bd9-4012-8d6d-2afdbcdf6b14?platform=QnA\" alt=\"set up real time endpoint - PRESSED DEPLOY button\" \/><\/p>\n<p><strong>BUT NOTHING HAPPENS!!!<\/strong> <\/p>\n<p><strong>ALSO I SHARE YOU THE WORKSPACE OVERVIEW:<\/strong> <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/cfd21661-f06c-4cd5-97ab-1ad2b953230e?platform=QnA\" alt=\"workspace overview\" \/><\/p>\n<p>I hope that some people of the expert team can Help me, Thank you! <\/p>",
        "Question_closed_time":1683799513366,
        "Answer_score_count":3.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=8f9f275d-8a35-4900-94e8-03effa4fecb8\">@Carlos Alanis  <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d8849772-db6e-4cbc-aac4-7e2bbe39dc8a\">Rania Boukhriss<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=c23a88da-a1fe-4209-9289-829c28dfa73b\">Carlos Garc\u00eda Gonz\u00e1lez<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=259d2834-c6dc-4038-b068-fe422681470d\">anzilparviz<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=f1b6c4a4-3330-4115-9b7a-eb63e63a4faa\">SpaceBuddha<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=c057ba5f-2c81-43c2-a518-cd25ef60490f\">jaime reinoso<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=a5ece606-8fef-4154-982f-69ded88859d4\">Cesar Olivares Espinosa<\/a> The hotfix deployment is complete. Could you please retry the Deployment action? If you still face any issues please do let us know the region of your workspace. Thanks!! <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/3343ee39-8aff-4859-9a73-1afd64140fad?platform=QnA\" alt=\"test_deploy_hotfix2\" \/><\/p>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"deploy button not working while deploying model to a web service",
        "Question_created_time":1683706121866,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1281560\/deploy-button-not-working-while-deploying-model-to",
        "Question_score_count":6,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>When I am trying to deploy the model in Azure machine learning, the deploy button is active, I don't have any mistakes, but nothing happens after I press the deploy button.  <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/61e1400c-dbf5-4b8e-b362-42f18f32d383?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Cognitive Language Service NER failed to detect certain entities",
        "Question_created_time":1683818600500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1282834\/azure-cognitive-language-service-ner-failed-to-det",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Azure Cognitive Language Service NER failed to detect certain entities<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why am I getting a \"\"Not enough quota available... . Current usage\/limit: 0\/6. Additional needed: 8\" when my YAML specifies `instance_count: 1`? Why does it think I need 8?",
        "Question_created_time":1683588223150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1280148\/why-am-i-getting-a-not-enough-quota-available-curr",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to create a simple deployment. In my deployment.yaml, I have: <\/p>\n<pre><code>instance_type: Standard_E4s_v3\ninstance_count: 1\n\n<\/code><\/pre>\n<p>When I run, the deployment fails with &quot;&quot;VmSize&quot;:[&quot;Not enough quota available for Standard_E4s_v3 in SubscriptionId xxxx. Current usage\/limit: 0\/6. Additional needed: 8&quot; I don't have <em>any<\/em> CPU compute in this subscription. The error message says I'm using 0 of my 6 but am asking for 8? But I'm not asking for 8. Where did 8 come from? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issues for implementing a real-time inference pipeline! The DEPLOY button is non-functional !!!!!!!",
        "Question_created_time":1683716052123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1281801\/issues-for-implementing-a-real-time-inference-pipe",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>deploy button doesn't show anything !!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how can I use data assets in azure ml registries in azure ml designer?",
        "Question_created_time":1683630259513,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1280703\/how-can-i-use-data-assets-in-azure-ml-registries-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created some uri_folder data asset in my custom  Azure ml registry.  <br \/>\nAlso, I have created some components in my registry. <\/p>\n<p>When I want to create a new custom pipeline in Azure ML Designer, I can use my custom component, but I can't see my registered data assets. <\/p>\n<p>How can I use shared\/Registered data assets in designer in  multiple workspaces?  <br \/>\nThanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Porqu\u00ea Azure Machine Learning n\u00e3o est\u00e1 deixando implantar nenhum modelo de Machine Learning?",
        "Question_created_time":1683600971300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1280209\/porqu-azure-machine-learning-n-o-est-deixando-impl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>O Azure Machine Learning n\u00e3o est\u00e1 deixando implantar nenhum modelo de Machine Learning. O bot\u00e3o implantar at\u00e9 habilita para clicar, mas ao clicar ele n\u00e3o executa nada.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AZUREML_MODEL_DIR",
        "Question_created_time":1683066281930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275251\/azureml-model-dir",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_body":"<p>I am trying to deploy a model into ACI, the scoring script has the following init() function:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/7028b571-9379-4c2d-94ff-51471d131981?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>The deployment fails with the following error: <\/p>\n<pre><code>File &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/xyz1\/code\/Users\/xyz\/chapter12\/score.py&quot;, line 8, in init\n    model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;model\/model.joblib&quot;)\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/posixpath.py&quot;, line 76, in join\n    a = os.fspath(a)\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n\n<\/code><\/pre>\n<p>It seems that the AZUREML_MODEL_DIR variable does not get created during the deployment.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/67a5ce38-ad37-4075-ac95-a39c1a91784f?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Any help is appreciated. Thanks a lot.<\/p>\n<p>Hesham<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Service configuration D365 f&o demand forecasting job stuck",
        "Question_created_time":1683111112793,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275578\/azure-machine-learning-service-configuration-d365",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey Folks,<\/p>\n<p>i have configured AzureML workspace for demand forecasting following this (<a href=\"https:\/\/learn.microsoft.com\/en-us\/dynamics365\/supply-chain\/master-planning\/demand-forecasting-setup\">https:\/\/learn.microsoft.com\/en-us\/dynamics365\/supply-chain\/master-planning\/demand-forecasting-setup<\/a>). Workspace configuration completed and as per step-5 I am executing (<strong>parameters.py)<\/strong> and this job is executing till yesterday. <\/p>\n<p>I am doubting this job is stuck but not sure from where I can check if the job is stuck at what step. How can I fix this issue?<\/p>\n<p>Any help would be appreciated. <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/b6bcacc2-8755-458c-967f-147d212c70ce?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export Labels Programmatically",
        "Question_created_time":1683236542663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1276329\/export-labels-programmatically",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>In Azure ML Studio, I can export and download a COCO file for a data labeling project. <\/p>\n<p>Is there any API to do this programmatically?  Is it possible to set this up with another format?<\/p>\n<p>Thank you,<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connection errors when connecting locally from VSC to Azure ML via MLflow tracking server",
        "Question_created_time":1683569095586,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1280054\/connection-errors-when-connecting-locally-from-vsc",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I'm experiencing problems when following the basic instructions from Azure ML docs to work locally on Python notebooks and track them in Azure ML via MLflow.<\/p>\n<p>I'm using a conda environment, it's activated and used as kernel in VSC.<\/p>\n<p>All modules from the docs are installed.<\/p>\n<p>I also have the config.json file in the same folder as the notebook.<\/p>\n<p>Azure ML standard workspace is selected in VSC (I think authentication is also okay, because i can see the whole menu tree from Azure ML in VSC)<\/p>\n<p>I'm on a Mac<\/p>\n<p><a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-configure-tracking?view=azureml-api-2&amp;tabs=cli%2Cmlflow<\/a><\/p>\n<p><a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-cli-runs?view=azureml-api-2&amp;tabs=interactive%2Ccli<\/a><\/p>\n<p>When running the follow code:<\/p>\n<pre><code>from azure.ai.ml import MLClient\n\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient.from_config(credential=DefaultAzureCredential())\n\nmlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n<\/code><\/pre>\n<p>I get this error:<\/p>\n<p><em>DefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. Visit <a href=\"\">https:\/\/aka.ms\/azsdk\/python\/identity\/environmentcredential\/troubleshoot<\/a> to troubleshoot.this issue.<\/em><\/p>\n<p>And further on:<\/p>\n<p><em>Content: {&quot;error&quot;:&quot;invalid_grant&quot;,&quot;error_description&quot;:&quot;AADSTS700082: The refresh token has expired due to inactivity. The token was issued on 2020-10-29T05:28:47.8757835Z and was inactive for 90.00:00:00.\\r\\nTrace ID: 3f2221fa-0d29-4934-893e-72c565a44a00\\r\\nCorrelation ID: dc908d2c-927e-4c55-a605-8e36bfcd0467\\r\\nTimestamp: 2023-05-08 14:41:48Z&quot;,&quot;error_codes&quot;:[700082],&quot;timestamp&quot;:&quot;2023-05-08 14:41:48Z&quot;,&quot;trace_id&quot;:&quot;3f2221fa-0d29-4934-893e-72c565a44a00&quot;,&quot;correlation_id&quot;:&quot;dc908d2c-927e-4c55-a605-8e36bfcd0467&quot;,&quot;error_uri&quot;:&quot;https:\/\/login.microsoftonline.com\/error?code=700082&quot;} To mitigate this issue, please refer to the troubleshooting guidelines here at <a href=\"\">https:\/\/aka.ms\/azsdk\/python\/identity\/defaultazurecredential\/troubleshoot.<\/a><\/em><\/p>\n<p>Thereafter I just set the tracking URI by copying it from the workspace. Then when running:<\/p>\n<pre><code>\nmlflow_tracking_uri = 'azureml:\/\/westeurope.api.azureml.ms\/mlflow\/v1.0\/subscriptions\/bb026f63-bb96-4a45-9ab1-aed3ded1f99e\/resourceGroups\/OSAP-Student-Env\/providers\/Microsoft.MachineLearningServices\/workspaces\/demo_workspace'\n\nimport mlflow\n\nmlflow.set_tracking_uri(mlflow_tracking_uri)\n\nmlflow.set_experiment(experiment_name='experiment_with_mlflow')\n<\/code><\/pre>\n<p>I get this error:<\/p>\n<p><em>UnsupportedModelRegistryStoreURIException: Model registry functionality is unavailable; got unsupported URI 'azureml:\/\/westeurope.api.azureml.ms\/mlflow\/v1.0\/subscriptions\/bb026f63-bb96-4a45-9ab1-aed3ded1f99e\/resourceGroups\/OSAP-Student-Env\/providers\/Microsoft.MachineLearningServices\/workspaces\/demo_workspace' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See <a href=\"\">https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage<\/a> for how to run an MLflow server against one of the supported backend storage locations.<\/em><\/p>\n<p><strong>Why is the standard code not working? I really have no clue what's wrong here. Does anybody experienced the same or knows how to solve this issue?<\/strong><\/p>\n<p>Many thanks for the person(s) who can help me!:)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to fix the bug for float values in confusion matrix in Azure ML service?",
        "Question_created_time":1681125906966,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1213742\/how-to-fix-the-bug-for-float-values-in-confusion-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I work with Azure Machine Learning Service for modeling. To track and analyze the result of a binary classification problem, I use a method named <strong>score-classification<\/strong> in <em>azureml.training.tabular.score.scoring<\/em> library. I invoke the method like this:<\/p>\n<pre><code>metrics = score_classification( y_test, y_pred_probs, metrics_names_list, class_labels, train_labels, sample_weight=sample_weights, use_binary=True)\n\n<\/code><\/pre>\n<p>Input arguments are: <\/p>\n<ul>\n<li> <em>y_test<\/em> is an array of 0 and 1. <\/li>\n<li> <em>y_pred<\/em> is an array of float values for each item. <\/li>\n<li> <em>metrics_names_list<\/em> is the list of the name of the metrics I want to calculate:['f1_score_classwise', 'confusion_matrix']. <\/li>\n<li> <em>class_labels<\/em> is a two-item array of [0, 1].<\/li>\n<li> <em>train_labels<\/em> is a two-item list of ['False', 'True']. <\/li>\n<\/ul>\n<p>When it calculates the metrics I sent as <em>metrics_names_list<\/em>, the results are shown in the Azure ML portal in the metrics page. <\/p>\n<p>Confusion matrix is one of the metrics I draw each time. It has a combo box for the representation. This combo box could be set as <strong>Raw<\/strong> to show the number of items for each cell, and <strong>Normalized<\/strong> to show the percentage of the cells.<\/p>\n<p>The problem is that I see float value for the Raw configuration of this matrix! I do not know how to handle this issue? <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92357b82-b9f4-4cc4-8630-9619d4584bfa?platform=QnA\" alt=\"enter image description here\" \/><\/p>",
        "Question_closed_time":1681173478840,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=e2b5cca4-3304-4fb3-9c9d-7d0f840d76b8\">@Elahe Dorani  <\/a><\/p>\n<p>Thanks for reaching out to us, I am not very clear about your question, so if I am not in the right way, please let me know. It sounds like the issue you are experiencing is that the confusion matrix is being displayed as float values instead of integers when you select the &quot;Raw&quot; option in the combo box.\nOne possible explanation for this behavior is that the <strong><code>score_classification<\/code><\/strong> function is returning the confusion matrix as a numpy array of float values instead of integers. This could happen if the function is doing some kind of normalization or scaling of the values.<\/p>\n<p>To address this issue, you could try converting the confusion matrix to integers before passing it to the <strong><code>score_classification<\/code><\/strong> function. You can use the numpy <strong><code>round<\/code><\/strong> function to round the float values to the nearest integer:<\/p>\n<pre><code>pythonCopy code\nconfusion_matrix = np.round(confusion_matrix).astype(int)\n<\/code><\/pre>\n<p>Then, when you call the <strong><code>score_classification<\/code><\/strong> function, pass in the rounded confusion matrix instead of the original one.<\/p>\n<p>If this does not work, another option is to modify the <strong><code>score_classification<\/code><\/strong> function to return the confusion matrix as integers instead of floats. You can do this by using the numpy <strong><code>astype<\/code><\/strong> function to convert the matrix to the <strong><code>int<\/code><\/strong> data type:<\/p>\n<pre><code>arduinoCopy code\nconfusion_matrix = confusion_matrix.astype(int)\n<\/code><\/pre>\n<p>I hope this helps.<\/p>\n<p>Regards,\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to convert a TensorFlow Data and BatchDataset into Azure DataTable ?",
        "Question_created_time":1681270742813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1221752\/how-to-convert-a-tensorflow-data-and-batchdataset",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am training a model using Azure PCA-based Anomaly Detection module and streaming the data for model training and evaluation using Kafka. The train and test dataset are in Azure DataTable format. How do I convert the tf BatchDataset into an Azure DataTable? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"getting access to std_log.txt programmatically",
        "Question_created_time":1683133611653,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275723\/getting-access-to-std-log-txt-programmatically",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>I am running my experiments on a compute cluster using <code>azure.ai.ml.command<\/code>. My script uses <code>lightgbm<\/code> and <code>Optuna<\/code> for hyperparameter tuning.  Intermediate output is written to stdout (not using <code>logging<\/code> package) which I am able to see in std_log.txt in the UI.  Is there a way to programmatically grab this file and move it to a different location?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/c1c4ea66-8db1-4200-a3e9-2c55e66226bc?platform=QnA\" alt=\"Screenshot 2023-05-03 at 1.03.54 PM\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to create a presigned url for Azure machine learning studio",
        "Question_created_time":1683534693673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1279783\/is-it-possible-to-create-a-presigned-url-for-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I wanted to know can we create a pre signed url for azure machine learning studio, I can see a studio url in ui but that requires user to sign in to access studio. Can we facilitate access to studio through presigned url which doesn\u2019t requires sign in to azure portal?<\/p>\n<p>This is possible in AWS Sagmaker studio, so wanted to know if same is possible in Azure ML Studio?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"accidentally deleted azureml_py38 conda env",
        "Question_created_time":1683262509120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1276395\/accidentally-deleted-azureml-py38-conda-env",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,<\/p>\n<p>My compute instance was complaining about disk full status and so I was trying to clear up some stuff to make space. <\/p>\n<p>In this process, I removed some conda envs including the azureml_py38 accidentally. <\/p>\n<p>Now, I am unable to access terminal or run any jupyter notebooks in that compute instance. <\/p>\n<p>I see that it is because of the deletion of the conda env. <\/p>\n<p>Is there a way to recover the compute instance?. Is there a way to reinstall the conda env.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Model Deployment (Endpoints) throws error",
        "Question_created_time":1683350863183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1276938\/ml-model-deployment-(endpoints)-throws-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hallo, <\/p>\n<p>I have a student version of azure account. So, I want to classify images (e.g. cat vs dog) with Azure Machine Learning. I used data labeling and automatedML for the task. I registered my model and I tried to deploy it by means of Real-time endpoint. I use for that the standard_F2s__v2 VM, because for other VMs I don't have enough quota.<\/p>\n<p>During deployment I get this error (see below). Do you know what can I do? what's the problem? the VM or scripts (docker etc.) which are generated by azure? <\/p>\n<p>Thanks for answers!<\/p>\n<blockquote>\n<p>Instance status:\nSystemSetup: Succeeded\nUserContainerImagePull: Succeeded\nModelDownload: Succeeded\nUserContainerStart: InProgress\nContainer events:\nKind: Pod, Name: Downloading, Type: Normal, Time: 2023-05-05T18:52:51.640736Z, Message: Start downloading models\nKind: Pod, Name: Pulling, Type: Normal, Time: 2023-05-05T18:52:51.939809Z, Message: Start pulling container image\nKind: Pod, Name: Pulled, Type: Normal, Time: 2023-05-05T18:53:18.896965Z, Message: Container image is pulled successfully\nKind: Pod, Name: Downloaded, Type: Normal, Time: 2023-05-05T18:53:18.896965Z, Message: Models are downloaded successfully\nKind: Pod, Name: Created, Type: Normal, Time: 2023-05-05T18:53:18.983732Z, Message: Created container inference-server\nKind: Pod, Name: Started, Type: Normal, Time: 2023-05-05T18:53:19.121257Z, Message: Started container inference-server\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:53:33.609235Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:53:44.184435Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:53:53.609086Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:54:03.608893Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:54:13.608775Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-05-05T18:54:23.608705Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\nContainer logs:\n2023-05-05T18:53:19,317469780+00:00 - rsyslog\/run \n2023-05-05T18:53:19,320703107+00:00 - gunicorn\/run \n2023-05-05T18:53:19,322375521+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,324133736+00:00 | gunicorn\/run | ###############################################\n2023-05-05T18:53:19,325868850+00:00 | gunicorn\/run | AzureML Container Runtime Information\n2023-05-05T18:53:19,328116769+00:00 | gunicorn\/run | ###############################################\n2023-05-05T18:53:19,331154294+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,333284612+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,341554081+00:00 | gunicorn\/run | AzureML image information: mlflow-ubuntu20.04-py38-cpu-inference:20230404.v14\n2023-05-05T18:53:19,343354796+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,345147111+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,346924426+00:00 | gunicorn\/run | PATH environment variable: \/opt\/miniconda\/envs\/amlenv\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n2023-05-05T18:53:19,348632240+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n2023-05-05T18:53:19,350929659+00:00 | gunicorn\/run | \n2023-05-05T18:53:19,358940326+00:00 - nginx\/run \nnginx: [warn] the &quot;user&quot; directive makes sense only if the master process runs with super-user privileges, ignored in \/etc\/nginx\/nginx.conf:1\n2023-05-05T18:53:21,047186621+00:00 | gunicorn\/run | CONDAPATH environment variable: \/opt\/miniconda<\/p>\n<h1 id=\"conda-environments\">conda environments:<\/h1>\n<h1 id=\"section\"><\/h1>\n<p>base                     \/opt\/miniconda\namlenv                   \/opt\/miniconda\/envs\/amlenv\n2023-05-05T18:53:22,109803493+00:00 | gunicorn\/run | \n2023-05-05T18:53:22,111660209+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\nazure-core==1.26.3\nazure-identity==1.12.0\nazureml-inference-server-http==0.8.3\ncachetools==5.3.0\ncertifi==2022.12.7\ncffi==1.15.1\ncharset-normalizer==3.1.0\nclick==8.1.3\ncryptography==40.0.1\nFlask==2.2.3\nFlask-Cors==3.0.10\ngoogle-api-core==2.11.0\ngoogle-auth==2.17.1\ngoogleapis-common-protos==1.59.0\ngunicorn==20.1.0\nidna==3.4\nimportlib-metadata==6.1.0\ninference-schema==1.5.1\nitsdangerous==2.1.2\nJinja2==3.1.2\nMarkupSafe==2.1.2\nmsal==1.21.0\nmsal-extensions==1.0.0\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\nportalocker==2.7.0\nprotobuf==4.22.1\npsutil==5.9.4\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\npydantic==1.10.7\nPyJWT==2.6.0\npython-dateutil==2.8.2\npytz==2023.3\nrequests==2.28.2\nrsa==4.9\nsix==1.16.0\ntyping_extensions==4.5.0\nurllib3==1.26.15\nWerkzeug==2.2.3\nwrapt==1.12.1\nzipp==3.15.0\n2023-05-05T18:53:23,247714179+00:00 | gunicorn\/run | \n2023-05-05T18:53:23,249556992+00:00 | gunicorn\/run | Entry script directory: \/var\/mlflow_resources\/.\n2023-05-05T18:53:23,251367404+00:00 | gunicorn\/run | \n2023-05-05T18:53:23,253148416+00:00 | gunicorn\/run | ###############################################\n2023-05-05T18:53:23,254978929+00:00 | gunicorn\/run | Dynamic Python Package Installation\n2023-05-05T18:53:23,256700340+00:00 | gunicorn\/run | ###############################################\n2023-05-05T18:53:23,258536553+00:00 | gunicorn\/run | \n2023-05-05T18:53:23,260471566+00:00 | gunicorn\/run | Updating conda environment from \/var\/azureml-app\/azureml-models\/trained_05052023\/1\/mlflow-model\/conda.yaml !\nRetrieving notices: ...working... done\n.\/run: line 152:    62 Killed                  conda env create -n userenv -f &quot;${CONDA_FILENAME}&quot;\nCollecting package metadata (repodata.json): ...working... Error occurred. Sleeping to send error logs.\n2023-05-05T18:54:29,187641958+00:00 - gunicorn\/finish 95 0\n2023-05-05T18:54:29,189598769+00:00 - Exit code 95 is not normal. Killing image.<\/p>\n<\/blockquote>",
        "Question_closed_time":1683360869436,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hello @<strong>student2023 !<\/strong><\/p>\n<p>it seems that the Container has some errors<\/p>\n<p>Can you post the steps of the Process as you did it ?<\/p>\n<p>Also check on Azure , is the Container Healthy ?<\/p>\n<p>Is this a lab you found or your own ? <\/p>\n<p>Come back to see your feedback !<\/p>\n<hr \/>\n<p>Kindly mark the answer as accepted in case it helped or post your feedback to help !<\/p>\n<p>Regards<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Studio - No pre built component appears in Designer",
        "Question_created_time":1670713679990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1124024\/azure-ml-studio-no-pre-built-component-appears-in",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>Hi,     <br \/>\nI'm experiencing the same problem. Not even one pre-built component appears in the Designer.     <br \/>\nWhat is going on. How can this happen.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/269248-capture.jpg?platform=QnA\" alt=\"269248-capture.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Thank You to the Microsoft Q&A Community Champions",
        "Question_created_time":1682935521550,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1273372\/thank-you-to-the-microsoft-q-a-community-champions",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>We would like to celebrate April's\u202f<a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Community Champions<\/a>\u202ffor their great contribution to the community on Microsoft Q&amp;A!<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Microsoft Q&amp;A Community Champions<\/a>\u202fprogram recognizes external technology experts who contribute to the Microsoft Q&amp;A community by providing quality answers to technical questions. They are our true \u2018champions\u2019 and provide additional help by taking moderator roles and provide suggestions to improve our overall platform as well as user experience. This program includes both MVPs and non-MVP expert users.\u00a0<\/p>\n<p>We recognize top contributors by providing incentives like moderator privileges in Microsoft Q&amp;A platform, gift cards\u00a0and also share about Q&amp;A contributions in social media channels like <a href=\"https:\/\/twitter.com\/AzureSupport\/status\/1458525468064288777?s=20\">Azure Support Twitter handle<\/a> and in <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/azure-leaderboard\">Microsoft Q&amp;A Azure Leaderboard<\/a>. <\/p>\n<p><strong>Thank You to all the Microsoft Q&amp;A Community Champions.<\/strong>\u00a0  <br \/>\nThey are helping make Microsoft Q&amp;A a vibrant place for learning.\u00a0<\/p>\n<p>@DillonJS @sdtslmn @AlbertoMorillo @subrothodas-9589 @KonstantinosPOfficeLine-9007 @ricardosolisvillegas-4678 @AlistairRoss-msft @AndrewBlumhardt-1137 @soysoliscarlos @michev @AndyDavid @msrini-MSFT @RahulRandive @RohitKumarSinha-4468 @SubashriVasudevan-1752 @SandervandeVelde42 @AndreiBarbu-MSFT @AndriyBilous @clivewatson-9831 @shivapatpi-MSFT @ZollnerD @JimmySalian-2011 @MichaelDurkan-1632 @Vinodh247-1375 @dkrishnaveni-MSFT @NandanHegde-7720 @rbrundritt @SonnyGillissen @sreejukg @DavidBroggy-5270 @ErlandSommarskog @DSPatrick @AndreasBaumgarten @FabricioGodoy @learn2skills @lukemurraynz @patchfox @RichMatheisen-8856 @Sam-Cogan @SinaSalam-7288 @stan @AdiD-5122 @maserg @RafaelDaRocha @57658876 @AyomideOluwaga-8463 @IoTGirl @lextm @LucaCloud @pituach @PratikSomaiya @BjoernPeters @CristianGatjens-0334 @dominicbetts @eddieneto-msft @HARPREET-MSFT @AbdulSajidMohammed-MSFT @AlanKinane @GoncaloCorreia-8856 @martins-jackson @rajeeshmenoth @ScottAzureRTOS @SudiptaChakraborty-1767 @yannara<\/p>\n<p><strong>Also, if you are interested in joining the Microsoft Q&amp;A Community Champions program and help shape the future of Microsoft Q&amp;A, please apply here:<\/strong>\u00a0<strong><a href=\"https:\/\/forms.office.com\/r\/vQcapa5BtB\">Community Champions Application Form<\/a><\/strong><\/p>\n<p>Special invitation to:\u00a0\u00a0<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=54ee969b-3f40-4741-89f4-fff4be002d6e\">@TP<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=f11fefe2-1b48-463c-8ab9-08fa64050938\">Boris Von dahle <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=e46275b8-0000-0006-0000-000000000000\">VasimTamboli <\/a><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=17b6b3f9-7eeb-4742-a20e-78fc23696702\">RevelinoB <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=054155e3-33cc-42b4-a13b-a41f3f5eb4cd\">Susheel Bhatt <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=8e18e72d-a4fa-4fd9-acd5-639ede416e0a\">  <br \/>\nZeeshan Bajwa <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=9f655253-d5a5-43c5-974b-94667b591f96\">Vahid Ghafarpour <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=a4cc95fe-0000-0006-0000-000000000000\">David Pazdera <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=fdf3f7ea-99f6-4208-8905-84ec94da8133\">Micheal Falowo <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=05a1775e-7a44-4ca9-a5b4-1e615d3518fd\">Saad Markou <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=f39a8d1a-e4aa-4721-811a-245ae20a43e2\">Syed Shiraz Shahid <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=95fe2526-bffd-0006-0000-000000000000\">Viorel <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=cf335b38-e9fd-4a12-ae79-7d51e5c7510c\">CharanyaB <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6bea43de-47ee-451b-8e21-9ab463f72b9d\">Mark Morowczynski <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=c97b933c-d006-467b-8fac-d747e4ab5d1a\">Sayantan Ganguly <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=42df8d0b-75d6-423f-83c8-1eaedc34d305\">Surbhi <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d4ea082c-e4d1-4c09-b5dc-afa31eae8796\">Erkan Sahin <\/a> <a href=\"\/users\/na\/?userid=6ec2ad70-1203-43cd-8c2a-523a82e17213\">@LiJia Liu  <\/a><a href=\"\/users\/na\/?userid=251d550c-a217-45b2-bbc5-a59e9e46b995\">@Sedat SALMAN  <\/a> <a href=\"\/users\/na\/?userid=e1e94fa5-a21c-4669-b019-7bfd40cd41bb\">@Ayomide Oluwaga  <\/a> <a href=\"\/users\/na\/?userid=80389cad-bffd-0003-0000-000000000000\">@Luca Lionetti  <\/a>  <a href=\"\/users\/na\/?userid=68851d39-c760-4dab-a290-cd3bfa2d8c5b\">@Fabricio Godoy  <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d70d5c95-0000-0003-0000-000000000000\">@Bas Pruijn<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6f6bb61e-afe6-4f38-9f92-62a4655b7267\">@Bruce (SqlWork.com)<\/a> <a href=\"\/users\/na\/?userid=857fa4fc-0000-0003-0000-000000000000\">@Olaf Helper  <\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to convert instance segmentation labels to object detection labels?",
        "Question_created_time":1683145632636,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275790\/how-to-convert-instance-segmentation-labels-to-obj",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>We have labelled thousands of instance segmentation images and would like to instead use an object detection model like yolo. How can convert the labelled data into a format for compatible with object detection with Auto ML? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Annotation tool for PDF",
        "Question_created_time":1683143377326,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275774\/annotation-tool-for-pdf",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, is the Azure annotation tool working for big PDF files (100 pages) and multiple labels (30-50 labels)? For the beginning I don't need the ML features, I just wand to label my files and after download the annotated PDF. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML model web service model deployment: Failure while loading azureml_run_type_providers",
        "Question_created_time":1678186126603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1187258\/automl-model-web-service-model-deployment-failure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have a Voting Ensemble model from the automated ML want to deploy an endpoint so that I can consume it in Power BI<\/p>\n<p>I follow the deployment steps in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-first-experiment-automated-ml#deploy-the-best-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-first-experiment-automated-ml#deploy-the-best-model<\/a><\/p>\n<p>I have select <\/p>\n<p>(1) Azure Container Instance (ACI) for the compute type<\/p>\n<p>(2) disable authentication<\/p>\n<p>(3) Disable custom deployment<\/p>\n<p>(4) keep the default in the <em>Advanced<\/em> menu<\/p>\n<p>as suggested in the tutorial.<\/p>\n<p>My endpoint deployment state is unhealthy and I got the following message in the deployment log<\/p>\n<pre><code>Booting worker with pid: 327\nInitializing logger\n2023-03-07 09:23:00,424 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2023-03-07 09:23:00,425 | root | INFO | Starting up app insight hooks\n2023-03-07 09:23:01,648 | root | INFO | Found user script at \/var\/azureml-app\/main.py\n2023-03-07 09:23:01,648 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs, GlobalParameters.\n2023-03-07 09:23:01,648 | root | INFO | Invoking user's init function\nImporting plotly failed. Interactive plots will not work.\n2023-03-07 09:23:13,132 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\n2023-03-07 09:23:13,143 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\n2023-03-07 09:23:13,158 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\n2023-03-07 09:23:13,168 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\n2023-03-07 09:23:13,249 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-identity 1.12.0 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('azure-identity==1.7.0'), {'azureml-dataprep'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-identity 1.12.0 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('azure-identity==1.7.0'), {'azureml-dataprep'}).\n2023-03-07 09:23:13,270 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.25.11 (\/azureml-envs\/azureml_4ceb345e4e0a419c28b56298b234f6b5\/lib\/python3.7\/site-packages), Requirement.parse('urllib3&gt;=1.26.0'), {'docker'}).\nWorker with pid 327 was terminated due to signal 9\nBooting worker with pid: 342\n<\/code><\/pre>\n<p>I have the latest docker desktop and urllib3 installed in the PC, I have chosen no-code deployment because I do not want to deal with writing the deployment script or environment script while I need the Power BI consume the model. Please let me know if there is any solution to the deployment issue or alternative to deploy a model and consume in Power BI. Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Cluster Compute Data Vaniches",
        "Question_created_time":1683035695890,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1275035\/azure-machine-learning-cluster-compute-data-vanich",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have configured GPU based Compute Cluster in Azure Machine Learning Workspace. After completing some work , when I turn that off and restart all my data vanishes. Any suggestions?  <\/p>\n<p>Also how do I attach a Azure blob storage to the compute cluster so that all my work gets stored there automatically?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Secrets automatically created in key vault",
        "Question_created_time":1682857366816,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1270782\/secrets-automatically-created-in-key-vault",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Bunch of secrets being automatically created in key vault that is integrated into Azure ML workspace(s). These secrets seem to be generated by the ML resource\/service itself and continues to generate new secrets.<\/p>\n<p>\u00a0Can you please help with the document for these secrets?<\/p>",
        "Question_closed_time":1682931416010,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">D-0887<\/a> Thanks, When you perform operations in Azure ML that require secret values to be stored like creating connections, datastores, or workspace management operations, the key vault instance associated to the workspace is used to store those secrets.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"unable to find sample data set Automobile price data (Raw) on Azure ML designer",
        "Question_created_time":1682787879083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1268364\/unable-to-find-sample-data-set-automobile-price-da",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am doing the tutorial: Designer - train a no-code regression model. I am no able to find the <strong>Automobile price data (Raw)<\/strong> data set. As per instructions there should be sample data set under instructions, but this does not exist. I do see many components, but no dataset at all. Any help will be appreciated.<\/p>\n<p>Here is the screen shot:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/82b8a57e-45da-4059-a3c5-df9070eeb027?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - How to do batch scoring if the workspace is using CMK (Customer Managed Keys)",
        "Question_created_time":1682606741926,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1262626\/azure-ml-how-to-do-batch-scoring-if-the-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,<\/p>\n<p>As per the MS documentation if the workspace use CMK (Customer Managed Keys) , we can't create a Batch Endpoint that can be called to run Batch prediction. In this case what are the alternatives ? We have a use case where we need to do run a forecasting model every day on batch data. Thank you !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why are my jobs failing with \"Error: Input request is invalid\" no matter what I do ?",
        "Question_created_time":1682711003583,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1266044\/why-are-my-jobs-failing-with-error-input-request-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>So, I have been wasting nearly 10 hours on this issue, and the nearly non-existent documentation on Azure is not exactly helping.<\/p>\n<p>I'm trying to create an Azure AutoML job using the Python SDK. The job is an Image classification job. I'm pointing it to a .jsonl file describing my image data. The job keeps failing with &quot;Error: Input request is invalid&quot;.<\/p>\n<p>Here are a couple of facts about this :<\/p>\n<p>(1) I don't know what caused it. It wasn't there before, I have previously made a job that ran for more than 1 hour. This job timed out (because I chose a model that is too big to converge), but it had no problems whatsoever with accessing the data.<\/p>\n<p>(2) The images can be viewed just fine in the Azure UI. When I click the job details and navigate to the training data asset, I can see in the &quot;Explore&quot; tab that the names of every image and the image itself. Azure has no problem reading my data, only the Job.<\/p>\n<p>(3) The .jsonl file is generated by a script that I wrote, it's a very simple script that constructs the json describing every image and serializes it to a file.<\/p>\n<p>There is no reason this should happen. It keeps happening anyway. Please help me. Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"SDK features mapping",
        "Question_created_time":1682716608216,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1266094\/sdk-features-mapping",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey experts, I am looking for a document of how features in SDK V1 mapping to SDK v2 to show my team and plan how we should move to SDK v2. I cannot find a summary for that. Can you please help with this <\/p>",
        "Question_closed_time":1682725999300,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/users\/na\/?userid=9603a4b0-3119-4f80-93b6-9637337c7a94\">@otto atler<\/a> <\/p>\n<p>Thanks for reaching out to us again, please see below list: <\/p>\n<p>For workspace - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace\">Method\/API in SDK v1 (use links to ref docs)<\/a>    <\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.workspace\">Method\/API in SDK v2 (use links to ref docs)<\/a><\/p>\n<p>For compute - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.compute.amlcompute(class)\">Method\/API in SDK v1 (use links to ref docs)<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.amlcompute\">Method\/API in SDK v2 (use links to ref docs)<\/a><\/p>\n<p>For datastore -<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_storage_datastore.azureblobdatastore?view=azure-ml-py&amp;preserve-view=true\">azureml_blob_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen1datastore\">azureml_blob_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_data_lake_datastore.azuredatalakedatastore?view=azure-ml-py&amp;preserve-view=true\">azureml_data_lake_gen1_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen1datastore\">azureml_data_lake_gen1_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_data_lake_datastore.azuredatalakegen2datastore?view=azure-ml-py&amp;preserve-view=true\">azureml_data_lake_gen2_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen2datastore\">azureml_data_lake_gen2_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_sql_database_datastore.azuresqldatabasedatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_sql_database_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_my_sql_datastore.azuremysqldatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_my_sql_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_postgre_sql_datastore.azurepostgresqldatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_postgre_sql_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>For data assets - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data\">Method\/API in SDK v1<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities\">Method\/API in SDK v2<\/a><\/p>\n<p>For model assets - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model(class)#azureml-core-model-register\">Model.register<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-create-or-update\">ml_client.models.create_or_update<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run#azureml-core-run-run-register-model\">run.register_model<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-create-or-update\">ml_client.models.create_or_update<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model(class)#azureml-core-model-deploy\">Model.deploy<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-begin-create-or-update\">ml_client.begin_create_or_update(blue_deployment)<\/a><\/p>\n<p>I hope this helps, please let me know if you have any questions.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support he community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"V2 and V1 comparison",
        "Question_created_time":1682716346303,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1266092\/v2-and-v1-comparison",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am looking for some guidance about Azure machine learning SDK migration, I know that there\u2019s a lot of difference between the two and I can\u2019t find a place to help me out. <\/p>\n<p>Can I get some help and suggestions?<\/p>",
        "Question_closed_time":1682725089860,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=9603a4b0-3119-4f80-93b6-9637337c7a94\">@otto atler  <\/a>    <\/p>\n<p>Thanks for reaching out to us, the document shared by Dillion is very helpful - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-resource-workspace?view=azureml-api-2\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-resource-workspace?view=azureml-api-2<\/a> <\/p>\n<p>In the document page, left panel, you can see there is a list include different aspects - workspace, compute, datastore, data assets, model assets, every page it describes the difference of how to use the SDK1 and SDK2. I don't want to copy and paste the whole content, but you can get everything in the related topic page.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/56869e70-46ab-4578-a3fa-e2f57007fc8a?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Like in the workspace page, it describes how to create workspace in both V1 and V2 - <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/090a0b0a-bb21-4a8e-8aa7-54fdb2dda0f8?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I hope this helps, please let me know if you have any other questions.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Bing Search API not working",
        "Question_created_time":1682800891813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1268762\/bing-search-api-not-working",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I can not make my api work, it\u2019s always return 404 error. It used to work very well. Any idea?<\/p>",
        "Question_closed_time":1682811623416,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello @12869769 <\/p>\n<p>Thanks for reaching out to us. A 404 error means that the API endpoint you are trying to access is not found. Here are some potential reasons for this issue:<\/p>\n<p>Endpoint URL: Double-check that you are using the correct URL for the endpoint you are trying to access. Bing Search API has multiple endpoints, including Web Search, Image Search, Video Search, News Search, and more. Make sure you are using the correct endpoint URL for the type of search you are trying to perform.<\/p>\n<p>API Key: Verify that your API key is still valid and has not expired. You can check your API key status in your Azure portal.<\/p>\n<p>Quota Limits: Make sure that you have not exceeded your quota limits. Bing Search API has usage limits and if you exceed them, you may receive a 404 error.<\/p>\n<p>Permissions: Ensure that you have the correct permissions to access the Bing Search API. If you are using a new Azure account or have recently updated your subscription, you may need to update your permissions.<\/p>\n<p>Network Issues: Check if there are any network issues that may be preventing you from accessing the Bing Search API. Try to access the API from a different network or location to see if the issue persists.<\/p>\n<p>Based on my personal experience, you may need to double check on your endpoint URL. Please let me know if none of above works, we are happy to help further.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Pipeline suddenly fails (500 internal error)",
        "Question_created_time":1682519855786,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1259244\/azure-ml-pipeline-suddenly-fails-(500-internal-err",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I have a pipeline that I have been running successfully for the last 2 months.<\/p>\n<p>Now, one of the jobs runs successfully, I am checking the logs, but when it reaches the final steps I get:\nFinalizing ...\nFinalizing ...\nFinalizing ...<\/p>\n<p><code>Failed to execute command group with error Docker container `5b5f21c26f5948a293ec4e7d4e8bd542-lifecycler` failed with status code `1`. Service 'HOSTTOOLS_CAPABILITY' returned capability end response with code: Response { code: &quot;500&quot;, error: Some(Error { code: &quot;TerminationError&quot;, message: &quot;hosttools process exit unexpectedly with code: Some(1)&quot;, target: &quot;hosttools-capability&quot;, node_info: None, category: SystemError, error_details: [], inner_error: None }) }<\/code>\nHow can I solve this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azureml dataset consumption does not work when whitespaces are in the file name",
        "Question_created_time":1645111306257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/740186\/azureml-dataset-consumption-does-not-work-when-whi",
        "Question_score_count":1,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <br \/>\nwhen i previously exported the data from a data labeling project to Azure ML dataset, i could consume them with the azureml.contrib.dataset  <\/p>\n<p>This seems to be not supported anymore, therefor i tried to download them with the azureml.core Dataset package.  <br \/>\nIt seems to works only for data which have no white space in their name.  <br \/>\nThe dataset is a Tabular dataset, i download them with:  <\/p>\n<pre><code>from azureml.core import Workspace, Dataset\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='my_dataset_name')\ndataset.download('image_url', target_path='.\/', overwrite=True)\n<\/code><\/pre>\n<p>Error:   <\/p>\n<blockquote>\n<p>AzureMLException:  <br \/>\n\tMessage: Some files have failed to download:('workspaceblobstore\/data\/quay_data_cra\/IMG_0082%20copy%207.jpg', 'Microsoft.DPrep.ErrorValues.DownloadFailed')  <br \/>\n('workspaceblobstore\/data\/quay_data_cra\/IMG_0543%20copy%205.jpg', 'Microsoft.DPrep.ErrorValues.DownloadFailed')  <\/p>\n<\/blockquote>\n<p>How can i download the dataset?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"getting error when deploying a model to real tim endpoint- getting message \"Could not find datastore: azureml\"",
        "Question_created_time":1682936882283,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1273382\/getting-error-when-deploying-a-model-to-real-tim-e",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi pls help,<\/p>\n<p> i am trying deploy a model to real time endpoint and getting an error message &quot;Could not find datastore: azureml&quot;<\/p>\n<p>this is after i have traind the model...<\/p>\n<p>any help will be a appreciated<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to include neural network models in regression problems by using Auto ML?",
        "Question_created_time":1682696504216,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1265838\/how-to-include-neural-network-models-in-regression",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I faced an issue in Azure ML, I do highly appreciate you giving me guidance. <\/p>\n<p>I have a regression problem for which I would like to set up Auto ML in Azure ML Studio to find the best model describing my data. For this purpose, I adjusted AutoML settings like below:<\/p>\n<pre><code class=\"lang-python\">automl_settings = {\n    &quot;n_cross_validations&quot;: 10,\n    &quot;primary_metric&quot;: 'normalized_root_mean_squared_error',\n    &quot;enable_early_stopping&quot;: True,\n    &quot;experiment_timeout_hours&quot;: 1,  \n    &quot;max_concurrent_iterations&quot;: 4,\n    &quot;max_cores_per_iteration&quot;: -1,\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;enable_dnn&quot; : True,\n    &quot;enable_voting_ensemble&quot;: True,\n    &quot;enable_stack_ensemble&quot;: True,\n    &quot;enable_tf&quot; : True, \n    &quot;iterations&quot; : 1000\n}\n<\/code><\/pre>\n<p>As I put &quot;enable_tf&quot; : True in the AutoML settings above, I expect that AutoML will include (deep) neural network (NN) models in the search for finding the best regression model. However, I check the models used through iterations (by monitoring the job section), I see that NNs are not included whatsoever.   <\/p>\n<p>Any advice on including NNs in the AutoML search for regression problems is much appreciated. <\/p>\n<p>Cheers<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning data scheme blue print support?",
        "Question_created_time":1682810430540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1268796\/azure-machine-learning-data-scheme-blue-print-supp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am looking for a way to import my data according to my data blueprint. My data scheme is changing depending on our scenario. It finally will be import as Pandas but I want to define the way. Is this possible?<\/p>",
        "Question_closed_time":1682886733486,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <\/p>\n<p>Thanks for reaching out to us, one choice you may want to consider is MLtable - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-mltable?view=azureml-api-2&amp;tabs=cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-mltable?view=azureml-api-2&amp;tabs=cli<\/a><\/p>\n<p>Azure Machine Learning supports a Table type (<code>mltable<\/code>). This allows for the creation of a <em>blueprint<\/em> that defines how to load data files into memory as a Pandas or Spark data frame.<\/p>\n<p>This is very similar to the scenario you described. <\/p>\n<p>Azure Machine Learning Tables (<code>mltable<\/code>) allow you to define how you want to <em>load<\/em> your data files into memory, as a Pandas and\/or Spark data frame. Tables have two key features:<\/p>\n<ol>\n<li> <strong>An MLTable file.<\/strong> A YAML-based file that defines the data loading <em>blueprint<\/em>. In the MLTable file, you can specify:<\/li>\n<\/ol>\n<ul>\n<li> The storage location(s) of the data - local, in the cloud, or on a public http(s) server.<\/li>\n<li> <em>Globbing<\/em> patterns over cloud storage. These locations can specify sets of filenames, with wildcard characters (<code>*<\/code>).<\/li>\n<li> <em>read transformation<\/em> - for example, the file format type (delimited text, Parquet, Delta, json), delimiters, headers, etc.<\/li>\n<li> Column type conversions (enforce schema).<\/li>\n<li> New column creation, using folder structure information - for example, creation of a year and month column, using the <code>{year}\/{month}<\/code> folder structure in the path.<\/li>\n<li> <em>Subsets of data<\/em> to load - for example, filter rows, keep\/drop columns, take random samples.<\/li>\n<\/ul>\n<ol>\n<li> <strong>A fast and efficient engine<\/strong> to load the data into a Pandas or Spark dataframe, according to the blueprint defined in the MLTable file. The engine relies on <a href=\"https:\/\/www.rust-lang.org\/\">Rust<\/a> for high speed and memory efficiency.<\/li>\n<\/ol>\n<p>Please take a look at above and let me know if  this is what you are looking for, thanks.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote yes if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"File Corrupted.. sqlite3.DatabaseError: database disk image is malformed..",
        "Question_created_time":1682879849116,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1272072\/file-corrupted-sqlite3-databaseerror-database-disk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have a datastore i made and was running perfectly. I made a new one uploaded a modified version of the database and it gives me this error .. i have this part of my code where the error is caused.. i am not sure why that happens because the same version of code with different database paths works but this one shows the information for the database but then it gives error when trying to read it. files 1. version that works start 2. version that doesn't 3. error from version 2.. Thanks I tried uploading it again and pointing the new upload same error. When I download file I can view it in database viewer so I don't know why I get error....<\/p>\n<p>File Corrupted.. sqlite3.DatabaseError: database disk image is malformed..<\/p>\n<pre><code>  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py&quot;, line 920, in do_execute\n    cursor.execute(statement, parameters)\nsqlalchemy.exc.DatabaseError: (sqlite3.DatabaseError) database disk image is malformed\n[SQL: SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name]\n(Background on this error at: https:\/\/sqlalche.me\/e\/20\/4xp6)\n<\/code><\/pre>\n<pre><code>import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport sqlite3\nimport csv\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, LSTM, Activation, Dropout, Reshape, Conv1D, MaxPooling1D, Dense, Flatten\nfrom tensorflow.keras.models import Model\n\nimport matplotlib.pyplot as plt\nfrom azureml.core import Workspace, Datastore, Dataset\nfrom azure.storage.blob import BlobServiceClient\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import inspect\nfrom sqlalchemy import MetaData\n\n# Connect to your workspace\nsubscription_id = 'b0132afa-d29b-4d66-88f8-2c189dcba3be'\nresource_group = 'resource-one'\nworkspace_name = 'workspace-one'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\n# Get the datastore\ndatastore_name = 'workspaceblobstore'\ndatastore = Datastore.get(workspace, datastore_name)\n\n# Retrieve datastore account name and key\naccount_name = datastore.account_name\naccount_key = datastore.account_key\n\n# Create a BlobServiceClient using the storage account key\nconnection_string = f&quot;DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net&quot;\nblob_service_client = BlobServiceClient.from_connection_string(connection_string)\n\n# Download the SQLite database file to your local environment\nlocal_file_name = &quot;qqqq.db&quot;\ndatastore.download(target_path=os.getcwd(), prefix='UI\/2023-04-27_225942_UTC\/qqqq.db', overwrite=True, show_progress=True)\n\n# Get a reference to the container\ncontainer_name = 'azureml-blobstore-94c291eb-0707-4d58-8ab8-33b5c7edb276'\ncontainer_client = blob_service_client.get_container_client(container_name)\n\n# Download a specific file (replace 'file_path' with the path of the file you want to download)\nfile_path = 'UI\/2023-04-27_225942_UTC\/qqqq.db'\nlocal_file_name = 'local_qqqq.db'\n\n# List blobs in the container\nblobs = container_client.list_blobs()\n\nfor blob in blobs:\n    print(&quot;Name:&quot;, blob.name)\n    print(&quot;Size:&quot;, blob.size)\n\n# Connect to the downloaded SQLite database file\nengine = create_engine(f'sqlite:\/\/\/{local_file_name}')\n# Query all the tables and store them in a dictionary with table names as keys and dataframes as values\ntables = {}\ninspector = inspect(engine)\ntable_names = inspector.get_table_names()\nprint(f&quot;Table names: {table_names}&quot;)\n# Connect to the downloaded SQLite database file\nconn = sqlite3.connect(local_file_name)\n\nfor table_name in table_names:\n    tables[table_name] = pd.read_sql_query(f&quot;SELECT * FROM {table_name}&quot;, conn)\n\n<\/code><\/pre>\n<pre><code>subscription_id = 'b0132afa-d29b-4d66-88f8-2c189dcba3be'\nresource_group = 'resource-one'\nworkspace_name = 'workspace-one'\n  \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n# Get the datastore\ndatastore_name = 'workspaceblobstore'\ndatastore = Datastore.get(workspace, datastore_name)\n# datastore = Datastore.get(workspace, &quot;workspaceblobstore&quot;)\n\n# Retrieve datastore account name and key\naccount_name = datastore.account_name\naccount_key = datastore.account_key\n\n# Create a BlobServiceClient using the storage account key\nconnection_string = f&quot;DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net&quot;\nblob_service_client = BlobServiceClient.from_connection_string(connection_string)\n\n# Download the SQLite database file to your local environment\nlocal_file_name = &quot;twodata.db&quot;\nprint(&quot;downloading datastore&quot;)\ndatastore.download(target_path=os.getcwd(), prefix='UI\/2023-04-30_175315_UTC\/twodata.db', overwrite=True, show_progress=True)\nprint(&quot;download complete&quot;)\n# Get a reference to the container\ncontainer_name = 'azureml-blobstore-94c291eb-0707-4d58-8ab8-33b5c7edb276'\n# UI\/2023-04-30_175315_UTC\/\n# UI\/2023-04-30_152949_UTC\/\ncontainer_client = blob_service_client.get_container_client(container_name)\n\n# Download a specific file (replace 'file_path' with the path of the file you want to download)\n# file_path = 'UI\/2023-04-30_152949_UTC\/twodata.db'\n# local_file_name = 'local_twodata.db'\nfile_path = 'twodata.db'\nlocal_file_name = 'local_twodata.db'\n\n# List blobs in the container\nblobs = container_client.list_blobs()\n\nfor blob in blobs:\n    print(&quot;Name:&quot;, blob.name)\n    print(&quot;Size:&quot;, blob.size)\n\n# Connect to the downloaded SQLite database file\nengine = create_engine(f'sqlite:\/\/\/{local_file_name}')\n# Query all the tables and store them in a dictionary with table names as keys and dataframes as values\ntables = {}\ninspector = inspect(engine)\ntable_names = inspector.get_table_names()\nprint(f&quot;Table names: {table_names}&quot;)\n# Connect to the downloaded SQLite database file\nconn = sqlite3.connect(local_file_name)\n\n<\/code><\/pre>\n<pre><code>downloading datastore\nDownloading UI\/2023-04-30_175315_UTC\/twodata.db\nDownloaded UI\/2023-04-30_175315_UTC\/twodata.db, 1 files out of an estimated total of 1\ndownload complete\nName: UI\/2023-04-27_225942_UTC\/qqqq.db\nSize: 1096105984\nName: UI\/2023-04-30_152949_UTC\/twodata.db\nSize: 1113436160\nName: UI\/2023-04-30_175315_UTC\/twodata.db\nSize: 1113436160\nTraceback (most recent call last):\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 1963, in _exec_single_context\n    self.dialect.do_execute(\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py&quot;, line 920, in do_execute\n    cursor.execute(statement, parameters)\nsqlite3.DatabaseError: database disk image is malformed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;mltwo.py&quot;, line 68, in &lt;module&gt;\n    table_names = inspector.get_table_names()\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/reflection.py&quot;, line 397, in get_table_names\n    return self.dialect.get_table_names(\n  File &quot;&lt;string&gt;&quot;, line 2, in get_table_names\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/reflection.py&quot;, line 97, in cache\n    ret = fn(self, con, *args, **kw)\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/dialects\/sqlite\/base.py&quot;, line 2117, in get_table_names\n    names = connection.exec_driver_sql(query).scalars().all()\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 1771, in exec_driver_sql\n    ret = self._execute_context(\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 1841, in _execute_context\n    return self._exec_single_context(\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 1982, in _exec_single_context\n    self._handle_dbapi_exception(\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 2339, in _handle_dbapi_exception\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py&quot;, line 1963, in _exec_single_context\n    self.dialect.do_execute(\n  File &quot;\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py&quot;, line 920, in do_execute\n    cursor.execute(statement, parameters)\nsqlalchemy.exc.DatabaseError: (sqlite3.DatabaseError) database disk image is malformed\n[SQL: SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name]\n(Background on this error at: https:\/\/sqlalche.me\/e\/20\/4xp6)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to make \"Machine Learning Execute Pipeline\" activity in ADF use default pipeline version(or latest version) of published endpoint in Azure ML studio",
        "Question_created_time":1681339140650,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1226510\/how-to-make-machine-learning-execute-pipeline-acti",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML studio, In pipelines -&gt; pipeline end points -&gt; select any published pipeline -&gt; published pipelines\nAs shown below, I have published one pipeline.\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/eb484aac-68cb-4835-9db8-a3b34f116d87?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Now while configuring &quot;Machine Learning Execute Pipeline&quot; activity in Azure Data Factory, it provides an option to select the pipeline version. I can select the latest version and run the pipeline. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16e62a6d-4ddb-4d8d-8969-4ec9a0d01a80?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>My question: In future, I have updated some things in the script and published new pipeline under the same end point as below and made it the default.\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/1ff05e25-8d68-4874-8500-cba24189ee04?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>But, my ML Execute pipeline still points to the older version, Is there a way to set the <strong>Pipeline Version<\/strong> in ADF in such a way that, it should always point out to the latest version or default version. So that I can make my developments and  there is no need for me to update each and every time in ADF.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Change input size of image classification model",
        "Question_created_time":1682481439760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1258427\/change-input-size-of-image-classification-model",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Whenever I use Azure AutoML, the resulting models always resize the image the 224 x 224 but I need the input size to be 1000 x 250. How can I stop it resizing the images? They are all the same size so I don't need this. I have tried multiple models with the same behaviors, but I specifically want a MobileNet model. Where is the parameter to change this??\nThanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run machine learning training on a virtual machine",
        "Question_created_time":1682678299290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1265294\/run-machine-learning-training-on-a-virtual-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello!  <\/p>\n<p>I am trying to fine-tune a previously trained GPT-2 model to my specific set of data in the cloud.  <\/p>\n<p>The code is working just fine, but my computer does not have the computing power to train the model, so I'd like to fine-tune it on an Azure VM.   <\/p>\n<p>I am following the instructions here:  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-model?view=azureml-api-2&amp;tabs=python#train-in-the-cloud\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-model?view=azureml-api-2&amp;tabs=python#train-in-the-cloud<\/a>  <\/p>\n<p>I am quite the newbie when it comes to cloud training, but whatever I do, it only runs on my computer.   <\/p>\n<p>I would appreciate any help to be able to move forward!  <\/p>\n<p>Thanks in advance. Code below.  <\/p>\n<p>This is my full code for the Azure training:<\/p>\n<pre><code>#import required libraries\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n#Enter details of your Azure Machine Learning workspace\nsubscription_id = '&lt;SUBSCRIPTION_ID&gt;'\nresource_group = '&lt;RESOURCE_GROUP&gt;'\nworkspace = '&lt;AZUREML_WORKSPACE_NAME&gt;'\n\n#connect to the workspace\nml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n\n# Enter details of your Azure Machine Learning workspace\nsubscription_id = 'xxx\nresource_group = 'xxx'\nworkspace = 'xxx'\n\n#%%\nfrom azure.ai.ml.entities import AmlCompute\n\n# specify aml compute name.\ncpu_compute_target = &quot;cpu-cluster&quot;\n\ntry:\n    ml_client.compute.get(cpu_compute_target)\nexcept Exception:\n    print(&quot;Creating a new cpu compute target...&quot;)\n    compute = AmlCompute(\n        name=cpu_compute_target, size=&quot;STANDARD_D2_V2&quot;, min_instances=0, max_instances=4\n    )\n    ml_client.compute.begin_create_or_update(compute).result()\n\n#%%\nfrom azure.ai.ml import command, Input\n\n# define the command\ncommand_job = command(\n    code=&quot;.\/Azure&quot;,\n    command=&quot;python chatgpt_transfer_learning.py&quot;,\n    environment=&quot;AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest&quot;,\n    inputs={\n        &quot;af_data.csv&quot;: Input(\n            type=&quot;path&quot;,\n            path=&quot;.\/python\/af_data.csv&quot;,\n        ),\n    },\n    compute=&quot;cpu-cluster&quot;,\n)\n\n\n#%%\n# submit the command\nreturned_job = ml_client.jobs.create_or_update(command_job)\n\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\nrun_model = Model(\n    path=&quot;azureml:\/\/jobs\/{}\/outputs\/artifacts\/paths\/model\/&quot;.format(returned_job.name),\n    name=&quot;swedish_gpt&quot;,\n    description=&quot;Model trained on tweets.&quot;,\n    type=AssetTypes.MLFLOW_MODEL\n)\n\nml_client.models.create_or_update(run_model)\n\n<\/code><\/pre>\n<p>And this is my fine-tuning code:<\/p>\n<pre><code># %% Load the tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained(&quot;birgermoell\/swedish-gpt&quot;)\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\nmodel = TFGPT2LMHeadModel.from_pretrained(&quot;birgermoell\/swedish-gpt&quot;, from_pt=True)\n\n# %% Load data\n\ndf = pd.read_csv('..\/af_data.csv', usecols=['type', 'text'])\ntexts = df.loc[df['type'] == 'Tweet', 'text'].tolist()\n\n# %% Preprocess data\ncleaned_texts = [preprocess_swedish_texts([text]) for text in texts]  # Preprocess the texts\ncleaned_texts = [text for sublist in cleaned_texts for text in sublist]  # Flatten the list\n\n\n# %%\n\nmax_length = 512\n\n# Split the data into training and validation sets\nX_train, X_test = train_test_split(cleaned_texts, test_size=0.2, random_state=42)\n\n# Tokenize and encode the training and validation texts\nX_train_encoded = tokenizer(X_train, padding=True, truncation=True, max_length=max_length, return_tensors='tf')[\n    'input_ids']\nX_val_encoded = tokenizer(X_test, padding=True, truncation=True, max_length=max_length, return_tensors='tf')[\n    'input_ids']\n\n# Check for input_ids values that are larger than the maximum input dimension of the embedding layer\nmax_input_dim = model.get_input_embeddings().weight.shape[1]\nX_train_encoded = [[token if token &lt; max_input_dim else 0 for token in seq] for seq in X_train_encoded.numpy()]\nX_val_encoded = [[token if token &lt; max_input_dim else 0 for token in seq] for seq in X_val_encoded.numpy()]\n\n\n# Split encoded texts into chunks of max length 512\nX_train_chunks = [chunk for text in X_train_encoded for chunk in (\n    [text[i:i + max_length] for i in range(0, len(text), max_length)] if len(text) &gt; max_length else [\n        text])]\nX_val_chunks = [chunk for text in X_val_encoded for chunk in (\n    [text[i:i + max_length] for i in range(0, len(text), max_length)] if len(text) &gt; max_length else [\n        text])]\n\n# Pad the encoded chunks\nX_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_chunks, padding='post', maxlen=max_length)\nX_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_chunks, padding='post', maxlen=max_length)\n\n# %% Create TensorFlow datasets\nbatch_size = 32\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, X_train))\ntrain_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, X_val))\n\n\n# %%\n\ndef print_loss(epoch, logs):\n    train_loss = logs['loss']\n    val_loss = logs['val_loss']\n    print(f&quot;Epoch {epoch + 1}: Train loss = {train_loss}, Validation loss = {val_loss}&quot;)\n\n\nnum_epochs = 15\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # monitor the validation loss\n    patience=3,  # stop after the validation loss doesn't improve for 3 epochs\n    restore_best_weights=True  # restore the weights from the epoch with the best validation loss\n)\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=val_dataset,\n    callbacks=[\n        early_stopping,\n        tf.keras.callbacks.LambdaCallback(\n            on_epoch_end=lambda epoch, logs: print_loss(epoch, logs)\n        )\n    ]\n)\n\n# %% Save the model\noutput_dir = os.getcwd()\nmodel.save(output_dir + '\/af_gpt2_model')\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Provisioning of new workspace is adding a Key Vault diagnostic setting to the Storage Account",
        "Question_created_time":1682002359633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1250547\/provisioning-of-new-workspace-is-adding-a-key-vaul",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Provisioning a new Azure Machine Learning instance (and the dependant services, such as the Key Vault and Storage Account) either manually via the portal or using Bicep, it is creating an undocumented setting against the Key Vault diagnostic settings called <code>KeyVaultLogging<\/code> that outputs to the Storage Account.<\/p>\n<p>I've tested different API's - working backwards from the current 2022-12-01-preview back to 2022-05-01 and it still does this. I believe it is a recent change, there is no docs that I can find on this setting, and it's not an option to enable\/disable in the Bicep\/ARM\/Terraform templates that I can see, so must be something deeper.<\/p>\n<p>To answer the question as to why wouldn't you want this setting enabled - we output our diagnostic settings to a Log Analytics Workspace - we don't need a duplicate set, at a storage cost, going to the Storage Account as well. I can delete the setting but every time I re-run the template it puts it back in.<\/p>\n<p>I can supply Bicep code if required, but outside of that - if you create a new Azure Machine Learning instance manually in the Azure Portal you will see something similar to the images in the Key Vault's diagnostic settings.<\/p>\n<p>I believe this is in-error and should be removed<\/p>\n<p>Region tested UKsouth<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/fe2daa8a-ba0c-40bf-adc0-87b2a32d04d8?platform=QnA\" alt=\"keyvaultlogging1\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/48372595-6506-4710-b8ec-fcba57ade83d?platform=QnA\" alt=\"keyvaultlogging2\" \/><\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How should I make the input format. Azure, API  with C#",
        "Question_created_time":1682325379690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1253405\/how-should-i-make-the-input-format-azure-api-with",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<pre><code>\n         static void Main(string[] args)\n        {\n            InvokeRequestResponseService().Wait();\n        }\n\n        static async Task InvokeRequestResponseService()\n        {\n        .............\n         *** var requestBody = @&quot;{\n                  &quot;&quot;input_data&quot;&quot;: {\n                    &quot;&quot;columns&quot;&quot;: [\n                      &quot;&quot;pclass&quot;&quot;,\n                      &quot;&quot;gender&quot;&quot;,\n                      &quot;&quot;age&quot;&quot;,\n                      &quot;&quot;sibsp&quot;&quot;,\n                      &quot;&quot;embarked&quot;&quot;\n                    ],\n                    &quot;&quot;index&quot;&quot;: [],\n                    &quot;&quot;data&quot;&quot;: []\n                  }\n                }&quot;;   *** \n \n\n\nThe input part of the code generated by &quot;Consume&quot; of &quot;endpoints in azure ml&quot;.\nShow me an example of what form the above should be filled in.\n\n\n\n-----------------------------\n\nThe bottom one was filled like this.\n\nvar requestBody = @&quot;{\n                        &quot;&quot;Inputs&quot;&quot;: {\n                          &quot;&quot;data&quot;&quot;: [\n                            {\n                             &quot;&quot;pclass&quot;&quot;: 2,\n                              &quot;&quot;gender&quot;&quot;:&quot;&quot;female&quot;&quot;,\n                              &quot;&quot;age&quot;&quot;: 70.0,\n                              &quot;&quot;sibsp&quot;&quot;: 0,\n                              &quot;&quot;embarked&quot;&quot;:&quot;&quot;C&quot;&quot;\n                            }\n                          ]\n                        },\n                        &quot;&quot;GlobalParameters&quot;&quot;: {\n                          &quot;&quot;method&quot;&quot;: &quot;&quot;predict&quot;&quot;\n                        }\n                      }&quot;;\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can Azure ML components write to dynamic outputs?",
        "Question_created_time":1682535941823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1259505\/can-azure-ml-components-write-to-dynamic-outputs",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>In the Azure ML SDK v2, is it possible to have a component that writes to different locations in Blob storage based on it's input?  <\/p>\n<p>Here is the only way I could think to arrange this (see <code>path<\/code> in the <code>outputs<\/code> variable), but it doesn't work. I don't think the <code>${{inputs.output_datastore}}<\/code> and <code>${{inputs.output_path}}<\/code> are accessible in the <code>outputs<\/code> definition.<\/p>\n<pre><code class=\"lang-python\">save_result_component = command(\n    name=&quot;save_result_component&quot;,\n    display_name=&quot;Save Result Component&quot;,\n    description=&quot;Saves data at input_path to output_path in output_datastore&quot;,\n    inputs={\n        &quot;input_path&quot;: Input(type=&quot;uri_file&quot;),\n        &quot;output_datastore&quot;: Input(type=&quot;string&quot;),\n        &quot;output_path&quot;: Input(type='string')\n    },\n    outputs=dict(\n        output_path=Output(type=&quot;uri_file&quot;,\n                           mode=&quot;rw_mount&quot;,\n                           path=&quot;azureml:\/\/datastores\/${{inputs.output_datastore}}\/paths\/${{inputs.output_path}}&quot;)\n    ),\n    # The source folder of the component\n    code='.\/save_result',\n    command=&quot;&quot;&quot;python save_result.py \\\n            --input_path ${{inputs.input_path}} --output_path ${{outputs.output_path}} \\\n            &quot;&quot;&quot;,\n    environment=&quot;azureml:ffm_env:4&quot;,\n)\n\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MS recommended way to setup git repo in Azure Devops",
        "Question_created_time":1681786038790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1243554\/ms-recommended-way-to-setup-git-repo-in-azure-devo",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,\nIn one our ML project we are using Azure ML and ADF to deploy ML scoring batch pipeline.\nIn this Pipeline <\/p>\n<ol>\n<li> ADF extract required data from SQL DW on to Azure ML workspace Blob Storage .<\/li>\n<li> Azure ML Batch Pipelines extract the data from Blob and do model scoring and save the prediction in Blob store itself<\/li>\n<li> ADF moves the ML prediction data in Blob on to DataVerse\nSo whole thing is developed in ADF pipeline with above 3 steps . In step #2  in ADF we will call AML Batch Endpoint .\nSo we will have ADF code as well as Azure ML code. In this scenario we want to use Azure Devops git for code management. What is the best way to manage this ?\nShould we have two repos , once for ADF pipeline and one for AML Batch Scoring pipeline ? And we set up CI\/CD in ADF repo ? Are there any example on how this can be setup ? Thank you <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azur ML does not show jobs",
        "Question_created_time":1682510858106,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1259042\/azur-ml-does-not-show-jobs",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>It is already second time Azure Ml Workspace does not jobs in UI. Job is runnning and I only get notification about state (failed, succeded etc.), but can not get outputs and related content.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting Error SQL Server 2019 machine learning service with Python",
        "Question_created_time":1682433688880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1257542\/getting-error-sql-server-2019-machine-learning-ser",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>*I am new to SQL Server (2019) Machine Learning Service....  I have a Table called, TBL_DRIVER_TEST_RESULT, which is having 3 columns, [TEST_DATE], [DRIVER_ID], [RED_POINT], over here I have data of past 1 year. Each driver (around 200) goes for daily test, and they get a RED Point score... this is basically a penalty score. i.e., Scoring 0 on any day is best, but if driver make mistake, then they get red points.... Now based on their past 1 year's performance data, I wanted to cluster them in 5 groups....  (Group1): Consistently Good Performing (Low Red Point) drivers (Group2): Consistently bad Performing (High Red point_) Drivers, (Group3): Drivers who are really improving their performance over time (Group4): Drivers whose performance getting worse.  (Group5): Driver who performs random.... *   <br \/>\n<em>Now I tried using some machine learning here (not sure if there are better \/easier ways to achieve above) and tried following Store Procedure...<\/em>\nBut when I am executing this: I am constantly getting error as:     <\/p>\n<blockquote>\n<p>&quot;Error executing external script: Procedure expects parameter '@params' of type 'ntext\/nchar\/nvarchar'.&quot;<\/p>\n<\/blockquote>\n<p>Please can someone help?<\/p>\n<pre><code class=\"lang-sql\">ALTER PROCEDURE [dbo].[usp_cluster_DRIVER]\nAS\nBEGIN\n    SET NOCOUNT ON;\n\n    -- Declare variables\n    DECLARE @language nvarchar(20) = N'Python';\n    DECLARE @script nvarchar(max) = N'\nimport pandas as pd\nfrom sklearn.cluster import KMeans\n\n# Get input data from SQL Server\ndf = input_data_1\n\n# Remove any null values\ndf.dropna(inplace=True)\n\n# Pivot the data to create a matrix with drivers as rows and days as columns\npivoted_df = df.pivot(index=&quot;DRIVER_ID&quot;, columns=&quot;TEST_DATE&quot;, values=&quot;RED_POINT&quot;)\n\n# Use KMeans clustering to cluster the drivers based on their daily red points\nkmeans = KMeans(n_clusters=5, random_state=42)\nkmeans.fit(pivoted_df)\n\n# Add the cluster labels to the input dataframe\ndf_clustered = pd.concat([pivoted_df.reset_index()[&quot;DRIVER_ID&quot;], pd.DataFrame(kmeans.labels_, columns=[&quot;cluster&quot;])], axis=1)\n\n# Output the clustered data to SQL Server\noutput_data_1 = df_clustered\n    ';\n\n    DECLARE @input_data_1_name nvarchar(128) = N'input_data_1';\n    DECLARE @input_data_1_query nvarchar(max) = N'SELECT [TEST_DATE], [DRIVER_ID], [RED_POINT] FROM [dbo].[TBL_DRIVER_TEST_RESULTS]';\n    DECLARE @output_data_1_name nvarchar(128) = N'output_data_1';\n\tDECLARE @params nvarchar(1000) = cast('@input_data_1_query nvarchar(max), @output_data_1_name nvarchar(128)' as nvarchar(1000))\n\n\n    -- Execute the external script\n    BEGIN TRY\n        EXEC sp_execute_external_script\n            @language = @language,\n            @script = @script,\n            @input_data_1_query = @input_data_1_query,\n            @input_data_1_name = @input_data_1_name,\n            @output_data_1_name = @output_data_1_name,\n            @params = @params,\n            @output_data_1_table = N'result'\n    END TRY\n    BEGIN CATCH\n        PRINT 'Error executing external script: ' + ERROR_MESSAGE()\n        RETURN\n    END CATCH\n\n    -- Select the output data\n    SELECT *\n    INTO result\n    FROM output_data_1\n    WHERE 1 = 0;\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What packages are needed to use a Azure URI with pandas",
        "Question_created_time":1682358462623,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1254146\/what-packages-are-needed-to-use-a-azure-uri-with-p",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am running a pipeline using the Azure ML Python SDK v2. For one of the pipeline steps, a <code>.csv<\/code> file in blob storage is being passed as input using <code>InputOutputModes.DIRECT<\/code>. In my understanding, this means that the pipeline step will be receiving a uri filepath <code>azureml:\/\/[blah]<\/code> . Within the pipeline step, I am calling <code>pandas.read_csv()<\/code> on the input, but am receiving the error <code>protocol not known : azureml<\/code> . This same function call works in a notebook using the Python 3.10 - SDK v2 kernel. So, my question is what packages need to be in the pipeline step's environment in order to be able to call <code>pandas.read_csv()<\/code> with the uri filepath? I've tried many different things, the most recent environment I tried is below. Any help is appreciated...<\/p>\n<pre><code class=\"lang-yaml\">name: prs-env\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7.6\n  - pip\n  - pip:\n      - matplotlib~=3.5.0\n      - psutil~=5.8.0\n      - tqdm~=4.62.0\n      - pandas~=1.3.0\n      - scipy~=1.7.0\n      - numpy~=1.21.0\n      - ipykernel~=6.0\n      - azureml-core==1.48.0\n      - azureml-defaults==1.48.0\n      - azureml-mlflow==1.48.0\n      - azureml-telemetry==1.48.0\n      - scikit-learn~=1.0.0\n      - debugpy~=1.6.3\n      - usaddress\n      - fsspec\n<\/code><\/pre>",
        "Question_closed_time":1682364114190,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Use the <a href=\"https:\/\/pypi.org\/project\/azureml-fsspec\/\"><code>azureml-fsspec<\/code><\/a> package:<\/p>\n<pre><code class=\"lang-bash\">pip install azureml-fsspec\n<\/code><\/pre>\n<p><strong>Note:<\/strong> The accepted URI format for the datastore URI is:\n<code>azureml:\/\/subscriptions\/([^\/]+)\/resourcegroups\/([^\/]+)\/workspaces\/([^\/]+)\/datastores\/([^\/]+)\/paths\/([^\/]+)<\/code><\/p>\n<p>This should technically work:<\/p>\n<pre><code class=\"lang-python\">import azureml-fsspec\nimport pandas as pd\n\n# credentials and variables\nsubscription = '&lt;subscription_id&gt;'\nresource_group = '&lt;resource_group&gt;'\nworkspace = '&lt;workspace&gt;'\ndatastore_name = '&lt;datastore&gt;'\npath_on_datastore '&lt;path&gt;'\nfile = '&lt;myfile.csv&gt;'\n\n# generate uri:\nuri = f'azureml:\/\/subscriptions\/{subscription}\/resourcegroups\/{resource_group}\/workspaces\/{workspace}\/datastores\/{datastore_name}\/paths\/{path_on_datastore}\/{file}'\n\n# read via pandas\ndf = pd.read_csv(uri)\n<\/code><\/pre>\n<p><em>See <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-interactive?view=azureml-api-2&amp;tabs=adls\">Azure Machine Learning - Access Data from Azure Cloud Storage During Interactive Development<\/a> for details.<\/em><\/p>\n<p>or you could try the <code>AzureMachineLearningFileSystem<\/code> class from the package:<\/p>\n<pre><code class=\"lang-python\">import pandas\nfrom azureml.fsspec import AzureMachineLearningFileSystem\n\n# instantiate file system using following URI\nfs = AzureMachineLearningFileSystem('azureml:\/\/subscriptions\/&lt;subid&gt;\/resourcegroups\/&lt;rgname&gt;\/workspaces\/&lt;workspace_name&gt;\/datastore\/datastorename')\n\nfs.ls() # list folders\/files in datastore 'datastorename'\n\n# use an open context\nwith fs.open('.\/folder1\/file1.csv') as f:\n    # do some process\n    df = pandas.read_csv(f)\n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why does auto-suggestion for columns not work in Azure ML studios?",
        "Question_created_time":1682340940846,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1253775\/why-does-auto-suggestion-for-columns-not-work-in-a",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hey everyone,I'm new to Azure ML studio and I'm trying to set up a ML pipeline in the designer. I'm using the &quot;Adult Census Income&quot; Dataset provided by Azure and in the data preview the schema is applied to the table. But now I want to use the &quot;Select Columns in Dataset&quot; and &quot;Edit Metadata&quot; component, but I cannot use the auto-suggestion, because it's showing the error:\nAuto-suggestion errorAnd I'm using a very simple pipeline, like shown here:  <br \/>\nPipelineWhat am I doing wrong? I mean, the provided data set is a dataset with a schema provided by Azure and I think there is nothing wrong with that, so where is the problem?\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/10344dec-e5bc-4307-8332-9f31a460e28a?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>And I'm just using a simply pipeline like this one:\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/77be75e0-1647-41a8-a9af-8bcc46b10f3e?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I check to see if an Auto ML model is actually training in Azure Machine Learning Studio?",
        "Question_created_time":1682358776493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1254147\/how-do-i-check-to-see-if-an-auto-ml-model-is-actua",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have an Auto ML job running in Azure Machine Learning Studio (AMLS) that is training its models. The data set associated with the job is just south of 900k rows of 2-column .csv data so I expect it to take some time due to the size. However, the first run just passed the 12-hour mark and not a single child job has been completed. I'm curious if there's a place that I can check to see if the job is actually training, stuck, etc. I'm relatively new to AMLS so forgive my ignorance of the best ways to debug. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/b4c49cf5-fdab-4be0-a8ab-b45a16f5a6d7?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>P.s., I'm running 1 node of Standard E8s_v3 clustered @ 4 cores and 32g of RAM.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Loading multiple models in an online fully managed endpoint",
        "Question_created_time":1682113257410,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1251565\/loading-multiple-models-in-an-online-fully-managed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey there!<\/p>\n<p>I am creating an endpoint which chains inference from different models. At the moment I solve the loading of them by doing:<\/p>\n<pre><code class=\"lang-python\"># define models paths\nartifacts_dir = Path(os.getenv(&quot;AZUREML_MODEL_DIR&quot;)) \/ &quot;artifacts&quot;\nmodel_file_path = &quot;runwayml\/stable-diffusion-v1-5&quot;\ngfpgan_model_file_path = artifacts_dir \/ &quot;gfpgan&quot; \/ &quot;gfpgan_v1.4.pth&quot;\ncontrolnet_model_file_path = artifacts_dir \/ &quot;controlnet&quot; \/ &quot;scribble_sd15&quot;\nembedding_file_path = (\n    artifacts_dir \/ &quot;stable_diffusion&quot; \/ &quot;sd15_journal_sketch_inversion.bin&quot;\n)\n\ninference = Inference(\n        model_file_path=model_file_path,\n        gfpgan_model_file_path=gfpgan_model_file_path,\n        enable_xformers=False,\n        controlnet_type=&quot;controlnet&quot;,\n        controlnet_model_file_path=controlnet_model_file_path,\n        embedding_file_path=embedding_file_path,\n)\n<\/code><\/pre>\n<p>The problem with this, is that I have all the models in a single artifact folder registered as a Model in the ML workspace. This works, but if I want to change or update only one of the models, I would need to re-upload the whole folder which is quite expensive in terms of storage and time.<\/p>\n<p>I found an <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\">example<\/a> using the python SDK v2:<\/p>\n<pre><code>from azureml.core.model import Model\n\ndef init():\n    global model_1, model_2\n    # Here &quot;my_first_model&quot; is the name of the model registered under the workspace.\n    # This call will return the path to the .pkl file on the local disk.\n    model_1_path = Model.get_model_path(model_name='my_first_model')\n    model_2_path = Model.get_model_path(model_name='my_second_model')\n    \n    # Deserialize the model files back into scikit-learn models.\n    model_1 = joblib.load(model_1_path)\n    model_2 = joblib.load(model_2_path)\n<\/code><\/pre>\n<p>And I was wondering if there's anything similar for SDK v2. I tried to find information on the net, but couldn't find any.<\/p>\n<p>If you have any lead would be greatly appreciated!\nThank you so much!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I want to use Azure ML trained model on my computer. How do I do in off-line (without web) mode?",
        "Question_created_time":1682042885700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1251080\/i-want-to-use-azure-ml-trained-model-on-my-compute",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<pre><code>\nI want to use Azure ML trained model on my computer. How do I do in off-line (without web) mode? \n\nAfter training something with Azure ML(or Automated ML), \n  then what I should save at my local computer? \n\nI want to get the output result by giving a new dataset input to the saved model(Azure model data).\n\nI will use C#.\n(Of course, there is a machine learning function in C#, and I have used it.)\n\n\nIs it possible?\nWhat kind of process should I go through?\n\nI'm a beginner and simple understanding of Azure ML. \nI would appreciate it if you could explain it easily and step by step.\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"os.makedir() in score.py, init() function, throws permission error while deploying",
        "Question_created_time":1681396615953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1229685\/os-makedir()-in-score-py-init()-function-throws-pe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have to create files and directories in order to perform prediction of my custom model.\nhere is my init function and deployment logs :<\/p>\n<pre><code class=\"lang-python\">\nimport os\n\ninputs_root = &quot;inputs&quot;\noutputs_root = &quot;outputs&quot;\n\ndef init():\n    if not os.path.exists(inputs_root):\n        os.mkdir(inputs_root)\n    if not os.path.exists(outputs_root):\n        os.mkdir(outputs_root)\n\n<\/code><\/pre>\n<p>It throws following error which can be seen from the deployment logs as follows : <\/p>\n<pre><code>2023-04-13 14:10:52,736 E [68] azmlinfsrv - Encountered Exception Traceback (most recent call last):\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 117, in invoke_init\n    self._user_init()\n  File &quot;\/var\/azureml-app\/avaj1870\/src\/score.py&quot;, line 71, in init\n    os.mkdir(inputs_root)\nPermissionError: [Errno 13] Permission denied: 'inputs'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 111, in setup\n    self.user_script.invoke_init()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 119, in invoke_init\n    raise UserScriptException(ex) from ex\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml.train'",
        "Question_created_time":1681319549420,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1226248\/modulenotfounderror-no-module-named-azureml-train",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am getting the following error:\n<strong>ModuleNotFoundError: No module named 'azureml.train'<\/strong>\nWhenever I try to import the HyperDriveConfig module:\n<strong>from azureml.train.hyperdrive import HyperDriveConfig.<\/strong>\nI tried the suggested solution from the following post:\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168278\/modulenotfounderror-no-module-named-azureml-train\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168278\/modulenotfounderror-no-module-named-azureml-train<\/a>\npip install azureml-sdk[train]\nbut I am getting the following:\n  <strong>WARNING: azureml-sdk 1.48.0 does not provide the extra 'train'<\/strong>\nRegards,\nHesham<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error during Azure SDK deployment - ERROR: No matching distribution found for azureml-sdk~=1.49.0",
        "Question_created_time":1680941266066,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1204810\/error-during-azure-sdk-deployment-error-no-matchin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, I am getting below error during Azure-SDK deployment. I tried !pip install azureml-sdk==1.47. Can someone help me with this issue.\n[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nInstalling pip dependencies: ...working... Ran pip subprocess with arguments:\n['\/azureml-envs\/azureml_-----------------------------------\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/azureml-environment-setup\/condaenv.2033jmf7.requirements.txt', '--exists-action=b']\nPip subprocess output:\nfailed\n\u001b[91mPip subprocess error:\nERROR: Could not find a version that satisfies the requirement azureml-sdk~=1.49.0 (from versions: 0.1.57, 0.1.58, 0.1.59, 0.1.65, 0.1.68, 0.1.74, 0.1.80, 1.0rc83, 1.0rc85, 1.0.2, 1.0.6, 1.0.8, 1.0.10, 1.0.15, 1.0.15.1, 1.0.17, 1.0.18, 1.0.18.1, 1.0.21, 1.0.23, 1.0.30, 1.0.33, 1.0.39, 1.0.41, 1.0.43, 1.0.45, 1.0.48, 1.0.53, 1.0.55, 1.0.57, 1.0.60, 1.0.62, 1.0.65, 1.0.69, 1.0.72, 1.0.74, 1.0.76, 1.0.79, 1.0.81, 1.0.83, 1.0.85, 1.1.0rc0, 1.1.1rc0, 1.1.2rc0, 1.1.5, 1.1.5.1, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.7.0.post1, 1.8.0, 1.9.0, 1.10.0, 1.11.0, 1.12.0, 1.13.0, 1.14.0, 1.15.0, 1.16.0, 1.17.0, 1.18.0, 1.19.0, 1.20.0, 1.21.0, 1.22.0, 1.23.0, 1.24.0, 1.25.0, 1.26.0, 1.27.0, 1.28.0, 1.29.0, 1.30.0, 1.31.0, 1.32.0, 1.33.0, 1.33.0.post1, 1.34.0, 1.35.0, 1.36.0, 1.37.0, 1.38.0, 1.39.0, 1.40.0, 1.41.0, 1.42.0, 1.43.0, 1.44.0, 1.45.0, 1.46.0, 1.47.0)\nERROR: No matching distribution found for azureml-sdk~=1.49.0\nCondaEnvException: Pip failed\n\u001b[0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_---------------------- -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} + &amp;&amp; ldconfig' returned a non-zero code: 1\n2023\/04\/08 07:22:42 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 1\nRun ID: cg2 failed after 2m56s. Error: failed during run, err: exit status 1<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Specifying AzureML output destination in SDK v2",
        "Question_created_time":1660825064220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/972481\/specifying-azureml-output-destination-in-sdk-v2",
        "Question_score_count":6,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi. I have set up an AzureML pipeline with YAML components using the Python SDK (v2) with an attached blob store. However, it appears that the output destination is handled automatically by AzureML and so I can't specify where on the blob the pipeline writes its output. I want to configure the AzureML pipeline run using ADF, which involves moving some data to the blob, running the AzureML pipeline, and then moving some data from the blob to somewhere else. The trouble is that ADF doesn't get access to the AzureML output directory, and so it won't know where to look for the output file.     <\/p>\n<p>I have tried to pass the output directory as an input rather than an output so that I can explicitly state where this should go. The directory, however, gets mounted as read only (quite sensibly by design, I trust) so that doesn't work. So I'm kind of running out of options.     <\/p>\n<p>Is there any way for me specify the output path for an Azure ML SDK v2 pipeline in a similar way to how I would specify an input path? Alternatively, is there another way of solving this particular predicament of mine?    <\/p>\n<p>I have looked through the notebooks (e.g. <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/8a4070f55593c9641083784283b773f4f20955dd\/sdk\/jobs\/pipelines\/1a_pipeline_with_components_from_yaml\/pipeline_with_components_from_yaml.ipynb\">https:\/\/github.com\/Azure\/azureml-examples\/blob\/8a4070f55593c9641083784283b773f4f20955dd\/sdk\/jobs\/pipelines\/1a_pipeline_with_components_from_yaml\/pipeline_with_components_from_yaml.ipynb<\/a>) and I can't find an example where people explicitly control the output destination (which seems odd).     <\/p>\n<p>Thoughts?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Designer is not retrieving the graphs of the pipelines",
        "Question_created_time":1681994735056,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1250366\/azureml-designer-is-not-retrieving-the-graphs-of-t",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,\nI am experiencing some problems with designer in azure ML. I have several pipelines submitted and they have run correctly, but today I am not able to retrieve any graph. IF I start a new one at the moment I use more than 3 boxes the error appears. \nWhat am I doing wrong?\nThanks in advance<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Thank You to the Microsoft Q&A Community Champions",
        "Question_created_time":1676961474750,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182621\/thank-you-to-the-microsoft-q-a-community-champions",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We would like to celebrate this month's\u202f<a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Community Champions<\/a>\u202ffor their great contribution to the community on Microsoft Q&amp;A!<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Microsoft Q&amp;A Community Champions<\/a>\u202fprogram recognizes external technology experts who contribute to the Microsoft Q&amp;A community by providing quality answers to technical questions. They are our true \u2018champions\u2019 and provide additional help by taking moderator roles and provide suggestions to improve our overall platform as well as user experience. This program includes both MVPs and non-MVP expert users.\u00a0<\/p>\n<p>We recognize top contributors by providing incentives like moderator privileges in Microsoft Q&amp;A platform, gift cards\u00a0and also share about Q&amp;A contributions in social media channels like <a href=\"https:\/\/twitter.com\/AzureSupport\/status\/1458525468064288777?s=20\">Azure Support Twitter handle<\/a> and in <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/azure-leaderboard\">Microsoft Q&amp;A Azure Leaderboard<\/a>. \u00a0<\/p>\n<p><strong>Thank You to all the Microsoft Q&amp;A Community Champions.<\/strong>\u00a0  <br \/>\nThey are helping make Microsoft Q&amp;A a vibrant place for learning.\u00a0<\/p>\n<p>@JimmySalian-2011 @DillonJS @AlbertoMorillo @soysoliscarlos @AndyDavid @lukemurraynz @NandanHegde-7720 @maserg @michev @DSPatrick @BjoernPeters @AndreasBaumgarten @MichaelDurkan-1632 @msrini-MSFT @ricardosolisvillegas-4678 @stan @DavidBroggy-5270 @ManuPhilip @SandervandeVelde42 @AndrewBlumhardt-1137 @dkrishnaveni-MSFT @AlistairRoss msft @Vinodh247-1375 @rafalzak @HARPREET-MSFT @sreejukg @ErlandSommarskog @martins jackson @RoderickBant74 @OlgaOS-msft @AlanKinane @AndriyBilous @SubashriVasudevan-1752 @cooldadtx @CristianSPIRIDON72 @rbrundritt @Sam-Cogan @TakahitoIwasa @chbeier @clivewatson-9831 @RamyaHarinarthini-MSFT @PratikSomaiya @Samy-7940 @shivapatpi-MSFT @learn2skills @maabdelr-MSFT @ArunSiripuram-1453 @BrunoLucas-9843 @pituach @RafaelDaRocha @ZollnerD @AndreiBarbu-MSFT @CarlosVillagomez-MSFT @lextm @AkramKathimi @subrothodas-9589 @ScottAzureRTOS @GeorgeMoise-0315\u00a0<\/p>\n<p><strong>Also, if you are interested in joining the Microsoft Q&amp;A Community Champions program and help shape the future of Microsoft Q&amp;A, please apply here:<\/strong>\u00a0<strong><a href=\"https:\/\/forms.office.com\/r\/vQcapa5BtB\">Community Champions Application Form<\/a><\/strong><\/p>\n<p>Special invitation to:\u00a0\u00a0<\/p>\n<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=54ee969b-3f40-4741-89f4-fff4be002d6e\">TP<\/a> @<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6f6bb61e-afe6-4f38-9f92-62a4655b7267\">Bruce (SqlWork.com)<\/a> @<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d70d5c95-0000-0003-0000-000000000000\">Bas Pruijn<\/a> <a href=\"\/users\/na\/?userid=857fa4fc-0000-0003-0000-000000000000\">@Olaf Helper  <\/a>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=115cb2ce-0487-49af-ae2c-8e6d8498c982\">LiHong-MSFT<\/a> @<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=95fe2526-bffd-0006-0000-000000000000\">Viorel<\/a> @<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=439d8369-91cf-4be6-9739-cdceba37a452\">Amit Singh<\/a> @<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=84f91418-bffd-0006-0000-000000000000\">Ali AlEnezi<\/a> <a href=\"\/users\/na\/?userid=479fd2ce-78dd-45ff-90e7-5461aedcc33e\">@Ebraheem Al-Muneyeer (MSFT)  <\/a><a href=\"\/users\/na\/?userid=06a47182-cdbf-4638-b646-f25d94014b83\">@John Deutscher (MSFT)  <\/a>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=7b47a988-7d11-41da-b2c5-8f42327776c2\">Rahul Randive<\/a> <a href=\"\/users\/na\/?userid=ce80ee7b-dcf4-475f-9d98-38cc6127e394\">@Rich Matheisen  <\/a> <a href=\"\/users\/na\/?userid=817c238b-4001-0003-0000-000000000000\">@Pavel Yannara Mirochnitchenko   <\/a><a href=\"\/users\/na\/?userid=0135a662-9db3-44da-88a9-747c6a560515\">@Shivam Dhiman  <\/a>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=14d0047a-2825-4cf3-856b-239f6b321d46\">Umang Middha<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to grant a system assigned managed identity an access to a workspace",
        "Question_created_time":1679668486163,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1192890\/how-to-grant-a-system-assigned-managed-identity-an",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I select &quot;system assigned managed identity&quot; in the &quot;Managed identity&quot; panel of my compute cluster.<\/p>\n<p>But when I go to the AML Workspace panel to gran READER acces to this managed Identity, I can not find it among the managed identity.<\/p>\n<p>I have to set an &quot;User assigned managed identity&quot; for my compute cluster and then I can find this kind of managed identity in the AML Workspace panel and grant the READER Access.<\/p>\n<p>Why can I not retrieve the system assigned managed identity ?<\/p>\n<p>The compute cluster is in another region than the one of the workspace. Is this the reason ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access App that has Authentication from ML workspace pipeline",
        "Question_created_time":1680861185100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1202342\/access-app-that-has-authentication-from-ml-workspa",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I have an App service for labeling data that has an API for importing and exporting the data. I also have ML workspace that has pipelines for import and export. They are both in the same Azure Active directory, subscription and resource group. Pipelines worked when there was no authentication, but now that I registered the App to the Azure AD for Microsoft IdP it doesn't work anymore because ML workspace has forbidden access. Is there a way to register ML workspace to Azure AD so that it has access, or is there some way to whitelist ML workspace through managed identity, or some other way to authenticate the workspace so it can access the app?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML MLFlow Batch Endpoint - Image build failed",
        "Question_created_time":1681910517490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1248565\/automl-mlflow-batch-endpoint-image-build-failed",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>When deploying an MLFlow model generated by Azure AutoML as a batch endpoint, using no-code option, the following &quot;Image build failed&quot; error occurs:<\/p>\n<pre><code>ERROR: Ignored the following versions that require a different python version: 0.7 Requires-Python &gt;=3.6, &lt;3.7; 0.8 Requires-Python &gt;=3.6, &lt;3.7; 1.19.0 Requires-Python &gt;=3.5,&lt;3.8; 1.20.0 Requires-Python &gt;=3.5,&lt;3.8; 1.20.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.21.0 Requires-Python &gt;=3.5,&lt;3.8; 1.21.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.22.0.post2 Requires-Python &gt;=3.6,&lt;3.8; 1.23.0 Requires-Python &gt;=3.5,&lt;3.8; 1.23.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.24.0 Requires-Python &gt;=3.5,&lt;3.8; 1.25.0 Requires-Python &gt;=3.5,&lt;3.8; 1.25.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.26.0 Requires-Python &gt;=3.5,&lt;3.8; 1.26.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.27.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0.post1 Requires-Python &gt;=3.5,&lt;3.8; 1.28.0.post2 Requires-Python &gt;=3.5,&lt;3.8; 1.29.0 Requires-Python &gt;=3.6,&lt;3.8; 1.29.0.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.30.0 Requires-Python &gt;=3.6,&lt;3.8; 1.31.0 Requires-Python &gt;=3.6,&lt;3.8; 1.32.0 Requires-Python &gt;=3.6,&lt;3.8; 1.33.0 Requires-Python &gt;=3.6,&lt;3.8; 1.33.1 Requires-Python &gt;=3.6,&lt;3.8; 1.33.1.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.0 Requires-Python &gt;=3.6,&lt;3.8; 1.34.0.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.1 Requires-Python &gt;=3.6,&lt;3.8; 1.34.1.post1 Requires-Python &gt;=3.6,&lt;3.8; 1.35.0 Requires-Python &gt;=3.6,&lt;3.8; 1.35.1 Requires-Python &gt;=3.6,&lt;3.8; 1.36.0 Requires-Python &gt;=3.6,&lt;3.8; 1.36.1 Requires-Python &gt;=3.6,&lt;3.8; 1.37.0 Requires-Python &gt;=3.6,&lt;3.8; 1.38.0 Requires-Python &gt;=3.6,&lt;3.8; 3.2.0.dev1 Requires-Python &gt;=3.9\nERROR: Could not find a version that satisfies the requirement en-core-web-sm==2.1.0 (from versions: none)\nERROR: No matching distribution found for en-core-web-sm==2.1.0\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml' even after installation",
        "Question_created_time":1680956375293,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1205393\/modulenotfounderror-no-module-named-azureml-even-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm unable to import the azure ml in the jupyter notebook, I have followed the steps from <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py<\/a>, still it is showing like below<\/p>\n<pre><code>ModuleNotFoundError: No module named 'azureml'\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to use installed packages in azure ML studio terminal to notebook",
        "Question_created_time":1681851491320,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1245739\/how-to-use-installed-packages-in-azure-ml-studio-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have installed few packages in both the terminal and notebook of Azure Machine Learning studio. \nI did both pip as well as pip3 install. \nTerminal goes about installing these pip packages without any problem the problem arises when I'm trying to import these into my notebook\n It throws me <code>ModuleNotFoundError<\/code> error. Even a most basic library like tensorflow and pytorch are not being imported into my notebook.\nBut here's a curveball, running python inside the terminal and calling the import statement works.\nWhat's the problem here, aren't the terminal and notebook python the same? But that doesn't answer why the notebook's pip statement also produces the same error. \nInstalling and using python packages is such an basic necessity to have in any environment. It's too sad I've wasted a better part of my day to fixing the horrible error. \nanyways, any help is greatly appreciated \nThanks <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting net\/http: request canceled while waiting for connection error when deploying a model trained with Azure Auto ML via Azure Studio",
        "Question_created_time":1672778054923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1150355\/getting-net-http-request-canceled-while-waiting-fo",
        "Question_score_count":3,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>0    <\/p>\n<p>I am training a simple text classification model in Azure Auto ML. Got a decent model and now trying to deploy it. Deployment goes ok initially and I get:    <\/p>\n<pre><code>Provisioning state: Succeeded  \n<\/code><\/pre>\n<p>But then after a while, Provisioning state is returning an error: and no traffic as allocated to the model. <code>ResourceNotReady: User container has crashed or terminated: Liveness probe failed: HTTP probe failed with statuscode: 502.<\/code>    <\/p>\n<p>When I logs at deployment logs, I see following on top of bunch successful env creation logs:    <\/p>\n<pre><code>Container events:  \nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2023-01-03T13:22:14.905684Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502  \nKind: Pod, Name: Killing, Type: Normal, Time: 2023-01-03T13:22:14.912478Z, Message: Stopping container inference-server  \nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2023-01-03T13:22:18.653423Z, Message: Readiness probe failed: Get http:\/\/10.66.0.2:5001\/: net\/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)  \n<\/code><\/pre>\n<p>Looks to me like contained was deployed but is not reachable?    <\/p>\n<p>I tried various combinations of models and virtual machines, but it ends up in this error every time.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML.Studio CUDNN_STATUS_EXECUTION_FAILED on free Compute Instance and envs\/azureml_py38_PT_TF",
        "Question_created_time":1680269577220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195104\/azure-ml-studio-cudnn-status-execution-failed-on-f",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi. While using free compute instance in ml.studio wit envs\/azureml\/_<em>py38<\/em>__PT_TF (preinstalled environment), my noteboog training fails on cuDNN error: CUDNN_STATUS_EXECUTION_FAILED.<\/p>\n<p>What I understand, the error emerges from pytorch library and up to my knowledge it leads to incompatibility of pytorch and cudnn. <\/p>\n<p>I can run it on my home PC with RTX3060 without any troubles.<\/p>\n<p>How could I fix this?<\/p>\n<p>thank you, Jan<\/p>\n<p>The error prompt is:<\/p>\n<pre><code class=\"lang-python\">[INFO] training the network...\nEpoch 1\/10\n\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/escafree\/code\/Users\/jan.kanka\/ds_handle.py:175: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  \/opt\/conda\/conda-bld\/pytorch_1656352463056\/work\/aten\/src\/ATen\/native\/Convolution.cpp:882.)\n  outimg = F.conv2d(img[None].float(), kernel.float(), padding=&quot;same&quot;, groups=3)\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nInput In [5], in &lt;cell line: 1&gt;()\n----&gt; 1 escanet.train()\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/escafree\/code\/Users\/jan.kanka\/classnet.py:310, in TrainModel.train(self)\n    308 x, y = http:\/\/x.to(self.device), http:\/\/y.to(self.device)\n    309 # perform a forward pass and calcualte the training lss\n--&gt; 310 pred = self.model(x)\n    311 loss = self.lossBCE(\n    312     torch.squeeze(pred), torch.squeeze(y.float())\n    313 )  # + diceloss(torch.squeeze(pred), torch.squeeze(y))jaccard_loss(torch.squeeze(pred), torch.squeeze(y)) + FocLossFn(torch.squeeze(pred), torch.squeeze(y)) #+ lossBCE(torch.squeeze(pred), torch.squeeze(y))\n    314 pred_bin = ((http:\/\/pred.to(&quot;cpu&quot;)).detach().numpy() &gt; 0.5) * 1\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/nn\/modules\/module.py:1130, in Module._call_impl(self, *input, **kwargs)\n   1126 # If we don't have any hooks, we want to skip the rest of the logic in\n   1127 # this function, and just call forward.\n   1128 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1129         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1130     return forward_call(*input, **kwargs)\n   1131 # Do not call functions when jit is used\n   1132 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/escafree\/code\/Users\/jan.kanka\/classnet.py:156, in EscaClass.forward(self, Input)\n    155 def forward(self, Input):\n--&gt; 156     x = self.ConvPart(Input)\n    157     Output = self.DenseTop(x)\n    159     return Output\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/nn\/modules\/module.py:1130, in Module._call_impl(self, *input, **kwargs)\n   1126 # If we don't have any hooks, we want to skip the rest of the logic in\n   1127 # this function, and just call forward.\n   1128 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1129         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1130     return forward_call(*input, **kwargs)\n   1131 # Do not call functions when jit is used\n   1132 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/escafree\/code\/Users\/jan.kanka\/classnet.py:114, in ConvPart.forward(self, x)\n    112 x = self.pool1(x)\n    113 x = self.conv_1(x)  # 64 -&gt; 64\n--&gt; 114 x = self.BatchNorm1(x)\n    115 x = self.Activation1(x)\n    116 x = self.pool2(x)\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/nn\/modules\/module.py:1130, in Module._call_impl(self, *input, **kwargs)\n   1126 # If we don't have any hooks, we want to skip the rest of the logic in\n   1127 # this function, and just call forward.\n   1128 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1129         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1130     return forward_call(*input, **kwargs)\n   1131 # Do not call functions when jit is used\n   1132 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/nn\/modules\/batchnorm.py:168, in _BatchNorm.forward(self, input)\n    161     bn_training = (self.running_mean is None) and (self.running_var is None)\n    163 r&quot;&quot;&quot;\n    164 Buffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\n    165 passed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\n    166 used for normalization (i.e. in eval mode when buffers are not None).\n    167 &quot;&quot;&quot;\n--&gt; 168 return F.batch_norm(\n    169     input,\n    170     # If buffers are not to be tracked, ensure that they won't be updated\n    171     self.running_mean\n    172     if not http:\/\/self.training or self.track_running_stats\n    173     else None,\n    174     self.running_var if not http:\/\/self.training or self.track_running_stats else None,\n    175     self.weight,\n    176     self.bias,\n    177     bn_training,\n    178     exponential_average_factor,\n    179     self.eps,\n    180 )\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/nn\/functional.py:2438, in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n   2435 if training:\n   2436     _verify_batch_size(input.size())\n-&gt; 2438 return torch.batch_norm(\n   2439     input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n   2440 )\n\nRuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I figure out what went wrong with Azure Machine Learning Endpoint deployment?",
        "Question_created_time":1681761398896,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1242838\/how-do-i-figure-out-what-went-wrong-with-azure-mac",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>How do I debug a failure to deploy an Azure Machine Learning Endpoint? The provisioning state is Failed, and Error Details are blank. This has all been done with no-code via the Azure ML Workspace UI.  <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/98b21493-6b17-4381-ae41-dd5c410eccc7?platform=QnA\" alt=\"enter image description here\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"From pandas dataframe back to MLTable",
        "Question_created_time":1681457875290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1230648\/from-pandas-dataframe-back-to-mltable",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, in the Microsoft Learn course it shows how we can convert an MLTable into a pandas dataframe with the to_pandas_dataframe() method.<\/p>\n<p>I wonder if the opposite exists, in order to convert from a pandas dataframe into an MLTable.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retirement announcement \u2013 Language Understanding (LUIS) will be retired on 1 October 2025",
        "Question_created_time":1664563968237,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1031241\/retirement-announcement-language-understanding-(lu",
        "Question_score_count":0,
        "Question_answer_count":12,
        "Question_comment_count":4,
        "Question_body":"<p>On 1 October 2025, Language Understanding (LUIS) will be retired. Starting 1 April 2023, you will not be able to create new LUIS resources. All your existing LUIS resources and applications will continue to be fully supported until the retirement date. You can migrate your LUIS applications to the next generation service conversational language understanding, a capability of Azure Cognitive Services for Language.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Workspace - Unable to get access token for ADLS Gen2",
        "Question_created_time":1681228111046,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1220935\/azure-ml-workspace-unable-to-get-access-token-for",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello Microsoft Q&amp;A,\nwhen running azure ml pipelines I got the following error:\n&quot; permission denied when access stream. Reason: Some(This request is not authorized to perform this operation using this permission.) &quot;\nWhen I checked the data assets for the pipeline, I got the follwoing error:<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/37d53c8a-2bec-4fa5-b769-3d57010a96f7?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>The Azure machine learning workspace is inside a vnet and I'm using a service principal for the data store authentification:\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/aa1dd74a-f306-4ddc-a8ef-97b8fc6ae98a?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I allready granted the workspace managed identity AND the service principal the reader role for ALL private endpointes. Moreover I checked all other permissions, for example that the workspace managed identiy has the blob storage reader role for the adls gen2 storage.\nDoes this has something to do with these changes:\n &quot;Azure Machine Learning Network Isolation Changes with Compute Instance and Compute Cluster&quot;<\/p>\n<p>Could you please help me.<\/p>",
        "Question_closed_time":1681272887700,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello @Lukas\nThanks for reaching out to us. I haven't seen the same error, but based on some researches and my personal experience, the error message you're seeing indicates that the user or service principal running the Azure ML pipeline does not have sufficient permissions to access the data assets required by the pipeline. It's possible that the recent changes to Azure Machine Learning Network Isolation could be a factor in this issue.<\/p>\n<p>Here are some steps you can take to further troubleshoot the issue:<\/p>\n<p>Check the credentials being used to access the data assets: Verify that the credentials being used to access the data assets are correct and have sufficient permissions to read the data. You can check this by attempting to manually access the data assets using the same credentials and seeing if you encounter any issues.<\/p>\n<p>Verify RBAC permissions: Make sure that the user or service principal running the pipeline has the necessary RBAC permissions to access the data assets. You can check this by reviewing the access policies and roles associated with the data assets, and making sure that the user or service principal is included in the appropriate role(s) with sufficient access.<\/p>\n<p>Check firewall and network settings: If the data assets are hosted in a private network, make sure that the firewall and network settings allow the pipeline to access the data. You may need to configure virtual network peering or VPN connections to enable access.<\/p>\n<p>Review pipeline configuration: Double-check the pipeline configuration to ensure that the correct data asset paths and permissions are specified. You can also try re-creating the pipeline from scratch to see if that resolves the issue.<\/p>\n<p>Review the Network Isolation changes: Review the recent Azure Machine Learning Network Isolation changes and ensure that they are not impacting your pipeline. You may need to update your pipeline configuration to account for any changes in network isolation.<\/p>\n<p>If none of the above steps resolve the issue, you can contact Microsoft support for further assistance. Please raise a support ticket if you have a support plan, please let us know if you have tried all above items but nothing works, I am happy to enable you a free ticket for this issue. <\/p>\n<p>I hope this helps! Let me know if you have any further questions.<\/p>\n<p>Regards,\nYutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to Create File based data set for Image Classification in Azure ML Designer",
        "Question_created_time":1677512766130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184724\/how-to-create-file-based-data-set-for-image-classi",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":13,
        "Question_body":"<p>Hi<\/p>\n<p>I want to use the image classification capabilities in Azure ML Designer.  When I create a data set of images from a blob store in Azure, it creates it as a Azure ML v2 file data asset but I believe all of the capabilities of Azure ML Designer require Azure ML v1 file data asset so I am stuck and can't do anything since the file based dataset I can create is the new version (v2) while all of the image capabilities of Azure ML studio require the old version (v1).<\/p>\n<p>Further, if you look at the sample ML Studio Azure Designer Densenet Sample, uses a V1 data set. <\/p>\n<p>Finally, I can't find any of the components (Pils) in the new version of the Designer that the Desnsenet sample uses that can access to the new v2 file based I created in the studio.<\/p>\n<p>Can someone help me move ahead by answering either or both questions:<\/p>\n<p>1 - Explain how I can currently create an Azure ML V1 file data set that I can use with the classic designer pipelines for image classification<\/p>\n<p>or<\/p>\n<p>2 - Point me to a tutorial\/documentation on how to use an Azure ML v2 file data set to do image categorization in the Azure ML Designer<\/p>\n<p>I want to develop the image classification in Designer and NOT Python<\/p>\n<p>Hope this makes sense!  Thx<\/p>\n<p>Dave C<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ImportError: No module named 'sklearn.linear_model._logistic': failing to import a locally train and serialized model",
        "Question_created_time":1617234546277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/339957\/importerror-no-module-named-sklearn-linear-model-l",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have tried importing a simple logistic regression model into Azure ML to use in a Execute Python Script-module It's attached the correct way, but I keep getting the same error. From what I understand this has to do with the version of scikit-learn and scipy, but I created venv for almost every possible version of Python.<\/p>\n<p>Error 0085: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nCaught exception while executing function: Traceback (most recent call last):  <br \/>\nFile &quot;C:\\server\\invokepy.py&quot;, line 199, in batch  <br \/>\nodfs = mod.azureml_main(*idfs)  <br \/>\nFile &quot;C:\\temp\\8c190f6b5c65446f8824ed5a578a75d5.py&quot;, line 22, in azureml_main  <br \/>\nmodel = pickle.load( open( &quot;.\/Script Bundle\/logreg_model_36.pkl&quot;, &quot;rb&quot; ) )  <br \/>\nImportError: No module named 'sklearn.linear_model._logistic'  <br \/>\nProcess returned with non-zero exit code 1<\/p>\n<p>Can someone please explain which version of scikit-learn I need to execute in Azure ML studio (classic) with the environment set to 'Anconda 4.0\/Python3.5'?<\/p>\n<p>Kind regards<\/p>",
        "Question_closed_time":1617261351653,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7cd6c1b8-29d2-45e1-9211-3963bc7ae8f3\">@David Eeckhout  <\/a> The packages installed in the designer version of the studio are listed <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/execute-python-script#preinstalled-python-packages\">here<\/a> which uses the following versions:    <\/p>\n<pre><code>scikit-learn==0.22.2  \nscipy==1.4.1  \n<\/code><\/pre>\n<p>The classic version of the studio is still available but it is preferable to use the designer studio which has better support for some of the pre-installed packages.     <br \/>\nIf you prefer to use classic version then if the package is not available you can try installing it in the execute python script. For example,    <\/p>\n<pre><code>import importlib.util  \npackage_name = 'scikit-misc'  \nspec = importlib.util.find_spec(package_name)  \nif spec is None:  \n    import os  \n    os.system(f&quot;pip install scikit-misc&quot;)  \n<\/code><\/pre>\n<p>Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Model state unhealthy : AzureML",
        "Question_created_time":1643298335143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/712704\/model-state-unhealthy-azureml",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have trained a model using Azure AutoML and when I am trying to deploy it I am getting unhealthy model state. Not sure what the problem might be. could you help out? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why am I recieving \"ModuleNotFoundError: No module named 'Quandl'\" in the Microsoft Azure Machine Learning Studio?",
        "Question_created_time":1647121274650,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769829\/why-am-i-recieving-modulenotfounderror-no-module-n",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>In the Microsoft Azure Machine Learning Studio I am trying to import quandl, but I keep running into this error: &quot;ModuleNotFoundError: No module named 'Quandl'&quot;. For context, I am using an .ipynb file.  <\/p>\n<p>I have tried:  <br \/>\n!pip install quandl  <br \/>\nimport quandl  <\/p>\n<p>as well as:  <br \/>\n!pip3 install quandl  <br \/>\nimport quandl  <\/p>\n<p>I have also tried spelling quandl with an uppercase q to no avail.  <\/p>\n<p>The pip installation command works just fine, outputting that the requirement is already satisfied.  <\/p>\n<p>I have no trouble doing this in jupyter notebooks or google colab, so what is the issue?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Behavior of 'allow_reuse' in a published pipeline referencing a versioned dataset \/ Newer datasets are ignored by the pipeline?",
        "Question_created_time":1647926664217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/781612\/behavior-of-allow-reuse-in-a-published-pipeline-re",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":12,
        "Question_body":"<p>Hello,    <\/p>\n<p>I have built an Azure ML pipeline which will be called from a Data Factory pipeline at a specified interval.    <br \/>\nThe ML pipeline contains PythonScriptSteps which take various datasets as an input. All datasets are registered and versioned in the same Azure ML workspace.    <br \/>\nThe Data Factory pipeline regularly updates the datasets to a new version and then run the registered ML pipeline. The expected behavior is that the ML pipeline will read the latest version of each dataset every time it is run by Data Factory.    <\/p>\n<p>Even though I have set the parameter 'allow_reuse' of my PythonScriptStep objects to 'True', I expect the steps to be executed when the input datasets have been updated to a new version. But the problem is they are not executed. In the Experiments details, I can see that each step has its flag 'Reuse' set to 'Yes' and the execution duration is 0 second.    <\/p>\n<p>When I look at the registered pipeline in 'Azure ML Studio -&gt; Pipelines -&gt; Pipeline endpoints' and I click on the input datasets, I can see that they have a parameter 'version' with an old version of the dataset 'hardcoded' in it (see picture below). It seems like once an ML pipeline has been published, it will always use the same dataset version at every run, even though the dataset have been updated in between. Is this the normal behavior?    <\/p>\n<p>Here is a simplified version of my pipeline code.    <\/p>\n<pre><code># Get a reference to the workspace  \nws = Workspace.from_config()  \n  \n# Get the registered dataset  \ndataset1 = Dataset.get_by_name(ws, 'dataset1')  \n  \n# Pipeline's first step  \nscript1 = PythonScriptStep(  \n    name=&quot;Script 1&quot;,  \n    script_name=&quot;script.py&quot;,  \n    source_directory=&quot;.\/&quot;,  \n    inputs=[dataset1.as_named_input('dataset1')], # Passes the dataset path to the script  \n    compute_target=compute_target,  \n    runconfig=aml_run_config,  \n    allow_reuse=True  \n)  \n  \n# Build the pipeline  \npipeline = Pipeline(workspace=ws, steps=[[script1]])  \n  \nfrom azureml.core import Experiment  \n  \n# Submit the pipeline to be run  \npipeline_run = Experiment(ws, 'experiment').submit(pipeline)  \npipeline_run.wait_for_completion()  \n  \npublished_pipeline = pipeline.publish(name = &quot;pipeline1&quot;)  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/185369-pipeline.jpg?platform=QnA\" alt=\"185369-pipeline.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Notebook: The code being run in the notebook may have caused a crash or the compute may have run out of memory",
        "Question_created_time":1663925084710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1020607\/azure-ml-notebook-the-code-being-run-in-the-notebo",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I am using Azure ML Notebook with python kernel to run the following code:    <\/p>\n<pre><code>%reload_ext rpy2.ipython  \n  \nfrom azureml.core import Dataset, Datastore,Workspace  \n  \nsubscription_id = 'abc'  \nresource_group = 'pqr'  \nworkspace_name = 'xyz'  \n  \nworkspace = Workspace(subscription_id, resource_group, workspace_name)  \ndatastore = Datastore.get(workspace, 'mynewdatastore')  \n  \n# create tabular dataset from all parquet files in the directory  \ntabular_dataset_1 = Dataset.Tabular.from_parquet_files(path=(datastore,'\/RNM\/CRUD_INDIFF\/CrudeIndiffOutput_PRD\/RW_Purchases\/2022-09-05\/RW_Purchases_2022-09-05T17:23:01.01.parquet'))  \ndf=tabular_dataset_1.to_pandas_dataframe()  \nprint(df)  \n<\/code><\/pre>\n<p>After executing this code, I am getting the Cancelled message from the notebook cell and also getting the message on top of the cell as:    <\/p>\n<pre><code> The code being run in the notebook may have caused a crash or the compute may have run out of memory.  \n Jupyter kernel is now idle.  \n Kernel restarted on the server. Your state is lost.  \n<\/code><\/pre>\n<p>The Parquet file which I am using in the code is of size 20.25 GiB and I think due to the large size of this file, this problem is being created. Can anyone please help me how to resolve this error without breaking the file into multiple files of small sizes. Any help would be appreciated.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Preferred Azure Service to run python script with an endpoint in a scalable way.",
        "Question_created_time":1680689337423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1197958\/preferred-azure-service-to-run-python-script-with",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I wrote a genetic algorithm script in Python and tested it using a Flask API. It receives JSON and returns JSON. \nNow we are looking to run the genetic algorithm in Azure, but we are not sure which service to use. I have been trying to integrate it into the Azure Machine Learning Studio, but I feel like it is meant to be used by a complete machine learning model rather than just a python script. \nWhat we need is a scalable way to run our genetic algorithm that is accessible through an endpoint. It should be compatible with Azure ml studio in some way, if possible. A database, which kind has not been decided yet, might be added later on. \nWhat would be the preferred service?\nI tried integrating the python scripts in the Azure machine learning studio. We expected this to be the appropriate service for this purpose, but are now wondering if it is the right choice after all.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting Folder data from Azure data lake gen2 in AzureML",
        "Question_created_time":1680730813576,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1198601\/getting-folder-data-from-azure-data-lake-gen2-in-a",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm currently working on a machine learning project, I do have a folder stored in azure data lake gen2 that has all the data I need to train the model. I created a datastore and I created a data asset in which the type is a folder(uri folder). So far everything is fine but I do fail to understand what I shall do next. The folder that I have has json files and npy files and they are all needed to train the model.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML pipeline not working",
        "Question_created_time":1654438612767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/877179\/azureml-pipeline-not-working",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":5,
        "Question_body":"<p>I have designed a pipeline that makes predictions and saves the results to a blob container.  <br \/>\nThe pipeline works fine after submitting the experiment. However, after I publish it and call it via its REST endpoint, it does not work (I don't get my results). The portal shows that the job has been completed, without any error.  <br \/>\nCan someone enlighten me on how to use a publish pipeline?   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"limited gpu ram",
        "Question_created_time":1681156161463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1215210\/limited-gpu-ram",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have subscribed to Standard_NC6 compute instance. has 56 GB RAM but only 10GB is allocated for the GPU. my model and data is huge which need at least 40GB Ram for gpu. how can I allocate more memory for the GPU ? \nI use Azure machine learning environment + notebooks \nalso I use pytorch for building my model <\/p>",
        "Question_closed_time":1681158737130,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello Turki,<\/p>\n<p>The Standard_NC6 only has 12 GiB of RAM (GPU memory) as seen in:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/bb1d7ed8-9421-421e-a25c-dfb2b026dd24?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/virtual-machines\/nc-series\">https:\/\/learn.microsoft.com\/en-us\/azure\/virtual-machines\/nc-series<\/a><\/p>\n<p>If your model requires 40 GiB of RAM you will have to upgrade to Standard_NC24 for at least 48 GiB of GPU memory (RAM).<\/p>\n<hr \/>\n<p>If this is helpful please accept answer.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to fix Apply Transformation error?",
        "Question_created_time":1681067352283,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1210242\/how-to-fix-apply-transformation-error",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to learn how to deploy regression and classification models in azure but in both the cases i got the &quot;apply transformation&quot; error that the column (The value which the model is predicting) is not found. I have tried many times to include that column in the &quot;Select Columns&quot; module ( even though the instructions said to remove them) but then i have error in the above module. what should i do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to utilize Azure",
        "Question_created_time":1681202888590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1218671\/how-to-utilize-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As a college student with a .edu email address, I have access to Azure services for free. However, I am unaware of how to utilize this platform. For instance, if I want to learn and practice SQL, can I do it? Any guidance on this is appreciated. Thanks!<\/p>",
        "Question_closed_time":1681206677626,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=293bf6a7-206e-45a1-bbbd-b32bc920f2ea\">Puranjay Wadhera <\/a>\u2022,\nWelcome to Microsoft Q&amp;A forum.\nAs I understand, you want to begin using Azure services related to SQL.\nWe have detailed documention on our official Microsoft Site for Azure SQL database where you could create your first Database and explore different functionalities of it.\nLink: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql\/database\/sql-database-paas-overview?view=azuresql\">What is Azure SQL Database?<\/a>\nOn the left panel, you could find Quickstarts, Tutorials, Concepts which covers the service very well.\nAdditionally, we have Azure SQL YouTube channel <a href=\"https:\/\/www.youtube.com\/@AzureSQL\/about\">https:\/\/www.youtube.com\/@AzureSQL\/about<\/a>\nPlease try these and let us know if you need any specific concept details, we would assist you.<\/p>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Mark Helpful<\/code> for the same. And, if you have any further query do let us know.\nThank you.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Adaptive cards full-width feature doesn't work.",
        "Question_created_time":1649651622673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/807459\/adaptive-cards-full-width-feature-doesnt-work",
        "Question_score_count":0,
        "Question_answer_count":6,
        "Question_comment_count":1,
        "Question_body":"<p>I'm using Teams :    <\/p>\n<ul>\n<li> 1.5.00.8070 (64 bit) on Windows.    <\/li>\n<li> Version not showed on Web.    <\/li>\n<\/ul>\n<p>Full-width feature doesn't work with a sample below.    <\/p>\n<p><a href=\"\">https:\/\/learn.microsoft.com\/en-us\/microsoftteams\/platform\/task-modules-and-cards\/cards\/cards-format?tabs=adaptive-md%2Cconnector-html#sample-adaptive-card-with-full-width<\/a>    <\/p>\n<pre><code>{  \n    &quot;type&quot;: &quot;AdaptiveCard&quot;,  \n    &quot;body&quot;: [{  \n        &quot;type&quot;: &quot;Container&quot;,  \n        &quot;items&quot;: [{  \n            &quot;type&quot;: &quot;TextBlock&quot;,  \n            &quot;text&quot;: &quot;Digest card&quot;,  \n            &quot;size&quot;: &quot;Large&quot;,  \n            &quot;weight&quot;: &quot;Bolder&quot;  \n        }]  \n    }],  \n  \n    &quot;msteams&quot;: {  \n        &quot;width&quot;: &quot;Full&quot;  \n    },  \n    &quot;$schema&quot;: &quot;http:\/\/adaptivecards.io\/schemas\/adaptive-card.json&quot;,  \n    &quot;version&quot;: &quot;1.2&quot;  \n}  \n<\/code><\/pre>\n<p>Windows :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/191675-image.png?platform=QnA\" alt=\"191675-image.png\" \/>    <\/p>\n<p>Web :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/191676-teams-full-web.png?platform=QnA\" alt=\"191676-teams-full-web.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can i run multiple jobs\/experiments on a single node using Compute Cluster ?",
        "Question_created_time":1680837975100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1201298\/can-i-run-multiple-jobs-experiments-on-a-single-no",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As the title, i would like to ask for running multiple job\/experiments using a single node Compute Cluster in AzureML ? \nAs i read some related documents, there is a Class call ParallelTaskConfiguration Class, but this class just support to run multiple process in one node, as I understand this will divide our task into mini batches to run parallel, not as what I want. Please help me clarify this !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML and Kafka Server Connection Issue",
        "Question_created_time":1680842576713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1202024\/azure-ml-and-kafka-server-connection-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using Azure ML for real-time machine learning. I have installed the Kafka server, but I am having a connection issue when trying to create a topic using the below line of code. I received the following warning: WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost\/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient). I appreciate your help.<\/p>\n<pre><code>!.\/kafka_2.13-3.3.2\/bin\/kafka-topics.sh --create --topic amids-train --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1\n<\/code><\/pre>",
        "Question_closed_time":1680844061480,
        "Answer_score_count":1.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p>Hi Ghada,\nThe warning message you received suggests that the Kafka broker may not be available or is not running on the specified address and port.\nHere are some steps you can follow to troubleshoot the issue:<\/p>\n<ol>\n<li> Verify that the Kafka broker is running: You can check if the Kafka broker is running by using the following command in a new terminal window:\n    .\/kafka_2.13-3.3.2\/bin\/kafka-server-start.sh .\/kafka_2.13-3.3.2\/config\/server.properties<\/li>\n<li> Verify that the address and port are correct: Make sure that the address and port specified in the <strong><code>bootstrap-server<\/code><\/strong> parameter are correct and that there are no firewall or network configuration issues preventing you from connecting to the broker.<\/li>\n<li> Check the Kafka logs for errors: Check the Kafka logs to see if there are any error messages that could help identify the issue. You can find the Kafka logs in the <strong><code>logs<\/code><\/strong> directory of your Kafka installation.<\/li>\n<li> Try using a different topic name: It's possible that the topic name you're using is already in use or is invalid. Try using a different topic name to see if that resolves the issue.<\/li>\n<\/ol>\n<p>I hope these steps help you resolve the issue. Let me know if you have any further questions!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Deploy cannot connect to Kafka Server",
        "Question_created_time":1599861372500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/92960\/azure-ml-deploy-cannot-connect-to-kafka-server",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>In the run function of the entry script to deploy a model in azure ml, I included a producer function from kafka-python. However, using the deployed service, I can't seem to connect to the bootstrap_servers\/topics in Kafka.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AttributeError: 'str' object has no attribute 'signed_session' for Python Notebook request to CV API.",
        "Question_created_time":1680780634250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1199848\/attributeerror-str-object-has-no-attribute-signed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have trained and deployed a custom vision model via an Azure ML Notebook, following the guide: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/quickstarts\/image-classification?tabs=visual-studio&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/quickstarts\/image-classification?tabs=visual-studio&amp;pivots=programming-language-python<\/a>  <\/p>\n<p>I'm now trying to send images to the service via the SDK Notebook code: <\/p>\n<pre><code class=\"lang-python\">test_images_folder = '5point2\/frames'\noutput_images_folder = '5point2\/output'\n\n# Load the Arial font from the Matplotlib font library\nfont_path = fm.findfont(fm.FontProperties(family='Arial'))\n\n# Create a PIL ImageFont object using the Arial font\nfont_size = 16\nfont = ImageFont.truetype(font_path, font_size)\n\nfor filename in os.listdir(test_images_folder):\n    if filename.endswith(&quot;.jpg&quot;):\n        image_path = os.path.join(test_images_folder, filename)\n\n        with open(image_path, &quot;rb&quot;) as image_contents:\n            predictor1 = CustomVisionPredictionClient(end_point, pred_key)\n            headers = {'Prediction-Key': pred_key, 'Content-Type': 'application\/octet-stream'}\n            results = predictor1.classify_image(project.id, pub_iter_name, image_contents.read(), headers=headers)\n\n            # Load the image and create a drawing context.\n            im = Image.open(image_path)\n            draw = ImageDraw.Draw(im)\n\n            # Draw the class labels and their probabilities on the image.\n            for prediction in results.predictions:\n                label = prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100)\n                draw.text((10, 10 + 20 * results.predictions.index(prediction)), label, fill=&quot;white&quot;, font=font)\n\n            # Save the output image.\n            output_image_path = os.path.join(output_images_folder, filename)\n            im.save(output_image_path)\n\n            # Print the predictions.\n            print(&quot;Predictions for&quot;, filename)\n            for prediction in results.predictions:\n                print(&quot;\\t&quot; + prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100))\n\n        # Delay before sending the next image.\n        time.sleep(1)\n\n<\/code><\/pre>\n<p>But I get the following error: <\/p>\n<pre><code>AttributeError                            Traceback (most recent call last)\nInput In [114], in &lt;cell line: 18&gt;()\n     23 predictor1 = CustomVisionPredictionClient(end_point, pred_key)\n     24 headers = {'Prediction-Key': pred_key, 'Content-Type': 'application\/octet-stream'}\n---&gt; 25 results = predictor1.classify_image(project.id, pub_iter_name, image_contents.read(), headers=headers)\n     27 # Load the image and create a drawing context.\n     28 im = Image.open(image_path)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/vision\/customvision\/prediction\/operations\/_custom_vision_prediction_client_operations.py:73, in CustomVisionPredictionClientOperationsMixin.classify_image(self, project_id, published_name, image_data, application, custom_headers, raw, **operation_config)\n     71 # Construct and send request\n     72 request = self._client.post(url, query_parameters, header_parameters, form_content=form_data_content)\n---&gt; 73 response = self._client.send(request, stream=False, **operation_config)\n     75 if response.status_code not in [200]:\n     76     raise models.CustomVisionErrorException(self._deserialize, response)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/service_client.py:336, in ServiceClient.send(self, request, headers, content, **kwargs)\n    334 kwargs.setdefault('stream', True)\n    335 try:\n--&gt; 336     pipeline_response = self.config.pipeline.run(request, **kwargs)\n    337     # There is too much thing that expects this method to return a &quot;requests.Response&quot;\n    338     # to break it in a compatible release.\n    339     # Also, to be pragmatic in the &quot;sync&quot; world &quot;requests&quot; rules anyway.\n    340     # However, attach the Universal HTTP response\n    341     # to get the streaming generator.\n    342     response = pipeline_response.http_response.internal_response\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/__init__.py:197, in Pipeline.run(self, request, **kwargs)\n    195 pipeline_request = Request(request, context)  # type: Request[HTTPRequestType]\n    196 first_node = self._impl_policies[0] if self._impl_policies else self._sender\n--&gt; 197 return first_node.send(pipeline_request, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/__init__.py:150, in _SansIOHTTPPolicyRunner.send(self, request, **kwargs)\n    148 self._policy.on_request(request, **kwargs)\n    149 try:\n--&gt; 150     response = self.next.send(request, **kwargs)\n    151 except Exception:\n    152     if not self._policy.on_exception(request, **kwargs):\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/requests.py:65, in RequestsCredentialsPolicy.send(self, request, **kwargs)\n     63 session = request.context.session\n     64 try:\n---&gt; 65     self._creds.signed_session(session)\n     66 except TypeError: # Credentials does not support session injection\n     67     _LOGGER.warning(&quot;Your credentials class does not support session injection. Performance will not be at the maximum.&quot;)\n\nAttributeError: 'str' object has no attribute 'signed_session'\n<\/code><\/pre>\n<p>I have checked all my credentials and they are all correct.   <br \/>\nI am unable to use  azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionEndpoint as I am using Python.   <\/p>\n<p>I assume this is an SDK issue, please assist.   <\/p>\n<p>Thank you. <\/p>",
        "Question_closed_time":1680786974796,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=43306268-160b-4903-9156-e7ca00e7f352\">@Shane Dzartov  <\/a> I think this error is from the <code>msrest<\/code> package rather than the custom vision library. I see that you have not used or imported <code>ApiKeyCredentials<\/code> from <code>msrest<\/code> and instead the keys are directly passed to prediction client which seems to fail the request.<\/p>\n<p>Could you add the following in imports section:<\/p>\n<p><code>from msrest.authentication import ApiKeyCredentials<\/code><\/p>\n<p>And pass your key to <code>ApiKeyCredentials<\/code> and then to the prediction client?<\/p>\n<pre><code class=\"lang-python\">python prediction_credentials = ApiKeyCredentials(in_headers={&quot;Prediction-key&quot;: prediction_key})  \npredictor1 = CustomVisionPredictionClient(end_point, prediction_credentials) \n#Comment the headers declaration since SDK should take care of Content-Type header \nresults = predictor1.classify_image(project.id, pub_iter_name, image_contents.read()) \n\n<\/code><\/pre>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"quota issues on ml azure",
        "Question_created_time":1680793065266,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1200178\/quota-issues-on-ml-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How do i fix the following error message: \n<strong>You do not have enough quota for the following VM sizes. It is possible that you have quota in a different location.<\/strong>\u00a0<a href=\"https:\/\/ml.azure.com\/quota\/97847e07-52b6-4f0f-b95e-f5082fa5abb0\/centralus?wsid=\/subscriptions\/97847e07-52b6-4f0f-b95e-f5082fa5abb0\/resourcegroups\/STEMcamp\/providers\/Microsoft.MachineLearningServices\/workspaces\/MLact&amp;tid=9eed4e30-00f7-4484-9ff1-93ad8005acec\">Click here to view and request quota.<\/a>\nIn my virtual machine?  I have not used any of the $200 credit that i have<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure MLv2 CLI extension not recognized in DevOps",
        "Question_created_time":1657302176180,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/919949\/azure-mlv2-cli-extension-not-recognized-in-devops",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Having some trouble with one of our DevOps pipelines. In the pipeline, we install the Azure MLv2 CLI extension and then use the extension to make a call to our AzureML workspace. The pipeline was working fine yesterday, but now results in an error saying that 'ml' is misspelled or not recognized. There is an additional message about a name import that might be causing the issue. Here is the full error message:    <\/p>\n<p>ERROR: 'ml' is misspelled or not recognized by the system.    <\/p>\n<p>Examples from AI knowledge base:    <br \/>\naz extension add --name anextension    <br \/>\nAdd extension by name    <\/p>\n<p>az extension list-available    <br \/>\nList all publicly available extensions    <\/p>\n<p><a href=\"\">https:\/\/learn.microsoft.com\/en-US\/cli\/azure\/extension#az_extension_add<\/a>    <br \/>\nRead more about the command in reference docs    <br \/>\ncannot import name 'case_insensitive_dict' from 'azure.core.utils' (\/opt\/az\/lib\/python3.10\/site-packages\/azure\/core\/utils\/<strong>init<\/strong>.py)    <\/p>\n<p>Azure CLI Versions:    <br \/>\nWARNING: You have 2 updates available. Consider updating your CLI installation with 'az upgrade'    <br \/>\nazure-cli                         2.37.0 *    <\/p>\n<p>Please let us know how we are doing: <a href=\"\">https:\/\/aka.ms\/azureclihats<\/a>    <br \/>\ncore                              2.37.0 *    <br \/>\nand let us know if you're interested in trying out our newest features: <a href=\"\">https:\/\/aka.ms\/CLIUXstudy<\/a>    <br \/>\ntelemetry                          1.0.6    <\/p>\n<p>Extensions:    <br \/>\nml                                 2.5.0    <br \/>\nazure-devops                      0.25.0    <\/p>\n<p>Dependencies:    <br \/>\nmsal                            1.18.0b1    <br \/>\nazure-mgmt-resource             21.1.0b1    <\/p>\n<p>Python location '\/opt\/az\/bin\/python3'    <br \/>\nExtensions directory '\/opt\/az\/azcliextensions'    <\/p>\n<p>Python (Linux) 3.10.4 (main, May 23 2022, 14:03:08) [GCC 9.4.0]    <\/p>\n<p>Trying to update the CLI version also results in an error<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Datadrift in Azure ML SDK v2",
        "Question_created_time":1657283475557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/919651\/datadrift-in-azure-ml-sdk-v2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I can't see a data drift module anywhere in v2 of the Azure ML Python SDK. Is this missing or what's the deal? If so, are there any plans of bringing it into v2?<\/p>",
        "Question_closed_time":1658311324113,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=1dc2a0bd-ac4b-413b-bae7-930e0079e70d\">@SH  <\/a>     <\/p>\n<p>I have a good news for you, I just got confirmation from product team, the datadrift function will be in SDK V2 for sure. But for now we don't have an exact date for when. I have forwarded this feedback to product group and we hope we can bring this feature in near future.     <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Request GPU Quota increase",
        "Question_created_time":1615999382250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/319120\/request-gpu-quota-increase",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_body":"<p>For my Machine Learning Experiments I need a dedicated VM with GPU. They are not available in my region (only low priority VMs). The system tells me to request a quota increase but if I go to the quota increase support page I can only select additional CPU's not a GPU for a dedicated VM. How do I request a GPU quota increase?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to modify the template script on azure auto ml?",
        "Question_created_time":1680251989910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195000\/how-to-modify-the-template-script-on-azure-auto-ml",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello to all, <\/p>\n<p>I am working on a machine learning project, I have trained my model on azure auto ml studio, I would like to import it in onnx format, but it is not in the download options, so I want to modify the resulting code directly in azure auto ml, in the script.py I have modified the recording format of the model but I can't find how to execute this script because it tells me that the script.py is not found, <\/p>\n<p>Could you help me please ? <\/p>\n<p>thank you <\/p>\n<p>Lysa<\/p>",
        "Question_closed_time":1680506244446,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=2d96c782-8477-4987-b5a4-5ea497b49eb9\">AMROUN Lysa<\/a> I believe you are looking to create a model wihich is ONNX compatible with AutoML as per your previous thread. In this case in the automl config if you setup <code>enable_onnx_compatible_models<\/code> to true in the automl config the model should be available for download. Something similar to what is provided as guidance in this <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/v1\/python-sdk\/tutorials\/automl-with-azureml\/classification-bank-marketing-all-features\/auto-ml-classification-bank-marketing-all-features.ipynb\">notebook<\/a>.<\/p>\n<p>I would recommend running through this notebook and then change your experiment settings in a similar way to retrieve the best onnx format model. <\/p>\n<pre><code>automl_settings = {\n    &quot;experiment_timeout_hours&quot;: 0.3,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;iteration_timeout_minutes&quot;: 5,\n    &quot;max_concurrent_iterations&quot;: 4,\n    &quot;max_cores_per_iteration&quot;: -1,\n    # &quot;n_cross_validations&quot;: 2,\n    &quot;primary_metric&quot;: &quot;AUC_weighted&quot;,\n    &quot;featurization&quot;: &quot;auto&quot;,\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;enable_code_generation&quot;: True,\n}\n\nautoml_config = AutoMLConfig(\n    task=&quot;classification&quot;,\n    debug_log=&quot;automl_errors.log&quot;,\n    compute_target=compute_target,\n    experiment_exit_score=0.9984,\n    blocked_models=[&quot;KNN&quot;, &quot;LinearSVM&quot;],\n    enable_onnx_compatible_models=True,\n    training_data=train_data,\n    label_column_name=label,\n    validation_data=validation_dataset,\n    **automl_settings,\n)\n\n<\/code><\/pre>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Connecting to VSCode wiped my notebook, completely",
        "Question_created_time":1679589627240,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1192605\/connecting-to-vscode-wiped-my-notebook-completely",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I've been working on a project for some months on AML Studio. I recently wanted to utilize the VSCode integration, so I opened my workspace via the extension. I had my notebook open in the vscode version, and ran a couple of cells. I shut down the compute, and left it there. <\/p>\n<p>Now I've come back to this and my notebook has been wiped. Completely, every cell. This is the case on the AML Studio proper, and on the vscode integration version. There doesn't seem to be any kind of backup tool I can use. I've looked in the filestore and there's no snapshot, no nothing. I looked at the last experiment run log, but it has no code. <\/p>\n<p>Ofc when I work elsewhere, I use git. But there's no git integration in AML studio, and the terminal is so unusably slow that I haven't touched it in a long time. <\/p>\n<p>I don't know what to do. This is literally months of work, wiped out. No idea what happened or how to rectify. <\/p>\n<p>Any help much appreciated. <\/p>",
        "Question_closed_time":1679893628340,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=83376df1-3fe7-4f8e-aeae-798027e4c31b\">@Daniel Goldwater  <\/a>If you have your notebook setup under your user directory the files that are created and saved should be available in your default storage account i.e the storage account connected to your workspace under the fileshares of your storage account. For example, here is a screen shot of my notebooks under my username from the studio.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/2e273099-db36-47d4-a82d-d1c43365bab9?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>By default, all these files are mounted to your compute instance when you start the instance, and this enables you to connect to git through terminal and use an external source control mechanism. Since you have not added this the files that are added previously should be available here even if you have deleted your compute. The files should be visible under your user account even when no compute is available. <\/p>\n<p>The file share that is mounted is from your storage account as seen in the screen shot below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a149337f-0fb2-4873-99d6-337cf73a946d?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>This file share should be visible under your storage account file share tab and you should be able to download the data from storage explorer till the point the data was last saved. Ideally, notebook data is saved every 30seconds or whenever they are saved or when a checkpoint is created. Here is a screen shot of my storage account from storage browser to help you check the same on your account.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/b527ad6a-403d-4aaa-b75b-d27131005d16?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I hope this is helpful!! Thanks!!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to access deployed container and edit score script",
        "Question_created_time":1678872532843,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1189800\/how-to-access-deployed-container-and-edit-score-sc",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I used Azure ML studio to set up a custom environment (base image using mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.6-cudnn8-ubuntu20.04) and an online endpoint using that env. <\/p>\n<p>The endpoint managed to deploy successfully using a Standard_NC4as_T4_v3 SKU. I would like to:<\/p>\n<ol>\n<li> Access the container to check if torch is accessing the GPU using terminal<\/li>\n<li> Edit the score script<\/li>\n<\/ol>\n<p>I am able to do so locally but how do I do so after deploying online?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Compute Cluster",
        "Question_created_time":1680516832996,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195654\/custom-compute-cluster",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I want to create a compute cluster in Azure ML that has one vGPU and can scale its vCPU's within the specified min and max. Is this possible? And can someone explain how this can be done or point me to a tutorial?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":1680518356223,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Unfortunately, you cannot create a compute cluster with a single vGPU that can scale its vCPUs independently in Azure ML. The available VM sizes in Azure are predefined with a fixed ratio of vCPUs, memory, and GPU resources. However, you can create a compute cluster with different VM sizes that can scale within a specified range of nodes, depending on your requirements<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine learning studio sign in issue",
        "Question_created_time":1680551277963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195834\/azure-machine-learning-studio-sign-in-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am facing issues with signing into the Machine Learning Studio. I have tried several times but I am unable to sign in to the Studio. Whenever I try to log in, it asks me for code through my company authenticator app. but i am currently not working in that company and i don not have access to the app. i am however able to sign in into azure portal, but unable to sign in into machine learning studio<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to save or convert the result of an NLP text classification job as an ONNX model?",
        "Question_created_time":1680270551206,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195115\/is-it-possible-to-save-or-convert-the-result-of-an",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to save or convert the result of an NLP text classification job as an ONNX model? For normal classification tasks, I know it's possible using the <code>enable_onnx_compatible_models<\/code> parameter.<\/p>\n<p>But for NLP Text Classification jobs using the Python SDK v2, I can't seem to find any parameter like this. I've checked the reference in <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.automl.textclassificationjob?view=azure-python\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.automl.textclassificationjob?view=azure-python<\/a>, as well as the example notebooks in <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/automl-standalone-jobs\">https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/automl-standalone-jobs<\/a>, but I couldn't find any examples of converting it to ONNX format.<\/p>\n<p>Is this something that can be done using the Python SDK v2 or some other library?<\/p>\n<p>For reference the code I'm using to create the job looks something like this:<\/p>\n<pre><code class=\"lang-python\">from azure.ai.ml import automl\n\ntext_classification_job = automl.text_classification(\n    compute=compute_cluster_name,\n    experiment_name=experiment_name,\n    training_data=training_data,\n    validation_data=validation_data,\n    target_column_name=&quot;labels&quot;,\n    primary_metric=&quot;accuracy&quot;\n)\n\n\nreturned_job = ml_client.jobs.create_or_update(\n    text_classification_job\n)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In Azure ML studio deploy option is not there",
        "Question_created_time":1680338490806,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195304\/in-azure-ml-studio-deploy-option-is-not-there",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi team im new to Azure ML studio in that i done trained data but i would like to deploy im in trial account i dont see option for deploy i can able to see only submit , share like that only please help<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/88acd6d3-f886-4193-abd3-dd22f6453378?platform=QnA\" alt=\"azure\" \/><\/p>",
        "Question_closed_time":1680338727863,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=b7477e61-4395-49cc-9454-e13b8a24bb87\">@manoj p  <\/a><\/p>\n<p>As you can read :<\/p>\n<p>In Azure Machine Learning Studio, the ability to deploy a model is only available in the paid tiers of the service. If you are using a trial account, you may not have access to the deploy functionality.<\/p>\n<p>To deploy a model in Azure Machine Learning Studio, you will need to upgrade to a paid subscription. The deploy functionality is available in the Standard and Enterprise tiers of the service.<\/p>\n<p>Once you have upgraded your subscription, you can follow these steps to deploy your trained model:<\/p>\n<p>Open the Azure Machine Learning Studio and navigate to your workspace.<\/p>\n<p>Navigate to the &quot;Models&quot; tab and select the trained model you want to deploy.<\/p>\n<p>Click on the &quot;Deploy&quot; button and select the deployment target, such as Azure Kubernetes Service (AKS) or Azure Container Instances (ACI).<\/p>\n<p>Configure the deployment settings, such as the number of nodes and the CPU and memory settings.<\/p>\n<p>Click on the &quot;Deploy&quot; button to start the deployment process.<\/p>\n<p>Once the deployment is complete, you can test the deployed model by sending requests to the endpoint.<\/p>\n<p>Please mark the answer as accepted if yu find it helpful !<\/p>\n<p>BR<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Questions about aml python  sdk v2  for pipeline",
        "Question_created_time":1679364811036,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1191592\/questions-about-aml-python-sdk-v2-for-pipeline",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>We are currently migrating v1 to v2  <br \/>\npipeline takes the decorator form in v2. Is there any other way similar to v1<\/p>\n<pre><code>\ndatastore = workspace.datastores['my_adlsgen2']\nstep1_output_data = OutputFileDatasetConfig(name=&quot;processed_data&quot;, destination=(datastore, &quot;mypath\/{run-id}\/{output-name}&quot;)).as_upload()\n\nstep1 = PythonScriptStep(\n    name=&quot;generate_data&quot;,\n    script_name=&quot;step1.py&quot;,\n    runconfig = aml_run_config,\n    arguments = [&quot;--output_path&quot;, step1_output_data]\n)\n\nstep2 = PythonScriptStep(\n    name=&quot;read_pipeline_data&quot;,\n    script_name=&quot;step2.py&quot;,\n    compute_target=compute,\n    runconfig = aml_run_config,\n    arguments = [&quot;--pd&quot;, step1_output_data.as_input()]\n\n)\n\npipeline = Pipeline(workspace=ws, steps=[step1, step2])\n<\/code><\/pre>\n<p>v1 is very convenient for ci\/cd deployment and generalizing the code<\/p>\n<pre><code>\ncluster_name = &quot;cpu-cluster&quot;\ncustom_path = &quot;azureml:\/\/datastores\/workspaceblobstore\/paths\/custom_path\/${{name}}\/&quot;\n\n# define a pipeline with component\n@pipeline(default_compute=cluster_name)\ndef pipeline_with_python_function_components(input_data, test_data, learning_rate):\n    &quot;&quot;&quot;E2E dummy train-score-eval pipeline with components defined via python function components&quot;&quot;&quot;\n\n    # Call component obj as function: apply given inputs &amp; parameters to create a node in pipeline\n    train_with_sample_data = train_model(\n        training_data=input_data, max_epochs=5, learning_rate=learning_rate\n    )\n    score_with_sample_data = score_data(\n        model_input=train_with_sample_data.outputs.model_output, test_data=test_data\n    )\n    # example how to change path of output on step level,\n    # please note if the output is promoted to pipeline level you need to change path in pipeline job level\n    score_with_sample_data.outputs.score_output = Output(\n        type=&quot;uri_folder&quot;, mode=&quot;rw_mount&quot;, path=custom_path\n    )\n    eval_with_sample_data = eval_model(\n        scoring_result=score_with_sample_data.outputs.score_output\n    )\n\n    # Return: pipeline outputs\n    return {\n        &quot;eval_output&quot;: eval_with_sample_data.outputs.eval_output,\n        &quot;model_output&quot;: train_with_sample_data.outputs.model_output,\n    }\n\n\npipeline_job = pipeline_with_python_function_components(\n    input_data=Input(\n        path=&quot;wasbs:\/\/demo@dprepdata.blob.core.windows.net\/Titanic.csv&quot;, type=&quot;uri_file&quot;\n    ),\n    test_data=Input(\n        path=&quot;wasbs:\/\/demo@dprepdata.blob.core.windows.net\/Titanic.csv&quot;, type=&quot;uri_file&quot;\n    ),\n    learning_rate=0.1,\n)\n# example how to change path of output on pipeline level\npipeline_job.outputs.model_output = Output(\n    type=&quot;uri_folder&quot;, mode=&quot;rw_mount&quot;, path=custom_path\n)\n<\/code><\/pre>\n<p>v2 I have two problems at the moment:<\/p>\n<p>1.Decorator issue. Decorator is not supported for methods in the class\uff0cI had to do it.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/d33d9a8f-2a66-4bd6-aaef-345c71562e68?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>2.pipeline_with_python_function_components, for example, seem unable to generalize<\/p>\n<p>If I have multiple pipelines that need to be processed, I need to declare multiple such jobs for processing. The entry and sale may be different<\/p>\n<p>So does anyone have a way around decorator  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"can I use prebuilt component in custom pipeline mode?",
        "Question_created_time":1680044853140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1194061\/can-i-use-prebuilt-component-in-custom-pipeline-mo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>There is very less components compared to classical mode, how can I use prebuilt components in custom mode? Is that possible? How should I get it? <\/p>\n<p>Can I get some help here? Much appreciated.<\/p>",
        "Question_closed_time":1680082887130,
        "Answer_score_count":2.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello @merten<\/p>\n<p>Thanks for reaching out to us, as you know Designer supports two type of components, classic prebuilt components and custom components. These two types of components <strong>are not compatible. So a quick answer for your question is you can not use it together.<\/strong><\/p>\n<p>Classic prebuilt components provides prebuilt components majorly for data processing and traditional machine learning tasks like regression and classification. This type of component continues to be supported but will not have any new components added.<\/p>\n<p>Custom components allow you to provide your own code as a component. It supports sharing across workspaces and seamless authoring across Studio, CLI, and SDK interfaces.<\/p>\n<p>I am sorry for all inconveniences. If you can share more details about your scenario, we are happy to discuss with product team.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Machine Learning Studio deprecation plan",
        "Question_created_time":1680125744563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1194471\/machine-learning-studio-deprecation-plan",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I understand Machine Learning studio will be on deprecation soon, I have already got a workspace of it and currently it works well. My questions is when the studio will be not useable anymore.<\/p>",
        "Question_closed_time":1680137203723,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d5d1581d-d5c6-4a48-a88d-16b3f134edc8\">@sukharev  <\/a><\/p>\n<p>Support for Machine Learning Studio (classic) will end on <strong>31 August 2024.<\/strong> We recommend you transition to <strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-azure-machine-learning\">Azure Machine Learning<\/a><\/strong> by that date.<\/p>\n<p>Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources. Through <strong>31 August 2024<\/strong>, you can continue to use the existing Machine Learning Studio (classic) resources.<\/p>\n<p>ML Studio (classic) documentation is being retired and may not be updated in the future.<\/p>\n<p>We would recommend you to migrate to Azure Machine Learning Service - <\/p>\n<p>The <strong>designer<\/strong> feature in Azure Machine Learning provides a similar drag-and-drop experience to Studio (classic). However, Azure Machine Learning also provides robust <strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-model-management-and-deployment\">code-first workflows<\/a><\/strong> as an alternative. This migration series focuses on the designer, since it's most similar to the Studio (classic) experience.<\/p>\n<p>I would invite you to take a look on the differences between classic and designer - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/migrate-overview#step-1-assess-azure-machine-learning\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/migrate-overview#step-1-assess-azure-machine-learning<\/a><\/p>\n<p>I hope this helps.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML - Notebook - Jupyter Kernel Error - No Kernel connection",
        "Question_created_time":1612145607873,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/252893\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c",
        "Question_score_count":7,
        "Question_answer_count":9,
        "Question_comment_count":3,
        "Question_body":"<p>In ML Studio, when I create a notebook the top of my screen says &quot;Jupyter kernel error&quot; in red.  I have a compute instance running (it's green), but it also says &quot;No Kernel connected&quot;.    <\/p>\n<p>To correct this matter, can you please provide explicit, step by step instructions on how to review.  Screen shots help too. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use a pickle file resulting from auto ml from azure studio in a c# .NET api?",
        "Question_created_time":1680079819343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1194189\/how-to-use-a-pickle-file-resulting-from-auto-ml-fr",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello to all, <\/p>\n<p>I am currently working on a Machine Learning project, I have launched the auto ML of Microsoft Azure Studio on my data and I have downloaded the best model in a folder with the appropriate Pickle file. However I would like to use this pickle in my prediction API in c# .NET, for this fact I used Microsoft.ML, to load the pickle and use it, here is my code snippet : <\/p>\n<p>&quot;MLContext mLContext = new MLContext();<\/p>\n<p>var model = mLContext.Model.Load(PicklePath, out DataViewSchema schema); &quot;<\/p>\n<p>However I have an error at this level (2nd line), the error tells me : &quot;Repository doesn't contain entry DataLoaderModel\\Model.key&quot;.<\/p>\n<p>From what I understand the pickle is incompatible with Microsoft.ML, how can I use the resulting pickle of auto ml in this api please?<\/p>\n<p>Thanks in advance, <\/p>\n<p>Lysa<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to import CSV file as a dataset for Azure machine learning",
        "Question_created_time":1615376822993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/307727\/how-to-import-csv-file-as-a-dataset-for-azure-mach",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>I need to import CSV files as a dataset for my Azure machine learning experiment but I will get an error in execution, kindly provide me with the correct steps.  <br \/>\nThe aim of the experiment is to generate a demand forecast in MS D365 F&amp;O based on the historical data provided in the CSV files.<\/p>",
        "Question_closed_time":1615447642347,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=fbc5fb82-83ce-4bda-b903-0f500318cca9\">@Abdelrahman Morsy  <\/a>     <br \/>\nThank you for posting in Q &amp; A.    <\/p>\n<p><strong>Azure ML Studio Classic import data<\/strong>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/import-data\">Import your training data into Azure Machine Learning Studio (classic) from various data sources<\/a>    <\/p>\n<p><strong>Azure ML Designer import data<\/strong>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-designer-import-data\">Import data into Azure Machine Learning designer<\/a>    <\/p>\n<p>Please don\u2019t forget to <code>Accept the answer<\/code> and <strong>up-vote<\/strong> wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Publishing AML Pipelines with SDK v2",
        "Question_created_time":1664802453843,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1033206\/publishing-aml-pipelines-with-sdk-v2",
        "Question_score_count":5,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,     <\/p>\n<p>is it possible (or will be in the future) using Python SDK v2 to create pipeline endpoint (or endpoint + deployment)?    <br \/>\nIm looking for a way to submit a job for a created pipeline with a REST request.     <\/p>\n<p>For SDK v1 pipeline i was able to acquire satisfying result using Pipeline.publish method.    <\/p>\n<p>Thanks for any advice!<\/p>",
        "Question_closed_time":1664861262760,
        "Answer_score_count":0.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=c12c38b8-0908-400e-b8ac-72519d30e7db\">@Maciej Stefaniak  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. For how to publish pipeline, I don't find anything currently. But for deploy endpoint, please check on this sample repo for SDK v2, there are several samples for you to refer about how to deploy endpoint - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/tree\/v2samplesreorg\/sdk\/python\">https:\/\/github.com\/Azure\/azureml-examples\/tree\/v2samplesreorg\/sdk\/python<\/a>    <\/p>\n<p>Also, there is an example about using Azure Machine Learning (Azure ML) to create a production ready machine learning (ML) project, using AzureML Python SDK v2 (preview). - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk<\/a>    <\/p>\n<p>I hope this helps, please let me know if you need more information or have any questiion regarding to above examples.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Weird outputs in Azure Machine Learning with advanced entry script - ONLY in Azure ML Studio",
        "Question_created_time":1679051182250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1190684\/weird-outputs-in-azure-machine-learning-with-advan",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,<\/p>\n<p>I have recently redeployed a model and while its output is fine when I use - for example - Postman - the outputs of 'test' tab and 'consume' codes is very weird. It was not an issue couple of days ago - what might have happened?<\/p>\n<pre><code>azureml.core.__version__\n'1.45.0'\n<\/code><\/pre>\n<p>Entry script:<\/p>\n<pre><code>import joblib\nfrom azureml.core.model import Model\nimport json\nimport pandas as pd\nimport numpy as np\nfrom oremoval import outlier_removal\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n\ndef init():\n    global model\n    # Example when the model is a file\n    model_path = Model.get_model_path('hd_otr_f') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\n    \ndata_sample = PandasParameterType(pd.DataFrame({'age': pd.Series([71], dtype='int64'),\n                                                'sex': pd.Series(['0'], dtype='object'),\n                                                'cp': pd.Series(['0'], dtype='object'),\n                                                'trestbps': pd.Series([112], dtype='int64'),\n                                                'chol': pd.Series([203], dtype='int64'),\n                                                'fbs': pd.Series(['0'], dtype='object'),\n                                                'restecg': pd.Series(['1'], dtype='object'),\n                                                'thalach': pd.Series([185], dtype='int64'),\n                                                'exang': pd.Series(['0'], dtype='object'),\n                                                'oldpeak': pd.Series([0.1], dtype='float64'),\n                                                'slope': pd.Series(['2'], dtype='object'),\n                                                'ca': pd.Series(['0'], dtype='object'),\n                                                'thal': pd.Series(['2'], dtype='object')}))\n\ninput_sample = StandardPythonParameterType({'data': data_sample})\nresult_sample = NumpyParameterType(np.array([0]))\noutput_sample = StandardPythonParameterType({'Results': result_sample})\n\n@input_schema('Inputs', input_sample)\n\n@output_schema(output_sample)\n\ndef run(Inputs):\n    try:\n        data = Inputs['data']\n        #result = model.predict_proba(data)\n        result = np.round(model.predict_proba(data)[0][0], 2)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n\n<\/code><\/pre>\n<p>Script<\/p>\n<pre><code>import json\nimport requests\nkey = key\nheaders = {'Content-Type':'application\/json'}\nheaders['Authorization'] = f'Bearer {key}'\n\nnew_data = {\n  &quot;Inputs&quot;: {\n    &quot;data&quot;: [\n      {\n       'age': 71,\n       'sex': 0,\n       'cp': 0,\n       'trestbps': 112,\n       'chol': 203,\n       'fbs': 0,\n       'restecg': 1,\n       'thalach': 185,\n       'exang': 0,\n       'oldpeak': 0.1,\n       'slope': 2,\n       'ca': 0,\n       'thal': 2\n      }\n    ]\n  }\n}\n\n\ndata = new_data\n\nr = requests.post(url, str.encode(json.dumps(data)), headers = headers)\nprint(r.status_code)\nprint(r.json())\n<\/code><\/pre>\n<p>returns<\/p>\n<p>200<\/p>\n<p>0.02<\/p>\n<p>Script from consumption - also in Python:<\/p>\n<pre><code>\/\/ This code requires the Nuget package Microsoft.AspNet.WebApi.Client to be installed.\n\/\/ Instructions for doing this in Visual Studio:\n\/\/ Tools -&gt; Nuget Package Manager -&gt; Package Manager Console\n\/\/ Install-Package Newtonsoft.Json\n\/\/ .NET Framework 4.7.1 or greater must be used\n\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Net.Http;\nusing System.Net.Http.Headers;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Newtonsoft.Json;\n\nnamespace CallRequestResponseService\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            InvokeRequestResponseService().Wait();\n        }\n\n        static async Task InvokeRequestResponseService()\n        {\n            var handler = new HttpClientHandler()\n            {\n                ClientCertificateOptions = ClientCertificateOption.Manual,\n                ServerCertificateCustomValidationCallback =\n                        (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n            };\n            using (var client = new HttpClient(handler))\n            {\n                \/\/ Request data goes here\n                \/\/ The example below assumes JSON formatting which may be updated\n                \/\/ depending on the format your endpoint expects.\n                \/\/ More information can be found here:\n                \/\/ https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\n                var requestBody = @&quot;{\n                  &quot;&quot;Inputs&quot;&quot;: {\n                    &quot;&quot;data&quot;&quot;: [\n                      {\n                        &quot;&quot;age&quot;&quot;: 71,\n                        &quot;&quot;sex&quot;&quot;: &quot;&quot;0&quot;&quot;,\n                        &quot;&quot;cp&quot;&quot;: &quot;&quot;0&quot;&quot;,\n                        &quot;&quot;trestbps&quot;&quot;: 112,\n                        &quot;&quot;chol&quot;&quot;: 203,\n                        &quot;&quot;fbs&quot;&quot;: &quot;&quot;0&quot;&quot;,\n                        &quot;&quot;restecg&quot;&quot;: &quot;&quot;1&quot;&quot;,\n                        &quot;&quot;thalach&quot;&quot;: 185,\n                        &quot;&quot;exang&quot;&quot;: &quot;&quot;0&quot;&quot;,\n                        &quot;&quot;oldpeak&quot;&quot;: 0.1,\n                        &quot;&quot;slope&quot;&quot;: &quot;&quot;2&quot;&quot;,\n                        &quot;&quot;ca&quot;&quot;: &quot;&quot;0&quot;&quot;,\n                        &quot;&quot;thal&quot;&quot;: &quot;&quot;2&quot;&quot;\n                      }\n                    ]\n                  }\n                }&quot;;\n                \n                \/\/ Replace this with the primary\/secondary key or AMLToken for the endpoint\n                const string apiKey = &quot;&quot;;\n                if (string.IsNullOrEmpty(apiKey))  \n                {\n                    throw new Exception(&quot;A key should be provided to invoke the endpoint&quot;);\n                }\n                client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue( &quot;Bearer&quot;, apiKey);\n                client.BaseAddress = new Uri(&quot;http:\/\/b5cbe4c2-f4e1-4d11-ba2f-dcffd29c9a79.westeurope.azurecontainer.io\/score&quot;);\n\n                var content = new StringContent(requestBody);\n                content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application\/json&quot;);\n\n                \/\/ WARNING: The 'await' statement below can result in a deadlock\n                \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                \/\/ One way to address this would be to call ConfigureAwait(false)\n                \/\/ so that the execution does not attempt to resume on the original context.\n                \/\/ For instance, replace code such as:\n                \/\/      result = await DoSomeTask()\n                \/\/ with the following:\n                \/\/      result = await DoSomeTask().ConfigureAwait(false)\n                HttpResponseMessage response = await client.PostAsync(&quot;&quot;, content);\n\n                if (response.IsSuccessStatusCode)\n                {\n                    string result = await response.Content.ReadAsStringAsync();\n                    Console.WriteLine(&quot;Result: {0}&quot;, result);\n                }\n                else\n                {\n                    Console.WriteLine(string.Format(&quot;The request failed with status code: {0}&quot;, response.StatusCode));\n\n                    \/\/ Print the headers - they include the requert ID and the timestamp,\n                    \/\/ which are useful for debugging the failure\n                    Console.WriteLine(response.Headers.ToString());\n\n                    string responseContent = await response.Content.ReadAsStringAsync();\n                    Console.WriteLine(responseContent);\n                }\n            }\n        }\n    }\n}\n<\/code><\/pre>\n<p>returns b'0.02'<\/p>\n<p>And clicking simply 'test' tab in ML Studio throws an error:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a225f31d-5383-444e-9874-bb4c2ace2b6c?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>What happened and how to cope with these issues?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When deploying ML model to online endpoint are you charged for the time the endpoint is up or the time it is running?",
        "Question_created_time":1679387434850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1191678\/when-deploying-ml-model-to-online-endpoint-are-you",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>If I deploy ML model to online endpoint say for 1 day but it is invoked only once and runs for 1min, then am I charged for the whole day or for the 1min? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Workspace Load Balancer",
        "Question_created_time":1620773916823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/391564\/machine-learning-workspace-load-balancer",
        "Question_score_count":1,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hi there,    <\/p>\n<p>Is it possible to delete the Load Balancer that's installed as part of the Machine Learning workspace? Or to adjust the configuration so that it doesn't cost so much?     <\/p>\n<p>I'm just using this ML workspace to study\/practice concepts for the DP-100 exam so I don't think I need a load balancer, but at no point did I see an option to turn it off, it doesn't even appear as a resource item.    <\/p>\n<p>What role\/purpose is the load balancer playing as part of the Workspace deployment?    <\/p>\n<p>Thanks kindly for any insight.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/95742-pluralsight-rg-microsoft-azure.png?platform=QnA\" alt=\"95742-pluralsight-rg-microsoft-azure.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Which algorithm is better for recommendation system design",
        "Question_created_time":1679952454270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1193654\/which-algorithm-is-better-for-recommendation-syste",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am new to machine learning, I want to design a recommendation system by azure machine learning studio, I am not sure which model I should apply to achieve this, can I get some help or information here?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ml sdk\/cli v2 - read multiple parquet in uri_folder in prepare_data.py script",
        "Question_created_time":1679338270660,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1191501\/azure-ml-sdk-cli-v2-read-multiple-parquet-in-uri-f",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I would like to know how to access a URI<em>FOLDER in Azure ML CLI\/SDK V2 in prepare<\/em>_data.py script ie How do I loop through the URI_FOLDER and construct a full dataframe from multiple files? <\/p>\n<p>I have registered the below path as a URI_FOLDER dataset (name as &quot;salesdataset&quot; )in Azure ML, the path has multiple parquet files  under it.<\/p>\n<p>https:\/\/&lt;account_name&gt;.blob.core.windows.net\/salesdatastore\/rawdata\/16032023\/<\/p>\n<ul>\n<li> salesdata1.parquet<\/li>\n<li> salesdata2.parquet<\/li>\n<li> salesdata3.parquet<\/li>\n<\/ul>\n<p>In pipeline.yml, I am passing the input to  as below.<\/p>\n<pre><code class=\"lang-yaml\">$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json\ntype: pipeline\nexperiment_name: exp-training\ndescription: Training Pipeline to train a model that predicts xx\n\ninputs:\n  input:\n    type: uri_folder\n    path: azureml:salesdataset@latest # dataset pointing to uri_folder containing multiple parquet files \n\noutputs:\n  train_data:\n  test_data:\n\nsettings:\n  default_datastore:  azureml:workspaceblobstore\n  default_compute: cpucluster\n  continue_on_step_failure: false\n\njobs:\n\n  prep_data:\n    name: prepare_data\n    display_name: prepare-data\n    code: ..\/..\/..\/data-science\/src\/prep\n    command: &gt;-\n      python prepare_data.py\n      --raw_data ${{inputs.raw_data}}\n      --train_data ${{outputs.train_data}}\n      --test_data ${{outputs.test_data}}\n    environment: azureml:train-env@latest\n    inputs:\n      raw_data: ${{parent.inputs.input}}\n    outputs:\n      train_data: ${{parent.outputs.train_data}}\n      test_data: ${{parent.outputs.test_data}}\n<\/code><\/pre>\n<p>In prepare_data.py script, if i have a URI_FILE, I can access input data with below code - <\/p>\n<pre><code>                       *df = pd.read_parquet((Path(args.raw_data)))*\n<\/code><\/pre>\n<p><strong>Question<\/strong>: <strong>In SDK\/CLI v2, In prepare_data.py, How do I loop through the URI_FOLDER and construct a full dataframe?<\/strong> <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Thank You to the Microsoft Q&A Community Champions",
        "Question_created_time":1679736794053,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1193069\/thank-you-to-the-microsoft-q-a-community-champions",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>We would like to celebrate this month's\u202f<a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Community Champions<\/a>\u202ffor their great contribution to the community on Microsoft Q&amp;A!<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Microsoft Q&amp;A Community Champions<\/a>\u202fprogram recognizes external technology experts who contribute to the Microsoft Q&amp;A community by providing quality answers to technical questions. They are our true \u2018champions\u2019 and provide additional help by taking moderator roles and provide suggestions to improve our overall platform as well as user experience. This program includes both MVPs and non-MVP expert users.\u00a0<\/p>\n<p>We recognize top contributors by providing incentives like moderator privileges in Microsoft Q&amp;A platform, gift cards\u00a0and also share about Q&amp;A contributions in social media channels like <a href=\"https:\/\/twitter.com\/AzureSupport\/status\/1458525468064288777?s=20\">Azure Support Twitter handle<\/a> and in <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/support\/azure-leaderboard\">Microsoft Q&amp;A Azure Leaderboard<\/a>. \u00a0<\/p>\n<p><strong>Thank You to all the Microsoft Q&amp;A Community Champions.<\/strong>\u00a0  <br \/>\nThey are helping make Microsoft Q&amp;A a vibrant place for learning.\u00a0<\/p>\n<p>@JimmySalian-2011 @DillonJS @AlbertoMorillo @soysoliscarlos @AndyDavid @lukemurraynz @NandanHegde-7720 @maserg @michev @DSPatrick @BjoernPeters @AndreasBaumgarten @MichaelDurkan-1632 @msrini-MSFT @ricardosolisvillegas-4678 @stan @DavidBroggy-5270 @ManuPhilip @SandervandeVelde42 @AndrewBlumhardt-1137 @dkrishnaveni-MSFT @AlistairRoss msft @Vinodh247-1375 @rafalzak @HARPREET-MSFT @sreejukg @ErlandSommarskog @martins jackson @RoderickBant74 @OlgaOS-msft @AlanKinane @AndriyBilous @SubashriVasudevan-1752 @cooldadtx @CristianSPIRIDON72 @rbrundritt @Sam-Cogan @TakahitoIwasa @chbeier @clivewatson-9831 @RamyaHarinarthini-MSFT @PratikSomaiya @Samy-7940 @shivapatpi-MSFT @learn2skills @maabdelr-MSFT @ArunSiripuram-1453 @BrunoLucas-9843 @pituach @RafaelDaRocha @ZollnerD @AndreiBarbu-MSFT @CarlosVillagomez-MSFT @lextm @AkramKathimi @subrothodas-9589 @ScottAzureRTOS @GeorgeMoise-0315 <\/p>\n<p><strong>Also, if you are interested in joining the Microsoft Q&amp;A Community Champions program and help shape the future of Microsoft Q&amp;A, please apply here:<\/strong>\u00a0<strong><a href=\"https:\/\/forms.office.com\/r\/vQcapa5BtB\">Community Champions Application Form<\/a><\/strong><\/p>\n<p>Special invitation to:\u00a0\u00a0<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=54ee969b-3f40-4741-89f4-fff4be002d6e\">@TP<\/a> <a href=\"\/users\/na\/?userid=6ec2ad70-1203-43cd-8c2a-523a82e17213\">@LiJia Liu  <\/a><a href=\"\/users\/na\/?userid=251d550c-a217-45b2-bbc5-a59e9e46b995\">@Sedat SALMAN  <\/a> <a href=\"\/users\/na\/?userid=e1e94fa5-a21c-4669-b019-7bfd40cd41bb\">@Ayomide Oluwaga  <\/a> <a href=\"\/users\/na\/?userid=80389cad-bffd-0003-0000-000000000000\">@Luca Lionetti  <\/a> <a href=\"\/users\/na\/?userid=76736f5e-6d21-4f15-b29b-5b7e8eae14dc\">@William Clarkson-Antill  <\/a> <a href=\"\/users\/na\/?userid=68851d39-c760-4dab-a290-cd3bfa2d8c5b\">@Fabricio Godoy  <\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d70d5c95-0000-0003-0000-000000000000\">@Bas Pruijn<\/a> <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6f6bb61e-afe6-4f38-9f92-62a4655b7267\">@Bruce (SqlWork.com)<\/a> <a href=\"\/users\/na\/?userid=857fa4fc-0000-0003-0000-000000000000\">@Olaf Helper  <\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permission issue while creating a ML pipeline job using Azure CLI  2.46.0 through Azure DevOps build pipeline",
        "Question_created_time":1679365723533,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1191594\/permission-issue-while-creating-a-ml-pipeline-job",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am calling a pythons Script from azure CLI task,<\/p>\n<p>python Test-Deployment.py<\/p>\n<p>Inside this script I am authenticating using a service principal with contributor access on resource group level to authorize the command. The script is able to find the workspace and associated cluster as below,<\/p>\n<pre><code>2023-03-21T01:58:05.5062560Z Found existing compute target\n2023-03-21T01:58:05.5063475Z Azure Machine Learning Compute Attached\n2023-03-21T01:58:05.5064101Z Step WrapperFunction is ready to be created [444dce21]\n<\/code><\/pre>\n<p>But on publishing the pipeline step,<\/p>\n<pre><code>published_pipeline = Tests_Pipeline.publish( name=&quot;BaseOrderData_Pipeline_Notebook&quot;, description=&quot;BaseOrderData Published Pipeline Description&quot;, version=&quot;1.0&quot;)\n<\/code><\/pre>\n<p> I am getting following error ,<\/p>\n<pre><code>2023-03-21T01:58:05.5161488Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/pipeline.py&quot;, line 309, in publish\n2023-03-21T01:58:05.5162454Z     return self.graph._save(name=name, description=description, version=version,\n2023-03-21T01:58:05.5163574Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3844, in _save\n2023-03-21T01:58:05.5164547Z     self._validate_and_finalize(pipeline_parameters=None, regenerate_outputs=regenerate_outputs)\n2023-03-21T01:58:05.5165682Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3863, in _validate_and_finalize\n2023-03-21T01:58:05.5166630Z     self.finalize(dry_run=False, regenerate_outputs=regenerate_outputs)\n2023-03-21T01:58:05.5167689Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3609, in finalize\n2023-03-21T01:58:05.5168566Z     Graph._check_threadpool_exceptions(done, not_done)\n2023-03-21T01:58:05.5169661Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3734, in _check_threadpool_exceptions\n2023-03-21T01:58:05.5170496Z     raise ex\n2023-03-21T01:58:05.5171214Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/concurrent\/futures\/thread.py&quot;, line 57, in run\n2023-03-21T01:58:05.5171999Z     result = self.fn(*self.args, **self.kwargs)\n2023-03-21T01:58:05.5173083Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3596, in get_or_create_module_for_fingerprint\n2023-03-21T01:58:05.5173910Z     raise ex\n2023-03-21T01:58:05.5174933Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/graph.py&quot;, line 3594, in get_or_create_module_for_fingerprint\n2023-03-21T01:58:05.5175844Z     module_id = node._module_builder.build()\n2023-03-21T01:58:05.5176863Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/_module_builder.py&quot;, line 62, in build\n2023-03-21T01:58:05.5177744Z     module_id = self._module_provider.create_module(\n2023-03-21T01:58:05.5178781Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 327, in create_module\n2023-03-21T01:58:05.5180050Z     module_entity = _AevaModuleProvider.module_creation(module_def, content_path,\n2023-03-21T01:58:05.5181204Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 293, in module_creation\n2023-03-21T01:58:05.5187263Z     storage_id = module_uploader.upload(directory=content_path)\n2023-03-21T01:58:05.5188102Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 81, in upload\n2023-03-21T01:58:05.5188726Z     storage_id = snapshots_client.create_snapshot(directory)\n2023-03-21T01:58:05.5189496Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/snapshots_client.py&quot;, line 121, in create_snapshot\n2023-03-21T01:58:05.5190210Z     revision_list = self._upload_snapshot_files(entries_to_send, file_or_folder_path, exclude_function)\n2023-03-21T01:58:05.5191106Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/snapshots_client.py&quot;, line 245, in _upload_snapshot_files\n2023-03-21T01:58:05.5191781Z     revision_list = self._upload_files_batch(file_nodes, file_or_folder_path, session)\n2023-03-21T01:58:05.5192624Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/snapshots_client.py&quot;, line 210, in _upload_files_batch\n2023-03-21T01:58:05.5193214Z     revision_list.append(file_revision)\n2023-03-21T01:58:05.5193920Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_common\/async_utils\/task_queue.py&quot;, line 55, in __exit__\n2023-03-21T01:58:05.5194715Z     self.flush(self.identity)\n2023-03-21T01:58:05.5195412Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_common\/async_utils\/task_queue.py&quot;, line 118, in flush\n2023-03-21T01:58:05.5196088Z     self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\n2023-03-21T01:58:05.5196929Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_common\/async_utils\/task_queue.py&quot;, line 118, in &lt;genexpr&gt;\n2023-03-21T01:58:05.5197590Z     self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\n2023-03-21T01:58:05.5198725Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_common\/async_utils\/async_task.py&quot;, line 58, in wait\n2023-03-21T01:58:05.5199344Z     res = self._handler(self._future, self._logger)\n2023-03-21T01:58:05.5200157Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_common\/async_utils\/async_task.py&quot;, line 16, in basic_handler\n2023-03-21T01:58:05.5200726Z     return future.result()\n2023-03-21T01:58:05.5201196Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 437, in result\n2023-03-21T01:58:05.5201681Z     return self.__get_result()\n2023-03-21T01:58:05.5202177Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 389, in __get_result\n2023-03-21T01:58:05.5202667Z     raise self._exception\n2023-03-21T01:58:05.5203141Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/concurrent\/futures\/thread.py&quot;, line 57, in run\n2023-03-21T01:58:05.5203639Z     result = self.fn(*self.args, **self.kwargs)\n2023-03-21T01:58:05.5204396Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/snapshots_client.py&quot;, line 199, in perform_upload\n2023-03-21T01:58:05.5205068Z     return upload_blob_from_stream(data, upload_url, session=session, timeout=TIMEOUT,\n2023-03-21T01:58:05.5205887Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 62, in upload_blob_from_stream\n2023-03-21T01:58:05.5206440Z     execute_func_with_reset(\n2023-03-21T01:58:05.5207150Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 93, in execute_func_with_reset\n2023-03-21T01:58:05.5208069Z     return ClientBase._execute_func_internal(backoff, retries, module_logger, func, reset_func, *args, **kwargs)\n2023-03-21T01:58:05.5208969Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 367, in _execute_func_internal\n2023-03-21T01:58:05.5209635Z     left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n2023-03-21T01:58:05.5210449Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 433, in _handle_retry\n2023-03-21T01:58:05.5210954Z     raise error\n2023-03-21T01:58:05.5211648Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 358, in _execute_func_internal\n2023-03-21T01:58:05.5212222Z     response = func(*args, **kwargs)\n2023-03-21T01:58:05.5212916Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azure\/core\/tracing\/decorator.py&quot;, line 78, in wrapper_use_tracer\n2023-03-21T01:58:05.5213469Z     return func(*args, **kwargs)\n2023-03-21T01:58:05.5214201Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_blob_client.py&quot;, line 731, in upload_blob\n2023-03-21T01:58:05.5214793Z     return upload_block_blob(**options)\n2023-03-21T01:58:05.5215581Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_helpers.py&quot;, line 197, in upload_block_blob\n2023-03-21T01:58:05.5216289Z     process_storage_error(error)\n2023-03-21T01:58:05.5217121Z   File &quot;\/opt\/hostedtoolcache\/Python\/3.8.16\/x64\/lib\/python3.8\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_shared\/response_handlers.py&quot;, line 181, in process_storage_error\n2023-03-21T01:58:05.5217901Z     exec(&quot;raise error from None&quot;)   # pylint: disable=exec-used # nosec\n2023-03-21T01:58:05.5218311Z   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n2023-03-21T01:58:05.5218795Z azure.core.exceptions.HttpResponseError: This request is not authorized to perform this operation.\n2023-03-21T01:58:05.5219394Z RequestId:c8b26985-201e-0022-3398-5b10a7000000\n2023-03-21T01:58:05.5219884Z Time:2023-03-21T01:58:05.3445101Z\n2023-03-21T01:58:05.5220252Z ErrorCode:AuthorizationFailure\n2023-03-21T01:58:05.5220999Z Content: &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthorizationFailure&lt;\/Code&gt;&lt;Message&gt;This request is not authorized to perform this operation.\n2023-03-21T01:58:05.5221693Z RequestId:c8b26985-201e-0022-3398-5b10a7000000\n2023-03-21T01:58:05.5222204Z Time:2023-03-21T01:58:05.3445101Z&lt;\/Message&gt;&lt;\/Error&gt;\n2023-03-21T01:58:05.8088397Z ##[error]Script failed with exit code: 1\n2023-03-21T01:58:05.8105983Z [command]\/usr\/bin\/az account clear\n2023-03-21T01:58:06.7588979Z ##[section]Finishing: Azure CLI \n<\/code><\/pre>\n<p>This works fine when I execute it from inside the Azure ML Studio,<\/p>\n<pre><code>ws = Workspace(\n    subscription_id=&quot;**********************&quot;,\n    resource_group=&quot;************&quot;,\n    workspace_name=&quot;**************&quot;,\n    auth=svc_pr\n    )\n\nSource_directory=&quot;.\/&quot;\n\n\naml_compute_target=&quot;xxxxxx&quot;\ntry:\n    aml_compute=AmlCompute(ws,aml_compute_target)\n    print(&quot;Found existing compute target&quot;)\nexcept ComputeTargetException:\n    provisoning_config=AmlCompute.provisioning_configuration(vm_size='Standard_F32s_v2',\n                                                             min_nodes=1,\n                                                             max_nodes=4)\n    aml_compute=ComputeTarget.create(ws,aml_compute_target,provisoning_config)\n    aml_compute.wait_for_completion(show_output=True,min_node_count=None,timeout_in_minutes=20)\n\nprint(&quot;Azure Machine Learning Compute Attached&quot;)\n\n\nfrom azureml.core import Environment\n\nenv = Environment.from_conda_specification(name='myCustomEnv', file_path='..\/parameters\/conda_dependencies.yml')\nDockerConfiguration(use_docker=True)\nenv.docker.base_image = 'mcr.microsoft.com\/azureml\/minimal-ubuntu20.04-py38-cpu-inference:latest'\n\n\n# # Create Docker Image \n\n\naml_run_config=RunConfiguration()\naml_run_config.target=aml_compute\naml_run_config.environment=env\n\n\n# # Create steps in Experiement\n\nstep1=PythonScriptStep(name=&quot;WrapperFunction&quot;,\n                        script_name=&quot;..\/src\/xxxx.py&quot;,\n                        compute_target=aml_compute,\n                        runconfig=aml_run_config,\n                        source_directory=Source_directory)\n\n\n\nsteps_=[step1]\n\n\n# # Create Pipeline\n\nTests_Pipeline=Pipeline(workspace=ws,steps=steps_)\n\n\n\n# # Validate pipeline\n\n\n\nTests_Pipeline.validate()\n\n\n# Run Experiem\n\n\nTests_Pipeline=Experiment(ws,'BaseOrderData').submit(Tests_Pipeline,regenerate_outputs=True)\n\n\n# In[13]:\n\n\npublished_pipeline = Tests_Pipeline.publish( name=&quot;BaseOrderData_Pipeline_Notebook&quot;, description=&quot;BaseOrderData Published Pipeline Description&quot;, version=&quot;1.0&quot;)\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Application insights doesnt work for Azure Machine Leaning data monitor",
        "Question_created_time":1678832247033,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1189652\/application-insights-doesnt-work-for-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>In Azure machine leaning I'm trying to setup DataDrift detector, however when loading data monitor in azure MAchine Leaning Studio, it shows the following error: <\/p>\n<p><strong>Failed to load metrics<\/strong>  <br \/>\nApplication Insight attached to workspace is not found, please check if you have detach Application Insights from your workspace.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/627bbfef-3345-427b-826e-be62edac836b?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How resolve the azmlinfsrv configuration error during the deploy of a model in Azure ML using CLI v2?",
        "Question_created_time":1678901206840,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1190002\/how-resolve-the-azmlinfsrv-configuration-error-dur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm trying to deploy a model in Azure Machine Learning using CLI v2 on a real-time endpoint with a compute of type AKS (where I've installed the azureml extension). <\/p>\n<p>The command that I'm using is the following:<\/p>\n<pre><code>az ml online-deployment create -f configuration\/blue-deployment.yml --all-traffic  \n<\/code><\/pre>\n<p>and the content of the file is:<\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/kubernetesOnlineDeployment.schema.json\n\nname: blue\ntype: kubernetes\nendpoint_name: &lt;endpoint-name&gt;\nmodel: azureml:&lt;model-name&gt;:&lt;model-version&gt;\n\ncode_configuration:\n  code: ..\/&lt;exp-name&gt;\/src\/deploy\n  scoring_script: score.py\n\nenvironment:\n  name: &lt;env-name&gt;\n  build:\n    path: ..\/&lt;exp-name&gt;\/environment\/\nrequest_settings:\n  request_timeout_ms: 10000\n  max_queue_wait_ms: 5000\n\nresources:\n  requests:\n    cpu: &quot;700m&quot;\n    memory: &quot;2Gi&quot;\n  limits:\n    cpu: &quot;1&quot;\n    memory: &quot;4Gi&quot;\nscale_settings:\n  type: target_utilization\n  min_instances: 1\n  max_instances: 2\n\n<\/code><\/pre>\n<p>The deploy starts, build the environment, but at some point I receive the error below that I never see before:<\/p>\n<pre><code>2023-03-15 17:21:23,312 I [78] gunicorn.error - Worker exiting (pid: 78)\n\n2023-03-15 17:21:23,312 C [78] azmlinfsrv - \n===============Configuration Error=================\nresource_group: extra fields not permitted (environment variable: resource_group)\n===================================================\n2023-03-15 17:21:23,312 C [78] azmlinfsrv - \n===============Configuration Error=================\nsubscription_id: extra fields not permitted (environment variable: subscription_id)\n===================================================\n2023-03-15 17:21:23,312 C [78] azmlinfsrv - \n===============Configuration Error=================\nworkspace_name: extra fields not permitted (environment variable: workspace_name)\n===================================================\n2023-03-15 17:21:23,375 I [11] gunicorn.error - Shutting down: Master\n2023-03-15 17:21:23,375 I [11] gunicorn.error - Reason: Worker failed to boot.\n\nAzure ML Inferencing HTTP server v0.8.1\n\n<\/code><\/pre>\n<p>Nowhere did I explicitly set those environment variables, so I don't know how to solve this problem..<\/p>\n<p>Can anyone be able to help me?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to mount dataset or datalake with read\/write permission in Notebook of Azure Machine Learning Studio?",
        "Question_created_time":1678919175233,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1190089\/how-to-mount-dataset-or-datalake-with-read-write-p",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I've successfully mounted a dataset with read permission to notebook of my machine learning studio account.<\/p>\n<p>But when I try to write back to the datalake\/dataset, it throughs &quot;[Errno 30] Read-only file system&quot;.<\/p>\n<p>How can I mount the dataset with write permission?<\/p>\n<pre><code class=\"lang-python\">\nfrom azureml.core import Workspace, Dataset, Datastore\n\nimport tempfile\n\nfrom azureml.dataprep.fuse.dprepfuse import MountOptions\n\nmount_options = MountOptions(default_permission=0o777)\n\nmounted_path = tempfile.mkdtemp()  \n\nsubscription_id = '**********************'\n\nresource_group = '**********************'\n\nworkspace_name = '**********************'\n\n  \n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\n  \n\ndatastore = Datastore.get(workspace, &quot;my_datalake&quot;)\n\ndataset = Dataset.File.from_files(path=(datastore, 'ml\/folder1\/folder2\/'))\n\nmount_context = dataset.mount(mounted_path, mount_options=mount_options)\n\nmount_context.start()\n\nprint(mounted_path)\n\nimport os\n\nos.mkdir(f&quot;{mounted_path}\/newfolder&quot;, )\n\nOSError                                   Traceback (most recent call last)\n\nCell In[2], line 22\n\n 18 print(mounted_path)\n\n 20 import os\n\n---&gt; 22 os.mkdir(f&quot;{mounted_path}\/john&quot;, )\n\n 24 # refer to this\n\n 25 # https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/884340\/read-only-file-system-error-in-azureml-studio\n\n 26 # https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/67126\/failure-exception-oserror-(errno-30)-read-only-fil\n\n 27 \n\n 28 # az ml datastore attach-blob --account-name cgrpdatalakepoc --container-name filesystempoc --name ds_datalake_poc\n\nOSError: [Errno 30] Read-only file system: '\/tmp\/tmpfyqld99p\/newfolder'\n\name: azureml_py38\n\nchannels:\n\n  - conda-forge\n\n  - anaconda\n\n  - defaults\n\ndependencies:\n\n  -...\n\n \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error when using azure trained model on yolov5",
        "Question_created_time":1650115703107,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/814600\/error-when-using-azure-trained-model-on-yolov5",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I trained a model with Azure Machine Learning studio for an objects detection tasks using yolov5 as the model. I created the experiment using the notebook and it ran successfully for a little less than 30 epochs. The experiment status tell me that it completed successfully and I have access to the file &quot;model.pt&quot; in the output folder of the child run.<\/p>\n<p>Now I would like to use that trained model and test it with the github version of yolov5 installed on my local computer, but when I use it, it simply doesn't work and display an error (it works with my own trained model from my local computer), the error is the following:<\/p>\n<p>Traceback (most recent call last):  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\detect.py&quot;, line 261, in &lt;module&gt;  <br \/>\nmain(opt)  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\detect.py&quot;, line 256, in main  <br \/>\nrun(**vars(opt))  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\lib\\site-packages\\torch\\autograd\\grad_mode.py&quot;, line 27, in decorate_context  <br \/>\nreturn func(*args, **kwargs)  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\detect.py&quot;, line 92, in run  <br \/>\nmodel = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\models\\common.py&quot;, line 305, in <strong>init<\/strong>  <br \/>\nmodel = attempt_load(weights if isinstance(weights, list) else w, map_location=device)  <br \/>\nFile &quot;C:\\Users\\Username\\Desktop\\yolov5\\models\\experimental.py&quot;, line 98, in attempt_load  <br \/>\nmodel.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval()) # FP32 model  <br \/>\nKeyError: 'model'<\/p>\n<p>So is there an explanation, or does the model simply doesn't work with classic yolov5 installations ? Either way I would appreciate the help. Thank you !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I delete a registered dataset on Azure Machine Learning?",
        "Question_created_time":1679054741080,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1190714\/how-can-i-delete-a-registered-dataset-on-azure-mac",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I know how to unregister a dataset, but I want to delete it to be able to create a new dataset using the same name. <\/p>\n<p>Reason for this is that I initially used the wrong Type (URI_FILE) instead of MLTable and it\u00b4s not possible to change that:<\/p>\n<pre><code>&quot;message&quot;: &quot;(UserError) The provided type MLTable for this version is incorrect, because all versions of this data asset should match the initial version type UriFile. \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML endpoint - gunicorn worker timeout",
        "Question_created_time":1630071044527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530811\/azureml-endpoint-gunicorn-worker-timeout",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello everyone,    <br \/>\nI am trying to deploy a large model using AzureML endpoint.     <br \/>\nThe model is made up of many sub-models which get loaded by the init() method as described in the documentation <a href=\"https:\/\/learn.microsoft.com\/bs-cyrl-ba\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">here<\/a>.    <br \/>\nThe model is trained and then registered in AzureML.     <\/p>\n<p>When I deploy the model I can see in the logs that the gunicorn worker resets themselves after 300 seconds, so the whole ensemble of sub-models never have time to completely be loaded.    <\/p>\n<p>Is there a way to manually set the timeout of the gunicorn workers?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Couldn't find 'Select Columns in Dataset' and 'Normalize Data' modules while trying to add transformations to my dataset",
        "Question_created_time":1675096889136,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165493\/couldnt-find-select-columns-in-dataset-and-normali",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hi All,<\/p>\n<p>As I wrote on the title, I couldn't find 'Select Columns in Dataset' and 'Normalize Data' modules while trying to add transformations to my dataset.<\/p>\n<p>Can anyone kindly help? Please note that I am just a beginner and I really am not well-versed in this topic, as I am just starting to learn the basics of Azure.<\/p>\n<p>Best regards,<\/p>\n<p>G<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permission issue while creating ML pipeline job using Azure CLI V2",
        "Question_created_time":1678379674266,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1188109\/permission-issue-while-creating-ml-pipeline-job-us",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to create a ML pipeline job using Azure CLI V2 commands. pls find the command below :<\/p>\n<pre><code>az ml job create --file .\/mlops\/azureml\/train\/train-pipeline.yml --resource-group myresource_group \\\n\t--workspace-name myworkspace --query name -o tsv\n\n<\/code><\/pre>\n<p>I am using Service principal with contributor access on resource group level to authorize the command. But on running the command, it failed to create the ML Pipeline job with following error :<\/p>\n<p>azure.core.exceptions.HttpResponseError: Operation returned an invalid status 'This request is not authorized to perform this operation.'<\/p>\n<p>1016ErrorCode:AuthorizationFailure<\/p>\n<p>1017<\/p>\n<p>1018ERROR: cli.azure.cli.core.azclierror: Operation returned an invalid status 'This request is not authorized to perform this operation.'<\/p>\n<p>1019ErrorCode:AuthorizationFailure<\/p>\n<p>1020ERROR: az_command_data_logger: Operation returned an invalid status 'This request is not authorized to perform this operation.'<\/p>\n<p>1021ErrorCode:AuthorizationFailure<\/p>\n<p>1022DEBUG: cli.knack.cli: Event: Cli.PostExecute [&lt;function AzCliLogging.deinit_cmd_metadata_logging at 0x7f6f3d7708b0&gt;]<\/p>\n<p>1023INFO: az_command_data_logger: exit code: 1<\/p>\n<p>1024INFO: cli.<strong>main<\/strong>: Command ran in 8.520 seconds (init: 0.336, invoke: 8.184)<\/p>\n<p>1025INFO: telemetry.main: Begin splitting cli events and extra events, total events: 1<\/p>\n<p>1026INFO: telemetry.client: Accumulated 0 events. Flush the clients.<\/p>\n<p>1027INFO: telemetry.main: Finish splitting cli events and extra events, cli events: 1<\/p>\n<p>1028INFO: telemetry.save: Save telemetry record of length 3744 in cache<\/p>\n<p>1029WARNING: telemetry.check: Negative: The \/home\/runner\/.azure\/telemetry.txt was modified at 2023-03-09 10:02:31.582632, which in less than 600.000000 s<\/p>\n<p>1030Error: Process completed with exit code 1.<\/p>\n<p>it says it is not authorized to access the Machine learning workspace's default blobstore while creating the job.<\/p>\n<p>Please help me figuring out the issue.<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why am I getting unexplained charges on my Microsoft Azure free account?",
        "Question_created_time":1678896697733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1189971\/why-am-i-getting-unexplained-charges-on-my-microso",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, hope everyone is well. I opened an Azure free account on the 10th of January. I used the Azure portal for Azure Fundamentals and Azure AI Fundamentals. One day I noticed that I didn't have access to the AI Fundamentals on the portal only to find out that costs have been incurred on my free account. I am not sure where these costs are coming from, because when I checked my invoice, it is not giving me a clear explanation of where these costs are coming from only labeled them as &quot;other Microsoft services&quot;  <\/p>\n<p>Please if someone could provide me with some clarity as to why I am getting these charges. Thank you<\/p>",
        "Question_closed_time":1678897172116,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi,<\/p>\n<p>Please create a new billing support request.  Below is link to open new billing support request in portal:<\/p>\n<p><a href=\"https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/%7E\/support\/openedBy\/AzurePortal\">https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/~\/support\/openedBy\/AzurePortal<\/a><\/p>\n<p>It will look similar to below sample screenshot:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/6882cb8e-c0c1-4aed-bffe-59c1e098af00?platform=QnA\" alt=\"azure new billing support request sample\" \/><\/p>\n<p>Enter summary, select Problem type, select Problem subtype, then click Next. After a delay, some potential solutions will be shown. Click <strong>Return to support request<\/strong> as shown below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/cfc06bb3-704f-44f5-af90-c32082ab5821?platform=QnA\" alt=\"azure support request solutions page\" \/><\/p>\n<p>This will return you to the recommended solution tab. Click <strong>Next<\/strong>, as shown below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/e17dbf4b-713a-4c8c-aa0d-6a3f60edf3ea?platform=QnA\" alt=\"azure support request after solutions page\" \/><\/p>\n<p>Fill out the information on the Additional details tab making sure your email address\/phone are correct, click <strong>Next<\/strong>, then finally click <strong>Create<\/strong>. At this point your support request will be created and you should receive a Case email from Microsoft Support and will be contacted in near future by support engineer.<\/p>\n<p>If the above was helpful, please click <strong>Accept Answer<\/strong>.<\/p>\n<p>Thanks.<\/p>\n<p>-TP<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"The workspace configuration file config.json, could not be found",
        "Question_created_time":1678117113273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1186946\/the-workspace-configuration-file-config-json-could",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm building a batch inference pipeline <strong>azureml.pipeline<\/strong>. I've placed the config.json in the directory and passed it explicitly<\/p>\n<pre><code class=\"lang-python\">ws = Workspace.from_config(path='ranking\/config.json')\n<\/code><\/pre>\n<p>I tried to let azure find it:<\/p>\n<pre><code class=\"lang-python\">ws = Workspace.from_config()\n<\/code><\/pre>\n<p>but in both cases, azure sdk doesn't seem to acknowledge the file.<\/p>\n<p><strong>The First:<\/strong><\/p>\n<p>&quot;error&quot;: {<\/p>\n<pre><code>    &quot;code&quot;: &quot;UserError&quot;,\n\n    &quot;message&quot;: &quot;The workspace configuration file config.json, could not be found in \/tmp\/44660cc1-2a72-49df-af2b-e41226727952\/azureml-bi\/114\/ranking\/config.json or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http:\/\/ml.azure.com and clicking on the name of your workspace in the right top.&quot;\n\n}\n<\/code><\/pre>\n<p><strong>The second:<\/strong><\/p>\n<p>&quot;error&quot;: {<\/p>\n<pre><code>    &quot;code&quot;: &quot;UserError&quot;,\n\n    &quot;message&quot;: &quot;The workspace configuration file config.json, could not be found in \/tmp\/44660cc1-2a72-49df-af2b-e41226727952\/azureml-bi\/114\/ or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http:\/\/ml.azure.com and clicking on the name of your workspace in the right top.&quot;\n\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is Speech to Text (Azure Cognitive Services) supported for WebGL Builds in Unity?",
        "Question_created_time":1664193255743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1023234\/is-speech-to-text-(azure-cognitive-services)-suppo",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I making a game in Unity using Azure Speech To Text SDK (C#).     <br \/>\nI have been able to build for mobile and standalones platforms, but I am encountering errors when trying to build for WebGL.     <br \/>\nIs Unity WebGL supported by the SDK? Or is there a way to support it outside the SDK available in GitHub?    <\/p>\n<p>Building fails due to a missing assembly reference for Microsoft namespace.    <br \/>\nScreen shot with console     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/244766-image.png?platform=QnA\" alt=\"244766-image.png\" \/>    <\/p>\n<p>Target environment for WebGL is missing in the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/quickstarts\/setup-platform?tabs=windows%2Cubuntu%2Cunity%2Cjre%2Cmaven%2Cnodejs%2Cmac%2Cpypi&amp;pivots=programming-language-csharp#tabpanel_1_unity\">Speech SDK Documentation<\/a>. Does it mean Azure Speech To Text can\u00b4t work in Web Build?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"calling AML model in DBX- HTTP Error 401: Unauthorized",
        "Question_created_time":1678673806663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1188851\/calling-aml-model-in-dbx-http-error-401-unauthoriz",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi!<\/p>\n<p>I have a api endpoint authentication issue in dbx.. and I posted my question in StackOverflow.<\/p>\n<p>You could see it through <a href=\"https:\/\/stackoverflow.com\/questions\/75717482\/calling-aml-model-in-dbx-http-error-401-unauthorized\">https:\/\/stackoverflow.com\/questions\/75717482\/calling-aml-model-in-dbx-http-error-401-unauthorized<\/a><\/p>\n<p>I would really appreciate it if anyone in Azure Support could help me with it.<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning with on premise SQL Server",
        "Question_created_time":1592874857830,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38894\/azure-machine-learning-with-on-premise-sql-server",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi is there a way for Azure Machine Learning to be able to perform analytics using data from an on premise SQL Server?    <\/p>\n<p>Only found the below article which is for Azure Machine Learning Studio (classic):    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server<\/a>    <\/p>\n<p>Thanks.    <\/p>",
        "Question_closed_time":1592900268573,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a>@conrad<\/a> Here is the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#access-datasets-in-your-script\">link<\/a> to connect with the Azure SQL server.  <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481\">https:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is there a way to delete datasets on AzureML?",
        "Question_created_time":1632745762197,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/567611\/is-there-a-way-to-delete-datasets-on-azureml",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have a list of datasets in our AzureML. Is there a way to delete the datasets that we no longer require?  <\/p>",
        "Question_closed_time":1632778084783,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>Thanks for reaching out to us. I think you are mentioning how to unregister dataset you do not need at this moment in Machine Learning Studio.    <\/p>\n<p>You can do it by go to your Azure Machine Learning Studio and check the Datasets. Then select the dataset you not longer need and click unregister.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135704-image.png?platform=QnA\" alt=\"135704-image.png\" \/>    <\/p>\n<p>Hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I install an older version of the Azure CLI ml extension?",
        "Question_created_time":1677177834880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1183753\/how-do-i-install-an-older-version-of-the-azure-cli",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I'm running CI\/CD pipelines in Azure Dev Ops in order to deploy my machine learning workloads on components of a Azure Machine Learning Workspace (e.g. AzureML pipelines, endpoints, etc). I recently came across an issue in my pipelines and wanted to validate that the versions of the Azure CLI and Azure CLI ml extension didn't cause this issue.<\/p>\n<p>Because the Azure CLI is a tool that is developed in python, it is relatively easy to install an older version of the cli. I can just run <code>pip install azure-cli==2.44.1<\/code>. However, I'm having trouble figuring out how to install a specific version of the ml extension. According to this documentation, all extensions are packaged as python wheels, so theoretically if I had the URL of the build wheel, I could just target that. But I'm having trouble finding where the ml extension code is hosted. I found the pypi package for <a href=\"https:\/\/pypi.org\/project\/azure-cli-ml\/\">v1 of the extension<\/a>. Does anyone know where v2 is hosted?<\/p>\n<p>The version of the extension I would like to install is <code>2.13.0<\/code>.<\/p>",
        "Question_closed_time":1677220157550,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=1837dca2-1954-4413-9ba8-ffcc3afb6ce4\">Claire Salling<\/a> You can install a specific version of <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli?tabs=private\">Azure ML cli extension<\/a> using these commands.<\/p>\n<p>Remove any existing extensions of azure-cli-ml(v1) or ml(v2)<\/p>\n<p><code>az extension remove -n azure-cli-ml <\/code>  <br \/>\n<code>az extension remove -n ml<\/code><\/p>\n<p>Add the required version:<\/p>\n<p><code>az extension add --name ml --version 2.13.0<\/code><\/p>\n<p>List the extension to confirm the version.<\/p>\n<p><code>az extension list<\/code><\/p>\n<pre><code> {\n    &quot;experimental&quot;: false,\n    &quot;extensionType&quot;: &quot;whl&quot;,\n    &quot;name&quot;: &quot;ml&quot;,\n    &quot;path&quot;: &quot;C:\\\\Users\\\\user\\\\.azure\\\\cliextensions\\\\ml&quot;,\n    &quot;preview&quot;: false,\n    &quot;version&quot;: &quot;2.13.0&quot;\n  }\n<\/code><\/pre>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why is CLI authentication required on Child Nodes when already authenticated on Parent Node?",
        "Question_created_time":1677537225356,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184854\/why-is-cli-authentication-required-on-child-nodes",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a python script configured to perform parallel step run. I am executing a pipeline which executes parallel run on cluster with 100 nodes. As the pipeline executes it asks for authentication using CLI which I did. But on each child node similar interactive authentication is required.<\/p>\n<p>Why it doesn't authenticates automatically for child nodes? How can I fix this?<\/p>",
        "Question_closed_time":1677537687750,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The reason why authentication is required on each child node, even if you have already authenticated on the parent node, is that each node is a separate machine with its own environment and security context. The authentication information you provided on the parent node is only valid within that particular environment and cannot be automatically propagated to the child nodes.<\/p>\n<p>To avoid having to authenticate on each child node, you can try one of the following options:<\/p>\n<ol>\n<li> Use a non-interactive authentication method: Instead of using interactive authentication with the CLI, you can use a non-interactive authentication method such as service principal authentication. This involves creating a service principal in Azure AD and providing it with the appropriate permissions to access the resources you need. Once you have created the service principal, you can use its credentials to authenticate your script on each child node without requiring interactive authentication.<\/li>\n<li> Use a centralized authentication mechanism: You can use a centralized authentication mechanism such as Active Directory Federation Services (ADFS) or Azure AD Domain Services to provide a single sign-on experience for all users and machines in your organization. With ADFS or Azure AD Domain Services, users can authenticate once and then access all the resources they need without requiring additional authentication.<\/li>\n<li> Use a session-based authentication method: You can use a session-based authentication method such as Remote Desktop Services (RDS) or PowerShell Remoting to establish a remote session with each child node and then authenticate once within that session. This will allow you to perform all the necessary operations on the child node without requiring additional authentication.<\/li>\n<\/ol>\n<p>Depending on your specific use case and requirements, one or more of these options may be suitable for your needs.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Authenticate managed online endpoint to download model from datastore",
        "Question_created_time":1678458511846,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1188427\/authenticate-managed-online-endpoint-to-download-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have a model registered in Machine Learning Workspace, and the underlying model files are stored in an Azure Data Lake Storage Gen2 type datastore. I would like to deploy this model to an managed online endpoint but I encounter authentication problems when doing so. If the underlying model files are saved to the default workspaceblobstore I do not encounter these same authentication issues.<\/p>\n<p>I am using python SDK v2 for both datastore and managed online endpoint\/deployment creation:<\/p>\n<pre><code class=\"lang-python\">from azure.ai.ml.entities import AzureDataLakeGen2Datastore\nfrom azure.identity import DefaultAzureCredential\nfrom azure.ai.ml import MLClient\n\ncredential = DefaultAzureCredential()\nml_client = MLClient.from_config(credential=credential)\nstore = AzureDataLakeGen2Datastore(\n    name=settings.data_lake_enriched_container_friendly_name,\n    description=&quot;enriched container&quot;,\n    account_name=settings.data_lake_storage_account_name,\n    filesystem=settings.data_lake_enriched_container,\n)\n\nadl_datastore = ml_client.create_or_update(store)\n<\/code><\/pre>\n<pre><code class=\"lang-python\">from azure.ai.ml.entities import (\n    Environment,\n    ManagedOnlineEndpoint,\n    ManagedOnlineDeployment,\n    CodeConfiguration,\n)\n\n\nregistered_model = ml_client.models.get(\n    &quot;model&quot;, version=&quot;1&quot;\n)\n\n\nendpoint = ManagedOnlineEndpoint(\n    name=settings.endpoint_name, description=&quot;Classification endpoint&quot;\n)\nenv = Environment(\n    conda_file=&quot;.\/environment.yml&quot;,\n    image=&quot;mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu20.04:latest&quot;,\n)\n\nblue_deployment = ManagedOnlineDeployment(\n    name=&quot;blue&quot;,\n    endpoint_name=settings.endpoint_name,\n    model=registered_model,\n    environment=env,\n    code_configuration=CodeConfiguration(\n        code=&quot;deployment_scripts&quot;, scoring_script=&quot;score.py&quot;\n    ),\n    instance_type=&quot;Standard_DS2_v2&quot;,\n    instance_count=1,\n    environment_variables={&quot;model_folder&quot;: settings.specific_model_folder},\n)\npoller = ml_client.online_endpoints.begin_create_or_update(endpoint)\nwhile True:\n    print(&quot;waiting for online endpoint creation&quot;)\n    poller.wait(10)\n    if poller.done():\n        print(poller.status())\n        break\nml_client.online_deployments.begin_create_or_update(\n    deployment=blue_deployment,\n)\n<\/code><\/pre>\n<p>If I manually go to the underlying datastore and add a role assignment to the managed online endpoint, the deployment succeeds but I would like to get rid of this manual step.  <\/p>\n<p>I am guessing that I should either use the credentials parameter of the AzureDataLakeGen2Datastore Class: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen2datastore?view=azure-python\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen2datastore?view=azure-python<\/a> or somehow make the managed online endpoint authenticate towards the underlying datastore using a service principal but I do not seem to be able to figure out how this should be done.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MLOps Maturity Model",
        "Question_created_time":1678125232640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1186987\/mlops-maturity-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey,<\/p>\n<p>i'm right now trying to understand the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/example-scenario\/mlops\/mlops-maturity-model\">MLOps Maturity Model<\/a>. The thing i don't understand is the Level 1 (DevOps but not MLOps). Why is the data gathering at this stage automatically, when data is unique for MLOps and is no part of DevOps? And the second thing is, why are the different people not working together at that stage? The DevOps principles say, that the Development and the Operations are working together and communicate with eachother. And in the case of MLOps the Developers are the Data Scientists and the Data Engineers. So why are they siloed from the Software Engineer (Operations)?<\/p>\n<p>Thanks in advance <\/p>",
        "Question_closed_time":1678153522030,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ee824636-df75-475b-b9cb-ed765083873f\">@MacerPacer  <\/a><\/p>\n<p>Thanks for reaching out to us, below answer is based on some researches I got across the internet, please let me know if you have any point you feel confused.<\/p>\n<p>For your question 1, why is the data gathering at this stage automatically, when data is unique for MLOps and is no part of DevOps?<\/p>\n<p>Level 1 representing organizations that have adopted DevOps practices but have not yet integrated MLOps practices into their workflows. Regarding the data gathering aspect of Level 1, it is important to note that data is a critical component of both DevOps and MLOps. <strong>In DevOps, data is often used for testing and monitoring applications in production, while in MLOps, data is used to train, validate, and test machine learning models.<\/strong> Therefore, it makes sense for organizations at Level 1 to have some data gathering processes in place, even if they have not yet fully integrated MLOps practices into their workflows.<\/p>\n<p>For your question 2, why are the different people not working together at that stage? The DevOps principles say, that the Development and the Operations are working together and communicate with eachother.<\/p>\n<p>Regarding the siloed nature of different teams at Level 1, it is true that DevOps emphasizes collaboration and communication between development and operations teams. However, in the context of MLOps, there may be additional teams involved, <strong>such as data science and data engineering teams, that are responsible for building and managing machine learning models.<\/strong> These teams may have different expertise and tooling requirements than traditional software engineering teams, which can lead to silos. However, as organizations progress through the maturity model, they can work towards breaking down these silos and fostering greater collaboration between different teams involved in the MLOps process.<\/p>\n<p>For your question 3, in the case of MLOps the Developers are the Data Scientists and the Data Engineers. So why are they siloed from the Software Engineer (Operations)?<\/p>\n<p>We have explained some parts of it in the Q2, it is mainly because of the different tooling and process as below.<\/p>\n<p>In the case of MLOps, it is true that developers, specifically data scientists and data engineers, are responsible for <strong>building and managing machine learning models.<\/strong> However, software engineering teams, specifically operations teams, play a critical role in <strong>deploying and managing<\/strong> these models in production environments.<\/p>\n<p>The reason for the potential silos between these teams is that they may have different areas of expertise and use different tools and technologies. For example, data scientists and data engineers may be more familiar with tools such as Jupyter notebooks and data processing frameworks, while operations teams may be more familiar with infrastructure automation tools such as Kubernetes or other approaches.<\/p>\n<p>I hope my answer helps, please take a look and let me know if you have any other question. Happy to help further. Thanks a lot.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do i send custom data from WebChat to Bot in Node.js?",
        "Question_created_time":1652743563510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/851665\/how-do-i-send-custom-data-from-webchat-to-bot-in-n",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>i am trying to send some data from the WebChat to a BotFramework (Node.js)<\/p>\n<p>Here is the WebChat code i am trying to use using the payload in the store :<\/p>\n<p>In the Bot side, when i log the activity i don't find the payload i sent :<\/p>\n<pre><code>this.onMembersAdded(async (context, next) =&gt; {\n      for (const idx in context.activity.membersAdded) {\n        \/\/ Greet anyone that was not the target (recipient) of this message.\n        \/\/ Since the bot is the recipient for events from the channel,\n        \/\/ context.activity.membersAdded === context.activity.recipient.Id indicates the\n        \/\/ bot was added to the conversation, and the opposite indicates this is a user.\n        console.log(context.activity)\n        if (context.activity.name === 'webchat\/join') {\n          console.log(context.activity.value)\n          await context.sendActivity(`Got \\`webchat\/join\\` event, your language is \\`${ (context.activity.value || {}).email }\\``);\n        }\n<\/code><\/pre>\n<p>Any ideas why ? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AZURE MAchine Learning  - Resource exhausted",
        "Question_created_time":1678104336393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1186849\/azure-machine-learning-resource-exhausted",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Currently we are facing issues with resource exhausted with several experiments (see table below).<\/p>\n<p>We are using <a href=\"https:\/\/images.nvidia.com\/content\/tesla\/pdf\/188417-Tesla-M60-DS-A4-fnl-Web.pdf%22https:\/\/images.nvidia.com\/content\/tesla\/pdf\/188417-tesla-m60-ds-a4-fnl-web.pdf%22\">GPU - 1 x NVIDIA Tesla M60<\/a>, Standard_NV6 (6 cores, 56 GB RAM, 380 GB disk)<\/p>\n<table>\n<thead>\n<tr>\n<th>Image size<\/th>\n<th>Batch size<\/th>\n<th>status<\/th>\n<th>Remarks<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>256x256<\/td>\n<td>32<\/td>\n<td>failed<\/td>\n<td>Resource exhausted<\/td>\n<\/tr>\n<tr>\n<td>256x256<\/td>\n<td>16<\/td>\n<td>working<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>512x512<\/td>\n<td>16<\/td>\n<td>failed<\/td>\n<td>Resource exhausted<\/td>\n<\/tr>\n<tr>\n<td>512x512<\/td>\n<td>8<\/td>\n<td>failed<\/td>\n<td>Resource exhausted<\/td>\n<\/tr>\n<tr>\n<td>512x512<\/td>\n<td>1<\/td>\n<td>working<\/td>\n<td><\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<p>How to decide which GPU machine is to be purchased to train the deep learning task semantic segmentation. Specifications: model with 31 million \u00a0parameters image size ( minimum 1024x1024), batch size 256 framework -tensorflow keras 2.7 Total image samples 30,000, Label Mask samples 30,000<\/p>\n<p>\u00a0<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to set disableLocalAuth property while creating AML compute using Azure Cli ML v2",
        "Question_created_time":1677603419413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185166\/how-to-set-disablelocalauth-property-while-creatin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,<\/p>\n<p>I want to set disableLocalAuth property while creating AMLCompute type compute using Azure CLI ML v2. I couldnt find any argument to set this property or value to this in <\/p>\n<p>&quot;az ml compute create&quot; command.<\/p>\n<p>without setting this property to true i am not able to create the amlcompute in my workspace as in our organization adminstrator has set this policy. I am getting following error :<\/p>\n<pre><code>Additional Information:Type: PolicyViolation\nInfo: {\n    &quot;evaluationDetails&quot;: {\n        &quot;evaluatedExpressions&quot;: [\n            {\n                &quot;result&quot;: &quot;True&quot;,\n                &quot;expressionKind&quot;: &quot;Field&quot;,\n                &quot;expression&quot;: &quot;type&quot;,\n                &quot;path&quot;: &quot;type&quot;,\n                &quot;expressionValue&quot;: &quot;Microsoft.MachineLearningServices\/workspaces\/computes&quot;,\n                &quot;targetValue&quot;: &quot;Microsoft.MachineLearningServices\/workspaces\/computes&quot;,\n                &quot;operator&quot;: &quot;Equals&quot;\n            },\n            {\n                &quot;result&quot;: &quot;True&quot;,\n                &quot;expressionKind&quot;: &quot;Field&quot;,\n                &quot;expression&quot;: &quot;Microsoft.MachineLearningServices\/workspaces\/computes\/disableLocalAuth&quot;,\n                &quot;path&quot;: &quot;properties.disableLocalAuth&quot;,\n                &quot;targetValue&quot;: &quot;True&quot;,\n                &quot;operator&quot;: &quot;NotEquals&quot;\n            }\n        ]\n    },\n\n<\/code><\/pre>\n<p>Please help me with proper guidance on this issue.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I figure out the duration of my AutoML run?",
        "Question_created_time":1678128410413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1187015\/how-do-i-figure-out-the-duration-of-my-automl-run",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am a newbie to Machine Learning.  I am using AutoML to run an experiment as I learn about machine learning. My current model has been running for 18 hours; 24-hour exit criterion training time is selected.<\/p>\n<p>Is there a way to figure out the duration of a model run?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I import existing bounding box annotations into Azure ML for relabelling",
        "Question_created_time":1678336351863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1187877\/how-can-i-import-existing-bounding-box-annotations",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have an external image dataset of ~10k images with bounding box classifications. I would like to reclassify the objects while keeping the original bounding boxes (e.g. the object was originally labelled as 'car' but I want to relabel it to its model 'Ford'). The annotations are currently stored in a json file with COCO detection format.<\/p>\n<p>Is there a way to import these external annotations into a data labelling project in the Azure ML studio?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Question_created_time":1643903626503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721792\/how-to-get-model-id-of-the-latest-version-register",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello MS team,  <\/p>\n<p>I have registered an ML model in the AML workspace using an Azure Machine learning pipeline and triggered the main control script of the pipeline by linking the repo present in Azure DevOps to the AML workspace(using Service principal).   <\/p>\n<p>How do I download the latest version of the model from the AML workspace to the <em>&quot;Artifacts&quot;<\/em> folder in Azure DevOPs?  <\/p>\n<p>Any help is appreciated please.  <\/p>",
        "Question_closed_time":1643933985587,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6755dac2-30f1-48a2-9d0d-4d2c96edc5d4\">@Shivapriya Katta  <\/a>     <\/p>\n<p>I think you are mentioning how to get the latest version of model and download the model in az ml.    <\/p>\n<p>There are 2 steps, one is list the model to get the model ID you want, two is download the model.    <\/p>\n<p><strong>az ml model list<\/strong>    <br \/>\nList models in the workspace.    <\/p>\n<pre><code>az ml model list [--dataset-id]  \n                 [--latest]  \n                 [--model-name]  \n                 [--path]  \n                 [--property]  \n                 [--resource-group]  \n                 [--run-id]  \n                 [--subscription-id]  \n                 [--tag]  \n                 [--workspace-name]  \n                 [-v]  \n<\/code><\/pre>\n<p>Optional Parameters    <br \/>\n--dataset-id    <br \/>\nIf provided, will only show models with the specified dataset ID.    <\/p>\n<p>--latest -l    <br \/>\nIf provided, will only return models with the latest version.    <\/p>\n<p>--model-name -n    <br \/>\nAn optional model name to filter the list by.    <\/p>\n<p>--path    <br \/>\nPath to a project folder. Default: current directory.    <\/p>\n<p>--property    <br \/>\nKey\/value property to add (e.g. key=value ). Multiple properties can be specified with multiple --property options.    <\/p>\n<p>--resource-group -g    <br \/>\nResource group corresponding to the provided workspace.    <\/p>\n<p>--run-id    <br \/>\nIf provided, will only show models with the specified Run ID.    <\/p>\n<p>--subscription-id    <br \/>\nSpecifies the subscription Id.    <\/p>\n<p>--tag    <br \/>\nKey\/value tag to add (e.g. key=value ). Multiple tags can be specified with multiple --tag options.    <\/p>\n<p>--workspace-name -w    <br \/>\nName of the workspace containing models to list.    <\/p>\n<p>-v    <br \/>\nVerbosity flag.    <\/p>\n<p><strong>az ml model download<\/strong>    <br \/>\nDownload a model from the workspace.    <\/p>\n<pre><code>az ml model download --model-id  \n                     --target-dir  \n                     [--overwrite]  \n                     [--path]  \n                     [--resource-group]  \n                     [--subscription-id]  \n                     [--workspace-name]  \n                     [-v]  \n<\/code><\/pre>\n<p>Required Parameters    <br \/>\n--model-id -i    <br \/>\nID of model.    <\/p>\n<p>--target-dir -t    <br \/>\nTarget directory to download the model file to.    <\/p>\n<p>Optional Parameters    <br \/>\n--overwrite    <br \/>\nOverwrite if the same name file exists in target directory.    <\/p>\n<p>--path    <br \/>\nPath to a project folder. Default: current directory.    <\/p>\n<p>--resource-group -g    <br \/>\nResource group corresponding to the provided workspace.    <\/p>\n<p>--subscription-id    <br \/>\nSpecifies the subscription Id.    <\/p>\n<p>--workspace-name -w    <br \/>\nName of the workspace containing model to show.    <\/p>\n<p>-v    <br \/>\nVerbosity flag.    <\/p>\n<p>Hope this helps!     <\/p>\n<p><em>Please kindly accept the answer if you feel helpful, thank you!<\/em>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Registered models with AML SDK v2 doesn't appear in pipeline",
        "Question_created_time":1678184230446,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1187246\/registered-models-with-aml-sdk-v2-doesnt-appear-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have successfully been able to register a model in AML workspace, using SDK v2, however, when I navigate to AML workspace UI and the given pipeline, the registered model don't appear:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/543497b2-98b7-4412-91b3-ea0e6287e592?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I have registered the models using both this method:<\/p>\n<pre><code class=\"lang-python\">cloud_model = Model(\n    path=model_path,\n    name=&quot;cloud-path-example&quot;,\n    type=AssetTypes.CUSTOM_MODEL,\n    description=&quot;Model created from cloud path.&quot;,\n)\nml_client.models.create_or_update(cloud_model)\n\n<\/code><\/pre>\n<p>and this method:<\/p>\n<pre><code>mlflow.spacy.save_model(nlp, output_folder)\nmodel_path = os.path.abspath(output_folder)\nmlflow.register_model(f&quot;file:\/\/{model_path}&quot;, &quot;model-test&quot;)\n<\/code><\/pre>\n<p>Both methods successfully registers the model but the &quot;connection&quot; between the registered model and the pipeline run is missing. What could the reason for this be? My impression is that this &quot;connection&quot; should appear automatically?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clone ADF pipeline for AML pipeline not editable",
        "Question_created_time":1677659754636,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185368\/clone-adf-pipeline-for-aml-pipeline-not-editable",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I had a ADF pipeline that ran a AML training pipeline. I created a new AML pipeline and in ADF cloned my pipeline. You are then unable to change the AML pipeline details in the AML Execution Activity. You have to create a new one. Is this supposed to be uneditable ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Need help understanding the data structure for AutoML",
        "Question_created_time":1677678930636,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185465\/need-help-understanding-the-data-structure-for-aut",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I have an IoT device that updates an Azure Storage Table anytime one of its values changes. For example, If the fish tank temperature changes from 68 to 69, that gets logged. If the filter pump runs, that gets logged. When the little treasure chest opens and bubbles come out, that gets logged. This makes my tabular data look like this:<\/p>\n<pre><code>TimeStamp  Name                 Value\n(time)     TreaureChestBubbles  2.8\n(time)     TreaureChestBubbles  5\n(time)     FilterPumpRunning    1\n(time)     TreaureChestBubbles  3.5\n(time)     FilterPumpRunning    0\n(time)     WaterTemp            66\n(time)     TreaureChestBubbles  -1 (indicating an error)\n<\/code><\/pre>\n<p>I want to create a model that predicts when my little treasure chest is going to fail.<\/p>\n<p>I dumped all this data into an AutoML job and clicked go...and it failed miserably. Then I started reading the documentation. I find lots of documentation talking about setting up experiments, but very little concerning the exact structure of the data. It looks like my tabular data needs to have EVERY parameter in each row? So instead of a Name column, I'd need a TreaureChestBubblesValue column, a WaterTempValues column, a FilterPumpRunningValues, etc.<\/p>\n<pre><code>TimeStamp TreaureChestBubblesValue WaterTempValues ... FilterPumpRunningValues\n(time)    2.8                      67                  0\n(time)    5                        67                  0\n(time)    5                        66                  0\n(time)    8.4                      66                  1\n(time)    2.8                      67                  0\n<\/code><\/pre>\n<p>Does that sound correct? Or does the structure of the data not matter for AutoML so long as its tabular?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Quertion about the Azure Designer save model",
        "Question_created_time":1647239817743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/770634\/quertion-about-the-azure-designer-save-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182598-picture1.png?platform=QnA\" alt=\"182598-picture1.png\" \/>    <\/p>\n<p>Hello guys. I have a question about how to save the model  as a file after I trained model(like model.pkl)??Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Referencing Python Dependency files in scoring file",
        "Question_created_time":1638888910963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/654894\/referencing-python-dependency-files-in-scoring-fil",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm intending to add some python files in the dependencies in the screenshot below. How do I reference them in my scoring.py file?    <\/p>\n<p>i.e. if the dependency file is called main.py, i'd like to import a python function from main.py - along the lines of the below:    <br \/>\n&quot;import main&quot;     <\/p>\n<p>in my scoring.py file. Is this possible?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/155653-image.png?platform=QnA\" alt=\"155653-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML and Data exfiltration prevention",
        "Question_created_time":1677415689026,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184373\/azure-ml-and-data-exfiltration-prevention",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to understand how DEP works in ML.<\/p>\n<p>The Microsoft recommended architecture states that I must use a service endpoint along with a service endpoint policy to prevent ML compute subnets from gaining access to non-white listed storage accounts (<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-isolation-planning#recommended-architecture-with-data-exfiltration-prevention<\/a>)<\/p>\n<p>Some other examples I found on the web don't use service endpoints and instead prefer private endpoints for storage accounts. Does using PEs alone prevent data exfiltration? I'm not sure, because from what I've seen so far, it's possible to add any storage account as a datastore through the ML workspace as long as you have the appropriate access rights for the storage account.<\/p>\n<p>So I'm a bit confused and would appreciate if someone could shed some light on this.<\/p>",
        "Question_closed_time":1677483032160,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=c7bbbc2c-bba8-4500-a3a8-df7a87f8e72a\">Plodie<\/a> Thanks, using private endpoints alone may not prevent data exfiltration, but it can reduce the attack surface and the chances of data exfiltration. It is recommended to use a combination of Azure Virtual Network, Azure Private Link, and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/governance\/policy\/overview\">Azure Policy<\/a> to secure your Azure Machine Learning resources.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to use compute cluster in Azure ML",
        "Question_created_time":1677812348346,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1186105\/unable-to-use-compute-cluster-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Keep getting below error whereas on my free subscription I can see I have a quota of 4 vCPUs.<\/p>\n<p><strong>Failed<\/strong><\/p>\n<p>The specified subscription has a total vCPU quota of 0 and cannot accomodate for at least 1 requested managed compute node which maps to 4 vCPUs. Talk to your Subscription Admin or refer to <a href=\"https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-manage-quotas#request-quota-increases\">https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-manage-quotas#request-quota-increases<\/a> to increase the total quota<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML studio Roles\/Permissions issue",
        "Question_created_time":1677773626496,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185943\/ml-studio-roles-permissions-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am a network admin and know very little about Machine Learning<\/p>\n<p>We setup a private ML studio workspace for our user who is assigned the Owner role to the resource group the workspace uses.<\/p>\n<p>First we had issue with creating compute and user had to be assigned some network join permissions at the Vnet, as he could not even get a list of subnets. I could not find any ML role at the Vnet level that needs to be assigned.<\/p>\n<p>After assigning those permissions, user can create compute but not able to click terminal as all the applications are greyed out. That may be because compute is not assigned to me.<\/p>\n<p>I created a test compute myself. and even added a dns entry pointing to compute instance as we have custom dns, terminal still does not open.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/c03305a2-59dc-4c88-9454-fe171d86a1c5?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>What all permissions that we need to assign user and at what resource so they can use ML studio without our intervention.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1677816721020,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=b845915b-4001-0003-0000-000000000000\">@R.T  <\/a><\/p>\n<p>Thanks for reaching out to us, I understand you are building your compute within your VNET for your team. There are two roles related to VNET you may want to add, could you please take a look and have a try? Please let me know if below roles are still not working and we can discuss the next step.<\/p>\n<p>To deploy your compute resources inside a VNet, you need to explicitly have permissions for the following actions:<\/p>\n<ul>\n<li> <code>Microsoft.Network\/virtualNetworks\/*\/read<\/code> on the VNet resources.<\/li>\n<li> <code>Microsoft.Network\/virtualNetworks\/subnets\/join\/action<\/code> on the subnet resource.   For more information on Azure RBAC with networking, see the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/role-based-access-control\/built-in-roles#networking\">Networking built-in roles<\/a>.<\/li>\n<\/ul>\n<p>Since you ask all relative permissions, I want to share some common Common scenarios for roles\/permissions management like below screenshot-<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dbf3883e-5d1b-4294-88b1-f31f79efd7a5?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>And also some examples of custom role for different scenarios like below screenshot- <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#example-custom-roles\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#example-custom-roles<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/fd4691a6-36f5-4eb8-ba40-f58460a1efd4?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Please let me know if you need further help.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Read-only file system error in AzureML studio - Azure ML SDK2",
        "Question_created_time":1677772230963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185934\/read-only-file-system-error-in-azureml-studio-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm having an issue while using Azure Machine Learning studio with a very simple operation:<\/p>\n<p>Write a JSON file to the Datastore (Azure Data Lake V2).<\/p>\n<p>I had a pipeline in the past using SDK1 and everything worked, we are now moving to sdk2 and we aren't able to write a json file in a Datastore we are getting the following error:<\/p>\n<pre><code>OSError: [Errno 30] Read-only file system: '\/mnt\/azureml\/cr\/j\/8bf7af1d0623404aa72957489926b032\/cap\/data-capability\/wd\/INPUT_source_data\/test.json'\n<\/code><\/pre>\n<p>I checked my access rights:<\/p>\n<ul>\n<li> AzureML workspace: Owner &amp; Contributor<\/li>\n<li> Azure Storage account: Storage Storage Contributor<\/li>\n<\/ul>\n<p>We are using a custom environment:<\/p>\n<ul>\n<li> image=&quot;mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu22.04:latest&quot;<\/li>\n<\/ul>\n<p>with the conda file:<\/p>\n<pre><code class=\"lang-yaml\">%%writefile {dependencies_dir}\/conda.yml\nname: hespreproc-env-testcf1\nchannels:\nconda-forge\ndependencies:\npython=3.10\nnumpy=1.24.1\npandas=1.5.2\npip=22.3.1\npip:\nazure-storage-blob\nazure-identity\npyproj==3.4.1\nmlflow==1.26.1\nazureml-mlflow==1.42.0\n<\/code><\/pre>\n<p>The datalake has no access policy defined.<\/p>\n<p>I am not sure what else I can try to solve this issue.<\/p>\n<p>Kind regards,  <br \/>\nCarla Fiadeiro<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning compute local",
        "Question_created_time":1669634912270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1106844\/azure-machine-learning-compute-local",
        "Question_score_count":3,
        "Question_answer_count":6,
        "Question_comment_count":3,
        "Question_body":"<p>Hello all, I have followed the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day<\/a> tutorial with successful result. Now, instead of using the compute cluster, i would like to use the resources of my local computer to run the job. I change the compute option to 'local' in the command function, but throws me an error: JobException: Failed to read in local executable job. Do i need additional configuration? Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure CLI ML extension v2 - az ml environment commands to find image build status",
        "Question_created_time":1675415670023,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1167353\/azure-cli-ml-extension-v2-az-ml-environment-comman",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm constructing a CI\/CD pipeline using the Azure ML v2 commands and using the following to create a custom environment ready to submit a deployment for a batch endpoint<\/p>\n<p><code>az ml environment create --name neiltestcustomenv --resource-group myrg --workspace-name myamlworkspace --build-context .\\batch --dockerfile-path Dockerfile<\/code><\/p>\n<p>When the command is issued and submitted to AML to build - the <strong>az ml environment create<\/strong> command instantly completes and doesn't wait for the build to complete<\/p>\n<p>How do I enumerate programmatically to find out the status of the environment build please? - it starts in <em><strong>Running<\/strong><\/em> state and then to <em><strong>Succeeded<\/strong><\/em> (or other error states)<\/p>\n<p>I've tried <strong>az ml environment list<\/strong> and <strong>az ml environment show<\/strong> commands - but I cannot find this &quot;<strong>Environment image build status<\/strong>&quot; field (screenshot) - this is required to allow pipelines to work<\/p>\n<p>Thanks<\/p>\n<p>(I've posted the screenshot image here as in-line image adding here doesn't appear to be working right now)<\/p>\n<p><a href=\"https:\/\/i.postimg.cc\/1RjJT4TS\/Capture.png\">https:\/\/i.postimg.cc\/1RjJT4TS\/Capture.png<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/99df77cc-e0d0-4b69-b7c7-8fa38167e0f1?platform=QnA\" alt=\"Capture\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to get data from ADLS after changing the Client Secret",
        "Question_created_time":1677728012643,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185676\/unable-to-get-data-from-adls-after-changing-the-cl",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi<\/p>\n<p>I have AML Workspace connected to ADLS through registered dataset in AML. Last week, secrets have been updated for the Service Principal. So we have updated the secrets in Data Assest in AML Workspace through <strong>Update Authentication option.<\/strong> But now the python code fails with Request is not authorized to access. Not sure what else needs to be done. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Re-trained the model with new observations",
        "Question_created_time":1675399434096,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1167295\/re-trained-the-model-with-new-observations",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, <\/p>\n<p>I would like to know how to re-train his model with new data.<\/p>\n<p>I have an Iris dataset where I have set aside a label among the three. I created a Designer pipeline, then a inference pipeline and i deploy a service. How can i retrain the model with label data set aside from the endpoint (retrain the model from the client) ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning sdk v2 release plan",
        "Question_created_time":1658322711003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/934478\/azure-machine-learning-sdk-v2-release-plan",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I have seen some questions in this forum saying v2 is in preview, but some functions are there already. Can you share the release plan?<\/p>",
        "Question_closed_time":1658348954517,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a><\/p>\n<p>SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews. <a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/legal\/preview-supplemental-terms\/\">https:\/\/azure.microsoft.com\/en-us\/support\/legal\/preview-supplemental-terms\/<\/a><\/p>\n<p>Some of the functions is still in private preview of SDK v2, so at this time, we are not recommending it for production, but you could try it for testing. We are working on bringing features to v2 step by step.<\/p>\n<p>Azure ML Python SDK v2 is an updated Python SDK package, which allows users to:<\/p>\n<ul>\n<li>\n<ul>\n<li> Submit training jobs<\/li>\n<\/ul>\n<\/li>\n<li> Manage data, models, environments<\/li>\n<li> Perform managed inferencing (real time and batch)<\/li>\n<li> Stitch together multiple tasks and production workflows using Azure ML pipelines<\/li>\n<li> The SDK v2 is on par with CLI v2 functionality and is consistent in how assets (nouns) and actions (verbs) are used between SDK and CLI. For example, to list an asset, the list action can be used in both CLI and SDK. The same list action can be used to list a compute, model, environment, and so on.<\/li>\n<li><\/li>\n<\/ul>\n<p>I hope this helps.<\/p>\n<p>Regards,  <br \/>\nYutong  <br \/>\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"deployment issue in Azure.",
        "Question_created_time":1631818774143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/555483\/deployment-issue-in-azure",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, I am a beginner in Azure ML. I am trying to deploy a machine learning model  (consisting of a  h5 file and a pickle file) in Azure. But when I call the web-service error is coming up.    <\/p>\n<pre><code> Pip subprocess error:  \n    ERROR: Could not find a version that satisfies the requirement pickle (from -r \/azureml-environment-setup\/condaenv.b2ewzkd8.requirements.txt (line 5)) (from versions: none)  \n<\/code><\/pre>\n<p>I am using Jupiter notebook with SDK 1.34, Python version 3.8.11 and pickle version 4. Can anyone help. Thank you.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting OSError: [Errno 30] Read-only file system",
        "Question_created_time":1624894187850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/454901\/getting-oserror-(errno-30)-read-only-file-system",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>I am new to AzureML, I am trying to run the pipeline using parallelRunSteps and pipeline is getting submitted successfully but while running the pipeline it is throwing an above error not sure what would be the root cause of it.<\/p>\n<p>The step I am following is<\/p>\n<ol>\n<li>  Creating the workspace if does not exists<\/li>\n<li>  Fetching the datastore by specifying the storage account and other details<\/li>\n<li>  Using the from file dataset<\/li>\n<li>  Registering the dataset<\/li>\n<li>  After registering fetching the dataset<\/li>\n<li>  Fetching\/Initialising Experiment<\/li>\n<li>  Fetching\/Initialising Environment<\/li>\n<li>  Adding Private wheel file to pip package<\/li>\n<li>  Registering the packages to conda dependencies<\/li>\n<li> Registering the Environment<\/li>\n<li> Fetching\/Initialising the Compute Target<\/li>\n<li> Initialising the ParallelRunConfig<\/li>\n<li> Initialising the PipelineData as output data<\/li>\n<li> Initialising the ParallelRunStep<\/li>\n<li> Fetching\/Initialising the Pipeline<\/li>\n<li> Submitting the Pipeline<\/li>\n<\/ol>\n<p>The above same technique I tried with different PythonScriptSteps instead of ParallelRunStep method.<\/p>\n<ol>\n<li>  Creating the workspace if does not exists<\/li>\n<li>  Fetching the datastore by specifying the storage account and other details<\/li>\n<li>  Tabular Dataset<\/li>\n<li>  setting dataset name input<\/li>\n<li>  Fetching the Experiment<\/li>\n<li>  Fetching\/Initialising the Experiment<\/li>\n<li>  Fetching\/Initialising the Environment<\/li>\n<li>  Adding Private wheel file to pip package<\/li>\n<li>  Registering the packages to conda dependencies<\/li>\n<li> Registering the Environment<\/li>\n<li> Fetching the ComputeTarget<\/li>\n<li> Initialising the PythonStepScript<\/li>\n<li> Initialising the Pipeline<\/li>\n<li> Submitting the Pipeline    With PythonStepScripts it is working fine. Not able to understand what mistake I am doing while running ParallelRunStep method.<\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Components disappear",
        "Question_created_time":1677510930330,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184712\/components-disappear",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I only have a few components. What\u2019s wrong with my workspace? I have removed all filters but not working. Can I get some guidance from it?<\/p>",
        "Question_closed_time":1677513365643,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d55db955-94bc-459c-9988-f19bdf6adaee\">sona sathe<\/a>, <\/p>\n<p>Thanks you for reaching out to us here. I just did some researches and I found there is a reason may cause your issue. Could you please confirm if you are in the classic prebuild pipeline so that you have the component you want? If you are not, please try the Classic prebuilt pipeline. <\/p>\n<p>If you are in but you can not  find the component you want, please share the name to me and the screenshot, I will forward it to product team. <\/p>\n<p>I hope this helps! <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dfae8944-0259-492d-bd74-d6393214c5c9?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"VS-Code unable to connect to AML Instance",
        "Question_created_time":1655366375100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/891682\/vs-code-unable-to-connect-to-aml-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi     <\/p>\n<p>I have a compute instance on AML Studio. I downloaded the VS Code and trying to connect to compute instance . But it shows error &quot;Failed to connect to the remote extension host server (Error: WebSocket close with status code 1006)&quot; . AML Storage is Public Access. I am able to start the Compute instance but connect is not happening. Any workaround or solution?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211984-image.png?platform=QnA\" alt=\"211984-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there named entity recognition model in designer?",
        "Question_created_time":1676600100276,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181595\/is-there-named-entity-recognition-model-in-designe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>There was a named entity recognition model in ML studio. But I can't find it in the ML service designer. I wonder if this model is still in the designer? If yes, how I can find it? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Managed Identity for Compute Instance",
        "Question_created_time":1637143820660,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/630520\/azure-ml-managed-identity-for-compute-instance",
        "Question_score_count":3,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We need to connect Azure Data Lake Storage Gen2 to Azure Machine Learning by means of a datastore. For security reasons we do not want to provide the credential-based authentication credentials (service principal or SAS token). Instead we want to connect with identity based access.  <\/p>\n<p>The problem we face is that we are not able to assign a managed identity to a compute instance, so we can connect from notebooks to the Data Lake. In the documentation is explained how to assign a managed identity to a cluster, but we need the same for the compute instance, as it is the only way to run commands directly from the notebook.  <\/p>\n<p>Is there a way to assign managed identity to an Azure Machine Learning Compute Instance? Otherwise, we would like to know the best approach to overcome this issue, considering that we do not want to introduce the credentials in the code.<\/p>",
        "Question_closed_time":1637157273153,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=cbcc7cd1-be1d-4352-9648-87343bfaafff\">@Nimbeo  <\/a> Thanks for the question. Currently It\u2019s not supported yet  to assign managed identity to an Azure Machine Learning Compute Instance, you\u2019d need to use credential-based access. We have forwarded to the product team to support in the near future.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How should I customize my own component and how should I use it.",
        "Question_created_time":1677550674846,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184883\/how-should-i-customize-my-own-component-and-how-sh",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello team, I see there is a custom component module in Designer. I am curious about it. Does it mean I can customize my own component? Any reference I can read?<\/p>\n<p>Can you let me know what is custom component and how to define it? <\/p>\n<p>It\u2019s known that designer has very less flexibility so we are always considering SDK. How could it help? <\/p>\n<p>Meanwhile I am very surprised by the new release, anywhere we should look for those releasing news? <\/p>",
        "Question_closed_time":1677573962083,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=0d974fba-0e6f-4b9f-a796-c7257f76884f\">kamala dey<\/a><\/p>\n<p>Thanks for reaching out to us. Yes, this helps. Designer supports two type of components, classic prebuilt components and <strong>custom components.<\/strong> These two types of components are not compatible.<\/p>\n<p>Classic prebuilt components provides prebuilt components majorly for data processing and traditional machine learning tasks like regression and classification. This type of component continues to be supported but will not have any new components added.<\/p>\n<p><strong>Custom components allow you to provide your own code as a component. It supports sharing across workspaces and seamless authoring across Studio, CLI, and SDK interfaces.<\/strong><\/p>\n<p>To build pipeline using components in UI, you need to register components to your workspace first. You can use CLI or SDK to register components to your workspace, so that you can share and reuse the component within the workspace. Registered components support automatic versioning so you can update the component but assure that pipelines that require an older version will continue to work.<\/p>\n<p>In the example below take using CLI for example. If you want to learn more about how to build a component, see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-cli\">Create and run pipelines using components with CLI<\/a>.<\/p>\n<ol>\n<li> From the <code>cli\/jobs\/pipelines-with-components\/basics<\/code> directory of the <a href=\"https:\/\/github.com\/Azure\/azureml-examples\"><code>azureml-examples<\/code> repository<\/a>, navigate to the <code>1b_e2e_registered_components<\/code> subdirectory.<\/li>\n<li> Register the components to Azure Machine Learning workspace using following commands. Learn more about <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-component\">ML components<\/a>.\n    CLICopy<\/li>\n<\/ol>\n<pre><code>    az ml component create --file train.yml\naz ml component create --file score.yml\naz ml component create --file eval.yml\n    ```\n    \n    \n1. After register component successfully, you can see your component in the studio UI.\n    \n[![Screenshot showing registered component in component page.](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/media\/how-to-create-component-pipelines-ui\/component-page.png)\n\n](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/media\/how-to-create-component-pipelines-ui\/component-page.png#lightbox)Please refer to this guidance for how to leverage your custom components - [https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-ui#create-pipeline-using-registered-component](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-ui#create-pipeline-using-registered-component)\n\nCurrently registered components and the designer built-in components cannot be used together.\n\n\nI hope this helps, please have a try and let me know if you have any questions. \n\nRegards,\n\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.\n\n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Service - Working in Postman but not in HTML, Javascript",
        "Question_created_time":1676792060326,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182084\/azure-machine-learning-service-working-in-postman",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I created an Azure Machine Learning Service, an Azure Static Web App, and an Azure API Management service to handle the Rest Endpoint of the Azure ML Service.<\/p>\n<p>Everything works fine in Postman but it will not work in HTML and Javascript in my Azure Static Web App.<\/p>\n<p>Here is what it looks like in Postman:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/bb7932b0-b10b-45b0-9459-3e5791988882?platform=QnA\" alt=\"postman\" \/><\/p>\n<p>Here is what my HTML looks like. As you can see in my HTML code, I displayed the JSON data to be sent along with the Post. I also showed the error message at the bottom:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9d91c660-7161-4c99-b284-f4abfc33b079?platform=QnA\" alt=\"html\" \/><\/p>\n<p>In both instances, I sent along with the header the subscription key.<\/p>\n<p>Here is my javascript<\/p>\n<pre><code class=\"lang-javascript\">\n&lt;script&gt;\n    const form = document.querySelector('#agriculture-form');\n    form.addEventListener('submit', (event) =&gt; {\n        event.preventDefault();\n\n        const areaHarvest = parseFloat(document.querySelector('#area-harvest').value);\n        const farmGatePrice = parseFloat(document.querySelector('#farm-gate-price').value);\n        const volumeOfImport = parseFloat(document.querySelector('#volume-of-import').value);\n        const lowTemp = parseFloat(document.querySelector('#low-temp').value);\n        const averageTemp = parseFloat(document.querySelector('#average-temp').value);\n        const highTemp = parseFloat(document.querySelector('#high-temp').value);\n        const precipitationMm = parseFloat(document.querySelector('#precipitation-mm').value);\n        const precipitationDays = parseFloat(document.querySelector('#precipitation-days').value);\n        const tropicalCyclones = parseFloat(document.querySelector('#tropical-cyclones').value);\n        const volumeProductionGuess = 0;\n\n        const data = {\n            &quot;Area_Harvested&quot;: areaHarvest,\n            &quot;FarmGatePricePHPPSA&quot;: farmGatePrice,\n            &quot;Volume_of_Import&quot;: volumeOfImport,\n            &quot;temp_low&quot;: lowTemp,\n            &quot;temp_ave&quot;: averageTemp,\n            &quot;temp_high&quot;: highTemp,\n            &quot;precipitation_mm&quot;: precipitationMm,\n            &quot;precipitation_days&quot;: precipitationDays,\n            &quot;tropical_cyclone&quot;: tropicalCyclones,\n            &quot;Volume_of_Production&quot;: volumeProductionGuess\n        };\n      \n        const formattedData = [data]; \n        console.log('formatted data:', formattedData);\n        const testData = JSON.stringify(formattedData);\n        console.log('test data:', testData);\n        document.getElementById(&quot;demo&quot;).innerHTML = testData;\n          \n        fetch('http:\/\/ziggyapimanagementservice.azure-api.net\/score', {\n              method: 'POST',\n              headers: {\n                'Content-Type': 'application\/json',\n                'Ocp-Apim-Subscription-Key': 'cd529cc993494fdfb1530eaf04ae63dc'\n              },\n        body: testData\n        })\n            .then(response =&gt; response.json())\n            .then(data =&gt; console.log(data))\n            .catch(error =&gt; { \n             document.getElementById(&quot;error&quot;).innerHTML = error.message;\n             console.error(error.message)\n          });\n    });\n&lt;\/script&gt;\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning exit code 134",
        "Question_created_time":1677234865300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1183958\/azure-machine-learning-exit-code-134",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an Azure ML job running which has a big training step code. This runs fine on the Azure ML without any error, but still it produces exit code 134 and fails the execution. As I understand exit code 134 relates to <strong>SIGABRT .<\/strong> But, also possible that it runs out of memory. I have not checked the memory yet, but will check this out. Still, does anyone have a clearer idea about this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - running code in curated environement gives ModuleNotFoundError: No module named 'azure.ai'",
        "Question_created_time":1677361660280,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184301\/azure-machine-learning-running-code-in-curated-env",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>The job crashes while trying to execute  <br \/>\n<code>from azure.ai.ml import MLClient<\/code><\/p>\n<p>in the curated environment AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:1<\/p>\n<p>I am getting: <\/p>\n<pre><code>    from azure.ai.ml import MLClient\nModuleNotFoundError: No module named 'azure.ai'\n<\/code><\/pre>\n<p>How can I fix it? There is installation of azure-ai-ml library in this environment so I don't understand why it crashed.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"While running an Azure ML Experiement, I get \"File Not found\" error when attempting to find ODBC driver for python pyodbc.connect command",
        "Question_created_time":1594589100353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/45912\/while-running-an-azure-ml-experiement-i-get-file-n",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello:  <\/p>\n<p>This is the python command.  It works fine in my local Windows environment and I can connect to the remote Azure SQL DB that I want to connect to.  <\/p>\n<p>sql_conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server}; ...  <\/p>\n<p>However, when I run my az ml submit-run CLI command in order to run an experiment in Azure Machine Learning, I get this error.:  <\/p>\n<p><strong>[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 17 for SQL Server' : file not found<\/strong>  <\/p>\n<p>So, it seems that AML is running its containers in Linux.  Ok....I have no problem with that, but how do I configure either my <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning cost",
        "Question_created_time":1607408839580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/190053\/azure-machine-learning-cost",
        "Question_score_count":1,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>I am new to Azure Machine Learning, I have some questions related to cost<\/p>\n<p>1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)<\/p>\n<p>2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/46057-azure-ml-cost.png?platform=QnA\" alt=\"46057-azure-ml-cost.png\" \/><\/p>\n<p>3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?<\/p>\n<p>4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?<\/p>\n<p>5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)<\/p>",
        "Question_closed_time":1607414554743,
        "Answer_score_count":2.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c0af539e-5b19-433b-85a1-2ca81772cd40\">@Srinivasan G  <\/a> Here are the charges that you could incur for the above setup:<\/p>\n<blockquote>\n<p>1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)<\/p>\n<\/blockquote>\n<p>For Azure Machine learning the <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/\">charges<\/a> of ML services are nil for enterprise edition workspaces. Currently all the workspaces are using enterprise edition and if there are any basic edition workspaces they can be migrated with no down time. All other charges while using Azure ML workspace depends on the compute used and the setup of the compute. If they are enabled in a vnet then you could incur data charges according to vnet's <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/virtual-network\/\">pricing<\/a>.<\/p>\n<blockquote>\n<p>2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?<\/p>\n<\/blockquote>\n<p>The charges incurred for LB and bandwidth could be based on your setup and how the compute was setup to run the experiments. If you have also setup your designer to use virtual network then there could be charges on how the compute was setup with respect to the region. More details of the setup of workspace with private networks are detailed <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview\">here<\/a>. For the breakup of charges mentioned above you can raise a support request through the azure portal for billing which does not require any support plan to raise a ticket from the Help+Support tab on Azure portal.<\/p>\n<blockquote>\n<p>3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?<\/p>\n<\/blockquote>\n<p>Once you are able to confirm if your vnet connection is successful you can get the data from Azure SQL database using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/import-data\">import data<\/a> module from Azure ML designer. If you are planning to setup your own SQL server then this functionality is not supported with the available options, you might need to use the option URL via HTTP to get the required data in your experiments.<\/p>\n<p>If you are attaching storage from different region than workspace region, it can result in higher latency and additional network usage costs.<\/p>\n<blockquote>\n<p>4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?<\/p>\n<\/blockquote>\n<p>The option to shutdown compute instance automatically that is not in use is not available currently. You can stop the compute instances that are not required, for compute clusters you can set the minimum no. of nodes to 0 to ensure no compute is running when not in use.<\/p>\n<blockquote>\n<p>5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)<\/p>\n<\/blockquote>\n<p>Azure ML learning enterprise edition workspaces do not have a surcharge i.e charges for using Azure ML. If there are any associated compute or storage or virtual networks there could be charges if used.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I get Power BI to see Azure ML models",
        "Question_created_time":1607979456767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/198154\/how-do-i-get-power-bi-to-see-azure-ml-models",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm following these tutorials:    <br \/>\n<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-designer-model<\/a>    <br \/>\n<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate?context=azure\/machine-learning\/context\/ml-context<\/a>    <\/p>\n<p>I've setup the pipelines &amp; endpoint. Attached is a screenshot of the endpoint.    <\/p>\n<p>For tutorial 2, on the Power BI Desktop, when I click Transform data to open the Power Query Editor, then click Azure Machine Learning, I originally got the prompt to login with my email (which I used my personal gmail for, the one that owns the Azure ML workspace). I keep seeing that no models are available, but I've followed the steps to tutorials &amp; expect since the endpoint was successfully deployed, I can see the model.    <\/p>\n<p>Can you help me understand what's missing please?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/48161-5.png?platform=QnA\" alt=\"48161-5.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/48152-image.png?platform=QnA\" alt=\"48152-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to pull docker image from Container Registry",
        "Question_created_time":1631798842910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/555024\/not-able-to-pull-docker-image-from-container-regis",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello community,     <br \/>\nI'm facing a problem, my ACR in my resource group was deleted and I couldn't create any instance. I created again and now I can create instances but i'm having problems to run the dataset profile. It's failing to pull the image docker.    <\/p>\n<p>This is the output    <\/p>\n<pre><code>AzureMLCompute job failed.  \nFailedPullingImage: Unable to pull docker image  \n\timageName: 19acd0cdf57549bcace363c924cf045b.azurecr.io\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f  \n\terror: Run docker command to pull public image failed with error: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.  \n.  \n\tReason: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.  \n  \n\tInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.  \n<\/code><\/pre>\n<p>The ML Studio has the following permissions on the ACR permissions    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132698-unbenannt.png?platform=QnA\" alt=\"132698-unbenannt.png\" \/>    <\/p>\n<p>The docker image appears in the repositories of the ACR    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132781-unbenannt2.png?platform=QnA\" alt=\"132781-unbenannt2.png\" \/>    <\/p>\n<p>Any hint how can i solve this problem?    <\/p>\n<p>Thanks in advance    <\/p>",
        "Question_closed_time":1631803071767,
        "Answer_score_count":3.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=5565f700-af3b-41a9-b47f-9b8a6276d8fd\">@Moresi, Marco  <\/a> Does this container registry have the admin account enabled? A requirement while creating a workspace with an <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace-cli?tabs=bringexistingresources1%2Cvnetpleconfigurationsv1cli#create-a-workspace\">existing container registry<\/a> is to have the admin account enabled.     <\/p>\n<p>If you have already enabled it then a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace-cli?tabs=bringexistingresources1%2Cvnetpleconfigurationsv1cli#sync-keys-for-dependent-resources\">re-sync of keys<\/a> might be required for your workspace.    <\/p>\n<pre><code>az ml workspace sync-keys -w &lt;workspace-name&gt; -g &lt;resource-group-name&gt;  \n<\/code><\/pre>\n<p>Deleting the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#deleting-the-azure-container-registry\">default container registry<\/a> used by the workspace can also cause the workspace to break.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Experiment stuck in Queued",
        "Question_created_time":1642636050810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/702171\/azure-ml-experiment-stuck-in-queued",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have only one experiment running, but it is stuck in queued. I see this happens to people a lot, but on one ever says how to fix it.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I got an error that the kernel could not be found in Azure ml.",
        "Question_created_time":1643096138537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/708659\/i-got-an-error-that-the-kernel-could-not-be-found",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>When I was using a compute instance with azure ml, I got the following message:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/168157-kernelerror.png?platform=QnA\" alt=\"168157-kernelerror.png\" \/>    <br \/>\nThe kernel for python 3.8 azure ml was not available.    <br \/>\nPlease tell me the cause and solution.    <br \/>\nThe instance I was using is:    <br \/>\nVirtual machine size    <br \/>\nStandard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use custom environment defined in the custom environments tab in Azure Machine Learning Studio.",
        "Question_created_time":1646779156963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/764339\/how-to-use-custom-environment-defined-in-the-custo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure Machine Learning Studio, in the Environments section's &quot;Custom environments&quot; tab, I defined a custom environment. I have done this once with a Conda yaml file, and once with a requirements.txt file, eg filling out this form as described here: <a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-environments-in-studio<\/a>     <\/p>\n<p>I can see that the environments have been created but I have no idea how to use them.    <\/p>\n<p>I have tried using this code within an Azure ML Studio notebook, where the new environment I defined is called &quot;my_new_env&quot;:    <\/p>\n<pre><code>from azureml.core import Workspace, Environment  \nws = Workspace.from_config()  \nenv = Environment.get(workspace=ws, name=&quot;my_new_env&quot;)  \n<\/code><\/pre>\n<p>I also tried this within an Azure ML Studio notebook to see if I could define an environment without doing it in the environments menu.    <\/p>\n<pre><code>from azureml.core.environment import Environment  \nmy_new_env = Environment.from_conda_specification(name = &quot;myenv&quot;, file_path = environment.yml)  \n<\/code><\/pre>\n<p>Both execute without any warnings or errors, but I'm not sure they are running, or indeed what I have done.    <\/p>\n<p>Having run either of these two blocks of code, when I try to select a new environment in the Azure ML Studio notebook's drop down menu:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/181193-image.png?platform=QnA\" alt=\"181193-image.png\" \/>    <\/p>\n<p>There is no evidence of my new environments.    <\/p>\n<p>I'm new to Azure ML Studio. What I want to do is create a new Python virtual environment. Am I getting confused between virtual Python environments and some other more general type of environments? If I wanted to create my own stable Python virtual environment within Azure ML to use in notebooks that was not tied to a specific compute instance, how would I do it?    <\/p>\n<p>Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning service was configured with a Load Balancer & Premium SSD Managed Disks (Cost Issue)",
        "Question_created_time":1651101671863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829249\/azure-machine-learning-service-was-configured-with",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I create an Azure Machine Learning service and it was configured with a Load Balancer &amp; Premium SSD Managed Disks.  Is this configuration correct?   <\/p>\n<p>I chose a Public Endpoint for the ML service.  Is this the reason for the Load Balancer?  <\/p>\n<p>Is there a way for me to change the &quot;Premium SSD Managed Disks&quot; to a lower-cost storage?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot Use the ML CLI v2",
        "Question_created_time":1658311750460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/934301\/cannot-use-the-ml-cli-v2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>After installing the ML CLI v2, following the steps here: <a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli?tabs=public<\/a>,  <br \/>\nI get the following error. For instance, when calling: az ml -h<\/p>\n<p>cannot import name 'ARMChallengeAuthenticationPolicy' from 'azure.mgmt.core.policies' ([FILEPATH]__init__.pyc)  <br \/>\n'ml' is misspelled or not recognized by the system.<\/p>\n<p>{  <br \/>\n&quot;azure-cli&quot;: &quot;2.23.0&quot;,  <br \/>\n&quot;azure-cli-core&quot;: &quot;2.23.0&quot;,  <br \/>\n&quot;azure-cli-telemetry&quot;: &quot;1.0.6&quot;,  <br \/>\n&quot;extensions&quot;: {  <br \/>\n&quot;ml&quot;: &quot;2.6.1&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endpoint \"predict-auto-price\" deployment failed",
        "Question_created_time":1661430065143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981735\/endpoint-predict-auto-price-deployment-failed",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I'm following the &quot;Exercise - Explore regression with Azure Machine Learning designer&quot;    <\/p>\n<p>I've redone this exercise twice following all the instructions perfectly!    <\/p>\n<p>On the &quot;Deploy a service&quot; section in the exercise, I've tried it over 7 times:    <\/p>\n<p><em>4. In the configuration screen, select Deploy a new real-time endpoint, using the following settings:<\/em>    <\/p>\n<p><em>Name: predict-auto-price    <br \/>\nDescription: Auto price regression    <br \/>\nCompute type: Azure Container Instance<\/em>    <\/p>\n<p><strong>It always fails with &quot;Endpoint &quot;predict-auto-price&quot; deployment failed&quot;<\/strong>    <\/p>\n<p>And nothing comes up in the Deployment Logs.    <br \/>\n<strong>Please help! I'm out of idea's<\/strong>    <\/p>\n<p>&quot;<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234916-untitled1.png?platform=QnA\" alt=\"234916-untitled1.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234799-untitled2.png?platform=QnA\" alt=\"234799-untitled2.png\" \/>&quot;    <\/p>",
        "Question_closed_time":1661512226997,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7d0191ce-e12e-41a0-9e2c-30b454b8736b\">@Mervyn King  <\/a> Do you see any new jobs added on the jobs tab when your deployment fails? Usually, there is a drop down that loads on the Deployment logs tab to select the Deployment. But, I dont see that on your page. It looks like the page might not have loaded completely. You can also report the issue using the smiley icon on the top right corner with a screen shot of this page.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"real-time inference pipeline failed to deploy for some unknown error and unable to view the logs",
        "Question_created_time":1662748337977,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1001503\/real-time-inference-pipeline-failed-to-deploy-for",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>After submitting a successful inference pipeline, I attempted to deploy the model to a container instance. However, it failed and to make it worse I can't see the logs due to forbidden permissions error even though I am <strong>sole owner<\/strong> of resource group &amp; instance. To put the nail on the coffin, I also can't view any related container instances inside Azure Portal...only the endpoints in ML studio.     <\/p>\n<p>Here's the permissions error:    <\/p>\n<pre><code>![{  \n  &quot;error&quot;: {  \n    &quot;code&quot;: &quot;Forbidden&quot;,  \n    &quot;message&quot;: &quot;Forbidden&quot;,  \n    &quot;details&quot;: [  \n      {  \n        &quot;code&quot;: &quot;AuthorizationFailed&quot;,  \n        &quot;message&quot;: &quot;The client 'df9ec36b-a97d-4c60-a6fe-91048565a571' with object id 'df9ec36b-a97d-4c60-a6fe-91048565a571' does not have authorization to perform action 'Microsoft.ContainerInstance\/containerGroups\/containers\/logs\/read' over scope '\/subscriptions\/7d36b75b-8fd4-4ef9-92fe-69f951afa25d\/resourceGroups\/playground\/providers\/Microsoft.ContainerInstance\/containerGroups\/playground-pipe-ommOzSbRhUSx8qiJGQ4HiA\/containers\/playground-pipe' or the scope is invalid. If access was recently granted, please refresh your credentials.&quot;  \n      }  \n    ]  \n  },  \n  &quot;correlation&quot;: {  \n    &quot;RequestId&quot;: &quot;745ad382-74c0-4c67-8853-053807cd6336&quot;  \n  }  \n}][1]  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cost of Batch Endpoint in Azure Machine Learning",
        "Question_created_time":1677027899073,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182960\/cost-of-batch-endpoint-in-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, <\/p>\n<p>I know that Online Endpoint is up and running for 24\/7 and the cost is charged since the start of deployment. For Batch Endpoint Deployment, Is it having the same billing style with Online Endpoint ? Or Will Azure only charge me based on the usage of compute during the completion of job under respective deployment? Hope someone can clarify me on this :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to utilize AutoML in an ML Designer pipeline?",
        "Question_created_time":1677273345036,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184152\/how-to-utilize-automl-in-an-ml-designer-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Currently, I have an ML pipeline built in Azure ML Designer that effectively does the following basic steps:<\/p>\n<ol>\n<li> Trains a model across a full quantitative range of [0.0, 7.0] from a full baseline dataset.<\/li>\n<li> Scores model to generate predictions appended to actuals in a scored dataset.<\/li>\n<li> Passes the scored dataset to R-scripts that row filter the scored dataset based on criteria that reduce the full quantitative range of [0.0, 7.0] into 3 segmented quantitative ranges of range 1 = [0,1.0], range 2 = (1.0, 3.3], and range 3 = (3.3, 7.0].<\/li>\n<li> Trains 1 new model from each of 3 filtered datasets from step 3 across the corresponding segmented range using same predictors from step 1 <strong>plus 1 new predictor<\/strong>: the predictions generated in step 2.<\/li>\n<li> Scores each model from step 4 to generate predictions appended to actuals in scored datasets.<\/li>\n<\/ol>\n<p>The idea here is that the predictions generated in step 2 are actually treated as an estimate, which is then used as an engineered feature in subsequent trainings to refine the predictions. I've provided the schematic of this pipeline in <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/c3e0c968-db7a-493e-91f3-b13c5bcbf7e5?platform=QnA\">Designer.PNG<\/a>.<\/p>\n<p>Now, before I built this in Designer, I used Azure's AutoML service to do all this manually as sort of a POC that this idea would work. And those results were very promising. But passing, filtering, splitting, etc. all the data is difficult to do manually and I would like a pipeline to do it for me.<\/p>\n<p>The problem? Ideally, I need ensemble models for each of the 4 trained models and I'm not seeing a way to get ensemble models out of Azure ML Designer. <\/p>\n<p>Is there a way to utilize AutoML within designer? Or is there a way to eliminate the regression\/train components from my Designer pipeline and replace with an already trained model stored in our workspace?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can Azure Computer Vision or Cognative Services do \"instance segmentation?",
        "Question_created_time":1676856259813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182210\/can-azure-computer-vision-or-cognative-services-do",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all,<\/p>\n<p>I'm relativley new to Azure Computer Vision and Machine Learning. Is it possible to do &quot;Instance Segmentation&quot; in Azure somehow?<\/p>\n<p>From what I have found Azure Computer Vision can only do &quot;Classification&quot; and &quot;Object Detection&quot;<\/p>\n<p>(My understanding of Instance Segmentation is more advanced in that it is able to output: Presence, Location, Count, Size, and Shape from an analysed image. Classificaiton and Object Detection can only do Presence, Location, Count)<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't get predicted probabilities with AutoML deployment",
        "Question_created_time":1677141900596,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1183524\/cant-get-predicted-probabilities-with-automl-deplo",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I have a AutoML model deployed with a real time endpoint and have been using a modified version of the python template from the 'Consume' tab to fetch predictions.<\/p>\n<p>I recently trained a new model and set up a deployment for it. I can get the predicted values but not their probabilities. Previously, passing the Global Parameter method: &quot;predict_proba&quot; worked for me, but now it returns predicted values instead. In fact, it seems Global Parameters isn't working at all (I can type gibberish and its ignored).<\/p>\n<p>I noticed MS had made some changes ('Inputs' variable is now  'input_data') as my original script no longer worked. So now I'm wondering if there is a new method for getting probabilities? I can't seem to find anything related to these updates in the documentation or release notes.<\/p>\n<p>Please let me know if I've missed any details that would be useful. Any advice, would be appreciated.<\/p>\n<p>Here is my code:<\/p>\n<pre><code>inputs_template = {\n  &quot;input_data&quot;: {\n    &quot;data&quot;: []\n  },\n  &quot;GlobalParameters&quot;: {\n    &quot;method&quot;: &quot;predict_proba&quot;\n  }\n}\ninputs = inputs_template.copy()\ninputs[&quot;input_data&quot;][&quot;data&quot;] = rows\nbody = str.encode(json.dumps(inputs))\n\nurl = ''\n# Replace this with the primary\/secondary key or AMLToken for the endpoint\napi_key = ''\nif not api_key:\n    raise Exception(&quot;A key should be provided to invoke the endpoint&quot;)\n\n# The azureml-model-deployment header will force the request to go to a specific deployment.\n# Remove this header to have the request observe the endpoint traffic rules\nheaders = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'silver-dog-1' }\n\nreq = urllib.request.Request(url, body, headers)\n\ntry:\n    response = urllib.request.urlopen(req)\n\n    proba = response.read()\n    print(proba)\nexcept urllib.error.HTTPError as error:\n    print(&quot;The request failed with status code: &quot; + str(error.code))\n\n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    print(error.info())\n    print(error.read().decode(&quot;utf8&quot;, 'ignore'))\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment failed with error Service invocation failed.",
        "Question_created_time":1676956672070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182608\/experiment-failed-with-error-service-invocation-fa",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>There are no logs, since the experiment didn't start. I am using the same pipeline in a diff workspace and subscription, it working fine there. Can someone help to find the issue.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Batch Endpoint for AutoML Object Detection - How to set up?",
        "Question_created_time":1676515090393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181172\/batch-endpoint-for-automl-object-detection-how-to",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>Previously, I have worked with Managed Online Endpoint for AutoML Object Detection. The process is quite easy because most of it are automated. Then, I plan to change the endpoint mode from Online to Batch Endpoint. From the official documentation, it does not explain much in detail about Batch Endpoint for Computer Vision Object detection and I see the AutoML does not support much for batch endpoint. Can anyone guide me with some references or docs that can assist me to build Batch Endpoint for AutoML Object Detection? really appreciate for any help :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to determine which deep learning method was used by Azure AutoML in a classification task?",
        "Question_created_time":1676701708860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181937\/how-to-determine-which-deep-learning-method-was-us",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am a non-data scientist \/ clinical researcher using Azure AutoML to predict binary and multi-class classification using features from patient records. I have been able to run my experiments using the Azure ML Studio UI. Deep learning is enabled for all my experiments.<\/p>\n<p>Now, I have to write about the work I have done and have managed to understand how to report the scaling and normalisation used and ML algorithm selected when running AutoML.<\/p>\n<p>However, I cannot find anything on how the deep learning feature was applied. I have looked through the documentation and have searched online.<\/p>\n<p>I know that the deep learning used by Azure AutoML could be one of the following: <\/p>\n<ol>\n<li> Platt Scaling<\/li>\n<li> Isotonic Regression<\/li>\n<li> Temperature Scaling<\/li>\n<li> Bayesian Calibration<\/li>\n<li> Ensemble Calibration<\/li>\n<\/ol>\n<p>But I can't find out which one is being used on my dataset. =(<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Speech-to-text fails to work with MP3 input in Machine Learning studio - error 'SPXERR_GSTREAMER_NOT_FOUND_ERROR'",
        "Question_created_time":1676567428973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181474\/speech-to-text-fails-to-work-with-mp3-input-in-mac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, <\/p>\n<p>I try to use the speech-to-text API from within Azure Machine Learning Studio on an MP3 file.<\/p>\n<p>I installed GStreamer using the instructions for Ubuntu\/Debian on <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-use-codec-compressed-audio-input-streams?tabs=linux%2Cdebian%2Cjava-android%2Cterminal&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-use-codec-compressed-audio-input-streams?tabs=linux%2Cdebian%2Cjava-android%2Cterminal&amp;pivots=programming-language-python<\/a><\/p>\n<p>However, when I then try to run my code, he gives an error. I put my error log and my code block below.<\/p>\n<p>On stackoverflow I found a solution for Windows that had something to do with the Gstreamer version installed. Are the Ubuntu instructions on your site also referring to a wrong version or is this error related to something else I'm missing ?<\/p>\n<p>Could it eg. have something to do that I should also build an authentication token still too as explained on: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python<\/a>:<\/p>\n<blockquote>\n<p>resourceId = &quot;Your Resource ID&quot; \nregion = &quot;Your Region&quot; <\/p>\n<h1 id=\"you-need-to-include-the-aad-prefix-and-the--hash-separator-between-resource-id-and-aad-access-token-authorizationtoken--aad--resourceid----aadtokentoken-\">You need to include the &quot;aad#&quot; prefix and the &quot;#&quot; (hash) separator between resource ID and AAD access token. authorizationToken = &quot;aad#&quot; + resourceId + &quot;#&quot; + aadToken.token <\/h1>\n<p>speechConfig = speechsdk.SpeechConfig(auth_token=authorizationToken, region=region)<\/p>\n<\/blockquote>\n<p>before running:<\/p>\n<blockquote>\n<p>speech_config = speechsdk.SpeechConfig(subscription=key, region=regio)<\/p>\n<\/blockquote>\n<p><strong>Error log:<\/strong><\/p>\n<p>Input In [4], in pull_audio_input_stream_compressed_mp3(mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  1 def pull_audio_input_stream_compressed_mp3(mp3_file_path: str, taal, key, regio):\n\n  2     # Create a compressed format\n\n  3     compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n<\/code><\/pre>\n<p>----&gt; 4     result=compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  6     return result\n<\/code><\/pre>\n<p>Input In [3], in compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  6 speech_config.speech_recognition_language=taal\n\n  7 audio_config = speechsdk.audio.AudioConfig(stream=stream)\n<\/code><\/pre>\n<p>----&gt; 9 speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)<\/p>\n<pre><code> 11 done = False\n\n 13 def stop_cb(evt):\n<\/code><\/pre>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/speech.py:1004, in SpeechRecognizer.<strong>init<\/strong>(self, speech_config, audio_config, language, source_language_config, auto_detect_source_language_config)<\/p>\n<p>   1002 audio_config_handle = audio_config._handle if audio_config is not None else None<\/p>\n<p>   1003 if language is None and source_language_config is None and auto_detect_source_language_config is None:<\/p>\n<p>-&gt; 1004     _call_hr_fn(<\/p>\n<p>   1005         fn=_sdk_lib.recognizer_create_speech_recognizer_from_config,<\/p>\n<p>   1006         *[ctypes.byref(handle), speech_config._handle, audio_config_handle])<\/p>\n<p>   1007 elif language is not None:<\/p>\n<p>   1008     source_language_config = languageconfig.SourceLanguageConfig(language)<\/p>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:62, in _call_hr_fn(fn, *args)<\/p>\n<pre><code> 60 fn.restype = _spx_hr\n\n 61 hr = fn(*args) if len(args) &gt; 0 else fn()\n<\/code><\/pre>\n<p>---&gt; 62 _raise_if_failed(hr)<\/p>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:55, in _raise_if_failed(hr)<\/p>\n<pre><code> 53 def _raise_if_failed(hr: _spx_hr):\n\n 54     if hr != 0:\n<\/code><\/pre>\n<p>---&gt; 55         __try_get_error(_spx_handle(hr))<\/p>\n<pre><code> 56         raise RuntimeError(hr)\n<\/code><\/pre>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:50, in __try_get_error(error_handle)<\/p>\n<pre><code> 45 message = &quot;Exception with error code: %s%s&quot; % (\n\n 46     callstack if callstack is not None else &quot;&quot;,\n\n 47     what if what is not None else code\n\n 48 )\n\n 49 _sdk_lib.error_release(error_handle)\n<\/code><\/pre>\n<p>---&gt; 50 raise RuntimeError(message)<\/p>\n<p>RuntimeError: Exception with error code: <\/p>\n<p>[CALL STACK BEGIN]<\/p>\n<p>\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/libMicrosoft.CognitiveServices.Speech.core.so(+0x1638a5) [.....]<\/p>\n<p>...<\/p>\n<p>[CALL STACK END]<\/p>\n<p>Exception with an error code: 0x29 (SPXERR_GSTREAMER_NOT_FOUND_ERROR)<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code class=\"lang-python\">class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n   &lt;defined as on your page: \n\ndef compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio):\n    \n    callback = BinaryFileReaderCallback(mp3_file_path)\n    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n    \n    #speech authentication needed too still?\n    #https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python\n\n    speech_config = speechsdk.SpeechConfig(subscription=key, region=regio)\n    speech_config.speech_recognition_language=taal\n    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n\n    done = False\n\n    def stop_cb(evt):\n        &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot;\n        print('CLOSING on {}'.format(evt))\n        nonlocal done\n        done = True\n\n    # Connect callbacks to the events fired by the speech recognizer\n    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n    # stop continuous recognition on either session stopped or canceled events\n    speech_recognizer.session_stopped.connect(stop_cb)\n    speech_recognizer.canceled.connect(stop_cb)\n\n    # Start continuous speech recognition\n    speech_recognizer.start_continuous_recognition()\n    while not done:\n        time.sleep(.5)\n\n    speech_recognizer.stop_continuous_recognition()\n\n\ndef pull_audio_input_stream_compressed_mp3(mp3_file_path: str, taal, key, regio):\n    # Create a compressed format\n    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n    result=compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)\n    \n    return result\n\ntekst=pull_audio_input_stream_compressed_mp3(&quot;file1.mp3&quot;, &quot;fr-BE&quot;, &quot;&lt;my speech services key&gt;&quot;, &quot;&lt;my speech services region&gt;&quot;)\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Open AI support supportability",
        "Question_created_time":1677357950333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184290\/open-ai-support-supportability",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>hello azure, is there anywhere azure will post the plan of the supportability and the current status? I went through Open AI document but I found nothing helpful. How should we start to use it in Azure? Where we can get more details? What\u2019s the pricing? Can you provide some details to these questions?<\/p>",
        "Question_closed_time":1677360042060,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=4d395bc2-5cc4-4ca4-a2c9-4cb20730b092\">Starfall<\/a> <\/p>\n<p>Thanks for reaching out to us here, you need to check on Azure Open AI models document for the information you are looking for - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/openai\/concepts\/models#gpt-3-models-1\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/openai\/concepts\/models#gpt-3-models-1<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/89541da1-ce9d-443d-812c-16db4a698845?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Pricing - <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/cognitive-services\/openai-service\/\">https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/cognitive-services\/openai-service\/<\/a><\/p>\n<p>For quick start, please refer to this document - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/openai\/quickstart?pivots=programming-language-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/openai\/quickstart?pivots=programming-language-studio<\/a> <\/p>\n<p>Prerequisites<\/p>\n<ul>\n<li> An Azure subscription - <a href=\"https:\/\/azure.microsoft.com\/free\/cognitive-services\">Create one for free<\/a>.<\/li>\n<li> Access granted to Azure OpenAI in the desired Azure subscription.\n   Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at <a href=\"https:\/\/aka.ms\/oai\/access\">https:\/\/aka.ms\/oai\/access<\/a>. Open an issue on this repo to contact us if you have an issue.<\/li>\n<li> An Azure OpenAI resource with a model deployed. For more information about model deployment, see the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/openai\/how-to\/create-resource\">resource deployment guide<\/a>.<\/li>\n<\/ul>\n<p>I hope you can start smoothly, please let me know if you need more help.<\/p>\n<p>Regards,<\/p>\n<p>Yutong <\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Speech Recognition canceled: Error details: Runtime error: Failed to initialize platform (azure-c-shared)",
        "Question_created_time":1636465017697,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/620702\/speech-recognition-canceled-error-details-runtime",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":4,
        "Question_body":"<p>When I use the default Azure sample code to convert speech to text using the activated speech service,  it shows that &quot;<strong>Speech Recognition canceled: CancellationReason.Error<\/strong>&quot; , &quot;<strong>Error details: Runtime error: Failed to initialize platform (azure-c-shared)<\/strong>&quot; . The question is that the same code can work in my local machine, but will raise such error message in my Lab server machine, don't know if there are any settings required for network setup. But I have checked that my speech service is open for all network by default. Any idea about this issue? Thanks in advance!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I can't find the component as the document",
        "Question_created_time":1675183442570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165885\/i-cant-find-the-component-as-the-document",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hello experts, I am following the quickstart of Azure Machine Learning but unfortunetely, the component I am looking for is not available. Is there any subscription limitation for some of the components? Hoiw can I find it, any guidance is appreciated. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azure.ai'",
        "Question_created_time":1668204745757,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1086028\/modulenotfounderror-no-module-named-azure-ai",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I  am getting the following error message    <\/p>\n<p>ModuleNotFoundError: No module named 'azure.ai'    <\/p>\n<p>in Azure machine learning studio...when i try to run sample    azureml-in-a-day.ipynb<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ClusterIdentityNotFound when submitting experiment.",
        "Question_created_time":1633943984543,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/585373\/clusteridentitynotfound-when-submitting-experiment",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>When I'm submitting my experiment fom notebook, experiment is queing for a long time then I get as error:  <\/p>\n<p>AzureMLCompute job failed.  <br \/>\nClusterIdentityNotFound: Identity of the specified   <br \/>\nmanaged compute &lt;hidden cluster location&gt; is not found  <\/p>\n<p>I've updated all azure ml packages and restarted cluster, deleted, recreating, ... Nothing seems to be working.  <\/p>\n<p>What Should I do?<\/p>",
        "Question_closed_time":1633987970467,
        "Answer_score_count":2.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, are you by any chance using a low priority VM? If so, can you try selecting 'dedicated' as priority to verify? Also, ensure that you are following the steps outlined in this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-studio#amlcompute\">document<\/a> for creating a compute cluster. In the advanced settings, ensure to assign a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-studio#managed-identity\">managed identity<\/a> and specify a system-assigned identity or user-assigned identity.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information provided helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"registering model with its associated data in azure ml",
        "Question_created_time":1657796790130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/926828\/registering-model-with-its-associated-data-in-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>i registered a model using the cli command &quot;az ml model register&quot; it work fine, but the registered model has no dataset associated with it     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220670-screenshot-7.png?platform=QnA\" alt=\"220670-screenshot-7.png\" \/>    <\/p>\n<p>so is there a way to link the dataset that have been used to train the model to appear in the data tab ?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to profile dataset in ML. The source is ADLS. Error showing as authentication problem",
        "Question_created_time":1677124331230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1183453\/unable-to-profile-dataset-in-ml-the-source-is-adls",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi All<\/p>\n<p>I have a ML Workspace and an ADLS Account . I created the data store and dataset manually in ML Workspace. But while profiling the dataset , error shows as below<\/p>\n<pre><code>Error Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by AuthenticationException.\n    'AdlsGen2-ReadHeaders' for 'https:\/\/dlsdevdatafizzaml002.dfs.core.windows.net\/alb\/iris.csv' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation.), client request ID 'b5c8a43a-9eb6-4b0e-ac05-4765330df3d0', request ID '83bb1721-401f-0077-3e38-476a01000000'. Error message: \n| session_id=ff44f9a7-2fcf-4d2e-84a7-5bfcd37ca08f\n\n<\/code><\/pre>\n<p>I have given Managed Identity of ML Workspace to ADLS with Reader, Storage Blob Data Reader and Storage Blob Data Contributor access.<\/p>\n<p>While creating the Datastore, I have given Service Principal Details. And the Service Principal is given Storage Blob Data Contirbutor accees to ADLS.<\/p>\n<p>I do not think of anything above with respect to authentication. But not sure if this is really a authentication issue. Please help on this <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save trained model from AutoML\/Designer as pickle file to disk - Azure ML in current version 2023?",
        "Question_created_time":1676907474046,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182462\/save-trained-model-from-automl-designer-as-pickle",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>Save trained model from AutoML\/Designer as pickle file to disk - Azure ML in current version 2023?<\/p>\n<p>Currently, the model is saved as ilearner model. How can I save my model to .pkl file.<\/p>\n<p>Thanks,<\/p>\n<p>Ishwar Sukheja<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is \"Positive class label\" when running automated ML classification job?",
        "Question_created_time":1676675255740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181901\/what-is-positive-class-label-when-running-automate",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi there,<\/p>\n<p>I'm following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-first-experiment-automated-ml\">this <\/a>guide to try the AuotML classification out, when set the classification up, there is one field called &quot;Positive class label&quot; , I'm wondering what is it and any example of how to use it? <\/p>\n<p>I tried searching but seems like no documentation nor example.<\/p>\n<p>Thanks,<\/p>\n<p>Henry<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/2e72ca8f-0024-41f7-92a1-565b9a4dff1e?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Enabling auto-shutdown of idle computes in Machine Learning causes shutdowns during active jobs",
        "Question_created_time":1677011443533,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1182894\/enabling-auto-shutdown-of-idle-computes-in-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We have enabled the preview feature \u201cConfigure auto-shutdown for idle compute instances\u201d in Azure Machine Learning.\u00a0\u00a0 I set this to, for example, 60 minutes for a given compute instance in the \u201cSchedules\u201d tab when navigating to the compute instance.\u00a0 When I do this it appears to be shutting down 60 minutes after the compute was started, independent of if any jobs were started or are currently running.<\/p>\n<p>Is there another way this setting should be enabled so that it allows any jobs to complete, and then shuts down after the period of inactivity?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't access to a Dataset on Azure Machine Learning with SparkPool",
        "Question_created_time":1676644955703,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181777\/cant-access-to-a-dataset-on-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Can't access to a Dataset on Azure Machine Learning with SparkPool<\/p>\n<p>Recently we added a Synapse SparkPool to a Machine Learning to use it as &quot;Compute \/ Attached computers&quot;. <\/p>\n<p>When we use a Dataset to connect to Azure Storage Datalake Gen2 we have the following error:<\/p>\n<p>&quot;Resolving access token for scope &quot;https:\/\/storage.azure.com\/.default&quot; using identity of type &quot;MANAGED&quot;. No identity was found on compute.&quot;<\/p>\n<p>Ex of the Dataset use:<\/p>\n<p>ds = Dataset.get_by_name(ws, &quot;XXXXXXXX&quot;)<\/p>\n<p>If we don't use a Dataset and instead we connect directly to Azure Storage Data Lake Gen2 in the Notebook using the same compute instance (Spark Pool) the job executes succefully.<\/p>\n<p>Ex of the direct connection: <\/p>\n<p>%%pyspark<\/p>\n<p>STRUCTURED_PATH = 'abfss:\/\/curated@xxxx.dfs.core.windows.net'<\/p>\n<p>df_xxxxxx = spark.read.load(STRUCTURED_PATH+'\/xxxx\/xxxx.snappy.parquet', format='parquet')<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"feedback loop azure ml possibilities?",
        "Question_created_time":1676376282820,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1180554\/feedback-loop-azure-ml-possibilities",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>for a project we are doing azure ml assisted labeling (object detection). we also want to check the model for false positives\/negatives, by receiving the results of the camera and performing manual labeling on it. then we want to take the results from the check and put those in the original dataset that we created using azure labeling. is there a built in function for this or do we need to create this ourselfs?<\/p>",
        "Question_closed_time":1676534037760,
        "Answer_score_count":1.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6ab37d97-2a03-49e5-8bb2-90417150ab68\">Hamza Outa<\/a> Are you looking to add new labels after some feedback for your systems? <\/p>\n<p>I think there is an option to add new labels to a project by pausing it and then you have the following options:<\/p>\n<ul>\n<li> Start over, removing all existing labels. Choose this option if you want to start labeling from the beginning with the new full set of labels.<\/li>\n<li> Start over, keeping all existing labels. Choose this option to mark all data as unlabeled, but keep the existing labels as a default tag for images that were previously labeled.<\/li>\n<li> Continue, keeping all existing labels. Choose this option to keep all data already labeled as is, and start using the new label for data not yet labeled.<\/li>\n<\/ul>\n<p>Is this what you are looking for? I think the second option might work for you to add new labels if the default tags need to be changed. As per <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-image-labeling-projects#add-new-labels-to-a-project\">documentation <\/a>you can start using the new labels for labeling and the ML assisted labeling will start after a certain threshold is reached or you can manually start an ML assisted training run. I hope this helps!!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml.train'",
        "Question_created_time":1675732052720,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168278\/modulenotfounderror-no-module-named-azureml-train",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am following the chalenge: &quot;How to predict many protein structures with AlphaFold2 at-scale in Azure Machine Learning&quot; <\/p>\n<p><a href=\"https:\/\/colbyford.medium.com\/how-to-predict-many-protein-structures-with-alphafold2-at-scale-in-azure-machine-learning-c1e0ece4e99f\">https:\/\/colbyford.medium.com\/how-to-predict-many-protein-structures-with-alphafold2-at-scale-in-azure-machine-learning-c1e0ece4e99f<\/a><\/p>\n<p>I run the pipeline below: <\/p>\n<p><em>from azureml.core import Experiment, ScriptRunConfig, Environment<\/em><\/p>\n<p><em>from azureml.core.conda_dependencies import CondaDependencies<\/em><\/p>\n<p><em>from azureml.train.hyperdrive import GridParameterSampling, RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice<\/em><\/p>\n<p><em>from azureml.widgets import RunDetails<\/em><\/p>\n<p><em>## Create a Python environment for the experiment<\/em><\/p>\n<p><em>alphafold2_env = Environment(&quot;alphafold2&quot;)<\/em><\/p>\n<p><em>alphafold2_env.docker.base_image = &quot;cford38\/alphafold2_aml:latest&quot;<\/em><\/p>\n<p><em>alphafold2_env.python.user_managed_dependencies = True<\/em><\/p>\n<p><em>## Create a script config<\/em><\/p>\n<p><em>script_config = ScriptRunConfig(source_directory = &quot;.&quot;,<\/em><\/p>\n<pre><code>                            *script='predict.py',*\n\n                            *arguments = ['--msa_mode', &quot;MMseqs2 (UniRef+Environmental)&quot;,*\n\n                                         *'--num_models', 1,*\n\n                                         *'--num_recycles', 3,*\n\n                                         *'--stop_at_score', 90],*\n\n                            *environment = alphafold2_env,*\n\n                            *compute_target = training_cluster)*\n<\/code><\/pre>\n<p><em>## Sample a range of parameter values<\/em><\/p>\n<p><em>params = GridParameterSampling({ '--sequence_id': choice('alpha_b117_6xc2', 'beta_b1351_7vx1', 'delta_b1617_7v70', 'omicron_b11529_7t9j') })<\/em><\/p>\n<p><em>## Configure hyperdrive settings<\/em><\/p>\n<p><em>hyperdrive = HyperDriveConfig(run_config = script_config,<\/em> <\/p>\n<pre><code>                          *hyperparameter_sampling = params,* \n\n                          *policy = None,* \n\n                          *primary_metric_name = 'complete',* \n\n                          *primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,* \n\n                          *max_total_runs = 4,*\n\n                          *max_concurrent_runs = 3)*\n<\/code><\/pre>\n<p><strong>I receive the following notifications at the end:<\/strong><\/p>\n<pre><code>ModuleNotFoundError                       Traceback (most recent call last)\nInput In [10], in &lt;cell line: 3&gt;()\n      1 from azureml.core import Experiment, ScriptRunConfig, Environment\n      2 from azureml.core.conda_dependencies import CondaDependencies\n----&gt; 3 from azureml.train.hyperdrive import GridParameterSampling, RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n      4 from azureml.widgets import RunDetails\n      6 ## Create a Python environment for the experiment\n\nModuleNotFoundError: No module named 'azureml.train'\n<\/code><\/pre>\n<p>It appears that &quot;azureml.train&quot; is an uninstalled module. But I did set it up.<\/p>\n<p>Best <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error Code: ScriptExecution.StreamAccess.Unexpected when running a job in AzureML Studio",
        "Question_created_time":1676589961420,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181563\/error-code-scriptexecution-streamaccess-unexpected",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I got this error when running a job in Azure Machine Learning Studio. Any ideas about how to fix it?<\/p>\n<pre><code>Error Code: ScriptExecution.StreamAccess.Unexpected\nNative Error: error in streaming from input data sources\n\tStreamError(Unknown(&quot;unsuccessful status code 409 Conflict, body &quot;, None))\n=&gt; unsuccessful status code 409 Conflict, body \n\tUnknown(&quot;unsuccessful status code 409 Conflict, body &quot;, None)\nError Message: Got unexpected error: unsuccessful status code 409 Conflict, body . | session_id=96032e2f-c1e6-423c-8225-c1c460b3192f\n<\/code><\/pre>",
        "Question_closed_time":1676870036790,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2506b2a8-0b14-4610-bdd6-41ac619af16a\">@Maria Rivera Araya  <\/a>The error message &quot;unsuccessful status code 409 Conflict, body&quot; suggests that there is a conflict with the input data sources. This error can occur when the input data sources are being modified while the job is running.&lt;sup&gt;<a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/component-reference\/designer-error-codes.md\">[2]<\/a>&lt;\/sup&gt;<\/p>\n<p>You can try the following steps to resolve the issue: Wait for the input data sources to finish being modified.<\/p>\n<ol>\n<li> If the input data sources are not being modified, try restarting the job.<\/li>\n<li> If the issue persists, try using a different input data source.<\/li>\n<\/ol>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"[Potential Bug] 500 internal Server Error when submit AI ML pipeline",
        "Question_created_time":1676654736196,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181832\/(potential-bug)-500-internal-server-error-when-sub",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi there,<\/p>\n<p>I'm following this exercise <a href=\"https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html\">https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html<\/a> to create a AI ML pipeline, when it comes to submitting the job, it always shows a 500 error code with no response body. <\/p>\n<p>I'm assuming there might be a bug or down time for AI ML studio. <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dce2c59e-b65a-47c4-8bf2-4fc5638aa2ca?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Registering Data Asset from Job with v2 SDK\/CLI",
        "Question_created_time":1663328415870,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1011004\/registering-data-asset-from-job-with-v2-sdk-cli",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>Following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-read-write-data-v2?tabs=python#write-data-in-a-job\">this example<\/a> I tried to register the output of a job as a Data Asset, by using the <code>azureml:&lt;my_data&gt;:&lt;version&gt;<\/code> syntax for the path. The following minimal example shows what I'm trying to achieve:    <\/p>\n<pre><code>from azure.ai.ml import command  \nfrom azure.ai.ml.entities import Data  \nfrom azure.ai.ml import Input, Output  \nfrom azure.ai.ml.constants import AssetTypes  \n  \nmy_job_outputs = {  \n    &quot;prep_data&quot;: Output(type=AssetTypes.URI_FOLDER, path=&quot;azureml:test_output:1&quot;)  \n}  \n  \njob = command(  \n    command=&quot;echo 'test' &gt; ${{outputs.prep_data}}&quot;,  \n    outputs=my_job_outputs,  \n    environment=&quot;test-env@latest&quot;,  \n    compute=&quot;cpu-cluster&quot;,  \n)  \n  \n# submit the command  \nreturned_job = ml_client.create_or_update(job)  \n<\/code><\/pre>\n<p>Unfortunately, this fails. The job submission works, but the Job is immediately going to the Failed status with the following error message:    <\/p>\n<pre><code>Invalid output uri azureml:test_output:1\/ found for output prep_data of run , the list of supported uri formats are [&quot;wasb:\/\/&quot;, &quot;wasbs:\/\/&quot;, &quot;adl:\/\/&quot;, &quot;abfs&quot;, &quot;abfss:\/\/&quot;, &quot;azureml:\/\/&quot;]  \n<\/code><\/pre>\n<p>What is the correct syntax for registering a Data Asset from a Job output?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot Create Real-time Endpoint",
        "Question_created_time":1676197975883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1179908\/cannot-create-real-time-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I tried to use the tutorial on deploying a Machine Learning Endpoint using this link: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy<\/a><\/p>\n<p>First off, I created my own model using my own dataset and was able to create a model with a 96% confidence level. I then started to deploy it using the tutorial above and found two issues:<\/p>\n<ol>\n<li> Upon creating the real-time inference pipeline the Web Service Input is not generated. \n   <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a2f8ef8d-d5ed-406d-bb54-07456ccb3e68?platform=QnA\" alt=\"Untitled\" \/>   Hence, I needed to manually add it..<\/li>\n<li> After adding the Web Service Input and running it again, I tried to deploy it but got this error:  <br \/>\n   Realtime endpoint deploy 'test' failed\n   Deploy: Failed on Preparing to deploy. Details: Call MT PrepareCreateRealTimeEndpointRequest api failed. Extract schema failed for web service input input1, from data node of node id: 8c29f71d<\/li>\n<\/ol>\n<p>Is there any thing I am missing out here?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to deploy a ML model to azure which requires an entire repository to run",
        "Question_created_time":1675521234990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1167665\/how-to-deploy-a-ml-model-to-azure-which-requires-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I was following guide <a href=\"https:\/\/medium.com\/aiguys\/model-deployment-on-azure-as-a-web-app-b7bb5599bfbf\">https:\/\/medium.com\/aiguys\/model-deployment-on-azure-as-a-web-app-b7bb5599bfbf<\/a>  <br \/>\nthis worked, but in my actual use case I am deploying a model which is made up of 4 different ML models.<\/p>\n<p>this means that my code is rather complicated and not something I can do in a simple &quot;scoring.py&quot; file.<\/p>\n<p>I have an entire repository with a function that when called takes care of everything, my issue is how can I deploy this model as an online service which simply gets an image and then runs the code in the repository?<\/p>\n<p>I uploaded this repository to <a href=\"https:\/\/dev.azure.com\/\">https:\/\/dev.azure.com\/<\/a> and also git cloned it into my ML workspace notebook.<\/p>\n<p>the repository also already has the ML models to simplify things, I tried searching online but there is practically no use cases like this (which is quire surprising) so maybe I'm trying to use the wrong service.<\/p>\n<p>Would really appreciate some help, thx!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to solve an error in model profiling where it is not recognizing the profile attribute provided by model library?",
        "Question_created_time":1675457343590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1167559\/how-to-solve-an-error-in-model-profiling-where-it",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>AttributeError: type object 'Model' has no attribute 'profile' when I am trying to profile my custom model<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio: can't open the terminal and connect to a kernel",
        "Question_created_time":1675680384793,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168009\/azure-machine-learning-studio-cant-open-the-termin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have a azureml studio with a notebook and suddenly since today, I cant run notebooks cells anymore. It says kernel not connected. I cant either open the terminal it never loads. I restarted the compute instance several time, but that didn't fix the problem. Additionally I created new compute environments but they have the same issue as my original compute environment. <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/f3469fcc-3c2b-43ad-9687-88826f683e32?platform=QnA\" alt=\"No terminal\" \/><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/695c4aff-2ffd-4763-b122-6b687240d9ac?platform=QnA\" alt=\"No kernel\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to get details for ML assisted labeling model in azure ML studio",
        "Question_created_time":1674226735333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1162803\/how-to-get-details-for-ml-assisted-labeling-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>In azure ml studio I use ML assisted labeling. And I want to know how that model is trained, what are the specifications, are there early stoppings, based on what criteria does it decide it needs a new run, what metrics, etc.<\/p>\n<p>so my question is where can I find the in depth information about that model?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to fix 'OpenMPI error on compute when running Azure Machine Learning jobs '",
        "Question_created_time":1675120830243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165597\/how-to-fix-openmpi-error-on-compute-when-running-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<ol>\n<li> Seeing below error in log file: <code>user_logs\/mpi_log.txt<\/code><\/li>\n<\/ol>\n<pre><code>Error: &quot;Orted process returned unsuccessful exit code: 2. If you are using a version of OpenMPI &lt; 4.0.1, please update to a newer version and try again. If the issue persists, please contact support. Error message: Execution failed. User process '-x' exited with status code 2. Please check log file '\/mnt\/azureml\/cr\/j\/464bfc758a684b42b512385a391314f3\/cap\/lifecycler\/wd\/.azureml_cr_log\/mpi_orted_1.txt' for error details. Error: \\t\/bin\/bash [GNU long option] [option] script-file ...\\nGNU long options:\\n\\t--debug\\n\\t--debugger\\n\\t--dump-po-strings\\n\\t--dump-strings\\n\\t--help\\n\\t--init-file\\n\\t--login\\n\\t--noediting\\n\\t--noprofile\\n\\t--norc\\n\\t--posix\\n\\t--rcfile\\n\\t--restricted\\n\\t--verbose\\n\\t--version\\nShell options:\\n\\t-ilrsD or -c command or -O shopt_option\\t\\t(invocation only)\\n\\t-abefhkmnptuvxBCHP or -o option\\n. More details can be found in error file: \/mnt\/azureml\/cr\/j\/464bfc758a684b42b512385a391314f3\/cap\/lifecycler\/wd\/.azureml_cr_log\/mpi_orted_1.txt.&quot;\n<\/code><\/pre>\n<ol start=\"2\">\n<li>  Log entry in the <code>system_logs\/lifecycler\/1\/mpi_orted_1.txt<\/code><\/li>\n<\/ol>\n<pre><code>\/bin\/bash: \/azureml-envs\/azureml_5542d71450c0cb2def095a8d9037155a\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n\/bin\/bash: - : invalid option\nUsage:\t\/bin\/bash [GNU long option] [option] ...\n\t\/bin\/bash [GNU long option] [option] script-file ...\nGNU long options:\n\t--debug\n\t--debugger\n\t--dump-po-strings\n\t--dump-strings\n\t--help\n\t--init-file\n\t--login\n\t--noediting\n\t--noprofile\n\t--norc\n\t--posix\n\t--rcfile\n\t--restricted\n\t--verbose\n\t--version\nShell options:\n\t-ilrsD or -c command or -O shopt_option\t\t(invocation only)\n\t-abefhkmnptuvxBCHP or -o option\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine learning studio stuck",
        "Question_created_time":1651358386807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/832643\/machine-learning-studio-stuck",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My project stuck again this week. It has been three hours for waiting.  <\/p>\n<p>Any help?<\/p>",
        "Question_closed_time":1651388646413,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=7b9bd507-2d3c-4b21-abf9-99923359198e\">@Azadeh  <\/a>    <\/p>\n<p>I am sorry for your experience, but I just double check on backlog, we don't see any ongoing issue currently. Could you please share your region?    <\/p>\n<p>Please let us know if you still see this issue after refreshing and we are willing to help you anytime.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Job stuck on 'starting' when creating an environment",
        "Question_created_time":1675968962376,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1179332\/azure-machine-learning-job-stuck-on-starting-when",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I've been reading along and working on the self-paced modules for Microsoft course <a href=\"https:\/\/docs.microsoft.com\/learn\/certifications\/courses\/dp-100t01\">DP-100 <\/a><em><a href=\"https:\/\/docs.microsoft.com\/learn\/certifications\/courses\/dp-100t01\">Designing and Implementing a Data Science Solution on Azure<\/a><\/em>.<\/p>\n<p>Often, when submitting an experiment from my azure ml workspace, my notebook stalls out when waiting for the experiment to complete. The jobs are always on 'starting'.  I had no luck despite reading the documentation and trying out different configurations... It stays on 'starting' for hours until I manually cancel the job. <\/p>\n<p>I execute this block and use the same compute running the notebook. What concerns me is that the kernel doesn't show any CPU utilization.  Any tips would be appreciated. <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9b5de009-2261-45fe-a9be-7d210d4369bb?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>This is my yaml file. <\/p>\n<pre><code class=\"lang-yaml\">\nname: simple_environment\nchannels:\n  - conda-forge\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.8\n- pandas\n- numpy\n\n<\/code><\/pre>\n<p>entry script, helloworld.py:<\/p>\n<pre><code class=\"lang-python\">from azureml.core import Run\nimport pandas as pd\nimport os\n\n\n# Get the experiment run context\nrun = Run.get_context()\n\nrun.log('helloworld1', 'helloworld2')\n\n# Complete the run\nrun.complete()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I make prediction and write it in my local Rdbms using azure.",
        "Question_created_time":1674216327440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1162737\/how-can-i-make-prediction-and-write-it-in-my-local",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How can I run the model trained with the training data and get an additional column in the dataset?<\/p>\n<p>For Eg:- If I have trained a model which has an interface that takes height weight and age as input and gives output as the individual health status of being fit unfit types. Now I want to do that through automation and put the prediction and inputs in the file of local RDBMS\/SQL and save the values. I want to do this by using Azure.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio environment fails to build with context",
        "Question_created_time":1654178870087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/874583\/azure-machine-learning-studio-environment-fails-to",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to build an environment for ML Studio which requires some private compiled binaries. I packed these files into a Tar (about 2.8 MB, if it's relevant) and added them to the context tab of an existing environment (I want to update it). I then added this Tar in my Dockerfile and built the environment, but it failed instantly. The log tab also doesn't open (it just sits loading).  <\/p>\n<p>I tried changing things around to eliminate as many variables as possible:  <\/p>\n<ul>\n<li> Instead of using ADD I tried COPY: No change  <\/li>\n<li> I tested building the Dockerfile locally in a folder containing only the Dockerfile and the tar: It worked  <\/li>\n<li> I tested clicking the &quot;Download Content&quot; button and building the image in the downloaded folder: It worked  <\/li>\n<li> I tried removing all references to the Tar from the Dockerfile but still uploading the file: It failed instantly  <\/li>\n<li> I tried uploading an equivalent Zip file: It failed in the same way  <\/li>\n<li> I uploaded a single text file instead of the Tar: It worked  <\/li>\n<\/ul>\n<p>How can I get this to work?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get request_id within the azure ml score.py run function ?",
        "Question_created_time":1676006403940,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1179456\/how-to-get-request-id-within-the-azure-ml-score-py",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to find the request id in the run function within the score.py. I however see the request id in the deployment logs tab as show in the screen shot (line 1665, 1670, 1680 etc). It is auto-magically logging the request id to the IO stream, i would like to log this to our logging mechanism any pointers to how or where to find this attribute would be extremely help.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/e6caa7a1-2ed6-4b39-b77c-d715db554090?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Automated ML(interface) choosing primary metrics to handle imbalanced data",
        "Question_created_time":1593398061863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40792\/azure-automated-ml(interface)-choosing-primary-met",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I figured out that there are some primary metrics I can choose when I run an automated ML experiment. Yet the number of primary metrics is fewer than the run metrics in the result page. I want to deal with imbalanced data(10:1 or 20:1) and    <\/p>\n<p>looked up the links below:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data<\/a>    <br \/>\nand    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>    <\/p>\n<p>It seems F1 score is recommended to evaluate each model with imbalanced data.    <\/p>\n<p>Here are my questions:    <\/p>\n<ul>\n<li> Is there any way to set F1 score or multiple measures as a primary metric?     <\/li>\n<li> If there is no such way, should I do it manually?     <\/li>\n<li> Of all the given primary metrics, which primary metric is the most appropriate(to build a Classification model with imbalanced data)?    <\/li>\n<\/ul>\n<p>Thanks.    <\/p>",
        "Question_closed_time":1593508812347,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p>For imbalanced data, it is preferred to choose AUC Weighted. Also user should then choose a metric that is appropriate to work well for imbalance. E.g. F1, micro averaged AUC, balanced accuracy for model evaluation. For primary metric (metric used for model optimization) the user should preferably choose AUC Weighted instead of accuracy.    <br \/>\nCurrently from the ml.azure.com the following metrics are supported. To add F1 score metric forwarded to product team to check on this.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#primary-metric\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#primary-metric<\/a>    <br \/>\n<img src=\"\/answers\/storage\/temp\/10986-screenshot-162.png\" alt=\"10986-screenshot-162.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Select Column by Name not working in the designer",
        "Question_created_time":1670006235947,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1114223\/select-column-by-name-not-working-in-the-designer",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\nI'm having issues working with the select columns by name option in the machine learning studio designer. In the documentation it says that we have to run the pipeline for the modules to pick up the data schema. In the previous version of the designer we were able to see the run progress in the pipeline view and dynamically add to it. This is not available now and the pipeline runs in the experiments section. As such the modules still do not pick up the data schema. How can I solve this issue and enable other data transformation modules to have an understanding of the data?    <br \/>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I find the best employee match",
        "Question_created_time":1675213954183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1166020\/how-can-i-find-the-best-employee-match",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all;<\/p>\n<p>Is there an Azure ML service where I can pass it the following for several hundred people:<\/p>\n<ol>\n<li> Their resume (probably PDF)<\/li>\n<li> Their LinkedIn username<\/li>\n<li> Several paragraphs of text (that they entered describing their job skills)<\/li>\n<\/ol>\n<p>And I then pass in a search term such as &quot;web designer.&quot; And the service returns to me those individuals that look like a good match for that job skill, ranked in order of how good a match they are.<\/p>\n<p>Is there a service that does this? Seems like this would be gigantic for HR departments.<\/p>\n<p>thanks - dave<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Create a Managed ML Inference Endpoint and deployment using Terraform",
        "Question_created_time":1675721150660,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168249\/create-a-managed-ml-inference-endpoint-and-deploym",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I would like to use Terraform to create a Managed ML Inference Endpoint and its corresponding deployment. I know the options to do it with CLI, python SDK and ARM template but I can't find a way to do it with Terraform, which feels very strange.<\/p>\n<p>On the Terraform docs, I only find how to create a <a href=\"https:\/\/registry.terraform.io\/providers\/hashicorp\/azurerm\/latest\/docs\/resources\/machine_learning_workspace\">ML Workspace<\/a> and <a href=\"https:\/\/registry.terraform.io\/providers\/hashicorp\/azurerm\/latest\/docs\/resources\/machine_learning_compute_instance\">Computing instances<\/a>. What am I missing? Is it really not possible to do it using Terraform?<\/p>\n<p>Thank you so much in advance! Appreciate a lot your help!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Selecting the Dependencies file in the Studio GUI for deploying to an endpoint is bugged - wrong file format specified",
        "Question_created_time":1671543586710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136021\/selecting-the-dependencies-file-in-the-studio-gui",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>When attempting to select the Dependencies file in the AML GUI - the file selector window that opens has the wrong file extension selected (*.py) - it should be either <em>.<\/em> or potentially <em>.yml\/<\/em>.yaml - thanks    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/272512-capture3.png?platform=QnA\" alt=\"272512-capture3.png\" \/>    <\/p>",
        "Question_closed_time":1672281348810,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">@Neil McAlister  <\/a>     <\/p>\n<p>Thanks for your waiting due to the holiday season and sorry for the confusion. This buttion is actually for adding <strong>code dependencies<\/strong>, i.e., my scoring script requires dependency.py. For package dependencies, those need to be included in the environment to use for the deployment.    <\/p>\n<p>The button name &quot;Add Dependencies&quot; is confused here, and product team is working on changing the name or add more explanation for this button.     <\/p>\n<p>In the UI here, you must have already created an environment to do a deployment. Providing a conda.yml file in the endpoints create dialog will not register a new environment for you.  The environment must be selected in the bottom section of the page as below -    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/274589-microsoftteams-image-12.png?platform=QnA\" alt=\"274589-microsoftteams-image-12.png\" \/>    <\/p>\n<p>If your environment doesn't exist in this list, or in the custom environments, then you'll need to go to the environments tab on the left side of the portal and create an enviornment.    <\/p>\n<p>I am sorry for the confusion and product team will fix it in the near future.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly acceept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Does Azure Auto ML support video classification?",
        "Question_created_time":1675458249353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1167562\/does-azure-auto-ml-support-video-classification",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm wondering if the Azure Machine Learning platform supports video classification using Azure AutoML. I know it supports image classification but I can't seem to find out whether it supports video classification. Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cost for Online Endpoint in Azure Machine Learning",
        "Question_created_time":1675126162933,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165606\/cost-for-online-endpoint-in-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I created the online endpoint for my object detection model but i am curious about the bill. I know the endpoint is available and online at anytime and I though Azure is going to charge me based on how long the endpoint takes to complete several request. But I see some articles (<a href=\"https:\/\/bea.stollnitz.com\/blog\/aml-online-endpoint\/\">https:\/\/bea.stollnitz.com\/blog\/aml-online-endpoint\/<\/a>) stated that the bill starts from the creation of endpoint, not duration to complete every request sent by us. The official does not explain much on the way they charge the endpoint, but it just encourages me to delete endpoint once it is not used. Hope anyone can clarify and share their experience on cost of online endpoint. thank you :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"converting the azure machine learning forecast into a dataframe",
        "Question_created_time":1674820546810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164788\/converting-the-azure-machine-learning-forecast-int",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am building the forecasting model in jupiter notebook in python in Azure Machine Learning service. To do so I am using the forecast function documented <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-forecast-function\/auto-ml-forecasting-function.ipynb\">here<\/a>.<\/p>\n<p>The problem is with the output. It looks like this:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/ac9586f3-afc1-4f65-a5cb-c8c1037be3ec?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Not sure even how do i call it. It does not look like a typical dataframe. More like a pivot table. Some of the columns starting from &quot;automl_target_col_wasnull&quot; are automaticaly added by the function.   <\/p>\n<p><strong>How do I convert it into a dataframe?<\/strong><\/p>\n<p>I am interested in only the columns &quot;Month&quot;, &quot;Branch&quot; and the last one containg the forecast called &quot;_automl_target_col&quot; . The docs do not show any of such example<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automl NER failed with .csv file",
        "Question_created_time":1675096757110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165491\/automl-ner-failed-with-csv-file",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I was trying AutoML to do some easy NLP model. Data set is small. For NER training, .csv is constantly failing. Am I missing something?<\/p>",
        "Question_closed_time":1675098209790,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=0e37a0a7-a326-4fb6-9c52-7c2fff3df543\">Nick<\/a><\/p>\n<p>Thanks for reaching out to us. I am sorry .csv actually not works for NER. <\/p>\n<p>Unlike multi-class or multi-label, which takes <code>.csv<\/code> format datasets, <strong>named entity recognition requires CoNLL format.<\/strong> The file must contain exactly two columns and in each row, the token and the label is separated by a single space.<\/p>\n<p>For example,<\/p>\n<p><code>Hudson B-loc<\/code><\/p>\n<p><code>Square I-loc<\/code><\/p>\n<p><code>is O<\/code><\/p>\n<p><code>a O<\/code><\/p>\n<p><code>famous O<\/code><\/p>\n<p><code>place O<\/code><\/p>\n<p><code>in O<\/code><\/p>\n<p><code>New B-loc<\/code><\/p>\n<p><code>York I-loc<\/code><\/p>\n<p><code>City I-loc<\/code><\/p>\n<p><code>Stephen B-per<\/code><\/p>\n<p><code>Curry I-per<\/code><\/p>\n<p><code>got O<\/code><\/p>\n<p><code>three O<\/code><\/p>\n<p><code>championship O<\/code><\/p>\n<p><code>rings O<\/code><\/p>\n<p>More information please refer to here - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli#named-entity-recognition-ner\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli#named-entity-recognition-ner<\/a><\/p>\n<p>I hope this helps! Let me know if you have more questions. <\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error code 400: AciDeploymentFailedin Azureml",
        "Question_created_time":1674791747380,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164692\/error-code-400-acideploymentfailedin-azureml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi Everyone,<\/p>\n<p>I have been trying for last 3 days but couldn't able to fix this issue. I have checked the model is also registered.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60561521-3677-4a26-bd8e-2e8bde417d39?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Below code is my score.py<\/p>\n<pre><code>#score.py\n\nimport json\nimport joblib\nfrom azureml.core.model import Model\n\ndef init():\n\tglobal model\n\tmodel_path = Model.get_model_path(model_name = 'model_estimator_500.pkl')\n\tmodel = joblib.load(model_path)\n\t\ndef run(raw_data):\n\ttry:\n\t\tdata = np.array(json.loads(raw_data)['data'])\n\t\ty_hat = model.predict(data)\n\t\treturn y_hat.to_list()\n\texcept Exception as e:\n\t\tresult = str(e)\n\t\treturn json.dump({&quot;error&quot;: result})\n\n\nfrom azureml.core.webservice import Webservice \nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.image import ContainerImage \nfrom azureml.exceptions import WebserviceException\nfrom azureml.core.image import Image \nfrom azureml.core.conda_dependencies import CondaDependencies\n\nmyenv = Environment(name=&quot;myenv&quot;)\nenv = CondaDependencies()\nenv = CondaDependencies.create(\n    pip_packages=['azureml-defaults','scikit-learn', 'joblib']\n)\nmyenv.python.conda_dependencies=env\n#myenv.python.conda_dependencies.save(&quot;myenv.yml&quot;)\n\n\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.environment import Environment\n\nservice_name = 'my-custom-env-service'\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=myenv)\n\nservice = Model.deploy(workspace=ws,\n                       name=service_name,\n                       models=[model], \n                       inference_config=inference_config,\n                       deployment_config=aciconfig,\n                       overwrite=True)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.scoring_uri)\n\n\n#--------------------------------xx--------------------------------#\n\n<\/code><\/pre>\n<p>Now here this is the o\/p I am getting:<\/p>\n<pre><code>\/tmp\/ipykernel_5105\/4290996075.py:70: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI\/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-deploy-managed-online-endpoints \/\nhttps:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-deploy-managed-online-endpoint-sdk-v2 \/\nhttps:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https:\/\/aka.ms\/acimoemigration. \nTo disable CLI\/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(workspace=ws,\nService deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 9d233765-e0f1-43e2-a02e-d92fc5d9fb31\nMore information can be found using '.get_logs()'\nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;\n    },\n    {\n      &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n      &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n&quot;RestartCount&quot;: 3\n&quot;CurrentState&quot;: {&quot;state&quot;:&quot;Waiting&quot;,&quot;startTime&quot;:null,&quot;exitCode&quot;:null,&quot;finishTime&quot;:null,&quot;detailStatus&quot;:&quot;CrashLoopBackOff: Back-off restarting failed&quot;}\n&quot;PreviousState&quot;: {&quot;state&quot;:&quot;Terminated&quot;,&quot;startTime&quot;:&quot;2023-01-27T03:31:58.463Z&quot;,&quot;exitCode&quot;:111,&quot;finishTime&quot;:&quot;2023-01-27T03:32:11.52Z&quot;,&quot;detailStatus&quot;:&quot;Error&quot;}\n&quot;Events&quot;: null\n&quot;\n    }\n  ]\n}\n\nTips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-01-27 03:28:38+00:00 Creating Container Registry if not exists.\n2023-01-27 03:28:38+00:00 Registering the environment.\n2023-01-27 03:28:39+00:00 Use the existing image.\n2023-01-27 03:28:39+00:00 Generating deployment configuration.\n2023-01-27 03:28:40+00:00 Submitting deployment to compute.\n2023-01-27 03:28:44+00:00 Checking the status of deployment my-custom-env-service..\n2023-01-27 03:30:36+00:00 Checking the status of inference endpoint my-custom-env-service.\nFailed\n---------------------------------------------------------------------------\nWebserviceException                       Traceback (most recent call last)\nCell In [6], line 77\n     68 inference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=myenv)\n     70 service = Model.deploy(workspace=ws,\n     71                        name=service_name,\n     72                        models=[model], \n     73                        inference_config=inference_config,\n     74                        deployment_config=aciconfig,\n     75                        overwrite=True)\n---&gt; 77 service.wait_for_deployment(show_output=True)\n     79 print(service.scoring_uri)\n     82 #--------------------------------xx--------------------------------#\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py:918, in Webservice.wait_for_deployment(self, show_output, timeout_sec)\n    915         if not logs_response:\n    916             logs_response = 'Current sub-operation type not known, more logs unavailable.'\n--&gt; 918         raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n    919                                   'service state: {}\\n'\n    920                                   'Operation ID: {}\\n'\n    921                                   '{}\\n'\n    922                                   'Error:\\n'\n    923                                   '{}'.format(self.state, self._operation_endpoint.split('\/')[-1],\n    924                                               logs_response, format_error_response), logger=module_logger)\n    925     print('{} service creation operation finished, operation &quot;{}&quot;'.format(self._webservice_type,\n    926                                                                           operation_state))\n    927 except WebserviceException as e:\n\nWebserviceException: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 9d233765-e0f1-43e2-a02e-d92fc5d9fb31\nMore information can be found using '.get_logs()'\nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;\n    },\n    {\n      &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n      &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n&quot;RestartCount&quot;: 3\n&quot;CurrentState&quot;: {&quot;state&quot;:&quot;Waiting&quot;,&quot;startTime&quot;:null,&quot;exitCode&quot;:null,&quot;finishTime&quot;:null,&quot;detailStatus&quot;:&quot;CrashLoopBackOff: Back-off restarting failed&quot;}\n&quot;PreviousState&quot;: {&quot;state&quot;:&quot;Terminated&quot;,&quot;startTime&quot;:&quot;2023-01-27T03:31:58.463Z&quot;,&quot;exitCode&quot;:111,&quot;finishTime&quot;:&quot;2023-01-27T03:32:11.52Z&quot;,&quot;detailStatus&quot;:&quot;Error&quot;}\n&quot;Events&quot;: null\n&quot;\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 9d233765-e0f1-43e2-a02e-d92fc5d9fb31\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n  \\&quot;statusCode\\&quot;: 400,\\n  \\&quot;message\\&quot;: \\&quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;,\\n  \\&quot;details\\&quot;: [\\n    {\\n      \\&quot;code\\&quot;: \\&quot;CrashLoopBackOff\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 361fa07ff378469392f42cc8f56c7bf9.azurecr.io\/azureml\/azureml_c471f026f58655f5b5c96f38d8bd754b locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;\\n    },\\n    {\\n      \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\&quot;RestartCount\\&quot;: 3\\n\\&quot;CurrentState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Waiting\\&quot;,\\&quot;startTime\\&quot;:null,\\&quot;exitCode\\&quot;:null,\\&quot;finishTime\\&quot;:null,\\&quot;detailStatus\\&quot;:\\&quot;CrashLoopBackOff: Back-off restarting failed\\&quot;}\\n\\&quot;PreviousState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Terminated\\&quot;,\\&quot;startTime\\&quot;:\\&quot;2023-01-27T03:31:58.463Z\\&quot;,\\&quot;exitCode\\&quot;:111,\\&quot;finishTime\\&quot;:\\&quot;2023-01-27T03:32:11.52Z\\&quot;,\\&quot;detailStatus\\&quot;:\\&quot;Error\\&quot;}\\n\\&quot;Events\\&quot;: null\\n\\&quot;\\n    }\\n  ]\\n}&quot;\n    }\n}\n<\/code><\/pre>\n<pre><code>print(service.get_logs())\n<\/code><\/pre>\n<p>Also when I am checking service logs its, returning me None  <\/p>\n<p>Thanks,<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How To Connect To Managed Instance from Machine Learning Studio",
        "Question_created_time":1675189332826,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165919\/how-to-connect-to-managed-instance-from-machine-le",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have migrated 4 on-premise DBs to Azure in an Azure Managed Instance.<\/p>\n<p>We are trying to connect to these DBs from Azure Machine Learning Studio.<\/p>\n<p>Some googling and a 2 year old post suggests ML does not support Managed Instances, only SQL Databases.  Our testing kinda confirmed that :-(<\/p>\n<p>Is it correct that ML can only connect to a SQL Databases and not a MI?<\/p>\n<p>We are using MI so that we can use Azure Managed Instance Link once we have site to site vpn configured.<\/p>\n<p>Thanks,<\/p>\n<p>Ross<\/p>",
        "Question_closed_time":1675311477690,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=24186a71-0c44-4fba-8380-5a960c9e0867\">RossW<\/a> Yes, Azure Machine Learning studio currently does not support connections to Azure Managed Instances. It only supports connections to Azure SQL Databases. You can use the SQL Database as a data source for your machine learning models in Azure Machine Learning studio.<\/p>\n<p>To connect to an Azure SQL Database from Azure Machine Learning studio, you need to follow these steps:<\/p>\n<ol>\n<li> Create an Azure SQL Database and make sure that it is accessible from your Azure Machine Learning workspace.<\/li>\n<li> In Azure Machine Learning studio, go to the Data tab and click on the +New button.<\/li>\n<li> Select the SQL Database option and provide the necessary details, such as the server name, database name, and authentication method.<\/li>\n<li> Click on the Connect button to establish a connection to the Azure SQL Database.<\/li>\n<li> Once the connection is established, you can use the SQL Database as a data source for your machine learning models in Azure Machine Learning studio.<\/li>\n<\/ol>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"azure machine learning teaching",
        "Question_created_time":1672957613043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1153648\/azure-machine-learning-teaching",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello    <br \/>\nI have 5000$ Azure grant that I will use to teach my deep learning class. We will have 5-6 groups with two students each. I have lecture notes and assignments in the form of Juptyter notebooks.    <br \/>\nThis is my first time I use Azure. I managed to train a model with default Tesla K80. It takes 6 mins to runs a model that I run in 18 seconds with my RTX-2070 Super in my local machine. My question what can be a best practice to teach this class. Compatring to Colab, I found Azure extremely confusing and difficult to navigate. Should I create multiple workspaces under a single subscription? If so, how can I fix that slow GPU issue, should I submit quota increase for each workspace?    <br \/>\nAny kind of help would be highly appreciated. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integration with Application Insights should allow you to specify a choice of which instance to use",
        "Question_created_time":1671543228090,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1135890\/integration-with-application-insights-should-allow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When ticking any boxes inside Azure Machine Learning Studio - or in the YAML templates by specifying it's enabled by a true or false value- you can't specify which Application Insights instance to use - it will use the default one connected to that Azure Machine Learning Studio only.    <\/p>\n<p>For using something like Azure Machine Learning Studio as a solutions provider, and that might have multiple customers models within it, the ability to be able to specify a Applications Insights connection string to an instance OUTSIDE of the default in-built one would be a great addition to functionality.     <\/p>\n<p>With the current set up we are forced to have a different AML Studio \/ Storage Account \/ ACR \/ App Insights \/ Key vault for each customer to allow Applications Insights data collection to make any sense per customer.    <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":1671640414100,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">@Neil McAlister  <\/a> Thanks for the feedback. I have forwarded to the product team to support near future to specify a Applications Insights connection string to an instance OUTSIDE of the default in-built.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"CLI v2 managed online endpoint deployment YAML file referencing an existing inbuilt environment - how?",
        "Question_created_time":1671542161167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1135929\/cli-v2-managed-online-endpoint-deployment-yaml-fil",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>The following documentation specifies this option...    <\/p>\n<blockquote>\n<p>To reference an existing environment, use the azureml:&lt;environment-name&gt;:&lt;environment-version&gt; syntax.    <\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/reference-yaml-deployment-managed-online#:%7E:text=To%20reference%20an%20existing%20environment%2C%20use%20the%20azureml%3A%3Cenvironment%2Dname%3E%3A%3Cenvironment%2Dversion%3E%20syntax\">https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/reference-yaml-deployment-managed-online#:~:text=To%20reference%20an%20existing%20environment%2C%20use%20the%20azureml%3A%3Cenvironment%2Dname%3E%3A%3Cenvironment%2Dversion%3E%20syntax<\/a>.    <\/p>\n<p>Can anyone help me work out what I need to put into the YAML deployment config file please - tried multiple things and nothing works. I tried to highlight this over at the documentation GitHub but they told me to come here - not a documentation issue apparently! There are no example around.    <\/p>\n<p>This is my deployment YAML file - I want to reference the Azure Machine Learning existing environment which is called <strong>AzureML-sklearn-1.0-ubuntu20.04-py38-cpu<\/strong> version <strong>32<\/strong>    <\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json  \nmodel: azureml:my-model:1  \ncode_configuration:  \n  code: models\/my-model\/  \n  scoring_script: score.py  \nenvironment:   \n ???????  \n  conda_file: models\/my-model\/conda.yml  \ninstance_type: Standard_DS2_v2  \ninstance_count: 2  \napp_insights_enabled: true  \n<\/code><\/pre>\n<p>Thank you in advance    <\/p>",
        "Question_closed_time":1671596306490,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">@Neil McAlister  <\/a> Thanks for the question. Here is the sample to create a Deployment YAML Definition.    <\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json \u200b  \n  \nname: blue \u200b  \n  \nendpoint_name: my-endpoint \u200b  \n  \nmodel: \u200b  \n  \n    path: ..\/..\/model-1\/model\/ \u200b  \n  \ncode_configuration: \u200b  \n  \n    code: ..\/..\/model-1\/onlinescoring\/ \u200b  \n  \n    scoring_script: score.py \u200b  \n  \nenvironment: \u200b  \n  \n    conda_file: ..\/..\/model-1\/environment\/conda.yml \u200b  \n  \n    image: mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1 \u200b  \n  \ninstance_type: Standard_DS2_v2 \u200b  \n  \ninstance_count: 1  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to save images on filestore with AzureMachineLearningFileSystem",
        "Question_created_time":1674484562583,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1163384\/how-to-save-images-on-filestore-with-azuremachinel",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How do I save images on azure filestore after changing values with azureml.fsspec AzureMachineLearningFileSystem? <\/p>\n<p>Example code below:<\/p>\n<pre><code class=\"lang-python\">\nfrom azureml.fsspec import AzureMachineLearningFileSystem\n\npath_to_imagefolder = &quot;azureml:\/\/subscriptions\/...\/resourcegroups\/...\/workspaces\/...\/datastores\/workspacefilestore\/paths\/data\/images\/&quot;\n\nfs = AzureMachineLearningFileSystem(path)\n\nfor image_path in fs.ls():\n    image = imageio.imread(fs.open(image_path))\n    \n    #do something with image\n\n    #now I have no idea how to save the image to like e.g.:\n    imageio.imsave(fs.open(f&quot;{image_path[:-4]}-changed.png&quot;))\n\n<\/code><\/pre>\n<p>Thanks for help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML shows status as \"Running\" when it appears to be done in the log",
        "Question_created_time":1642549573467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/700178\/azure-ml-shows-status-as-running-when-it-appears-t",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Azure ML shows status as &quot;Running&quot; when it appears to be done in the log<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"API Management - Can you import from Swagger JSON that requires HTTP Header records?",
        "Question_created_time":1675070514726,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165334\/api-management-can-you-import-from-swagger-json-th",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Using API Management - can I import from a Swagger JSON file definition AND where that endpoint requires the following injection to a header so that it can call\/retrieve that Swagger JSON?<\/p>\n<p>The API in question is actually an Azure Machine Learning Online Endpoint - and that contains a Swagger JSON definition. In order to see the definition you have to inject the following header records into the HTTP call...<\/p>\n<pre><code>Authorization: Bearer longRandomtokengeneratedbyAML12345\nazureml-model-deployment: nameofmyamlmodeldendpointdeployment\n<\/code><\/pre>\n<p>Using API Management - can I somehow import this Swagger JSON ? I can't find a way to reach the endpoint and specify the x2 header records it requires<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1675215836676,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">Neil McAlister<\/a> Thanks for posting it in Microsoft Q&amp;A. Based on the statement above, it looks like you are importing Swagger JSON to APIM via portal, CLI or PowerShell with specification URL, correct?<\/p>\n<p>If so, unfortunately that's not possible right now. There is no way to specify headers with <code>--specification-url<\/code> in <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/apim\/api?view=azure-cli-latest#az-apim-api-import\">az apim api import<\/a> (or <a href=\"https:\/\/learn.microsoft.com\/en-us\/powershell\/module\/az.apimanagement\/import-azapimanagementapi\">Import-AzApiManagementApi<\/a> - PowerShell) and you would need to download swagger JSON in your pipeline and then use it with <code>--specification-path<\/code>(check size limitation when using this parameter <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/api-management\/api-management-api-import-restrictions#openapi-specifications\">here<\/a>) or place it in another location where APIM can directly access it. <\/p>\n<p>If you are interested in this feature and like to submit feedback to our product team, please submit it via <a href=\"https:\/\/aka.ms\/apimwish\">https:\/\/aka.ms\/apimwish<\/a> and would help our product team to prioritize the features. Also, others with similar interests can upvote it too.<\/p>\n<p>Feel free to reach out if you have any other questions.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"More explanation need for Studio (classic)",
        "Question_created_time":1675192186650,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165936\/more-explanation-need-for-studio-(classic)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When I tried the new studio, it was not the same feeling of the old one. The migration is hard, I have no idea on how to do it. Even the document is lacking, no explanation of new and old. I can feel a good customer care for it. Why you did a easy decision to migrate but have no plan? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Azure ML Studio Designer with R script: package not found but I installed it on the compute instance",
        "Question_created_time":1630452066907,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/535094\/using-azure-ml-studio-designer-with-r-script-packa",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I created a compute instance and then I installed all the necessary R packages to execute a few scripts. The scripts run without issue when I'm inside an RStudio instance on that compute instance. However, when I try to have those scripts run through the Designer service using the same compute instance, R no longer recognizes the packages as being installed. Is there a way for Designer to recognize the installed R packages without resorting to using a Docker image, or the zip file method from the stackoverflow question linked below?  <\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/40632047\/azure-ml-studio-cannot-load-a-installed-package-in-r\">https:\/\/stackoverflow.com\/questions\/40632047\/azure-ml-studio-cannot-load-a-installed-package-in-r<\/a>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the fundamental idea of missing value cleanse?",
        "Question_created_time":1675098882120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165512\/what-is-the-fundamental-idea-of-missing-value-clea",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, My project\u2019s project need some data from user feedback. There will be some missing value, but when I try it I find the result is not reliable. What is the fundamental idea? What is the best setting? I just want to make the result constantly.<\/p>",
        "Question_closed_time":1675101477626,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=3d56ad4b-236f-4005-8b59-e187ae456696\">Haans<\/a> <\/p>\n<p>Thanks for reaching out to us. For Clean Missing Value component, please refer to this document - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/clean-missing-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/clean-missing-data<\/a><\/p>\n<p>Use this component to <strong>remove, replace, or infer missing values.<\/strong><\/p>\n<p>Data scientists often check data for missing values and then perform various operations to fix the data or insert new values. The goal of such cleaning operations is to prevent problems caused by missing data that can arise when training a model.<\/p>\n<p>This component supports multiple types of operations for &quot;cleaning&quot; missing values, including:<\/p>\n<ul>\n<li> Replacing missing values with a placeholder, mean, or other value<\/li>\n<li> Completely removing rows and columns that have missing values<\/li>\n<li> Inferring values based on statistical methods<\/li>\n<\/ul>\n<p>Using this component does not change your source dataset. Instead, it creates a new dataset in your workspace that you can use in the subsequent workflow. You can also save the new, cleaned dataset for reuse.<\/p>\n<p>This component also outputs a definition of the transformation used to clean the missing values. You can re-use this transformation on other datasets that have the same schema, by using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/apply-transformation\">Apply Transformation<\/a> component.<\/p>\n<p>The component returns two outputs:<\/p>\n<ul>\n<li> <strong>Cleaned dataset<\/strong>: A dataset comprised of the selected columns, with missing values handled as specified, along with an indicator column, if you selected that option.\n   Columns not selected for cleaning are also &quot;passed through&quot;.<\/li>\n<li> <strong>Cleaning transformation<\/strong>: A data transformation used for cleaning, that can be saved in your workspace and applied to new data later.<\/li>\n<\/ul>\n<p>If you don't want to the missing data to effect the result a lot, you may try mean as an option.<\/p>\n<p>I hope this helps!<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Save output model from a training job",
        "Question_created_time":1675000372393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165150\/save-output-model-from-a-training-job",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,<\/p>\n<p>I am trying to use Azure ML studio to run training jobs with python scripts using Spacy library.<\/p>\n<p>The script runs fine and I can see the logs with training progress. However I am having difficulties storing\/accessing the output model that should be created during the training. Spacy takes an &quot;output&quot; path where it can save model folders at different steps of the training. I am however unable to locate these at the end of the job.<\/p>\n<p>I tried using Outputs in the Job settings but it returns an error and I can't run the job. The Output Type is forced on &quot;Data&quot; and when I select the following to reference an output path for Azure to store the model<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/bad2cb21-0582-489a-b9cd-1c5781ef49cf?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I get an error about an unexpected &quot;JobOutputType&quot; eventhough I can't change it from the default &quot;Data&quot; in the dropdown.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/cd1f4866-d49d-46b9-aefe-ea2593e1c00d?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Any idea how to fix this and have a way to save the model somewhere during training ? I am new to Azure ML so I may not be doing things correctly<\/p>\n<p>Thank you,  <br \/>\nBest regards,<\/p>\n<p>Victor<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How databrick save ml model into Azure Storage Container?",
        "Question_created_time":1673582881903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160457\/how-databrick-save-ml-model-into-azure-storage-con",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to use mlflow package in databricks to save the model into Azure Storage.<\/p>\n<p>The Script:<\/p>\n<p><code>abfss_path='abfss:\/\/mlops@dlsgdpeasdev03.dfs.core.windows.net'<\/code><\/p>\n<p><code>project = 'test'<\/code><\/p>\n<p><code>model_version = 'v1.0.1'<\/code><\/p>\n<p><code>model = {model training step}<\/code>  <br \/>\n<code>prefix_model_path = os.path.join(abfss_path, project, model_version)<\/code><\/p>\n<p><code>model_path = prefix_model_path<\/code><\/p>\n<p><code>print(model_path) # <\/code>abfss:\/\/mlops@dlsgdpeasdev03.dfs.core.windows.net\/test\/v1.0.1<\/p>\n<p><code>mlflow.sklearn.save_model(model, model_path)<\/code><\/p>\n<p>The message is successfully save the model. <\/p>\n<p>When I check the container and file does not exist, but I am able to load model with the same path. That mean the model file saved in databricks somewhere.<\/p>\n<p>I want to know where is the model file in databricks, and how to save the model directly from databricks notebook to Azure Storage.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1673889987903,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ff486681-dc42-4832-92a7-87a687f2ec26\">@Benny Lau ,Shui Hong - Group Office  <\/a>, <\/p>\n<p>Thanks for the ask and welcome to Microsoft Q&amp;A . <\/p>\n<p>As I understand the ask here is to where the model is saved and how you can save to the blob . <\/p>\n<p>As per the document here : [https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/mlflow\/models#api-commands<\/p>\n<p>You have three option and I assume that your  model file is getting stored in the DBFS on the Azure databricks cluster .<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/4d409166-ee35-4252-9294-6e7a4140ffab?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Databricks can save a machine learning model to an Azure Storage Container using the <strong><code>dbutils.fs<\/code><\/strong> module. This module provides a set of functions for interacting with the Databricks file system (DBFS) and Azure Blob Storage. Here is an example of how to save a model to an Azure Storage Container:<\/p>\n<ol>\n<li> First, you will need to mount the Azure Storage Container to DBFS, this can be done using the <strong><code>dbutils.fs.mount<\/code><\/strong> function.<\/li>\n<\/ol>\n<pre><code>dbutils.fs.mount(\n  source='wasbs:\/\/&lt;your-container-name&gt;@&lt;your-storage-account-name&gt;.blob.core.windows.net',\n  mount_point='\/mnt\/&lt;your-mount-point&gt;',\n  extra_configs={\n    &quot;fs.azure.account.auth.type&quot;: &quot;OAuth&quot;,\n    &quot;fs.azure.account.oauth.provider.type&quot;: &quot;org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider&quot;,\n    &quot;fs.azure.account.oauth2.client.id&quot;: &quot;&lt;your-client-id&gt;&quot;,\n    &quot;fs.azure.account.oauth2.client.secret&quot;: &quot;&lt;your-client-secret&gt;&quot;,\n    &quot;fs.azure.account.oauth2.client.endpoint&quot;: &quot;https:\/\/login.microsoftonline.com\/&lt;your-tenant-id&gt;\/oauth2\/token&quot;\n  }\n)\n\n<\/code><\/pre>\n<ol>\n<li> Once the container is mounted, you can use the <strong><code>dbutils.fs.cp<\/code><\/strong> function to copy the model from the local file system to the mount point.<\/li>\n<\/ol>\n<p>dbutils.fs.cp(&quot;path\/to\/local\/model&quot;, &quot;\/mnt\/&lt;your-mount-point&gt;\/model&quot;)<\/p>\n<ol>\n<li> You can also use <strong><code>model.save()<\/code><\/strong> method to save the model in the mounted container path<\/li>\n<\/ol>\n<p>model.save(&quot;\/mnt\/&lt;your-mount-point&gt;\/model&quot;)<\/p>\n<p>Note: Be sure to replace the placeholders in the above code with the appropriate values for your use case.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why Data asset is not supported when try to create a AutoML job?",
        "Question_created_time":1673565081940,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160399\/why-data-asset-is-not-supported-when-try-to-create",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I successuffly created a data asset (folder_URI type) with uploaded imges in an Azure Blob storage (registered storage source), but when I try to create a job in Azure AutoML the Data asset shows (not supported).<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/3a257a84-d5f8-4d9c-bf1e-30035b0aae50?platform=QnA\" alt=\"select data asset\" \/><\/p>\n<p>Any idea what is the issue?<\/p>\n<p>Thanks <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cost Management budgets is not supported for this account. Please change to another scope.",
        "Question_created_time":1674956403453,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165089\/cost-management-budgets-is-not-supported-for-this",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I just started a Pay-As-You-Go account for the Azure Machine Learning training, when I tried to create a budget, I get the error that says &quot;Cost Management budgets is not supported for this account. Please change to another scope.&quot; <\/p>\n<p>I do not know what means or how to go about it.<\/p>\n<p>Please assist me<\/p>\n<p>Jonathan<\/p>",
        "Question_closed_time":1674963239873,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi Jonathan,<\/p>\n<p>Are you able to open Cost Management and set the scope to your Pay-As-You-Go subscription?   For example, open Cost Management Budgets using link below, then click on Scope and set the scope to be the correct subscription:<\/p>\n<p><a href=\"https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/%7E\/budgets\/openedBy\/AzurePortal\">https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/~\/budgets\/openedBy\/AzurePortal<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/af6ac92e-9bab-46c3-ab9e-1c03e404897e?platform=QnA\" alt=\"azure budget scope\" \/><\/p>\n<p>If the above is useful please click Accept Answer.<\/p>\n<p>Thanks.<\/p>\n<p>-TP<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to open the dataset exported from Azure ML Designer?",
        "Question_created_time":1674530511673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1163567\/how-to-open-the-dataset-exported-from-azure-ml-des",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I authored a simple pipeline in Azure ML Designer that does the following:<\/p>\n<ol>\n<li> Imports a dataset from my datastore.<\/li>\n<li> Edits the metadata for 2 columns of the total 480 to ensure they're labeled as categorical.<\/li>\n<li> Performs a Filter Based Feature Selection to obtain top 30 features of the dataset on the target.<\/li>\n<li> Exports Filtered Dataset to a .csv in my storage container.<\/li>\n<li> Exports Features to a .csv in same path as #4.<\/li>\n<\/ol>\n<p>However, when the pipeline completes, I cannot find either of the .csv files. Instead, there are two files--Block blob types--both titled as I wrote them in the Export Data parameter for 'Path' field. Additionally, from this pipeline, there are 6 additional files created with the following filenames:<\/p>\n<ul>\n<li> meta.yaml<\/li>\n<li> samples.json<\/li>\n<li> data.dataset<\/li>\n<li> data.dataset.parquet<\/li>\n<li> data.visualization<\/li>\n<li>  schema\/schema.json<\/li>\n<\/ul>\n<p>None of these are the csv file I requested. I very well could have something set incorrectly as this is the first time I've used this component of Azure. But the parameters seemed pretty intuitive so I don't understand why a .csv file isn't created in the path I submitted below. Can someone please help me?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/4f61928e-2afc-459e-bd03-e8acd1c53798?platform=QnA\" alt=\"pipeline snip\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I pass a tabular dataset to a script using the arguments array?",
        "Question_created_time":1674642925113,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164090\/how-can-i-pass-a-tabular-dataset-to-a-script-using",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I want to pass the path of a tabular dataset to a python script in the PythonScriptStep but then I don't want to use the Run.get_context() from azure in the python script. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Explanations are not available from Models page in the Azure ML studio",
        "Question_created_time":1674643432096,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164092\/explanations-are-not-available-from-models-page-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to view the explanations from Models tab in Azure ML studio, but it is empty. The model was created from AutoML pipeline using azure-python-sdk V1.<\/p>\n<p>I want to know what I can do so that explanations can appear when we go to Model details page.<\/p>\n<p>Model page below:<\/p>\n<p>=============<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/b93f48e2-ab97-47c0-b462-a864b6cff3db?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Explanation page:<\/p>\n<p>============<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a5937b9f-e399-4c11-a63e-733ab28a5af1?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to load .ipynb file or terminal in Azure Machine Learning Workspace",
        "Question_created_time":1674455749663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1163217\/unable-to-load-ipynb-file-or-terminal-in-azure-mac",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hey all,<\/p>\n<p>Our team experienced the issue below. To summarize, I cannot open .ipynb files or the terminal in my azure machine learning workspace. <\/p>\n<p>This also happens with new created clusters and while using different Browsers and private modes. <\/p>\n<p>Can anyone give suggestions\/guidance on how to resolve the issue?<\/p>\n<p>I also get a lot of Failed to load resource errors.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/46bb729a-dd22-4a1f-9f81-e9a148670c45?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"export dataset to csv - Azure Machine Learning",
        "Question_created_time":1674827451026,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164823\/export-dataset-to-csv-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have a python script and a dataframe with the forceast created by azure ml model.<\/p>\n<p>I would like to write this dataframe to csv under the specific location in Azure Blob Storage attached to Azure Machine Learning service. Let's say the file is called my_file.csv<\/p>\n<p>and I need this to be saved on:<\/p>\n<p>my_cointainer\/my_folder\/my_file.csv<\/p>\n<p>This is what i tried:<\/p>\n<pre><code class=\"lang-python\">df.to_csv(r'https:\/\/storagename.blob.core.windows.net\/my_cointainer\/my_folder\/my_file.csv', sep=';', index=False)\n<\/code><\/pre>\n<p>but got an error:<\/p>\n<p><strong>&quot;HTTPError: HTTP Error 409: Public access is not permitted on this storage account.&quot;<\/strong><\/p>\n<p>That's odd, because i can read the files from this storage without passing any credentials to the code. Also azure ml model generates meta-data which are saved there. So i guess i am doing sth wrong.<\/p>\n<p>How can I do this ideally by avoiding passing the credentials to code?<\/p>\n<p>Alternatively, can I save the dataframe as dataset and then export this dataset to csv under specific location?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get Form Recognizer for Receipts to return Payment Method",
        "Question_created_time":1644684842353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/733014\/how-to-get-form-recognizer-for-receipts-to-return",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Most receipts include a payment method.  This payment method is very useful when automating receipt processing and integration with accounting systems (Even though for credit cards it is often truncated).  It does not appear to be one of the standard fields on template.  Can I teach it to extract this additional field?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Form recognizer studio cotentsourcenotaccessible when training custom model",
        "Question_created_time":1647578196813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/777373\/form-recognizer-studio-cotentsourcenotaccessible-w",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Following the guide here (<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/applied-ai-services\/form-recognizer\/quickstarts\/try-v3-form-recognizer-studio#configure-cors<\/a>)  I have creates a subscription, resourcegroup, form recognizer, storage account and blob. The container is setup as anonymous read access and  I've also set up CORS, which is in the same guide.  I've uploaded my pdf and can label it in the studio, but when I try and train the model I get this error:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/184392-image.png?platform=QnA\" alt=\"184392-image.png\" \/>    <\/p>\n<p>I suspect it map be a SAS token setting, but there is nowhere in studio I can find to modify this.  The options are greyed out.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/184317-image.png?platform=QnA\" alt=\"184317-image.png\" \/>    <\/p>\n<p>Is it not possible to train a custom model in studio v3.0 (preview)?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML realtime endpoint provisioning fail can't find azureml-studio",
        "Question_created_time":1654010449827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/871653\/azure-ml-realtime-endpoint-provisioning-fail-cant",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have been following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer\">this tutorial<\/a> and been trying to deploy the model to real-time endpoint but the provisioning fails with the following logs:<\/p>\n<pre><code>Exception in worker process  \nTraceback (most recent call last):  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker  \n    worker.init_process()  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process  \n    self.load_wsgi()  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi  \n    self.wsgi = self.app.wsgi()  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi  \n    self.callable = self.load()  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load  \n    return self.load_wsgiapp()  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp  \n    return util.import_app(self.app_uri)  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app  \n    mod = importlib.import_module(module)  \n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module  \n    return _bootstrap._gcd_import(name[level:], package, level)  \n  File &quot;\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"InvalidContentLength The input image is too large. Refer to documentation for the maximum file size. JPEG 5MB",
        "Question_created_time":1647524366683,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/776406\/invalidcontentlength-the-input-image-is-too-large",
        "Question_score_count":3,
        "Question_answer_count":3,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,   <br \/>\nI have been having this issue with JPEG files since Studio launched. On 2.1-preview it is working fine, but with newer API I am getting image too large error.  <br \/>\nI have tried changing between JPEG\/JPG\/Bitmap and such files. Also cropping the image to less than 5MB, but the issue seems to persist. From documentation max file size is 50MB, this is 1 page, 5MB 3000x4000 pixel image.  <br \/>\nTried analyzing with studio and through REST API, still same error.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"An error occured while retrieving the signin link",
        "Question_created_time":1640620798367,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/676437\/an-error-occured-while-retrieving-the-signin-link",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to login using bot framework. Everything goes well, up to the moment I click the &quot;Sign-in&quot; button on my &quot;auth&quot; card. Sign in dialog model open and it show the error  <\/p>\n<pre><code> {\n   &quot;error&quot;: {\n     &quot;code&quot;: &quot;ServiceError&quot;,\n     &quot;message&quot;: &quot;An error occured while retrieving the signin link&quot;\n    }\n }\n<\/code><\/pre>\n<p>MainDialog.ts  <\/p>\n<pre><code>  this.addDialog(new OAuthPrompt(OAUTH_PROMPT, {\n            connectionName: process.env.connectionName,\n            text: `Hi! I'm Bot - welcome to our app for Microsoft Team!&quot;,\n            I'm here to help you manage your ticket`,\n            timeout: 300000,\n            title: 'Sign In'\n        }))\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure guidance video out of date in YouTube",
        "Question_created_time":1659301109740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/949113\/azure-guidance-video-out-of-date-in-youtube",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>hello, I was doing some search in the internet about azure machine learning, I found videos published in YouTube but out of date. Please update it <\/p>",
        "Question_closed_time":1659316793043,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6ec12307-1a06-4236-b249-3fd890a3f2a1\">@matsuoka  <\/a>     <\/p>\n<p>Thanks for the feedback, we are aware of this issue and have forwarded the feedback to product group. Sorry for the experience.    <\/p>\n<p>Actually some of the videos are for some technicle event, I will suggest content team to deliver the video with more version info so that future audience will not be confused.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Newbie Question - How can I gauge runtime for an Azure Auto ML model?",
        "Question_created_time":1674240436416,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1162867\/newbie-question-how-can-i-gauge-runtime-for-an-azu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am a college student new to machine learning and Azure.  I have kicked off my first Azure Auto ML product using a dataset of energy data (CSV file, 850,000  rows, 10 columns).  Is there any way or me to figure out how long the process will run?<\/p>\n<p>I set the configuration Exit Time at one hour, but my current model run time is already over two hours.  <\/p>",
        "Question_closed_time":1674240606010,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The runtime for an Azure Auto ML model can vary depending on a number of factors, including the size and complexity of the dataset, the number of models being trained and evaluated, and the specific configuration settings you have chosen.<\/p>\n<p>In your case, the dataset you are using is quite large with 850,000 rows and 10 columns, which can add to the runtime. Also, you have set an Exit time of 1 hour, but it looks like the model is taking longer than that to run.<\/p>\n<p>It's also possible that the runtime is affected by the specific machine learning algorithm or algorithms that you have chosen to use, as some algorithms can be more computationally intensive than others.<\/p>\n<p>While it's not always possible to predict the exact runtime for an Azure Auto ML model, you can monitor the progress of the model training and evaluating process in the Azure Machine Learning Studio to get an idea of how long it is taking. Additionally, you can also check the &quot;Duration&quot; column of the &quot;Runs&quot; section to see the total runtime for each run of the model. You can also use the SDK to monitor the status of the run and log the run duration.<\/p>\n<p>It's also worth considering to scale up the compute resources if you are running into performance issues.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"issue with encoding while creating dataset",
        "Question_created_time":1674818458130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1164780\/issue-with-encoding-while-creating-dataset",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to create Azure Machine Learning dataset from csv file  on the blob storage.<\/p>\n<p>The csv has polish language specials characters. For simplicity let it has 1 column with 2 value<\/p>\n<p>col1<\/p>\n<p>sprzeda\u017c<\/p>\n<p>przemys\u0142<\/p>\n<p>Assuming the csv file is called &quot;my_file.csv&quot; here is a code I am using to read this csv.<\/p>\n<pre><code class=\"lang-python\">ws = Workspace.from_config()\ndatastore = Datastore.get(ws, 'azure_ml')\ndataset = Dataset\\\n    .Tabular.from_delimited_files(path = datastore.path('my_file.csv'), encoding='ISO-8859-2')\\\n    .to_pandas_dataframe()\n<\/code><\/pre>\n<p>And here is the error I got:<\/p>\n<p><em><strong>&quot;Message: Invalid encoding 'ISO-8859-2'. The supported encodings are 'utf8', 'iso88591', 'latin1', 'ascii', 'utf16', 'utf32', 'utf8bom' and 'windows1252'&quot;<\/strong><\/em><\/p>\n<p>The problem is none of these supported encoding types is able to read correctly the language specyfic characters. For instance if I tried to read with encoding = 'windows1252'<\/p>\n<p>instead of &quot;sprzeda\u017c&quot; it gives me:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/d6292925-498d-4746-ba6b-f672c0a95caa?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio can't generate job when datastore is used as input; failed string validation? Also, code files not being loaded on job.",
        "Question_created_time":1673751364376,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160904\/azure-ml-studio-cant-generate-job-when-datastore-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>The error I get:  <br \/>\n<strong>Job submission error<\/strong>  <br \/>\nUserError: Unexpected JobInputType in request body: [UriFolder]. Supported types: literal,uri_file,uri_folder,mltable,custom_model,mlflow_model,triton_model.  <br \/>\n<strong>Trace ID\u00a0:<\/strong>\u00a0d32c0fca-df85-4679-854d-f9b76989bb5c<strong>Client request ID\u00a0:<\/strong>\u00a0be63cb66-373b-457f-82d5-43d6dd132eb6<strong>Service request ID\u00a0:<\/strong>\u00a03c5afbfe-2994-48f8-8379-d2868eefb878  <\/p>\n<p>It seems to me that the form provides the string &quot;UriFolder&quot; to tell what type of data is being submitted, but it fails validation because it's checked against &quot;uri_folder&quot;. My best guess is that the Azure ML Studio frontend is providing an invalid string for the backend, which fails validation.<\/p>\n<p>More details about my issue:  <br \/>\nI managed to load my code into blob storage. Now I'm trying to create a job, but whenever I add to the job any input or output which uses a Datastore (such as workspaceworkingdirectory where my data is, or a blob), the job fails to generate. I'm using Azure ML Studio (web interface).<\/p>\n<p>Settings when creating the input for the job: <\/p>\n<p>Input type = Data  <br \/>\ndata type = folder  <br \/>\ndata source = datastore  <br \/>\nselected datastore = workspaceworkingdirectory  <br \/>\npath to data = Users\/me\/data\/** (chosen using the &quot;browse&quot; button, so it must be correct)  <br \/>\ninput can be mounted in any way (read only, download, direct), I always get the same error. Distributed training settings also don't matter, anything I choose gives the same error.<\/p>\n<p>Edit: I found yet another error in Azure ML Studio.<\/p>\n<p>To circumvent the error reported above, I've painstakingly uploaded all my data to the blob storage container, so I wouldn't have to use any inputs or outputs to create the job. My strategy worked, the job was created, but it fails at start with the error message &quot;detector.py: file not found&quot;. I've added an &quot;ls -R&quot; to the beginning of the command that is executed to start the job, and then checked the logs. The &quot;ls&quot; shows that there are absolutely no files on the path where the terminal is started, only 4 empty folders: azureml-logs, logs, outputs, user_logs.  <br \/>\nI've tried uploading the code from my PC through the form when creating the job, it takes longer to create the job because the files are being uploaded, but I still get the same error.<\/p>\n<p>Where are my files going? Why I don't get an error code telling me there was a problem accessing\/transfering the data? Or is the data actually being transfered, but the terminal is pointing to the wrong folder? The yaml file generated by the web GUI is suspiciously dry, with no mentions to code path or code files...<\/p>\n<p>Are these two bugs in the Azure ML Studio known? Do you maybe have any open positions for a test engineer? ;-)  <br \/>\nBoth problems I've reported happen in the same page shown in the following screenshot.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/6d8daf68-26f3-4fdb-9b5c-6c03680a86f4?platform=QnA\" alt=\"User's image\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I import existing data labels to Azure Machine Learning Studio?",
        "Question_created_time":1625099167257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458706\/how-can-i-import-existing-data-labels-to-azure-mac",
        "Question_score_count":3,
        "Question_answer_count":8,
        "Question_comment_count":2,
        "Question_body":"<p>I have a dataset on the Azure Machine Learning Studio, which is about 1200 images. I also have a tab-delimited text file that specifies the file name, i.e. &quot;xxyyzz.png&quot;, and the category name i.e. &quot;dog&quot;.  <\/p>\n<p>The data labeling tools in the dashboard seem to be built with the intention of labeling the images by hand. How can I apply the labels I that I already have to the data in my dataset?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot access Azure Storage File Shares from Azure Machine Learning Notebook (Python SDK v2)",
        "Question_created_time":1672670113473,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1148536\/cannot-access-azure-storage-file-shares-from-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":11,
        "Question_body":"<p>When I try to access Azure Storage File Shares from Azure Machine Learning Notebook, I get the following error.    <\/p>\n<p> <strong>1. Error Message<\/strong>    <br \/>\nDataAccessError(PermissionDenied(Some(NoIdentityOnCompute)))    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/275396-image.png?platform=QnA\" alt=\"275396-image.png\" \/>    <\/p>\n<p> <strong>2. What I did<\/strong>    <br \/>\nI executed the following code from Notebook to get image data stored in the Azure Storage File Shares.    <br \/>\nSince the datasource is File Shares, I used &quot;abfss&quot; as the type, and followed the instructions written in the document (<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-read-write-data-v2?tabs=python<\/a>)    <\/p>\n<pre><code>from azure.ai.ml import command  \nfrom azure.ai.ml import UserIdentityConfiguration  \nfrom azure.ai.ml import Input  \n  \ngpu_compute_target = &quot;gpu-cluster-rainbow&quot;  \ncustom_env_name = &quot;keras-env&quot;  \nweb_path = &quot;abfss:\/\/[file_shared_name]@[storage_account_name].dfs.core.windows.net\/[file_shared_name]\/[path]\/&quot;  \n  \njob_env = ml_client.environments.get(name=custom_env_name, version=str(len(list(ml_client.environments.list(name=custom_env_name)))))  \njob = command(  \n    inputs=dict(  \n        data_folder=Input(type=&quot;uri_folder&quot;, path=web_path),  \n    ),   \n    compute=gpu_compute_target,  \n    environment=f&quot;{job_env.name}:{job_env.version}&quot;,  \n    code=&quot;.\/src\/&quot;,  \n    command=&quot;python keras_image_preprocessing.py --data-folder ${{inputs.data_folder}}&quot;,  \n    experiment_name=&quot;keras-images-preprocessing-kaggle&quot;,  \n    display_name=&quot;keras-images-preprocessing&quot;,  \n)  \nml_client.jobs.create_or_update(job)  \n<\/code><\/pre>\n<p>as per now I am allowing public access for the storage.    <\/p>\n<p> <strong>3. I also tried...<\/strong>    <br \/>\nI also tried to make a data store using SDK v2, refering to the following document.    <\/p>\n<p><a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Csdk-azfiles-sas%2Csdk-adlsgen1-identity-access<\/a>    <\/p>\n<p>But, this time I also stuck because I couldn't import the following package.    <\/p>\n<pre><code>from azure.ai.ml.entities._datastore.credentials import SasTokenCredentials  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/275389-image.png?platform=QnA\" alt=\"275389-image.png\" \/>    <\/p>\n<p>I was assuming this import will succeed because I am using the Python SDK v2, but only the above import is failing.    <br \/>\nI will also show the full piece of code (Both Sas Token, Account key is not working)    <\/p>\n<pre><code>from azure.ai.ml.entities import AzureFileDatastore  \nfrom azure.ai.ml.entities._datastore.credentials import SasTokenCredentials  \nfrom azure.ai.ml import MLClient  \n  \nstore = AzureFileDatastore(  \n    name=&quot;file-sas-example&quot;,  \n    description=&quot;Datastore pointing to a file share using sas token.&quot;,  \n    account_name=&quot;rainbowmlstorage&quot;,  \n    file_share_name=&quot;xxxx&quot;,  \n    # credentials=SasTokenCredentials(  \n    #     sas_token=&quot;?sv=xxxxxxxxxxxx&quot;  \n    # ),  \n    credentials={  \n        &quot;account_key&quot;: &quot;xxxx&quot;  \n    },  \n)  \n<\/code><\/pre>\n<p>Would somebody help me?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does compute cluster & Endpoints costs if we dont delete after use ?",
        "Question_created_time":1617894953567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349617\/does-compute-cluster-endpoints-costs-if-we-dont-de",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I'm aware that running <strong>compute Instance<\/strong> costs us for the number of hours we used. So, we stop it when ever we don't need it.  <\/p>\n<p>Similarly, does <strong>compute cluster<\/strong> &amp; <strong>Endpoints<\/strong> also costs us if we do not delete them after use?  <\/p>\n<p>Thanks  <br \/>\nBhaskar  <\/p>",
        "Question_closed_time":1617896011617,
        "Answer_score_count":9.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=7c0d4f65-2f38-4fdd-91df-9f513e0321c1\">@Bhaskar11  <\/a>     <\/p>\n<p>When a <strong>compute cluster is idle<\/strong>, it autoscales to 0 nodes, so you don't pay when it's not in use. A compute instance is always on and doesn't autoscale. You should stop the compute instance when you aren't using it to avoid extra cost.    <br \/>\n<strong>refer -<\/strong> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target<\/a>    <\/p>\n<p>If the Answer is helpful, please click <code>Accept Answer<\/code> and <strong>up-vote<\/strong>, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Publishing pipeline endpoints with SDK V2",
        "Question_created_time":1673366197177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1159059\/publishing-pipeline-endpoints-with-sdk-v2",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,<\/p>\n<p>I created a basic two step pipeline with v2 SDK. It takes two inputs, first and last name. The first step prints Hello {first name}, and the second step prints Bye {last name}.<\/p>\n<p>I ran this pipeline successfully giving my name as inputs, and then clicked on publish pipeline. That was successful, but I notice that now my name is being considered as a default value of the inputs. I do not want that, and I want the inputs to be mandatory user inputs.<\/p>\n<p>In other words, I want to know <strong>how can I publish the pipeline without any default values, and not a particular run of the pipeline<\/strong>?<\/p>\n<p>To clarify why I do not want default values as inputs of one run, this is a dummy pipeline. But the real pipelines can take many things, possibly sensitive, as inputs, and I do not want those to be available to everyone as default value.<\/p>\n<p>Also, a related question, <strong>is there a way to programmatically publish a pipeline endpoint<\/strong>?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML designer - Error in scoring W&D Recommender when using All items or Unrated items",
        "Question_created_time":1673786197753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160959\/azure-ml-designer-error-in-scoring-w-d-recommender",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Starting from the example pre-build of the Restaurant Ratings (Wide and Deep Recommender) pipeline:<\/p>\n<ol>\n<li> I trained the model using the score setting &quot;From rated items (for model evaluation)<\/li>\n<li> When job finished succesfully I created an online-inference pipeline as shown below (auto-created + added web serivce input that the designer &quot;forgot&quot; to add automatically\n   <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/79c847a0-72dc-485b-9857-6df744bcbc4d?platform=QnA\" alt=\"Screenshot 2023-01-15 at 13.06.28\" \/>   3. <\/li>\n<li> Set the scoring setting of the component to &quot;From unrated items&quot; to suggest items to &quot;new users&quot;, following the documentation I had to connect to third port of the component the ratings dataset to &quot;filter&quot; out the knows users already trained<\/li>\n<li> saved and submitted his pipeline I get the error:<\/li>\n<\/ol>\n<p>azureml.studio.internal.error.LibraryExceptionError: Unknown library exception: type object 'object' has no attribute 'dtype'. Please contact product team by submit a feedback. You can submit a feedback by clicking the face icon on top right corner of the page. . <\/p>\n<p>ModuleExceptionMessage:Library Error - AttributeError: type object 'object' has no attribute 'dtype'<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9580bdb2-476d-4415-9576-a61c14138b41?platform=QnA\" alt=\"Screenshot 2023-01-15 at 13.34.37\" \/><\/p>\n<p>The above was not happening in December.<\/p>\n<p>I've also try to get the model in datastore and run the score.py in a Jupyter notebook getting the same error.<\/p>\n<p>some libraries are not correctly configured in the Studio I believe, any help on the above?<\/p>\n<p>Thanks,<\/p>\n<p>AGA<\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dcb15e13-2a8c-40fe-b3e5-2cb2cb72369a?platform=QnA\">std_log.txt<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How we can do NLP by Azure machine learning",
        "Question_created_time":1673999637410,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1161775\/how-we-can-do-nlp-by-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As title, I want to seek out a way to develop NLP project in Azure machine learning, any guidance? No document or sample found.<\/p>",
        "Question_closed_time":1674000433630,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello James,<\/p>\n<p>There are several ways in Microsoft to develop NLP, one is using Azure Cognitive Service - Language, one is using Apache Spark as a customized NLP framework.<\/p>\n<p>In Azure, Spark services like Azure Databricks, Azure Synapse Analytics, and Azure HDInsight provide NLP functionality when you use them with Spark NLP. Azure Cognitive Services is another option for NLP functionality. To decide which service to use, consider these questions:<\/p>\n<ul>\n<li> Do you want to use prebuilt or pretrained models? If yes, consider using the APIs that Azure Cognitive Services offers. Or download your model of choice through Spark NLP.<\/li>\n<li> Do you need to train custom models against a large corpus of text data? If yes, consider using Azure Databricks, Azure Synapse Analytics, or Azure HDInsight with Spark NLP.<\/li>\n<li> Do you need low-level NLP capabilities like tokenization, stemming, lemmatization, and term frequency\/inverse document frequency (TF\/IDF)? If yes, consider using Azure Databricks, Azure Synapse Analytics, or Azure HDInsight with Spark NLP. Or use an open-source software library in your processing tool of choice.<\/li>\n<li> Do you need simple, high-level NLP capabilities like entity and intent identification, topic detection, spell check, or sentiment analysis? If yes, consider using the APIs that Cognitive Services offers. Or download your model of choice through Spark NLP.<\/li>\n<\/ul>\n<p>More information I would invite you to check on this document - [https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/data-guide\/technology-choices\/natural-language-processing#capability-matrix<\/p>\n<p>Please choose one according to your scenario, please let us know if you have any questions.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"delete compute instance by python sdk",
        "Question_created_time":1672862465810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1151897\/delete-compute-instance-by-python-sdk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>hello    <\/p>\n<p>I request your help to configure the deletion of the azure machine learning compute instance after the job is finished     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use an environment to run code directly from my workspaceworkingdirectory ?",
        "Question_created_time":1671255870623,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1132641\/how-to-use-an-environment-to-run-code-directly-fro",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I have some code which runs fine on my local machine in a conda environment, but it's super slow (as expected, because I don't have a decent GPU).    <\/p>\n<p>I got to Azure ML Studio, got a subscription, made a workspace with all assets needed. Also made a compute cluster with a healthy amount of GPU.    <br \/>\nBased on image mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04 , I built an environment in Azure with the ancient Python 3.6.13, keras 2.1.6 and tensorflow 1.15.5 which are necessary to run my code, and the environment was built without errors.    <br \/>\nI've managed to put all the data and code under my workspaceworkingdirectory. I even created a Data Asset that points directly to it.    <\/p>\n<p>If I were on my machine, I would now open Anaconda Prompt and do this:    <\/p>\n<p>cd myfolder\/myscript    <br \/>\nconda activate myenv    <br \/>\npython script.py &lt;a bunch of parameters&gt;    <\/p>\n<p>However, in Azure ML Studio I can't do the same directly from the terminal (outside of the enviroment) because of the dependencies. I also can't run it from the environment I built, because it's not listed there. If I open a terminal and type conda env list, I get this:    <\/p>\n<p>base                     \/anaconda    <br \/>\nazureml_py310_sdkv2      \/anaconda\/envs\/azureml_py310_sdkv2    <br \/>\nazureml_py38          *  \/anaconda\/envs\/azureml_py38    <br \/>\nazureml_py38_PT_TF       \/anaconda\/envs\/azureml_py38_PT_TF    <\/p>\n<p>As simple as this issue may seem, I've been struggling for days to get this to run on Azure ML, and I haven't progressed at all. If anyone could point me in the right direction, I'd be immensely grateful.    <\/p>\n<p>Edit: Let me clarify one thing: on the Azure ML Studio, if I click on &quot;notebooks&quot; and get the terminal I used to download my code and data to workspaceworkingdirectory, and use that same terminal to invoke conda, I can create an environment and run my code with the same commands I mentioned above, BUT; that environment can't access any GPU acceleration (probably the plain terminal feature is missing the CUDA files, which are present on the docker image used by Azure to generate the proper Conda environment as I initially described). Also that environment manually created at the terminal doesn't seem to be persistent, I had to rebuild it from scratch when I switched computing instances and I might even need to rebuild again every time I restart that compute instance (haven't tested it yet because it's irrelevant unless I get the CUDA acceleration to run)    <\/p>\n<p>So, my goal is to get the image-based environment to access the workspaceworkingdirectory and run code there with R+W permissions to write the output files, OR to get cuda working on this environment I built from scratch on the terminal. Also, I need to see the tensorboard in either case.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is Machine Learning Studio included in my subscription?",
        "Question_created_time":1673619039086,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160625\/is-machine-learning-studio-included-in-my-subscrip",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi!<\/p>\n<p>I have a Pay-As-You-Go account (with monthly amounts of free services) and want to create\/deploy a machine learning model in Azure ML Studio. Is it included in my subscription or do I have to pay more? I'm asking because in order to start working in ML Studio, I need to create a 'compute instance' and there is no free option.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":1673651290070,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a>@Marco <\/a>, Thanks for using Microsoft Q&amp;A Platform.  <\/p>\n<p>There are no additional costs associated with using Machine Learning service under a <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/purchase-options\/pay-as-you-go\/\">Pay-as-you-go<\/a> subscription.  But, for creating a compute instance it charges since it run on Azure infrastructure. If you have any doubts, always use the <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\">Azure pricing calculator<\/a> to get an estimate of the costs before you create anything.<\/p>\n<p>Please visit here to know more information on <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/\">Machine Learning pricing<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-plan-manage-cost\">cost management<\/a>.<\/p>\n<p>I hope this helps.<\/p>\n<p>Regards,\nVasavi<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Cannot create resourse group under Azure for Students",
        "Question_created_time":1673533128806,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1160258\/cannot-create-resourse-group-under-azure-for-stude",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I was trying to go through a tutoria on Azure Machine learning service and suddenly I encountered a problem with creating a resource group with Azure for Students subscribtion.  <\/p>\n<p>In addition, my friend who has Azure for Students as well doesn't have such problem.<\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a925e74b-502a-4e40-9278-79e25d22bc52?platform=QnA\">azureProblem1.PNG<\/a><\/p>\n<p>What's wrong?<\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/47f2c67c-9be4-474b-981b-5137a924d789?platform=QnA\">azureProblem2.PNG<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom NER detects all the numbers in a text as Invoice ID even though only 5********* and ****A******** numbers were only used  for training the invoice Ids",
        "Question_created_time":1672318385567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1145672\/custom-ner-detects-all-the-numbers-in-a-text-as-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>We have created a lis tof template texts for detecting invoice ids and we use the number series in question title to train a Custom NER model but still it detects numbers of any length as invoice ID as well combinations of number text and symbol as invoice ids. Any suggestions would be highly appreciated which would help here to improve the model so that numbers only in specific range or pattern provided in the training gets extracted as valid invoice ids<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issue in my MLOPs CD pipeline.",
        "Question_created_time":1649140550093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/800334\/issue-in-my-mlops-cd-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Deploying my model to ACI takes forever and fails without any error message. In the ML workspace, the status of the deployed endpoint is unhealthy. I checked common errors while deployment but could not solve the problem. Pleas help. The deployment is never successful and it keeps running.<\/p>",
        "Question_closed_time":1649231254493,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><em>anonymous user<\/em> Thanks for the question. Could you clarify the architecture of your model deployment? In particular, are you using a custom docker container for it?  Also, usually ACI would be used for testing, but I'd recommend investigating AKS for production model deployment.     <\/p>\n<p> I would deploy the container into a local machine\/VM with Docker to see the exact detail error message which you don't see via ACI deployment.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"I got error in inference pipeline in Azure machine Learning notebook",
        "Question_created_time":1622619661983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/418869\/i-got-error-in-inference-pipeline-in-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/101608-ekran-goruntusu-3.png?platform=QnA\" alt=\"101608-ekran-goruntusu-3.png\" \/>    <\/p>\n<p>\u0131 am learning machine learning on microsoft learn and \u0131 have problem with inference pipeline    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/tr-tr\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline\">inference-pipeline<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to save algorithm results from scoring script?",
        "Question_created_time":1673271903383,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1156970\/how-to-save-algorithm-results-from-scoring-script",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>How can I save the results of the algorithm to a file in the scoring script?    <br \/>\nI am using AzureML v1 and python sdk.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why can't I create a vGPU instance in Azure ML Studio",
        "Question_created_time":1673290854303,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1157379\/why-cant-i-create-a-vgpu-instance-in-azure-ml-stud",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using a personal account and all vGPU is unavaliable to me (all regions)? I'm using a Visa (Pay monthly) subscriptions. Why is that?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"All possible options to import exising Azure ML models to newly created Azure ML environment!",
        "Question_created_time":1672980780277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1153982\/all-possible-options-to-import-exising-azure-ml-mo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>There is a requirement -    <\/p>\n<ol>\n<li> ML models are created by third party vendors in their Azure environment. ML models will be readily available for consumption.    <\/li>\n<li> As an admin, we need to setup new environment for Azure machine learning for our organization.    <\/li>\n<li> Once point#2 is completed, need to import ML models from point#1 to the newly setup ML environment.    <\/li>\n<\/ol>\n<p>Can you please let us know all possible ways to do this?    <\/p>\n<p>Thank You!    <\/p>\n<p>Regards,    <br \/>\nPreetha    <\/p>",
        "Question_closed_time":1673007028250,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=9dd3fdca-62ad-43a4-9e40-b142520a64a4\">@Preetha Rajesh  <\/a> I believe the models are trained in another workspace or subscription that are used by your company which you would need to use in your workspace or environment.    <\/p>\n<p>The common scenario is to register the models in your workspace by providing a valid path or through studio\/cli\/SDK. This <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local%2Ccli\">document<\/a> should help you setup the same.    <br \/>\nThe newer or a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-share-models-pipelines-across-workspaces-with-registries?tabs=cli\">preview version<\/a> of sharing the models across workspaces is available to use, you can try the same and check if this works for your organization.    <\/p>\n<p>Once the models are registered in your workspace, the usage of the same in an environment is pretty much the same as using the models you have trained in your workspace. Initially, you might want to use the UI but the SDK and CLI can also be used for automating if you have large number of models from your vendors.     <\/p>\n<p>The documents referenced contains all possible ways to achieve this, I hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to read a data file in RStudio from Azure data lake (storage account)",
        "Question_created_time":1671791706273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1140524\/how-to-read-a-data-file-in-rstudio-from-azure-data",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I am able to upload and download data file in RStudio from Azure data lake (storage account) using AzureAuth and AzureStor packages with service principal Authentication.    <\/p>\n<p>I want to read a data file in RStudio from Azure data lake (storage account).    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot access Azure Storage File via a DataStore",
        "Question_created_time":1672837917353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1151289\/cannot-access-azure-storage-file-via-a-datastore",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p><strong>(1) Overview of Error<\/strong>    <br \/>\nWhen I try to access Azure Storage File Shares from Azure Machine Learning Notebook, I get the following error.    <\/p>\n<p>Attachment : 1_Error.JPG <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/276112-1-error.jpg?platform=QnA\" alt=\"276112-1-error.jpg\" \/>    <\/p>\n<p>Error Message : DataAccessError(NotFound)    <\/p>\n<p><strong>(2) Detail of my Notebook<\/strong>    <br \/>\nThanks to <a href=\"\/users\/na\/?userid=bc467a93-95da-4dea-bc82-06951da4cfad\">@romungi-MSFT  <\/a> in <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1148536\/cannot-access-azure-storage-file-shares-from-azure.html\">this post<\/a>, I succeeded creating a 'AzureFileDatastore' using the following piece of code.    <\/p>\n<p>===    <\/p>\n<pre><code>from azure.ai.ml.entities import AzureFileDatastore  \nfrom azure.ai.ml.entities._credentials import (  \n     AccountKeyConfiguration,  \n     CertificateConfiguration,  \n     NoneCredentialConfiguration,  \n     SasTokenConfiguration,  \n     ServicePrincipalConfiguration,  \n )  \nfrom azure.ai.ml import MLClient  \n  \nstore = AzureFileDatastore(  \n    name='file_sas_example',  \n    description='Datastore pointing to a file share using sas token.',  \n    account_name='rainbowmlstorage',  \n    file_share_name='xxxxxxxxx',  \n    credentials=SasTokenConfiguration(  \n        sas_token='xxxxxxxxxxxxxxxxxx'  \n    ),  \n)  \nml_client.create_or_update(store)  \n<\/code><\/pre>\n<p>===    <br \/>\nAttachment :  2_Succeed_creating_DataStore.JPG <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/276099-2-succeed-creating-datastore.jpg?platform=QnA\" alt=\"276099-2-succeed-creating-datastore.jpg\" \/>    <\/p>\n<p><strong>(3) Access to the data via DataStore<\/strong>    <br \/>\nFinally, I get the error shown on top when I ran the following piece of code from Notebook.    <\/p>\n<p>===    <\/p>\n<pre><code>from azure.ai.ml import command  \nfrom azure.ai.ml import UserIdentityConfiguration  \nfrom azure.ai.ml import Input  \n  \ngpu_compute_target = 'gpu-cluster-rainbow'  \ncustom_env_name = 'keras-env'  \n  \n# Refered to this(https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-read-write-data-v2?tabs=python) document.   \n# And tried to make it like 'azureml:\/\/datastores\/(data_store_name)\/paths\/(path)'  \nweb_path = 'azureml:\/\/datastores\/file_sas_example\/paths\/data\/test\/'  \n  \njob_env = ml_client.environments.get(name=custom_env_name, version=str(len(list(ml_client.environments.list(name=custom_env_name)))))  \njob = command(  \n    inputs=dict(  \n        data_folder=Input(type='uri_folder', path=web_path),  \n    ),   \n    compute=gpu_compute_target,  \n    environment=f'{job_env.name}:{job_env.version}',  \n    code='.\/src\/',  \n    command='python keras_image_preprocessing.py --data-folder ${&lt;!-- --&gt;{inputs.data_folder}}',  \n    experiment_name='keras-images-preprocessing-kaggle',  \n    display_name='keras-images-preprocessing',  \n)  \n  \nml_client.jobs.create_or_update(job)  \n<\/code><\/pre>\n<p>===    <br \/>\nAttachment : 3_Error_when_access_Datastore.JPG' <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/276100-3-error-when-access-datastore.jpg?platform=QnA\" alt=\"276100-3-error-when-access-datastore.jpg\" \/>    <\/p>\n<p>And this is the final error message shown in &quot;lifecycler.log&quot;    <\/p>\n<pre><code>2023-01-04T12:47:09.731127Z ERROR run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle: lifecycler::lifecycle: failed to start capabilities exception=CapabilityError(StartError(ErrorResponse(&quot;DATA_CAPABILITY&quot;, Response { code: &quot;500&quot;, error: Some(Error { code: &quot;data-capability.UriMountSession.PyFuseError&quot;, message: &quot;DataAccessError(NotFound)&quot;, target: &quot;UriMountSession:INPUT_data_folder&quot;, node_info: Some(NodeInfo { node_id: &quot;tvmps_xxxxxx_p&quot;, vm_id: &quot;xxxxxx&quot; }), category: UserError, error_details: [ErrorDetail { key: &quot;NonCompliantReason&quot;, value: &quot;DataAccessError(NotFound)&quot; }, ErrorDetail { key: &quot;StackTrace&quot;, value: &quot;  File \\&quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/capability_session.py\\&quot;, line 70, in start\\n    (data_path, sub_data_path) = session.start()\\n\\n  File \\&quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py\\&quot;, line 386, in start\\n    options=mnt_options\\n\\n  File \\&quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\\&quot;, line 680, in rslex_uri_volume_mount\\n    raise e\\n\\n  File \\&quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\\&quot;, line 674, in rslex_uri_volume_mount\\n    mount_context = RslexDirectURIMountContext(mount_point, uri, options)\\n&quot; }], inner_error: None }) })))  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to create NC or ND type compute instance",
        "Question_created_time":1673084403660,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1155310\/unable-to-create-nc-or-nd-type-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, I'm trying to create a compute instance of type NC or ND for image-classification task and I have a pay-as-you-go subscription , yet I'm unable to create an instance for the same.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"what is the path to read the data?",
        "Question_created_time":1672151314873,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1143409\/what-is-the-path-to-read-the-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I\u2019m using machine learning studio, I have uploaded my file to data, how can I read that, what is the path?<\/p>",
        "Question_closed_time":1672154615573,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=fd6c7c6c-1300-405c-8e72-0e5b3e2887f1\">@peter  <\/a>     <\/p>\n<p>Thanks for reaching out to us in Microsoft Q&amp;A, you can follow below step to check your data path -     <\/p>\n<ol>\n<li> go to the portal and select the data you upload    <\/li>\n<li> Click &quot;Consume&quot; and you will see the way you can use your data     <\/li>\n<\/ol>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/274361-image.png?platform=QnA\" alt=\"274361-image.png\" \/>    <\/p>\n<p>You could leverage it directly by using it name.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML No Module Found Error on Deployment of Inference model: Xgboost",
        "Question_created_time":1641912514007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/690970\/azureml-no-module-found-error-on-deployment-of-inf",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>We're getting in an error in one environment deploying a ML endpoint with stating that xgboost cannot be found although it's included in the Dockerfile. We do not see this issue in 3 other environments and the model is able to deploy fine without this package error.<\/p>\n<p>Dockerfile:<\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.0-cudnn7-ubuntu16.04:20210220.v1\nUSER root\nRUN mkdir -p \/etc\/OpenCL\/vendors &amp;&amp; echo &quot;libnvidia-opencl.so.1&quot; &gt; \/etc\/OpenCL\/vendors\/nvidia.icd\nRUN apt-get update &amp;&amp; echo 'success updated apt-get!'\nRUN apt-get install -y --no-install-recommends cmake libboost-dev libboost-system-dev libboost-filesystem-dev\nRUN conda create -n gpuexp python=3.6.2 -y\n\n###############################\n# Pre-Build LightGBM\n###############################\nRUN cd \/usr\/local\/src &amp;&amp; mkdir lightgbm &amp;&amp; cd lightgbm &amp;&amp; \\\n    git clone --recursive --branch v2.3.0 --depth 1 https:\/\/github.com\/microsoft\/LightGBM &amp;&amp; \\\n cd LightGBM &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; \\\n cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ .. &amp;&amp; \\\n make -j4\n\n###############################\n# Install GPU LightGBM and XgBoost\n###############################\nRUN \/bin\/bash -c &quot;source activate gpuexp &amp;&amp; \\\n    cd \/usr\/local\/src\/lightgbm\/LightGBM\/python-package &amp;&amp; python setup.py install --precompile &amp;&amp; \\\n pip install --upgrade --force-reinstall xgboost==1.1.1 &amp;&amp; \\ \n source deactivate&quot;\n<\/code><\/pre>\n<p>Conda:<\/p>\n<pre><code>channels:\n  - anaconda\n  - conda-forge\n  - pytorch\ndependencies:\n  - python=3.6.2\n  - pip=20.2.4\n  - pip:\n      - azureml-core==1.27.0\n      - azureml-pipeline-core==1.27.0\n      - azureml-telemetry==1.27.0\n      - azureml-defaults==1.27.0\n      - azureml-interpret==1.27.0\n      - azureml-automl-core==1.27.0\n      - azureml-automl-runtime==1.27.0.post2\n      - azureml-train-automl-client==1.27.0\n      - azureml-train-automl-runtime==1.27.0.post1\n      - azureml-dataset-runtime==1.27.0\n      - azureml-mlflow==1.27.0\n      - inference-schema\n      - py-cpuinfo==5.0.0\n      - boto3==1.15.18\n      - botocore==1.18.18\n      - azure-storage-file-datalake\n      - azure-identity&lt;1.5.0\n      - azure-keyvault\n      - azure-servicebus\n  - numpy~=1.18.0\n  - scikit-learn==0.22.1\n  - pandas~=0.25.0\n  - fbprophet==0.5\n  - holidays==0.9.11\n  - setuptools-git\n  - 'psutil&gt;5.0.0,&lt;6.0.0'\n<\/code><\/pre>\n<p>I haven't included the name in the conda file intentionally.<\/p>\n<p>Is there something we're missing in the container set up for this issue that could cause it to fail for one environment and not the other?<\/p>\n<p>We are able to see the model within our endpoints section in the Azure Machine Learning Studio, but this error is visible on the deployment logs and the endpoint is a Failed state.<\/p>\n<p>In our three other environments, the endpoint is visible and in a healthy state.<\/p>\n<p>Full error message:<\/p>\n<pre><code>    2022-01-11T19:46:08,279016451+00:00 - rsyslog\/run \n    2022-01-11T19:46:08,277445539+00:00 - gunicorn\/run \n    2022-01-11T19:46:08,280042359+00:00 - iot-server\/run \n    \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n    2022-01-11T19:46:08,285741101+00:00 - nginx\/run \n    \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n    \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n    \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n    \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n    rsyslogd: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libuuid.so.1: no version information available (required by rsyslogd)\n    EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n    2022-01-11T19:46:08,407862719+00:00 - iot-server\/finish 1 0\n    2022-01-11T19:46:08,409832434+00:00 - Exit code 1 is normal. Not restarting iot-server.\n    Starting gunicorn 19.9.0\n    Listening at: http:\/\/127.0.0.1:31311 (11)\n    Using worker: sync\n    worker timeout is set to 300\n    Booting worker with pid: 37\n    SPARK_HOME not set. Skipping PySpark Initialization.\n    Generating new fontManager, this may take some time...\n    Initializing logger\n    2022-01-11 19:46:09,674 | root | INFO | Starting up app insights client\n    2022-01-11 19:46:09,675 | root | INFO | Starting up request id generator\n    2022-01-11 19:46:09,675 | root | INFO | Starting up app insight hooks\n    2022-01-11 19:46:09,675 | root | INFO | Invoking user's init function\n    Loading model from path.\n    2022-01-11 19:46:11,728 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n    Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n    2022-01-11 19:46:12,132 | root | ERROR | User's init function failed\n    2022-01-11 19:46:12,133 | root | ERROR | Encountered Exception Traceback (most recent call last):\n      File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 182, in register\n        main.init()\n      File &quot;\/var\/azureml-app\/main.py&quot;, line 35, in init\n        driver_module.init()\n      File &quot;\/structure\/azureml-app\/scripts\/inference\/score.py&quot;, line 67, in init\n        raise e\n      File &quot;\/structure\/azureml-app\/scripts\/inference\/score.py&quot;, line 64, in init\n        model = joblib.load(model_path)\n      File &quot;\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py&quot;, line 605, in load\n        obj = _unpickle(fobj, filename, mmap_mode)\n      File &quot;\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py&quot;, line 529, in _unpickle\n        obj = unpickler.load()\n      File &quot;\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py&quot;, line 1050, in load\n        dispatch[key[0]](self)\n      File &quot;\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py&quot;, line 1347, in load_stack_global\n        self.append(self.find_class(module, name))\n      File &quot;\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py&quot;, line 1388, in find_class\n        __import__(module, level=0)\n    ModuleNotFoundError: No module named 'xgboost'\n\n    2022-01-11 19:46:12,134 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n    2022-01-11 19:46:12,137 | root | INFO | Waiting 30 seconds for upload.\n    Worker exiting (pid: 37)\n    Shutting down: Master\n    Reason: Worker failed to boot.\n    2022-01-11T19:46:42,562394399+00:00 - gunicorn\/finish 3 0\n    2022-01-11T19:46:42,563843910+00:00 - Exit code 3 is not normal. Killing image.\n<\/code><\/pre>\n<p>Partial deployment logs for a successfully deployed endpoint using the same pkl file:<\/p>\n<pre><code>2022-01-10T20:02:28,608154878+00:00 - rsyslog\/run \n2022-01-10T20:02:28,608160978+00:00 - iot-server\/run \n2022-01-10T20:02:28,609567614+00:00 - gunicorn\/run \n2022-01-10T20:02:28,619823782+00:00 - nginx\/run \n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\nrsyslogd: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libuuid.so.1: no version information available (required by rsyslogd)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-01-10T20:02:28,789369303+00:00 - iot-server\/finish 1 0\n2022-01-10T20:02:28,791654562+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http:\/\/127.0.0.1:31311 (14)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 40\nSPARK_HOME not set. Skipping PySpark Initialization.\nGenerating new fontManager, this may take some time...\nInitializing logger\n2022-01-10 20:02:30,434 | root | INFO | Starting up app insights client\n2022-01-10 20:02:30,435 | root | INFO | Starting up request id generator\n2022-01-10 20:02:30,435 | root | INFO | Starting up app insight hooks\n2022-01-10 20:02:30,435 | root | INFO | Invoking user's init function\nLoading model from path.\n2022-01-10 20:02:32,892 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\nModel loaded succesfully.\nManagedIdentityCredential will use IMDS\n<\/code><\/pre>\n<p>I have tried utilizing py-xgboost in the Conda File and updating packages, however, I get the following error message:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 182, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/main.py&quot;, line 35, in init\n    driver_module.init()\n  File &quot;\/structure\/azureml-app\/scripts\/inference\/score.py&quot;, line 67, in init\n    raise e\n  File &quot;\/structure\/azureml-app\/scripts\/inference\/score.py&quot;, line 64, in init\n    model = joblib.load(model_path)\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py&quot;, line 605, in load\n    obj = _unpickle(fobj, filename, mmap_mode)\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py&quot;, line 529, in _unpickle\n    obj = unpickler.load()\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py&quot;, line 1050, in load\n    dispatch[key[0]](self)\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py&quot;, line 1347, in load_stack_global\n    self.append(self.find_class(module, name))\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py&quot;, line 1390, in find_class\n    return _getattribute(sys.modules[module], name)[0]\n  File &quot;\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py&quot;, line 272, in _getattribute\n    .format(name, obj))\nAttributeError: Can't get attribute 'XGBoostLabelEncoder' on &lt;module 'xgboost.compat' from '\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/xgboost\/compat.py'&gt;\n<\/code><\/pre>\n<p>The hyper parameters within the model created by Azure Auto ML include a XGBoost package from Azure ML:<\/p>\n<pre><code>{\n    &quot;spec_class&quot;: &quot;sklearn&quot;,\n    &quot;class_name&quot;: &quot;XGBoostClassifier&quot;,\n    &quot;module&quot;: &quot;automl.client.core.common.model_wrappers&quot;,\n    &quot;param_args&quot;: [],\n    &quot;param_kwargs&quot;: {\n        &quot;tree_method&quot;: &quot;auto&quot;\n    },\n    &quot;prepared_kwargs&quot;: {}\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a limit for endpoint bandwidth quota",
        "Question_created_time":1672326027260,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1145811\/is-there-a-limit-for-endpoint-bandwidth-quota",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, my endpoint seems be throttled so I want to know what is the default limitation. I did some research but found nothing in the official docs, please help me point the obvious data. <\/p>",
        "Question_closed_time":1672328170423,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=80951d13-b803-4a3c-a513-64b99f671835\">@jim jones  <\/a>     <\/p>\n<p>Thanks for reaching out to us for this issue. Mirroring traffic uses your endpoint bandwidth quota <strong>(default 5 MBPS)<\/strong>. Your endpoint bandwidth will be throttled if you exceed the allocated quota. For information on monitoring bandwidth throttling, see Monitor managed online endpoints.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/274868-image.png?platform=QnA\" alt=\"274868-image.png\" \/>    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Select column by name option is faded in edit metadata object in Azure ML studio",
        "Question_created_time":1653833837490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/868582\/select-column-by-name-option-is-faded-in-edit-meta",
        "Question_score_count":2,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>As shown in the image, by name option is faded. I have already ran the pipeline and it was successful. Then why not adding another step in pipeline shows the output of imported data ?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206492-image.png?platform=QnA\" alt=\"206492-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to access the data used during the azure automl pipeline training?",
        "Question_created_time":1671429879837,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1133620\/how-to-access-the-data-used-during-the-azure-autom",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <\/p>\n<p>Is there any way to access the X_tain, y_train, X_test, y_test data that was used in azure automl pipeline step during training?<\/p>",
        "Question_closed_time":1672240955833,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>You can access the data that was used during the training of an Azure AutoML model by using the TrainingData property of the Model object in the Azure Machine Learning SDK.    <\/p>\n<p>Here's an example of how you can do this:    <\/p>\n<pre><code>from azureml.core import Workspace, Dataset, Experiment, Model  \n  \n# Load the workspace  \nws = Workspace.from_config()  \n  \n# Get the experiment that contains the model  \nexperiment = Experiment(workspace=ws, name='my-experiment')  \n  \n# Get the model  \nmodel = Model(workspace=ws, name='my-model', version='1')  \n  \n# Get the training data  \ntraining_data = model.training_data  \n  \n# Access the X_train and y_train data  \nX_train = training_data.split['train']['X']  \ny_train = training_data.split['train']['y']  \n  \n# Access the X_test and y_test data  \nX_test = training_data.split['test']['X']  \ny_test = training_data.split['test']['y']  \n<\/code><\/pre>\n<p>Note that the training_data object is a TabularDataset object, which represents a dataset in tabular format (i.e., rows and columns). The split property of this object is a dictionary that contains the training and test data splits. The keys of this dictionary are 'train' and 'test', and the values are dictionaries containing the 'X' and 'y' data for each split.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Transitioning from kfp.dsl pipelines to azure-ai-ml (v2) ones",
        "Question_created_time":1672254459697,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1144813\/transitioning-from-kfp-dsl-pipelines-to-azure-ai-m",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am a long time time user of <a href=\"https:\/\/kubeflow-pipelines.readthedocs.io\/en\/latest\/source\/kfp.dsl.html\">Kubeflow pipelines<\/a>. Recently, my company started to explore Azure Machine Learning, and started to migrate some of the existing pipelines to Azure Machine Learning pipelines. Not sure if it matters significantly or not, I decided to use <a href=\"https:\/\/learn.microsoft.com\/en-gb\/python\/api\/overview\/azure\/ai-ml-readme?view=azure-python\">V2 SDK<\/a>.    <\/p>\n<p>While transitioning, my first challenge seems to be that there is no direct counter-part of dsl.Condition or dsl.ParallelFor. And much more importantly, it seems I cannot define a DAG without outputs. So, I wanted to know if someone else tried such migration before and have some suggestions.    <\/p>\n<p>I am completely new to Azure, so there's a chance that I am trying the wrong tool. If that is the case, or if there's just no such counterpart whatsoever, please let me know that as well.    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Python 3.8 - AzureML kernel not starting",
        "Question_created_time":1638550291587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/650960\/python-3-8-azureml-kernel-not-starting",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>tl;dr: Azureml - 3.8 Python kernel will not connect to jupyter notebook using Standard_NC6 GPU compute  <\/p>\n<p>I'm using Azure for a class with a Standard_NC6 GPU as the compute (this is required for the assignment). While I was working yesterday, the compute got stuck on cell in jupyter for around 30 minutes when it only should have taken 10. I tried to interrupt the kernel, but it wasn't responding. I tried stopping the compute, but it wouldn't stop. Then I tried deleting the compute, which stopped the compute, but didn't actually delete it. I couldn't restart the compute, so I tried to delete it again, which did work. Then I created a new compute in the same resource group with the same requirements as before, only once it finally launched the correct kernel, Azureml-3.8 Python wouldn't start up in Jupyter. It would say launching when I tried to start it, run for maybe 5-10 minutes, and then say it couldn't connect.   <\/p>\n<p>I then created a new resource group with a brand new compute, and still ran into the same error. I could even start the notebook up with any of the other kernels, but unfortunately I have to use azureml-3.8 Python for the assignement. What am I doing wrong? Please let me know if I should post more information  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does Azure ML have a service that can identify the best people for a task?",
        "Question_created_time":1671565679017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136469\/does-azure-ml-have-a-service-that-can-identify-the",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi all;    <\/p>\n<p>I'm working on an app to handle all the volunteers for an organization. In it, we'd like to have a way to identify the best volunteers to reach out to for a given project.     <\/p>\n<p>We can't ask them to spend 20 minutes giving us their life stories but I figure they'll be willing to answer a couple of questions. So I was thinking:    <\/p>\n<ul>\n<li> Work background    <\/li>\n<li> Unique Skills    <\/li>\n<li> Educational background    <\/li>\n<li> Why do you volunteer, what matters to you    <\/li>\n<li> Their LinkedIn, Twitter, Facebook, Instagram, &amp; TikTok pages    <\/li>\n<li> What types of projects\/jobs most interest you.    <\/li>\n<\/ul>\n<p>So... with the above info is there a service\/app in the AzureML stack that will take a text query describing the project\/job and from that will return the volunteers likely to sign up for this? Preferably in order of likelihood?    <\/p>\n<p>thanks - dave    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why does Azure Auto ML take so much time to train a time series forecasting Model.",
        "Question_created_time":1671790031517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1140380\/why-does-azure-auto-ml-take-so-much-time-to-train",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to train a dataset of approx. 30 MB in size to do inventory forecasting  and to do that I am using compute cluster as my compute target whose virtual machine size is Standard_DS12_v2 (4 cores, 28 GB RAM, 56 GB disk). Also I am keeping all the configurations to default while preparing a new job. But this training is failing again and again, and it suggests me to increase compute size but I think this compute size is ok for a dataset as small as 30 MB. Please suggest me some solutions to overcome this.  Please response as soon as possible.     <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ml cli - Deploy and score a machine learning model by using an online endpoint issue",
        "Question_created_time":1671806620823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1140771\/azure-ml-cli-deploy-and-score-a-machine-learning-m",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm using Azure DevOps pipelines with azure cli tasks and I'm trying to deploy and score a machine learning model by using an online endpoint.  <br \/>\nI'm following the steps here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-online-endpoints?tabs=azure-cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-online-endpoints?tabs=azure-cli<\/a><\/p>\n<p>So I have my endpoint.yml file like this:<\/p>\n<p><em>$schema: <a href=\"https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineEndpoint.schema.json\">https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineEndpoint.schema.json<\/a>  <br \/>\nname: my-test-endpoint  <br \/>\nauth_mode: key<\/em><\/p>\n<p>And using azure cli with the following syntax:<\/p>\n<p>az ml online-endpoint create --resource-group $(azureml.resourceGroup) --workspace-name $(azureml.workspaceName) -n $(endpoint.name) -f $(endpoint.file)<\/p>\n<p>where endpoint.file is endpoint.yml and endpoint.name is my-test-endpoint.<\/p>\n<p>But everytime that I run it I get the following error:<\/p>\n<blockquote>\n<p>2022-12-23T14:16:35.6220095Z Traceback (most recent call last):<\/p>\n<\/blockquote>\n<p>2022-12-23T14:16:35.6220861Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_util.py&quot;, line 147, in load_from_dict  <br \/>\n2022-12-23T14:16:35.6221661Z return schema(context=context).load(data, **kwargs)  <br \/>\n2022-12-23T14:16:35.6222337Z File &quot;\/opt\/az\/azcliextensions\/ml\/marshmallow\/schema.py&quot;, line 722, in load  <br \/>\n2022-12-23T14:16:35.6223207Z return self._do_load(  <br \/>\n2022-12-23T14:16:35.6223828Z File &quot;\/opt\/az\/azcliextensions\/ml\/marshmallow\/schema.py&quot;, line 909, in _do_load  <br \/>\n2022-12-23T14:16:35.6224434Z raise exc  <br \/>\n2022-12-23T14:16:35.6226674Z marshmallow.exceptions.ValidationError: {'baseImage': ['Unknown field.'], 'sourceDirectory': ['Unknown field.'], 'runtime': ['Unknown field.'], 'baseImageRegistry': ['Unknown field.'], 'enableGpu': ['Unknown field.'], 'entryScript': ['Unknown field.'], 'condaFile': ['Unknown field.'], 'extraDockerfileSteps': ['Unknown field.'], 'schemaFile': ['Unknown field.']}  <br \/>\n2022-12-23T14:16:35.6227645Z  <br \/>\n2022-12-23T14:16:35.6228137Z During handling of the above exception, another exception occurred:  <br \/>\n2022-12-23T14:16:35.6228506Z  <br \/>\n2022-12-23T14:16:35.6228910Z Traceback (most recent call last):  <br \/>\n2022-12-23T14:16:35.6229617Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/knack\/cli.py&quot;, line 233, in invoke  <br \/>\n2022-12-23T14:16:35.6230227Z cmd_result = self.invocation.execute(args)  <br \/>\n2022-12-23T14:16:35.6230998Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/azure\/cli\/core\/commands\/<strong>init<\/strong>.py&quot;, line 663, in execute  <br \/>\n2022-12-23T14:16:35.6231571Z raise ex  <br \/>\n2022-12-23T14:16:35.6232294Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/azure\/cli\/core\/commands\/<strong>init<\/strong>.py&quot;, line 726, in _run_jobs_serially  <br \/>\n2022-12-23T14:16:35.6232992Z results.append(self._run_job(expanded_arg, cmd_copy))  <br \/>\n2022-12-23T14:16:35.6233790Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/azure\/cli\/core\/commands\/<strong>init<\/strong>.py&quot;, line 697, in _run_job  <br \/>\n2022-12-23T14:16:35.6234384Z result = cmd_copy(params)  <br \/>\n2022-12-23T14:16:35.6235123Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/azure\/cli\/core\/commands\/<strong>init<\/strong>.py&quot;, line 333, in <strong>call<\/strong>  <br \/>\n2022-12-23T14:16:35.6235753Z return self.handler(*args, **kwargs)  <br \/>\n2022-12-23T14:16:35.6236523Z File &quot;\/opt\/az\/lib\/python3.10\/site-packages\/azure\/cli\/core\/commands\/command_operation.py&quot;, line 121, in handler  <br \/>\n2022-12-23T14:16:35.6237306Z return op(**command_args)  <br \/>\n2022-12-23T14:16:35.6237940Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/custom\/online_endpoint.py&quot;, line 119, in ml_online_endpoint_create  <br \/>\n2022-12-23T14:16:35.6238660Z log_and_raise_error(err, debug, yaml_operation=yaml_operation)  <br \/>\n2022-12-23T14:16:35.6239353Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/custom\/raise_error.py&quot;, line 145, in log_and_raise_error  <br \/>\n2022-12-23T14:16:35.6239931Z raise cli_error  <br \/>\n2022-12-23T14:16:35.6240549Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/custom\/online_endpoint.py&quot;, line 87, in ml_online_endpoint_create  <br \/>\n2022-12-23T14:16:35.6241287Z endpoint = load_online_endpoint(source=file, params_override=params_override)  <br \/>\n2022-12-23T14:16:35.6242072Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_load_functions.py&quot;, line 571, in load_online_endpoint  <br \/>\n2022-12-23T14:16:35.6242862Z return load_common(OnlineEndpoint, source, relative_origin, **kwargs)  <br \/>\n2022-12-23T14:16:35.6243636Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_load_functions.py&quot;, line 105, in load_common  <br \/>\n2022-12-23T14:16:35.6244326Z raise e  <br \/>\n2022-12-23T14:16:35.6244966Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_load_functions.py&quot;, line 89, in load_common  <br \/>\n2022-12-23T14:16:35.6245799Z return _load_common_raising_marshmallow_error(cls, yaml_dict, relative_origin, params_override, **kwargs)  <br \/>\n2022-12-23T14:16:35.6246693Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_load_functions.py&quot;, line 135, in _load_common_raising_marshmallow_error  <br \/>\n2022-12-23T14:16:35.6247733Z return cls._load(data=yaml_dict, yaml_path=relative_origin, params_override=params_override, **kwargs)  <br \/>\n2022-12-23T14:16:35.6248562Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_endpoint\/online_endpoint.py&quot;, line 264, in _load  <br \/>\n2022-12-23T14:16:35.6249587Z return load_from_dict(ManagedOnlineEndpointSchema, data, context)  <br \/>\n2022-12-23T14:16:35.6250476Z File &quot;\/opt\/az\/azcliextensions\/ml\/azext_mlv2\/manual\/vendored_curated_sdk\/azure\/ai\/ml\/entities\/_util.py&quot;, line 150, in load_from_dict  <br \/>\n2022-12-23T14:16:35.6251261Z raise ValidationError(decorate_validation_error(schema, pretty_error, additional_message))  <br \/>\n2022-12-23T14:16:35.6251994Z marshmallow.exceptions.ValidationError: Validation for ManagedOnlineEndpointSchema failed:  <br \/>\n2022-12-23T14:16:35.6252408Z  <br \/>\n2022-12-23T14:16:35.6252773Z {  <br \/>\n2022-12-23T14:16:35.6253144Z &quot;baseImage&quot;: [  <br \/>\n2022-12-23T14:16:35.6253577Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6253956Z ],  <br \/>\n2022-12-23T14:16:35.6254339Z &quot;sourceDirectory&quot;: [  <br \/>\n2022-12-23T14:16:35.6254766Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6255160Z ],  <br \/>\n2022-12-23T14:16:35.6255526Z &quot;runtime&quot;: [  <br \/>\n2022-12-23T14:16:35.6255920Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6256329Z ],  <br \/>\n2022-12-23T14:16:35.6256715Z &quot;baseImageRegistry&quot;: [  <br \/>\n2022-12-23T14:16:35.6257139Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6257551Z ],  <br \/>\n2022-12-23T14:16:35.6257922Z &quot;enableGpu&quot;: [  <br \/>\n2022-12-23T14:16:35.6258319Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6258693Z ],  <br \/>\n2022-12-23T14:16:35.6259099Z &quot;entryScript&quot;: [  <br \/>\n2022-12-23T14:16:35.6259737Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6260924Z ],  <br \/>\n2022-12-23T14:16:35.6261162Z &quot;condaFile&quot;: [  <br \/>\n2022-12-23T14:16:35.6261444Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6261684Z ],  <br \/>\n2022-12-23T14:16:35.6261953Z &quot;extraDockerfileSteps&quot;: [  <br \/>\n2022-12-23T14:16:35.6262243Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6262502Z ],  <br \/>\n2022-12-23T14:16:35.6262734Z &quot;schemaFile&quot;: [  <br \/>\n2022-12-23T14:16:35.6263014Z &quot;Unknown field.&quot;  <br \/>\n2022-12-23T14:16:35.6263251Z ]  <br \/>\n2022-12-23T14:16:35.6263472Z }  <br \/>\n2022-12-23T14:16:35.6263564Z  <br \/>\n2022-12-23T14:16:35.6263782Z  <br \/>\n2022-12-23T14:16:35.6264425Z Visit this link to refer to the OnlineEndpoint schema if needed: <a href=\"https:\/\/aka.ms\/ml-cli-v2-endpoint-online-yaml-reference\">https:\/\/aka.ms\/ml-cli-v2-endpoint-online-yaml-reference<\/a>.<\/p>\n<blockquote>\n<p>Blockquote<\/p>\n<\/blockquote>\n<p>It seems some validations are failing and it's complaining about some fields which I have no idea what are about (my YAML file doesn't have those anywhere).<\/p>\n<p>I've also checked <a href=\"https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineEndpoint.schema.json\">https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineEndpoint.schema.json<\/a> and I can't see any reference to those there.<\/p>\n<p>Can you help me understanding what's going on?<\/p>\n<p>Thank you in advance<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure studio",
        "Question_created_time":1670445833330,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1120604\/azure-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Could you please tell me how to link Notebook and Data (their type was .jpge 'image') inside Azure studio<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/268298-123.png?platform=QnA\" alt=\"268298-123.png\" \/>??    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Can not list\/load registered Datasets via Python SDK",
        "Question_created_time":1667981280147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1081549\/azure-ml-can-not-list-load-registered-datasets-via",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I'm quite new to Azure ML and Python. I created some datasets using both the Azure ML GUI and the Python SDK:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/258627-datasets.png?platform=QnA\" alt=\"258627-datasets.png\" \/>    <\/p>\n<p>Now I want to load these datasets in a Pandas Dataframe. But when I run    <\/p>\n<p><code> Dataset.get_all(workspace=workspace)<\/code>       <\/p>\n<p>I got an empty list:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/258589-command.png?platform=QnA\" alt=\"258589-command.png\" \/>    <\/p>\n<p>Do I miss something? I'm using the version 0.2.7. of azureml and Version 1.46.0. of azureml-core.    <\/p>\n<p>I also tried     <\/p>\n<p><code>workspace.datasets<\/code>    <\/p>\n<p>But also got an empty result.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there any Java SDK available for Azure ML",
        "Question_created_time":1671707842773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1139048\/is-there-any-java-sdk-available-for-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>HI Team,    <br \/>\nI see that documentation is only available for Python SDL and azure CLI.    <br \/>\nAs per the records, there does not seem to be any Java SDK.    <br \/>\nis my understanding correct?    <\/p>\n<p>is yes, then I am Just wondering why so?  What could be the reason behind it? Or is it under pipeline for the future releases?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the difference between Data Labeling Text Azure Machine Learning Studio and cognitive service Text Classifition (Langage Studio) ?",
        "Question_created_time":1671445270327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1134081\/what-is-the-difference-between-data-labeling-text",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Good morning,     <br \/>\nI am on a text classification project and I test the text classification services on Microsoft Aeure.     <br \/>\nI would like to know the difference between Microsoft Azure Machine Learning Studio Data Labeling and Text Classifition de cognitive service (Langage Studio)?     <br \/>\nDoes one service perform better than the other?     <\/p>\n<p>Thank you in advance for your help     <\/p>\n<p>Cordially     <br \/>\nLysa <\/p>",
        "Question_closed_time":1671545106010,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2d96c782-8477-4987-b5a4-5ea497b49eb9\">@AMROUN Lysa  <\/a> Thanks for the question. In Azure ML you will be able to train and customize text classification. In Language studio base line model provided to do the classification.    <\/p>\n<p>With Custom text classification, you can build custom AI models to classify text into pre-defined custom classes. By creating a custom text classification project, you can iteratively label data, train, evaluate, and improve model performance before deploying your model and making it available for consumption.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Recognizing problematic content",
        "Question_created_time":1671566297007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136505\/recognizing-problematic-content",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all;    <\/p>\n<p>I am creating an app to handle volunteers for a NGO. One of the things volunteers will be allowed to do is create events &amp; other projects. And a concern we have is a troll enters something hateful that they then point reporters to.    <\/p>\n<p>So... and I know this is probably beyond ML at present (but it never hurts to ask), is there an AzureML service\/app that we could feed all the text for the proposed event and it would rate the likelihood of it being problematic?     <\/p>\n<p>And if there isn't one that can work with no data from us, is there a service\/app that we could train for this once we have say 100,000 projects? We have no data for this at present but after running for a year we likely will have 100,000 projects to use for training.    <\/p>\n<p>thanks - dave<\/p>",
        "Question_closed_time":1671617821857,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2e000d14-7fa3-4e41-9299-8306855b228f\">@David Thielen  <\/a> It is possible to use Azure language services' <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/sentiment-opinion-mining\/overview\">sentiment analysis and opinion mining<\/a> offering to identify such problematic comments from your projects. This feature of the service does not require any training as the models behind the service are trained to provide sentiment of the text passed to the service. It returns either a postive, neutral or negative sentiment along with a score to justify the same. I think this should help you solve the issue that you are currently facing to identify trolls.    <\/p>\n<p>The service currently does not have an option to train custom sentiment models, the current recommendation for custom text is to use the azure machine learning service to train your own models.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Does the Azure ML stack have functionality to summarize meetings?",
        "Question_created_time":1671565097407,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136479\/does-the-azure-ml-stack-have-functionality-to-summ",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all;    <\/p>\n<p>Is there an Azure ML resource\/program that can be fed a transcript of a meeting and from it can:    <\/p>\n<ol>\n<li> Create a written summary of the meeting.    <\/li>\n<li> Create a list of action items promised in the meeting.    <\/li>\n<li> Create a list of conclusions reached in the meeting.    <\/li>\n<\/ol>\n<p>The service <a href=\"https:\/\/otter.ai\/\">Otter<\/a> does a lot (all?) of this. <a href=\"https:\/\/www.fiercehealthcare.com\/tech\/microsoft-and-nuance-developing-ambient-ai-technologies-to-tackle-doctors-administrative-tasks\">Microsoft\/Nuance<\/a> has something similar too.    <\/p>\n<p>thanks - dave    <\/p>",
        "Question_closed_time":1671619392127,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=2e000d14-7fa3-4e41-9299-8306855b228f\">@David Thielen  <\/a>     <\/p>\n<p>I have checked with the document and pm, there is a preview feature I think is very suitable for your senario - document and conversation summarization (preview) from Azure Language Service.    <\/p>\n<p><strong>Summarization<\/strong> is one of the features offered by Azure Cognitive Service for Language, a collection of <strong>machine learning and AI algorithms<\/strong> in the cloud for developing intelligent applications that involve written language. Conversation summarization supports the following features:    <\/p>\n<ol>\n<li> Issue\/resolution summarization: A call center specific feature that gives a summary of issues and resolutions in conversations between customer-service agents and your customers.    <\/li>\n<li> Chapter title summarization: Gives suggested chapter titles of the input conversation.    <\/li>\n<li> <strong>Narrative summarization: Gives call notes, meeting notes or chat summaries of the input conversation.<\/strong>    <\/li>\n<\/ol>\n<p>I think the <strong>narrative summarization<\/strong> is what you are looking for. Please check on below document to see if that is what you are looking for -    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/overview?tabs=conversation-summarization\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/overview?tabs=conversation-summarization<\/a>    <\/p>\n<p>This is the quickstart session for you, but since this feature is new and under preview, you need to send a request for the access -     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/quickstart?pivots=rest-api&amp;tabs=conversation-summarization\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/quickstart?pivots=rest-api&amp;tabs=conversation-summarization<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support our community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to set budget limit on a compute instance created in azure ML studio",
        "Question_created_time":1666864166367,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1065129\/how-to-set-budget-limit-on-a-compute-instance-crea",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>hi Team,    <br \/>\nI want to set limitations on the VMs which are used for model training. Now, these compute instances are created using ML Studio and my requirement is to pause the model training if the pre-defined budget is over. This is to prevent user of unexpected charges and control the expenses.    <\/p>\n<p>But I am not able to figure out the way on how to do it.    <br \/>\n1 way is to put a limit on the compute instance so that if it crosses the budget then its is paused and only upon resetting the budget, user can start it back.    <\/p>\n<p>To achieve this,  I am thinking to set some actionGroup on budget to pause the VM or is there any automatic setting available to do this?    <\/p>\n<p>On top of everything, I am not able to find the filter which can put a budget on ML Compute. I can find till workspace but nowhere on compute part. How to control the model training budgets in that case?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure cli ml commands should be idempotent",
        "Question_created_time":1671542598663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1135983\/azure-cli-ml-commands-should-be-idempotent",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Commands run from the Azure CLI ML extension should really be idempotent where required.     <\/p>\n<p>For example this command when run twice...    <\/p>\n<blockquote>\n<p>az ml online-endpoint create -n my-endpoint -f .\\my-endpoint.yml --resource-group my-rg --workspace-name my-aml    <\/p>\n<\/blockquote>\n<p>...second time of asking...    <\/p>\n<pre><code>(UserError) An endpoint with this name already exists. If you are trying to create a new endpoint, use a  \ndifferent name. If you are trying to update an existing endpoint, use `az ml online-endpoint update` instead.  \n<\/code><\/pre>\n<p>Creating CI\/CD pipelines for this is hard - constantly writing scaffolding scripts around enumerating though what already exists and working around the issue it isn't really the done thing now. Please consider changing some of these ML cmdlets with this in mind please - Thanks    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/online-deployment?view=azure-cli-latest#az-ml-online-deployment-create\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/online-deployment?view=azure-cli-latest#az-ml-online-deployment-create<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure CLI with Java code",
        "Question_created_time":1671015836413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1128761\/azure-cli-with-java-code",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everyone , I know that at the moment it is not possible to run Java Codes inside Azure ML workspace.    <br \/>\nThe best answer by <a href=\"\/users\/na\/?userid=ad870133-9538-4d77-adc8-2b5ffc5c1b45\">@YutongTie-MSFT  <\/a> in another post was to use Azure CLI with Java. I would like to know what would be the best way to achieve this?     <br \/>\nAre there any examples that i could follow ?    <\/p>\n<p>Thanks in advance. :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Register models in Azure machine learning Studio from Databricks",
        "Question_created_time":1670236984677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1116300\/register-models-in-azure-machine-learning-studio-f",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hello, i have a databricks workspace where i have the code to create experiments and register models, code that runs successfully By other side, i have an Azure machine learning studio created. When i create the job in Databricks it creates the job aswell in AML Studio, but no model is registered there. My goal is exactly that, runing the script and the necesary configuration from Databricks then register the model in Databricks and AML studio. Anyone knows how can i achieve this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Workspace Name",
        "Question_created_time":1671128166580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1130894\/workspace-name",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi. Why is a workspace like ws-MC-Azure-ML unacceptable    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/271156-image.png?platform=QnA\" alt=\"271156-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"DefaultAzureCredential failed to retrieve a token from the included credentials.",
        "Question_created_time":1671076439927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1129620\/defaultazurecredential-failed-to-retrieve-a-token",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, While trying authentication in AzureML SDK v2 the DefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: \tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. <\/p>",
        "Question_closed_time":1671083438317,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a>  Thanks for the question. Hers is the <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/blob\/main\/sdk\/identity\/azure-identity\/TROUBLESHOOTING.md#troubleshoot-environmentcredential-authentication-issues\">Troubleshooting guide<\/a> for Default Azure credential errors.    <\/p>\n<p> from azure.core.exceptions import ClientAuthenticationError    <br \/>\n    from azure.identity import DefaultAzureCredential  <br \/>\n    from azure.keyvault.secrets import SecretClient  <\/p>\n<pre><code># Create a secret client using the DefaultAzureCredential  \nclient = SecretClient(&quot;https:\/\/myvault.vault.azure.net\/&quot;, DefaultAzureCredential())  \ntry:  \n    secret = client.get_secret(&quot;secret1&quot;)  \nexcept ClientAuthenticationError as ex:  \n    print(ex.message)  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML 'Designer': how to view logistic regression model coefficients \/ intercept",
        "Question_created_time":1607433503623,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/190478\/azure-ml-designer-how-to-view-logistic-regression",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Using Azure ML Designer it is easy to create a model using the Two-Class Logistic Regression &amp; Train Model components. However it does not seem to be possible to view the regression coefficients \/ intercept (ie. the weights applied to the feature values within the model). How can we go about viewing the model coefficients? Are they stored in one of the Train Model output files (eg. data.ilearner) in a way that can be viewed \/ exported to a human readable format?  <\/p>\n<p>Note: this question relates to the Azure Machine Learning Studio (not the older 'classic' version where I believe it was possible to 'right-click' and visualise the model coefficients).<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Java with Azureml",
        "Question_created_time":1670945661683,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1127395\/java-with-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,    <\/p>\n<p>i am urgently looking for the possibility of running Java code on Azure ML.     <br \/>\nSo apparantly we have our code in Python and also in Java (let us say our ML Model and pre-processing is in Python).    <\/p>\n<p>What would be the best possible way to work around this ? Your suggestions would be helpful    <\/p>\n<p>Thanks in advance :) <\/p>",
        "Question_closed_time":1670954670943,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=f5d4c7c7-659d-41ce-a69c-2b7c4f838dad\">@antara.das  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A. I am sorry Azure Machine Learning now is not support Java.     <\/p>\n<p>You can use R &amp; Pyhton in Azure Machine Learning Designer, for Azure Machine Learning SDK, there is only Python SDK now.    <\/p>\n<p>The only one possible way if you want to run it by Java - Call Azure CLI from Java code, but this is not very recommended.    <br \/>\nAzure Machine Learning CLI reference - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli?tabs=public\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli?tabs=public<\/a>    <\/p>\n<p>I can forward this feedback to product team for future consideration if you could provide more details about your scenario.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Will SQL Server enable  sp_execute_external_script to work with a previously installed Anaconda3",
        "Question_created_time":1670958836030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1127660\/will-sql-server-enable-sp-execute-external-script",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Having read Erland's article     <\/p>\n<p><a href=\"https:\/\/www.sqlservergeeks.com\/a-tip-about-using-python-for-regular-expressions-in-t-sql-by-erland-sommarskog\/\">https:\/\/www.sqlservergeeks.com\/a-tip-about-using-python-for-regular-expressions-in-t-sql-by-erland-sommarskog\/<\/a>    <\/p>\n<p>on <em>regular expressions<\/em> for SQL Server and the advantage of enabling sp_execute_external_script.  This works with the version of Anaconda3 that installs with SQL Server 2019.   There is an issue on the laptop used here because group policy (via the government policy) demands the use of FIPS.  For this reason, installing R or Java will fail (I suspect it doesn't sit well with managed copies of encryption).  Anaconda requires many over-rides during installation via <em>Privileged Management Administrator<\/em> and is installed locally through a painstaking process.       <\/p>\n<p>My bigger fear is that if I remove Anaconda3 to install using SQL, it will either fail similarly as did R and Java, or worse, I'll have trouble re-installing the version of Anaconda currently on the machine.    <\/p>\n<p>So again, the question is whether or not it is possible to enable sp_execute_external_script on SQL without installing R, Python, or Java.   I tried Java and R and both fail to install.   The Java and Python are already installed.<\/p>",
        "Question_closed_time":1670970968173,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I am not sure that I understand the question. To use Python from SQL Server, you need to do one of:<\/p>\n<p>1) Use the Python that comes with SQL 2017 or SQL 2019.  <br \/>\n2) Install any version of Python you like as described on <a href=\"https:\/\/learn.microsoft.com\/en-us\/sql\/machine-learning\/install\/sql-machine-learning-services-windows-install-sql-2022\">https:\/\/learn.microsoft.com\/en-us\/sql\/machine-learning\/install\/sql-machine-learning-services-windows-install-sql-2022<\/a>. (That page is for SQL 2022, but it should be good for SQL 2019 as well.)<\/p>\n<p>If you don't have any external languages installed, you can still enable sp_execute_external_script, but you don't have much use for it, obviously.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to Submit Run with Registered V1-Tabular Registered Dataset using SDK2 Script?",
        "Question_created_time":1670511914290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1121856\/how-to-submit-run-with-registered-v1-tabular-regis",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have a <strong>SDK1-Tabular registered dataset<\/strong> that contains a table generated from a <strong>parquet<\/strong> file inside a Storage Account. The parquet file is in a storage account protected by a virtual network. The compute cluster is created with such virtual network specified.    <\/p>\n<p>Using <strong>SDK1<\/strong> (i.e. experiment.submit  and dataset.as_named_input('training_data')) my training script can read the parquet without problems (i.e. run.input_datasets['training_data']. So, SDK1 works, and the cluster is able to reach the data (i.e. networking is not an issue).    <\/p>\n<p>When I try to use the new <strong>SDK2<\/strong>, I could make it work, and i could not find the answer in documentation. Error messages say SDK1-Tabular datasets can only be read directly and need be passed as MLTABLE.    <\/p>\n<p>I am trying to submit an experiment run using the following code (pseudo):    <\/p>\n<p><code>command_job = command(command=&quot;python train.py --input_data ${{inputs.input_data}}.&quot;, inputs=my_job_inputs&quot;, etc)<\/code>    <br \/>\n<code>ml_clients.jobs.create_or_update(command_job)<\/code>    <\/p>\n<p>My question is:    <\/p>\n<ul>\n<li> How should <strong>my_job_inputs<\/strong> be set?    <\/li>\n<li> What the lines in the <strong>training script<\/strong> should look like to open the parquet dataset as a pandas dataframe?<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to  give Source Directory on the step pipeline in Azure Machine Learning",
        "Question_created_time":1670262634633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1116799\/how-to-give-source-directory-on-the-step-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi<\/p>\n<blockquote>\n<p>I'm trying to Specify the Source Directory and tried several ways but i could not find the solution .<\/p>\n<p>below is the example of my file: (where I'm trying to specify the source directory as CodeBase and file is Data.py  <br \/>\nand my pipeline file as Datapipeline.py.<\/p>\n<p>Folder Structure :<\/p>\n<p>CodeBase  <br \/>\n---Data.Py  <br \/>\n---Data1.py  <br \/>\nPipeline  <br \/>\n----Datapipeline.py<\/p>\n<p>Code Example:  <br \/>\nfrom azureml.pipeline.steps import PythonScriptStep<\/p>\n<p>path= '.\/CodeBase\/'  <br \/>\ndataprep_source_dir = path  <br \/>\nentry_point = &quot;Data.py&quot;  <br \/>\ndata_prep_step = PythonScriptStep(name='Inference_Service',  <br \/>\nscript_name=entry_point,  <br \/>\nsource_directory=dataprep_source_dir,  <br \/>\ninputs= [Top_150_Merchants.as_named_input('Top_150_Merchants'),  <br \/>\nacquire.as_named_input('Weekly_volume_Acquire')],  <br \/>\noutputs=[datafolder],  <br \/>\ncompute_target=compute_target,  <br \/>\nrunconfig=aml_run_config,  <br \/>\nallow_reuse=True  <br \/>\n)<\/p>\n<p>ValueError: Step [Inference_Service]: script not found at: \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/dev-mural-&gt; gpu\/code\/Users\/Roopesh.Bharatwaj\/Mural_Code\/Pipeline\/CodeBase\/Data.py.<\/p>\n<p>Make sure to specify an appropriate source_directory on the Step or default_source_directory on the Pipeline.<\/p>\n<p>Kindly Let me know, if anyone can help me in this. Thank you !!<\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The pre-built components of the pipeline designer in Azure ML studio don't appear",
        "Question_created_time":1653032834087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/857398\/the-pre-built-components-of-the-pipeline-designer",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>With allarming frequency, when I try to design a pipeline I don't have access to all the pre-built components\/assets. In this case, the only components that are still available are the datasets, web input and output and the custom components. This problem reverts itself after some time without any input. What should I do to avoid it or at least revert it as fast as possible?    <\/p>\n<p>Edit: I add a screenshot of the issue    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204983-capture-azure-issue-2.png?platform=QnA\" alt=\"204983-capture-azure-issue-2.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Python SDK v2 user defined environment",
        "Question_created_time":1670489210250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1121319\/azure-ml-python-sdk-v2-user-defined-environment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I'm trying to use v2 of the AML Python SDK, but I'm having problems defining a user defined environment. When I create a command object it requires an environment to be provided. But I can't find any documentation on how to create an environment that is user defined.     <\/p>\n<p>If I list the environments that the system has (az ml environment list) it has an environment called user-managed-env, but if I try and use it, I get an error stating that it can't be found.     <\/p>\n<p>Anyone know how to define a user managed environment with the v2 Python SDK?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Reinforcement Learning: `Eperiment.submit` of Python SDK (azureml.contrib.train.rl) returns 530 with \"unkown to cluster\" message in response.",
        "Question_created_time":1670484833530,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1121196\/azure-ml-reinforcement-learning-eperiment-submit-o",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Context of where I am:    <\/p>\n<ul>\n<li> I'm using &quot;azureml.contrib.train.rl&quot; in Python SDK (current version).    <\/li>\n<li> I'm also using the PONG notebook as starter.    <\/li>\n<li> The ML workspace and two computes have been created using ARM\/DevOps.    <\/li>\n<\/ul>\n<p>The issue:    <\/p>\n<ul>\n<li> It seems that when the training code calls <code>Experiment.submit<\/code> - internally, it ends up with <code>reinforcement_learning_operations.py<\/code>#94 - where a POST call is made to <code>https:\/\/australiaeast.experiments.azureml.net\/reinforcementlearning\/v1.0\/subscriptions\/xxxxxxxx\/resourceGroups\/rg-xxx-xxx-ae-demo\/providers\/Microsoft.MachineLearningServices\/workspaces\/mlw-xxx-xxx-ae-demo\/experiments\/rllib-pong-multi-node-2\/startrun\/rllib-pong-multi-node-2_1670483726_01fc29d0<\/code>    <\/li>\n<li> The response comes back as 530, and the response content is 'unkown to cluster'    <\/li>\n<\/ul>\n<p>Could you please review this issue and guide me through diagnosing it?    <\/p>\n<p>Thank you.    <\/p>\n<ul>\n<li> Rikki    <\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"best practice to apply logic regression in azure ml",
        "Question_created_time":1669838650910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1111053\/best-practice-to-apply-logic-regression-in-azure-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p> I am developing my logic regression model and I want to use azure ml to do so. What is the best proactive way to do it? How to start<\/p>",
        "Question_closed_time":1669854799130,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d871097d-7248-431e-be81-1cf586fe17a0\">@kevin  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I would suggest you start from below sample for regression project - <a href=\"https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/text-classification-wiki.md\">https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/text-classification-wiki.md<\/a>    <\/p>\n<p>This sample demonstrates how to use text analytics modules to build a text classification pipeline in Azure Machine Learning designer.    <\/p>\n<p>The goal of text classification is to assign some piece of text to one or more predefined classes or categories. The piece of text could be a document, news article, search query, email, tweet, support tickets, customer feedback, user product review etc. Applications of text classification include categorizing newspaper articles and news wire contents into topics, organizing web pages into hierarchical categories, filtering spam email, sentiment analysis, predicting user intent from search queries, routing support tickets, and analyzing customer feedback.    <\/p>\n<p>This pipeline trains a multiclass logistic regression classifier to predict the company category with Wikipedia SP 500 dataset derived from Wikipedia.    <\/p>\n<p><img src=\"https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/media\/text-classification-wiki\/nlp-modules-overall.png?raw=true\" alt=\"nlp-modules-overall.png\" \/>    <\/p>\n<p>This is a good example if you want to design your project, I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Question on Tutorial Part 2 of tutorial-designer-automobile-price-deploy Azure Machine Learning Studio",
        "Question_created_time":1670373533030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1119060\/question-on-tutorial-part-2-of-tutorial-designer-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi    <\/p>\n<p>I am trying to follow the tutorial at this link here    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy<\/a>    <\/p>\n<p>There is a really important concept presented as an note in a purple box near the top of the tutorial about not having to supply the price since this is what the model is trying to predict .  The concept is presented but there is no example so I am struggling  trying to understand what I am supposed to do exactly    <\/p>\n<p>Here is the concept presented    <\/p>\n<p><em>By default, the Web Service Input will expect the same data schema as the component output data which connects to the same downstream port as it. In this sample, Web Service Input and Automobile price data (Raw) connect to the same downstream component, hence Web Service Input expect the same data schema as Automobile price data (Raw) and target variable column price is included in the schema. However, usually When you score the data, you won't know the target variable values. For such case, you can remove the target variable column in the inference pipeline using Select Columns in Dataset component. Make sure that the output of Select Columns in Dataset removing target variable column is connected to the same port as the output of the Web Service Input component.<\/em>    <\/p>\n<p>Does anyone know what I am supposed to do to achieve this important concept within the pipeline I have created?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why explanation dashboard is showing 2 tabs with duplicate information in Azure ML Studio?",
        "Question_created_time":1669620849057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1106407\/why-explanation-dashboard-is-showing-2-tabs-with-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When using explanations for AutoML models or standalone model, the explanation dashboard has 2 tabs which displays same information.    <\/p>\n<p>I am using azureml-interpret to explain the models that are executed under azure context  and upload the explanations into Azure ML studio.    <br \/>\nI use global_explanation and local_explanation to explain the overall model performance and local model performance.    <\/p>\n<p>I guess this is creating 2 tabs if I am correct, but both of them seems to have same or duplicate information. I don't understand what is the need for that?    <\/p>\n<p>This seem to the case when I use AutoML models also, there is 2 tabs which has same information. Note, here I am not uploading anything,  it is by default uploading the model explanations and I am using azure-python-sdk-v1.    <\/p>\n<p>I have provided the accompanying screenshots with the information, please let me know if there is gap in my understanding or it is problem with the azure explanation?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264609-first-tab-information.png?platform=QnA\" alt=\"264609-first-tab-information.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264610-second-tab-information.png?platform=QnA\" alt=\"264610-second-tab-information.png\" \/>    <\/p>",
        "Question_closed_time":1669634696120,
        "Answer_score_count":1.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b3da8189-5298-4acf-8e9a-e4e5f7b30c14\">@Bharath Kumar Loganathan  <\/a> I think the explanation ids are based on the raw and engineered datasets. Raw explanations are based on the features from the original dataset and engineered explanations are based on the features from the dataset with feature engineering applied. The documentation from these links provides a bit more information about the different explanation ids. If you expand the menu on the left this should confirm the same.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264729-image.png?platform=QnA\" alt=\"264729-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"information required on ml",
        "Question_created_time":1670398969097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1119574\/information-required-on-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>How do we write back the results into ADLS when we link Azure ML to Synapse ?    <\/p>\n<p>Can azure machine learning take delta file as input data set for model building from enriched, curated zone ?    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot access terminal jupyter in compute instance",
        "Question_created_time":1669933676927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1112789\/cannot-access-terminal-jupyter-in-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi I've been following the Azure for data science course on coursera and i've encountered the following problem.    <\/p>\n<p>After creating a compute instance, i cannot access jupyter, terminal and kernels.    <\/p>\n<p>After some research i've tried to disable avast protection for websockets, microsoft firewall but to no avail.    <br \/>\nI've also tried to restart and even create new compute instances but it didn't solve the problem.    <\/p>\n<p>funny thing, it worked for the first time i used it and then not.    <\/p>\n<p>the compute istance has France for its location , Standard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk) for the VM size and CPU for the processing unit.    <\/p>\n<p>the troubleshooting page says that i should configure my workspace to allow websocket connections, how do i enable them?    <\/p>\n<p>Any advice?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azureml Attached VM cannot run the specified environment (docker)",
        "Question_created_time":1670306520083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1117711\/azureml-attached-vm-cannot-run-the-specified-envir",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<h3 id=\"i-created-a-spot-vm-and-wanted-it-to-execute-python-code-and-the-environment-i-used-is-a-dockerimage-in-a-private-acr----\">I created a Spot VM and wanted it to execute python code. And the environment I used is a DockerImage in a private ACR.    <\/h3>\n<h4 id=\"however-from-the-running-result-the-dockerimage-was-not-downloaded-and-executed----\">However from the running result, the DockerImage was not downloaded and executed.    <\/h4>\n<h3 id=\"code----\">Code    <\/h3>\n<pre><code># prepare env  \nenv = Environment(&quot;XXX&quot;)  \nenv.docker.base_image = &quot;XXXX:latest&quot;  \nenv.python.user_managed_dependencies = True  \nenv.docker.base_image_registry.address = &quot;XXX.azurecr.io&quot;  \n\n# Specify a attached VM  \ncompute_target = RemoteCompute(workspace=ws, name=cluster_name)  \n\n# ScriptRunConfig  \nsrc = ScriptRunConfig(source_directory='.',  \n                  script='XXXX.py',  \n                  compute_target=compute_target,  \n                  environment=env)  \n<\/code><\/pre>\n<h4 id=\"if-i-dont-use-attached-vm-this-code-will-execute-by-using-compute-instance----\">If I don't use attached VM this code will execute by using Compute Instance.    <\/h4>\n<h4 id=\"how-can-i-solve-this-problem----\">How can I solve this problem?    <\/h4>\n<h3 id=\"error-log----\">Error Log    <\/h3>\n<blockquote>\n<p>[2022-12-06T05:42:37.294840] The experiment failed. Finalizing run...    <br \/>\n[2022-12-06T05:42:37.294853] Start FinalizingInRunHistory    <br \/>\n[2022-12-06T05:42:37.295683] Logging experiment finalizing status in history service.    <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 5158    <br \/>\n[2022-12-06T05:42:37.419166]Hosttool Job Error file path is not set    <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 5158    <br \/>\nTraceback (most recent call last):    <br \/>\n  File &quot;XXX.py&quot;, line 3, in &lt;module&gt;    <br \/>\n    import pandas as pd    <br \/>\nModuleNotFoundError: No module named 'pandas'    <\/p>\n<p>[2022-12-06T05:42:37.500050] Finished context manager injector with Exception.    <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Explanation IDs have different number of datapoints",
        "Question_created_time":1670332549017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1118298\/explanation-ids-have-different-number-of-datapoint",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>As per my understanding the 2 tabs in the explanation dashboard of ML studio represents the &quot;raw&quot; and &quot;engineered&quot; feature explanations.    <\/p>\n<p>Therefore, each of the tab must have same number of datapoints, but in the below screenshot, it does not behave like that. The first tab has 1 datapoint and second tab has 34 datapoint. But ideally it should be 34 datapoints in both the tabs.    <\/p>\n<p>Also, is there information where we can find which explanation id belongs to raw features and which explanation id belongs to engineered features.    <\/p>\n<p>Another question, is there an option to choose only one between raw or engineered features for explanation?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/267750-1st-tab.png?platform=QnA\" alt=\"267750-1st-tab.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/267754-2nd-tab.png?platform=QnA\" alt=\"267754-2nd-tab.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model explanation job failing",
        "Question_created_time":1670280861333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1117134\/model-explanation-job-failing",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>In Azure Automated ML, the Model explanation job keeps failing. I believe there is a timeout of 60 minutes that it is hitting.     <\/p>\n<p>Warning: AzureMLCompute job failed. MaxWallClockTimeExpired: Job was terminated since it's execution time exceeded the max_run_duration_seconds.    <\/p>\n<p>Is there a way to override the max run duration? Or any other kind of workaround?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Predict whether use azure machine learning service",
        "Question_created_time":1669753848153,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109255\/predict-whether-use-azure-machine-learning-service",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am new to this feature, can you help with whether I should use the machine learning service? I am confused on whether and when to use it.    <\/p>",
        "Question_closed_time":1669756893180,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=4467f1b6-0740-4467-92e0-70187f3663c9\">@geiko sun  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A, I think you are mentioning you want to do predication and want to know if Azure Machine Learning can make it?     <\/p>\n<p>The quick answer is yes.     <\/p>\n<p>I will provide some samples for predictions in different scenarios in Designer - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/samples-designer\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/samples-designer<\/a>    <\/p>\n<p>You can follow the guidance to do a quick try to see if this is the style you want or not.    <\/p>\n<p>There are more examples in SDK and CLI if you are familiar with coding and prefer to do that in code style - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\">https:\/\/github.com\/Azure\/azureml-examples<\/a>    <\/p>\n<p>Please do take a look and have a try, let me know ifyou have any questions.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"New Azure ML failed run due to utf8 code",
        "Question_created_time":1669408545177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1105085\/new-azure-ml-failed-run-due-to-utf8-code",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,  <br \/>\nError to use new AMl pipeline with a simpe mannual input and R script module:<\/p>\n<p>AmlExceptionMessage:{&quot;NonCompliant&quot;:&quot;Process '\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/bin\/python' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: ModuleReflector(parser.module_entry, env).exec(\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\&quot;, line 397, in exec\\n self._handle_exception(bex)\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\&quot;, line 471, in _handle_exception\\n raise exception\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\&quot;, line 379, in exec\\n output_tuple = self._entry.func(**reflected_input_ports, **reflected_parameters)\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\&quot;, line 76, in wrapper\\n ret = func(*args, **validated_args)\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modules\/r_language_modules\/execute_r_script.py\\&quot;, line 174, in run\\n return _run_impl(**input_values)\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modules\/r_language_modules\/execute_r_script.py\\&quot;, line 278, in _run_impl\\n ErrorMapping.throw(FailedToEvaluateScriptError(\\n File \\&quot;\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/common\/error.py\\&quot;, line 835, in throw\\n raise err\\nazureml.studio.common.error.FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\\n---------- Start of error message from R interpreter ----------\\nGot exception when invoking script: ''utf-8' codec can't decode byte 0xe2 in position 105: invalid continuation byte'.\\n---------- End of error message from R interpreter ----------\\n\\n'. Please check the log file 'user_logs\/std_log.txt' for more details.&quot;}  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;ExecutionFailed&quot;,  <br \/>\n&quot;target&quot;: &quot;&quot;,  <br \/>\n&quot;category&quot;: &quot;UserError&quot;,  <br \/>\n&quot;error_details&quot;: [  <br \/>\n{  <br \/>\n&quot;key&quot;: &quot;exit_codes&quot;,  <br \/>\n&quot;value&quot;: &quot;1&quot;  <br \/>\n}  <br \/>\n]  <br \/>\n}<\/p>\n<p>ModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:<\/p>\n<hr \/>\n<p>Start of error message from R interpreter ----------  <br \/>\nGot exception when invoking script: ''utf-8' codec can't decode byte 0xe2 in position 105: invalid continuation byte'.<\/p>\n<hr \/>\n<p>End of error message from R interpreter ----------<\/p>\n<p>What could be wrong?<\/p>\n<p>Thanks,  <br \/>\nA.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Will the python version of docker image for training be impacted by Azure's notice \"Stop support Python 3.6 on 5 December 2022\"?",
        "Question_created_time":1669968457547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1113439\/will-the-python-version-of-docker-image-for-traini",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi guys,    <\/p>\n<p>I received the email notice that &quot;Azure Machine Learning will stop support for Python 3.6 on 5 December 2022 \u2013 transition to Python 3.8 or later.&quot;    <br \/>\nWill the python version of docker image for training be impacted by Azure's notice &quot;Stop support Python 3.6 on 5 December 2022&quot;?    <br \/>\ndocker image for training is the &quot;custom_docker_image&quot; set in &quot;Estimator&quot;.    <br \/>\nCurrently we have several model training using docker with python 3.6.    <\/p>\n<p>Thanks,    <br \/>\nHaoran    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AI gallery for Designer",
        "Question_created_time":1669766733727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109523\/ai-gallery-for-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, there was a website for machine learning studio. You can publish your pipelines and you can also get others publish. But it not works for designer. Is there any plan for the platform migration? <\/p>",
        "Question_closed_time":1669854634263,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=662ea9f1-8d5c-4484-9ff1-c27d48858639\">@Markswift  <\/a>     <\/p>\n<p>I am sorry the AI gallery currently is not supporting Azure Machine Learning Service Designer at this moment, but I do see there are some sample shared by offcial product team. Currently you can refer to it for general style project.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/265941-image.png?platform=QnA\" alt=\"265941-image.png\" \/>    <\/p>\n<p>I will bring this feedback to product team, but at this moment we still need to wait for the next step plan. I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to suppor the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to authenticate to ML Classic from HTTP Request in Flow",
        "Question_created_time":1669948696717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1113097\/how-to-authenticate-to-ml-classic-from-http-reques",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi - Hoping someone can help    <\/p>\n<p>Keep getting 401 error and cannot authenticate to a published Azure ML experiment using a Post in HTTP action within Flow    <\/p>\n<p>Guessing you use Basic authentication and supplied creds in action (as shown in the screenshot attached) but keep getting 401 error    <\/p>\n<p>See attached image of HTTP Post - anyone know how to authenticate so I can call Azure ML if created from flow?    <\/p>\n<p>I know it is possible but how???    <\/p>\n<p>Thx!    <\/p>\n<p>Stumped as I cannot find any documentation how to do it anywhere    <\/p>\n<p>Thx!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/266358-post-screenshot.jpg?platform=QnA\" alt=\"266358-post-screenshot.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the difference between R-squared generated during machine learning model training and the R-squared generated for model performance under Explanations?",
        "Question_created_time":1669146778730,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1100346\/what-is-the-difference-between-r-squared-generated",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>For some of my ML experiments, I've selected R-squared as the primary metric for guiding the training. I also noticed that under the Explanations section of the algorithm overview, there is a section called Model Performance and with it, a box plot graph that also shows a different value for R-squared.    <\/p>\n<p>What is the difference between these two values of R-squared?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/263213-r2.png?platform=QnA\" alt=\"263213-r2.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio - Create Environment with private ACR is blocked by Firewall",
        "Question_created_time":1663859823703,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1019515\/azure-machine-learning-studio-create-environment-w",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>We have a Azure Machine Learning Studio, which is connected to a private ACR. The ACR sits behind a Firewall and has a private endpoint to our VNET.    <\/p>\n<p>In Machine Learning Studio, when using the feature &quot;Environments&quot; -&gt; &quot;Custom Environments&quot; -&gt; &quot;Create&quot; -&gt; &quot;Use existing docker image with conda&quot; and &quot;<em>imagePathInOurPrivateRegistry<\/em>&quot;, we get the error &quot;Logging in to registry: <em>ourregistry<\/em>.azurecr.io    <br \/>\nfailed to login, ran out of retries: failed to set docker credentials: Error response from daemon: Get &quot;https:\/\/<em>ourregistry<\/em>.azurecr.io\/v2\/&quot;: denied: client with IP '20.50.200.109' is not allowed access.&quot;. A manual approach to fix this, was to whitelist the mentioned IP address in the Firewall Settings of our ACR.    <\/p>\n<p>I know there is a public list of IP adresses, which are used by AzureML. But these are way over 300 and I don't think it is a proper solution to whitelist all of them.    <\/p>\n<p>What would be the best solution to fix this?    <\/p>\n<ul>\n<li> This article ( <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-workspace-vnet?tabs=pe%2Ccli#azure-container-registry-1\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-workspace-vnet?tabs=pe%2Ccli#azure-container-registry-1<\/a>) states an environment has to be created from one of our Compute Instances, which can be placed in our VNET. Is there an article describing how to create a custom environment via Compute Instance? This seems to me a rather complicated way for a feature, which is directly included in Azure ML. Do I miss something here?    <\/li>\n<li> Is there a way to get the IP Address of our current Azure ML Studio?    <\/li>\n<li> When creating this environment, what hardware or compute instance is used? Our ML workspace currently has only one Compute Cluster, which is integrated in our VNET. There is no compute instance.    <\/li>\n<\/ul>\n<p>Thanks in advance and kind regards!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Import issue with azureml-train-automl-runtime package",
        "Question_created_time":1669689516027,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1107805\/import-issue-with-azureml-train-automl-runtime-pac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to import azureml-train-automl-runtime to do explanations from azure automl pipeline following the tutorial in the link <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-machine-learning-interpretability-automl\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-machine-learning-interpretability-automl<\/a>    <\/p>\n<p>But I am getting the below error    <\/p>\n<pre><code>Exception ignored in: &lt;function _Win32Helper.del at 0x0000021ECA3AD430&gt; Traceback (most recent call last): File &quot;C:\\Anaconda3\\envs\\check_win32_error\\lib\\site-packages\\azureml\\automl\\runtime\\shared\\win32_helper.py&quot;, line 246, in del TypeError: catching classes that do not inherit from BaseException is not allowed  \n<\/code><\/pre>\n<p><strong>Error Screenshot:<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264938-image.png?platform=QnA\" alt=\"264938-image.png\" \/>    <\/p>\n<p>I asked this question in stackoverflow but did not get valid answer,    <br \/>\nplease refer to the stackoverflow link below:    <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/74160617\/baseexception-when-trying-to-import-azureml-train-automl-runtime-in-windows-10\">https:\/\/stackoverflow.com\/questions\/74160617\/baseexception-when-trying-to-import-azureml-train-automl-runtime-in-windows-10<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Create ML-model endpoint based on image in other container registry",
        "Question_created_time":1669734991270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1108820\/create-ml-model-endpoint-based-on-image-in-other-c",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hey,     <br \/>\nI want to deploy my ML-model in an Azure Container Instance, which is accessable over a REST-endpoint for inference. Important is, that I need to create the ACI with images, that are not in the automaticly created Azure Container Registry in my own subscription, but in a centrally organized one.     <br \/>\nIs there a possibility to specify the ACR I want to use in the deployment?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML VS Code integration with synapse spark pool as attached computes",
        "Question_created_time":1669791827530,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109976\/aml-vs-code-integration-with-synapse-spark-pool-as",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey!    <br \/>\nThe VS code integration in the AML ecosystem is great.    <br \/>\nIs it possible to debug using the synapse spark pool as it attached compute (like I am running notebook on it)    <br \/>\nCurrently from the VS code only compute instance is supported .    <br \/>\nAm I missing something?    <\/p>\n<p>Thanks,    <br \/>\nMaya<\/p>",
        "Question_closed_time":1669871984343,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce96d2b0-635e-4ed7-b685-15e43ebb5007\">@Maya Shauli  <\/a>,    <\/p>\n<p>Thanks for the question and using MS platform.    <\/p>\n<blockquote>\n<p>Unfortunately,  synapse spark pool as it attached compute on Visual Code is no longer supported.    <\/p>\n<\/blockquote>\n<p>Appreciate if you could share the feedback on our <a href=\"https:\/\/feedback.azure.com\/d365community\/idea\/184e6a07-14fa-ec11-a81b-6045bd853c94\">feedback channel<\/a>. Which would be open for the user community to upvote &amp; comment on. This allows our product teams to effectively prioritize your request against our existing feature backlog and gives insight into the potential impact of implementing the suggested feature.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is jhow you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I increase the swap space in a linux compute instance?",
        "Question_created_time":1669803899547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1110239\/how-do-i-increase-the-swap-space-in-a-linux-comput",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I'm using Microsoft Azure Machine Learning to train a model. The problem is that the process gets terminated. I'm almost 100% sure that it happens because I dont have enough virtual memory.     <\/p>\n<p>I've tried this <a href=\"https:\/\/azure.microsoft.com\/es-es\/blog\/swap-space-in-windows-azure-virtual-machines-running-pre-built-linux-images-part-1\/\">https:\/\/azure.microsoft.com\/es-es\/blog\/swap-space-in-windows-azure-virtual-machines-running-pre-built-linux-images-part-1\/<\/a> but when I do swapon i get &quot;insecure premissions 077, 0600 suggested&quot;. It seems that my chmod 600 is not doing the trick.    <\/p>\n<p>Any sugestions to increase the swap size using my file share?    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best practice for model deployment (Real-time Endpoints vs Compute Inference Cluster)",
        "Question_created_time":1669291283107,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1103168\/best-practice-for-model-deployment-(real-time-endp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello community!  <br \/>\nReaching out for some help here.<\/p>\n<p><em>ManagedOnlineDeployment<\/em>\n vs <em>KubernetesOnlineDeployment<\/em><\/p>\n<p><strong>Goal:<\/strong><\/p>\n<p>Host a large number of distinct models on Azure ML.<\/p>\n<p><strong>Description:<\/strong><\/p>\n<p>After throughout investigation, I found out that there are two ways to host a pre-trained real-time model (i.e., run inference) on Azure ML.  <\/p>\n<ul>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\">Real-time Endpoints - Managed Online Deployment<\/a>  <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-attach-kubernetes-anywhere\">Compute Inference cluster - kubernetes-online-endpoints<\/a>  <br \/>\nThe differences between the two options are detailed <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints#managed-online-endpoints-vs-kubernetes-online-endpoints\">here<\/a>.  <br \/>\nI want to host a large number of distinct models (i.e., endpoints) while having the best price\/performance\/ease-of-deployment ratio.<\/li>\n<\/ul>\n<p><strong>Details:<\/strong><\/p>\n<ul>\n<li>   What I tried  <br \/>\n    I have 4 running VMs as a result of my creation of 4 real-time endpoints. Those endpoints use Curated Environments that are provided by <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-curated-environments\">Microsoft<\/a>.  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/263904-epsquotas.png?platform=QnA\" alt=\"263904-epsquotas.png\" \/>  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/263922-realtimeendpoints.png?platform=QnA\" alt=\"263922-realtimeendpoints.png\" \/><\/li>\n<\/ul>\n<hr \/>\n<ul>\n<li>   Issues\n<ol>\n<li>  When I want to create a custom environment out of a docker file and then use it as a base image for a certain endpoint, it is a long process:  <br \/>\n        Build Image &gt; Push Image to CR &gt; Create Custom Environment in AzureML &gt; Create and Deploy Endpoint  <br \/>\n        If something goes wrong, it only shows when I finish the whole pipeline. It just doesn't feel like the correct way of deploying a model.  <br \/>\n        This process is needed when I cannot use one of the curated environments because I need some dependency that cannot be imported using the conda.yml file  <br \/>\n        For example:<\/li>\n<\/ol>\n<\/li>\n<\/ul>\n<blockquote>\n<p>RUN apt-get update -y &amp;&amp; apt-get install build-essential cmake pkg-config -y  <br \/>\nRUN python setup.py build_ext --inplace<\/p>\n<\/blockquote>\n<ol start=\"2\">\n<li>  Although I'm using 1 instance per endpoint (Instance count = 1), each endpoint creates its dedicated VM which will cost me a lot in the long run (i.e., when I have lots of endpoints), now it is costing me around 20$ per day.<\/li>\n<\/ol>\n<hr \/>\n<ul>\n<li>   Note: Each endpoint has a distinct set of dependencies\/versions...<\/li>\n<\/ul>\n<hr \/>\n<ul>\n<li>   Questions  <br \/>\n    1- Am I following the best practice? Or do I need to drastically change my deployment strategy (Move from <em>ManagedOnlineDeployment<\/em> to <em>KubernetesOnlineDeployment<\/em> or even another option that I don't know of)?  <br \/>\n    2- Is there a way to host all the endpoints on a single VM? Rather than creating a VM for each endpoint. To make it affordable.  <br \/>\n    3- Is there a way to host the endpoints and get charged per transaction?<\/li>\n<\/ul>\n<hr \/>\n<p>General recommendations and clarification questions are more than welcome.<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while depolying Whisper Model in batch pipeline",
        "Question_created_time":1667482799767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1074438\/error-while-depolying-whisper-model-in-batch-pipel",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I'm trying to deploy the OpenAI Whisper model with a batch pipeline, following the example notebook: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/file-dataset-image-inference-mnist.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/file-dataset-image-inference-mnist.ipynb<\/a>    <\/p>\n<p>I'm using the STANDARD_NC6S_V3 Machine.     <\/p>\n<p>I keep getting the following error:    <\/p>\n<ul>\n<li> Error '\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/lib\/..\/..\/nvidia\/cublas\/lib\/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11   File &quot;\/mnt\/azureml\/cr\/j\/3f034c6e7a1b4166b24b196339e7b655\/exe\/wd\/whisper_transcribe.py&quot;, line 3, in &lt;module&gt;    <br \/>\n    import whisper  <br \/>\n  File &quot;\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/whisper\/<strong>init<\/strong>.py&quot;, line 8, in &lt;module&gt;    <br \/>\n    import torch  <br \/>\n  File &quot;\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/<strong>init<\/strong>.py&quot;, line 191, in &lt;module&gt;    <br \/>\n    _load_global_deps()  <br \/>\n  File &quot;\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/<strong>init<\/strong>.py&quot;, line 153, in _load_global_deps    <br \/>\n    ctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)  <br \/>\n  File &quot;\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/ctypes\/<strong>init<\/strong>.py&quot;, line 382, in <strong>init<\/strong>    <br \/>\n    self._handle = _dlopen(self._name, mode)'   <\/li>\n<\/ul>\n<p>I can't find what causes the error, but I think it has to do with the machine I'm deploying on, because with a different machine, the error did not appear.    <br \/>\nhelp will be much appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Data Labeling: labeler can access the project but can't see the data",
        "Question_created_time":1669659426597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1107289\/azure-machine-learning-data-labeling-labeler-can-a",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Granted the &quot;labeler&quot; permission. But when vendor clicked the &quot;start labeling&quot; button, blank under &quot;Tasks&quot;. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning samples 404",
        "Question_created_time":1669742901290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109020\/azure-machine-learning-samples-404",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am looking for sample of notebook\/SDK, but this link is not working at all. Any new repo for reference? <a href=\"https:\/\/learn.microsoft.com\/en-us\/samples\/azure\/azureml-examples\/azure-machine-learning-examples\/\">https:\/\/learn.microsoft.com\/en-us\/samples\/azure\/azureml-examples\/azure-machine-learning-examples\/<\/a><\/p>",
        "Question_closed_time":1669743760393,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=79877fab-184b-4267-bfdd-49ea0b34bfe1\">@Yadama Kenzan  <\/a>     <\/p>\n<p>Thanks for reporting this issue, is there any place you got the link or it's from the web search? This link has been deprecated.    <\/p>\n<p>Please see this repo for SDK V2 samples\/ CLI V2 samples - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\">https:\/\/github.com\/Azure\/azureml-examples<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/265362-image.png?platform=QnA\" alt=\"265362-image.png\" \/>    <\/p>\n<p>Please let me know where this link is from so that I can fix the resource as well.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to share project to my team",
        "Question_created_time":1669425813897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1105193\/how-to-share-project-to-my-team",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to share my whole project to my team in CLI, how to do that, can\u2019t find any document about that.    <\/p>",
        "Question_closed_time":1669459235147,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=48a2ff5d-608a-4174-9e75-20f9e77fd20f\">@sursala terrano  <\/a>     <\/p>\n<p>Thanks for reaching out to us, which version you are working on?     <\/p>\n<p>For Azure Machine Learning CLI V1, you should use az ml workspace share commands     <\/p>\n<p>For Azure Machine Learning CLI V2, you should use az role assignment create commands    <\/p>\n<p>Please refer to below document -     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/workspace?view=azure-cli-latest\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/workspace?view=azure-cli-latest<\/a>    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Hide arugments of the Job properties on AzureML ?",
        "Question_created_time":1667818798267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1078267\/hide-arugments-of-the-job-properties-on-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I would like to know if there is a way to hide specific Arguments from being displayed in the properties Tab of a Job ?     <br \/>\nThis would be helpful because for the run i have to pass several IDs and dont want it to be displayed. I am using a ScriptRunConfig() function to which i am passing the arguments.    <br \/>\nThanks in advance     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"deploy-a-model-as-a-service: <Response [400]>",
        "Question_created_time":1668961426670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1096747\/deploy-a-model-as-a-service-(response-(400))",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi There,    <br \/>\nSorry if this very silly mistake. I am onto &quot;microsoft-azure-machine-learning&quot;. Just created account, and set up environment    <\/p>\n<p>If I got to Endpoints --&gt; Consume -- &gt; Python snippet, it runs fine in Jupyter within Azure Studio    <\/p>\n<p>However, when I try to run test code (endpoint and key replaced as required), I am getting below error    <\/p>\n<p>&lt;Response [400]&gt;    <\/p>\n<p>Basic difference in snippet and exercise is     <\/p>\n<p>endpoint = 'http:\/\/URL\/score' #Replace with your endpoint     <br \/>\nkey = 'my key' #Replace with your key     <\/p>\n<p>url = 'http:\/\/URL\/score'    <br \/>\napi_key = 'my key' # Replace this with the API key for the web service    <\/p>\n<p>ANy help would be great    <\/p>\n<p>Regards    <br \/>\nNikhil    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AciDeploymentFailed",
        "Question_created_time":1655464430947,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/893526\/acideploymentfailed",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>It's been a few days already since I've been struggling with this error which is not suggesting me anything.    <br \/>\nThis is the error I receive. Every time I'm trying to access the logs it displays me <em>&quot;None&quot;<\/em>. Also, the init() function is a very basic one. It's the one I've found in your tutorials and while I've followed your tutorials I didn't encounter this bug.    <\/p>\n<p><em><strong>score.py script:<\/strong><\/em>    <\/p>\n<pre><code>import pandas as pd  \nimport numpy as np  \nimport joblib  \nimport json  \nimport os  \n  \n# Called when the service is loaded  \ndef init():  \n    global model  \n    # Get the path to the deployed model file and load it  \n    model = joblib.load(Model.get_model_path(model_name='aml_live_model_end'))  \n  \n# Called when a request is received  \ndef run(raw_data):  \n    # Get the input data as a numpy array  \n    data = np.array(json.loads(raw_data)['data'])  \n    # Get a prediction from the model  \n    predictions = model.predict(data)  \n    # Get the corresponding classname for each prediction (0 or 1)  \n    classnames = ['De avizat', 'De analizat']  \n    predicted_classes = []  \n    for prediction in predictions:  \n        predicted_classes.append(classnames[prediction])  \n    # Return the predictions as JSON  \n    return json.dumps(predicted_classes)  \n<\/code><\/pre>\n<p><em><strong>.yaml file<\/strong><\/em>    <\/p>\n<pre><code>name: aml_live_env  \ndependencies:  \n- python=3.6.2  \n- scikit-learn  \n- ipykernel  \n- matplotlib  \n- pandas  \n- pip  \n- pip:  \n  - azureml-defaults  \n  - pyarrow  \n<\/code><\/pre>\n<p><em><strong>The error I receive<\/strong><\/em>    <\/p>\n<pre><code>Deploying model...  \nTips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.  \nRunning  \n2022-06-17 10:52:16+00:00 Creating Container Registry if not exists.  \n2022-06-17 10:52:16+00:00 Registering the environment.  \n2022-06-17 10:52:17+00:00 Use the existing image.  \n2022-06-17 10:52:17+00:00 Generating deployment configuration.  \n2022-06-17 10:52:18+00:00 Submitting deployment to compute.  \n2022-06-17 10:52:20+00:00 Checking the status of deployment aml-live-service-model..  \n2022-06-17 10:54:07+00:00 Checking the status of inference endpoint aml-live-service-model.  \nFailed  \nService deployment polling reached non-successful terminal state, current service state: Failed  \nOperation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f  \nMore information can be found using '.get_logs()'  \nError:  \n{  \n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n  &quot;statusCode&quot;: 400,  \n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,  \n  &quot;details&quot;: [  \n    {  \n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;  \n    },  \n    {  \n      &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:  \n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.  \n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.  \n\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.  \n&quot;RestartCount&quot;: 5  \n&quot;CurrentState&quot;: {&quot;state&quot;:&quot;Waiting&quot;,&quot;startTime&quot;:null,&quot;exitCode&quot;:null,&quot;finishTime&quot;:null,&quot;detailStatus&quot;:&quot;CrashLoopBackOff: Back-off restarting failed&quot;}  \n&quot;PreviousState&quot;: {&quot;state&quot;:&quot;Terminated&quot;,&quot;startTime&quot;:&quot;2022-06-17T10:56:57.554Z&quot;,&quot;exitCode&quot;:111,&quot;finishTime&quot;:&quot;2022-06-17T10:57:01.314Z&quot;,&quot;detailStatus&quot;:&quot;Error&quot;}  \n&quot;Events&quot;:  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:26:38Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:26:38Z&quot;,&quot;name&quot;:&quot;Pulling&quot;,&quot;message&quot;:&quot;pulling image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:27:42Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:27:42Z&quot;,&quot;name&quot;:&quot;Pulled&quot;,&quot;message&quot;:&quot;Successfully pulled image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:10,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:28:00Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:47:11Z&quot;,&quot;name&quot;:&quot;Started&quot;,&quot;message&quot;:&quot;Started container&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:9,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:28:03Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:40:46Z&quot;,&quot;name&quot;:&quot;Killing&quot;,&quot;message&quot;:&quot;Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:31:33Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:31:33Z&quot;,&quot;name&quot;:&quot;Pulling&quot;,&quot;message&quot;:&quot;pulling image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:32:31Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:32:31Z&quot;,&quot;name&quot;:&quot;Pulled&quot;,&quot;message&quot;:&quot;Successfully pulled image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:5,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:47:52Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:52:09Z&quot;,&quot;name&quot;:&quot;Started&quot;,&quot;message&quot;:&quot;Started container&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:6,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:48:26Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:52:37Z&quot;,&quot;name&quot;:&quot;Killing&quot;,&quot;message&quot;:&quot;Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n&quot;  \n    }  \n  ]  \n}  \n  \n---------------------------------------------------------------------------  \nWebserviceException                       Traceback (most recent call last)  \n&lt;ipython-input-17-315dbb5f83ec&gt; in &lt;module&gt;  \n     16 service_name = &quot;aml-live-service-model&quot;  \n     17 service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)  \n---&gt; 18 service.wait_for_deployment(True)  \n     19 print(service.state)  \n  \n\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output, timeout_sec)  \n    916                     logs_response = 'Current sub-operation type not known, more logs unavailable.'  \n    917   \n--&gt; 918                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '  \n    919                                           'service state: {}\\n'  \n    920                                           'Operation ID: {}\\n'  \n  \nWebserviceException: WebserviceException:  \n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed  \nOperation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f  \nMore information can be found using '.get_logs()'  \nError:  \n{  \n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n  &quot;statusCode&quot;: 400,  \n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,  \n  &quot;details&quot;: [  \n    {  \n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;  \n    },  \n    {  \n      &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:  \n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.  \n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.  \n\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.  \n&quot;RestartCount&quot;: 5  \n&quot;CurrentState&quot;: {&quot;state&quot;:&quot;Waiting&quot;,&quot;startTime&quot;:null,&quot;exitCode&quot;:null,&quot;finishTime&quot;:null,&quot;detailStatus&quot;:&quot;CrashLoopBackOff: Back-off restarting failed&quot;}  \n&quot;PreviousState&quot;: {&quot;state&quot;:&quot;Terminated&quot;,&quot;startTime&quot;:&quot;2022-06-17T10:56:57.554Z&quot;,&quot;exitCode&quot;:111,&quot;finishTime&quot;:&quot;2022-06-17T10:57:01.314Z&quot;,&quot;detailStatus&quot;:&quot;Error&quot;}  \n&quot;Events&quot;:  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:26:38Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:26:38Z&quot;,&quot;name&quot;:&quot;Pulling&quot;,&quot;message&quot;:&quot;pulling image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:27:42Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:27:42Z&quot;,&quot;name&quot;:&quot;Pulled&quot;,&quot;message&quot;:&quot;Successfully pulled image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:10,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:28:00Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:47:11Z&quot;,&quot;name&quot;:&quot;Started&quot;,&quot;message&quot;:&quot;Started container&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:9,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:28:03Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:40:46Z&quot;,&quot;name&quot;:&quot;Killing&quot;,&quot;message&quot;:&quot;Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:31:33Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:31:33Z&quot;,&quot;name&quot;:&quot;Pulling&quot;,&quot;message&quot;:&quot;pulling image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:32:31Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:32:31Z&quot;,&quot;name&quot;:&quot;Pulled&quot;,&quot;message&quot;:&quot;Successfully pulled image &quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:5,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:47:52Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:52:09Z&quot;,&quot;name&quot;:&quot;Started&quot;,&quot;message&quot;:&quot;Started container&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n{&quot;count&quot;:6,&quot;firstTimestamp&quot;:&quot;2022-06-17T10:48:26Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-06-17T10:52:37Z&quot;,&quot;name&quot;:&quot;Killing&quot;,&quot;message&quot;:&quot;Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n&quot;  \n    }  \n  ]  \n}  \n\tInnerException None  \n\tErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n  \\&quot;statusCode\\&quot;: 400,\\n  \\&quot;message\\&quot;: \\&quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;,\\n  \\&quot;details\\&quot;: [\\n    {\\n      \\&quot;code\\&quot;: \\&quot;CrashLoopBackOff\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;\\n    },\\n    {\\n      \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\&quot;RestartCount\\&quot;: 5\\n\\&quot;CurrentState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Waiting\\&quot;,\\&quot;startTime\\&quot;:null,\\&quot;exitCode\\&quot;:null,\\&quot;finishTime\\&quot;:null,\\&quot;detailStatus\\&quot;:\\&quot;CrashLoopBackOff: Back-off restarting failed\\&quot;}\\n\\&quot;PreviousState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Terminated\\&quot;,\\&quot;startTime\\&quot;:\\&quot;2022-06-17T10:56:57.554Z\\&quot;,\\&quot;exitCode\\&quot;:111,\\&quot;finishTime\\&quot;:\\&quot;2022-06-17T10:57:01.314Z\\&quot;,\\&quot;detailStatus\\&quot;:\\&quot;Error\\&quot;}\\n\\&quot;Events\\&quot;:\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:26:38Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:26:38Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulling\\&quot;,\\&quot;message\\&quot;:\\&quot;pulling image \\&quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:27:42Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:27:42Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulled\\&quot;,\\&quot;message\\&quot;:\\&quot;Successfully pulled image \\&quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:10,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:28:00Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:47:11Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Started\\&quot;,\\&quot;message\\&quot;:\\&quot;Started container\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:9,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:28:03Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:40:46Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Killing\\&quot;,\\&quot;message\\&quot;:\\&quot;Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:31:33Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:31:33Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulling\\&quot;,\\&quot;message\\&quot;:\\&quot;pulling image \\&quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:32:31Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:32:31Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulled\\&quot;,\\&quot;message\\&quot;:\\&quot;Successfully pulled image \\&quot;libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:5,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:47:52Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:52:09Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Started\\&quot;,\\&quot;message\\&quot;:\\&quot;Started container\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:6,\\&quot;firstTimestamp\\&quot;:\\&quot;2022-06-17T10:48:26Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2022-06-17T10:52:37Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Killing\\&quot;,\\&quot;message\\&quot;:\\&quot;Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n\\&quot;\\n    }\\n  ]\\n}&quot;  \n    }  \n}  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What's the best way to preserve Azure ML workspace so that it can be restored",
        "Question_created_time":1669442139003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1105130\/whats-the-best-way-to-preserve-azure-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>What's the best way to preserve Azure ML workspace so that it can be restored at a later point? I was hoping to find some automatic way to take a snapshot of artifacts &amp; code and dump it into Azure storage, but haven't been able to find anything relevant in the online documentation. <\/p>",
        "Question_closed_time":1669596362440,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@VaraPrasad-1740 Thanks for the question. I would recommend you can have a git repository that backs your project.  For some details about this approach you can check <a href=\"https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652\">https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Batchscoring on Batch Endpoint of AutoML model giving error - UserError: {\"NonCompliant\":\"Process",
        "Question_created_time":1669318257423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1103764\/batchscoring-on-batch-endpoint-of-automl-model-giv",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>AutoML time-series model created from Sql Database data. - <strong>successful<\/strong>  <br \/>\nRegistered Model. - <strong>successful<\/strong>  <br \/>\nEndPoints creation - Deploy to Batch End Point. - <strong>successful<\/strong>  <br \/>\nCreating Batchscoring Jon in EndPoint - <strong>Fails<\/strong> with below error.<\/p>\n<p>Error -  <br \/>\n{&quot;NonCompliant&quot;:&quot;Process '\/azureml-envs\/azureml_c9e8754bdba5226a1ab803f256ee343b\/bin\/python' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: Traceback (most recent call last):\\n File \\&quot;driver\/amlbi_main.py\\&quot;, line 184, in &lt;module&gt;\\n main()\\n File \\&quot;driver\/amlbi_main.py\\&quot;, line 126, in main\\n boot(driver_dir)\\n File \\&quot;driver\/amlbi_main.py\\&quot;, line 58, in boot\\n booter.start()\\n File \\&quot;\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\&quot;, line 383, in start\\n self.start_sys_main()\\n File \\&quot;\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\&quot;, line 269, in start_sys_main\\n self.run_sys_main(cmd)\\n File \\&quot;\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_node.py\\&quot;, line 111, in run_sys_main\\n self.check_run_result(proc=proc, stdout=stdout or \\&quot;\\&quot;, stderr=stderr or \\&quot;\\&quot;)\\n File \\&quot;\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\&quot;, line 218, in check_run_result\\n BootResult().check_result(stdout)\\n File \\&quot;\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_result.py\\&quot;, line 36, in check_result\\n raise Exception(message) from cause\\nException: Run failed, please check logs for details. You can check logs\/readme.txt for the layout of logs.\\n\\n'. Please check the log file 'user_logs\/std_log_0.txt' for more details.&quot;}  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;ExecutionFailed&quot;,  <br \/>\n&quot;target&quot;: &quot;&quot;,  <br \/>\n&quot;category&quot;: &quot;UserError&quot;,  <br \/>\n&quot;error_details&quot;: [  <br \/>\n{  <br \/>\n&quot;key&quot;: &quot;exit_codes&quot;,  <br \/>\n&quot;value&quot;: &quot;1&quot;  <br \/>\n}  <br \/>\n]  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"undefined symbol: cublasLtGetStatusString at Endpoint Deployment Error",
        "Question_created_time":1669225633070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1102061\/undefined-symbol-cublasltgetstatusstring-at-endpoi",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi     <\/p>\n<p>I am getting this error while deploying an end point. This was working fine for 3 months and I had to rebuild due to a minor change and started getting this error.    <\/p>\n<p> File &quot;\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py&quot;, line 81, in load_script    <br \/>\n    main_module_spec.loader.exec_module(user_module)  <br \/>\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 843, in exec_module    <br \/>\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed    <br \/>\n  File &quot;\/var\/azureml-app\/221123171914-1667710269\/score.py&quot;, line 6, in &lt;module&gt;    <br \/>\n    import ktrain  <br \/>\n  File &quot;\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/<strong>init<\/strong>.py&quot;, line 191, in &lt;module&gt;    <br \/>\n    _load_global_deps()  <br \/>\n  File &quot;\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/<strong>init<\/strong>.py&quot;, line 153, in _load_global_deps    <br \/>\n    ctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)  <br \/>\n  File &quot;\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/ctypes\/<strong>init<\/strong>.py&quot;, line 373, in <strong>init<\/strong>    <br \/>\n    self._handle = _dlopen(self._name, mode)  <br \/>\nOSError: \/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/lib\/..\/..\/nvidia\/cublas\/lib\/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11    <\/p>\n<p>This is my environment:    <\/p>\n<p>FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220714.v1    <\/p>\n<p>ENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.7    <\/p>\n<h1 id=\"create-conda-environment----\">Create conda environment    <\/h1>\n<p>RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\    <br \/>\n    python=3.8 pip=20.2.4  <\/p>\n<h1 id=\"prepend-path-to-azureml-conda-environment----\">Prepend path to AzureML conda environment    <\/h1>\n<p>ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH    <\/p>\n<h1 id=\"install-pip-dependencies----\">Install pip dependencies    <\/h1>\n<p>RUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\    <br \/>\n                                          'psutil~=5.8.0' \\  <br \/>\n                                          'tqdm~=4.62.0' \\  <br \/>\n                                          'scipy~=1.7.0' \\  <br \/>\n                                          'numpy~=1.21.0' \\  <br \/>\n                                          'ipykernel~=6.0' \\  <br \/>\n                                          # upper bound azure-core to address typing-extensions conflict  <br \/>\n                                          'azure-core&lt;1.23.0' \\  <br \/>\n                                          'azureml-core==1.43.0' \\  <br \/>\n                                          'azureml-defaults==1.43.0' \\  <br \/>\n                                          'azureml-mlflow==1.43.0.post1' \\  <br \/>\n                                          'azureml-telemetry==1.43.0' \\  <br \/>\n                                          'azureml-inference-server-http==0.7.2' \\  <br \/>\n                                          'pandas==1.4.1' \\  <br \/>\n                                          'ktrain==0.30.0' \\  <br \/>\n                                          'sentence-transformers==2.1.0' \\  <br \/>\n                                          'tensorflow==2.7.0' \\  <br \/>\n                                          'tokenizers==0.10.3' \\  <br \/>\n                                          'protobuf~=3.19.1' \\  <br \/>\n                                          'Flask==2.1.0' \\  <br \/>\n                                          'transformers==4.10.3'   <\/p>\n<h1 id=\"this-is-needed-for-mpi-to-locate-libpython----\">This is needed for mpi to locate libpython    <\/h1>\n<p>ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzurePipeline failing with ResourceExhausted error",
        "Question_created_time":1669128558063,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1099870\/azurepipeline-failing-with-resourceexhausted-error",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\nI am using Microsoft Azure Machine Learning Studio to train LSTM model on 600K rows of data for binary classification.    <br \/>\nWhile doing that I am getting this error in 5th\/6th Epoch. Could you please let me know which setting in my Azure should I change to overcome this error.    <br \/>\nLet me know in case you need more information.    <\/p>\n<p>Virtual machine size=&gt; Standard_F8s_v2 (8 cores, 16 GB RAM, 64 GB disk)    <br \/>\nProcessing unit=&gt;CPU - Compute-optimized<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/263096-pipelineerror.jpg?platform=QnA\" alt=\"263096-pipelineerror.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to import prophet",
        "Question_created_time":1650846070067,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/824199\/unable-to-import-prophet",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am attempting to run Prophet (fbprophet) in an Azure Notebook. I have installed prophet using the terminal window and it is listed as an installed package (prophet (0.1.1.post1)).  <\/p>\n<p>When I attempt to import the Prophet module using either of the following commands in a Notebook cell I receive the error message; &quot;ModuleNotFoundError: No module named 'prophet'&quot;  <\/p>\n<pre><code>from fbprophet import Prophet\nor\nfrom prophet import Prophet\n<\/code><\/pre>\n<p>Could someone please assist...thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Working with AzureMachineLearningFileSystem and binary files",
        "Question_created_time":1669043044797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1098198\/working-with-azuremachinelearningfilesystem-and-bi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/how-to-access-data-interactive?tabs=adls\">https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/how-to-access-data-interactive?tabs=adls<\/a> - this is the recommended route in the v2 API for interactive \/ exploratory data access - rather than <code>mount()<\/code> a <code>FileDataset<\/code> object, use this new filesystem-like interface. So far this works:    <\/p>\n<pre><code>   uri = f'azureml:\/\/subscriptions\/{subscription}\/resourcegroups\/{resource_group}\/workspaces\/{workspace}\/datastores\/{datastore_name}\/paths\/{path_on_datastore}'  \n     \n   fs = AzureMachineLearningFileSystem(uri)  \n   fs.ls()  \n<\/code><\/pre>\n<p><code>fs.open('path\/to\/file.tif')<\/code> returns a <code>pystreaminfo_companion.StreamInfoFileObject<\/code> which has io.BytesIO-like behaviours and apparently no documentation on the internet    <\/p>\n<p>In this case we are trying to work with the data using the <code>rasterio<\/code> python package which accepts a python file object or a path as input. This won't work, it throws a read buffer error:    <\/p>\n<pre><code>   raster_data = rasterio.open(fs.open('path\/to\/image.tif'))  \n   img_arr = raster_data.read()  \n<\/code><\/pre>\n<p>We can short-term work around this by reading the byte stream into a rasterio <code>MemoryFile<\/code> object, but it's inefficient - files could be very large    <\/p>\n<p><code>fs.get('path\/to\/image.tif', 'local_path.tif')<\/code> throws a <code>NotImplementedError<\/code>    <\/p>\n<p>We know this interface is only in public preview but is it cooked? Is it mainly a documentation problem?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"can I build my ML pipeline\/experiment in ML studio designer, and export it as a python and jupyter notebook?",
        "Question_created_time":1667248966827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069926\/can-i-build-my-ml-pipeline-experiment-in-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am able to run the notebook in studio, but can I export the studio as notebook and import it in another place?<\/p>",
        "Question_closed_time":1667268149163,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a7efa3c2-0ff5-4cc8-8b14-63a031eb0713\">@usui gina  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A. Sorry, this is not support at this moment. But Azure Machine Learning Studio already has Notebook function just for your reference.     <\/p>\n<p>I will forward your feedback to product team and at the same time, I would highly recommend you provide your feedback in Azure Machine Learning portal to raise more visability - top right side as below screenshot    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255817-image.png?platform=QnA\" alt=\"255817-image.png\" \/>    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Compose model",
        "Question_created_time":1669041105107,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1098169\/compose-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As the document     <br \/>\nA composed model is created by taking a collection of custom models and assigning them to a single model ID. You can assign up to 100 trained custom models to a single composed model ID. When a document is submitted to a composed model, the service performs a classification step to decide which custom model accurately represents the form presented for analysis.     <\/p>\n<p>What\u2019s the price for the classification step? <\/p>",
        "Question_closed_time":1669044705523,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=08dc8e09-5319-4bd7-9cf8-cce17f133981\">@KenSmith  <\/a>     <\/p>\n<p>Thanks for reaching out to us and sorry for the confusion of the document.     <\/p>\n<p>There is <strong>no extra fee<\/strong> for the classification you mentioned in the document. You only pay for the custom model you finally run for your document.    <\/p>\n<p>I will raise a ticket to fix the document, thanks a lot for pointing out it.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks! <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Access to Azure ML named datasets",
        "Question_created_time":1668460319020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1088577\/access-to-azure-ml-named-datasets",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>We have a computer vision pipeline that finetunes a vision model.    <br \/>\nThe data for training the vision model is a large collection of images that lands in our data lake.     <br \/>\nThe problem is that we are not able to mount this dataset to our training job.    <\/p>\n<p>In Azure ML portal we defined a named dataset for the image folder in our data lake (not the default workspace data source).    <br \/>\nBut if in our job control script we will try to reference the dataset by name and mount it to the training job:    <\/p>\n<pre><code>docker_config = DockerConfiguration(use_docker=True)  \n  \n# Access the dataset  \ndataset = Dataset.get_by_name(ws, 'the name of our named dataset')  \n  \n# Run the experiment  \nargs = ['--data-folder', dataset.as_mount() ]  \nprint(&quot;Mounted dataset&quot;)  \n  \nsrc = ScriptRunConfig(source_directory='.\/src',  \n                      script='balearms_cnn_training.py',  \n                      arguments=args,  \n                      compute_target=compute_target,  \n                      environment=keras_env,  \n                      docker_runtime_config=docker_config)  \n<\/code><\/pre>\n<p>The job will fail with the error:     <\/p>\n<pre><code>{&quot;NonCompliant&quot;:&quot;UserErrorException:\\n\\tMessage: Cannot mount Dataset(id='389fb088-59eb-4288-8225-aa9fb55f14c0', name='balearms', version=1). Error Message: DataAccessError(PermissionDenied(Some(This request is not authorized to perform this operation using this permission.)))\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n        \\&quot;message\\&quot;: \\&quot;Cannot mount Dataset(id='389fb088-59eb-4288-8225-aa9fb55f14c0', name='balearms', version=1). Error Message: DataAccessError(PermissionDenied(Some(This request is not authorized to perform this operation using this permission.)))\\&quot;\\n    }\\n}&quot;}  \n<\/code><\/pre>\n<p>\u2026    <\/p>\n<p>To overcome this problem we use the default workspace dataset.    <\/p>\n<pre><code>datastore = ws.get_default_datastore()  \n dataset = Dataset.File.from_files(path=(datastore, 'datasets\/balearms\/ExtractedImages\/'))  \n   \n # Run the experiment  \n args = ['--data-folder', dataset.as_mount() ]  \n print(&quot;Mounted dataset&quot;)  \n   \n src = ScriptRunConfig(source_directory='.\/src',  \n script='balearms_cnn_training.py',  \n arguments=args,  \n compute_target=compute_target,  \n environment=keras_env,  \n docker_runtime_config=docker_config)  \n<\/code><\/pre>\n<p>It works but it also means that we have to copy the files to a different storage account (the default workspace dataset) and that creates complexities.     <br \/>\nThere is no doubt that we should be able to mount a named dataset. I believe that we miss just a small detail\u2026    <\/p>\n<p>Would you be able to help us to figure out how to use named datasets and mount them to our training jobs?    <\/p>\n<p>Thanks    <\/p>\n<p>Manu    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wide and Deep Reccomender online endpoint deploying failing from Studio Designer",
        "Question_created_time":1668178557950,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1085654\/wide-and-deep-reccomender-online-endpoint-deployin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I am trying to deploy a Wide And Deep Reccomender from the Azure studio designer by creating the online endpoint from the job details (inference) but i get the same error:    <\/p>\n<p>TypeError: Descriptors cannot not be created directly.    <br \/>\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.    <br \/>\nIf you cannot immediately regenerate your protos, some other possible workarounds are:    <\/p>\n<ol>\n<li> Downgrade the protobuf package to 3.20.x or lower.    <\/li>\n<li> Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).    <\/li>\n<\/ol>\n<p>Both using the Azure Container both if I create a Kubernetes cluster inference instance.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/259539-screenshot-2022-11-11-at-145305.png?platform=QnA\" alt=\"259539-screenshot-2022-11-11-at-145305.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/259573-screenshot-2022-11-11-at-145315.png?platform=QnA\" alt=\"259573-screenshot-2022-11-11-at-145315.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"az ml workspace share command (v1) alternatives",
        "Question_created_time":1668184683380,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1085726\/az-ml-workspace-share-command-(v1)-alternatives",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to share my azure ML workspace by SP (Service Principal)    <\/p>\n<p>I've created a SP and share my workspace to the SP    <\/p>\n<p>But when I try to share a workspace using the cli, I get this error:    <\/p>\n<pre><code>   'share' is misspelled or not recognized by the system.  \n<\/code><\/pre>\n<p>Maybe I guess this error was caused by version of azure cli, (share command only exists in v1 docs: <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest<\/a>)    <\/p>\n<p>but I don't have any idea to alter the command above.    <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does Azure Cognitive Service provide a way to detect depression (or mental health) from a text?",
        "Question_created_time":1668695329173,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1093496\/does-azure-cognitive-service-provide-a-way-to-dete",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm doing research that aims to detect if social media users are depressed or\/and have mental health issues. Does Cognitive Service and its sentiment analysis models provide an API for this?<\/p>",
        "Question_closed_time":1668715953530,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=7518a830-4fa1-4aa7-867e-fad36ac3156a\">@xiriro  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. Sentimnt Analysis of Azure Cognitive Service does not support Depression Detection at this moment, it can only returen positive, neutral and negative labels, which may not enough for depression from my personal experience.    <\/p>\n<p>But I do see Microsoft Research group is working on this case - <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/project\/technology-for-mental-health-and-well-being-interventions\/\">https:\/\/www.microsoft.com\/en-us\/research\/project\/technology-for-mental-health-and-well-being-interventions\/<\/a>    <\/p>\n<p>And also I see some external Microsoft resource about this topic you may be interested in - <a href=\"https:\/\/www.youtube.com\/watch?v=HzlOkaGHZSg&amp;t=1432s\">https:\/\/www.youtube.com\/watch?v=HzlOkaGHZSg&amp;t=1432s<\/a>    <\/p>\n<p>I hope this helps and thank you for your product feedback, I will bring this feature to product team for future considerations.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Compute Instance Times Out During File Upload",
        "Question_created_time":1668533994507,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1090211\/azure-ml-compute-instance-times-out-during-file-up",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have deployed a gpu-enabled AZ ML Compute instance and am running a custom docker container on top of it. This custom docker container uses bentoml to receive, batch, and manage inference requests, with various endpoints for doing so. I have exposed the necessary ports so that the endpoints are available to send requests to. There are 2 major types of request endpoints involve: first, an endpoint where a path to a file that the compute\/container have access to through a volume mount\/storage mounting is sent as the data, and the container endpoint preforms inference on the file that path points to. This works just fine. Second is where the actual file is uploaded to the endpoint. The files in question are quite large image files, ~300-500mb. This second method has an issue: the file never reaches the endpoint. I attached a remote debugger and found the entrypoint of the data, and it is never reached in the case of the image upload, while it is in the case of the path upload. I then replicated the container on a local compute, and repeated the same scenario, in which the container was able to receive and handle the image upload with no issue. Additionally, when the image is more than 500mb, when attempting to upload to the container on the ml compute instance, I get an &quot;entity too large&quot; error, that I do not get when doing the same thing on a local compute instance.     <\/p>\n<p>I have been unable to find any definite documentation of the limitations on file upload size\/speed for ML compute instances, all that I have been able to find pertains to azure apps and to ml online endpoints (which could be an alternative option), but not to ml compute instances. Is there such a limit? If so, what is it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ACI Service request failed",
        "Question_created_time":1619647321237,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/376182\/aci-service-request-failed",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,<\/p>\n<p>I got an error when trying to deploy AML model. The tutorial I refer to is this: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a>  <br \/>\nPart of the console log is below.<\/p>\n<p>2021-04-28 14:35:51-07:00 Registering the environment.  <br \/>\n2021-04-28 14:35:53-07:00 Use the existing image.  <br \/>\n2021-04-28 14:35:55-07:00 Submitting deployment to compute.  <br \/>\nFailed  <br \/>\nService deployment polling reached non-successful terminal state, current service state: Transitioning  <br \/>\nOperation ID: b6e3b3b3-d1f0-4819-81ac-b72c7b3582dd  <br \/>\nCurrent sub-operation type not known, more logs unavailable.  <br \/>\nError:  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;InaccessibleImage&quot;,  <br \/>\n&quot;statusCode&quot;: 400,  <br \/>\n&quot;message&quot;: &quot;ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container  <br \/>\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to <a href=\"https:\/\/learn.microsoft.com\/azure\/cont\">https:\/\/learn.microsoft.com\/azure\/cont<\/a>  <br \/>\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.&quot;  <br \/>\n}<\/p>\n<p>Traceback (most recent call last):  <br \/>\nFile &quot;deploy-model.py&quot;, line 34, in &lt;module&gt;  <br \/>\nservice.wait_for_deployment(show_output=True)  <br \/>\nFile &quot;C:\\Users\\Administrator\\source\\repos\\TestPython\\venv\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py&quot;, line 917, in wait_for_deployment  <br \/>\nraise WebserviceException('Service deployment polling reached non-successful terminal state, current '  <br \/>\nazureml.exceptions._azureml_exception.WebserviceException: WebserviceException:  <br \/>\nMessage: Service deployment polling reached non-successful terminal state, current service state: Transitioning  <br \/>\nOperation ID: b6e3b3b3-d1f0-4819-81ac-b72c7b3582dd  <br \/>\nCurrent sub-operation type not known, more logs unavailable.  <br \/>\nError:  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;InaccessibleImage&quot;,  <br \/>\n&quot;statusCode&quot;: 400,  <br \/>\n&quot;message&quot;: &quot;ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container  <br \/>\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to <a href=\"https:\/\/learn.microsoft.com\/azure\/cont\">https:\/\/learn.microsoft.com\/azure\/cont<\/a>  <br \/>\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.&quot;  <br \/>\n}  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Transitioning\\nOperation ID: b6e3b3b3-d1f0-4819  <br \/>\n-81ac-b72c7b3582dd\\nCurrent sub-operation type not known, more logs unavailable.\\nError:\\n{\\n \\&quot;code\\&quot;: \\&quot;InaccessibleImage\\&quot;,\\n \\&quot;statusCode\\&quot;: 400,\\n \\  <br \/>\n&quot;message\\&quot;: \\&quot;ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container  <br \/>\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to <a href=\"https:\/\/learn.microsoft.com\/azure\/cont\">https:\/\/learn.microsoft.com\/azure\/cont<\/a>  <br \/>\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\\&quot;\\n}&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>The python code used for this is below. The local deployment works actually.<\/p>\n<p>from azureml.core import Environment  <br \/>\nfrom azureml.core.model import InferenceConfig  <br \/>\nfrom azureml.core.webservice import LocalWebservice  <br \/>\nfrom azureml.core.webservice import AciWebservice  <br \/>\nfrom azureml.core.model import Model  <br \/>\nfrom azureml.core import Workspace<\/p>\n<p>ws = Workspace.from_config(path=&quot;.\/config.json&quot;)<\/p>\n<p>model = Model(ws, 'bidaf_onnx')  <br \/>\nprint(model.name, &quot; : &quot;, model.created_by)<\/p>\n<p>env = Environment(name='myenv')  <br \/>\npython_packages = ['nltk', 'numpy', 'onnxruntime']  <br \/>\nfor package in python_packages:  <br \/>\nenv.python.conda_dependencies.add_pip_package(package)<\/p>\n<p>inf_config = InferenceConfig(environment=env, source_directory='.\/source_dir', entry_script='.\/score.py')  <br \/>\nprint(&quot;Generated inference configuration&quot;)<\/p>\n<p>deploy_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 1)  <br \/>\nprint(&quot;Generated deployment configuration&quot;)<\/p>\n<p>service = Model.deploy(ws, &quot;myservice&quot;, [model], inf_config, deploy_config, overwrite=True)  <br \/>\nservice.wait_for_deployment(show_output=True)  <br \/>\nprint(service.get_logs())<\/p>\n<p>I've enabled &quot;Admin user&quot; for the container registry as indicated by the error message. But still got the same error message.  <br \/>\nThank you,<\/p>\n<p>Hai<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Error on Linux: \"Unable to retrieve .NET dependencies. Please make sure you are connected ...\"",
        "Question_created_time":1618767312437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361522\/azureml-error-on-linux-unable-to-retrieve-net-depe",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I am getting this error on a Linux box (Gentoo w\/ .NET via Mono properly installed)<\/p>\n<p><strong>&quot;Unable to retrieve .NET dependencies. Please make sure you are connected to the Internet and have a stable network connection.&quot;<\/strong><\/p>\n<p>The error is triggered when creating a dataset from a directory using<\/p>\n<p>&quot;dataset = Dataset.File.from_files(path=(datastore, path_to_dataset_in_datastore))&quot;<\/p>\n<p>Some system info:  <br \/>\nPython: 3.8.8.  <br \/>\nazureml-automl-core 1.26.0  <br \/>\nazureml-core 1.26.0  <br \/>\nazureml-dataprep 2.13.2  <br \/>\nazureml-dataprep-native 32.0.0  <br \/>\nazureml-dataprep-rslex 1.11.2  <br \/>\nazureml-dataset-runtime 1.26.0  <br \/>\nazureml-pipeline 1.26.0  <br \/>\nazureml-pipeline-core 1.26.0  <br \/>\nazureml-pipeline-steps 1.26.0  <br \/>\nazureml-sdk 1.26.0  <br \/>\nazureml-telemetry 1.26.0  <br \/>\nazureml-train 1.26.0  <br \/>\nazureml-train-automl-client 1.26.0  <br \/>\nazureml-train-core 1.26.0  <br \/>\nazureml-train-restclients-hyperdrive 1.26.0<\/p>\n<p>.NET Info:  <br \/>\nMono JIT compiler version 6.6.0.161 (tarball Sat Apr 10 16:41:12 PDT 2021)  <br \/>\nCopyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. <a href=\"https:\/\/www.mono-project.com\">www.mono-project.com<\/a>  <br \/>\nTLS: __thread  <br \/>\nSIGSEGV: altstack  <br \/>\nNotifications: epoll  <br \/>\nArchitecture: amd64  <br \/>\nDisabled: none  <br \/>\nMisc: softdebug  <br \/>\nInterpreter: yes  <br \/>\nLLVM: supported, not enabled.  <br \/>\nSuspend: hybrid  <br \/>\nGC: sgen (concurrent by default)<\/p>",
        "Question_closed_time":1619068615363,
        "Answer_score_count":0.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=48487b4e-cd4d-4b5e-aae5-dcf8dfaf50c4\">@Victor Fragoso  <\/a>  Thanks for the details. Gentoo is not a 'natively' supported distribution of linux for Datasets. The Exception message doesn't link to a .NET docs page with instructions on installing the system dependencies required for .NET to work. Though it seems a different one is being thrown related to not being able to connect to out blob storage which has pre-prepared dependency sets for some linux distros (not gentoo).    <\/p>\n<p>This page <a href=\"https:\/\/learn.microsoft.com\/en-us\/dotnet\/core\/install\/linux\">Install .NET on Linux Distributions | Microsoft Learn<\/a> does not detail support for .NET on gentoo.    <br \/>\nYou can get the names of the missing dependencies themselves by running:    <\/p>\n<pre><code>from dotnetcore2 import runtime  \nruntime._enable_debug_logging()  \nruntime.ensure_dependencies()  \n<\/code><\/pre>\n<p>This code snippet should print the libraies missing required by .NET core 2.1.    <br \/>\nIf the above does not print anything, other than the Exception, then instead this should:    <\/p>\n<pre><code>from dotnetcore2 import runtime  \nprint(runtime._gather_dependencies(runtime._get_bin_folder()))  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML HyperDriveStep is incorrectly reading Input port names as duplicates",
        "Question_created_time":1668549291787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1090410\/azureml-hyperdrivestep-is-incorrectly-reading-inpu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to build a regression model pipeline using a HyperDriveStep for parameter tuning.<\/p>\n<p>When I pass in my features dataset and targets dataset as named inputs, if I run this in a notebook with a fresh kernel, I get an error that says <code>ValueError: [features_data] is repeated. Input port names must be unique.<\/code> (See first screenshot)<\/p>\n<p>If I comment out the features data input and re-run the cell, the HyperDriveStep builds with no issue. (But obviously I can't run the step and train my model without the features.) (See second screenshot)<\/p>\n<p>If I un-comment the features data input and re-run the cell, this time the HyperDriveStep builds with no issue, and I can run my pipeline. (See third screenshot)<\/p>\n<p>Error report is as follows:<\/p>\n<hr \/>\n<p>ValueError Traceback (most recent call last)  <br \/>\nInput In [7], in &lt;cell line: 25&gt;()  <br \/>\n21 # Risk: need to ensure tha the model_file entered here is the same name  <br \/>\n22 # as what's saved in training\/train_{model_algorithm}_regressor.py  <br \/>\n24 hd_step_name=f'hd_training_step_{segment_type}_{model_algorithm}'  <br \/>\n---&gt; 25 hd_step = HyperDriveStep(  <br \/>\n26 name=hd_step_name,  <br \/>\n27 hyperdrive_config=hd_config,  <br \/>\n28 inputs=[  <br \/>\n29 training_features.as_named_input('features_data'),  <br \/>\n30 training_targets.as_named_input('targets_data')],  <br \/>\n31 outputs=[metrics_data, saved_model],  <br \/>\n32 allow_reuse=False)<\/p>\n<p>File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py:249, in HyperDriveStep.<strong>init<\/strong>(self, name, hyperdrive_config, estimator_entry_script_arguments, inputs, outputs, metrics_output, allow_reuse, version)  <br \/>\n246 self._params[HyperDriveStep._primary_metric_goal] = hyperdrive_config._primary_metric_config['goal'].lower()  <br \/>\n247 self._params[HyperDriveStep._primary_metric_name] = hyperdrive_config._primary_metric_config['name']  <br \/>\n--&gt; 249 super(HyperDriveStep, self).<strong>init<\/strong>(name=name, inputs=inputs, outputs=outputs,  <br \/>\n250 arguments=estimator_entry_script_arguments)<\/p>\n<p>File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:149, in PipelineStep.<strong>init<\/strong>(self, name, inputs, outputs, arguments, fix_port_name_collisions, resource_inputs)  <br \/>\n146 resource_input_port_names = [PipelineStep._get_input_port_name(input) for input in resource_inputs]  <br \/>\n147 output_port_names = [PipelineStep._get_output_port_name(output) for output in outputs]  <br \/>\n--&gt; 149 PipelineStep._assert_valid_port_names(input_port_names + resource_input_port_names,  <br \/>\n150 output_port_names, fix_port_name_collisions)  <br \/>\n152 self._inputs = inputs  <br \/>\n153 self._resource_inputs = resource_inputs<\/p>\n<p>File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:190, in PipelineStep._assert_valid_port_names(input_port_names, output_port_names, fix_port_name_collisions)  <br \/>\n188 if input_port_names is not None:  <br \/>\n189 assert_valid_port_names(input_port_names, 'input')  <br \/>\n--&gt; 190 assert_unique_port_names(input_port_names, 'input')  <br \/>\n192 if output_port_names is not None:  <br \/>\n193 assert_valid_port_names(output_port_names, 'output')<\/p>\n<p>File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:184, in PipelineStep._assert_valid_port_names.&lt;locals&gt;.assert_unique_port_names(port_names, port_type, seen)  <br \/>\n182 for port_name in port_names:  <br \/>\n183 if port_name in seen:  <br \/>\n--&gt; 184 raise ValueError(&quot;[{port_name}] is repeated. {port_type} port names must be unique.&quot;  <br \/>\n185 .format(port_name=port_name, port_type=port_type.capitalize()))  <br \/>\n186 seen.add(port_name)<\/p>\n<p>ValueError: [features_data] is repeated. Input port names must be unique.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/260618-screen-shot-2022-11-15-at-35102-pm.png?platform=QnA\" alt=\"260618-screen-shot-2022-11-15-at-35102-pm.png\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML - AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available.",
        "Question_created_time":1667553245710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1075753\/aml-assetexception-error-with-code-cant-connect-to",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello Microsoft Q&amp;A Team,    <\/p>\n<p>I get the error     <\/p>\n<blockquote>\n<p>AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available    <\/p>\n<\/blockquote>\n<p> when executing the following command:    <\/p>\n<blockquote>\n<p>pipeline_job = ml_client.jobs.create_or_update(    <br \/>\n    pipeline_job, experiment_name=&quot;data_preparation&quot;    <br \/>\n)    <br \/>\npipeline_job    <\/p>\n<\/blockquote>\n<p>Yesterday the command worked without an error. I did not make any changes. So I have no idea, what the problem is.    <\/p>\n<p>Thanks for helping me out.    <\/p>\n<p>Cheers    <\/p>\n<p>Lukas    <\/p>",
        "Question_closed_time":1667605270037,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=733bec54-8d30-4052-8297-64b100f6e3d4\">@Lukas  <\/a> Thanks for your question. Can you please add more details about the document\/sample that you are trying.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML deploy new model",
        "Question_created_time":1667478071347,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1074346\/azure-ml-deploy-new-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have created an Azure ML model using Azure ML studios notebooks.    <\/p>\n<p>Im trying to build and environment with the needed packages, but im having some problems get my model deployed to the environment.    <\/p>\n<p>Im pretty new to this whole process so im following the Microsofts guides, but im finding them hard to use when running into issues.    <\/p>\n<p>Are there some blogs\/post with real life examples on how to deploy and troubleshoot deploying ML models on Azure?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use parameter weight_column_name in AutoMLConfig Class for Automated Azure MAchine Learning",
        "Question_created_time":1642428938500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/698115\/how-to-use-parameter-weight-column-name-in-automlc",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everybody,  <br \/>\ncould you please help with the weight_column_Name in the AutomLconfig how is used,and how should the syntax be for multiple columns? We are trying to run various different experiments with specific weights in some columns that we consider more serious. Can somebody provide an example of this parameter in use?  <\/p>\n<p>Kind Regards<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML pipeline designer export",
        "Question_created_time":1668149568060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1085047\/azure-ml-pipeline-designer-export",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey,    <br \/>\nIs there any way to export the ML Pipeline as Template\/PNG\/Code ?<\/p>",
        "Question_closed_time":1668156834877,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=979eeb5c-297b-4af8-af81-bb25ddabe5d5\">@Kumar Shanu  <\/a> The designer pipelines cannot be exported to code or a template currently.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"EntryPointNotFoundException: Unable to find an entry point named 'OrtGetApiBase' in DLL 'onnxruntime'.",
        "Question_created_time":1615215403083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/304053\/entrypointnotfoundexception-unable-to-find-an-entr",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":3,
        "Question_body":"<p>I want to make prediction using azure AutoML onnx model in .net core(3.1) console application in visual studio. I have exported onnx  model from azure AutoML.    <\/p>\n<p>I am following the tutorial link : <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automl-onnx-model-dotnet\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automl-onnx-model-dotnet<\/a>    <\/p>\n<p>It says to install following packages (in parenthesis shows the version I am using)    <br \/>\nMicrosoft.ML (1.5.4)    <br \/>\nMicrosoft.ML.OnnxRuntime(1.7.0)    <br \/>\nMicrosoft.ML.OnnxTransformer(1.5.4)    <\/p>\n<p>while defining the pipeline    <br \/>\nvar onnxPredictionPipeline =mlContext.Transforms.ApplyOnnxModel(    <br \/>\n            outputColumnNames: outputColumns,  <br \/>\n            inputColumnNames: inputColumns,  <br \/>\n            ONNX_MODEL_PATH);  <\/p>\n<p>I am getting the following error :     <br \/>\nSystem.TypeInitializationException: 'The type initializer for 'Microsoft.ML.OnnxRuntime.NativeMethods' threw an exception.'    <br \/>\nEntryPointNotFoundException: Unable to find an entry point named 'OrtGetApiBase' in DLL 'onnxruntime'.    <\/p>\n<p>Then I tried with Microsoft.ML.OnnxRuntime.Managed(1.7.1) along with above packages but still getting the same issue.    <\/p>\n<p>Please suggest to resolve this issue.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Access uri_folder dataset (ML v2) from notebook (not job)",
        "Question_created_time":1666794361980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1063867\/azure-machine-learning-access-uri-folder-dataset-(",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I've registered in Azure Machine Learning a Data Lake Gen2 datastore that point to a container with a hierarchy of folders that contain avro files and on top of it I registered a folder_uri dataset (ML v2).    <\/p>\n<p>Now I want to access to these folders from a notebook, convert them in a pandas dataframe in order to do some data exploration.    <\/p>\n<p>I search on the documentation, and I only found examples that run job and using this type of dataset as input, but I need to be able to explore it using notebook.     <\/p>\n<p>Is it possible? How can I do it?    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1666874705140,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c637b1ab-bffd-0006-0000-000000000000\">@G Cocci  <\/a> Thanks for the question. Currently it's not supported to access the avro files. Here is the document for accessing the datastore using folder_uri dataset.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-resource-datastore\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-resource-datastore<\/a>    <\/p>\n<p>Mapping Data Flow supports AVRO as a source type <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/data-flow-source#supported-sources\">https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/data-flow-source#supported-sources<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Constantly getting this error while training Deep and Wide model. Model is expected to be fed with features: ['feature_user_feature_2', ....",
        "Question_created_time":1668240133527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1086242\/constantly-getting-this-error-while-training-deep",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core&lt;2.0.0,&gt;=1.3.1'), {'azure-mgmt-keyvault'}).    <br \/>\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core&lt;2.0.0,&gt;=1.3.1'), {'azure-mgmt-keyvault'}).    <br \/>\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core&lt;2.0.0,&gt;=1.3.1'), {'azure-mgmt-keyvault'}).    <br \/>\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core&lt;2.0.0,&gt;=1.3.1'), {'azure-mgmt-keyvault'}).    <br \/>\nSession_id = 84c324df-90e3-4d06-963d-c896854583    <br \/>\nInvoking module by urldecode_invoker 0.0.8.    <\/p>\n<p>Module type: custom module.    <\/p>\n<p>Using runpy to invoke module 'azureml.designer.modules.recommendation.dnn.wide_and_deep.train.run'.    <\/p>\n<p>2022-11-06 17:12:43.374707: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/azureml-envs\/azureml_1c52c6e25bd041eabbd9a52168ae46\/lib:\/usr\/local\/nvidia\/lib:\/usr\/local\/nvidia\/lib64:\/usr\/local\/cuda\/lib64:\/usr\/local\/cuda\/extras\/CUPTI\/lib64    <br \/>\n2022-11-06 17:12:43.374762: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.    <br \/>\n2022-11-06 17:12:45,992 studio.common        INFO       azureml-designer-recommender-modules 0.0.54    <br \/>\n2022-11-06 17:12:51,404 studio.core          INFO       preprocess_transactions - Start:    <br \/>\n2022-11-06 17:13:06,585 studio.core          INFO       preprocess_transactions - End with 15.1769s elapsed.    <br \/>\n2022-11-06 17:13:06,589 studio.core          INFO       preprocess_features - Start:    <br \/>\n2022-11-06 17:13:06,607 studio.core          INFO       preprocess_features - End with 0.0176s elapsed.    <br \/>\n2022-11-06 17:13:06,607 studio.core          INFO       preprocess_features - Start:    <br \/>\n2022-11-06 17:13:06,666 studio.core          INFO       preprocess_features - End with 0.0583s elapsed.    <br \/>\n2022-11-06 17:13:12,074 studio.common        INFO       Get 10 features    <br \/>\n2022-11-06 17:13:12,166 studio.common        INFO       Create feature metas for 10 features    <br \/>\n2022-11-06 17:13:14,412 studio.common        INFO       Get 1 features    <br \/>\n\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages\/pandas\/core\/generic.py:6245: SettingWithCopyWarning:     <br \/>\nA value is trying to be set on a copy of a slice from a DataFrame    <\/p>\n<p>See the caveats in the documentation: <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html#returning-a-view-versus-a-copy\">https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html#returning-a-view-versus-a-copy<\/a>    <br \/>\n  self._update_inplace(new_data)    <br \/>\n2022-11-06 17:13:14,466 studio.common        INFO       Create feature metas for 1 features    <br \/>\n2022-11-06 17:13:14,500 studio.common        DEBUG      Init train input function builder.    <br \/>\n2022-11-06 17:13:14,503 studio.common        INFO       Build 10 features for User ids.    <br \/>\n2022-11-06 17:13:17,704 studio.common        INFO       Process null values for features.    <br \/>\n2022-11-06 17:13:17,736 studio.common        INFO       Build 1 features for Item ids.    <br \/>\n2022-11-06 17:13:20,012 studio.common        INFO       Process null values for features.    <br \/>\n2022-11-06 17:13:26,398 studio.module        INFO       Get 5775792 training instances, and 90247.0 batches per epoch.    <br \/>\n2022-11-06 17:13:29,489 studio.module        INFO       Build model:    <br \/>\nEpochs: 15    <br \/>\nBatch size: 64    <br \/>\nWide optimizer: OptimizerSelection.Adagrad    <br \/>\nWide learning rate: 0.1    <br \/>\nDeep optimizer: OptimizerSelection.Adagrad    <br \/>\nDeep learning rate: 0.1    <br \/>\nHidden units: (256, 128)    <br \/>\nActivation function: ActivationFnSelection.ReLU    <br \/>\nDropout: 0.8    <br \/>\nBatch norm: True    <br \/>\nCrossed dimension: 1000    <br \/>\nUser embedding dimension: 16    <br \/>\nItem embedding dimension: 16    <br \/>\nCategorical feature embedding dimension: 4    <br \/>\n2022-11-06 17:13:29,546 studio.module        INFO       <strong>Model is expected to be fed with features: ['feature_user_feature_2', 'feature_user_feature_8', 'feature_user_feature_3', 'feature_user_feature_9', 'feature_user_feature_4', 'feature_item_feature_0', 'User', 'Item', 'feature_user_feature_5', 'feature_user_feature_1', 'feature_user_feature_6', 'feature_user_feature_0', 'feature_user_feature_7']<\/strong>    <br \/>\n2022-11-06 17:13:30,077 tensorflow           INFO       Using config: {'_model_dir': '\/tmp\/tmp7lhxl5n0\/checkpoints', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 1353705.0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true    <br \/>\ngraph_options {    <br \/>\n  rewrite_options {    <br \/>\n    meta_optimizer_iterations: ONE  <br \/>\n  }    <br \/>\n}    <br \/>\n, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 90247.0, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error creating endpoint from mlflow model (tensorflow job)",
        "Question_created_time":1667731273557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1077214\/error-creating-endpoint-from-mlflow-model-(tensorf",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello everybody,    <br \/>\nI am trying to deploy a realtime endpoint from a registered mlflow model obtained from a tensorflow training job.    <br \/>\nIn this repository, you will find the training scripts:    <\/p>\n<p><a href=\"https:\/\/github.com\/antigones\/py-hands-ml-tf\/tree\/main\/azure_ml\/job_script\">https:\/\/github.com\/antigones\/py-hands-ml-tf\/tree\/main\/azure_ml\/job_script<\/a>    <\/p>\n<p>The job outputs a MLFlow model with its conda environment yml file.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/257488-image.png?platform=QnA\" alt=\"257488-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/257527-image.png?platform=QnA\" alt=\"257527-image.png\" \/>    <\/p>\n<p>When I try to deploy the model to a realtime endpoint, I get the following error:    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/257528-azure-ml-deploy-error.txt?platform=QnA\">257528-azure-ml-deploy-error.txt<\/a>    <\/p>\n<p>It seems to be an error related to protobuf, when loading the model:    <\/p>\n<pre><code> File &quot;\/opt\/miniconda\/envs\/userenv\/lib\/python3.8\/site-packages\/google\/protobuf\/descriptor.py&quot;, line 560, in __new__  \n    _message.Message._CheckCalledFromGeneratedFile()  \nTypeError: Descriptors cannot not be created directly.  \nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.  \nIf you cannot immediately regenerate your protos, some other possible workarounds are:  \n 1. Downgrade the protobuf package to 3.20.x or lower.  \n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).  \n  \nMore information: https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates  \n<\/code><\/pre>\n<p>The environment is deployed automatically (the scoring script is also generated).    <br \/>\nI have also tried different images, with different python versions (3.7) and Tensorflow versions (2.4) with no luck.    <\/p>\n<p>How can I solve this issue?    <\/p>\n<p>Thank you in advance for your support.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer: Export Code",
        "Question_created_time":1646150939773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/755142\/azure-ml-designer-export-code",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Is there an option to export the Azure ML Designer to code so we can copy between workspaces?<\/p>",
        "Question_closed_time":1646202005287,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, this feature is currently not supported as mentioned on this <a href=\"https:\/\/stackoverflow.com\/questions\/60306240\/export-azure-ml-studio-designer-project-as-jupyter-notebook\">thread<\/a>. However, it's on the roadmap.  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Creating Workspace using python",
        "Question_created_time":1667322573967,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1071316\/creating-workspace-using-python",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to create a Workspace using Python    <\/p>\n<p>ws = Workspace.create(name = '', subscription_id ='', resource_group='', create_resource_group = True, location = 'India')    <\/p>\n<p>Below is the error I'm facing    <\/p>\n<p>Me default directory has a subscription    <\/p>\n<p> AzureMLException: AzureMLException:    <br \/>\n\tMessage: No subscriptions found for enochkranthi<a href=\"\/users\/na\/?userid=13b1dcfc-4001-0003-0000-000000000000\">@Stuff  <\/a>.com.  <br \/>\n\tInnerException None  <br \/>\n\tErrorResponse   <br \/>\n{    <br \/>\n    &quot;error&quot;: {  <br \/>\n        &quot;message&quot;: &quot;No subscriptions found for enochkranthi<a href=\"\/users\/na\/?userid=13b1dcfc-4001-0003-0000-000000000000\">@Stuff  <\/a>.com.&quot;  <br \/>\n    }  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Import, call and development of other predictive models into Azure",
        "Question_created_time":1667551730223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1075731\/import-call-and-development-of-other-predictive-mo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Can Microsoft Azure supports <strong>importing<\/strong>, <strong>calling<\/strong> and <strong>development of custom predictive models<\/strong> through <strong>R<\/strong>, <strong>SAS code<\/strong>, <strong>C<\/strong>, <strong>C++<\/strong>, <strong>Java<\/strong>, <strong>Predictive Model Markup Language (PMML)<\/strong>, <strong>Open Neural Network Exchange (ONNX)<\/strong> or <strong>REST APIs<\/strong>?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML service and SAS files",
        "Question_created_time":1667406090587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1072904\/azure-ml-service-and-sas-files",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Am not able to preview the sas7bdat files in Azure ML service.. whether sas7bdat files analysis are supported in Azure ML services ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML assisted data labeling completed the Training run phase, but how to start the Inference run?",
        "Question_created_time":1663730318027,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1016703\/ml-assisted-data-labeling-completed-the-training-r",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I'm having trouble getting ML assisted data labeling to begin prelabeling.    <\/p>\n<p>I have an object detection Data Labeling project in Azure ML Studio workspace. ML Assisted is enabled from the project creation. I manually labeled the number required to start Training run (in my case, 45). Completed Training run without issue. Yet, the Inference run never started up. The info button when I hover over the &quot;Prelabeled&quot; Task Queue informs me the Inference run must be done before prelabeling can begin. How do I start the Inference run? Is there a manual step needed to start the Inference run? I thought it would happen automatically after the Training run completed (ensuring compute resource is available of course). I labeled more manually to trigger and complete a 2nd Training run, but Inference still did not start. I must be missing something, but not sure what to do.    <\/p>\n<p>The on-demand button in the Settings is for the Training run only, so it is not clear if the Inference run can be triggered on-demand.     <\/p>\n<p>Here's my project experiments summary on the dashboard view:    <\/p>\n<p><strong>ML assisted data labeling experiments            Experiment                        Latest run                    Run Status<\/strong>    <br \/>\nTraining                                                             cool_experiment               AutoML_&lt;hashid&gt;      Completed    <br \/>\nInference                                                           Experiment not started    --                                  --    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wheres my component",
        "Question_created_time":1667251682350,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1070006\/wheres-my-component",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi expert, I am struggling in a bug, I can\u2019t see anything in my studio and it shows empty, how can I fixed it. Anyone else experience this or is this a bug.    <\/p>",
        "Question_closed_time":1667259764343,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d9b0571c-98f4-45f6-b170-c08f181d4bca\">@james schmidt  <\/a>     <\/p>\n<p>Thanks for reaching out to us for this issue. I have checked on my end and I find everything is OK.    <\/p>\n<p>Could you please make sure you have not selected any filter\/ selected all tags and click on the refresh button to make sure you have every component.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255777-image.png?platform=QnA\" alt=\"255777-image.png\" \/>    <\/p>\n<p>My studio is as above, please do check all the settings and let me know if you still have any issue.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the asnwer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Trained NLP model snippet",
        "Question_created_time":1667251332713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069986\/trained-nlp-model-snippet",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Newbie data scientist here, I am just starting my way in Azure, is there any I should start NLP? Any trained model or code sample? Thank you for any idea<\/p>",
        "Question_closed_time":1667776545220,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=12b79ebe-b30f-4203-a714-62377c3d557b\">@jackson schmidt  <\/a>     <\/p>\n<p>Sorry I have not heard from you. I have done some researches around NLP in Azure. This can be done by two ways -    <\/p>\n<ol>\n<li> Azure Machine Learning Python SDK\/ ML CLI extension    <br \/>\nWe don't have any trained model you can use in Azure ML but you do have the SDK supporting you to train your model    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli<\/a>    <\/li>\n<li> NLP Server     <br \/>\nApache Spark is a parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Azure Synapse Analytics, Azure HDInsight, and Azure Databricks offer access to Spark and take advantage of its processing power.    <\/li>\n<\/ol>\n<p>For customized NLP workloads, Spark NLP serves as an efficient framework for processing a large amount of text. This open-source NLP library provides Python, Java, and Scala libraries that offer the full functionality of traditional NLP libraries such as spaCy, NLTK, Stanford CoreNLP, and Open NLP. Spark NLP also offers functionality such as spell checking, sentiment analysis, and document classification. Spark NLP improves on previous efforts by providing state-of-the-art accuracy, speed, and scalability.    <\/p>\n<p><img src=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/data-guide\/images\/natural-language-processing-functionality.png\" alt=\"natural-language-processing-functionality.png\" \/>    <\/p>\n<p>The NLP Server is available in Azure Marketplace. To explore large-scale custom NLP in Azure, see NLP Server - <a href=\"https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622\">https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622<\/a>    <\/p>\n<ol start=\"3\">\n<li> Azure Language Service    <br \/>\nThough we don't have trained model in Azure ML, but we do have REST APIs you can use for Text Analytics, Sentiment Analytics and so on functions for NLP, I would suggest you to check on the document, it may help you achieve your bussiness goals.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/<\/a>    <\/li>\n<\/ol>\n<p>I hope those information helps. Please let me know if you have any questions regarding to any of above.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Response status code does not indicate success: 400 (Conda dependencies were not specified. Please make sure that all conda dependencies were specified i).",
        "Question_created_time":1667250048510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069928\/response-status-code-does-not-indicate-success-400",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<blockquote>\n<p>I was trying to setup my env                                                          runconfig = ScriptRunConfig(source_directory='script\/', script='my-script.py', arguments=script_params)    <br \/>\nrunconfig.run_config.target = compute_target    <br \/>\nrunconfig.run_config.environment = env    <br \/>\nrun = exp.submit(runconfig)<\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML online endpoint suddenly returns timeout",
        "Question_created_time":1666021337190,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1051161\/azure-ml-online-endpoint-suddenly-returns-timeout",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi all,    <\/p>\n<p>We have deployed a managed online endpoint in Azure ML and first it works fine. However, after a few days, with the exact same request, the endpoint takes much longer to process the request and gives a timeout (the HTTP code returned is 504). We don't understand this behavior since we did not modify the endpoint and the metrics don't show a huge increase in cpu or memory usage. If we restart it then it works again for a few days until it doesn't work anymore.  Has anyone faced the same issue? Could you solve it?    <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy Azure ML Model on HTML able to read excel files",
        "Question_created_time":1667420764960,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1073090\/deploy-azure-ml-model-on-html-able-to-read-excel-f",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a trained model on Azure Automated Machine Learning, what I want to know is that if it is possible to deploy that model on an executable program (C# or Python) or with an HTML program.     <br \/>\nWith this I want to accomplish the following process:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/256498-diapositiva1.png?platform=QnA\" alt=\"256498-diapositiva1.png\" \/>    <\/p>\n<p>I would really appreciate an answer. Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to connect to adls gen2 from azure ml workspace",
        "Question_created_time":1667403446370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1072809\/unable-to-connect-to-adls-gen2-from-azure-ml-works",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I tried to create datastore in azure ml to connect to adls gen2. I have created app registration and used those client id and secret id. I also assigned the required permission [ storage blob data owner for the client id] in the resource group where the adls gen2 is located    <\/p>\n<p>But still I am not able to access the data. Please suggest me what further I have to do    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I install local python library to azure ml studio environment",
        "Question_created_time":1667248136980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069983\/how-can-i-install-local-python-library-to-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As title, find no docs or code sample from Azure<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Model deployment outside Azure",
        "Question_created_time":1667289083130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1070537\/ml-model-deployment-outside-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>There are company restrictions on using Azure AKS and ACI for deployment, and also we are restricted to use only Notebooks for ML model development. Can someone point me to step-by-step documentation on downloading modle and deploying it outside Azure?    <\/p>\n<p>Like after building a ML Model, how to download a packaged model - Docker image that contains the model and other files needed to host it as a web service<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access to Azure subscription for users",
        "Question_created_time":1666972949727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067157\/access-to-azure-subscription-for-users",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have an active subscription. For few of the users we activated owner role for the machine learning resource group.    <br \/>\nBut when they login to the portal\/ML environment and try to switch directory and subscription, they don't see our production subscription and hence the workspace, although directory is correct. User had created a trial subscription on its own before and he only has visibility to that.    <\/p>\n<p>I checked with a test account and after login to ML studio I see this, which I believe is the same reason user does not see the subscription.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255195-screenshot-2022-10-28-085206.png?platform=QnA\" alt=\"255195-screenshot-2022-10-28-085206.png\" \/>    <\/p>\n<p>How can I safely give user subscription access only for ML resource group    <\/p>",
        "Question_closed_time":1666977116507,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=8cb8b6e9-f7ac-47d9-bcd3-6c4b5af3201d\">@RT-7199  <\/a>     <\/p>\n<p>Thank you for asking this question on the **Microsoft Q&amp;A Platform. **    <\/p>\n<p>The role will depend on the activity that the user performs, for example, to create a new workspace you will require the role owner or contributor at the Resource group-level. (If you receive a failure when trying to create a workspace for the first time, make sure that your role allows Microsoft.MachineLearningServices\/register\/action. This action allows you to register the Azure Machine Learning resource provider with your Azure subscription.)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255119-image.png?platform=QnA\" alt=\"255119-image.png\" \/>    <\/p>\n<p>You can get more information about RBAC for Azure Machine Learning workspace <strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios\">here<\/a><\/strong>    <\/p>\n<p>Hope this helps!    <\/p>\n<p>----------    <\/p>\n<p><strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/accepted-answers\">Accept Answer<\/a><\/strong> and Upvote, if any of the above helped, this thread can help others in the community looking for remediation for similar issues.    <br \/>\n<em>NOTE: To answer you as quickly as possible, please mention me in your reply.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML pipeline from an Azure DevOps pipeline",
        "Question_created_time":1667236694490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069739\/azure-ml-pipeline-from-an-azure-devops-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Tried invoking an Azure ML pipeline from an Azure DevOps pipeline ? I keep running into errors, so I want to make sure my high level process is correct.<\/p>",
        "Question_closed_time":1667271469657,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. You can use the Azure CLI task - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/devops\/pipelines\/tasks\/deploy\/azure-cli?view=azure-devops\">Azure Pipelines | Microsoft Learn<\/a> step and run command line or Python scripts inside that to submit your pipelines.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can't Test my ML model because of schema mismatch in Test data",
        "Question_created_time":1666918751970,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1066126\/cant-test-my-ml-model-because-of-schema-mismatch-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a model which I would like to test against a test dataset.  I am using AutoML and have generated a regression model.  I notice that when I register a data asset it randomly incorrectly assigns certain columns as Integer or Decimal.  When I try to test the model against a new data asset there is a mismatch of about 50 columns.  I have about 1400 columns in my dataset so it is impossible to go through every column to make sure they match what was in the orginal data asset used for the model.  I don't even know how to view or change the schema of a data asset as it doesn't seem to allow me to do that in the Azure ML Studio.  Is there a workaround for this problem or at least a way I can programatically update my test data asset schema to match the schema used in the model?    <br \/>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why am I being charged for Azure Machine Learning?",
        "Question_created_time":1667150713980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1068344\/why-am-i-being-charged-for-azure-machine-learning",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Context: I created an Azure Machine Learning workspace and uploaded a dataset that's less than 1mb. I created a compute instance and a compute cluster to test. They're shutdown, and haven't used the workspace since Oct 25, yet today I log in and find out I have been charged around $0.40 daily for no apparent reason at all.    <\/p>\n<p>The cost management shows the following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255457-service-cost.png?platform=QnA\" alt=\"255457-service-cost.png\" \/>    <\/p>\n<p>And it's even showing that i'm supposedly using a premium SSD, which is what's costing the most:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255359-premium-ssd.png?platform=QnA\" alt=\"255359-premium-ssd.png\" \/>    <\/p>\n<p>I don't remember getting such a disk. And according to the portal, there isn't any:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255462-no-disks.png?platform=QnA\" alt=\"255462-no-disks.png\" \/>    <\/p>\n<p>According to the cost management again, it's not storage what's causing the high cost, it's the Azure ML resource:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255437-resources-azureml.png?platform=QnA\" alt=\"255437-resources-azureml.png\" \/>    <\/p>\n<p>There's even this tag: amlresourcetype: provisioner.batch    <br \/>\nI tried to google it, but I can't find anything about it.    <\/p>\n<p>So finally, I check the computer instances but everything seems ok:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255463-computes.png?platform=QnA\" alt=\"255463-computes.png\" \/>    <\/p>\n<p>So, does anyone have any remote idea as to why I'm being charged? Why does the cost management says I'm been charged for storage but then it says it's the Azure ML resource? How can I get rid of the supposedly premium SSD I'm using?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to set Quota at resource group level?",
        "Question_created_time":1667069444447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067916\/how-to-set-quota-at-resource-group-level",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi team,     <br \/>\nI am learning about the quota for machine learning service and I have a general doubt.    <\/p>\n<p>I can see that quotas for CPU cores is set at subscription level. Now, lets say my subscription level total CPU cores quota is 10.    <br \/>\nAnd i have 2 resource groups under that subscription. Can I assign 5 -5 cores each to both of the resource groups.     <\/p>\n<p>so that if all the cores are taken up by the resources under 1 resource group, the other resource_group (or the ML workspace under the other resource group) should not suffer.    <\/p>\n<p>I am able to find out  the-  get details query but this one doesnt give me details specific to each resource-group or the workspace.    <\/p>\n<p>HTTP query -&gt; <a href=\"https:\/\/management.azure.com\/subscriptions\/%7Bsubs_id%7D\/providers\/Microsoft.MachineLearningServices\/locations\/eastus\/usages?api-version=2022-10-01\">https:\/\/management.azure.com\/subscriptions\/{subs_id}\/providers\/Microsoft.MachineLearningServices\/locations\/eastus\/usages?api-version=2022-10-01<\/a><\/p>",
        "Question_closed_time":1667069947337,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=7bafa6a3-9285-4b1c-a003-4490a74d05b5\">@JA  <\/a> ,    <\/p>\n<p>quotas can be set on Azure Subscription level only.    <br \/>\nThere is no option to apply quotas for different Azure Resource Groups.    <br \/>\nThere are 2 options I can see for your requirement:    <br \/>\nUse 2 Azure Subscriptions for each Resource Group    <br \/>\nUse the 2 Resource Groups in 2 different regions. There is a quota for vCPUs per region within the same Subscription.    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Last Operation Failed. Not able to Start my VM compute",
        "Question_created_time":1666994188850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067503\/last-operation-failed-not-able-to-start-my-vm-comp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I am very new to the azure cloud, and I was using ML Studio service for my DS modeling until something happened with my Compute. One of my compute is stuck on Stopped status with a loading icon for a week. I cannot do anything with it, no start, no stopping, and no restarting. Does anybody know what is going on with my compute?    <\/p>\n<p>Thank you    <br \/>\nNathan<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255250-screenshot-2022-10-28-175353.png?platform=QnA\" alt=\"255250-screenshot-2022-10-28-175353.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML, OnlineEndPoint List API",
        "Question_created_time":1666975825190,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067262\/azure-ml-onlineendpoint-list-api",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>The Rest API to list all Online endpoints is returning an empty list. I have several Online Endpoints some with kubernetes cluster and some with Instance Containers.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/2022-10-01-preview\/online-endpoints\/list?tabs=HTTP#code-try-0\">https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/2022-10-01-preview\/online-endpoints\/list?tabs=HTTP#code-try-0<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML REST API - how to list Realtime Endpoints?",
        "Question_created_time":1650984915950,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/827037\/azure-ml-rest-api-how-to-list-realtime-endpoints",
        "Question_score_count":0,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to find the right Azure REST endpoint that would allow me to programmatically list out Realtime-Endpoints have have deployed in Azure ML.    <br \/>\nThe closest one that looked like it might give me what I'm looking for is <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/online-endpoints\/list?view=azure-ml-py\">Online Endpoints - List<\/a>, what when I test it out, get get back and empty results set, even though my workspace does contain a live and working Realtime enabled endpoint. Is this possibly a feature that's not fully implemented because it's in preview? Or is there another endpoint I should use to get this information? Thanks in advance for any help on this.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data Labeling Data name",
        "Question_created_time":1622641393617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/419384\/data-labeling-data-name",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Is there a possibility to show the data name of an image while labeling?     <br \/>\nSo I mean in this step <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects<\/a>     <br \/>\nIt would be much easier to choose the label if we know the data name<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"can I set budget for each model training session and then to pause the model training if the budget is crossed?",
        "Question_created_time":1666811077247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1064344\/can-i-set-budget-for-each-model-training-session-a",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>is it possible to control the budget for each training session in azure ML.     <br \/>\nLets say I am training a model and before starting the run, I want to set a budget of X dollars. and if it crosses, then my model training should pause unless I increase the budget to X+Y dollars.    <\/p>\n<p>Once the budget is increased, then only model training should resume. Is there any raw rest HTTP API or SDK options to control this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use a trained model for use cases (a new data set)",
        "Question_created_time":1665310129110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1040790\/use-a-trained-model-for-use-cases-(a-new-data-set)",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Dear all    <\/p>\n<p>I conducted some experiments with Microsoft Azure automated ML and DESIGNER.    <\/p>\n<p>As far as I understand the given results, the trained model shows e.g. the accuracy? How well or in how many cases can the trained model predict the value (e.g. TRUE or FALSE) correctly?    <\/p>\n<p>Now, I want to use the &quot;trained&quot; model(s) for use cases. My goal is to use the trained model(s) and provide predictions for new samples (a new data set). E.g. I want to predict the value &quot;TRUE&quot; or &quot;FALSE&quot; for the values of the new data set.    <\/p>\n<p>In my case, there is no value in the column (TRUE or FALSE). I want the model to provide me with the answers.    <\/p>\n<p>Next steps: As far as I see, I need to deploy the model so that I can conduct the same experiments with new samples?    <\/p>\n<p>Or how can I apply my trained model for the new use cases? (please see my description above)    <\/p>\n<p>Thank you for your feedback    <\/p>\n<p>Best regards    <\/p>\n<p>Lukas    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrate Azure ML Studio with Azure DevOps repo",
        "Question_created_time":1666021308520,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1051117\/integrate-azure-ml-studio-with-azure-devops-repo",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am working with Azure Machine Learning Studio via GUI (upload dataset, run experiments, register ML models, register endpoints, develop code in notebooks, ...) and would like to have that code available in Azure DevOps repo in order to restore it if necessary.    <\/p>\n<p>Does anyone know how that integration between Azure ML Studio and Azure DevOps repo could be done?    <\/p>\n<p>Thanks,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get the probability\/score by each cell\/row with machine learning?",
        "Question_created_time":1666667585287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1061214\/how-to-get-the-probability-score-by-each-cell-row",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have go through the solution in the forum but couldn't find a suitable solution for my question.    <br \/>\nI have use machine learning model to get the best algo for data modelling.    <br \/>\nI manage to get the confusion table but somehow i looking for probability\/scoring for each cell instead of overall result.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Generating scoring.py for azure ml model deployment",
        "Question_created_time":1642499410857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/699403\/generating-scoring-py-for-azure-ml-model-deploymen",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,   <br \/>\nI have registered a pretrained model to azure ml and i wish to deploy the model.   <br \/>\nThere is a compulsory file attachment called scoring file that i need to attach in order to deploy my model.   <br \/>\nMay i know how do i generate this scoring.py file?  <br \/>\nThanks in advance<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"Cold-start\" problem in Azure Recommender",
        "Question_created_time":1623136695973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/426312\/cold-start-problem-in-azure-recommender",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I've trained and deployed an Azure Wide &amp; Deep Recommender in the Designer tab of the Machine learning workspace.     <br \/>\nI have 3 datasets:    <\/p>\n<ul>\n<li> Ratings    <\/li>\n<li> User features    <\/li>\n<li> Item features    <\/li>\n<\/ul>\n<p>The recommendation system works fine for existing user IDs available in User Features and Rating datasets.     <br \/>\nHowever, when a want to make a prediction for a new user to the system, which IDs were not used during training, I get an error.    <\/p>\n<p>Is that expected that the recommendations are made only for users that the model learned during training? If not, please help me resolve this issue, so that even &quot;cold&quot; users can receive recommendations.     <\/p>\n<p>The model training and real-time inference pipelines are attached. Also, included the deployment logs with errors when sending a request to the model to make recommendations for new users.    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/103326-ci-error-logs-recommender-system.txt?platform=QnA\">103326-ci-error-logs-recommender-system.txt<\/a>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/103308-model-training-pipeline.png?platform=QnA\" alt=\"103308-model-training-pipeline.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/103320-model-training-pipeline.png?platform=QnA\" alt=\"103320-model-training-pipeline.png\" \/>    <\/p>\n<p>Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"OSError: Cannot save file into a non-existent directory",
        "Question_created_time":1666367036920,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1058457\/oserror-cannot-save-file-into-a-non-existent-direc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using <code>Azure ML Studio<\/code> to read data from a csv file by creating a data asset <code>test5<\/code> and write data into a csv file for my current working directory (which is failing). I am submitting a <code>Job<\/code> using a <code>Compute Cluster<\/code> and a <code>Custom Environment<\/code> and I am following the instructions from the tutorial: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day<\/a>    <\/p>\n<p>I have written the code in a notebook cell as:    <\/p>\n<pre><code># Handle to the workspace  \nfrom azure.ai.ml import MLClient  \n  \n# Authentication package  \nfrom azure.identity import DefaultAzureCredential  \ncredential = DefaultAzureCredential()  \n  \n# Get a handle to the workspace  \nml_client = MLClient(  \n    credential=credential,  \n    subscription_id=&quot;abc&quot;,  \n    resource_group_name=&quot;xyz&quot;,  \n    workspace_name=&quot;pqr&quot;,  \n)  \nfrom azure.ai.ml import command  \nfrom azure.ai.ml import Input  \n  \nregistered_model_name = &quot;read_data&quot;  \nenv_name = &quot;docker-context&quot;  \njob = command(inputs=dict(  \n        data=Input(  \n            type=&quot;uri_file&quot;,  \n            path=&quot;azureml:test5:1&quot;,  \n        ),  \n        registered_model_name=registered_model_name  \n    ),     \n    code=&quot;.\/src\/&quot;,  # location of source code  \n    command=&quot;python main.py --data ${&lt;!-- --&gt;{inputs.data}} --registered_model_name ${&lt;!-- --&gt;{inputs.registered_model_name}}&quot;,  \n    environment=&quot;docker-context:10&quot;,  \n    compute=&quot;amlcluster01&quot;,  \n    experiment_name=&quot;read_data1&quot;,  \n    display_name=&quot;read_data2&quot;,  \n    )  \nml_client.create_or_update(job)  \n  \n<\/code><\/pre>\n<p>This works fine. The content of the main.py is:    <\/p>\n<pre><code>import os  \nimport argparse  \nimport pandas as pd  \n  \ndef main():  \n    print(&quot;Hello&quot;)  \n     # input and output arguments  \n    parser = argparse.ArgumentParser()  \n    parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;)  \n    parser.add_argument(&quot;--registered_model_name&quot;, type=str, help=&quot;model name&quot;)  \n    args = parser.parse_args()  \n    print(&quot; &quot;.join(f&quot;{k}={v}&quot; for k, v in vars(args).items()))  \n    print(&quot;input data:&quot;, args.data)  \n    read_data=pd.read_csv(args.data)  \n    #read_data=pd.read_parquet(args.data, engine='pyarrow')  \n    #credit_df = pd.read_excel(args.data, header=1, index_col=0)  \n    print(read_data)  \n    read_data.to_csv(r'\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src\/file3.csv')  \n  \n    print(&quot;Hello World !&quot;)  \n  \nif __name__ == &quot;__main__&quot;:  \n    main()  \n  \n<\/code><\/pre>\n<p>Here, all lines of code work fine except <code>read_data.to_csv(r'\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src\/file3.csv')<\/code>.     <\/p>\n<p>It shows the error message as:  <code>OSError: Cannot save file into a non-existent directory:\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src<\/code>    <\/p>\n<p>Can anyone please help me how to save dataframe into a csv file into my current working directory through a <code>Job<\/code>. Any help would be appreciated.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't pull ACR image in compute instance of Azure Machine Learning Workspace:  VNetPLSetupError",
        "Question_created_time":1666098594973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1052833\/cant-pull-acr-image-in-compute-instance-of-azure-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When I deployed a training job to a compute instance it fails with the following error:<\/p>\n<p>AzureMLCompute job failed.  <br \/>\nVNetPLSetupError: Failed to pull Docker image xxxxxxxxxxx.azurecr.io\/azureml\/azureml_f306f67d2a96fc883ff0773a2a01394e with authentication mode IdentityToken due to: Docker responded with status code 500: {&quot;message&quot;:&quot;Head \\&quot;https:\/\/xxxxxxxxxx.azurecr.io\/v2\/azureml\/azureml_f306f67d2a96fc883ff0773a2a01394e\/manifests\/latest\\&quot;: Post \\&quot;https:\/\/xxxxxxxx.azurecr.io\/oauth2\/token\\&quot;: net\/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)&quot;}  <br \/>\n. This error may be caused by a Deny outgoing rule to Container Registry or AzureFrontDoor service tag, or a missing Allow outgoing rule to the same, which is blocking access to container registry <code>xxxxxxxxxx.azurecr.io<\/code><\/p>\n<p>It suddenly stopped working after it pulled without problems before.  <br \/>\nI can build and push an image, but not pull anymore.<\/p>\n<p>I checked the NSG that is associated with this ML workspace, but it has no outbound rules that could prevent the pull (push works as mentioned). There is no AzureFrontDoor tag configured.<\/p>\n<p>Did anyone come across this 'VNetPLSetupError' error?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Register Data Sets in Azure ML",
        "Question_created_time":1665561633607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1044629\/register-data-sets-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hello dear Microsoft Q&amp;A Team,    <\/p>\n<p>I'm new to Azure ML and have the following problem: I can't create data assets using a datastore. I did the following:    <\/p>\n<p>I created a datastore which points on my adls gen2 datalake using a service principal. I assigend all Storage Blob Data rolls (of the ressource group of the datalake) to this service principal. But when I try to create a dataset using this datastore the storage path does not load:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/249595-image.png?platform=QnA\" alt=\"249595-image.png\" \/>    <\/p>\n<p>Any idea what I'm doing wrong?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not enough quota available when deploying a machine learning model on Azure",
        "Question_created_time":1666148560563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1053752\/not-enough-quota-available-when-deploying-a-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was trying to deploy and score a machine learning model by using an online endpoint.    <\/p>\n<p>When I was trying to run code this on Azure Machine Learning Wordspace,    <\/p>\n<pre><code>!az ml online-deployment create --name fraud-ga --endpoint endpoint-name -f ..\/deployment\/deployment.yml --all-traffic  \n<\/code><\/pre>\n<p>I got this error:    <\/p>\n<pre><code>{&quot;errors&quot;:{&quot;VmSize&quot;:[&quot;Not enough quota available for Standard_F16s_v2 in SubscriptionId 671ef6e1-2ded-466b-8fd1-91363cf12275. Current usage\/limit: 4\/6. Additional needed: 32 Please see troubleshooting guide, available here: https:\/\/aka.ms\/oe-tsg#error-outofquota&quot;]},&quot;type&quot;:&quot;https:\/\/tools.ietf.org\/html\/rfc7231#section-6.5.1&quot;,&quot;title&quot;:&quot;One or more validation errors occurred.&quot;,&quot;status&quot;:400,&quot;traceId&quot;:&quot;00-a308e99ddee5fc8714e34fd0808b7e93-2031400dbc3e84d1-01&quot;}  \n<\/code><\/pre>\n<p>What I understood is that I need more cores.    <\/p>\n<p>So, in this case how many cores I needed and how to solve this error?    <\/p>",
        "Question_closed_time":1666152123510,
        "Answer_score_count":2.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>It sounds like you don't have enough quota available in the region where you are trying to deploy the ML model.    <br \/>\nIn Azure portal, you can check the allocated quota for each region under the subscription blade:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/251795-image.png?platform=QnA\" alt=\"251795-image.png\" \/>    <\/p>\n<p>The error message says: <em>Current usage\/limit: 4\/6. Additional needed: 32<\/em>    <\/p>\n<p>Request a quota increase and Azure support team can help on that!    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/251719-image.png?platform=QnA\" alt=\"251719-image.png\" \/>    <\/p>\n<p>----------    <\/p>\n<p>--please don't forget to <code>upvote<\/code> and <code>Accept as answer<\/code> if the reply is helpful--<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"I can't select By name in Columns to be cleaned as picture I attached. How should I deal with this?",
        "Question_created_time":1666255977207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1056111\/i-cant-select-by-name-in-columns-to-be-cleaned-as",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/252412-screenshot-704.png?platform=QnA\" alt=\"252412-screenshot-704.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/252367-screenshot-705.png?platform=QnA\" alt=\"252367-screenshot-705.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ray+dask native support  be added to Azure Machine Learning",
        "Question_created_time":1666227934133,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1055350\/ray-dask-native-support-be-added-to-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>While distributed dask can be setup manually on AML compute, the process requires lot of configs to be maintained. Is there any native support.<\/p>",
        "Question_closed_time":1666266282800,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">@D-0887  <\/a> Thanks for the question. you can do is to setup the compute cluster &amp; compute instance in the same vnet and pip install ray-on-aml. This allows both interactive and job use of Ray and Dask right within Azure ML.    <\/p>\n<p>Here is the document Library to turn Azure ML Compute into Ray and Dask cluster.    <br \/>\n<a href=\"https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/library-to-turn-azure-ml-compute-into-ray-and-dask-cluster\/ba-p\/3048784\">https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/library-to-turn-azure-ml-compute-into-ray-and-dask-cluster\/ba-p\/3048784<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to add\/modify AKS pod's labels when using Azure ML model deployment V2?",
        "Question_created_time":1666100120170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1052819\/is-it-possible-to-add-modify-aks-pods-labels-when",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hey!    <\/p>\n<p>I am deploying model to AKS by using <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-managed-online-endpoints\">model deployment V2<\/a>.    <\/p>\n<p>When deployment is succeeding, I can see from created pod in AKS, that it contains certain labels, like:    <\/p>\n<blockquote>\n<p><code>ml.azure.com\/compute: ***<\/code>    <br \/>\n<code>ml.azure.com\/deployment-name: ***<\/code>    <br \/>\n<code>ml.azure.com\/endpoint-name: ***<\/code>    <br \/>\n<code>ml.azure.com\/resource-group: ***<\/code>    <br \/>\n<code>ml.azure.com\/scrape-metrics: 'true'<\/code>    <br \/>\n<code>ml.azure.com\/subscription-id: ***<\/code>    <br \/>\n<code> ml.azure.com\/workspace: ***<\/code>    <\/p>\n<\/blockquote>\n<p>Many of these are very clear, but where <em><code>ml.azure.com\/scrape-metrics: 'true'<\/code><\/em> comes from? Can I modify these labels or create new ones somehow in the deployment.yaml?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure OpenAI advantages",
        "Question_created_time":1648125540293,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/785866\/azure-openai-advantages",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have a customer that is interested in the Azure OpenAI Service and had a few question:  <\/p>\n<p>What are the advantages for  using Azure OpenAI vs. OpenAI API.  <\/p>",
        "Question_closed_time":1648131698047,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>@App-4824  Thanks for the question. The Azure OpenAI team always works to make the latest models available in Azure as soon as they are available from OpenAI. This is an active area of work for the team to tighten release date for future models.  <br \/>\nThe Azure service is backed by an SLA (which typically a customer's primary need for high availability, low latency), and the support that comes along with Azure services. This is the first commercialized model of its kind from any public cloud provider. This is  unique advantage to be first to market and to work closely with customer to adopt\/embrace these models for production use. <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to use Azure ML Design ML Algorithms and Anomaly Detection in notebook?",
        "Question_created_time":1665342567200,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1041081\/how-to-use-azure-ml-design-ml-algorithms-and-anoma",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using Azure ML notebook to build and test a PCA-based anomaly detection model. The Azure ML Designer contains ML algorithms and anomaly detection methods. How can I reuse these Designer components in Azure notebook? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Is there a way to prevent registering an Environment when deploying locally?",
        "Question_created_time":1665427554937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1042597\/azure-ml-is-there-a-way-to-prevent-registering-an",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, we're trying to separate environment registration from deployment scripts so we have created two py files. This is a very simple example of the first one, which is actually registering the environment as desired.    <\/p>\n<pre><code>import argparse  \nimport logging  \n  \nfrom azureml.core import Workspace  \nfrom azureml.core.environment import Environment  \n  \nimport azure_config  \n  \n'''  \nThis script registers an environment in Azure ML Studio.  \nUsage:  \n    # Deploy a local webservice for testing  \n    python register_env-rm.py -m department  \n'''  \n  \n# Set up logging  \nlogging.basicConfig(level=logging.INFO)  \nlogger = logging.getLogger()  \nlogger.setLevel(logging.INFO)  \n  \ndef register_env(test_name: str):  \n    '''  \n    Registers an environment if one of the same version OR specs doesnt already exist.  \n    '''  \n    # Create instance of workspace  \n    ws = Workspace.get(  \n        name=azure_config.WORKSPACE_NAME,  \n        subscription_id=azure_config.SUBSCRIPTION_ID,  \n        resource_group=azure_config.RESOURCE_GROUP  \n    )  \n      \n    # Create an instance of the Environment based on the given specs  \n    myenv = Environment(name=test_name)  \n  \n    # Register Environment  \n    myenv.register(workspace=ws)  \n\tmyenv.python.conda_dependencies = CondaDependencies.create(  \n\t\t\tpip_packages=[&quot;fasttext==0.9.2&quot;]  \n\t\t\t)  \n    logger.info(&quot;New env registered&quot;)  \n  \nif __name__ == &quot;__main__&quot;:  \n    parser = argparse.ArgumentParser(description='Registers an environment in Azure ML Studio')  \n    parser.add_argument(  \n        &quot;-m&quot;,  \n        &quot;--test-name&quot;,  \n        help=&quot;Name of test&quot;,  \n        required=True,  \n        default=None,  \n        type=str)  \n      \n    args = parser.parse_args()  \n    test_name = args.test_name  \n  \n    register_env(test_name)  \n  \n<\/code><\/pre>\n<p>Then, here's another simple example of the script that will use to deploy our model. Since we're detecting that a new environment is being registered when deploying locally after the one that we've explicitly registered (running the script above), I'm just including that part of the deployment.    <\/p>\n<pre><code>import argparse  \nimport json  \nimport logging  \n  \nfrom azureml.core import Workspace  \nfrom azureml.core.environment import Environment  \nfrom azureml.core.model import InferenceConfig, Model  \nfrom azureml.core.webservice import LocalWebservice  \n  \nimport azure_config  \n  \n'''  \nThis script reproduces the bug where Model.deploy registers an environment.  \n'''  \n  \n# Set up logging  \nlogging.basicConfig(level=logging.INFO)  \nlogger = logging.getLogger()  \nlogger.setLevel(logging.INFO)  \n  \ndef test_dup_envs(test_name: str):  \n  \n    # Create instance of workspace  \n    ws = Workspace.get(  \n        name=azure_config.WORKSPACE_NAME,  \n        subscription_id=azure_config.SUBSCRIPTION_ID,  \n        resource_group=azure_config.RESOURCE_GROUP  \n    )  \n      \n    # Load model if exists  \n    model = Model(  \n        ws,  \n        name='mymodel',   \n        version=1  \n    )  \n  \n    # Get a newly registered env  \n    env = Environment.get(  \n            workspace=ws,   \n            name=test_name,   \n            version='1')  \n      \n    logger.info(f&quot;Env object: {env}&quot;)  \n  \n    # Create inference config  \n    inference_config = InferenceConfig(  \n        entry_script='score.py',   \n        source_directory='mysourcedir',  \n        environment=env)  \n  \n    # Deploy service locally  \n    local_dep_config = LocalWebservice.deploy_configuration(port=6789)  \n  \n    service = Model.deploy(  \n        workspace=ws,   \n        name=test_name,   \n        models=[model],   \n        inference_config=inference_config,   \n        deployment_config=local_dep_config  \n        )  \n  \n    service.wait_for_deployment(show_output=True)  \n    logger.info(service.get_logs())  \n  \n  \nif __name__ == &quot;__main__&quot;:  \n    parser = argparse.ArgumentParser(description='Reproduces the duplicate env bug')  \n    parser.add_argument(  \n        &quot;-m&quot;,  \n        &quot;--test-name&quot;,  \n        help=&quot;Name of test to deploy&quot;,  \n        required=True,  \n        default=None,  \n        type=str)  \n  \n    args = parser.parse_args()  \n      \n    test_name = args.test_name  \n  \n    test_dup_envs(test_name)  \n  \n<\/code><\/pre>\n<p>Is there a way to prevent that? Although we believe this might no impact predictions, we wouldn't like to have many versions of the same environment being registered.     <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pytorch error - RuntimeError: Unable to find a valid cuDNN algorithm to run convolution on Standard_NC6 and Python 3.8 - Pytorch and Tensorflow kernel",
        "Question_created_time":1666006220943,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1050727\/pytorch-error-runtimeerror-unable-to-find-a-valid",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello community,<\/p>\n<p>I am new to Azure. I have some scripts in a working environment in google colab, and as I am working on my Thesis I tried to user Azure Student promo.  <br \/>\nI have setup a Standard_NC6 with Pytorch and Tensorflow kernel and I am getting the following error:<\/p>\n<blockquote>\n<hr \/>\n<p>RuntimeError Traceback (most recent call last)  <br \/>\nInput In [9], in &lt;cell line: 64&gt;()  <br \/>\n76 loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))  <br \/>\n77 critic.zero_grad()  <br \/>\n---&gt; 78 loss_critic.backward(retain_graph=True)  <br \/>\n79 opt_critic.step()  <br \/>\n81 # clip critic weights between -0.01, 0.01<\/p>\n<p>File \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/_tensor.py:396, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)  <br \/>\n387 if has_torch_function_unary(self):  <br \/>\n388 return handle_torch_function(  <br \/>\n389 Tensor.backward,  <br \/>\n390 (self,),  <br \/>\n(...)  <br \/>\n394 create_graph=create_graph,  <br \/>\n395 inputs=inputs)  <br \/>\n--&gt; 396 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)<\/p>\n<p>File \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/autograd\/<strong>init<\/strong>.py:173, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)  <br \/>\n168 retain_graph = create_graph  <br \/>\n170 # The reason we repeat same the comment below is that  <br \/>\n171 # some Python versions print out the first line of a multi-line function  <br \/>\n172 # calls in the traceback and some print out the last line  <br \/>\n--&gt; 173 Variable._execution_engine.run_backward( # Calls into the C++ engine to run the backward pass  <br \/>\n174 tensors, grad_tensors_, retain_graph, create_graph, inputs,  <br \/>\n175 allow_unreachable=True, accumulate_grad=True)<\/p>\n<p>RuntimeError: Unable to find a valid cuDNN algorithm to run convolution<\/p>\n<\/blockquote>\n<p>I tried different versions of pytorch + cu113 and cu116.<\/p>\n<p>The nvdia-smi output is:<\/p>\n<blockquote>\n<p>+-----------------------------------------------------------------------------+  <br \/>\n| NVIDIA-SMI 470.141.03 Driver Version: 470.141.03 CUDA Version: 11.4 |  <br \/>\n|-------------------------------+----------------------+----------------------+  <br \/>\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |  <br \/>\n| Fan Temp Perf Pwr:Usage\/Cap| Memory-Usage | GPU-Util Compute M. |  <br \/>\n| | | MIG M. |  <br \/>\n|===============================+======================+======================|  <br \/>\n| 0 Tesla K80 On | 00000001:00:00.0 Off | 0 |  <br \/>\n| N\/A 41C P0 70W \/ 149W | 880MiB \/ 11441MiB | 0% Default |  <br \/>\n| | | N\/A |  <br \/>\n+-------------------------------+----------------------+----------------------+<\/p>\n<p>+-----------------------------------------------------------------------------+  <br \/>\n| Processes: |  <br \/>\n| GPU GI CI PID Type Process name GPU Memory |  <br \/>\n| ID ID Usage |  <br \/>\n|=============================================================================|  <br \/>\n| 0 N\/A N\/A 11425 C ...eml_py38_PT_TF\/bin\/python 877MiB |  <br \/>\n+-----------------------------------------------------------------------------+<\/p>\n<\/blockquote>\n<p>I guess that the problem is about drivers and versions.. as in google colab environment it's working<\/p>\n<p>Thanks,  <br \/>\nDP<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"R support in Azure ML using CLI 2.0",
        "Question_created_time":1666005191493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1050764\/r-support-in-azure-ml-using-cli-2-0",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, can somebody point me out to the latest hands on for using R Machine Learning in Azure ML. All the documentations are using Azure SDK for R, but it is deprecated as of end of 2021. Is there any step by step sample implementation using CLI 2.0 for R ML development<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can you create an MLTable Dataset (Tabular Format) from a CSV file?",
        "Question_created_time":1665800219957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1049085\/can-you-create-an-mltable-dataset-(tabular-format)",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have collected data that I'd like to use in AutoML to see if there's a pattern that can be derived from the data.  According to docs, the data needs to be uploaded in the MLTable format in order to be used in AutoML.  However, my data is currently in CSV format.  There are <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-data-assets?tabs=cli#create-data-assets\">fairly clear instructions<\/a> on how to create an MLTable data asset, but the instructions assume your data starts in MLTable format (see the Note: &quot;The path points to the folder containing the MLTable artifact&quot;).  I can't seem to find any instructions on how to create the MLTable artifact\/folder in the first place, so I can't follow these instructions.  Do these instructions exist somewhere?  If so, is it possible for someone to link me to it or describe this process?  Thank you!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"getting error -> does not support the API version '2022-05-01' while making query for arm using CURL",
        "Question_created_time":1665747402973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1048385\/getting-error-)-does-not-support-the-api-version-2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to get the AML token using CLI.    <br \/>\nI am able to get the token using the command -&gt; <strong>token=$(az account get-access-token --subscription {subscri ID} --resource-type arm --query accessToken --output tsv)<\/strong>    <\/p>\n<p>but when I use this token to get the AMLToken I get below error, however it is working fine if I make this query using postman :    <br \/>\n <strong>curl -d POST --header  &quot;Authorization: Bearer $token&quot; &quot;https:\/\/management.azure.com\/subscriptions\/{subcri id}\/resourceGroups\/{res_grup}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspace}\/onlineEndpoints\/{endpoint}\/token?api-version=2022-05-01&quot;<\/strong>    <\/p>\n<p>any helps or pointers please, why I am getting this error? Not able to find any documentation for it.    <\/p>\n<p>Error which I am getting is this-&gt;     <\/p>\n<p>{    <br \/>\n  &quot;error&quot;: {    <br \/>\n    &quot;code&quot;: &quot;UnsupportedApiVersion&quot;,  <br \/>\n    &quot;message&quot;: &quot;The HTTP resource that matches the request URI 'https:\/\/cert-eastus2.experiments.azureml.net\/mferp\/managementfrontend\/subscriptions\/{sub_id}\/resourceGroups\/{r_group}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspace}\/onlineEndpoints\/{endpoint}\/token' does not support the API version '2022-05-01'.&quot;,  <br \/>\n    &quot;innerError&quot;: null  <br \/>\n  }    <br \/>\n}   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is Data Drift Magnitude and Data Drift Contribution of each feature calculated in Azure Machine Learning (Azure ML)?",
        "Question_created_time":1646758413733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/764042\/how-is-data-drift-magnitude-and-data-drift-contrib",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>On <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python<\/a>,    <\/p>\n<p>it says :    <\/p>\n<p>Data drift magnitude:    <br \/>\nA percentage of drift between the baseline and target dataset over time. Ranging from 0 to 100, 0 indicates identical datasets and 100 indicates the Azure Machine Learning data drift model can completely tell the two datasets apart. Noise in the precise percentage measured is expected due to machine learning techniques being used to generate this magnitude.    <\/p>\n<p>Top drifting features:    <br \/>\nShows the features from the dataset that have drifted the most and are therefore contributing the most to the Drift Magnitude metric. Due to covariate shift, the underlying distribution of a feature does not necessarily need to change to have relatively high feature importance.    <\/p>\n<p>My questions are:    <\/p>\n<ol>\n<li> How is data drift magnitude calculated?    <\/li>\n<li> How is the data drift contribution of each feature calculated?    <\/li>\n<li> In the documentation, there are cases where the Wasserstein distance is low, yet the contribution of the feature is significant. Could you please clarify why that is the case?    <\/li>\n<\/ol>\n<p>Thank you in advance!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Total Regional Cores quota error",
        "Question_created_time":1665265961547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1040655\/total-regional-cores-quota-error",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Dear all    <br \/>\nI have a free Microsoft Azure student account. I am using Microsoft Azure automated ML and DESIGNER.    <br \/>\nI tried to deploy my model, which I created in DESIGNER.    <br \/>\nFor that, I need to create Compute, Inference clusters. When I do so, I always receive an error message: &quot;Operational could not be completed as it results in exceeding approved Total Regional Cores quota&quot;.  I tested various options, but all failed. I always chose Switzerland North, as it is the closest.    <br \/>\nIn addition, I constructed a new resource group. However, this did not make any difference.    <br \/>\nI read something about altering the Subscription (Azure for Students). However, then I'm not sure if I have to pay for the upgrade?    <\/p>\n<p>May you can tell me how it works with &quot;Azure for students&quot; when I want to deploy my model? How can I build a Compute, Inference clusters?    <\/p>\n<p>Thank you for your feedback.    <\/p>\n<p>Best regards    <\/p>\n<p>Lukas    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"which role to assign to a user to prevent him from accessing an ML scoring endpoint",
        "Question_created_time":1665639362440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1046043\/which-role-to-assign-to-a-user-to-prevent-him-from",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have users who have contributor access for a subscription, so what I understand from this is that they would have all the access to the resource groups, resources except granting  user access.    <br \/>\nNow, I have ML endpoints created in a ML workspace.    <br \/>\nWorkspace also by default inherit the access for all user as contributor which means they will be able to access the scoring endpoints.    <br \/>\nNow, I want to prevent users from accessing few endpoints in the workspace.    <br \/>\nSo, how I can achieve this narrow access when they already inherit broader access from subscription.    <br \/>\nWhich access should I give to user on endpoint? will the &quot;reader&quot; role prevent a user from accessing the endpoint?    <br \/>\nI am not able to understand this very clearly from microsoft documentation so clear pointers would help here.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Pepiline data not showing anything",
        "Question_created_time":1665577767170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1045134\/azure-pepiline-data-not-showing-anything",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm following the <a href=\"https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html\">https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html<\/a> exercise from the Azure IA-900 tutorial. In the Pepiline Assert Library Data Search is not showing anything, the Automobile price data (Raw) is not being found. ![249725-azure-pepiline.png][1] [1]: \/api\/attachments\/249725-azure-pepiline.png?platform=QnA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Scoring Script fails with ImportError: no known parent package",
        "Question_created_time":1603969996160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/144492\/azureml-scoring-script-fails-with-importerror-no-k",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>On trying to deploy a Model as a Container, endpoint gets created, however, scoring script fails with an error:<\/p>\n<blockquote>\n<p>ImportError: attempted relative import with no known parent package<\/p>\n<\/blockquote>\n<p>This is because i'm referencing another module (packaged in the docker image using source_directory) with a relative path from scoring file.<\/p>\n<p>Can you help me in resolving this error?<\/p>\n<p>Files\\modules structure (a simplified version):<\/p>\n<p>project  <br \/>\n-&gt;src  <br \/>\n-&gt; scoring.py  <br \/>\n-&gt; module1.py  <br \/>\n-&gt; common  <br \/>\n-&gt; module2.py, etc  <br \/>\n-&gt; <strong>init<\/strong>.py  <br \/>\n-&gt; <strong>init<\/strong>.py  <br \/>\n-&gt; configs  <br \/>\n-&gt; conda_env.yml<\/p>\n<p>In scoring.py,  <br \/>\nfrom .module1.py import SomeClass  <br \/>\n..  <br \/>\n..<\/p>\n<p>In module1.py,  <br \/>\nfrom .common.module2.py importSC2  <br \/>\n...  <br \/>\n..<\/p>\n<p>And below is how an Inference config is initialized:  <br \/>\ninference_config = InferenceConfig(source_directory=&quot;.\/&quot;,  <br \/>\nruntime= &quot;python&quot;,  <br \/>\nentry_script=&quot;src\/scoring.py&quot;,  <br \/>\nconda_file=&quot;configs\/conda_env.yml&quot;  <br \/>\n)<\/p>\n<p>I could not pass entry_script as &quot;src.scoring&quot; as this fails the Validation and relative path to scoring file is expected<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to trigger a python script on Azure Cloud?",
        "Question_created_time":1665493185007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1043642\/how-to-trigger-a-python-script-on-azure-cloud",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I wrote a python script on Azure Cloud for Machine Learning to analyze files in a folder with Cognitive Service. I need that script to be triggered, when a new folder is added to analyze the files in this folder.     <\/p>\n<p>Does anyone have an idea how to do this?    <\/p>\n<p>I\u00b4m quite clueless about this and would be thankful for any help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine learning model retraining on Azure Devops",
        "Question_created_time":1665464342207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1042999\/machine-learning-model-retraining-on-azure-devops",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I am building a pipeline Azure Devops. The model is in a .py file which connect to a database to extract training data and output a pickle file with the model.    <br \/>\nI would like to trigger this script every time there  is a database update.     <br \/>\nI use a .yaml file pipeline where I build and run a docker container with the model inside.    <br \/>\nI checked the possible way to trigger the .yaml pipeline and could not find a way to do that.    <br \/>\nWhat is the best way to achieve this? Should it be on it's own .yaml pipeline?     <br \/>\nI just started to use Azure devops and I am not sure what is the best practice in this case.    <\/p>\n<p>Thank you in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning pricing",
        "Question_created_time":1664581676843,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1031348\/machine-learning-pricing",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>hi I would like to know how to estimate the price for designer ?<\/p>",
        "Question_closed_time":1665358871540,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=5c0df626-d144-412c-8dd3-6bbe9f527d31\">@Louis  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform, I am sorry I should have seen your question earlier.     <\/p>\n<p>This price depends on your settings about the compute. I would say you should try the calculator to estimate your price to avoid surprise - <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\">https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/<\/a>    <\/p>\n<p>The screenshot of pricing calculator is as below -    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/248822-image.png?platform=QnA\" alt=\"248822-image.png\" \/>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <br \/>\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"is move workspace easy?",
        "Question_created_time":1664405263187,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027803\/is-move-workspace-easy",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p> we are not sure about our location but we do want to start now. If we need to move our workspace, is that possible? easy to accomplishing? Thank you <\/p>",
        "Question_closed_time":1664417546213,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=94bb880d-285d-4901-b0c8-d07117e001d8\">@Manuel  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. In my opionion, it depends on your scenario. Please check on this preview feature - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace<\/a>    <\/p>\n<p>As the document said, there are a lot of limitations -     <\/p>\n<ul>\n<li> Workspace move is not meant for replicating workspaces, or moving individual assets such as models or datasets from one workspace to another.    <\/li>\n<li> <strong>Workspace move doesn't support migration across Azure regions or Azure Active Directory tenants.<\/strong>    <\/li>\n<li> The workspace mustn't be in use during the move operation. Verify that all experiment jobs, data profiling jobs, and labeling projects have completed. Also verify that inference endpoints aren't being invoked.    <\/li>\n<li> The workspace will become unavailable during the move.    <\/li>\n<li> Before to the move, you must delete or detach computes and inference endpoints from the workspace.    <\/li>\n<li> Datastores may still show the old subscription information after the move.    <\/li>\n<\/ul>\n<p>Especially the second point, if you are considering move the region, you may need to be careful. I hope this helps!    <\/p>\n<p>Let me know if you have more questions and we are happy to help.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"need guidance to use train models in ML studio",
        "Question_created_time":1664405211343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027872\/need-guidance-to-use-train-models-in-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>hello new to ML studio. We have some trained model already but I want to use the studio for my next step. How should I import my model and retrain them? <\/p>",
        "Question_closed_time":1664410354943,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=94bb880d-285d-4901-b0c8-d07117e001d8\">@Manuel  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. Yes you can import your trained model to Azure Machine Learning Studio - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local<\/a>    <\/p>\n<p>You can learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.    <\/p>\n<p>Please check on above article to see how to register your model. I hope it helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"anomaly detector with azure",
        "Question_created_time":1664585272280,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1031454\/anomaly-detector-with-azure",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>May I have some samples about anomaly detector with azure machine learning studio? <\/p>",
        "Question_closed_time":1665356587117,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=033f3419-75e1-402b-b1ac-8869dd655829\">@minhoo lee  <\/a>     <\/p>\n<p>Sorry about the late response, I think what you are looking for is Anomaly detection in time series analytic. I find some resource you may want to have a look -     <br \/>\n<a href=\"https:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE\">https:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection\">https:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection<\/a>    <\/p>\n<p>Above resource are a little bit old, it is how to achieve the target in Azure Machine Learning.     <\/p>\n<p>Please let me know if you have more questions.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"RStudio application not installed in Azure ML compute",
        "Question_created_time":1662442948630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/995175\/rstudio-application-not-installed-in-azure-ml-comp",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>When users were creating a new compute in AML environment by default RStudio application was created.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/238009-screenshot-2022-08-23-170502.png?platform=QnA\" alt=\"With RStudio\" \/>    <\/p>\n<p>However, from month of July, by default RStudio application is not getting created. Only JupyterLab, Jupyter, VS Code, Terminal, Notebook applications installed not a RStudio.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/237995-4.png?platform=QnA\" alt=\"without RStudio\" \/>    <\/p>\n<p>Is there any way to by default install RStudio application in azure ML compute instance?    <\/p>",
        "Question_closed_time":1662454114980,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=8876fdcf-bcee-403a-827a-7cff9a68f8ee\">@SHAIKH, Alif Abdul  <\/a> Yes, this is a recent change in the setup of compute instance that happens during the creation of compute instance. This change does not setup the rstudio community edition by default but you can set it up while creation by adding it as a custom application from advanced settings. This change is done as part of RStudio requirements to allow users to setup their own license key or use open studio version during creation. Please refer this documentation <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=python#add-custom-applications-such-as-rstudio-preview\">page<\/a> for details to setup licensed and open version of the studio.    <\/p>\n<p>If you add a license key then please use RStudio Workbench (bring your own license) option from the advanced options and enter your own license key.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/238075-image.png?platform=QnA\" alt=\"238075-image.png\" \/>    <\/p>\n<p>If you need to add the open version you need to select custom application and enter the docker image and mount point details to setup the rstudio during creation.    <\/p>\n<p>Target\/Published port <code>8787<\/code>    <br \/>\nDocker image set to <code>ghcr.io\/azure\/rocker-rstudio-ml-verse:latest<\/code>    <br \/>\n<code>\/home\/azureuser\/cloudfiles<\/code> for Host path    <br \/>\n<code>\/home\/azureuser\/cloudfiles<\/code> for Container path    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/238135-image.png?platform=QnA\" alt=\"238135-image.png\" \/>    <\/p>\n<p>Once the creation and setup is complete the options to use Rstudio for open and licensed version will be visible as links on the compute instances page.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/238142-image.png?platform=QnA\" alt=\"238142-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Studio error while testing real-time endpoint -  list index out of range",
        "Question_created_time":1645577589217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp",
        "Question_score_count":1,
        "Question_answer_count":5,
        "Question_comment_count":4,
        "Question_body":"<p>I am new to the Azure ML Studio and just deployed the bike-rental regression model. When I tried to test it using the built in test tool in the studio, I am getting the attached error. Similar results running the Python code as well. Can someone please help me?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/176918-mlerror.png?platform=QnA\" alt=\"176918-mlerror.png\" \/>    <\/p>",
        "Question_closed_time":1645695329740,
        "Answer_score_count":3.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b7844017-59f9-4d2e-a021-76c2270e06ca\">@Kumar, Priya  <\/a> Thanks for the question. It's known issue and the product team working on the fix to change in the UI.    <\/p>\n<p>Workaround: As shown below please set the GlobalParameters flag to 1.0 or a float number or remove it.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/177485-image.png?platform=QnA\" alt=\"177485-image.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I fix the ImportError: cannot import name 'delayed'?",
        "Question_created_time":1664630157437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1031590\/how-do-i-fix-the-importerror-cannot-import-name-de",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>I am using the LORAS package from pyloras for imbalanced learning, but it requires importing the delayed package. I used the pip.main() to install the delayed package and from delayed.delay imported delayed. However, I am still getting the following error: ImportError: cannot import name 'delayed'. I appreciate your help and suggestions.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to download mlflow model artifacts from Azure Databricks workspace to local directory?",
        "Question_created_time":1664972415760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1036179\/how-to-download-mlflow-model-artifacts-from-azure",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have trained a machine learning model in Databricks workspace using mlflow. Model is getting registered in databricks model registry and saved in databricks file share. Now I want to download model artifacts from workspace. Currently I am transferring model to azure machine learning workspace. There I am able to download all the artifacts. How to do it from databricks workspace? <\/p>",
        "Question_closed_time":1665051150293,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c18ee9ee-fe4d-4f61-a87a-4da34719e169\">@Sriram Reddy  <\/a> Thanks for the question. To download a model from Databricks workspace you need to do two things:    <\/p>\n<p>Set MLFlow tracking URI to databricks using python API    <\/p>\n<p>Setup databricks authentication. I prefer authenticating by setting the following environment variables, you can also use databricks CLI to authenticate:    <\/p>\n<p>DATABRICKS_HOST    <\/p>\n<p>DATABRICKS_TOKEN    <br \/>\nHere's a basic code snippet to download a model from Databricks workspace model registry:    <\/p>\n<pre><code>import os  \nimport mlflow  \nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository  \n  \nmodel_name = &quot;example-model-name&quot;  \nmodel_stage = &quot;Staging&quot;  # Should be either 'Staging' or 'Production'  \n  \nmlflow.set_tracking_uri(&quot;databricks&quot;)  \n  \nos.makedirs(&quot;model&quot;, exist_ok=True)  \nlocal_path = ModelsArtifactRepository(  \n    f'models:\/{model_name}\/{model_stage}').download_artifacts(&quot;&quot;, dst_path=&quot;model&quot;)  \n  \nprint(f'{model_stage} Model {model_name} is downloaded at {local_path}')  \n<\/code><\/pre>\n<p>Running above python script will download an ML model in the model directory.    <\/p>\n<p>Containerizing MLFlow model serving with Docker    <\/p>\n<p>For more information you can follow this <a href=\"https:\/\/dev.to\/itachiredhair\/downloading-mlflow-model-from-databricks-and-serving-with-docker-38ip\">article<\/a> from Akshay Milmile    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Not able to read variable in custom RStudio open-source application , Azure ML",
        "Question_created_time":1665035652217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1037115\/not-able-to-read-variable-in-custom-rstudio-open-s",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML we have created compute instance by using setup shell script and we also installed custom RStudio open-source application using below MS docs  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/247908-image.png?platform=QnA\" alt=\"compute instance\" \/><\/p>\n<p>In setup shell script we define environment variable<\/p>\n<h1 id=\"create-renviron-file\">Create .Renviron file<\/h1>\n<p>r_env_file=&quot;\/home\/${aml_user}\/.Renviron&quot;<\/p>\n<p>echo &quot;Creating R environment variables&quot;  <br \/>\nsudo tee &quot;${r_env_file}&quot; &gt; \/dev\/null &lt;&lt;EOF  <br \/>\nAZURE_TENANT_ID=${AZURE_TENANT_ID}  <br \/>\nAZURE_CLIENT_ID=${AZURE_CLIENT_ID}  <br \/>\nAZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}  <br \/>\nDEFAULT_ADLS_ACCOUNT=${DEFAULT_ADLS_ACCOUNT}  <br \/>\nDEFAULT_ADLS_CONTAINER=${DEFAULT_ADLS_CONTAINER}  <br \/>\nEOF<\/p>\n<p>sudo chown &quot;${aml_user}&quot; &quot;${r_env_file}&quot;  <br \/>\nsudo chmod 600 &quot;${r_env_file}&quot;<\/p>\n<p>In terminal we are able to read above variable  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/247949-image.png?platform=QnA\" alt=\"treminal\" \/><\/p>\n<p>However, we are not able to read above variable in custom RStudio open-source application.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can you create an azure aks cluster with ephemeral os disk using python sdk ?",
        "Question_created_time":1664280949717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1025025\/can-you-create-an-azure-aks-cluster-with-ephemeral",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm deploying some code with azure aks and think an ephemeral os disk would be beneficial but I can't see a way to include this setting with the python SDK. Is this possible at the moment?     <\/p>\n<p>Cheers    <br \/>\nRhys<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to priotize certain values from the Excel Worksheet (CSV) in \"automated ML or Designer\"",
        "Question_created_time":1664834223093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1033854\/how-to-priotize-certain-values-from-the-excel-work",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an Excel Worksheet with many values from students (anonymized) who applied for a MSC.    <br \/>\nAll values are checked during the &quot;admission process&quot; from the University.    <\/p>\n<p>Admission criteria: The student will only be granted (accepted) to the MSc if he has a certain grade (BSc) and his University (BSc) is accepted (accredited). Furthermore, he should show a good English level. In addition, the student needs at least (around) 2 years of work experience, before he can start with the MSc. Certain values (e.g. the grade) can be compensated by other values (e.g. the work experience) to a defined level.    <\/p>\n<p>By using Microsoft Azure, I want to predict if a student will be accepted or not accepted. And\/or maybe if a certain process step (e.g. check the English level) needs to be conducted or a recommendation\/prediction can be given instead - just on the basis of historical values.    <\/p>\n<p>So far, my models (in Microsoft Azure automated ML and sometimes in Micorosft Azure Designer) recognize (or weight) values such as the student ID (e.g. 1, 2, 3) or the Start-Semester (e.g. Autumn 2022) as more important than values such as e.g. &quot;work experience&quot;, &quot;grade&quot; (BSc) or &quot;the University&quot; (BSc).    <\/p>\n<p>My question: Is there a possibility to prioritize certain values in &quot;Microsoft Azure automated ML&quot; or Microsoft Azure Designer&quot;?    <br \/>\nMoreover, can I set admission criteria (please see above), which need to be fulfilled or taken into account for the model?    <\/p>\n<p>Thank you for your feedback    <br \/>\nBest regards    <br \/>\nLukas<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine learning, Resource group exhaustion when triggering ML Compute Cluster run",
        "Question_created_time":1664374745717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027000\/machine-learning-resource-group-exhaustion-when-tr",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I am running a Jupiter notebook in Azure Machine Learning, but my runs today frequently end up with this error:    <\/p>\n<p>Creating the resource group 'afd46bcb-6c53-431c-9f34-f6c2e97e95a0-AzureBatch-CloudService' would exceed the quota of '980'. The current resource group count is '980', please delete some groups before creating a new one.    <br \/>\n{&quot;error&quot;:{&quot;code&quot;:&quot;ResourceGroupQuotaExceeded&quot;,&quot;message&quot;:&quot;Creating the resource group 'afd46bcb-6c53-431c-9f34-f6c2e97e95a0-AzureBatch-CloudService' would exceed the quota of '980'. The current resource group count is '980', please delete some groups before creating a new one.&quot;}}. False    <\/p>\n<p>My guess is that the mentioned subscription (and resource group) is part of the Machine Learning PaaS. Could you advise me what to do if I want to avoid this error going forward while I insist on deploying my Machine Learning workspace in West Europe ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Time duration (years and months)",
        "Question_created_time":1664745919727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1032331\/time-duration-(years-and-months)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Dear all.    <br \/>\nI'm trying to figure out how I need to format &quot;a time duration value&quot; (years and months) on my Excel sheet (CSV) so that it is recognized correctly by Microsoft Azure automated ML and Designer. E.g. I have a value on my Excel Sheet like: &quot;14years, 4months&quot;.    <br \/>\nMay you can tell me which format I have to choose in Excel for such values?    <br \/>\nThank you.    <br \/>\nBest regards Lukas    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Input \"Untrained model\" has invalid type \"DataTable\" error",
        "Question_created_time":1663734079143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1016607\/azure-machine-learning-input-untrained-model-has-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>First time trying Azure ML using Two-Class Logistic Regression.     <\/p>\n<p>Data source is a table in AzureSQL and it's throwing InvalidLearnerError: Input &quot;Untrained model&quot; has invalid type &quot;DataTable&quot;.    <\/p>\n<p>Help? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML for SAP ERP",
        "Question_created_time":1664541861543,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1030800\/azure-ml-for-sap-erp",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to figure out about standard connectors between SAP ERP product and Azure ML especially for NLP scenarios. Can you please suggest on this.<\/p>",
        "Question_closed_time":1664542897547,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">@D-0887  <\/a> Thanks for the question. Here is the blog that could help and <a href=\"https:\/\/github.com\/microsoft\/nlp-recipes\">nlp recipes<\/a>.    <br \/>\n<a href=\"https:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/\">https:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"I want to register the model learned by AutoML in Azure Machine learning in ONNX format and call it in Azure Synapse Analitics.",
        "Question_created_time":1664411309103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027830\/i-want-to-register-the-model-learned-by-automl-in",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I found that I can register the model using Mlflow, but I don't know how to register it in ONNX format.    <br \/>\nI found out that the model is registered using Mlflow.    <br \/>\nBut I don't know how to convert AutoML models to ONNX format and register them with Mlflow.    <\/p>\n<p>from azure.ai.ml import MLClient    <br \/>\nfrom azure.identity import DefaultAzureCredential    <br \/>\nfrom azureml.train.automl import AutoMLConfig    <br \/>\nfrom azureml.core import Workspace, Dataset    <br \/>\nfrom azureml.core.experiment import Experiment    <br \/>\nfrom azureml.core.model import Model    <br \/>\nfrom azureml.core.authentication import ServicePrincipalAuthentication    <br \/>\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter    <br \/>\nfrom random import random    <br \/>\nfrom mlflow.tracking import MlflowClient    <br \/>\nimport mlflow    <br \/>\nimport mlflow.onnx    <br \/>\nimport os    <br \/>\nimport azureml.mlflow    <\/p>\n<p>auth = ServicePrincipalAuthentication(    <br \/>\n    tenant_id=&quot;&quot;,  <br \/>\n    service_principal_id=&quot;&quot;,  <br \/>\n    service_principal_password=&quot;&quot;)  <\/p>\n<p>subscription_id = ''    <br \/>\nresource_group = ''    <br \/>\nworkspace_name = ''    <\/p>\n<p>ml_client = MLClient(credential=auth,    <br \/>\n                    subscription_id=subscription_id,  <br \/>\n                    resource_group_name=resource_group)  <\/p>\n<p>azure_mlflow_uri = ml_client.workspaces.get(workspace_name).mlflow_tracking_uri    <br \/>\nmlflow.set_tracking_uri(azure_mlflow_uri)    <\/p>\n<p>ws = Workspace(subscription_id, resource_group, workspace_name, auth=auth)    <\/p>\n<p>train_data = Dataset.get_by_name(ws, name='iris')    <\/p>\n<p>label = &quot;class&quot;    <\/p>\n<p>automl_settings = {    <br \/>\n    &quot;primary_metric&quot;: 'AUC_weighted',  <br \/>\n    &quot;n_cross_validations&quot;: 2  <br \/>\n    }  <\/p>\n<p>automl_classifier = AutoMLConfig(    <br \/>\n    task='classification',  <br \/>\n    blocked_models=['XGBoostClassifier'],  <br \/>\n    enable_onnx_compatible_models=True,  <br \/>\n    experiment_timeout_minutes=30,  <br \/>\n    training_data=train_data,  <br \/>\n    label_column_name=label,  <br \/>\n    **automl_settings  <br \/>\n    )  <\/p>\n<p>experiment_name = 'experimetn_with_mlflow'    <br \/>\nmlflow.set_experiment(experiment_name)    <br \/>\nexperiment = Experiment(ws, experiment_name)    <\/p>\n<p>with mlflow.start_run() as mlflow_run:    <br \/>\n    mlflow.log_metric(&quot;iris_metric&quot;, random())  <\/p>\n<pre><code>mlflow_run = experiment.submit(automl_classifier, show_output=True)  \n\ndescription = 'iris_Description'  \n\nmodel = mlflow_run.register_model(description=description,  \n                               model_name='iris_Model')  \n\nbest_run, onnx_mdl = mlflow_run.get_output(return_onnx_model=True)  \nonnx_fl_path = &quot;.\/best_model.onnx&quot;  \nOnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)  \n\nmodel = Model.register(workspace=ws,  \n                    description=description,  \n                    model_name='iris_onnx_model',  \n                    model_path=onnx_fl_path)  \n\nclient = MlflowClient()  \n\nfinished_mlflow_run = MlflowClient().get_run(mlflow_run.run_id)  \n\nmetrics = finished_mlflow_run.data.metrics  \ntags = finished_mlflow_run.data.tags  \nparams = finished_mlflow_run.data.params  \n\nmodel_path  = &quot;best_model&quot;  \nmodel_uri = 'runs:\/{}\/{}'.format(mlflow_run.run_id, model_path)  \nmlflow.register_model(model_uri, 'iris_onnx_mlflow_model')\n<\/code><\/pre>",
        "Question_closed_time":1664453127300,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=cef675e6-0d34-4e7e-873a-aec3478f614f\">@\u4fdd\u53f2 \u7d30\u898b  <\/a> Thanks for the question.  Can you please share document\/sample that you are trying. In order to save trained model download (and score) as the ONNX model you have here a few code <a href=\"https:\/\/github.com\/CESARDELATORRE\/azureml-workshop-2019\/blob\/master\/2-training-inference\/2.3-automl-training\/local-compute\/binayclassification-employee-attrition-autoaml-local-compute.ipynb\">examples<\/a>.    <br \/>\nMLflow model registry will enable Synapse to run ONNX models is in preview.    <\/p>\n<p>Here is the ONNX prediction section in the sample <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/classification-bank-marketing-all-features\/auto-ml-classification-bank-marketing-all-features.ipynb\">notebook<\/a>.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Not able to archieve specific enviornment version in azure ml",
        "Question_created_time":1664433909617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1028195\/not-able-to-archieve-specific-enviornment-version",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I was trying to archive a specific environment version in azure machine learning using the &quot;az ml environment archive &quot; but getting error that the &quot;Version is already registered and can not be changed&quot;.      <br \/>\nAs per the Microsoft documentation at <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/environment?view=azure-cli-latest#az-ml-environment-archive\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/environment?view=azure-cli-latest#az-ml-environment-archive<\/a> it is possible to archive a specific version without archiving entire environment container.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/245922-image-1.png?platform=QnA\" alt=\"245922-image-1.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Moving Azure Machine Learning Studio jobs to a new region",
        "Question_created_time":1662467585447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/995833\/moving-azure-machine-learning-studio-jobs-to-a-new",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I need to move my Machine Learning Studio workspace to a new region. I am aware that the move function <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\">doesn't allow automatically moving to a new region<\/a>, so I'll have to create a new workspace. That's not a big problem, but I still want to keep my job\/experiment history (in my new workspace). How can I do that?    <\/p>",
        "Question_closed_time":1664291528087,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a645d9b8-7c24-4419-8686-bc144a45c4f1\">@David-3633  <\/a>     <\/p>\n<p>Sorry, I just got confimation from product team, this is currently impossible. I am sorry for the inconvenience.     <\/p>\n<p>A near future workaround which could let users at least share some experiment outputs\/inputs like environments, models, datasets cross region, but not the jobs\/metrics\/logs themselves. This feature is in private preview now and will be in public preview soon.    <\/p>\n<p>I hope this information helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Issue with DataDriftDetector get_output method",
        "Question_created_time":1664169018620,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1022532\/issue-with-datadriftdetector-get-output-method",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>Hi,    <\/p>\n<p>Please help me with issue in below code    <\/p>\n<p>When i run above code in .ipynb file separately, there is no issue.    <\/p>\n<p><strong>Standalone execution:<\/strong>    <br \/>\n    from azureml.core import Workspace  <br \/>\n    from azureml.datadrift import DataDriftDetector, AlertConfiguration  <br \/>\n    from datetime import datetime  <br \/>\n    ws = Workspace.from_config()  <br \/>\n    dstore = ws.get_default_datastore()  <\/p>\n<pre><code>monitor = DataDriftDetector.get_by_name(ws, 'cc-silver_stable-drift-test-ver2')  \nmonitor.get_output(start_time=datetime(year=2019, month=9, day=1))  \n<\/code><\/pre>\n<p><strong>Within Azure SDK Pipeline<\/strong>    <br \/>\nWhile running below code <strong>(monitor.get_output())<\/strong> in Azure SDK pipeline,     <br \/>\nit results in error <strong>(TypeError: Cannot Unpack Non-Iterable NoneType Object).<\/strong>    <br \/>\nIssue is with last line of code (bold).    <\/p>\n<pre><code>from azureml.core import Datastore, Dataset, Workspace  \nfrom azureml.core import Experiment, Run  \nfrom azureml.core.compute import ComputeTarget, AmlCompute  \nfrom azureml.core.compute_target import ComputeTargetException  \nfrom azureml.datadrift import DataDriftDetector  \nfrom azureml.core import Workspace  \nimport pandas as pd  \nimport numpy as np  \nimport datetime as dt  \nfrom datetime import datetime, date, timedelta  \n  \nrun = Run.get_context()  \nws = run.experiment.workspace  \n  \nfrom azureml.datadrift import DataDriftDetector  \nfrom azureml.core import Workspace  \nmonitor = DataDriftDetector.get_by_name(ws, 'cc-silver_stablever3')  \nprint(monitor.get_output(start_time=datetime(year=2022, month=1, day=1),  \n                        end_time=datetime(year=2022, month=5, day=1)))  \n<\/code><\/pre>\n<p>Regards,    <br \/>\nAijaz Ahmad Hajam    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Warning while cretaing Dataset from Datastore",
        "Question_created_time":1664348355043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1026239\/warning-while-cretaing-dataset-from-datastore",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>While creating a dataset using a datastore I see the following    <br \/>\n&quot;Warning: The selected datastore's SAS is insufficient to create this dataset.    <br \/>\nReading the dataset requires Read permission for Objects as well as Containers if the path is a folder or glob.&quot;    <\/p>\n<p>I've ensured that the necessary permissions are assigned to the managed resources as well as the users. But still I see this warning. Will this create problem while accessing data from blob storage?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure CLI - az ml register components idempotent?",
        "Question_created_time":1664211025747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1023499\/azure-cli-az-ml-register-components-idempotent",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Are az ml register components idempotent?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Could not find a suitable TLS CA certificate bundle invalid path",
        "Question_created_time":1664204652743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1023399\/could-not-find-a-suitable-tls-ca-certificate-bundl",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have a project using Azure Macline Learning service and Translator. The project language is Python 3.7.2.    <br \/>\nWhat is the reason this problem ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML: Data initialization error when input to the batch endpoint is data from cloud",
        "Question_created_time":1664012828150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1021674\/azureml-data-initialization-error-when-input-to-th",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to invoke batch endpoint using data on cloud as input using CLI. When I use the input as local data it works fine but when I use the register datastore as input the job fails with the following error:    <br \/>\nDataset initialization failed: UserErrorException:    <br \/>\n\tMessage: Cannot mount Dataset(id='d10c7934-9c62-4e15-adf1-bc7386648403', name='None', version=None). Error Message: DataAccessError(NotFound)  <br \/>\n\tInnerException None  <br \/>\n\tErrorResponse   <br \/>\n{    <br \/>\n    &quot;error&quot;: {  <br \/>\n        &quot;code&quot;: &quot;UserError&quot;,  <br \/>\n        &quot;message&quot;: &quot;Cannot mount Dataset(id='d10c7934-9c62-4e15-adf1-bc7386648403', name='None', version=None). Error Message: DataAccessError(NotFound)&quot;  <br \/>\n    }  <br \/>\n}    <\/p>\n<p>My cli command:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/244501-screenshot-2022-09-24-at-114415.png?platform=QnA\" alt=\"244501-screenshot-2022-09-24-at-114415.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"unable to create datadrift alert in Azure ML",
        "Question_created_time":1663946292127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1021112\/unable-to-create-datadrift-alert-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am unable to create datadrift alert while trying to create a datadrift monitor. I am getting following error: Datadriftdetector with id: e83bd907-a268-4137. This may be because you do not have access to the AppInsights associated with this AzureML Workspace    <\/p>\n<p>I have even given User Access Admin role but not able to create alert<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML CLI v2 independent, parallel, low-priority nodes which restart",
        "Question_created_time":1663790217710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1018156\/azure-ml-cli-v2-independent-parallel-low-priority",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi and thanks in advance for your time. This one's a bit long-winded, sorry.    <\/p>\n<p>I am using the Azure ML CLI v2 to perform both training and hyperparameter optimization of deep neural networks. My codebase makes use of checkpointing and can therefore be pre-empted. I also have a lot of parallel, largely independent work going on (e.g. training separate models over a fixed number of seeds or performing parallel hyperparameter optimization with an RDB coordinating the trials). Basically I want to recreate a <a href=\"https:\/\/help.rc.ufl.edu\/doc\/SLURM_Job_Arrays\">SLURM Job Array<\/a>. My solution so far has been to create a low-priority compute cluster of size <code>N<\/code>, spawn a single job with <code>N<\/code> nodes, and use    <\/p>\n<pre><code>   yaml  \n   distribution:  \n     type: pytorch  \n     process_count_per_instance: 1  \n<\/code><\/pre>\n<p>to create <code>N<\/code> processes to run independently. This works (sort of), but has two major drawbacks. First, Azure doesn't know that the <code>N<\/code> processes are independent, meaning both queueing and preemption happens for all <code>N<\/code> processes at once. I'm fine with any number of processes being preempted at a time as long as they finish eventually. That's my second point: the preempted job does not requeue automatically. I can manually restart it, of course, but ideally I can leave it and come back.    <\/p>\n<p>Does anyone have a better solution for this? Can Azure ML handle what I want to do, or do I have to switch to something like <a href=\"https:\/\/azure.github.io\/batch-shipyard\/\">Batch Shipyard<\/a>?    <\/p>\n<p>Thanks again,    <br \/>\nSean<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do you create an azure jupyter in vscode?",
        "Question_created_time":1662435889603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/995055\/how-do-you-create-an-azure-jupyter-in-vscode",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hey all,    <\/p>\n<p>I hope you are all doing well. I am wondering if you can use azure jupyter notebook in vscode if you have the azure extension and the jupyter notebook extension?     <\/p>\n<p>Thanks,    <br \/>\nKen<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I use a already trained model of AutoML in Designer pipelines, for retraining and deploy?",
        "Question_created_time":1663853333980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1019338\/how-can-i-use-a-already-trained-model-of-automl-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a model that is already been trained with Auto ML (Voting Ensemble algorithm). This model is already deployed and in production.    <br \/>\nI would like to know how can I retrain this model using the Designer pipelines? More specificaly, how can I import this model, builded on Auto ML, with some of the components in the designer for retraining?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I use Azure Key Vault from Notebook in Azure Machine Learning",
        "Question_created_time":1662737071997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1001137\/how-do-i-use-azure-key-vault-from-notebook-in-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to use Azure Key Vault in Azure Machine learning notebook. However, I am unable to load the credentials from Kev Vault to Jupiter Notebook Environment.     <\/p>\n<p>I tried using the Microsoft Learn available. Using those docs it works for python environments outside Jupiter notebook but not in  Jupiter notebook.    <\/p>\n<p>Can someone please let me know solution for this? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is azure ml studio not showing my subscription",
        "Question_created_time":1662182084083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/992557\/why-is-azure-ml-studio-not-showing-my-subscription",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>azure machine learning studio does not show my azure pass subscription <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to access Azure Machine Learning Studio without a Public IP",
        "Question_created_time":1645431850553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/743872\/how-to-access-azure-machine-learning-studio-withou",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Dear Support Team,<\/p>\n<p>Hope this email finds you well. I am writing to you because I am trying to access Azure ML Studio without a public IP but I am having some troubles.<\/p>\n<p>I saw the tutorial &quot;Create a secure workspace&quot; tutorial and I wanted to confirm that making the jump box is a &quot;must&quot; for accessing the azure ML studio without public IP, or I can do it from my browser after making all the secure space?<\/p>\n<p>Is there any method I can do it? I just can not upload any file\/ or see previous files<\/p>\n<p>Also I have this error:  <br \/>\nHowever I have the contributor permission  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/176315-screen-shot-2022-02-21-at-171938.png?platform=QnA\" alt=\"176315-screen-shot-2022-02-21-at-171938.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/176304-screen-shot-2022-02-21-at-171846.png?platform=QnA\" alt=\"176304-screen-shot-2022-02-21-at-171846.png\" \/>  <br \/>\nCan you help me with this?<\/p>\n<p>Thank you for your time and hope you are having a great day,<\/p>\n<p>Catherine<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"what is the best IoT architecture for AI in Azure ?",
        "Question_created_time":1663849334273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1019237\/what-is-the-best-iot-architecture-for-ai-in-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm here to ask for advice on an architecture I've set up for real-time data processing. The goal is to have a Dashboard able to display all the metrics coming from the connected objects and to be able to make predictions in real time (cost prediction, maintenance prediction etc..) using AI.     <\/p>\n<p>I set up the architecture below with a script simulating a machine. But I have a lot of doubts about this one.    <\/p>\n<p>Especially for Stream Analytics. I would like to be able to clean the raw data, before storing them (aggregation in particular) to calculate an OEE and other things.    <\/p>\n<p>But SA is limited in terms of data aggregation, so I would like to know what would be the best alternative for real-time data processing before storing it.    <\/p>\n<p>Should I use Azure Function combined with SA?     <br \/>\nCan Azure Machine Learning studio do this processing work with or without SA?     <br \/>\nAzure Databricks seemed to be a good alternative but I'm having a lot of trouble setting up a real-time data processing stream and CSV\/Json storage in my data lake but I don't know if I'm doing it wrong or if it's just impossible.    <\/p>\n<p>Azure Data Factory didn't seem to be adapted to real time data processing so I abandoned this option    <\/p>\n<p> There are so many options and I have no idea in which direction to go, I've been working on it for several months.    <\/p>\n<p>Thanks to all the people who will take the time to answer.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connection Error 403",
        "Question_created_time":1663611187617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1014310\/connection-error-403",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I keep on getting this error while trying to access the Twitter API using the TwitterClient. The Client builds successfully but then it shows this error when I run: <code>dotnet run<\/code>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/242681-screen-shot-2022-09-19-at-90755-pm.png?platform=QnA\" alt=\"242681-screen-shot-2022-09-19-at-90755-pm.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create tabular dataset in notebook with R kernel",
        "Question_created_time":1663428115537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1012184\/how-to-create-tabular-dataset-in-notebook-with-r-k",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to create a tabular dataset in a notebook with R kernel. The following code works with python kernel but how to do the same thing with R kernel ? Can anyone please help me ? Any help would be appreciated.     <\/p>\n<pre><code>from azureml.core import Workspace, Dataset  \n from azureml.core.dataset import Dataset  \n      \n subscription_id = 'abc'  \n resource_group = 'abcd'  \n workspace_name = 'xyz'  \n      \n workspace = Workspace(subscription_id, resource_group, workspace_name)  \n      \n dataset = Dataset.get_by_name(workspace, name='test')  \n      \n      \n # create tabular dataset from all parquet files in the directory  \n tabular_dataset_3 = Dataset.Tabular.from_parquet_files(path=(datastore,'\/UI\/09-17-2022_125003_UTC\/userdata1.parquet'))  \n<\/code><\/pre>",
        "Question_closed_time":1663571695407,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=0274aa41-1ea9-4fdc-8434-c9c13c43307c\">@Ankit19 Gupta  <\/a> The Azure Machine Learning SDK for R was deprecated at the end of 2021 to make way for an improved R training and deployment experience using Azure Machine Learning CLI 2.0    <br \/>\nPlease refer the azureml SDK <a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\">repo<\/a> for more details which was deprecated at the end of last year. You can use CLI to register the dataset using specification file.    <\/p>\n<pre><code>az ml dataset register [--file]  \n                       [--output-metadata-file]  \n                       [--path]  \n                       [--resource-group]  \n                       [--show-template]  \n                       [--skip-validation]  \n                       [--subscription-id]  \n                       [--workspace-name]  \n<\/code><\/pre>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can we connect the data from Kusto to Azure Machine Learning Studio directly ?",
        "Question_created_time":1663120535263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1006422\/can-we-connect-the-data-from-kusto-to-azure-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi everyone,    <br \/>\nPlease help me to verify that is there anyway to connect the data from Kusto (KQL\/ADX) to use on Azure ML Studio. I have tried the solution alternatively that I exported the data from Kusto and them imported them to the instance container on Azure Portal, then link them to the Datastore of Azure ML Studio.    <\/p>\n<p>As I researched, there is a suggestion as : <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.kustostep?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.kustostep?view=azure-ml-py<\/a>    <\/p>\n<p>But I dont know whether that is a good approach? And how to implemented the &quot;KustoStep&quot; pipeline correctly?    <br \/>\nPlease help me if there is another way to connect the data directly from Kusto to Azure ML     <br \/>\nThank you so much !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to delete classic  azure machine learning workspace",
        "Question_created_time":1663644201527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1014833\/how-to-delete-classic-azure-machine-learning-works",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I could see it in <a href=\"https:\/\/studio.azureml.net\/\">https:\/\/studio.azureml.net\/<\/a> , but I couldn't see it in the azure portal, it spends 9 dollar each month. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"allow_reuse in Azure ml sdk v2",
        "Question_created_time":1656438857840,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/906911\/allow-reuse-in-azure-ml-sdk-v2",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am running a training pipeline on azure ml python sdk v2. It is running fine but when I am reinitiating it, it takes only 1 second to finish which I assume is taking previous step from last ran pipeline. In v1 sdk we have <strong>allow_reuse<\/strong> parameter to stop this behaviour. But how can we do that in ml python sdk v2.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Databricks mlflow model serving networking",
        "Question_created_time":1662480716897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/996163\/databricks-mlflow-model-serving-networking",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hi there, I'm trying to register a ML model to the mlflow model registry to be served from an Azure web app. I'm wondering if the databricks networking configuration will apply to the model api endpoint, as in, calls to the api from outside the VNET which the databricks is deployed to with private endpoints and disabled public access will be rejected and the call from within the vnet integrated web app will be successful?    <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":1663046075633,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=72c1697f-78db-46b7-813e-f61c7171cb88\">@Chammie Ho  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>I'm wondering if the databricks networking configuration will apply to the model api endpoint    <\/p>\n<\/blockquote>\n<p>Yes, it will. The single node cluster on which the model is hosted (classic), is deployed in data plane and will have a private IP.     <\/p>\n<blockquote>\n<p>I should be able to call the model with the url &lt;databricks-instance&gt;\/model\/&lt;registered-model-name&gt;\/&lt;model-version&gt;\/invocations, my question is whether this url will have the same restrictions as the databricks where it resides    <\/p>\n<\/blockquote>\n<p>I believe, this should work as long as you have not defined any IP access list. The PAT will let you authenticate.    <\/p>\n<blockquote>\n<p>but I can't find information for IP restrictions    <\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/security\/network\/ip-access-list\">IP access lists - Azure Databricks | Microsoft Learn<\/a>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.pngsfe?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.pngjust?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.htmlstr\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is jhow you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can we scale up and down the ML Compute instance while compute ( run) the notebook on Ms Azure ML Studio?",
        "Question_created_time":1662618616250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/998717\/can-we-scale-up-and-down-the-ml-compute-instance-w",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello all,    <br \/>\nPlease help me to verify the question above, as working for a company, I would like to run, process a predict model on Microsoft Azure ML Studio notebook, as I tried, I could only pick 1 option at the beginning to compute the notebook source code. I would like to know whether we can scale up for the stronger CPU ( with higher charging price ) in certain timestamp that we process for a high demand of data from users, otherwise, we just scale down and use the basic option of CPU for optimize the price.     <br \/>\nAs I research, the microsoft azure portal has a function for Virtual Machine like that, but I dont know ML Studio has the same one as follow :    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/virtual-machine-scale-sets\/quick-create-portal\">https:\/\/learn.microsoft.com\/en-us\/azure\/virtual-machine-scale-sets\/quick-create-portal<\/a>    <\/p>\n<p>Thanks so much !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deployment stuck with deployment state as transitioning for over 2 hours",
        "Question_created_time":1663182438927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1007819\/azure-ml-real-time-inference-endpoint-deployment-s",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have an AKS cluster and am trying to deploy a real-time inference pipeline to it as an endpoint. The deployment state is switching between &quot;Transitioning&quot; and &quot;Failed&quot; and I am unable to see any logs. My cluster is in West Central US.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Set MLflow Tracking to only track in your Azure Machine Learning workspace",
        "Question_created_time":1656381127797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/905516\/set-mlflow-tracking-to-only-track-in-your-azure-ma",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>As per below link    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-azure-databricks?tabs=custom\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-azure-databricks?tabs=custom<\/a>    <\/p>\n<p>And section: Set MLflow Tracking to only track in your Azure Machine Learning workspace    <\/p>\n<p>We can set ML Flow Tracking URI to Azure ML in Databricks but i am getting below error upon setting and trying to create experiement    <\/p>\n<p>UnsupportedModelRegistryStoreURIException:  Model registry functionality is unavailable; got unsupported URI 'azureml:\/\/eastus.api.azureml.ms\/mlflow\/v1.0\/subscriptions\/60732f07-e07d-4492-b2cc-e43155932aca\/resourceGroups\/RG-BHOGA\/providers\/Microsoft.MachineLearningServices\/workspaces\/[REDACTED]' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage\">https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage<\/a> for how to run an MLflow server against one of the supported backend storage locations.    <\/p>\n<p>Could you please advise what has to be done?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure for students showing no usage despite using it",
        "Question_created_time":1662893566663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1002201\/azure-for-students-showing-no-usage-despite-using",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I've created an azure for students account wiht $100 free credit and started using Azure Notebooks to train some ML models. I've created a GPU instance which costs $1.20\/hr. I've been using it for at least 1.5h now and what's weird is that no usage is being shown on my dashboard, and on the sponsorship page it's showing that it is not active and that I haven't used any of my credit:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239817-image.png?platform=QnA\" alt=\"239817-image.png\" \/>    <\/p>\n<p>On the other hand when I go to my subscriptions it says it's active:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239809-image.png?platform=QnA\" alt=\"239809-image.png\" \/>    <\/p>\n<p>Is something wrong or does it take a while to see usage statistics\/credit spending?    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Question_closed_time":1662904704207,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi,    <\/p>\n<p>Usually it is every 4 hours the data\/cost is updated so check after sometime, you can check and download the data by using and following the steps over here - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/understand\/download-azure-daily-usage\">download-azure-daily-usage<\/a>    <\/p>\n<p>==    <br \/>\nPlease &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"BatchARMResponseError when creating environment in AzureML Studio",
        "Question_created_time":1662653924287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/999600\/batcharmresponseerror-when-creating-environment-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I cannot create a new environment through the AzureML studio GUI - each time I reach &quot;create&quot; I receive this error<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239155-azureml-error.png?platform=QnA\" alt=\"239155-azureml-error.png\" \/>. I previously was able to create environments and am not aware of any configuration changes since then. While the error initially says &quot;Service temporarily unavailable,&quot; it has been a week and is still not working.     <\/p>\n<p>Any suggestions?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround?",
        "Question_created_time":1662886746297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1002087\/azure-ml-creating-a-siamese-network-i-have-the-ref",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround? The setup looks like this. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239776-screenshot-2022-09-11-at-105820.png?platform=QnA\" alt=\"239776-screenshot-2022-09-11-at-105820.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML: I'm quite new to Azure ML, I created a CI\/CD pipeline for my pytorch basedmachine learning model using azure. But since my model takes more than 60mins to train, I'm unable to train my machine learning model using CI pipeline.",
        "Question_created_time":1662383691607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/994546\/azure-ml-im-quite-new-to-azure-ml-i-created-a-ci-c",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I'm trying to train my Pytorch based machine learning model via azure CI pipeline. But since it takes more than 60mins to train, the CI pipeline fails. How can I train such huge model using azure CI pipeline. Additionally, I would like to use the GPU based cluster but I'm unable to do so. I have tried many workflows but failed every time.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Submitting a job using the Azureml SDK gives an error \"Execution failed in operation 'to_pandas_dataframe' for Dataset",
        "Question_created_time":1636261062910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/617861\/submitting-a-job-using-the-azureml-sdk-gives-an-er",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am getting the above error and the runs are constantly failing. I have attached a screenshot of the code I am running. Script 180 runs fine if ran manually so I don't understand why when I run script 180 indirectly via script 170 it is throwing up an error about the to_pandas_dataframe() function. Everything is installed and I checked the version numbers so I need help understanding why it is failing.    <\/p>\n<p>Thanks    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/147092-error-msg.png?platform=QnA\" alt=\"147092-error-msg.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/146968-170.png?platform=QnA\" alt=\"146968-170.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/147093-180.png?platform=QnA\" alt=\"147093-180.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automated ML endpoint questions (performance, multiple return values, scoring)",
        "Question_created_time":1662590602493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/998394\/automated-ml-endpoint-questions-(performance-multi",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi....    <\/p>\n<p>I used Automated ML to train a model on a set of grouping ids and titles, very simple use case, just two columns...predict the group id from the title.  There were about 32000 rows in the input split into a training set of 90% and a validation set of 10%.  Best model was 'MaxAbsScaler, LogisticRegression'.    <\/p>\n<ol>\n<li> I deployed the endpoint using the 'realtimeendpoint' method.  But each request takes 10 seconds to return a response.  I took the default ML compute type VM which isn't a wimpy machine.  Is it normal to be so slow?  Will better hardware get the response time into the sub-one-second time-frame I need it to be?  Are there other options to improve performance?    <\/li>\n<li> I only ever get back one value in the response.  Is it possible to get multiple predicted values?    <\/li>\n<li> I don't see a 'confidence' score in the response, or see a way to request one.  Is that possible?    <\/li>\n<\/ol>\n<p>Thank you.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ml notebook does not show widgets from ipywidgets",
        "Question_created_time":1621085408217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/396317\/azure-ml-notebook-does-not-show-widgets-from-ipywi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>ipywidgets seems to work fine for the simplest usages, i.e. just using a slider. However, when trying to use more complex functionality the notebook does not show \/ display the widgets anymore.    <\/p>\n<p>See in the picture:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/96865-image.png?platform=QnA\" alt=\"96865-image.png\" \/>    <\/p>\n<p>The simple usage    <\/p>\n<pre><code>widgets.IntSlider()  \n<\/code><\/pre>\n<p>works fine.    <br \/>\nHowever, using ipywidget's interact does not show any widget:    <\/p>\n<pre><code>def f(x):  \n    return x  \n  \ninteract(f, x=10)  \n<\/code><\/pre>\n<p>When I change the editor using the dropdown    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/96817-image.png?platform=QnA\" alt=\"96817-image.png\" \/>    <\/p>\n<p>and use Jupyter or JupyterLab, everything works as expected without flaws.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating Components in Azure ml throws an error after update, how do I resolve it?",
        "Question_created_time":1661965347647,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989198\/creating-components-in-azure-ml-throws-an-error-af",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hey everyone,     <br \/>\nI was building components using YAML scripts and it worked pretty fine and everything was smooth as butter until I upgraded the az ml extension &amp; az ml cli extension.    <br \/>\nMostly, reading the error responses helps, but here I am not at all able to debug or trace down into the depth to discover the cause of the issue.    <\/p>\n<p>Below is the snippet of the version of extensions and the errors that are popping up:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236643-image.png?platform=QnA\" alt=\"236643-image.png\" \/>    <\/p>\n<p>For the sake of reference, below is the snippet of yaml file of the component    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236567-image.png?platform=QnA\" alt=\"236567-image.png\" \/>    <\/p>\n<p>Below is the snapshot of the conda file referenced in the above yaml file    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236615-image.png?platform=QnA\" alt=\"236615-image.png\" \/>    <\/p>\n<p>And below is the python script that executes for the corresponding component    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236662-image.png?platform=QnA\" alt=\"236662-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"updating\/upgrading of Azure ML VM Operating System?",
        "Question_created_time":1662553688820,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/997469\/updating-upgrading-of-azure-ml-vm-operating-system",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Currently in my Azure ML portal the OS version is    <\/p>\n<p>NAME=&quot;Ubuntu&quot;    <br \/>\nVERSION=&quot;20.04.4 LTS (Focal Fossa)&quot;    <\/p>\n<p>I need to update os version to Ubuntu 22.04 LTS    <\/p>\n<p>In azure, user can updating os version manually? or it is by default upgrading from Microsoft Azure?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is the different components not grouped in the designer any more?",
        "Question_created_time":1661248060107,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/978187\/why-is-the-different-components-not-grouped-in-the",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, Guys,    <br \/>\nI'm new to Azure Ml, and when i started using the Designer, the different components where grouped.     <br \/>\nWhen you chose for example &quot;model scoring and evaluation&quot;, and then all components related to that topic was there.     <br \/>\nNow it's like all components available is just listed in alphabetic order.    <br \/>\nWhat is the point with that change? and can i get the grouped components back?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Kubernetes \/ AKS cluster requirments for Azure ML Endpoints",
        "Question_created_time":1660720523597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/970235\/kubernetes-aks-cluster-requirments-for-azure-ml-en",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm trying to experiment with <strong>Azure ML Endpoints<\/strong> deployed to a <strong>Azure Kubernetes Service<\/strong> (AKS) cluster.    <\/p>\n<p>Right now I'm able to attach <strong>AKS cluster<\/strong>(s) to <strong>Azure ML<\/strong>, from <strong>Compute \/ Inference Clusters<\/strong>.    <\/p>\n<p>However, the no Kubernetes clusters are showing up nor in <strong>Endpoint Deployments<\/strong>, neither in the <strong>Attached Computes<\/strong> <em>(see the screenshots bellow)<\/em>.    <\/p>\n<p>I would like to now if there are any special requirements \/ additional steps needed for <strong>AKS cluster<\/strong> used with <strong>Azure ML endpoints<\/strong>. The AKS cluster I'm using is <strong>3 nodes<\/strong>, each with <strong>4 vCPU<\/strong> and <strong>16 GB RAM<\/strong>.    <\/p>\n<p><strong>Endpoint<\/strong>(s):    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/231885-image.png?platform=QnA\" alt=\"231885-image.png\" \/>    <\/p>\n<p><strong>Attached Compute<\/strong>(s):    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/231951-image.png?platform=QnA\" alt=\"231951-image.png\" \/>    <\/p>\n<p>Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"SDK v1 or V2",
        "Question_created_time":1661977244390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989368\/sdk-v1-or-v2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We are planing for next gen of product. Will V2 provide way more changes than V1? <\/p>",
        "Question_closed_time":1661981560817,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=7f2ff54e-2fc4-4d74-b946-fc6ec46d4863\">@nam  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A. I will recommend you keeping in V1 at this moment.     <\/p>\n<p>SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.    <\/p>\n<p><a href=\"https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\">https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is Azure supporting distributed GPU?",
        "Question_created_time":1661977194510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989398\/is-azure-supporting-distributed-gpu",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Is there any plan? Any date we can expect?<\/p>",
        "Question_closed_time":1662345271897,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=7f2ff54e-2fc4-4d74-b946-fc6ec46d4863\">@nam  <\/a>     <\/p>\n<p>I hope yo are doing well. We have multiple options for Distributed GPU for Azure Machine Learnig for SDK v1 as below -     <br \/>\n<strong>Message Passing Interface (MPI)<\/strong>    <br \/>\nHorovod    <br \/>\nDeepSpeed    <br \/>\nEnvironment variables from Open MPI    <br \/>\n<strong>PyTorch<\/strong>    <br \/>\nProcess group initialization    <br \/>\nLaunch options    <br \/>\nDistributedDataParallel (per-process-launch)    <br \/>\nUsing torch.distributed.launch (per-node-launch)    <br \/>\nPyTorch Lightning    <br \/>\nHugging Face Transformers    <br \/>\n<strong>TensorFlow<\/strong>    <br \/>\nEnvironment variables for TensorFlow (TF_CONFIG)    <br \/>\n<strong>Accelerate GPU training with InfiniBand<\/strong>    <\/p>\n<p>For V2 there should be big change. Please feel free to let us know any problems. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"YOLO v5 in azure",
        "Question_created_time":1661985450753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989581\/yolo-v5-in-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, does Azure Machine Learning support YOLOv5? How we can import it? <\/p>",
        "Question_closed_time":1662053252523,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6ec12307-1a06-4236-b249-3fd890a3f2a1\">@matsuoka  <\/a>     <\/p>\n<p>More info about YOLO v5 could be found here - <a href=\"https:\/\/github.com\/ultralytics\/yolov5\">https:\/\/github.com\/ultralytics\/yolov5<\/a>    <\/p>\n<p>Microsoft currently has no official docs about YOLO v5 but you can surely use it in Azure environment as guidance above. I will reach out to product team to see how we can leverage YOLO v5 more but please let us know if you have more question during the time you working on your project.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"DataDrift in AzureML",
        "Question_created_time":1659816958003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/957739\/datadrift-in-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, What is the underlying algorithm for azureml DataDriftDetector class? and what is the mathematical implication of the threshold in datadrift?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"web site journalism reports",
        "Question_created_time":1662165549230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/992515\/web-site-journalism-reports",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>how i cant build a website to use it in creat journalism reports by artifical intelegence <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot create new compute instance",
        "Question_created_time":1662003553540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989732\/cannot-create-new-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to create my first compute instance using Azure Machine Learning Studio, but it fails every time with little to no details.    <\/p>\n<p>Here are the parameters I use to create a new instance:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236670-screen-shot-2022-08-31-at-112907-pm.png?platform=QnA\" alt=\"236670-screen-shot-2022-08-31-at-112907-pm.png\" \/>    <\/p>\n<p>This is what the instance looks like during creation:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236772-screen-shot-2022-08-31-at-113131-pm.png?platform=QnA\" alt=\"236772-screen-shot-2022-08-31-at-113131-pm.png\" \/>    <br \/>\nAs well as additional attributes    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236733-screen-shot-2022-08-31-at-113158-pm.png?platform=QnA\" alt=\"236733-screen-shot-2022-08-31-at-113158-pm.png\" \/>    <\/p>\n<p>It runs like that for an hour or so, and then fails.    <br \/>\nThis is what the instance looks like after an error:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236715-screen-shot-2022-08-31-at-113457-pm.png?platform=QnA\" alt=\"236715-screen-shot-2022-08-31-at-113457-pm.png\" \/>    <\/p>\n<p>I can also see another error message in the logs:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236700-screen-shot-2022-08-31-at-113545-pm.png?platform=QnA\" alt=\"236700-screen-shot-2022-08-31-at-113545-pm.png\" \/>    <\/p>\n<p>Can I please get some help to create new compute instance. Everything looks pretty straight forward, I would definitely expect to have no errors there.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to get all the machine learning algorigthms tried by azure automl for a machine learning job in python sdk?",
        "Question_created_time":1662345469883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/993641\/is-there-a-way-to-get-all-the-machine-learning-alg",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying azure automl through python sdk. What I need is to get all the algorithm names along with the best algorithm azure tried for that particular job using python sdk.    <br \/>\nI have been exploring documentation but didn't get much. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Question_created_time":1662205880130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/992629\/certification-test-for-ai-900-microsoft-azure-ai-f",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.     <br \/>\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?<\/p>",
        "Question_closed_time":1662210933980,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi Jurian,    <\/p>\n<p>This is available in PearsonVue check this.  <a href=\"https:\/\/learn.microsoft.com\/en-us\/certifications\/exams\/ai-900\">ai-900<\/a>    <\/p>\n<p>Any specific region you are trying from?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/237503-image.png?platform=QnA\" alt=\"237503-image.png\" \/>    <\/p>\n<p>==    <br \/>\nPlease &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Machine Learning migration",
        "Question_created_time":1647272307493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771467\/machine-learning-migration",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>now I would like to migrate the machine learning component from 'dev environment' to 'prd environment', may I know how I can do step by step\uff0c thanks\u3002  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Descriptors cannot not be created",
        "Question_created_time":1661977116463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989409\/descriptors-cannot-not-be-created",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>This error message is super confusing, what does it mean? <\/p>",
        "Question_closed_time":1661980770760,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6ec12307-1a06-4236-b249-3fd890a3f2a1\">@matsuoka  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. This problem is caused by breaking changes introduced in protobuf 4.0.0. For more information, see <a href=\"https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates\">https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates<\/a>.    <\/p>\n<p>Please refer to this troubleshooting guidance - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-protobuf-descriptor-error\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-protobuf-descriptor-error<\/a>    <\/p>\n<p>I hope it helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Endpoint-Deploy as Webservice Greyed out",
        "Question_created_time":1661970732707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989371\/azure-ml-endpoint-deploy-as-webservice-greyed-out",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236628-image.png?platform=QnA\" alt=\"236628-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Very slow execution time with NC6_Standart",
        "Question_created_time":1661975240997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989386\/very-slow-execution-time-with-nc6-standart",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,     <br \/>\nIn Azure ML, I created an NC6_Standart instance in order to have GPU. In order to familiarize myself with the cloud, I decide to run this (which is actually in a microsoft tutorial) <a href=\"https:\/\/github.com\/MicrosoftDocs\/tensorflowfundamentals\/blob\/main\/intro-keras\/kintro.py\">https:\/\/github.com\/MicrosoftDocs\/tensorflowfundamentals\/blob\/main\/intro-keras\/kintro.py<\/a> on my pc it takes about 2~3 minutes to do 100 epochs (with 2ms\/step), from the documentation sandbox about 3 minutes also with 2ms\/step but from the NC6 instance it takes 8 minutes BUT with 2ms\/step. In fact, it is the time between each epoch that is long. Would you have a solution? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Multiple Inputs to a Single Port while creating component.",
        "Question_created_time":1661875118607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/987589\/multiple-inputs-to-a-single-port-while-creating-co",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi there,    <br \/>\nI am creating custom components using yaml scripts containing my reusable code in python scripts.    <\/p>\n<p>I want to create one component with a single input port that could handle multiple inputs at a time, i.e take the outputs of multiple components within the single component.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236212-image.png?platform=QnA\" alt=\"236212-image.png\" \/>    <\/p>\n<p>for example in the image above, i want the final component to take in the output not only from 'Component Models - Random Forest Regression', but should also take output of 'Component Models - Arima' within the same input port of 'Component Aggregate'    <\/p>\n<p>The Yaml script for component Aggregate is below:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236232-image.png?platform=QnA\" alt=\"236232-image.png\" \/>    <\/p>\n<p>The python script for the same is below:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/236205-image.png?platform=QnA\" alt=\"236205-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML: In Batch Endpoints can we use a tuple(two file paths from different folders) as input?",
        "Question_created_time":1661847830690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/986878\/azureml-in-batch-endpoints-can-we-use-a-tuple(two",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm a novice to Azure and Azure ML, I'm trying to create a batch endpoint and in most of the documentation I found it was mentioned that the input to the batch endpoint would be a file path. In my case I was to connect the endpoint to two blobstorage and get a tuple as input to the batch endpoint. Is it possible? If not is there any other work around as my model takes as input path to two files.<\/p>",
        "Question_closed_time":1661915045907,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d2cc8057-ef7d-498e-944d-421a8e30bd64\">@Samarjeet Singh Patil  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform! I am sorry you can not use multiple resource as one input for one job, but you can do it in separate jobs.    <\/p>\n<p>An alternative way\/ workaround for you is a FileDataset, you can put your resource into one dataset and then input it.     <\/p>\n<p>FileDataset -     <br \/>\n<em>Represents a collection of file references in datastores or public URLs to use in Azure Machine Learning.    <br \/>\nA FileDataset defines a series of lazily-evaluated, immutable operations to load data from the data source into file streams. Data is not loaded from the source until FileDataset is asked to deliver data.    <br \/>\nA FileDataset is created using the from_files method of the FileDatasetFactory class.    <br \/>\nFor more information, see the article Add &amp; register datasets. To get started working with a file dataset, see <a href=\"https:\/\/aka.ms\/filedataset-samplenotebook.\">https:\/\/aka.ms\/filedataset-samplenotebook.<\/a><\/em>    <\/p>\n<p>Reference - <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.filedataset?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.filedataset?view=azure-ml-py<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoints-studio#start-a-batch-scoring-job-with-different-input-options\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoints-studio#start-a-batch-scoring-job-with-different-input-options<\/a>     <\/p>\n<p>I hope it helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Mounting the dataset in ML Workspace",
        "Question_created_time":1661408727513,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981126\/mounting-the-dataset-in-ml-workspace",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How to mount the dataset in ML Studio using python sdk ?    <br \/>\nWhat are the different ways and which is the right one ?    <\/p>\n<p>Can we create dataset pointing to two different stores ?    <\/p>\n<p>Also where can I learn more about azure machine learning ?<\/p>",
        "Question_closed_time":1661469512520,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=b2d28b4e-27a0-4d31-9f64-5723bfe88382\">@V JEEVA  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. Let me answer your questions one by one.    <\/p>\n<p><em>where can I learn more about azure machine learning<\/em>    <br \/>\nThe best way to learn Azure Machine Learning is the documentation, please refer to - <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/#documentation\">https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/#documentation<\/a>    <\/p>\n<p><em>How to mount the dataset in ML Studio using python sdk ?<\/em>    <br \/>\nGenerally there are two ways to work with data in Azure Machine Learning -    <br \/>\nUse datastores - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access<\/a>    <br \/>\nUse data assets - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access<\/a>    <\/p>\n<p><em>What are the different ways and which is the right one ?<\/em>    <br \/>\nIt depends on your need. Compared to data assets and datastore, the benefits of creating data assets are:    <br \/>\nYou can share and reuse data with other members of the team such that they do not need to remember file locations.    <br \/>\nYou can seamlessly access data during model training (on any supported compute type) without worrying about connection strings or data paths.    <br \/>\nYou can version the data.    <\/p>\n<p><em>Can we create dataset pointing to two different stores ?<\/em>    <br \/>\nIf you need to assembly data, you may want to consider data assets. By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and don't risk the integrity of your data sources. You can create Data from datastores, Azure Storage, public URLs, and local files.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Time series training for anomal detect",
        "Question_created_time":1661358044013,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/980372\/time-series-training-for-anomal-detect",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have not seen any doc talking about this topic, is this supported in Microsoft Machine Learning? Is this a good plan if anyone has tried? <\/p>",
        "Question_closed_time":1661379528520,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=033f3419-75e1-402b-b1ac-8869dd655829\">@minhoo lee  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform, Azure Machine Learning Serivce support time series training - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast<\/a>    <\/p>\n<p>You can check above document to see how to set up a quick model.    <\/p>\n<p>But for Anomaly Dectection, I think Anomaly Detector API is a better choice for you - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/anomaly-detector\/\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/anomaly-detector\/<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Two Class Decision Forest - Evaluate Results with Own Test Dataset?",
        "Question_created_time":1659565398167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/954252\/two-class-decision-forest-evaluate-results-with-ow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi - can you train the Azure Two Class Decision Tree forest with a training data set you upload, then test it with a different data set that you upload rather than letting Azure do the random splitting into train and test?    <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Models registered with AML CLI cause ACI deployments to fail",
        "Question_created_time":1634746520717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/597710\/models-registered-with-aml-cli-cause-aci-deploymen",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>We were registering a local file <code>ts_scalar.pickle<\/code> as a model using AML CLI's <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/model?view=azure-cli-latest#az_ml_model_create\">create<\/a> <code>az model create -n test-model -l .\/ts_scalar.pickle ...<\/code>    <br \/>\nThis registered model <code>test-model<\/code> works fine when deployed to a  <code>LocalWebService<\/code>, but does not work for a <code>AciWebService<\/code>.    <br \/>\nWe either get a timeout during the deployment (does not reach stage where containers start running) or this error:    <\/p>\n<pre><code>Traceback (most recent call last):  \n  File &quot;.\/download.py&quot;, line 353, in &lt;module&gt;  \n    init_container_assets(args.config_json, args.conn_string, args.container, args.appinsights_key, args.config_folder)  \n  File &quot;.\/download.py&quot;, line 327, in init_container_assets  \n    downloader.download(config_file_content)  \n  File &quot;.\/download.py&quot;, line 128, in download  \n    self.download_artifact(blob_path, local_path, unpack_type)  \n  File &quot;.\/download.py&quot;, line 92, in download_artifact  \n    file_path=local_path)  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py&quot;, line 2014, in get_blob_to_path  \n    cpk=cpk)  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py&quot;, line 2193, in get_blob_to_stream  \n    raise ex  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py&quot;, line 2160, in get_blob_to_stream  \n    cpk=cpk)  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py&quot;, line 1887, in _get_blob  \n    operation_context=_context)  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py&quot;, line 446, in _perform_request  \n    raise ex  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py&quot;, line 374, in _perform_request  \n    raise ex  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py&quot;, line 360, in _perform_request  \n    HTTPError(response.status, response.message, response.headers, response.body))  \n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/_error.py&quot;, line 115, in _http_error_handler  \n    raise ex  \nazure.common.AzureMissingResourceHttpError: The specified blob does not exist. ErrorCode: BlobNotFound  \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;BlobNotFound&lt;\/Code&gt;&lt;Message&gt;The specified blob does not exist.  \nRequestId:59b52a82-301e-005a-51c8-c52ce4000000  \nTime:2021-10-20T15:40:04.2703282Z&lt;\/Message&gt;&lt;\/Error&gt;  \n<\/code><\/pre>\n<p>However if we register the model through AML's UI model registration, both kinds of deployments are successful.    <\/p>\n<p>Is there an issue with using the CLI to register models for ACI deployment?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azureml-core 1.44.0 fails to deploy model to webservice",
        "Question_created_time":1661413994937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981325\/azureml-core-1-44-0-fails-to-deploy-model-to-webse",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<ul>\n<li> azureml-core     <\/li>\n<li> 1.44.0    <\/li>\n<li> conda virtualenv (compute instance):     <\/li>\n<li>  Azure Machine Learning    <\/li>\n<li> ML    <\/li>\n<\/ul>\n<p><strong>Describe the bug<\/strong><\/p>\n<p>Model fails to deploy when I run the deployment code in Azure Notebook using virtualenv with azureml-core 1.44.0    <\/p>\n<p>It works just fine with older version (1.43.0) or the default Python 3.8 - Azure ML that uses 1.42.0 at the moment.    <\/p>\n<p>The output:    <\/p>\n<pre><code>   Running  \n   2022-08-25 07:03:20+00:00 Creating Container Registry if not exists.  \n   2022-08-25 07:03:20+00:00 Registering the environment.  \n   2022-08-25 07:03:21+00:00 Use the existing image.  \n   2022-08-25 07:03:22+00:00 Generating deployment configuration.  \n   2022-08-25 07:03:23+00:00 Submitting deployment to compute.  \n   2022-08-25 07:03:30+00:00 Checking the status of deployment heart-disease-classification-env..  \n   2022-08-25 07:05:44+00:00 Checking the status of inference endpoint heart-disease-classification-env.  \n   Failed  \n   Service deployment polling reached non-successful terminal state, current service state: Failed  \n   Operation ID: 3a980ad2-890e-4e8a-91d6-c119bd0528a4  \n   More information can be found using '.get_logs()'  \n   Error:  \n   {  \n     &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n     &quot;statusCode&quot;: 400,  \n     &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n   \t1. Please check the logs for your container instance: heart-disease-classification-env. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n   \t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n   \t3. You can also try to run image 237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,  \n     &quot;details&quot;: [  \n       {  \n         &quot;code&quot;: &quot;CrashLoopBackOff&quot;,  \n         &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.  \n   \t1. Please check the logs for your container instance: heart-disease-classification-env. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.  \n   \t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n   \t3. You can also try to run image 237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;  \n       },  \n       {  \n         &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n         &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:  \n   \t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.  \n   \t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.  \n   \t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.  \n   \t4. View the diagnostic events to check status of container, it may help you to debug the issue.  \n   &quot;RestartCount&quot;: 3  \n   &quot;CurrentState&quot;: {&quot;state&quot;:&quot;Waiting&quot;,&quot;startTime&quot;:null,&quot;exitCode&quot;:null,&quot;finishTime&quot;:null,&quot;detailStatus&quot;:&quot;CrashLoopBackOff: Back-off restarting failed&quot;}  \n   &quot;PreviousState&quot;: {&quot;state&quot;:&quot;Terminated&quot;,&quot;startTime&quot;:&quot;2022-08-25T07:07:34.619Z&quot;,&quot;exitCode&quot;:111,&quot;finishTime&quot;:&quot;2022-08-25T07:07:48.858Z&quot;,&quot;detailStatus&quot;:&quot;Error&quot;}  \n   &quot;Events&quot;:  \n   {&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-08-25T07:03:36Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-08-25T07:03:36Z&quot;,&quot;name&quot;:&quot;Pulling&quot;,&quot;message&quot;:&quot;pulling image &quot;237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a@sha256:7650a3f19eb4803881637a920dc3e9bf9837c0e9c492b7d22be840d0ba8cb1cf&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n   {&quot;count&quot;:1,&quot;firstTimestamp&quot;:&quot;2022-08-25T07:05:15Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-08-25T07:05:15Z&quot;,&quot;name&quot;:&quot;Pulled&quot;,&quot;message&quot;:&quot;Successfully pulled image &quot;237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a@sha256:7650a3f19eb4803881637a920dc3e9bf9837c0e9c492b7d22be840d0ba8cb1cf&quot;&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n   {&quot;count&quot;:4,&quot;firstTimestamp&quot;:&quot;2022-08-25T07:05:37Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-08-25T07:07:34Z&quot;,&quot;name&quot;:&quot;Started&quot;,&quot;message&quot;:&quot;Started container&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n   {&quot;count&quot;:4,&quot;firstTimestamp&quot;:&quot;2022-08-25T07:05:54Z&quot;,&quot;lastTimestamp&quot;:&quot;2022-08-25T07:07:48Z&quot;,&quot;name&quot;:&quot;Killing&quot;,&quot;message&quot;:&quot;Killing container with id 54971cd5cf0e6de46f30bd592bea94752d4ad857fb32f6d85e33b3a8bd4e4c92.&quot;,&quot;type&quot;:&quot;Normal&quot;}  \n   &quot;  \n       }  \n     ]  \n   }  \n<\/code><\/pre>\n<p><strong>To Reproduce<\/strong><\/p>\n<p>Steps to reproduce the behavior:    <\/p>\n<ol>\n<li> I use the standard heart-diseaase dataset, train the model and export it to model\/hd_otr.pkl    <\/li>\n<li> In assets folder I store the outlierremover.py script that I use to remove outliers:    \n<pre><code>import pandas as pd  \nfrom sklearn.base import BaseEstimator, TransformerMixin  \n\nclass OutlierRemover(BaseEstimator, TransformerMixin):  \n    def __init__(self, factor=1.5):  \n        self.factor = factor  \n\n    def outlier_detector(self, X, y=None):  \n        X = pd.Series(X).copy()  \n        q1 = X.quantile(0.25)  \n        q3 = X.quantile(0.75)  \n        iqr = q3 - q1  \n        self.lower_bound.append(q1 - (self.factor * iqr))  \n        self.upper_bound.append(q3 + (self.factor * iqr))  \n\n    def fit(self,X,y=None):  \n        self.lower_bound = []  \n        self.upper_bound = []  \n        X.apply(self.outlier_detector)  \n        return self  \n\n    def transform(self, X, y=None):  \n        X = pd.DataFrame(X).copy()  \n        for i in range(X.shape[1]):  \n            x = X.iloc[:, i].copy()  \n            x[(x &lt; self.lower_bound[i])] = self.lower_bound[i]  \n            x[(x &gt; self.upper_bound[i])] = self.upper_bound[i]  \n            X.iloc[:, i] = x  \n        return X  \n\noutlier_remover = OutlierRemover()  \n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>and score.py file:    <\/p>\n<pre><code>   import joblib  \n   from azureml.core.model import Model  \n   import json  \n   import pandas as pd  \n   import numpy as np  \n   from outlierremover import OutlierRemover  \n     \n   from inference_schema.schema_decorators import input_schema, output_schema  \n   from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType  \n   from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType  \n   from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType  \n     \n   def init():  \n       global model  \n       # Example when the model is a file  \n       model_path = Model.get_model_path('hd_otr') # logistic  \n       print('Model Path is  ', model_path)  \n       model = joblib.load(model_path)  \n         \n   data_sample = PandasParameterType(pd.DataFrame({'age': pd.Series([71], dtype='int64'),  \n                                                   'sex': pd.Series(['0'], dtype='object'),  \n                                                   'cp': pd.Series(['0'], dtype='object'),  \n                                                   'trestbps': pd.Series([112], dtype='int64'),  \n                                                   'chol': pd.Series([203], dtype='int64'),  \n                                                   'fbs': pd.Series(['0'], dtype='object'),  \n                                                   'restecg': pd.Series(['1'], dtype='object'),  \n                                                   'thalach': pd.Series([185], dtype='int64'),  \n                                                   'exang': pd.Series(['0'], dtype='object'),  \n                                                   'oldpeak': pd.Series([0.1], dtype='float64'),  \n                                                   'slope': pd.Series(['2'], dtype='object'),  \n                                                   'ca': pd.Series(['0'], dtype='object'),  \n                                                   'thal': pd.Series(['2'], dtype='object')}))  \n     \n   input_sample = StandardPythonParameterType({'data': data_sample})  \n   result_sample = NumpyParameterType(np.array([0]))  \n   output_sample = StandardPythonParameterType({'Results': result_sample})  \n     \n   @input_schema('Inputs', input_sample)  \n   @output_schema(output_sample)  \n   def run(Inputs):  \n       try:  \n           data = Inputs['data']  \n           #result = model.predict_proba(data)  \n           result = np.round(model.predict_proba(data)[0][0], 2)  \n           return result.tolist()  \n       except Exception as e:  \n           error = str(e)  \n           return error  \n<\/code><\/pre>\n<ol start=\"3\">\n<li> In the deployment.ipynb notebook the code is as follows:    \n<pre><code>from azureml.core import Workspace  \nfrom azureml.core.webservice import AciWebservice  \nfrom azureml.core.webservice import Webservice  \nfrom azureml.core.model import InferenceConfig  \nfrom azureml.core.environment import Environment  \nfrom azureml.core import Workspace  \nfrom azureml.core.model import Model  \nfrom azureml.core.conda_dependencies import CondaDependencies  \n\nws = Workspace.from_config()  \n\nmodel = Model.register(workspace = ws,  \n              model_path ='model\/hd_otr.pkl',  \n              model_name = 'hd_otr',  \n              tags = {'version': '1'},  \n              description = 'Heart disease classification with outliers detection',  \n              )  \n\n# to install required packages  \nenv = Environment('env')  \ncd = CondaDependencies.create(pip_packages=['pandas', 'azureml-defaults', 'joblib', 'inference-schema', 'imbalanced-learn'], conda_packages = ['scikit-learn'])  \nenv.python.conda_dependencies = cd  \n\n# register environment to re-use later  \nenv.register(workspace = ws)  \n\nmyenv = Environment.get(workspace=ws, name='env')  \n\nmyenv.save_to_directory('.\/environ', overwrite=True)  \n\naciconfig = AciWebservice.deploy_configuration(  \n            cpu_cores=1,  \n            memory_gb=1,  \n            tags={'data':'heart disease classifier'},  \n            description='Classification of heart diseases'  \n            )  \n\ninference_config = InferenceConfig(entry_script='score.py', environment=myenv, source_directory='.\/assets')  \n\nservice = Model.deploy(workspace=ws,  \n                name='heart-disease-classification-env',  \n                models=[model],  \n                inference_config=inference_config,  \n                deployment_config=aciconfig,   \n                overwrite=True)  \n\nservice.wait_for_deployment(show_output=True)  \nurl = service.scoring_uri  \nprint(url)  \n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>...which gives the error from 1. with 1.44.0 but works just fine with the older versions.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"a request to change the personal account (MSA) associated with my Certification profile",
        "Question_created_time":1661434194677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981835\/a-request-to-change-the-personal-account-(msa)-ass",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to connect my MSA with my certification profile.    <\/p>\n<p>My MSA is julia.loef<a href=\"\/users\/na\/?userid=ff0fe430-0000-0006-0000-000000000000\">@Karima ben  <\/a>.com and my work account is julia.loef-bleiksch@nl.abnamro.com    <\/p>\n<p>Can you please help me with this?<\/p>",
        "Question_closed_time":1661435443443,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=75eb21e6-d923-4b38-8134-7fa8e68a193a\">@Julia Loef-Bleiksch  <\/a>     <\/p>\n<p>Please post this on Microsoft Certifications forum found at <a href=\"https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\">https:\/\/trainingsupport.microsoft.com\/en-us\/mcp<\/a> and someone will gladly assist.    <\/p>\n<p>Unfortunately MS Certifications is not supported on this forum.    <\/p>\n<p>If this was helpful please accept answer.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Model in Failed State when deploying as Web Service",
        "Question_created_time":1661369796427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/980558\/azure-ml-model-in-failed-state-when-deploying-as-w",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234619-image.png?platform=QnA\" alt=\"![234620-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234619-image.png?platform=QnA\">1<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What's the next step after creating a pipeline?",
        "Question_created_time":1661266129010,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/978610\/whats-the-next-step-after-creating-a-pipeline",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, the UI is very confused, not straightforward as Studio. Can you guide me to the next step to use the pipeline?     <\/p>",
        "Question_closed_time":1661278037917,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a1c46131-fcca-467d-9bfb-d1c7cdf021ad\">@Nichole\u2019s  <\/a>     <\/p>\n<p>Thanks for using Microsft Q&amp;A platform. I think you are on the stage of designing your pipeline and running it.     <\/p>\n<p>The next step should be submit your pipeline and evaluate your model - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score#submit-the-pipeline\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score#submit-the-pipeline<\/a>    <\/p>\n<p>When you feel good with your model, you can then deploy your pipeline as this guidance - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy<\/a>    <\/p>\n<p>You may then want to test and update your endpoint as above guidance.     <\/p>\n<p>Each time you run a pipeline, the configuration of the pipeline and its results are stored in your workspace as a pipeline job. You can go back to any pipeline job to inspect it for troubleshooting or auditing. Clone a pipeline job to create a new pipeline draft for you to edit.    <\/p>\n<p>Pipeline jobs are grouped into experiments to organize job history. You can set the experiment for every pipeline job.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Receiving error while submitting the pipeline run",
        "Question_created_time":1661308367600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/979208\/receiving-error-while-submitting-the-pipeline-run",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to train Model in the AML Designer and on the Train Model component, I am receiving the following error when submitting it for a pipeline run\u2026    <\/p>\n<p>AmlExceptionMessage:AzureMLCompute job failed.    <br \/>\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.    <\/p>\n<p>ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: &quot;MessageID&quot; is greater than allowed.    <\/p>",
        "Question_closed_time":1661311380710,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. Here is the troubleshooting <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/designer-error-codes#error-0014\">document<\/a> for this issue.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"'Execution Python Script' version change",
        "Question_created_time":1661190354030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/977128\/execution-python-script-version-change",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello all,    <\/p>\n<p>I coded some ML models using darts library on local desktop.    <br \/>\nI am trying to build the pipeline in Azure ML Studio, using the in-built component 'Execute Python Script' in the designer tab.    <\/p>\n<p>What I am doing is, compressing the '.py' files of my code on local desktop into a zip file, and passing it into the 'Script bundle' argument of 'Execute Python Script' component of Azure ML, so that the code programmed on the local desktop could be reused in that component of pipeline.    <\/p>\n<p>What the issue is, the python version of 'Execute Python Script' component shows up as 3.6.8 and the darts library is suitable for python versions 3.8 and above. This version gap does not let the pipeline execute successfully and ends up throwing the following error:    <\/p>\n<p>azureml.studio.common.error.FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:    <\/p>\n<p>----------    <br \/>\n Start of error message from Python interpreter ----------    <br \/>\nGot exception when invoking script at line 38 in function azureml_main: 'ImportError: cannot import name 'parse_version''.    <\/p>\n<p>----------    <br \/>\n End of error message from Python  interpreter  ----------    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Realtime endpoint deploy 'xxx' stayed in progress",
        "Question_created_time":1661074944827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/975300\/realtime-endpoint-deploy-xxx-stayed-in-progress",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I'm trying to deploy my real time inference, but after a while not happened to it. I didn't got any error or message and nothing happens. (See the following picture).<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/233224-screenshot-2022-08-21-112604.png?platform=QnA\" alt=\"233224-screenshot-2022-08-21-112604.png\" \/><\/p>\n<p>What I did:<\/p>\n<ol>\n<li>  I created a pipeline in designer, it's valid and be submitted very well.<\/li>\n<li>  After submit is complete, I created a &quot;Real-time inference pipeline&quot; via button in menu!    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/233213-screenshot-2022-08-21-113258.png?platform=QnA\" alt=\"233213-screenshot-2022-08-21-113258.png\" \/><\/li>\n<li>  And finally I tried to deploy it, but nothing happened. (For deploy I tried both of Azure Kubernetes Service and Azure Container Instance)    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/233159-screenshot-2022-08-21-114551.png?platform=QnA\" alt=\"233159-screenshot-2022-08-21-114551.png\" \/><\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_created_time":1661155798650,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/976098\/issue-with-data-lake-mounting-in-custom-rstudio-ap",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<ol>\n<li>  previously while creating a compute instance we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234344-screenshot-2022-08-23-170502.png?platform=QnA\" alt=\"compute creation\" \/><\/li>\n<\/ol>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234353-5.png?platform=QnA\" alt=\"Data lake mont\" \/>  <br \/>\n2. In current situation we are not able to access RStudio application by default.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234345-4.png?platform=QnA\" alt=\"234345-4.png\" \/>  <br \/>\n3.with the help of below link we are able to create custom RStudio application<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a>  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234314-2.png?platform=QnA\" alt=\"custom RStudio app\" \/><\/p>\n<p>4.In custom RStudio we are not able to mount\/access the data lake.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234361-3.png?platform=QnA\" alt=\"missing data lake\" \/><\/p>\n<p>Is there way to mount\/access the data lake in custom RStudio app<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML BFSMountError: Unable to mount blob fuse file system",
        "Question_created_time":1660200527397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/963683\/azure-ml-bfsmounterror-unable-to-mount-blob-fuse-f",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Training yolov5 using Azure ML SDK and encountered error below. I have a gpu cluster created (no vnet) and encountered this error when i ScriptRunConfig and experiment.submit.  My Azure ML Storage account is enabled from all network (no vnet). Thank you very much    <\/p>\n<p>src = ScriptRunConfig(.......)    <br \/>\nrun = experiment.submit(src)    <\/p>\n<p>AzureMLCompute job failed.    <br \/>\nBFSMountError: Unable to mount blob fuse file system    <br \/>\n\tInfo: Could not mount Azure Blob Container azureml-blobstore-xxxxxxxx at workspaceblobstore: &lt;nil&gt;. Unable to start blobfuse due to a lack of credentials. Please check the readme for valid auth setups.  <br \/>\nUnmounting blobfuse.    <br \/>\nUnmounted blobfuse successfully.    <\/p>\n<pre><code>Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.   \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Python SDK - Create Workspace with existing resources",
        "Question_created_time":1661014342310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/975103\/azure-machine-learning-python-sdk-create-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>This article shows you how to create a workspace with the Python SDK     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#create-a-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#create-a-workspace<\/a>     <\/p>\n<p>For some reason the existing resources are added to the ServicePrincipalAuthentication, but I think this is a mistake and should be added to the Workspace.Create function.     <br \/>\nBut when I try to add the existing Azure resource IDs to the Create function I get a non descriptive error. Can someone show a working example of how to create a workspace (including a new resource group) programmatically with existing resources (in another resource group), like a Key Vault, Azure Container Registry and Storage Account?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Change in Machine Learning Designer",
        "Question_created_time":1660839023247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/972775\/change-in-machine-learning-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I can\u2019t find some of the basic modules from this week. Any significant change about Designer? <\/p>",
        "Question_closed_time":1660841903857,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=2ce87912-8dda-483a-8ead-0e2912a6e6ef\">@Mofoch  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform, there is no surprising change in Azure Machine Learning Designer.    <\/p>\n<p>Based on my experience, you may use the filter so you can not see some of the modules as below screenshot.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/232490-image.png?platform=QnA\" alt=\"232490-image.png\" \/>    <\/p>\n<p>If this is not your case, could you please share which module you have lost? Thanks.     <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning profiling model errors",
        "Question_created_time":1660748272003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/970964\/azure-machine-learning-profiling-model-errors",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>After successfully completing the image-classification-mnist-data tutorial in Azure Machine Learning Samples    <\/p>\n<blockquote>\n<p>Samples\/1.43.0\/tutorials\/image-classification-mnist-data\/img-classification-part1-training.ipynb    <\/p>\n<\/blockquote>\n<p> I would like to profile the resulting model as shown in this article <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-deploy-profile-model?pivots=py-sdk\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-deploy-profile-model?pivots=py-sdk<\/a>     <\/p>\n<p>However I keep getting an error saying <code>Running.....................................     Failed     \/tmp\/ipykernel_56534\/2365332213.py:15: UserWarning: Model Profiling operation failed with the following error: Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed. Request ID: b5384f0f-8a3a-4f53-908e-0a028374b924. Inspect ModelProfile.error property for more information.       profile.wait_for_completion(True)     {'name': 'sklearn-08172022-143854',      'createdTime': '2022-08-17T14:38:56.706085+00:00',      'state': 'Failed',      'requestedCpu': 3.5,      'requestedMemoryInGB': 15.0,      'requestedQueriesPerSecond': 0,      'error': {'code': 'ModelTestBackendCrashLoopBackoff',       'statusCode': 400,       'message': &quot;Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed.&quot;,       'details': []}}<\/code>    <\/p>\n<p>I only have 1 model in my workspace model list. So why am I getting an error and how can I see the error that is thrown inside the scoring file?    <\/p>\n<p><strong>scoring.py<\/strong>    <\/p>\n<pre><code>  %%writefile score.py  \n    import json  \n    import numpy as np  \n    import os  \n    import pickle  \n    import joblib  \n      \n    def init():  \n        global model  \n        # AZUREML_MODEL_DIR is an environment variable created during deployment.  \n        # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)  \n        # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)  \n        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_mnist_model.pkl')  \n        model = joblib.load(model_path)  \n      \n    def run(raw_data):  \n        data = np.array(json.loads(raw_data)['data'])  \n        # make prediction  \n        y_hat = model.predict(data)  \n        # you can return any data type as long as it is JSON-serializable  \n        return y_hat.tolist()  \n  \n<\/code><\/pre>\n<p><strong>profiling.py<\/strong>    <\/p>\n<pre><code>    import os  \n    from azureml.core import Dataset  \n    from azureml.opendatasets import MNIST  \n    from utils import load_data  \n    import os  \n    import glob  \n      \n      \n    data_folder = os.path.join(os.getcwd(), 'data')  \n    os.makedirs(data_folder, exist_ok=True)  \n      \n    mnist_file_dataset = MNIST.get_file_dataset()  \n    mnist_file_dataset.download(data_folder, overwrite=True)  \n      \n    data_folder = os.path.join(os.getcwd(), 'data')  \n    # note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster  \n    X_test = load_data(glob.glob(os.path.join(data_folder,&quot;**\/t10k-images-idx3-ubyte.gz&quot;), recursive=True)[0], False) \/ 255.0  \n    y_test = load_data(glob.glob(os.path.join(data_folder,&quot;**\/t10k-labels-idx1-ubyte.gz&quot;), recursive=True)[0], True).reshape(-1)  \n      \n      \n      \n      \n    import json  \n    from azureml.core import Datastore  \n    from azureml.core.dataset import Dataset  \n    from azureml.data import dataset_type_definitions  \n      \n    random_index = np.random.randint(0, len(X_test)-1)  \n    input_json = &quot;{\\&quot;data\\&quot;: [&quot; + str(list(X_test[random_index])) + &quot;]}&quot;  \n    # create a string that can be utf-8 encoded and  \n    # put in the body of the request  \n    serialized_input_json = json.dumps(input_json)  \n    dataset_content = []  \n    for i in range(100):  \n        dataset_content.append(serialized_input_json)  \n    dataset_content = '\\n'.join(dataset_content)  \n    file_name = 'sample_request_data.txt'  \n    f = open(file_name, 'w')  \n    f.write(dataset_content)  \n    f.close()  \n      \n    # upload the txt file created above to the Datastore and create a dataset from it  \n    data_store = Datastore.get_default(ws)  \n    data_store.upload_files(['.\/' + file_name], target_path='sample_request_data')  \n    datastore_path = [(data_store, 'sample_request_data' +'\/' + file_name)]  \n    sample_request_data = Dataset.Tabular.from_delimited_files(  \n        datastore_path, separator='\\n',  \n        infer_column_types=True,  \n        header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)  \n    sample_request_data = sample_request_data.register(workspace=ws,  \n                                                       name='sample_request_data',  \n                                                       create_new_version=True)  \n      \n      \n      \n    from azureml.core.model import InferenceConfig, Model  \n    from azureml.core.dataset import Dataset  \n    from datetime import datetime  \n      \n      \n    model = Model(ws, id='sklearn_mnist:1')  \n    inference_config = InferenceConfig(entry_script='score.py', environment=env)  \n    input_dataset = Dataset.get_by_name(workspace=ws, name='sample_request_data')  \n    profile = Model.profile(ws,  \n                'sklearn-%s' % datetime.now().strftime('%m%d%Y-%H%M%S'),  \n                [model],  \n                inference_config,  \n                input_dataset=input_dataset)  \n      \n    profile.wait_for_completion(True)  \n      \n    # see the result  \n    details = profile.get_details()  \n      \n  \n  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where should I begin with Machine Learning on Azure?",
        "Question_created_time":1660784016847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/971544\/where-should-i-begin-with-machine-learning-on-azur",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I have only been programming for about 6 months and I don't have any formal training.    <\/p>\n<p>I started on a platform called Ninjatrader8 building automated trading systems in C#5 on .NET 4.8    <\/p>\n<p>out of curiosity I have been experimenting with ML.NET in C# using my own machine but now I have started experimenting with Azure.    <\/p>\n<p>I have taken a peak at Python etc, and it seems easy to understand, I have also read a bit about Computer Science principles but there seems to be so much learning I can devout myself to now that I need to break it up into things that I will actually use, else I be stuck in a perpetual loop.    <\/p>\n<p>my goal is simply to have my strategy in the Ninjatrader platform be able to look up the most recent values output by an ML model.    <\/p>\n<p>I was going to have my model analyse a file any time a new file was added to a data set and then serialise the results in some way, perhaps by .csv file.    <\/p>\n<p>the file would need to allow for multiple simultaneous read iterations but only a single write iteration.    <\/p>\n<p>I feel like with azure I could probably have the strategy and model talking directly over the internet somehow, but it is not 100% necessary if it is to difficult     <\/p>\n<p>I am starting on the Microsoft online courses but they are also very broad and numerous.    <\/p>\n<p>Thankyou, Any help would be appreciated.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Train model with DockerFile and any other files needed to build the image",
        "Question_created_time":1660640861417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/968696\/azure-machine-learning-train-model-with-dockerfile",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am trying to train a model using azureml.core using my own custom Dockerfile. However my Dockerfile depends on a configuration file, so it needs to Copy this file when it is build.    <br \/>\nWhen I run my experiment I get an error saying it can't find my config.yml file while building the docker file. How do I add a file to my docker environment build context?    <\/p>\n<p>I have the following setup to build my environment     <\/p>\n<pre><code>from azureml.core import Workspace  \nfrom azureml.core import Experiment  \nfrom azureml.core.environment import Environment  \nimport os  \nimport shutil  \n  \nws = Workspace.from_config()  \nexp = Experiment(workspace=ws, name=&quot;tfrs-test-experiment&quot;)  \n  \nenv = Environment('tfrs-test-env')  \n  \nenv.docker.base_image = None  \nenv.docker.base_dockerfile = os.path.join('..', 'Dockerfile')  \n### NOT WORKING  \nshutil.copy(os.path.join('..', 'config.yml'), os.getcwd())  \n###  \n  \nenv.register(workspace = ws)  \n\n### CODE TO BUILD COMPUTE CLUSTER  \n ...  \n###  \nfrom azureml.core import ScriptRunConfig  \n  \nsrc = ScriptRunConfig(source_directory=os.path.join('..', 'src'),  \n                      script='tfrs-recsys.py',   \n                      compute_target=compute_target,  \n                      environment=env)  \n\n\n\nrun = exp.submit(config=src)  \nrun  \n  \nfrom azureml.widgets import RunDetails  \nRunDetails(run).show()  \n  \n# specify show_output to True for a verbose log  \nrun.wait_for_completion(show_output=True)   \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issue with Deploying a Model using Azure Machine Learning Service using notebook",
        "Question_created_time":1660651524797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/968888\/issue-with-deploying-a-model-using-azure-machine-l",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>---&gt; Running in 6d157abd883c  <br \/>\nRemoving intermediate container 6d157abd883c  <br \/>\n---&gt; f7ff072c2749  <br \/>\nStep 6\/10 : RUN mv '\/var\/azureml-app\/tmpiax4fwcd.py' \/var\/azureml-app\/main.py  <br \/>\n---&gt; Running in 28fb7f825815  <br \/>\nRemoving intermediate container 28fb7f825815  <br \/>\n---&gt; a475f38ff1ed  <br \/>\nStep 7\/10 : RUN sed -i '\/^\\s*-\\s<em>python\\s<\/em>[&lt;&gt;=]\/d' '\/var\/azureml-app\/conda_env.yml' &amp;&amp; cat '\/var\/azureml-app\/conda_env.yml'  <br \/>\n---&gt; Running in 6f1b1bcf415a<\/p>\n<h1 id=\"conda-environment-specification-the-dependencies-defined-in-this-file-will\">Conda environment specification. The dependencies defined in this file will<\/h1>\n<h1 id=\"be-automatically-provisioned-for-runs-with-usermanageddependenciesfalse\">be automatically provisioned for runs with userManagedDependencies=False.<\/h1>\n<h1 id=\"details-about-the-conda-environment-file-format\">Details about the Conda environment file format:<\/h1>\n<h1 id=\"httpscondaiodocsuser-guidetasksmanage-environmentshtmlcreate-env-file-manually\"><a href=\"https:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html#create-env-file-manually\">https:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html#create-env-file-manually<\/a><\/h1>\n<p>name: project_environment  <br \/>\ndependencies:<\/p>\n<h1 id=\"the-python-interpreter-version\">The python interpreter version.<\/h1>\n<h1 id=\"currently-azure-ml-only-supports-38-and-later\">Currently Azure ML only supports 3.8 and later.<\/h1>\n<ul>\n<li> pip&lt;=22.1.2<\/li>\n<li> pip:\n<ul>\n<li> azureml-train-automl-runtime==1.44.0<\/li>\n<li> inference-schema<\/li>\n<li> azureml-interpret==1.44.0<\/li>\n<li> azureml-defaults==1.44.0<\/li>\n<li> datefinder<\/li>\n<\/ul>\n<\/li>\n<li> numpy&gt;=1.18.5,&lt;=1.23.3<\/li>\n<li> pynacl&lt;=1.5.0<\/li>\n<li> pandas==1.1.5<\/li>\n<li> scikit-learn==0.22.2.post1<\/li>\n<li> py-xgboost==1.3.3<\/li>\n<li> fbprophet==0.7.1<\/li>\n<li> holidays==0.11.3.1<\/li>\n<li> psutil&lt;=5.9.1  <br \/>\n  channels:<\/li>\n<li> anaconda<\/li>\n<li> conda-forgeRemoving intermediate container 6f1b1bcf415a  <br \/>\n  ---&gt; 9205898728ba  <br \/>\n  Step 8\/10 : RUN CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n &quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p &quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/conda_env.yml'; else conda env update -n base -f '\/var\/azureml-app\/conda_env.yml'; fi &amp;&amp; conda clean -aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} +  <br \/>\n  ---&gt; Running in 8f7055e32ad7  <br \/>\n  Collecting package metadata: ...working...  <br \/>\n  done  <br \/>\n  Solving environment: ...working...  <br \/>\n  [91mKilled  <br \/>\n  [0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n &quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p &quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/conda_env.yml'; else conda env update -n base -f '\/var\/azureml-app\/conda_env.yml'; fi &amp;&amp; conda clean -aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} +' returned a non-zero code: 137  <br \/>\n  2022\/08\/12 13:17:23 Container failed during run: acb_step_0. No retries remaining.  <br \/>\n  failed to run step ID: acb_step_0: exit status 137  <br \/>\n  Run ID: ch1y failed after 9m7s. Error: failed during run, err: exit status 1<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failed to test real-time endpoint request() got an unexpected keyword argument 'tenant_id'",
        "Question_created_time":1660588808613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/967753\/failed-to-test-real-time-endpoint-request()-got-an",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,    <br \/>\nafter deployment of real time endpoint I try to test it by pinging. For now my run is minimal and looks like this:    <br \/>\n    def run(raw_data):  <br \/>\n        &quot;&quot;&quot;  <br \/>\n        This function is called for every invocation of the endpoint to perform the actual scoring\/prediction.  <br \/>\n        In the example we extract the data from the json input and call the scikit-learn model's predict()  <br \/>\n        method and return the result back  <br \/>\n        &quot;&quot;&quot;  <br \/>\n        logging.info(&quot;Request received&quot;)  <\/p>\n<pre><code>    KVUri = f&quot;&lt;&lt;endpoint url here&gt;&gt;&quot;  \n  \n    credential = ManagedIdentityCredential()  \n    client = SecretClient(vault_url=KVUri, credential=credential)  \n    retrieved_secret = client.get_secret(&quot;test-secret&quot;)  \n  \n    logging.info(&quot;Request processed&quot;)  \n    return [retrieved_secret]  \n  \n<\/code><\/pre>\n<p>After pinging I just get an error:    <\/p>\n<p>Failed to test real-time endpoint    <br \/>\nrequest() got an unexpected keyword argument 'tenant_id'    <\/p>\n<p>Somebody mentioned that this might be something that was fixed in later verisions of azure identity library. My conda currently looks like this:    <\/p>\n<pre><code>name: model-env  \nchannels:  \n  - conda-forge  \ndependencies:  \n  - python=3.7  \n  - numpy=1.21.2  \n  - pip=21.2.4  \n  - scikit-learn=0.24.2  \n  - scipy=1.7.1  \n  - pip:  \n    - azureml-defaults==1.39.0  \n    - inference-schema[numpy-support]==1.3.0  \n    - joblib==1.0.1  \n    - azure-identity  \n    - azure-keyvault-secrets  \n<\/code><\/pre>\n<p>Unfortunately, getting never azure-identity seems to require newer python. Unfortunately - I did not manage to make an endpoint even deploy with python 3.8\/3.9.    <br \/>\nDoes anybody have a suggestion on how to fix it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio Error CammandLine exceeds Limit",
        "Question_created_time":1657656469800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/924104\/azure-ml-studio-error-cammandline-exceeds-limit",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I am setting up ML experiment in Azure ML Studio Designer for K-Means Clustering and have ~750 attributes that I am attempting to cluster with ~4000 rows.    <\/p>\n<p>When i go to execute this i get the following error:    <\/p>\n<p>AzureMLCompute job failed. InvalidPropertyValue: The size of the specified property Job.Properties.CustomToolkitSettings.CommandLine exceeds the limit of 20480 characters    <\/p>\n<p>There isn't much on this error but would someone be able to assist me on how to increase the limit? I don't believe this is an K-Means error but a Azure ML Studio error.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how can i deploy a non-ML model on azure ML ?",
        "Question_created_time":1660648529110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/968884\/how-can-i-deploy-a-non-ml-model-on-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>okay so i built a recommendation system that doesn't rely on any ML ( only linear kernel between entries ) and I want to deploy it and make it available for users through a website, I'm confused as to how the deployment process is any different since in this case there is no machine learning being done ( so no.h5 weights or anything like that ) <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In AzureML, start_logging will start asynchronous execution or synchronous execution?",
        "Question_created_time":1659982904493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/959540\/in-azureml-start-logging-will-start-asynchronous-e",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>It was written in the Microsoft AzureML documentation, &quot;A run represents a single trial of an experiment. Runs are used to monitor the asynchronous execution of a trial&quot; and A Run object is also created when you submit or start_logging with the Experiment class.&quot;    <\/p>\n<p>Related to start_logging, as far as I know, when we have simply started the run by executing this start logging method. We have to stop, or complete by complete method when the run is completed. This is because start_logging is a synchronized way of creating an experiment. However, Run object created from start_logging is to monitor the asynchronous execution of a trial.    <\/p>\n<p>Can anyone clarify whether start_logging will start asynchronous execution or synchronous execution?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML Workspace Alerting and Application Insight Dashboard Configuration",
        "Question_created_time":1660054347030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/960800\/aml-workspace-alerting-and-application-insight-das",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi All,    <\/p>\n<p>I would need seach query understanding to configure alert for below metrics for AML Workspace and I also need to show metrics in Application Insight dashboard which are associated with AML.    <\/p>\n<p>Please guide on this.    <\/p>\n<p>Alert Description :     <\/p>\n<p>  Metric Name                Unit        Description    <\/p>\n<ol>\n<li> -Warnings                  -Count       -Number of run warnings in this workspace. Count is updated whenever a run encounters a warning.    <\/li>\n<li> -Errors                        -Count       -Number of run errors in this workspace. Count is updated whenever run encounters an error.    <\/li>\n<li> -Failed Runs               -Count       -Number of runs failed for this workspace. Count is updated when a run fails.    <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Designer is too slow!",
        "Question_created_time":1605910757727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/170450\/machine-learning-designer-is-too-slow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am teaching ML next week. I have usually been using ML Studio (Classic), but thought it would be time to transfer to ML the ML Designer. It is great in many ways, but it is just too slow for demo and teaching purposes.   <\/p>\n<p>1000 rows from an Azure DB in the same region. The simplest of experiments (Select Columns, Split Rows, Train Boosted Decission Tree, Score and Evaluate) on a STANDARD_DS5_V2 (16 Cores, 56 GB RAM, 112 GB Disk) compute target, which was the most expensive I could choose on my VS subscription. Creating a model takes about eight minutes!  <\/p>\n<p>Or to phrase it as a question: Am I doing anything wrong? Is there any way to make the Designer usable?  <\/p>\n<p>Thanks,  <br \/>\nChristian  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use export data module in Azure ML to move ML output to Azure SQL Data Warehouse?",
        "Question_created_time":1660233242963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/964452\/how-to-use-export-data-module-in-azure-ml-to-move",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Can anyone help me with the right configuration settings for the Export Data module in Azure ML studio. I am trying to export a data output from the ML studio to the SQL Data warehouse to enable build a visualization report with PowerBI. Find the screenshot of my pipeline, configuration and the error message I'm getting respectively below;    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/230544-image.png?platform=QnA\" alt=\"230544-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/230457-image.png?platform=QnA\" alt=\"230457-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/230468-image.png?platform=QnA\" alt=\"230468-image.png\" \/>    <\/p>\n<p>I look forward to a prompt assistance from anyone.    <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NCCL INFO and WARNING logs not present in new AzureML runtime",
        "Question_created_time":1659780711157,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/957497\/nccl-info-and-warning-logs-not-present-in-new-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>Recently, I have been trying to debug a very weird <code>NCCL<\/code> <code>OOM<\/code> issue and I have noticed that if I use the old runtime <code>NCCL<\/code> prints an <code>OOM<\/code> warning in <code>70_driver_log_0.txt<\/code> but that when I use the new runtime all these <code>NCCL<\/code> logs magically disappear. My hunch is that warnings are somehow suppressed in the new runtime. Is there a way to activate them again? If I enforce the old runtime by specifying the environment variable <code>pytorch_env.environment_variables = {&quot;AZUREML_COMPUTE_USE_COMMON_RUNTIME&quot;: &quot;false&quot;}<\/code> in my runs, then the warning is logged. My worry is that warnings like these (i.e. <code>OOM<\/code> warnings that don't make the job crash) would be difficult to detect if warnings are switched off by default in the new runtime. Otherwise, would there be any other reason why this warning wouldn't make it into the logs? If it does appear, would you be so kind to point me in the right direction? Btw, my job completes successfully even with the warning message below so can't really troubleshoot based on job status.    <\/p>\n<pre><code>:200:451 [0] include\/socket.h:423 NCCL WARN Net : Connection closed by remote peer 10.0.0.8&lt;&gt;  \n:200:451 [0] NCCL INFO include\/socket.h:445 -&gt; 2  \n:200:451 [0] NCCL INFO include\/socket.h:457 -&gt; 2  \n:200:451 [0] NCCL INFO bootstrap.cc:229 -&gt; 2  \n  \n:200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 71)  \n  \n:200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'  \n:200:451 [0] NCCL INFO bootstrap.cc:231 -&gt; 1  \n  \n:200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 70)  \n  \n:200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'  \n:200:451 [0] NCCL INFO bootstrap.cc:231 -&gt; 1  \n<\/code><\/pre>\n<p>Thanks in advance for your time.    <\/p>\n<p>Best,    <\/p>\n<p>Kiki    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - endpoint failure 502 when testing the model",
        "Question_created_time":1642932141937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/706183\/azure-machine-learning-endpoint-failure-502-when-t",
        "Question_score_count":2,
        "Question_answer_count":4,
        "Question_comment_count":2,
        "Question_body":"<p><strong>Very basic example from ms-learn does not work!!! So frustrating<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/167468-screenshot-2022-01-23-025300.png?platform=QnA\" alt=\"167468-screenshot-2022-01-23-025300.png\" \/>    <\/p>\n<p>from: <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/<\/a>    <\/p>\n<ol>\n<li> Created a model    <\/li>\n<li> model deployment to ACI    <\/li>\n<li> I copied the generated py code from the Consume tab into a notebook in the same service    <\/li>\n<li> get 502    <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"what do you know about  appium vs  selenium?",
        "Question_created_time":1659074114117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/947135\/what-do-you-know-about-appium-vs-selenium",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/226063-1625831698.jpg?platform=QnA\" alt=\"Selenium\" \/> and <a href=\"https:\/\/hkrtrainings.com\/appium-vs-selenium\">Appium<\/a> are both open source test automation frameworks. Selenium reduces the complexity of automated web application testing by supporting a wide range of browsers, operating systems, and programming languages. Appium includes features that make automated testing of native, mobile web, and hybrid apps easier.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resilience Test tools\/services for DevOps and MLOps in Azure",
        "Question_created_time":1660275015307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/965012\/resilience-test-tools-services-for-devops-and-mlop",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>what are the tools or services can be used for Resilience Test for DevOps and MLOps in Azure.    <br \/>\nCan you please suggest any azure native service or 3rd party tools?    <\/p>\n<p>I want to cover the below scopes as part of Resilience Test for DevOps and MLOps    <br \/>\nidempotency,    <br \/>\ngraceful degradation    <br \/>\nretry policy     <br \/>\ncircuit breaker    <br \/>\nperformance     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Text Classification Import Text Files",
        "Question_created_time":1659040614790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/946690\/azure-ml-text-classification-import-text-files",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I'm trying to create an Azure Machine Learning model to classify text files. I have hundreds of text files that have been organized into a subfolder named its correct label. Similar to how you train Image classification.     <\/p>\n<p>How would I get this data into a data set. I have been trying to use the python sdk since I was able to successfully get the Image classification to work.     <\/p>\n<p>Thanks,    <br \/>\nKyle<\/p>",
        "Question_closed_time":1659586063577,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=8a26106b-c601-41ff-b38c-3aa0f07e4ea0\">@Domsohn, Kyle  <\/a> Thanks for the question. Here is the sample to import text files and explore azure ml text classification.    <\/p>\n<p><a href=\"https:\/\/github.com\/microsoft\/nlp-recipes\/blob\/master\/examples\/text_classification\/tc_bert_azureml.ipynb\">https:\/\/github.com\/microsoft\/nlp-recipes\/blob\/master\/examples\/text_classification\/tc_bert_azureml.ipynb<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to connect to KeyVault to azureml real time endpoint using managed identity?",
        "Question_created_time":1660172274087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/963249\/how-to-connect-to-keyvault-to-azureml-real-time-en",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to connect  keyvault to an insanely simple app with score file as follows:    <\/p>\n<pre><code>def init():  \n    pass  \ndef run(raw_data):  \n    KVUri=&quot;&lt;&lt;AN ACTUAL KEYVAULT URI&gt;&gt;&quot;  \n    credential = DefaultAzureCredential()  \n    client = SecretClient(vault_url=KVUri, credential=credential)  \n    retrieved_secret = client.get_secret(&quot;test-secret&quot;)  \n    return  [retrieved_secret]  \n<\/code><\/pre>\n<p>I deploy using python SDK as follows:    <\/p>\n<pre><code># create an online endpoint  \nendpoint = ManagedOnlineEndpoint(  \n    name=local_endpoint_name,  \n    description=&quot;this is a sample online endpoint&quot;,  \n    auth_mode=&quot;key&quot;,  \n)  \nml_client.begin_create_or_update(endpoint)  \nmodel = Model(path=&quot;..\/model\/dummy.txt&quot;)  \nenv = Environment(  \n    conda_file=&quot;.\/conda.yaml&quot;,  \n    image=&quot;mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1&quot;,  \n)  \n  \nblue_deployment = ManagedOnlineDeployment(  \n    name=&quot;blue&quot;,  \n    endpoint_name=local_endpoint_name,  \n    model=model,  \n    environment=env,  \n    code_configuration=CodeConfiguration(  \n        code=&quot;.&quot;, scoring_script=&quot;app.py&quot;  \n    ),  \n    instance_type=&quot;Standard_F2s_v2&quot;,  \n    instance_count=1,  \n)  \nml_client.begin_create_or_update(blue_deployment)  \n<\/code><\/pre>\n<p>After the deployment I add System assigned managed identity to azure key vault (Access Controls IAM &gt; grant access to this resource). I assign access to instance of online endpoint, but when testing I get:    <\/p>\n<p>Failed to test real-time endpoint    <br \/>\nDefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. Visit <a href=\"https:\/\/aka.ms\/azsdk\/python\/identity\/environmentcredential\/troubleshoot\">https:\/\/aka.ms\/azsdk\/python\/identity\/environmentcredential\/troubleshoot<\/a> to troubleshoot.this issue. ManagedIdentityCredential: request() got an unexpected keyword argument 'tenant_id' To mitigate this issue, please refer to the troubleshooting guidelines here at <a href=\"https:\/\/aka.ms\/azsdk\/python\/identity\/defaultazurecredential\/troubleshoot\">https:\/\/aka.ms\/azsdk\/python\/identity\/defaultazurecredential\/troubleshoot<\/a>.    <\/p>\n<p>Do you know what is the source of an error? How should I do it correctly?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not Able to Create a Dataset using azure SDK",
        "Question_created_time":1659602908663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/954905\/not-able-to-create-a-dataset-using-azure-sdk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello There,    <br \/>\nI am trying to register dataset from a csv file in my blob container storage using Azure ML SDK. However, I keep getting this error message.(Authentication Failed).    <\/p>\n<p>Point to note - I used the same Authentication key(from the same object) to upload the csv file in the blob container storage using Azure ML SDK, which was successful.     <\/p>\n<pre><code>    DatasetValidationError: DatasetValidationError:  \n    \tMessage: Failed to validate the data.  \n    ScriptExecutionException was caused by StreamAccessException.  \n      StreamAccessException was caused by AuthenticationException.  \n        Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.  \n          Failed due to inner exception of type: StorageException  \n    | session_id=************  \n    \tInnerException None  \n    \tErrorResponse   \n    {  \n        &quot;error&quot;: {  \n            &quot;code&quot;: &quot;UserError&quot;,  \n            &quot;message&quot;: &quot;Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n  StreamAccessException was caused by AuthenticationException.\\r\\n    Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n      Failed due to inner exception of type: StorageException\\r\\n| session_id=**********&quot;  \n        }  \n    }  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML.NET or Azure ML for job satisfaction prediction?",
        "Question_created_time":1659816548317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/957699\/ml-net-or-azure-ml-for-job-satisfaction-prediction",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Recently my manager asked to consider machine learning in our company. The specific problem he had in mind could be described as follows.    <\/p>\n<p>There are customers with datasets with employee information - gender, nationality, age, marital status, last salary increase time, current salary, CV information (can deduce &quot;how many times the employee has changed their job in last 10 years&quot; etc.) and also we could include general job market data (typical salary for this position in other companies etc.). Based on all of these features and their historically observed results, we would like to train ML models that can predict specific simple yes\/no answers about employees, such as &quot;are they considering leaving the company?&quot;, &quot;are they undervalued?&quot; and generate a report on employees who have high probability scores for predicted &quot;yes&quot; answers.      <\/p>\n<p>I'm an experienced .net C# developer and also have general architecture experience with Azure (VMs, app services, functions, DevOps) but I have no serious experience with machine learning yet. Some years ago I was playing around with Nvidia's StyleGAN and neural networks based speech synthesis, but I was treating the &quot;AI stuff&quot; as a black box, tweaking only the control UIs and data input utilities. However, yesterday I watched a few MLNET tutorials and it all seemed to make sense and made me thinking that even a &quot;mere mortal&quot; .net developers might be able to create something usable, especially if we get some help from a data scientist sometime later.    <\/p>\n<p>Would MLNET Model Builder be enough to help with this specific scenario? Would binary classification model be a good candidate? Or maybe Azure ML Studio might offer a better starting point?    <br \/>\nAre there any code examples that show how to properly featurize such kind of input data and that might work well for our case, at least to have a usable proof-of-concept to demonstrate? Or am I oversimplifying the task and it would need much more data analysis and algorithm selection than automated ML.NET and Azure builders can offer?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Relation Google node hour to Azure computing hour",
        "Question_created_time":1659708002537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/956892\/relation-google-node-hour-to-azure-computing-hour",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hey there,    <\/p>\n<p>I am writing my masters thesis at the moment.\u00a0In my master thesis I compare the machine learning services of Google and Microsoft for image classification. This also includes the costs. Google uses node hours and Microsoft computing hours for the calculation. Is it possible to compare these units? This would be a crucial part of the comparison.    <br \/>\nThanks a lot!\u00a0<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Newly released based image for Azure Machine Learning contains medium- and high-level security vulnerabillities",
        "Question_created_time":1659575906903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/954345\/newly-released-based-image-for-azure-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,     <\/p>\n<p>We are currently using the latest (as of 4 Aug 2022) container based image released by Microsoft for our AML workloads: mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu20.04:20220729.v1 (<a href=\"https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/cpu\/openmpi4.1.0-ubuntu20.04\/release-notes.md\">https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/cpu\/openmpi4.1.0-ubuntu20.04\/release-notes.md<\/a>).    <\/p>\n<p>However, this image contains the following security vulnerabilities:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/227904-screenshot-1.jpg?platform=QnA\" alt=\"227904-screenshot-1.jpg\" \/>    <\/p>\n<p>We would like to know if it's possible to resolve them (we are not sure how to implement the remedy provided).    <br \/>\nIn our company, vulnerable container registry images would be deleted automatically - hence it's important for us to know how to make the image secure.    <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning excel add-ins error",
        "Question_created_time":1659592116103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/954559\/azure-machine-learning-excel-add-ins-error",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone,     <\/p>\n<p>Has anyone else experienced this issue before ? It was working fine yesterday and the web service is also fine. Just that the Excel Add-Ins is having this problem. It's saying &quot;The content is blocked because it isn't signed by a valid security certificate&quot;. I am not sure where else to ask. Kindly help.     <\/p>\n<p>Thanks,    <br \/>\nAiman    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/227870-image.png?platform=QnA\" alt=\"227870-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"time series training",
        "Question_created_time":1659301076627,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/949086\/time-series-training",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I see one document mentioned time series training can be done with AutoML: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast<\/a> is that any sample which from basic build of model? <\/p>",
        "Question_closed_time":1659343661097,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6ec12307-1a06-4236-b249-3fd890a3f2a1\">@matsuoka  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform, we don't have any samples for basic build of a model in AutoML, but we do have quick start for how to use time series in AutoML - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-automated-ml-forecast\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-automated-ml-forecast<\/a>    <\/p>\n<p>This is a low code sample for beginning user. Please take a look.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Estimate the cost for Machine learning SDK or UI portal",
        "Question_created_time":1658729307217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/940045\/estimate-the-cost-for-machine-learning-sdk-or-ui-p",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello experts, we are working on a medium size solution for our company and we are exploring basic estimate for SDK or studio decision. How I can know? <\/p>",
        "Question_closed_time":1658757422623,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>     <\/p>\n<p>Thanks for reachin out to us, the Azure Machine Learnng pricing mainly is consist of CPU pricing and compute pricing, to get a better estimate pricing, a good way to calculate is using the calculator - <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\">https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/224435-image.png?platform=QnA\" alt=\"224435-image.png\" \/>    <\/p>\n<p>You can add your details into it and you will have a general idea about that.    <\/p>\n<p>I hope this helps, thank you.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Store real time inference data from Azure ML",
        "Question_created_time":1658947320020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/944890\/store-real-time-inference-data-from-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>The models trained on Azure have - model object, scoring script and environment settings.    <br \/>\nWe are eying complete MLOps automation and that means that we do not touch anything from from training to deployment to monitoring.     <\/p>\n<p>How can I capture data that came for inference to real time deployed model without touching scoring script (as it is generated as part of training).    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Negative Samples in ML Assisted Image Labeling",
        "Question_created_time":1658973322783,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/945298\/negative-samples-in-ml-assisted-image-labeling",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We are evaluating the Azure ML Assisted Object detection labeling and I have some questions:    <\/p>\n<ol>\n<li> How do I mark an image as a negative?    <\/li>\n<li> How do I rename a label?    <\/li>\n<li> How do I go back to a skipped image?    <\/li>\n<li> When labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.    <\/li>\n<li> For an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?    <\/li>\n<li> Sometime the autolabeler creates small bounding boxes without any labels. Is this a bug?    <\/li>\n<\/ol>\n<p>Thank you    <\/p>",
        "Question_closed_time":1659001066757,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=0e12a81e-dc27-426e-964f-919ca7d5e308\">@Prashant Saraswat  <\/a> I think I can answer some of your questions from some of the projects I used for labeling.<\/p>\n<ol>\n<li>  How do I mark an image as a negative?  <br \/>\n    Unlike the Azure custom vision labeling experience, there isn't a feature to mark a label as negative. I believe you can add another label and use it as a negative label and tag images.<\/li>\n<li>  How do I go back to a skipped image?  <br \/>\n    Go to the Data tab of your project and select Review Labels tab from the side. Using the filters option on right hand side, set the Asset Type as &quot;Skipped&quot;. This should pull any skipped images and you should be able to assign the required label and a button should be enabled to update label. The same applies for updating any labeled image or bounding box.  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/225606-image.png?platform=QnA\" alt=\"225606-image.png\" \/><\/li>\n<li>  How do I rename a label?  <br \/>\n    I think a label cannot be renamed after it is created. You can delete all labels and create a new set though. Just stop your project and select the Details-&gt; Label Classes tab and click Add label option to see this screen.  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/225667-image.png?platform=QnA\" alt=\"225667-image.png\" \/>\n<ol start=\"4\">\n<li>  When labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.  <br \/>\n        I think you can skip the image since the dataset is registered while creating a project there is no option to delete certain images after this action.<\/li>\n<li>  For an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?  <br \/>\n        I have not used auto labeling before but the same step to update the skipped image or label should help you with this step.<\/li>\n<li>  Sometime the autolabeler creates small bounding boxes without any labels. Is this a bug?  <br \/>\n        Not sure about this issue since I haven't come across it. You could report through support or through portal using the smiley image on the top right hand corner.<\/li>\n<\/ol>\n<\/li>\n<\/ol>\n<p>I hope this helps!!<\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Endpoint Deletion",
        "Question_created_time":1628657145543,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/509079\/endpoint-deletion",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi , I Have tried to deploy a time series model which was created using Auto-Ml,and i tried to deplot that model as a Azure Container instance service ,but it got failed,in the model section it shows deploy status as Failed but in the Endpoints Section it shows that the deployment is in transitioning state,So I'm unable to delete the Endpoint ,can you help me resolve this?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/122030-screenshot-2021-08-11-100411.png?platform=QnA\" alt=\"122030-screenshot-2021-08-11-100411.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/122193-screenshot-2021-08-11-100437.png?platform=QnA\" alt=\"122193-screenshot-2021-08-11-100437.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/122183-screenshot-2021-08-11-100455.png?platform=QnA\" alt=\"122183-screenshot-2021-08-11-100455.png\" \/>    <br \/>\nNiranjan    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy model in Real-time \/ Online Endpoint",
        "Question_created_time":1658225492927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/932550\/unable-to-deploy-model-in-real-time-online-endpoin",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>While trying to deploy mlflow model in Realtime endpoint , I am getting the following error:-    <\/p>\n<p>&quot;Deployment failed due to missing NCD Model or default environment definition&quot;    <\/p>\n<p>--------------------------------------------------------------------------------    <\/p>\n<p>ONLINE DEPLOYMENT FILE CONFIG:-    <\/p>\n<p>$schema: <a href=\"https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\">https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json<\/a>    <br \/>\nname: aiml-test-deploy-008    <br \/>\nendpoint_name: aiml-online-ep-008    <br \/>\nmodel: azureml:taxi-model@latest    <br \/>\ntype: mlflow_model    <br \/>\ninstance_type: Standard_DS2_v2    <br \/>\ninstance_count: 1    <br \/>\ntype: managed    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222272-image.png?platform=QnA\" alt=\"222272-image.png\" \/>    <\/p>\n<p>I have all those files in Artifacts also. Kindly let me know what was causing the issue<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I download onnx model from pipeline create by Azure Machine Learning Designer",
        "Question_created_time":1658129471700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/930701\/can-i-download-onnx-model-from-pipeline-create-by",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I don't understand the model format trained by pipeline create by Azure Machine Learning Designer, Like default Linear Regression. Can I download the onnx format model? and How.<\/p>",
        "Question_closed_time":1658147834667,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=f88945ec-b857-45bb-903b-77ad4e83ce25\">@Qing Shuang  <\/a> If the pipeline is created using the designer, then the train model module output would be .ilearner file which is a binary format that encapsulates the statistical patterns learned from the data. You cannot directly modify or read this format; however, other components can use this trained model in your pipelines and you can register the model and deploy it as a endpoint. Please refer this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/train-model#how-the-training-process-works\">document<\/a> for more details about the training process.    <\/p>\n<p>However, if you use the SDK and register a different model format you can download the trained model and convert it to ONNX if it is supported from the listed formats on this <a href=\"https:\/\/github.com\/onnx\/tutorials\">page<\/a>.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to create Dataset using azureml sdk",
        "Question_created_time":1657779749267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/926455\/unable-to-create-dataset-using-azureml-sdk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\nActually I am trying to create dataset using sdk, but keep on getting this error message    <\/p>\n<pre><code>DatasetValidationError: DatasetValidationError:  \nMessage: Failed to validate the data.  \nScriptExecutionException was caused by StreamAccessException.  \nStreamAccessException was caused by AuthenticationException.  \nAuthentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.  \nFailed due to inner exception of type: StorageException  \n| session_id=***************************  \nInnerException None  \nErrorResponse  \n{  \n&quot;error&quot;: {  \n&quot;code&quot;: &quot;UserError&quot;,  \n&quot;message&quot;: &quot;Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by AuthenticationException.\\r\\n Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n Failed due to inner exception of type: StorageException\\r\\n| session_id=*************************&quot;  \n}  \n}  \n<\/code><\/pre>\n<p>I changed the key and revalidated it multiple times but it is giving the same error.    <br \/>\nYesterday I had also faced the similar type of issue while creating environment using sdk.    <\/p>\n<pre><code>ActivityFailedException: ActivityFailedException:  \n\tMessage: Activity Failed:  \n{  \n    &quot;error&quot;: {  \n        &quot;code&quot;: &quot;UserError&quot;,  \n        &quot;message&quot;: &quot;Creating conda environment failed with exit code: 1&quot;,  \n        &quot;messageParameters&quot;: {},  \n        &quot;details&quot;: []  \n    },  \n    &quot;time&quot;: &quot;2022-07-14T07:21:34.797598Z&quot;  \n}  \n\tInnerException None  \n\tErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;message&quot;: &quot;Activity Failed:\\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n        \\&quot;message\\&quot;: \\&quot;Creating conda environment failed with exit code: 1\\&quot;,\\n        \\&quot;messageParameters\\&quot;: {},\\n        \\&quot;details\\&quot;: []\\n    },\\n    \\&quot;time\\&quot;: \\&quot;2022-07-14T07:21:34.797598Z\\&quot;\\n}&quot;  \n    }  \n}  \n<\/code><\/pre>\n<p>Please note I am not facing any type of issue if I perform actions using the Azure portal.    <\/p>\n<p>Regards,    <br \/>\nAlok    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hyperparamter optimization in Azure AutoML",
        "Question_created_time":1625435556057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Which type of hyperparameter optimization is used in Azure Automated Machine Learning (not the SDK) as default? Grid Search, Random Search, Bayesian? In the SDK you can specify that but in the AutoML section you can not specify that and there is no further information on that<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there any additional cost when I attach Azure Databricks cluster in Azure Machine Learning Workspace?",
        "Question_created_time":1658728943337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/940007\/is-there-any-additional-cost-when-i-attach-azure-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is there any additional cost when I attach Azure Databricks cluster in Azure Machine Learning Workspace?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Compute Instance stopped provisioning RStudio",
        "Question_created_time":1656439437333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/906921\/ml-compute-instance-stopped-provisioning-rstudio",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<ol>\n<li> Just wondering if anyone knows why Azure ML compute instance suddenly stopped provisioning RStudio?     <\/li>\n<li> I have tried to set up a custom app using ghcr.io\/azure\/rocker-rstudio-ml-verse:latest, but it is not able to access the files (e.g. files that are previously accessible via the automatically provisioned RStudio, jupyter, jupyterhub, terminal etc)    <\/li>\n<\/ol>\n<p>Would be great if you could provide any guidance etc.    <br \/>\nthanks a lot.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Test section blank after deployment",
        "Question_created_time":1658298895807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/933895\/test-section-blank-after-deployment",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_body":"<p>Hi ,    <\/p>\n<p>Am trying to deploy Two-Class Logistic Regression model endpoint using AZML Designer. But I cant get the &quot;Test&quot; to show as I expect it to . Please find attached the images and logs    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222558-pic1.png?platform=QnA\" alt=\"222558-pic1.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222508-pic2.png?platform=QnA\" alt=\"222508-pic2.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222518-pic3.png?platform=QnA\" alt=\"222518-pic3.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222546-pic4.png?platform=QnA\" alt=\"222546-pic4.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Building an ML Model for open-ended questions Answers",
        "Question_created_time":1658395702420,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/935973\/building-an-ml-model-for-open-ended-questions-answ",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi All,     <\/p>\n<p>I am working on my thesis and require your help. Now I am trying to create text detector using Azur auto ML. the idea is the tutor will upload the model answers of open-ended questions such as  ''What is Blockchain Technology?''. The model will the compare the student's answer with the model answers that is provided by the tutor.  For example the model answer would be ''Blockchain defined: Blockchain is a shared, immutable ledger that facilitates the process of recording transactions and tracking assets in a business network. An asset can be tangible (a house, car, cash, land) or intangible (intellectual property, patents, copyrights, branding)''.     <br \/>\nI do not how can I go about this model?     <\/p>\n<p>Thanks <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Auzre ML realtime endpoint deployment stuck after source folder upload",
        "Question_created_time":1658139184840,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/930850\/auzre-ml-realtime-endpoint-deployment-stuck-after",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>Hi,    <\/p>\n<p>Using either Azure CLI or Python SDK V2, realtime endpoint deployment gets stuck forever after source folder is uploaded. Any suggestions? Thanks.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/221758-screenshot-from-2022-07-18-20-02-57.png?platform=QnA\" alt=\"221758-screenshot-from-2022-07-18-20-02-57.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error invoking the azure ML pipeline from Azure Devops",
        "Question_created_time":1658316045857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/934296\/error-invoking-the-azure-ml-pipeline-from-azure-de",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When I tried invoking an Azure ML pipeline from an Azure DevOps pipeline, I keep running into errors, Can you please share any sample that works.<\/p>",
        "Question_closed_time":1658317648817,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. yes this is possible just use the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/devops\/pipelines\/tasks\/deploy\/azure-cli?view=azure-devops\">Azure CLI task - Azure Pipelines<\/a>  step and run command line or Python scripts inside that to submit your pipelines.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to upload(write) data(dataframe) to azure SQL datastore from azure machine learning(azureML) using SDK",
        "Question_created_time":1596612863487,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/59457\/how-to-upload(write)-data(dataframe)-to-azure-sql",
        "Question_score_count":2,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>From the documentation I could find ways to read data from Azure SQL database registered as datastore in azureML,but not ways to upload or write output data to azure SQL database from azureML.Can anyone please guide me on the same? Also can SQL datastore be used as output for the batch inference step<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error 404 for design pipelines",
        "Question_created_time":1658146582847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/931152\/error-404-for-design-pipelines",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am trying to run a ML pipeline that I built on Microsoft Azure design some time ago, approximately six months ago, and I realize the interface for design has changed since then. When I try to run these pipelines, I have tried with several, then I get the attached message error. Please your help to see if there is any solution.    <\/p>\n<p>Thank you!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/221836-image.png?platform=QnA\" alt=\"221836-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export custom model\/code",
        "Question_created_time":1620897291797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/393890\/export-custom-model-code",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>If I use transformer\/estimator from the sklearn package it's sufficient to export a <em>model.pkl<\/em> artifact then simply use it following the various tutorials on microsoft site.  <br \/>\nHowever, when I use scikit-learn's <strong>FunctionTransformer<\/strong> or <strong>TransformerMixin<\/strong> class to incorporate custom transformations how can I export the custom code to azure machine learning together with the model? (<em>model.pkl<\/em> do not contains the custom code)  <br \/>\nWhat is the best practice?   <\/p>\n<p>Thanks.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"403: AuthorizationPermissionMismatch",
        "Question_created_time":1657807579977,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/926988\/403-authorizationpermissionmismatch",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I have my source data in a storage account and I am trying to access it from my Machine learning workspace. I have assigned system assigned managed identity to my compute cluster and I have also added &quot;Storage Blob Contributor\/Reader access to my machine learning workspace in the storage account IAM.    <\/p>\n<p>But still I am getting the below error    <\/p>\n<p>03: AuthorizationPermissionMismatch'. Please make sure the compute or login identity has 'Storage Blob Data Reader' or 'Storage Blob Data Owner' role in the storage IAM.    <br \/>\n      This request is not authorized to perform this operation using this permission  <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220831-image.png?platform=QnA\" alt=\"220831-image.png\" \/>    <\/p>\n<p>Please help me to sort out this issue    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delay in Code Output in Azure ML",
        "Question_created_time":1658194083553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/931876\/delay-in-code-output-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have been using Azure ML for last 2 months and since last 3-4 days running notebook is not behaving normal. Since my default notebooks do not have an option for indentation of code, so i manually indented my code and since then there have been issues.     <br \/>\nAlso the code output takes few second 5-8 seconds and sometimes even more to generate the output. My CPU on and off shows 50% consumed and i am not sure why because the data size is only in MB's - around 10k rows of data and 20 off columns.     <br \/>\nI am using a pretty decent compute -     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222035-image.png?platform=QnA\" alt=\"222035-image.png\" \/>    <\/p>\n<p>Also here is the greyed out snippet of notebooks where it does not show any output. Could someone please advice on potential reasons for this     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/222009-image.png?platform=QnA\" alt=\"222009-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Given allow_reuse set to false and regenerate_outputs set to True when the pipeline is submitted then it stucks at the running stage with first step saying \"Not Started\"",
        "Question_created_time":1657676507390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/924406\/given-allow-reuse-set-to-false-and-regenerate-outp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am using Azure Machine Learning SDK in python to create a pipeline which needs to read data from Azure SQL Database, perform transformation, model the data as per need and store the output back to Azure SQL Database. In this scenario, I need to run the published pipeline every time(without reusing output from previous run) because underlying data changes. To resolve this problem I set allow_reuse flag to False in PythonScriptStep(). Also, I set regenerate_outputs=True while submitting the pipeline. Following is the code:    <\/p>\n<p>from azureml.pipeline.steps import PythonScriptStep    <br \/>\ndataprep_source_dir = &quot;.\/&quot;    <br \/>\nentry_point = &quot;Fetch_Data.py&quot;    <br \/>\ndata_fetch_step = PythonScriptStep(    <br \/>\n    name=&quot;Fetch step&quot;,  <br \/>\n    script_name=entry_point,  <br \/>\n    source_directory=dataprep_source_dir,  <br \/>\n    arguments=[&quot;--fetched-data&quot;, fetched_data_folder],  <br \/>\n    outputs=[fetched_data_folder],  <br \/>\n    compute_target=target_compute,  <br \/>\n    runconfig=aml_run_config,  <br \/>\n    allow_reuse=False  <br \/>\n)    <\/p>\n<p>pipeline_run = Experiment(workspace, 'exp_name').submit(pipeline1, regenerate_outputs=True)    <\/p>\n<p>It was working fine until last month and every time pipeline was generating outputs which I intend to (not using result from previous run) but this week it started to give me another weird problem. <strong>When I am submitting the pipeline first time, I see the first step is &quot;Not Started&quot; saying that rerun will be used (which it should not as allow_reuse set to false) and weirdly the rerun id of that step and current runId is same. So finally nothing happens and pipeline stays in running stage for like 12 hrs until I cancel it.<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220222-image.png?platform=QnA\" alt=\"220222-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220182-image.png?platform=QnA\" alt=\"220182-image.png\" \/>    <\/p>\n<p>Please help me fix this issue. It is very weird that I can't submit pipeline where I don't want to reuse previous job run results.    <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML pipeline not shown up in Azure Data Factory",
        "Question_created_time":1657836174723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/927602\/ml-pipeline-not-shown-up-in-azure-data-factory",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I would like to trigger azure ml pipeline in ADF and the connection to azure ml is successful, but no pipeline is found in the drop down list. I have several pipeline endpoints (Pipelines &gt; Pipeline endpoints) in Azure ML. Did I miss something?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220884-image.png?platform=QnA\" alt=\"220884-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Recommendations on handling the models",
        "Question_created_time":1657703130580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/924897\/recommendations-on-handling-the-models",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I'm currently experimenting with ML.NET.    <br \/>\nThe goal is to be able to forecast values for future months based on historical data.    <\/p>\n<p><strong>Example scenario:<\/strong>    <\/p>\n<p>Let's say a company named XYZ has 10 stores across United States and each branch has it's own historical sales data for the past year.    <\/p>\n<p>If I want to forecast the Net income for each store for the next 6-12 months, does that mean we'll have 1 model for each store since each store has its own set of data?    <\/p>\n<p>If yes, do you have a recommendation on how to organize these models? Are all the models part of the same zip file?    <\/p>\n<p>Also, for any given day, new data comes in for each store, is there a way to automatically add these new data to the model's knowledge?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to use KFold cross-validation without shuffling in Azure AutoML?",
        "Question_created_time":1657930963903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/929194\/is-it-possible-to-use-kfold-cross-validation-witho",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to disable shuffling when using kfold cross-validation in Azure AutoML? I have a dataset with significant correlation between adjacent samples and would like to use continuous chunks as validation folds. I'm aware I can manually create a validation set, but as my dataset is small I would prefer to use multiple continuous folds if possible.    <\/p>\n<p>Also, as not shuffling is default behavior in scikit-learn, I'm concerned this could be a trap for naive users. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question on running an experiment",
        "Question_created_time":1657906415713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/928739\/question-on-running-an-experiment",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>This is the first time I am creating an experiment with my Microsoft Azure learning machine account. I have created and saved the experiment, but I am unable to run the experiment. The system keeps bringing out error message. What could be responsible for this, please?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When using AutoML for forecasting, is it possible to include lagged exogenous features?",
        "Question_created_time":1657059623547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/915375\/when-using-automl-for-forecasting-is-it-possible-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\">documentation<\/a>, it states &quot;When training a model for forecasting future values, ensure all the features used in training can be used when running predictions for your intended horizon. For example, when creating a demand forecast, including a feature for current stock price could massively increase training accuracy. However, if you intend to forecast with a long horizon, you may not be able to accurately predict future stock values corresponding to future time-series points, and model accuracy could suffer,&quot; which seems to imply only features that are known or can reasonably be estimated in the future should be used. This seems like a pretty severe limitation. Is it really not possible to include exogenous features that should be lagged like the target is?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azurerml v2 Pipeline: Steps not running in the mentioned conda environment",
        "Question_created_time":1656965879723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/913607\/azurerml-v2-pipeline-steps-not-running-in-the-ment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello I am trying to create a pipeline using the documentation of Azureml v2. But the steps in a Job are not running in the environment mentioned in the yaml script of the pipeline. I don't know where I am going wrong. I am hereby attaching the yaml I created to create the pipeline. Please do let me know how to tackle this issue:    <\/p>\n<pre><code>   $schema: https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json  \n   type: pipeline  \n   experiment_name: ccep_training  \n   description: Training Pipeline to train a model that predicts coke and non coke bottles  \n     \n   inputs:  \n    training_images:  \n       type: uri_folder  \n       mode: download # pick ro_mount, rw_mount or download  \n       path: azureml:\/\/datastores\/ccepdatastore\/paths\/yolo\/dummy_dataset\/**  \n   outputs:  \n     step_output_train:  \n       type: uri_folder  \n   settings:  \n     default_datastore: &lt;NAME OF DATASTORE&gt;  \n     continue_on_step_failure: false  \n     \n   jobs:  \n     train:  \n       name: training  \n       display_name: Model-training  \n       environment: azureml:ccep_train_env@latest  \n       code: ..\/..\/ccep\/training  \n       command: &gt;-  \n         python train_aml.py  \n         --model_name ${&lt;!-- --&gt;{inputs.model_name_train}}  \n         --step_output ${&lt;!-- --&gt;{outputs.step_output}}  \n           \n       inputs:  \n     \n         model_name_train: &quot;ccep.pt&quot;  \n         model_name_tflite: &quot;ccep-fp16.tflite&quot;  \n         dataset_version: &quot;latest&quot;  \n         epochs: 1  \n         data_file_path: ${&lt;!-- --&gt;{parent.inputs.training_images}}  \n         caller_run_id_param: none  \n         dataset_name: &quot;dummy_dataset&quot;  \n       outputs:  \n         step_output: ${&lt;!-- --&gt;{parent.outputs.step_output_train}}  \n       compute: azureml:ccepcomputeclust  \n       resources:  \n         instance_count: 1  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Change AML script",
        "Question_created_time":1657574990310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/922634\/change-aml-script",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>How can we change the pipeline script OR the output setting of &quot;regenerate output&quot; over the AML pipeline description page, instead of submitting the pipeline again?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parallel computing with Python SDK V2",
        "Question_created_time":1657198500433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/918129\/parallel-computing-with-python-sdk-v2",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello :)     <\/p>\n<p>Do you have any kind of idea when Azure Machine Learning Python SDK V2 could support parallel computing? We are testing things out with the machine learning studio and we are in a bit confusing stage that should we go with the SDK V1 or V2, but seemingly the V2 is not yet supporting multiple nodes in compute clusters.    <\/p>\n<p>Best regards,    <br \/>\nTuomas<\/p>",
        "Question_closed_time":1657774403743,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=618a88ea-c762-4907-9a08-ae41864a250e\">@Tuomas Partanen  <\/a>     <\/p>\n<p>I have a good news for you, we are testing Parallel Run Step NOW in private preview of V2.     <\/p>\n<p>For your scenario, v1 is stable and serving all production customers. v2 (through DPv2) is still in private preview, and there are some dependency on new dataset\/mltable implementation. So if you want to seriously put some production traffic, I suggest guide to v1; but if you just want to have some prototypes, v2 may be better, as v2 is growing but v1 will not. Also, V2 will have the feature you want - Parallel.     <\/p>\n<p>The estimate time is not confirmed but should be around October.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AZ ML Designer. Swagger file missing on deployment. Test empty.",
        "Question_created_time":1657708598787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/925083\/az-ml-designer-swagger-file-missing-on-deployment",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Guys,  <br \/>\nAm trying to deploy a very small logistic regression model endpoint using AZML Designer. But I cant get the &quot;Test&quot; to show as I expect it to . I think I have narrowed it down to the same issue as the others on this thread. Please find attached the images and logs  <br \/>\n1.This is the inference pipeline  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220383-inference-pipe.png?platform=QnA\" alt=\"220383-inference-pipe.png\" \/><\/p>\n<p>2.This is the deployed endpoint  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220358-endpointdetail.png?platform=QnA\" alt=\"220358-endpointdetail.png\" \/><\/p>\n<p>3.The test section of the endpoint  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220376-endpointtest.png?platform=QnA\" alt=\"220376-endpointtest.png\" \/><\/p>\n<ol start=\"4\">\n<li>  Swagger missing info from the logs  <br \/>\n    <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220360-swagger.png?platform=QnA\" alt=\"220360-swagger.png\" \/><\/li>\n<\/ol>\n<p>5.<strong>Expected<\/strong> test section  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/220359-endpoint-expected.png?platform=QnA\" alt=\"220359-endpoint-expected.png\" \/><\/p>\n<ol start=\"6\">\n<li>  Entire deployment log dump below signature<\/li>\n<\/ol>\n<p>regards  <br \/>\nSharath<\/p>\n<pre><code>2022-07-13T09:30:23,130461474+00:00 - iot-server\/run   \n2022-07-13T09:30:23,157246653+00:00 - rsyslog\/run   \n2022-07-13T09:30:23,159450135+00:00 - nginx\/run   \n2022-07-13T09:30:23,197683320+00:00 - gunicorn\/run   \n2022-07-13T09:30:23,199090409+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,227403276+00:00 | gunicorn\/run | ###############################################  \n2022-07-13T09:30:23,257497428+00:00 | gunicorn\/run | AzureML Container Runtime Information  \n2022-07-13T09:30:23,267026449+00:00 | gunicorn\/run | ###############################################  \n2022-07-13T09:30:23,268411738+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,276054375+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,278626954+00:00 | gunicorn\/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20220708.v2  \n2022-07-13T09:30:23,286217091+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,287579180+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,295279917+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin  \n2022-07-13T09:30:23,296728705+00:00 | gunicorn\/run | PYTHONPATH environment variable:   \n2022-07-13T09:30:23,298062894+00:00 | gunicorn\/run |   \n2022-07-13T09:30:23,306503424+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)  \n\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...  \n2022-07-13T09:30:23,602722185+00:00 - iot-server\/finish 1 0  \n2022-07-13T09:30:23,604481070+00:00 - Exit code 1 is normal. Not restarting iot-server.  \nadal==1.2.7  \napplicationinsights==0.11.10  \nattrs==21.4.0  \nazure-common==1.1.28  \nazure-core==1.24.2  \nazure-graphrbac==0.61.1  \nazure-identity==1.10.0  \nazure-mgmt-authorization==0.61.0  \nazure-mgmt-containerregistry==10.0.0  \nazure-mgmt-core==1.3.1  \nazure-mgmt-keyvault==9.3.0  \nazure-mgmt-resource==13.0.0  \nazure-mgmt-storage==11.2.0  \nazure-storage-blob==1.5.0  \nazure-storage-common==1.4.2  \nazureml-core==1.36.0.post2  \nazureml-dataprep==2.24.4  \nazureml-dataprep-native==38.0.0  \nazureml-dataprep-rslex==2.0.3  \nazureml-dataset-runtime==1.36.0  \nazureml-defaults==1.36.0  \nazureml-designer-classic-modules==0.0.161  \nazureml-designer-core==0.0.68  \nazureml-designer-internal==0.0.56  \nazureml-inference-server-http==0.4.13  \nazureml-interpret==1.36.0  \nazureml-model-management-sdk==1.0.1b6.post1  \nazureml-pipeline-core==1.36.0  \nazureml-telemetry==1.36.0  \nbackports.tempfile==1.0  \nbackports.weakref==1.0.post1  \nblis==0.2.4  \ncachetools==4.2.4  \ncertifi==2022.6.15  \ncffi==1.12.3  \nchardet==3.0.4  \ncharset-normalizer==2.0.12  \nclick==7.1.2  \ncloudpickle==2.1.0  \nconfigparser==3.7.4  \ncontextlib2==21.6.0  \ncontextvars==2.4  \ncryptography==37.0.4  \ncycler==0.11.0  \ncymem==2.0.6  \ndill==0.3.4  \ndistro==1.4.0  \ndocker==5.0.3  \ndotnetcore2==3.1.23  \nen-core-web-sm @ https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz  \nFlask==1.0.3  \nfusepy==3.0.1  \ngensim==3.8.3  \ngoogle-api-core==2.8.2  \ngoogle-auth==2.9.0  \ngoogleapis-common-protos==1.56.3  \ngunicorn==20.1.0  \nidna==3.3  \nimbalanced-learn==0.4.3  \nimmutables==0.18  \nimportlib-metadata==4.8.3  \nimportlib-resources==5.4.0  \ninference-schema==1.3.0  \ninterpret-community==0.21.0  \ninterpret-core==0.2.6  \nisodate==0.6.1  \nitsdangerous==1.1.0  \njeepney==0.7.1  \nJinja2==3.0.3  \njmespath==0.10.0  \njoblib==0.14.0  \njson-logging-py==0.2  \njsonpickle==2.2.0  \njsonschema==3.0.1  \nkiwisolver==1.3.1  \nliac-arff==2.5.0  \nlightgbm==3.2.1  \nllvmlite==0.36.0  \nMarkupSafe==2.0.1  \nmatplotlib==3.1.3  \nmore-itertools==6.0.0  \nmsal==1.18.0  \nmsal-extensions==1.0.0  \nmsrest==0.7.1  \nmsrestazure==0.6.4  \nmurmurhash==1.0.7  \nndg-httpsclient==0.5.1  \nnimbusml==1.6.1  \nnumba==0.53.1  \nnumpy @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/numpy_1626681920064\/work  \noauthlib==3.2.0  \nopencensus==0.10.0  \nopencensus-context==0.1.2  \nopencensus-ext-azure==1.1.5  \npackaging==21.3  \npandas==1.0.4  \npathspec==0.9.0  \nPillow==8.3.2  \nplac==0.9.6  \nportalocker==2.5.1  \npreshed==2.0.1  \nprotobuf==3.19.4  \npsutil==5.9.1  \npyarrow==0.16.0  \npyasn1==0.4.8  \npyasn1-modules==0.2.8  \npycparser==2.21  \npycryptodomex==3.7.3  \nPyJWT==2.4.0  \npyOpenSSL==20.0.1  \npyparsing==3.0.9  \npyrsistent==0.18.0  \npython-dateutil==2.8.2  \npytz==2022.1  \nrequests==2.27.1  \nrequests-oauthlib==1.3.1  \nrsa==4.8  \nruamel.yaml==0.16.10  \nruamel.yaml.clib==0.2.6  \nscikit-learn==0.22.2  \nscikit-surprise==1.0.6  \nscipy==1.4.1  \nseaborn==0.10.0  \nSecretStorage==3.3.2  \nshap==0.39.0  \nsix @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work  \nslicer==0.0.7  \nsmart-open==6.0.0  \nspacy==2.1.7  \nsrsly==1.0.5  \nthinc==7.0.8  \ntqdm==4.64.0  \ntyping-extensions==4.1.1  \nurllib3==1.26.10  \nwasabi==0.9.1  \nwebsocket-client==1.3.1  \nWerkzeug==1.0.1  \nwrapt==1.12.1  \nzipp==3.6.0  \n\n2022-07-13T09:30:24,740357515+00:00 | gunicorn\/run |   \n2022-07-13T09:30:24,742081301+00:00 | gunicorn\/run | ###############################################  \n2022-07-13T09:30:24,747351958+00:00 | gunicorn\/run | AzureML Inference Server  \n2022-07-13T09:30:24,750376533+00:00 | gunicorn\/run | ###############################################  \n2022-07-13T09:30:24,752770513+00:00 | gunicorn\/run |   \n2022-07-13T09:30:27,698759963+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.  \n\nAzure ML Inferencing HTTP server v0.4.13  \n\n\nServer Settings  \n---------------  \nEntry Script Name: main.py  \nModel Directory: \/var\/azureml-app\/azureml-models\/amlstudio-loanv1ep002\/1  \nWorker Count: 1  \nWorker Timeout (seconds): 300  \nServer Port: 31311  \nApplication Insights Enabled: false  \nApplication Insights Key: AppInsights key provided  \n\n\nServer Routes  \n---------------  \nLiveness Probe: GET   127.0.0.1:31311\/  \nScore:          POST  127.0.0.1:31311\/score  \n\nStarting gunicorn 20.1.0  \nListening at: http:\/\/0.0.0.0:31311 (17)  \nUsing worker: sync  \nBooting worker with pid: 70  \nCollecting azureml-designer-serving==0.0.10  \n  Downloading azureml_designer_serving-0.0.10-py3-none-any.whl (20 kB)  \nCollecting azureml-contrib-services  \n  Downloading azureml_contrib_services-1.43.0-py3-none-any.whl (4.8 kB)  \nRequirement already satisfied: azureml-defaults in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (1.36.0)  \nRequirement already satisfied: azureml-designer-core[image,model]&gt;=0.0.32 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (0.0.68)  \nRequirement already satisfied: Flask in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (1.0.3)  \nRequirement already satisfied: azureml-core~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.36.0.post2)  \nRequirement already satisfied: json-logging-py==0.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.2)  \nRequirement already satisfied: azureml-inference-server-http~=0.4.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.4.13)  \nRequirement already satisfied: configparser==3.7.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.7.4)  \nRequirement already satisfied: azureml-dataset-runtime[fuse]~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.36.0)  \nRequirement already satisfied: pyarrow==0.16.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (0.16.0)  \nRequirement already satisfied: jsonschema==3.0.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (3.0.1)  \nCollecting numpy==1.18.1  \n  Downloading numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)  \nRequirement already satisfied: pandas==1.0.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (1.0.4)  \nCollecting python-dateutil==2.8.1  \n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)  \nRequirement already satisfied: distro==1.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (1.4.0)  \nRequirement already satisfied: ruamel.yaml==0.16.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (0.16.10)  \nRequirement already satisfied: pycryptodomex==3.7.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (3.7.3)  \nRequirement already satisfied: more-itertools==6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (6.0.0)  \nRequirement already satisfied: Pillow==8.3.2; extra == &quot;image&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (8.3.2)  \nCollecting cloudpickle==1.2.2; extra == &quot;model&quot;  \n  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)  \nRequirement already satisfied: Werkzeug&gt;=0.14 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask-&gt;azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (1.0.1)  \nRequirement already satisfied: Jinja2&gt;=2.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask-&gt;azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (3.0.3)  \nRequirement already satisfied: click&gt;=5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask-&gt;azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (7.1.2)  \nRequirement already satisfied: itsdangerous&gt;=0.24 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask-&gt;azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (1.1.0)  \nRequirement already satisfied: azure-graphrbac&lt;1.0.0,&gt;=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.61.1)  \nRequirement already satisfied: PyJWT&lt;3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.4.0)  \nRequirement already satisfied: jmespath&lt;1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.10.0)  \nRequirement already satisfied: azure-common&lt;2.0.0,&gt;=1.1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.1.28)  \nRequirement already satisfied: azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (13.0.0)  \nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0  \n  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)  \nRequirement already satisfied: jsonpickle&lt;3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.2.0)  \nRequirement already satisfied: azure-mgmt-containerregistry&gt;=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (10.0.0)  \nRequirement already satisfied: ndg-httpsclient&lt;=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.5.1)  \nRequirement already satisfied: docker&lt;6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (5.0.3)  \nRequirement already satisfied: msrestazure&lt;=0.6.4,&gt;=0.4.33 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.6.4)  \nRequirement already satisfied: backports.tempfile in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.0)  \nRequirement already satisfied: pyopenssl&lt;21.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (20.0.1)  \nRequirement already satisfied: azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (11.2.0)  \nRequirement already satisfied: msrest&lt;1.0.0,&gt;=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.7.1)  \nRequirement already satisfied: adal&lt;=1.2.7,&gt;=1.2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.2.7)  \nRequirement already satisfied: azure-mgmt-keyvault&lt;10.0.0,&gt;=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (9.3.0)  \nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.19.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.27.1)  \nRequirement already satisfied: contextlib2&lt;22.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (21.6.0)  \nRequirement already satisfied: SecretStorage&lt;4.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.3.2)  \nRequirement already satisfied: azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.61.0)  \nRequirement already satisfied: pytz in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2022.1)  \nCollecting urllib3&lt;=1.26.7,&gt;=1.23  \n  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)  \nRequirement already satisfied: pathspec&lt;1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.9.0)  \nRequirement already satisfied: opencensus-ext-azure~=1.1.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.1.5)  \nRequirement already satisfied: inference-schema==1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.3.0)  \nRequirement already satisfied: gunicorn==20.1.0; platform_system != &quot;Windows&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (20.1.0)  \nRequirement already satisfied: applicationinsights&gt;=0.11.7 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.11.10)  \nRequirement already satisfied: azureml-dataprep&lt;2.25.0a,&gt;=2.24.0a in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.24.4)  \nRequirement already satisfied: fusepy&lt;4.0.0,&gt;=3.0.1; extra == &quot;fuse&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.0.1)  \nRequirement already satisfied: six&gt;=1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from pyarrow==0.16.0-&gt;azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (1.16.0)  \nRequirement already satisfied: attrs&gt;=17.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1-&gt;azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (21.4.0)  \nRequirement already satisfied: setuptools in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1-&gt;azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (58.0.4)  \nRequirement already satisfied: pyrsistent&gt;=0.14.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1-&gt;azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (0.18.0)  \nRequirement already satisfied: ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &quot;CPython&quot; and python_version &lt; &quot;3.9&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ruamel.yaml==0.16.10-&gt;azureml-designer-core[image,model]&gt;=0.0.32-&gt;azureml-designer-serving==0.0.10) (0.2.6)  \nRequirement already satisfied: MarkupSafe&gt;=2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Jinja2&gt;=2.10-&gt;Flask-&gt;azureml-contrib-services-&gt;azureml-designer-serving==0.0.10) (2.0.1)  \nRequirement already satisfied: cffi&gt;=1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.12.3)  \nRequirement already satisfied: importlib-metadata; python_version &lt; &quot;3.8&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonpickle&lt;3.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (4.8.3)  \nRequirement already satisfied: azure-mgmt-core&lt;2.0.0,&gt;=1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-mgmt-containerregistry&gt;=2.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.3.1)  \nRequirement already satisfied: pyasn1&gt;=0.1.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ndg-httpsclient&lt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.4.8)  \nRequirement already satisfied: websocket-client&gt;=0.32.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from docker&lt;6.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.3.1)  \nRequirement already satisfied: backports.weakref in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from backports.tempfile-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.0.post1)  \nRequirement already satisfied: isodate&gt;=0.6.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest&lt;1.0.0,&gt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.6.1)  \nRequirement already satisfied: azure-core&gt;=1.24.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest&lt;1.0.0,&gt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.24.2)  \nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest&lt;1.0.0,&gt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.3.1)  \nRequirement already satisfied: certifi&gt;=2017.4.17 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest&lt;1.0.0,&gt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2022.6.15)  \nRequirement already satisfied: charset-normalizer~=2.0.0; python_version &gt;= &quot;3&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.0.12)  \nRequirement already satisfied: idna&lt;4,&gt;=2.5; python_version &gt;= &quot;3&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.3)  \nRequirement already satisfied: jeepney&gt;=0.6 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from SecretStorage&lt;4.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.7.1)  \nRequirement already satisfied: opencensus&lt;1.0.0,&gt;=0.10.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.10.0)  \nRequirement already satisfied: psutil&gt;=5.6.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (5.9.1)  \nRequirement already satisfied: azure-identity&lt;2.0.0,&gt;=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.10.0)  \nRequirement already satisfied: wrapt&lt;=1.12.1,&gt;=1.11.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from inference-schema==1.3.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.12.1)  \nRequirement already satisfied: azureml-dataprep-rslex~=2.0.0dev0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep&lt;2.25.0a,&gt;=2.24.0a-&gt;azureml-dataset-runtime[fuse]~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.0.3)  \nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14  \n  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)  \nRequirement already satisfied: azureml-dataprep-native&lt;39.0.0,&gt;=38.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep&lt;2.25.0a,&gt;=2.24.0a-&gt;azureml-dataset-runtime[fuse]~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (38.0.0)  \nRequirement already satisfied: pycparser in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cffi&gt;=1.12-&gt;cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.21)  \nRequirement already satisfied: zipp&gt;=0.5 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version &lt; &quot;3.8&quot;-&gt;jsonpickle&lt;3.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.6.0)  \nRequirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &quot;3.8&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version &lt; &quot;3.8&quot;-&gt;jsonpickle&lt;3.0.0-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (4.1.1)  \nRequirement already satisfied: oauthlib&gt;=3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&lt;1.0.0,&gt;=0.5.1-&gt;azureml-core~=1.36.0-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.2.0)  \nRequirement already satisfied: opencensus-context&gt;=0.1.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.1.2)  \nRequirement already satisfied: google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.8.2)  \nRequirement already satisfied: msal-extensions&lt;2.0.0,&gt;=0.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.0.0)  \nRequirement already satisfied: msal&lt;2.0.0,&gt;=1.12.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.18.0)  \nRequirement already satisfied: contextvars; python_version &gt;= &quot;3.6&quot; and python_version &lt; &quot;3.7&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-context&gt;=0.1.2-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.4)  \nRequirement already satisfied: google-auth&lt;3.0dev,&gt;=1.25.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.9.0)  \nRequirement already satisfied: googleapis-common-protos&lt;2.0dev,&gt;=1.56.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (1.56.3)  \nRequirement already satisfied: protobuf&lt;5.0.0dev,&gt;=3.15.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (3.19.4)  \nRequirement already satisfied: portalocker&lt;3,&gt;=1.0; python_version &gt;= &quot;3.5&quot; and platform_system != &quot;Windows&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msal-extensions&lt;2.0.0,&gt;=0.3.0-&gt;azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (2.5.1)  \nRequirement already satisfied: immutables&gt;=0.9 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from contextvars; python_version &gt;= &quot;3.6&quot; and python_version &lt; &quot;3.7&quot;-&gt;opencensus-context&gt;=0.1.2-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.18)  \nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (0.2.8)  \nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &quot;3.6&quot; in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (4.8)  \nRequirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0; python_version &gt;= &quot;3.6&quot;-&gt;opencensus&lt;1.0.0,&gt;=0.10.0-&gt;opencensus-ext-azure~=1.1.0-&gt;azureml-inference-server-http~=0.4.1-&gt;azureml-defaults-&gt;azureml-designer-serving==0.0.10) (4.2.4)  \nInstalling collected packages: azureml-contrib-services, azureml-designer-serving, numpy, python-dateutil, cloudpickle, cryptography, urllib3, dotnetcore2  \n  Attempting uninstall: numpy  \n    Found existing installation: numpy 1.19.5  \n    Uninstalling numpy-1.19.5:  \n      Successfully uninstalled numpy-1.19.5  \n  Attempting uni\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"problems secure connection",
        "Question_created_time":1656963784913,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/913567\/problems-secure-connection",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How to use safe and protected communication?<\/p>",
        "Question_closed_time":1656964172657,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Your question is too vague for anyone to answer. Can you please elaborate?    <\/p>\n<p>If you are talking about securing Azure Machine Learning you will need to use Virtual Networks (VNet) to protect.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deloyment stuck - with deployment state as Transitioning for over 2 hours.",
        "Question_created_time":1591823291753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/34653\/azure-ml-real-time-inference-endpoint-deloyment-st",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_body":"<p>Hi,  <\/p>\n<p>I  was deploying a real-time inference pipeline into an AKS compute in East US region today. The endpoint deployment state was stuck at Transitioning for over 2 hours and never finished and I had to delete it. A separate deployment to region East US 2 got stuck as well.  I was able to deploy the same pipeline to East US  the day before yesterday.  <\/p>\n<p> I wonder if this is likely an error related to my account\/resources or a system wide issue? Did anyone else encounter the similar issue?  <\/p>\n<p>thanks in advance!  <\/p>",
        "Question_closed_time":1591940540980,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello All,  <\/p>\n<p>We have deployed a fix now to all regions and this should be fixed. Could you please retry and let us know if there are any issues.  <\/p>\n<p>-Rohit<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to write to synapse from ml studio using python SDK?",
        "Question_created_time":1656484327123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/907522\/is-it-possible-to-write-to-synapse-from-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>I am trying to write to Azure SQL database from Azure ML studio. When I create a pipeline in designer, I can use Export Data Component to write data to a table in Azure SQL database. Our platform team has added a datastore with type as Azure SQL database in ML studio workspace. So, I can select the respective datastore, give table name and copy data using export data component in designer.    <\/p>\n<p>However, my intention is to write a Python script to create a pipeline. I don't find any step in ML Python SDK which can be used same as Export data component in designer. I want to write my results generated within the pipeline back to a table in Azure SQL database.    <\/p>\n<p>Solutions tried:    <br \/>\nStoring the result first in blob storage and then using datatransferstep() to copy that result to Azure SQL database. But this can't work for me because it requires ADF instance.    <\/p>\n<p>Is there any other way to directly write to Azure SQL databasein ML Python SDK instead of using datatransferstep and copying to blob storage?    <br \/>\nDue to restricted permissions, I can't create ADF instance to use for datatransferstep.    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to make data working in the Studio",
        "Question_created_time":1657242496467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/918864\/not-able-to-make-data-working-in-the-studio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,    <br \/>\n  I am using Azure classic studio for ML.  Reading large CSV files with 20 columns. One column has a Timestamp which becomes 2.01E+16 after I cleaned the data using Excel.     <\/p>\n<p>  Each time I run it, it says:     <br \/>\n[Information]         In <code>[&lt;-.factor<\/code>(<code>*tmp*<\/code>, ri, value = c(0L, 148L, 50L, 4L, 39L, 5L,  :    <br \/>\n[Information]           invalid factor level, NA generated    <br \/>\n[Stop]     DllModuleMethod::Execute. Duration = 00:09:24.4753205    <br \/>\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:    <\/p>\n<p>----------    <br \/>\n Start of error message from R ----------    <br \/>\nreplacement has 1 row, data has 0    <\/p>\n<p>I used colSums to print it: colSums(is.na(test). It shows this column has 3 na VALUES in data and 2 in test.    <br \/>\nI replace na with test[is.na(test$Timestamp),]$Timestamp&lt;-&quot;2.01E+16&quot;    <br \/>\nStill the same error.    <\/p>\n<p>It's so exhausting to test line by line with no way to debug it to pinpoint exactly where is the problem.    <\/p>\n<p>Plz help!    <br \/>\nNWA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No request body provided or error in deserializing the request body.",
        "Question_created_time":1657494568657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/921005\/no-request-body-provided-or-error-in-deserializing",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <br \/>\n  I used the sample  azure ml web service request in R to send a simple request using     <br \/>\n  library(&quot;jsonlite&quot;) since the rson is not able to install to my R studio:    <\/p>\n<p>req = list(    <\/p>\n<pre><code>    Inputs = list(  \n\n \n        &quot;input1&quot; = list(  \n            &quot;ColumnNames&quot; = list(&quot;Log_Type&quot;, &quot;Ad_Slot_Height&quot;, &quot;Ad_Slot_Visibility&quot;, &quot;Ad_Slot_Floor_Price&quot;),  \n            &quot;Values&quot; = list( list( &quot;1&quot;, &quot;250&quot;, &quot;FirstView&quot;, &quot;0&quot; ),  list( &quot;2&quot;, &quot;90&quot;, &quot;OtherView&quot;, &quot;20&quot; )  )  \n        )                ),  \n    GlobalParameters = setNames(fromJSON('{}'), character(0))  \n<\/code><\/pre>\n<p>)    <br \/>\n Print(body):    <br \/>\n{&quot;Inputs&quot;:{&quot;input1&quot;:{&quot;ColumnNames&quot;:[[&quot;Log_Type&quot;],[&quot;Ad_Slot_Height&quot;],[&quot;Ad_Slot_Visibility&quot;],[&quot;Ad_Slot_Floor_Price&quot;]],&quot;Values&quot;:[[[&quot;1&quot;],[&quot;250&quot;],[&quot;FirstView&quot;],[&quot;0&quot;]],[[&quot;2&quot;],[&quot;90&quot;],[&quot;OtherView&quot;],[&quot;20&quot;]]]}},&quot;GlobalParameters&quot;:{}}     <\/p>\n<p>Why it's not working?    <\/p>\n<p>Plz help asap!    <br \/>\nN.A.W.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Visual Code red underline",
        "Question_created_time":1617894794830,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349688\/visual-code-red-underline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello! I'm studying the Phyton First Steps course and I have questions about the Video Code. When I type &quot;Print&quot; in the code thing it doesn't get a red underline as they said it should. I want to know if I need to enable that type of thing<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"'Error: AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling when submitting experiment",
        "Question_created_time":1657211874993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/918457\/error-aadsts70016-oauth-2-0-device-flow-error-auth",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi I am trying to run an azureml pipeline using a compute instance through Azureml SDK.    <\/p>\n<p>After over 15 minutes of waiting I get the error 'Error: AADSTS70016: OAuth 2.0 device flow error. Authorization is pending' , if I run the same code but with the computer target as local it runs right,    <\/p>\n<p>I know that it is an autetication problem, but it is not clear to me how can I solve it. Thanks for any advice<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to access to the featurized dataset in Automated ML",
        "Question_created_time":1618306428473,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/355323\/how-to-access-to-the-featurized-dataset-in-automat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I\u2019m performing a series of experiments with AutoML and I need to see the featurized data. I mean, not just the new features names retrieved by method get_engineered_feature_names() or the featurization details retrieved by get_featurization_summary(), I refer to the whole transformed dataset, the one obtained after scaling\/normalization\/featurization that is then used to train the models.   <\/p>\n<p>Is it possible to access to this dataset or download it as a file?  <\/p>\n<p>Thanks.  <\/p>",
        "Question_closed_time":1618340955137,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi, currently, we don't store the dataset from scaling\/normalization\/featurization after the run is complete. This feature isn't supported at this time. Sorry for the inconvenience.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure machine learning",
        "Question_created_time":1656618921300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909965\/azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.<\/p>",
        "Question_closed_time":1656632594977,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello @Yasuo-9899     <\/p>\n<p>Thanks for reaching out to us for this question. Are you looking for this document? <a href=\"https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\">https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments<\/a>    <\/p>\n<p>I have found one pic which is described the structure well:    <br \/>\n<img src=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/raw\/main\/images\/workshop-playbook\/media\/image2.png\" alt=\"image2.png\" \/>    <\/p>\n<p>And also a repo you may want to refer to: <a href=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\">https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md<\/a>    <\/p>\n<p>Please let us know more details you are interested in so that we can help. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML Pipeline step gets stuck on Finalizing status, eventually gets marked as failed.",
        "Question_created_time":1657029836827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/914821\/azureml-pipeline-step-gets-stuck-on-finalizing-sta",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>My python file finishes the job( verified in driver logs file), but the step file when finalizing takes lot of time and eventually gets marked as failed step.    <\/p>\n<p>Logs from job post log file    <\/p>\n<p>[2022-07-05T13:44:27.063561] Entering job release    <br \/>\n[2022-07-05T13:44:28.612901] Starting job release    <br \/>\n[2022-07-05T13:44:28.613665] Logging experiment finalizing status in history service.    <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 330    <br \/>\n[2022-07-05T13:44:28.614116] job release stage : upload_datastore starting...    <br \/>\n[2022-07-05T13:44:28.616222] job release stage : start importing azureml.history._tracking in run_history_release.    <br \/>\n[2022-07-05T13:44:28.616341] job release stage : execute_job_release starting...    <br \/>\n[2022-07-05T13:44:28.616970] Entering context manager injector.    <br \/>\n[2022-07-05T13:44:28.626569] job release stage : copy_batchai_cached_logs starting...    <br \/>\n[2022-07-05T13:44:28.626790] job release stage : copy_batchai_cached_logs completed...    <br \/>\n[2022-07-05T13:44:28.631233] job release stage : upload_datastore completed...    <br \/>\n[2022-07-05T13:44:28.894740] job release stage : execute_job_release completed...    <br \/>\n<strong>Failed to set run status: Finalizing    <br \/>\n&lt;urlopen error timed out&gt;<\/strong>    <\/p>\n<p>Retrying...    <br \/>\nFailed to set run status: Finalizing    <br \/>\n&lt;urlopen error timed out&gt;    <\/p>\n<p>Retrying...    <br \/>\n[2022-07-05T13:44:41.757229] job release stage : send_run_telemetry starting...    <br \/>\n[2022-07-05T13:44:41.776454] get vm size and vm region successfully.    <br \/>\n[2022-07-05T13:44:41.783878] get compute meta data successfully.    <br \/>\n<strong>Failed to upload compute record artifact, error_details=&lt;urlopen error [Errno 110] Connection timed out&gt;<\/strong>    <br \/>\n[2022-07-05T13:45:13.220949] job release stage : send_run_telemetry completed...    <br \/>\n[2022-07-05T13:45:13.221247] Job release is complete    <\/p>\n<p>Attached error log screenshots for reference.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/217719-error-logs.png?platform=QnA\" alt=\"217719-error-logs.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/217775-driver-logs.png?platform=QnA\" alt=\"217775-driver-logs.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Got exception when invoking script: 'ImportError: cannot import name 'get_active_cloud''.",
        "Question_created_time":1655043066320,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/885933\/got-exception-when-invoking-script-importerror-can",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <\/p>\n<p>While creating a workspace using below code I am getting &quot;Got exception when invoking script: 'ImportError: cannot import name 'get_active_cloud''.&quot;    <\/p>\n<p>  ws = Workspace.get(name=&quot;myworkspace&quot;,    <br \/>\n               subscription_id='&lt;azure-subscription-id&gt;',  <br \/>\n               resource_group='myresourcegroup')  <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/210584-image.png?platform=QnA\" alt=\"210584-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Numbers of columns of arguments do not match",
        "Question_created_time":1656632530313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/910151\/numbers-of-columns-of-arguments-do-not-match",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>I input data from a zip file that contains 10 cvs files with equals columns that I checked on excel that range from A-T.    <\/p>\n<p>When I run it, it says: numbers of columns of arguments do not match    <\/p>\n<p>Don't know what can I do to check\/correct it.    <\/p>\n<p>Here's the log:    <\/p>\n<p>[Stop]     DllModuleMethod::Execute. Duration = 00:07:15.6892939    <br \/>\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:    <\/p>\n<p>----------    <br \/>\n Start of error message from R ----------    <br \/>\nnumbers of columns of arguments do not match    <\/p>\n<p>numbers of columns of arguments do not match    <\/p>\n<p>-----------    <br \/>\n End of error message from R -----------    <br \/>\n[Critical]     {&quot;InputParameters&quot;:{&quot;Generic&quot;:{&quot;bundlePath&quot;:&quot;..\\..\\Script Bundle\\Script Bundle.zip&quot;,&quot;rLibVersion&quot;:&quot;R344&quot;},&quot;Unknown&quot;:[&quot;Key: rStreamReader, ValueType : System.IO.StreamReader&quot;]},&quot;OutputParameters&quot;:[],&quot;ModuleType&quot;:&quot;LanguageWorker&quot;,&quot;ModuleVersion&quot;:&quot; Version=6.0.0.0&quot;,&quot;AdditionalModuleInfo&quot;:&quot;LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR&quot;,&quot;Errors&quot;:&quot;Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0063: The following error occurred during evaluation of R script:\\r\\n---------- Start of error message from R ----------\\r\\nnumbers of columns of arguments do not match\\r\\n\\r\\n\\r\\nnumbers of columns of arguments do not match\\r\\n----------- End of error message from R -----------\\r\\n   at Microsoft.Analytics.Exceptions.ErrorMapping.Throw(ExceptionID id, Object[] arguments)\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.ExecuteR(NewRWorker worker, DataTable dataset1, DataTable dataset2, IEnumerable<code>1 bundlePath, StreamReader rStreamReader, Nullable<\/code>1 seed) in m:\\AzureMLVS15-004\\_work\\117\\s\\Product\\Source\\Modules\\LanguageWorker\\LanguageWorker.Dll\\EntryPoints\\RModule.cs:line 284\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS._RunImpl(NewRWorker worker, DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable<code>1 seed, ExecuteRScriptExternalResource source, String url, ExecuteRScriptGitHubRepositoryType githubRepoType, SecureString accountToken) in m:\\\\AzureMLVS15-004\\\\_work\\\\117\\\\s\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 208\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.RunRSNR(DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable<\/code>1 seed, ExecuteRScriptRVersion rLibVersion) in m:\\AzureMLVS15-004\\_work\\117\\s\\Product\\Source\\Modules\\LanguageWorker\\LanguageWorker.Dll\\EntryPoints\\REntryPoint.cs:line 97&quot;,&quot;Warnings&quot;:[],&quot;Duration&quot;:&quot;00:07:15.5925361&quot;}    <br \/>\nModule finished after a runtime of 00:07:16.8387443 with exit code -2    <br \/>\nModule failed due to negative exit code of -2    <\/p>\n<p>Thanks,    <br \/>\nN.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use Azure files for model endpoints created in AML hosted on AKS?",
        "Question_created_time":1656329447103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/904580\/how-to-use-azure-files-for-model-endpoints-created",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,     <br \/>\nwe have a complex data processing pipeline, including multiple different Models.    <br \/>\nOne of those models is a GPU-Model, which will be hosted as an API via AML.    <br \/>\nTherefore, we are also using an AKS for the hosting\/compute. This is working fine.    <br \/>\nHowever, the model itself is supposed to use data generated by prior steps.     <br \/>\nDownloading the data from a storage account into the container, is not a good solution.    <br \/>\nWe would like to &quot;mount&quot; the storage account directly and use the data therein (similar to databricks).    <\/p>\n<p>I also know, that for persistent volumes in AKS, you can use Azure Files.     <br \/>\nHowever, normally you set this is up in the AKS and in the deployment-yaml.    <br \/>\nWith AML I did not find a way, to modify the deployments to use persistent volumes.    <br \/>\nIs there really no way? Or did I just not find the documentation for that?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best practice for migration",
        "Question_created_time":1656613684597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909885\/best-practice-for-migration",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Anyone has been migrated to new studio? Please share experience. I am confused about the migration, how should I copy paste my model from studio     <\/p>",
        "Question_closed_time":1656629071167,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I think you are talking about move from Studio classc to Designer, please refer to below document:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <\/p>\n<p>Basically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.    <\/p>\n<p>I am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure-Machine-Learning-Adoption-Framework",
        "Question_created_time":1656615790997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909961\/azure-machine-learning-adoption-framework",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>According to the adoption plan, we need to rebuild everything, there is no quick way to push <a href=\"https:\/\/github.com\/Azure\/Azure-Machine-Learning-Adoption-Framework\">https:\/\/github.com\/Azure\/Azure-Machine-Learning-Adoption-Framework<\/a>    <\/p>\n<p>Am I correct?     <\/p>\n<p>It\u2019s not user friendly if I am not wrong.<\/p>",
        "Question_closed_time":1656630131777,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>    <\/p>\n<p>Thanks for reaching out to us, I have answered this question as well in your other post. I think you are talking about move from Studio classc to Designer, please refer to below document:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <\/p>\n<p>Basically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.    <\/p>\n<p>I am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"OrchestrateJobError - When according to Tutorials about Submit the run to Azure Machine Learning",
        "Question_created_time":1654592788387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/879639\/orchestratejoberror-when-according-to-tutorials-ab",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train<\/a>    <\/p>\n<p>when I submitted the run to Azure Machine Learning according to the tutorials, the computer cluster's status running keep so long, and finally failed.    <br \/>\nThe error info is as fallows:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209042-image.png?platform=QnA\" alt=\"209042-image.png\" \/>    <\/p>\n<p>Service Error:    <br \/>\nAzureMLCompute job failed.    <br \/>\nOrchestrateJobError: Failed to execute command group with error Unexpected CommandError: Failed to pull Docker image <code>CreateImageOptions { from_image: &quot;viennaglobal.azurecr.io\/cap\/hosttools-capability\/installed:eastus2-stable&quot;, from_src: &quot;&quot;, repo: &quot;&quot;, tag: &quot;&quot;, platform: &quot;&quot; }<\/code> due to: Some(ErrorInfo(&quot;received unexpected HTTP status: 500 Operation could not be completed within the specified time.&quot;))    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Compute Cost - Detailed information for each compute",
        "Question_created_time":1654075947357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872840\/azure-machine-learning-compute-cost-detailed-infor",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I need to have the cost detail for each compute (compute instance, compute clusters) configured within Azure Machine Learning.     <br \/>\nRight now from portal I can only retrieve an aggregate cost per compute type, but I need to have the detail per individual compute.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/207380-image.png?platform=QnA\" alt=\"207380-image.png\" \/>    <\/p>\n<p>How can I get this information? Not necessarily from portal, but it's fine via SDK, Rest API, querying logs, etc. Just having this information is enough.    <\/p>\n<p>Thanks!    <\/p>\n<p>G    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML \"Real-time Endpoint Deploy\" not working",
        "Question_created_time":1656130037907,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/903147\/azure-ml-real-time-endpoint-deploy-not-working",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to deploy as Kubernetes service (AKS) on Azure ML studio.    <br \/>\nI get a notification stating &quot;Preparing to deploy&quot;, but Nothing shows up after that. I checked the endpoints list after a while and it is not there either.    <\/p>\n<p>After that &quot;Preparing to deploy&quot; notification I don't receive any success or failure notification.    <\/p>\n<p>If anyone has any solution to this issue, the help is much appreciated.    <\/p>\n<p>I have attached screenshots of the notification and ml pipeline I tried to deploy for context.    <\/p>\n<p>Facing the above issues when using container instances as well...    <\/p>\n<p>The notification:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/214819-screenshot-from-2022-06-25-09-19-31.png?platform=QnA\" alt=\"214819-screenshot-from-2022-06-25-09-19-31.png\" \/>    <\/p>\n<p>The pipeline I tried to deploy:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/214850-screenshot-from-2022-06-25-09-33-08.png?platform=QnA\" alt=\"214850-screenshot-from-2022-06-25-09-33-08.png\" \/>    <\/p>\n<p><strong>Update:<\/strong>    <br \/>\n<em>I think the problem was with the pipeline... I removed the web services, ran the pipeline, then created an inference pipeline from that, and then I was able to deploy using AKS. Although would be good to know the reason behind this... and why this workaround made all the difference<\/em>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Working bicep example for Azure ML environments",
        "Question_created_time":1652269980557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/845199\/working-bicep-example-for-azure-ml-environments",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi<\/p>\n<p>I'm trying to deploy an environment and environment version to Azure ML using Bicep. The documentation doesn't have any examples, and I keep getting an unhelpful error stating:<\/p>\n<p><em>&quot;The response for resource had empty or invalid content.&quot;<\/em><\/p>\n<p>Can anyone provide a working example deploying the following two resources:<\/p>\n<p>Microsoft.MachineLearningServices\/workspaces\/environments@2021-03-01-preview  <br \/>\nMicrosoft.MachineLearningServices\/workspaces\/environments\/versions@2021-03-01-preview<\/p>\n<p>My config is like this and it can successfully deploy the cluster, but not the environment and version:<\/p>\n<pre><code>param location string = resourceGroup().location\n\nresource amlCluster 'Microsoft.MachineLearningServices\/workspaces\/computes@2022-01-01-preview' = {\n  name: 'workspaceA\/cluster'\n  location: location\n  tags: {\n    project: 'projectA'\n  }\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    computeLocation: location\n    computeType: 'AmlCompute'\n    properties: {\n      osType: 'Linux'\n      vmSize: 'STANDARD_D1'\n      scaleSettings: {\n        minNodeCount: 0\n        maxNodeCount: 2\n      }\n      subnet: null\n    }\n  }\n}\n\n\/\/ Create environment\nresource amlEnv 'Microsoft.MachineLearningServices\/workspaces\/environments@2021-03-01-preview' = {\n  name: 'workspaceA\/env'\n  properties: {\n    properties: {}\n    tags: {}\n  }\n\n}\n\nresource amlEnvVersion 'Microsoft.MachineLearningServices\/workspaces\/environments\/versions@2021-03-01-preview' = {\n  name: 'env-version'\n  parent: amlEnv\n  properties: {\n    properties: {}\n    isAnonymous: false\n    docker: {\n        platform: {\n            operatingSystemType: 'Linux'\n        }\n        dockerSpecificationType: 'Image'\n        dockerImageUri: 'mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04'\n    }\n    condaFile: 'conda.yml'\n  }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error running an Azure Experiment script (Azure Notebook)",
        "Question_created_time":1656584703123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909355\/error-running-an-azure-experiment-script-(azure-no",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,     <\/p>\n<p>I am attempting to run an experiment script using Azure Notebooks as per this example,     <br \/>\n<a href=\"https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/04%20-%20Run%20Experiments.ipynb\">https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/04%20-%20Run%20Experiments.ipynb<\/a>    <\/p>\n<p>but receive the following error;    <\/p>\n<p>Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (\/azureml-envs\/sklearn-0.24.1\/lib\/python3.7\/site-packages), Requirement.parse('azure-core&lt;2.0.0,&gt;=1.23.0'), {'azure-mgmt-core'}).    <br \/>\nMSI: Failed to retrieve a token from 'identity-responder-not-enabled\/?resource=https:\/\/management.core.windows.net\/&amp;api-version=2017-09-01' with an error of 'No connection adapters were found for 'identity-responder-not-enabled\/?resource=https:\/\/management.core.windows.net\/&amp;api-version=2017-09-01''.    <br \/>\nPerforming interactive authentication. Please follow the instructions on the terminal.    <br \/>\nTo sign in, use a web browser to open the page <a href=\"https:\/\/microsoft.com\/devicelogin\">https:\/\/microsoft.com\/devicelogin<\/a> and enter the code XXXXXXX to authenticate.    <\/p>\n<p>Could someone please advise a work around.    <\/p>\n<p>Thank you    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to input data(csv) TO R-script model?",
        "Question_created_time":1654040013303,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872215\/how-to-input-data(csv)-to-r-script-model",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <br \/>\n  I loaded all csv files, but R-script only allow two files for input ports. So I zipped all use 7-zip and verifed all files are same as not zipped before and loaded to Azure ml studio and connect it to R-script on 3rd port.  <\/p>\n<p>  Each time I run it, it says no connection, zip file corrupt.  <\/p>\n<p> PLZ point out what is it and how to input datasets?  <\/p>\n<p>Thanks,  <br \/>\nN.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Monitoring",
        "Question_created_time":1656094570340,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/902953\/azure-machine-learning-monitoring",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>How can we setup monitor for Azure Machine Learning pipeline\/job failures ? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"will experiments disappear if I don\u2019t migrate to Designer?",
        "Question_created_time":1654743684097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/882424\/will-experiments-disappear-if-i-don-t-migrate-to-d",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>do I still have the access to it? <\/p>",
        "Question_closed_time":1655315539550,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>     <\/p>\n<p>I hope Rohit's reponse is helpful, please let us know if you have more question. All the data of studio will be avaiable till August 2024, you still have time to decide if you want to keep them, but Designer will provide the same experience and supporting the same function, you may want to try.     <\/p>\n<p>Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to run next step as a graph in azure ai ml sdk2",
        "Question_created_time":1656513973487,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/908194\/how-to-run-next-step-as-a-graph-in-azure-ai-ml-sdk",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am running different steps in azure ai ml using <strong>command<\/strong> api. But they are running in random order. I want to run them sequentially. I don't have any data injection from previous step to next step as I am saving the output of one step on cloud storage and next step will fetch that one once the previous step is finished running. I tried to create fake_op (uri_string) for one step and gave input to the very next step. Doing this I am getting error.    <\/p>\n<pre><code>{'code': data-capability.UriMountSession.UserErrorException, 'message': UserErrorException:  \n\tMessage: DataAccessError(NotFound)  \n\tInnerException None  \n\tErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;code&quot;: &quot;UserError&quot;,  \n        &quot;message&quot;: &quot;DataAccessError(NotFound)&quot;  \n    }  \n}, 'target': , 'category': UserError, 'error_details': [{'key': NonCompliantReason, 'value': UserErrorException:  \n\tMessage: DataAccessError(NotFound)  \n\tInnerException None  \n\tErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;code&quot;: &quot;UserError&quot;,  \n        &quot;message&quot;: &quot;DataAccessError(NotFound)&quot;  \n    }  \n}}, {'key': StackTrace, 'value':   File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py&quot;, line 331, in start  \n    options=mnt_options  \n  \n  File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py&quot;, line 696, in rslex_uri_volume_mount  \n    raise e  \n  \n  File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py&quot;, line 690, in rslex_uri_volume_mount  \n    mount_context = RslexDirectURIMountContext(mount_point, uri, options)  \n}, ], 'inner_error': null}  \n<\/code><\/pre>\n<p>Also, would u suggest to move to azure ml sdk v2 now or should we wait until it is stable.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting an SSL error azureml",
        "Question_created_time":1656434118017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/906759\/getting-an-ssl-error-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm getting this error:     <\/p>\n<p>ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1131)    <\/p>\n<p>urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eastus.api.azureml.ms', port=443): Max retries exceeded with url: \/rp\/workspaces\/subscriptions\/. . .     <\/p>\n<p>while trying to do anything with azureml sdk    <\/p>\n<pre><code>from azureml.core import Workspace  \n  \nws = Workspace.from_config()  \n  \nfor compute_name in ws.compute_targets:  \n    compute = ws.compute_targets[compute_name]  \n    print(compute.name, &quot;:&quot;, compute.type)  \n  \n<\/code><\/pre>\n<p>How would I go about fixing this and running any kind of operation with the azureml-sdk?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure : \"message\": \"Error: Scoring was unsuccessful.\" when we run forecasting.",
        "Question_created_time":1655568786827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/894519\/azure-message-error-scoring-was-unsuccessful-when",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>init() function in score.py is executed properly but I am getting error in run function. As shown in image I am getting  below error.    <\/p>\n<p> <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/212721-error.png?platform=QnA\" alt=\"212721-error.png\" \/> &quot;error&quot;: {    <br \/>\n        &quot;message&quot;: &quot;Error: Scoring was unsuccessful.&quot;  <br \/>\n    }  <\/p>\n<p>Thank you,    <br \/>\nSaswat    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"proportion of ML is in Azure data centers",
        "Question_created_time":1655642379753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/894789\/proportion-of-ml-is-in-azure-data-centers",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Dear Azure Support,    <br \/>\nMy Name is Erim and I study computer sciene in Germany.    <br \/>\nI am currently preparing a presentation on machine learning and energy consumption. Next Friday is the deadline.    <\/p>\n<p>I would like to know how high the proportion of ML is in your data centers, like how many customers use you date centers for ML? Since I could not find any data on this, I am contacting you directly. I hope you can help me    <\/p>\n<p>Best regards    <br \/>\nErim Medi<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how i can recover my compute instance ?",
        "Question_created_time":1655132409567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/887255\/how-i-can-recover-my-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>error: The specified Azure ML Compute Instance cs-bi-cloud2 encountered an unusable node. Please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Suppor    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/210912-image.png?platform=QnA\" alt=\"210912-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"CSC FILE UPLOAD FAILED",
        "Question_created_time":1654643403817,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/880649\/csc-file-upload-failed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi I'm each time I try to upload my csv file its failing.  See error below:  <\/p>\n<p>Error 0030: Error while downloading the file: Error 0039: Error while completing operation: System.Net.WebException: An exception occurred during a WebClient request. ---&gt; Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0078: Http redirection not allowed  <br \/>\n   at Microsoft.Analytics.Exceptions.ErrorMapping.Throw(ExceptionID id, Object[] arguments)  <br \/>\n   at Microsoft.Analytics.Modules.Reader.Dll.HttpReader.HttpWebClient.GetWebResponse(WebRequest request) in m:\\AzureMLVS15-004_work\\117\\s\\Product\\Source\\Modules\\Reader.Dll\\HttpReader.cs:line 265  <br \/>\n   at System.Net.WebClient.DownloadBits(WebRequest request, Stream writeStream, CompletionDelegate completionDelegate, AsyncOperation asyncOp)  <br \/>\n   at System.Net.WebClient.DownloadFile(Uri address, String fileName)  <br \/>\n   --- End of inner exception stack trace ---  <br \/>\n   at System.Net.WebClient.DownloadFile(Uri address, String fileName)  <br \/>\n   at Microsoft.Analytics.Modules.Reader.Dll.HttpReader.DownloadWithRetry(Uri url) in m:\\AzureMLVS15-004_work\\117\\s\\Product\\Source\\Modules\\Reader.Dll\\HttpReader.cs:line 124..  <br \/>\nStart time: UTC 06\/07\/2022 22:59:23  <br \/>\nEnd time: UTC 06\/07\/2022 22:59:26<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to export data from compute instance to Datastore",
        "Question_created_time":1631557345167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/550288\/how-to-export-data-from-compute-instance-to-datast",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I pull in data from a Datastore to the compute instance using the code below. I then do stuff with that data. What I'd like to do is to push the modified data back to the Datastore but I'm not finding the documentation that can show me how this is done.  <\/p>\n<pre><code># Azure management\nfrom azureml.core import Workspace, Dataset\n\n# MetaData\nsubscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\nresource_group = 'xCloudData'\nworkspace_name = 'xCloudML'\n\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\n# Retention_Engagement_CombinedData from cosmos ss\ndataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n\n# Do stuff with data\n...\n\n# Push data back to Datastore\n...\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to export trained azure ml model to production environment",
        "Question_created_time":1656249928277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/903600\/how-to-export-trained-azure-ml-model-to-production",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How we can copying trained azure ml model from dev environment to production. Its possible to use trained model from one resource group to another resource group with same trained data.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Web service REST Type POST in Azure Machine learning from data factory",
        "Question_created_time":1654098119170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/873192\/web-service-rest-type-post-in-azure-machine-learni",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I try to use en the pipe line the web activity i cant to vinculate the dataset, but only with de body its succesfull de calling<\/p>\n<p>{  <br \/>\n&quot;name&quot;: &quot;pipeline1&quot;,  <br \/>\n&quot;properties&quot;: {  <br \/>\n&quot;activities&quot;: [  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Web1&quot;,  <br \/>\n&quot;type&quot;: &quot;WebActivity&quot;,  <br \/>\n&quot;dependsOn&quot;: [],  <br \/>\n&quot;policy&quot;: {  <br \/>\n&quot;timeout&quot;: &quot;7.00:00:00&quot;,  <br \/>\n&quot;retry&quot;: 0,  <br \/>\n&quot;retryIntervalInSeconds&quot;: 30,  <br \/>\n&quot;secureOutput&quot;: false,  <br \/>\n&quot;secureInput&quot;: false  <br \/>\n},  <br \/>\n&quot;userProperties&quot;: [],  <br \/>\n&quot;typeProperties&quot;: {  <br \/>\n&quot;url&quot;: &quot;http:\/\/80a36f92-5b73-4852-8e72-247379fa0bd6.westeurope.azurecontainer.io\/score&quot;,  <br \/>\n&quot;method&quot;: &quot;POST&quot;,  <br \/>\n&quot;body&quot;: {  <br \/>\n&quot;Inputs&quot;: {  <br \/>\n&quot;data&quot;: [  <br \/>\n{  <br \/>\n&quot;Product ID&quot;: &quot;410&quot;,  <br \/>\n&quot;Week&quot;: 24,  <br \/>\n&quot;Year&quot;: 2022,  <br \/>\n&quot;Customer ID&quot;: &quot;3959&quot;,  <br \/>\n&quot;Score&quot;: 12  <br \/>\n}  <br \/>\n]  <br \/>\n},  <br \/>\n&quot;GlobalParameters&quot;: 1  <br \/>\n},  <br \/>\n&quot;datasets&quot;: [  <br \/>\n{  <br \/>\n&quot;referenceName&quot;: &quot;Json2&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n}  <br \/>\n]  <br \/>\n}  <br \/>\n}  <br \/>\n],  <br \/>\n&quot;annotations&quot;: [],  <br \/>\n&quot;lastPublishTime&quot;: &quot;2022-05-20T11:40:24Z&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>Answer: Error Code 2108. user configuration issue. run () got an unexpected keyword argument 'datasets', i use postman and everything ist ok<\/p>\n<p>in other way, in the dataflow i use the external call bur the error its, connection failed. Error Code DFExecutorUserError. Some(list index out of range), Status code: 502. Please check your request url and body.<\/p>\n<p>When i probe the conection in the edit linked service, the test conection its ok. but in the property linked service the conection ist failed<\/p>\n<p>I consume this web service without any problem in power bi.<\/p>\n<p>{  <br \/>\n&quot;name&quot;: &quot;dataflow_RFM&quot;,  <br \/>\n&quot;properties&quot;: {  <br \/>\n&quot;type&quot;: &quot;MappingDataFlow&quot;,  <br \/>\n&quot;typeProperties&quot;: {  <br \/>\n&quot;sources&quot;: [  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;Salmonsurdb&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;TransWeekCPto&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;Salmonsurdb&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;Salmonsurdb&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;PredictData&quot;  <br \/>\n}  <br \/>\n],  <br \/>\n&quot;sinks&quot;: [  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM11&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;SSTransRFM&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM15&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;BStorageSSFRQ&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM14&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM13&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;BStorageSSFRQ&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM12&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFQ10&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM9&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM8&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;BStorageSSFRQ&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM7&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;BStorageSSFRQ&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM6&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM5&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;BStorageSSFRQ&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM4&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;RFM3&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;linkedService&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;AzureBlobStorage1&quot;,  <br \/>\n&quot;type&quot;: &quot;LinkedServiceReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;sink1&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;dataset&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;SSTransRFM&quot;,  <br \/>\n&quot;type&quot;: &quot;DatasetReference&quot;  <br \/>\n},  <br \/>\n&quot;name&quot;: &quot;sink2&quot;  <br \/>\n}  <br \/>\n],  <br \/>\n&quot;transformations&quot;: [  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;externalCall1&quot;,  <br \/>\n&quot;linkedService&quot;: {  <br \/>\n&quot;referenceName&quot;: &quot;RestService1&quot;,  <br \/>\n&quot;type&quot;: &quot;LinkedServiceReference&quot;  <br \/>\n}  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;join1&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;RemoveColumns11&quot;,  <br \/>\n&quot;description&quot;: &quot;Generado autom\u00e1ticamente por acciones de vista previa de datos&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster14&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster15&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster11&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster13&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster12&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster10&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster9&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster8&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster7&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster6&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster5&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster4&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;Cluster3&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;filter1&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;join2&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;RemoveColumns12&quot;,  <br \/>\n&quot;description&quot;: &quot;Autogenerated by data preview actions&quot;  <br \/>\n},  <br \/>\n{  <br \/>\n&quot;name&quot;: &quot;filter2&quot;  <br \/>\n}  <br \/>\n],  <br \/>\n&quot;scriptLines&quot;: [  <br \/>\n&quot;source(output(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; {Product ID} as string,&quot;,  <br \/>\n&quot; Week as integer,&quot;,  <br \/>\n&quot; Year as integer,&quot;,  <br \/>\n&quot; Quantity as decimal(19,4)&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; isolationLevel: 'READ_UNCOMMITTED',&quot;,  <br \/>\n&quot; query: 'SELECT --p.[document no_] AS \\'Sales ID\\',\\n --p.[entry type],\\n p.[source no_] AS \\'Customer ID\\',\\n p.[item no_] AS \\'Product ID\\',\\n --p.[document type] AS \\'Type\\',\\n --p.[posting date] AS \\'Transaction Date\\',\\n Datepart(wk,p.[posting date] ) AS \\'Week\\',\\n Year(p.[posting date] ) AS \\'Year\\',\\n SUM( CONVERT(MONEY, p.[Shipped Qty_ Not Returned]))<em>-1 AS \\'Quantity\\'\\n\\n FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n where p.[document type] = 1\\n GROUP BY p.[document no_],\\n p.[source no_],\\n p.[item no_],\\n p.[document type],\\n p.[posting date],\\n quantity\\n',&quot;,  <br \/>\n&quot; format: 'query') ~&gt; TransWeekCPto&quot;,  <br \/>\n&quot;source(output(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; Recency as integer,&quot;,  <br \/>\n&quot; Frecuency as integer,&quot;,  <br \/>\n&quot; MonetaryValue as decimal(19,4),&quot;,  <br \/>\n&quot; R as long,&quot;,  <br \/>\n&quot; F as long,&quot;,  <br \/>\n&quot; M as long,&quot;,  <br \/>\n&quot; Score as long&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; allowSchemaDrift: false,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; isolationLevel: 'READ_UNCOMMITTED',&quot;,  <br \/>\n&quot; query: 'select RFM.[Customer ID]\\n --,RFM.[Product ID]\\n ,AVG(RFM.[Recency]) AS \\'Recency\\'\\n ,AVG(RFM.[Frecuency]) AS \\'Frecuency\\' \\n ,AVG(RFM.[Sales Amount]) As \\'MonetaryValue\\'\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Recency]) DESC) As \\'R\\'\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Frecuency])ASC) As \\'F\\'\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Sales Amount])ASC) As \\'M\\'\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Recency]) DESC) \\n +NTILE(5) OVER(ORDER BY AVG(RFM.[Frecuency]))\\n +NTILE(5) OVER(ORDER BY AVG(RFM.[Sales Amount])) as \\'Score\\'\\n\\nfrom (\\n-- Consulta con informaci\u00f3n de RFM \\n-- Recency: D\u00edas ultima compra\\n-- Frecuency: Promedio de Frecuencia de compra del cliente Mensual\\n-- SalesAmount: Promedio del valor de la factura de venta Mensual\\n\\n SELECT \\n p.[source no_] AS \\'Customer ID\\'\\n ,p.[item no_] AS \\'Product ID\\'\\n ,p.[document type] AS \\'Type\\'\\n ,year(p.[posting date]) AS \\'TransactionYear\\'\\n ,Month(p.[posting date]) AS \\'TransactionMonth\\'\\n ,max(ti.Recency) AS \\'Recency\\'\\n ,Count(p.[document no_]) AS \\'Frecuency\\'\\n ,SUM(Ve.[Sales Amount]) AS \\'Sales Amount\\' \\n \\n FROM\\n [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n outer apply(\\n select \\n pp.[source no_] AS \\'Customer ID\\'\\n ,pp.[item no_] AS \\'Product ID\\'\\n ,datediff(day,max(pp.[posting date]), getdate()) AS \\'Recency\\'\\n From [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] pp\\n where pp.[source no_] = p.[source no_] \\n and pp.[item no_] = p.[item no_]\\n \\n group by pp.[source no_] , pp.[item no_]\\n ) ti\\n \\n \\n LEFT OUTER JOIN ( SELECT [Item Ledger Entry No_]\\n , Iif( Sum(CONVERT(MONEY, [Sales Amount (Actual)], 0)) = 0, \\n Sum(CONVERT(MONEY, [Sales Amount (Expected)], 0)), \\n Sum(CONVERT(MONEY, [Sales Amount (Actual)], 0))) AS \\'Sales Amount\\'\\n ,Iif(CONVERT(MONEY, Sum([Cost Amount (Actual)]), 0) = 0,\\n CONVERT(MONEY, Sum([Cost Amount (Expected)]), 0),\\n CONVERT(MONEY, Sum([Cost Amount (Actual)]), 0)) AS \\'Cost amount\\'\\n ,CONVERT(MONEY, Sum([Discount Amount]), 0) AS \\'Discount amount\\'\\n FROM [salmonsur,s_a_$value entry$437dbf0e-84ff-417a-965d-ed2bb9650972] \\n GROUP BY [Item Ledger Entry No_]\\n ) Ve\\n ON p.[entry no_]= Ve.[Item Ledger Entry No_]\\n\\n \\n\\n where --p.[source no_] = \\'2772\\' \\n --and p.[item no_] = \\'215\\' and\\n p.[posting date] &gt;= DATEADD(month,-12,GETDATE())\\n and p.[document type] = \\'1\\'\\n\\n GROUP BY \\n p.[source no_],\\n p.[item no_],\\n p.[document type],\\n Year(p.[posting date]),\\n Month(p.[posting date])\\n )RFM\\n\\n--Where RFM.[Customer ID] = \\'2772\\' \\n\\nGroup by\\n RFM.[Customer ID]\\n --,RFM.[Product ID]\\n\\n--Order by RFM.[Customer ID]\\n \\n',&quot;,  <br \/>\n&quot; format: 'query',&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM&quot;,  <br \/>\n&quot;source(output(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; {Product ID} as string,&quot;,  <br \/>\n&quot; Week as integer,&quot;,  <br \/>\n&quot; Year as integer&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; isolationLevel: 'READ_UNCOMMITTED',&quot;,  <br \/>\n&quot; query: 'select A.[Customer ID] AS \\'Customer ID\\'\\n ,a.[Product ID] AS \\'Product ID\\'\\n ,Datepart(wk,B.[Transaction Date]) As \\'Week\\'\\n ,year(B.[Transaction Date]) As \\'Year\\'\\n , \\'1\\' as \\'Predict\\'\\n\\nfrom (\\n\\n SELECT p.[source no_] AS \\'Customer ID\\'\\n ,p.[item no_] AS \\'Product ID\\'\\n --convert(date, p.[posting date]) AS \\'Transaction Date\\',\\n --Datepart(wk,p.[posting date] ) AS \\'Week\\',\\n --Year(p.[posting date] ) AS \\'Year\\',\\n --SUM(CONVERT(MONEY, p.[Shipped Qty_ Not Returned]))<\/em>-1 AS \\'Quantity\\'\\n\\n FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n where p.[document type] = 1\\n GROUP BY p.[source no_],\\n p.[item no_]\\n ) A, \\n (\\n select convert(date, max(p.[posting date])+8) AS \\'Transaction Date\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n UNION ALL\\n select convert(date, max(p.[posting date])+16) AS \\'Transaction Date\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n UNION ALL\\n select convert(date, max(p.[posting date])+24) AS \\'Transaction Date\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n UNION ALL\\n select convert(date, max(p.[posting date])+32) AS \\'Transaction Date\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\n )B\\n',&quot;,  <br \/>\n&quot; format: 'query') ~&gt; PredictData&quot;,  <br \/>\n&quot;filter2 call(output(&quot;,  <br \/>\n&quot; headers as [string,string],&quot;,  <br \/>\n&quot; status as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; allowSchemaDrift: true,&quot;,  <br \/>\n&quot; format: 'rest',&quot;,  <br \/>\n&quot; store: 'restservice',&quot;,  <br \/>\n&quot; timeout: 5,&quot;,  <br \/>\n&quot; requestInterval: 5000,&quot;,  <br \/>\n&quot; httpMethod: 'POST',&quot;,  <br \/>\n&quot; headerColumnName: 'headers',&quot;,  <br \/>\n&quot; statusColumnName: 'status',&quot;,  <br \/>\n&quot; addResponseCode: true,&quot;,  <br \/>\n&quot; requestFormat: ['type' -&gt; 'json'],&quot;,  <br \/>\n&quot; responseFormat: ['type' -&gt; 'json', 'documentForm' -&gt; 'arrayOfDocuments']) ~&gt; externalCall1&quot;,  <br \/>\n&quot;TransWeekCPto, RFM join(TransWeekCPto@{Customer ID} == RFM@{Customer ID},&quot;,  <br \/>\n&quot; joinType:'right',&quot;,  <br \/>\n&quot; broadcast: 'auto')~&gt; join1&quot;,  <br \/>\n&quot;join1 select(mapColumn(&quot;,  <br \/>\n&quot; {Customer ID} = TransWeekCPto@{Customer ID},&quot;,  <br \/>\n&quot; {Product ID},&quot;,  <br \/>\n&quot; Week,&quot;,  <br \/>\n&quot; Year,&quot;,  <br \/>\n&quot; Quantity,&quot;,  <br \/>\n&quot; Score&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true) ~&gt; RemoveColumns11&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 14) ~&gt; Cluster14&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 15) ~&gt; Cluster15&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 11) ~&gt; Cluster11&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 13) ~&gt; Cluster13&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 12) ~&gt; Cluster12&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 10) ~&gt; Cluster10&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 9) ~&gt; Cluster9&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 8) ~&gt; Cluster8&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 7) ~&gt; Cluster7&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 6) ~&gt; Cluster6&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 5) ~&gt; Cluster5&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 4) ~&gt; Cluster4&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='' &amp;&amp; Score == 3) ~&gt; Cluster3&quot;,  <br \/>\n&quot;RemoveColumns11 filter({Customer ID}!='') ~&gt; filter1&quot;,  <br \/>\n&quot;PredictData, RFM join(PredictData@{Customer ID} == RFM@{Customer ID},&quot;,  <br \/>\n&quot; joinType:'right',&quot;,  <br \/>\n&quot; partitionBy('hash', 1),&quot;,  <br \/>\n&quot; broadcast: 'auto')~&gt; join2&quot;,  <br \/>\n&quot;join2 select(mapColumn(&quot;,  <br \/>\n&quot; {Product ID},&quot;,  <br \/>\n&quot; Week,&quot;,  <br \/>\n&quot; Year,&quot;,  <br \/>\n&quot; {Customer ID},&quot;,  <br \/>\n&quot; Score,&quot;,  <br \/>\n&quot; {Customer ID} = PredictData@{Customer ID}&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true) ~&gt; RemoveColumns12&quot;,  <br \/>\n&quot;RemoveColumns12 filter({Customer ID}!='') ~&gt; filter2&quot;,  <br \/>\n&quot;Cluster11 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM11.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM11&quot;,  <br \/>\n&quot;filter1 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['TransRFM.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; SSTransRFM&quot;,  <br \/>\n&quot;Cluster15 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM15.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM15&quot;,  <br \/>\n&quot;Cluster14 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; Column_1 as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM14.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM14&quot;,  <br \/>\n&quot;Cluster13 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM13.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM13&quot;,  <br \/>\n&quot;Cluster12 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; Column_1 as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM12.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM12&quot;,  <br \/>\n&quot;Cluster10 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM10.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFQ10&quot;,  <br \/>\n&quot;Cluster9 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM9.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM9&quot;,  <br \/>\n&quot;Cluster8 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM8.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM8&quot;,  <br \/>\n&quot;Cluster7 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; Column_1 as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM7.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM7&quot;,  <br \/>\n&quot;Cluster6 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; Column_1 as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM6.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM6&quot;,  <br \/>\n&quot;Cluster5 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM5.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM5&quot;,  <br \/>\n&quot;Cluster4 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; Column_1 as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM4.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM4&quot;,  <br \/>\n&quot;Cluster3 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFM3.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; header: ([\\&quot;Customer ID, Product ID, Week, Year, Quantity, Score\\&quot;]),&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; RFM3&quot;,  <br \/>\n&quot;filter2 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; format: 'json',&quot;,  <br \/>\n&quot; container: 'azureml-blobstore-282b5a81-86c2-4495-83cf-ebc234b5549c',&quot;,  <br \/>\n&quot; folderPath: 'RFM',&quot;,  <br \/>\n&quot; partitionFileNames:['jsonPredict'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; sink1&quot;,  <br \/>\n&quot;filter2 sink(allowSchemaDrift: true,&quot;,  <br \/>\n&quot; validateSchema: false,&quot;,  <br \/>\n&quot; input(&quot;,  <br \/>\n&quot; {Customer ID} as string,&quot;,  <br \/>\n&quot; { Product ID} as string,&quot;,  <br \/>\n&quot; { Week} as string,&quot;,  <br \/>\n&quot; { Year} as string,&quot;,  <br \/>\n&quot; { Quantity} as string,&quot;,  <br \/>\n&quot; { Score} as string&quot;,  <br \/>\n&quot; ),&quot;,  <br \/>\n&quot; partitionFileNames:['RFMPredict.csv'],&quot;,  <br \/>\n&quot; skipDuplicateMapInputs: true,&quot;,  <br \/>\n&quot; skipDuplicateMapOutputs: true,&quot;,  <br \/>\n&quot; partitionBy('hash', 1)) ~&gt; sink2&quot;  <br \/>\n]  <br \/>\n}  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Tabular data from a SQL datastore already in Azure ML in the pipeline",
        "Question_created_time":1655995821250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/901060\/using-tabular-data-from-a-sql-datastore-already-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have a dataset, Tabular type, created from a SQL connection in AzureML.    <br \/>\nNow I can consume the table inside my python script using Workspace credentials.    <\/p>\n<pre><code>dataset = Dataset.get_by_name(workspace, name='.....')  \ndataset.to_pandas_dataframe()  \n<\/code><\/pre>\n<p>I would like to use this table as an input (possibly as a uri_file or mltable) in my pipeline, but the only mode that works is direct. In direct mode, the input I get inside the job is just a url of the table.    <br \/>\nHow can I mount or download this kind of Tables directly in a job, like blob storage files or folders?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/214388-image.png?platform=QnA\" alt=\"214388-image.png\" \/>    <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AML - Diagnostic Logs AmlModelsEvent not collected",
        "Question_created_time":1655976210980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/900632\/azure-aml-diagnostic-logs-amlmodelsevent-not-colle",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\nI have configured a DiagnosticLogs setting in my AML resource, but when I check within the Log Analytcs Workspace I see all logs but no AmlModelsEvent.    <br \/>\nI tested by accessing my AML models and modifyng them. Why I cannot see these logs?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use blob storage file as input to azure ml endpoint",
        "Question_created_time":1655374179990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/891865\/how-to-use-blob-storage-file-as-input-to-azure-ml",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have big data that I need to pass it to already trained Machine Learning model on Azure and has been deployed as online endpoint, I realize that batch endpoints supports adding a reference to blob file as input, my question is: how to do the same for online enpdoints ?    <\/p>\n<p>So far all examples I see are passing the payload as json (Even in the test tab of the online enpoints) but i don't know how to simply pass a blob storage file's uri as the payload.<\/p>",
        "Question_closed_time":1656051612080,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=a66ab675-b0e9-4f63-b57d-101663c4aaa0\">@Mostafa Mansour  <\/a> Thanks for the question. I have checked internally with the product team, Currently Online endpoints are for Realtime synchronous requests.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"error - unable to find ggplot function",
        "Question_created_time":1655169164353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/887802\/error-unable-to-find-ggplot-function",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, could  assist to advise me?     <br \/>\nR-script in Azure machine.    <\/p>\n<p>error message: unable to find ggplot function.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211041-error-message.png?platform=QnA\" alt=\"211041-error-message.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connecting to an existing Databricks Cluster in AMLS",
        "Question_created_time":1654614267930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/880189\/connecting-to-an-existing-databricks-cluster-in-am",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>we have also found this example of using <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-use-databricks-as-compute-target.ipynb\">Databricks as a Compute Target for an Azure Machine Learning Pipeline<\/a>.  <\/p>\n<p>However, we want to use an existing Databricks Cluster as compute target within Azure Machine Learning Studio for our Azure Machine Learning Pipeline.  <br \/>\nCould you help us in accomplishing this, please?  <\/p>\n<p>With best regards  <br \/>\nAlex  <\/p>",
        "Question_closed_time":1654664851167,
        "Answer_score_count":0.0,
        "Answer_comment_count":10.0,
        "Answer_body":"<p>@AlexanderPakakis-0994 Are you looking at adding the cluster from the UI of ML studio rather than using the SDK as mentioned in the notebook you referenced?    <br \/>\nIf Yes, you need to add the same attached compute.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209283-image.png?platform=QnA\" alt=\"209283-image.png\" \/>    <\/p>\n<p>Once you select Azure Databricks the following option to add the existing databricks workspace is seen.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209260-image.png?platform=QnA\" alt=\"209260-image.png\" \/>    <\/p>\n<p>I hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Run experiment crashes when using a pre-build Docker image as environment",
        "Question_created_time":1654697991800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/881670\/run-experiment-crashes-when-using-a-pre-build-dock",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I duplicated my <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/737518\/run-experiment-fails-when-using-a-pre-build-docker.html\">question<\/a> because I have not received a proper answer, yet.    <br \/>\nThe reason why I duplicated the question is that I need to implement something within Azure for a customer where I need to use a pre-build Docker image as an environment.    <br \/>\nUnfortunately, it is not working because AMLS cannot download the pre-build Docker image when you need credentials for downloading the pre-build Docker image.    <br \/>\nIn my opinion, the credentials for using the pre-build Docker image are not saved correctly in Azure Machine Learning Studio. This is the reason why AMLS cannot download the pre-build Docker image. I will be very grateful if someone can test the code snippets below and give me feedback if they worked or not.    <\/p>\n<p>Here is the backstory:    <br \/>\nMy co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.    <br \/>\nIn a separate script, they have registered these environments with the command <code>myenv.register(workspace=ws)<\/code>. In another script, I should use their environment for testing our model.    <\/p>\n<p>In order to get one of their environments, I use the command  <code>registered_env = Environment.get(ws, 'the-specific-environment-name')<\/code>    <\/p>\n<p>Unfortunately, this does not work when I use <code>registered_env<\/code> for the experiment. I get the error &quot;Authentication failed for container registry name_of_their_container_registry.azurecr.io&quot;. The experiment run works perfectly when I copy their environment definition code into my script instead of using the command  <code>registered_env = Environment.get(ws, 'the-specific-environment-name')<\/code>.    <\/p>\n<p>However, I cannot copy every time their environment definition code into my script.    <br \/>\nHow can I get the environment into my script which has been defined in another script?    <\/p>\n<p>This StackOverFlow post is quite related to my problem:    <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\">https:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der<\/a>    <\/p>\n<p>To illustrate what my problem is, here are some code samples.    <\/p>\n<p>This code sample is working:    <\/p>\n<pre><code>registry = ContainerRegistry()  \nregistry.address = &lt;DockerRegistryAddress&gt;  \nregistry.username = &lt;UserName&gt;  \nregistry.password = &lt;Password&gt;  \nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)  \n  \nexemplarily_env_docker_image.python.user_managed_dependencies = True  \n  \n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved  \nexemplarily_env_docker_image.register(workspace=ws)  \n\nmodel = Model(ws, 'exemplarily_model')  \n  \ninference_config = InferenceConfig(environment=exemplarily_env_docker_image,   \n                                   source_directory='.\/source_dir',   \n                                   entry_script='.\/score.py')   \n\n\ndeployment_config = LocalWebservice.deploy_configuration(port=6789)  \n  \nservice = Model.deploy(  \n    ws,  \n    &quot;myservice&quot;,  \n    [model],  \n    inference_config,  \n    deployment_config,  \n    overwrite=True,  \n)  \n  \nservice.wait_for_deployment(show_output=True)  \nprint(service.get_logs())  \n<\/code><\/pre>\n<p>Now, I do a small change and the code sample is <strong>not<\/strong> working anymore:    <\/p>\n<pre><code>registry = ContainerRegistry()  \nregistry.address = &lt;DockerRegistryAddress&gt;  \nregistry.username = &lt;UserName&gt;  \nregistry.password = &lt;Password&gt;  \nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)  \n  \nexemplarily_env_docker_image.python.user_managed_dependencies = True  \n\n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved  \nexemplarily_env_docker_image.register(workspace=ws)  \n\nmodel = Model(ws, 'exemplarily_model')  \n  \nreg_env = Environment.get(ws, &quot;exemplarily-env_Docker-image-AzureRegistry&quot;)  \ninference_config = InferenceConfig(environment=reg_env,   \n                                   source_directory='.\/source_dir',   \n                                   entry_script='.\/score.py')   \n  \ndeployment_config = LocalWebservice.deploy_configuration(port=6789)  \n  \nservice = Model.deploy(  \n    ws,  \n    &quot;myservice&quot;,  \n    [model],  \n    inference_config,  \n    deployment_config,  \n    overwrite=True,  \n)  \n  \nservice.wait_for_deployment(show_output=True)  \nprint(service.get_logs())  \n<\/code><\/pre>\n<p>What is working:    <\/p>\n<pre><code>registry = ContainerRegistry()  \nregistry.address = &lt;DockerRegistryAddress&gt;  \nregistry.username = &lt;UserName&gt;  \nregistry.password = &lt;Password&gt;  \nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)  \n  \nexemplarily_env_docker_image.python.user_managed_dependencies = True  \n\n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved  \nexemplarily_env_docker_image.save_to_directory(path=&quot;.\/env&quot;, overwrite=True)  \n\nmodel = Model(ws, 'exemplarily_model')  \n  \nreg_env = Environment.load_from_directory(path=&quot;.\/env&quot;)  \ninference_config = InferenceConfig(environment=reg_env,   \n                                   source_directory='.\/source_dir',   \n                                   entry_script='.\/score.py')   \n  \ndeployment_config = LocalWebservice.deploy_configuration(port=6789)  \n  \nservice = Model.deploy(  \n    ws,  \n    &quot;myservice&quot;,  \n    [model],  \n    inference_config,  \n    deployment_config,  \n    overwrite=True,  \n)  \n  \nservice.wait_for_deployment(show_output=True)  \nprint(service.get_logs())  \n<\/code><\/pre>\n<p>Why is the middle code sample not working? Is this a bug?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the difference between uri_file and uri_folder in components?",
        "Question_created_time":1655434518570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/892897\/what-is-the-difference-between-uri-file-and-uri-fo",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>What is the difference between uri_file and uri_folder in components?    <\/p>\n<p>No matter I specify <code>uri_file<\/code> or <code>uri_folder<\/code> in a component input\/output type, in Azure ML Studio jobs it is displayed as <code>uri_folder<\/code> and I still need to manually append a file name to the path derefernced by <code>uri_file<\/code> to access a single file. Is there any convenience or difference to specify <code>uri_file<\/code> if I only intend to access a single file?<\/p>",
        "Question_closed_time":1655861438640,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks.    <br \/>\nWe are planning for some smart deduction or inheriting the type from component to job runtime, we still have some open questions that need to close.    <br \/>\nAlso, we will add doc\/sample explicitly call out the default type in job level.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Request help with Azure machine learning workspace",
        "Question_created_time":1655371059130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/891716\/request-help-with-azure-machine-learning-workspace",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have enrolled myself in Azure Machine Learning course and the first step there is to create an azure ML workspace with subscription, resource group, region, storage account etc. I am a new joiner and I am doing this for my learning. Not sure which option to select. Is there any guidance or doc to follow? I have checked with my team and they are suggesting to use my personal account to get a demo account and free azure subscription to do the course and not my microsoft credentials. Require assistance in this regard.<\/p>",
        "Question_closed_time":1655384032827,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=149f8035-b796-4252-b4c0-40b562c68c91\">@Sanjana Das  <\/a>  Thanks for the question. Here is the document to Create workspace resources you need to get started with Azure Machine Learning. You can use your personal account to get free azure subscription.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources<\/a>    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning - Deploy model with DockerFile",
        "Question_created_time":1654794549783,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/883631\/azure-machine-learning-deploy-model-with-dockerfil",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I'm trying to deploy a model with the azure-cli-ml with the following command:    <\/p>\n<p>az ml model deploy --name local-test-endpoint --model name:version --compute-type local --ic inference_config.json --dc deployment_config_local.json -g rg --workspace-name amw    <\/p>\n<p>with the following inference configuration:    <\/p>\n<p>inference_config.json    <\/p>\n<pre><code>{  \n    &quot;entryScript&quot;: &quot;score.py&quot;,  \n    &quot;environment&quot;: {  \n        &quot;docker&quot;: {  \n            &quot;arguments&quot;: [],  \n            &quot;baseDockerfile&quot;: &quot;dockerFile&quot;,  \n            &quot;baseImage&quot;: null,  \n            &quot;enabled&quot;: true,  \n            &quot;sharedVolumes&quot;: true,  \n            &quot;shmSize&quot;: &quot;2g&quot;  \n        },  \n        &quot;name&quot;: &quot;test-environment&quot;,  \n        &quot;python&quot;: {  \n            &quot;baseCondaEnvironment&quot;: null,  \n            &quot;condaDependencies&quot;: {  \n                &quot;channels&quot;: [  \n                    &quot;conda-forge&quot;  \n                ],  \n                &quot;dependencies&quot;: [  \n                    &quot;python=3.7&quot;  \n                ],  \n                &quot;name&quot;: &quot;project_environment&quot;  \n            },  \n            &quot;condaDependenciesFile&quot;: null,  \n            &quot;interpreterPath&quot;: &quot;python&quot;,  \n            &quot;userManagedDependencies&quot;: false  \n        },  \n        &quot;version&quot;: &quot;1&quot;  \n    }  \n}  \n<\/code><\/pre>\n<p>and this is the dockerFile:    <\/p>\n<pre><code>FROM pytorch\/pytorch:1.11.0-cuda11.3-cudnn8-runtime  \n  \nRUN pip install \\  \n    'azureml-mlflow==1.37.0' \\  \n    'mlflow-skinny' \\  \n    'pytorch-accelerated&gt;=0.1.22' \\  \n    'torchmetrics&gt;=0.7.2' \\  \n    'func_to_script' \\  \n    'albumentations==1.1.0' \\  \n    'pandas==1.3.4' \\  \n    'matplotlib' \\  \n    'sklearn'  \n  \n<\/code><\/pre>\n<p>Running the deploy command I get the following error message:    <\/p>\n<p>Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).    <br \/>\nfatal: not a git repository (or any parent up to mount point \/)    <br \/>\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).    <br \/>\nunexpected dockerfile format    <br \/>\nfailed to run step ID: acb_step_0: failed to scan dependencies: exit status 1    <\/p>\n<p>I get the same error even deploying to ACI and AKS.    <br \/>\nWhat am I doing wrong in the configuration?    <\/p>\n<p>Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to change Sklearn flavors version in mlflow on azure machine learning?",
        "Question_created_time":1655725906710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/895819\/how-to-change-sklearn-flavors-version-in-mlflow-on",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I need to change the flavors &quot;sklearn_version&quot; in mlflow from &quot;0.22.1&quot; to &quot;1.0.0&quot; on azure machine learning when I log my trained model, since this model will be incompatible with the sklearn version that I am using for deployment during inference. I could change the version of conda by setting &quot;conda_env&quot; in     <\/p>\n<pre><code>   mlflow.sklearn.log_model(conda_env= 'my_env')  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/212868-conda-yml.png?platform=QnA\" alt=\"212868-conda-yml.png\" \/>    <\/p>\n<p>in the conda.yaml file, however it still remains unchanged in flavors in MLmodel file     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/212869-mlmodel.png?platform=QnA\" alt=\"212869-mlmodel.png\" \/>    <\/p>\n<p>and here is script that I use to create this mlflow experiment in azure machine learning notebooks.     <\/p>\n<pre><code>import mlflow  \nfrom sklearn.tree import DecisionTreeRegressor  \n  \nfrom azureml.core import Workspace  \nfrom azureml.core.model import Model  \nfrom azureml.mlflow import register_model  \n  \n  \ndef run_model(ws, experiment_name, run_name, x_train, y_train):  \n      \n    # set up MLflow to track the metrics  \n    mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())  \n    mlflow.set_experiment(experiment_name)    \n      \n    with mlflow.start_run(run_name=run_name) as run:  \n          \n        # fit model  \n        regression_model = DecisionTreeRegressor()  \n        regression_model.fit(x_train, y_train)  \n\t  \n\t    # log training score   \n        training_score = regression_model.score(x_train, y_train)  \n        mlflow.log_metric(&quot;Training score&quot;, training_score)  \n  \n        my_conda_env = {  \n                    &quot;name&quot;: &quot;mlflow-env&quot;,  \n                    &quot;channels&quot;: [&quot;conda-forge&quot;],  \n                    &quot;dependencies&quot;: [  \n                        &quot;python=3.8.5&quot;,  \n                        {  \n                            &quot;pip&quot;: [  \n                                &quot;pip&quot;,  \n                                &quot;scikit-learn~=1.0.0&quot;,  \n                                &quot;uuid==1.30&quot;,  \n                                &quot;lz4==4.0.0&quot;,  \n                                &quot;psutil==5.9.0&quot;,  \n                                &quot;cloudpickle==1.6.0&quot;,  \n                                &quot;mlflow&quot;,  \n                            ],  \n                        },  \n                    ],  \n                }  \n  \n          \n        # register the model  \n        mlflow.sklearn.log_model(regression_model, &quot;model&quot;, conda_env=my_conda_env)  \n  \n    model_uri = f&quot;runs:\/{run.info.run_id}\/model&quot;  \n    model = mlflow.register_model(model_uri, &quot;sklearn_regression_model&quot;)  \n  \nif __name__ == '__main__':  \n  \n    # connect to your workspace  \n    ws = Workspace.from_config()  \n  \n    # create experiment and start logging to a new run in the experiment  \n    experiment_name = &quot;exp_name&quot;  \n  \n    # mlflow run name  \n    run_name= '1234'  \n  \n    \n    # get train data  \n    x_train, y_train  = get_train_data()  \n      \n    run_model(ws, experiment_name, run_name, x_train, y_train)  \n  \n<\/code><\/pre>\n<p>Any idea how can change the flavor sklearn version in &quot;MLmodel&quot; file in my script?     <\/p>\n<p>With many thanks in advance!     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Proxy Support on AML Compute Instance and Compute Clusters",
        "Question_created_time":1655714307587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/895509\/proxy-support-on-aml-compute-instance-and-compute",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Currently , AML CIs and Clusters do not support proxy configuration. So we are forced to use firewall for the outbound internet access. When we use a firewall using whitelist approach is best way however it is suitable for the AML CIs and CCs given the large number  of URLs used by the Data scientist. The need of the hour is the proxy configuration support on the AML CIs and CCs.  Can we have proxy  support asap ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to install python package in hardware accelerated GPU spark pool ?",
        "Question_created_time":1654683175267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/881432\/how-to-install-python-package-in-hardware-accelera",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I've a azure synapse analytics workspace in region North Europe, as the region has hardware Accelerated pools, GPU base pools so to say. But i don't see the packages setting.     <br \/>\nhere is the comparison for 2 workspace, 1 in north Europe and other one in West Europe.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209418-screenshot-2022-06-08-at-120209.png?platform=QnA\" alt=\"209418-screenshot-2022-06-08-at-120209.png\" \/> vs <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209494-screenshot-2022-06-08-at-120550.png?platform=QnA\" alt=\"209494-screenshot-2022-06-08-at-120550.png\" \/>    <\/p>\n<p>Even the package setting in the Workspace itself is disabled for me: here is the screenshot.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209434-screenshot-2022-06-08-at-120143.png?platform=QnA\" alt=\"209434-screenshot-2022-06-08-at-120143.png\" \/>    <\/p>\n<p>I've 2 questions in this reagrd:     <\/p>\n<ul>\n<li> Am I missing any configuration for the GPU pool or this feature is not released?    <\/li>\n<li> Is there any alternate way to install a package? <code>pip install<\/code> or <code>pip3 install<\/code> are not working.      <\/li>\n<\/ul>",
        "Question_closed_time":1654770659817,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=f236076b-e057-4c60-b0fd-0068a6492053\">@Prateek Narula  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>(UPDATE:6\/10\/2022): Unfortunately, we do not have Library Management (Package) support for GPU spark pools in Azure Synapse Analytics.    <\/p>\n<\/blockquote>\n<p>---------------------------------------------------    <\/p>\n<p>As per the repro, I had noticed similar behaviour.     <\/p>\n<blockquote>\n<p>Looks like packages are only supported for Node size family: &quot;Memory Optimized&quot; - let me get a confirmation from the product team.    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209808-synape-gpu.gif?platform=QnA\" alt=\"209808-synape-gpu.gif\" \/>    <\/p>\n<p>We are reaching out to internal team to get more information related to this issue and will get back to you as soon as we have an update.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is there any limitations for the number of runs per user in each experiment in Azure ML?",
        "Question_created_time":1654530231357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/878540\/is-there-any-limitations-for-the-number-of-runs-pe",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I and my team members are working on a machine learning project through the Azure ML portal. We have created a specific experiment in our workspace in Azure ML and are submitting our Python script runs from our local or remote machines in this experiment.  <\/p>\n<p>Although I'm collaborating with my colleagues, most of the runs in this specific experiment are submitted by me.  <\/p>\n<p>Recently, I have faced a problem with experiment submissions. The problem is that after some number of experiments created by me, I cannot add any other runs to this experiment, but my colleagues can!!!  <\/p>\n<p>Unfortunately, the Azure ML portal does not show any clear error message for this problem. It continues submitting the run till a timeout exception occurs!  <\/p>\n<p>As a temporary solution, I've just changed the name of the experiment and I could conquer this problem.  <\/p>\n<p>This solution helped me to submit my run on Azure ML but it didn\u2019t satisfy me because. We want to collect all related runs under a specific experiment. On the other hand creating multiple number of experiments for each run is overwhelming!  <\/p>\n<p>What I know is that there are some service limits for the number of runs in a workspace on this page. I am sure that the number of runs in our workspace has not reached to the 10 millions, because I can created new runs under new experiments dashboard. But I don\u2019t know anything about the limitations on the number of runs in a specific experiment or even any limitations for the number of runs per users in a specific experiment. I couldn't find any clear document explaining this fact.  <\/p>\n<p>Is there anyone who can help me for this issue?  <\/p>\n<p>I have also put myquestion in <a href=\"https:\/\/stackoverflow.com\/questions\/72516242\/is-there-any-limitations-for-runs-per-users-in-azure-ml-experiments\">StackoverFlow<\/a>. I would be grateful if you could help me with this issue.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Build Azure Bot",
        "Question_created_time":1655232434093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/889331\/build-azure-bot",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>How I can build an Azure Bot from our hand book<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Specifying input type as number in ComponentCommand and registing command with Python SDK v2 causes error",
        "Question_created_time":1655446170600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/893075\/specifying-input-type-as-number-in-componentcomman",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Specifying input type as number in ComponentCommand and registing component with Python SDK v2 causes error <code>Input string was not in a correct format<\/code>. The error is gone by removing the number-typed inputs and the relevant references to the inputs. It is noted that registering the component loaded from a YML spec does not have such a problem.    <\/p>\n<p>Programmically build ComponentCommand:    <\/p>\n<pre><code>   data_prep_comp = CommandComponent(  \n           name='stock_pred_data_prep',  \n           display_name='Preprocess data for training',  \n           description='reads raw price data, normalize and split the data',  \n           inputs={  \n               'data': Input(type='uri_folder', mode='ro_mount'),  \n               # the inputs below will cause error &quot;Input string was not in a correct format&quot;  \n               'test_ratio': Input(type='number'),  \n               'window': Input(type='number')  \n           },  \n           outputs={  \n               'scaler': Output(type='uri_file'),  \n               'train_data_x': Output(type='uri_file'),  \n               'train_data_y': Output(type='uri_file'),  \n               'test_data_x': Output(type='uri_file'),  \n               'test_data_y': Output(type='uri_file')  \n           },  \n           # TODO: reorganize code to minimize the code context  \n           code='.',  \n           command='''PYTHONPATH=$PYTHONPATH:$(pwd) \\  \n                   python azure_pipeline\/preproc_data\/preproc_data.py \\  \n                       --data=${{inputs.data}} --test_ratio=0.2 \\  \n                       --window=50 \\  \n                       --scaler=${{outputs.scaler}} \\  \n                       --train_data_x=${{outputs.train_data_x}} --train_data_y=${{outputs.train_data_y}} \\  \n                       --test_data_x=${{outputs.test_data_x}} --test_data_y=${{outputs.test_data_y}}  \n                   ''',  \n           environment=f'{my_env.name}:{my_env.version}'  \n       )  \n     \n       data_prep_comp = ml_client.components.create_or_update(data_prep_comp)  \n<\/code><\/pre>\n<p>Output:    <\/p>\n<pre><code>   Uploading stock-pred (7.61 MBs): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7605532\/7605532 [00:02&lt;00:00, 3504713.55it\/s]   \n     \n     \n     \n   \\---------------------------------------------------------------------------  \n     \n   HttpResponseError                         Traceback (most recent call last)  \n   Input In [23], in &lt;cell line: 38&gt;()  \n         7 else:  \n         8     data_prep_comp = CommandComponent(  \n         9         name='stock_pred_data_prep',  \n        10         display_name='Preprocess data for training',  \n      (...)  \n        35         environment=f'{my_env.name}:{my_env.version}'  \n        36     )  \n   \\---&gt; 38 data_prep_comp = ml_client.components.create_or_update(data_prep_comp)  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_telemetry\/activity.py:230, in monitor_with_telemetry_mixin.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)  \n       228 dimensions = {**parameter_dimensions, **(custom_dimensions or {})}  \n       229 with log_activity(logger, activity_name or f.__name__, activity_type, dimensions) as activityLogger:  \n   \\--&gt; 230     return_value = f(*args, **kwargs)  \n       231     if not parameter_dimensions:  \n       232         # collect from return if no dimensions from parameter  \n       233         activityLogger.activity_info.update(_collect_from_return_value(return_value))  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_component_operations.py:263, in ComponentOperations.create_or_update(self, component, **kwargs)  \n       254             result = self._version_operation.create_or_update(  \n       255                 name=rest_component_resource.name,  \n       256                 version=component.version,  \n      (...)  \n       260                 **self._init_args,  \n       261             )  \n       262 except Exception as e:  \n   \\--&gt; 263     raise e  \n       265 if not result:  \n       266     return self.get(name=component.name, version=component.version)  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_component_operations.py:244, in ComponentOperations.create_or_update(self, component, **kwargs)  \n       242 else:  \n       243     if component._auto_increment_version:  \n   \\--&gt; 244         result = _create_or_update_autoincrement(  \n       245             name=component.name,  \n       246             body=rest_component_resource,  \n       247             version_operation=self._version_operation,  \n       248             container_operation=self._container_operation,  \n       249             resource_group_name=self._operation_scope.resource_group_name,  \n       250             workspace_name=self._workspace_name,  \n       251             **self._init_args,  \n       252         )  \n       253     else:  \n       254         result = self._version_operation.create_or_update(  \n       255             name=rest_component_resource.name,  \n       256             version=component.version,  \n      (...)  \n       260             **self._init_args,  \n       261         )  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_utils\/utils.py:496, in retry.&lt;locals&gt;.retry_decorator.&lt;locals&gt;.func_with_retries(*args, **kwargs)  \n       494 delay = delay_multiplier * 2**counter + random.uniform(0, 1)  \n       495 try:  \n   \\--&gt; 496     return f(*args, **kwargs)  \n       497 except exceptions as e:  \n       498     tries -= 1  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_utils\/_asset_utils.py:287, in _create_or_update_autoincrement(name, body, version_operation, container_operation, resource_group_name, workspace_name, **kwargs)  \n       284 except ResourceNotFoundError:  \n       285     version = &quot;1&quot;  \n   \\--&gt; 287 result = version_operation.create_or_update(  \n       288     name=name,  \n       289     version=version,  \n       290     resource_group_name=resource_group_name,  \n       291     workspace_name=workspace_name,  \n       292     body=body,  \n       293     **kwargs,  \n       294 )  \n       295 return result  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/core\/tracing\/decorator.py:78, in distributed_trace.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper_use_tracer(*args, **kwargs)  \n        76 span_impl_type = settings.tracing_implementation()  \n        77 if span_impl_type is None:  \n   \\---&gt; 78     return func(*args, **kwargs)  \n        80 # Merge span is parameter is set, but only if no explicit parent are passed  \n        81 if merge_span and not passed_in_parent:  \n     \n   File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_restclient\/v2022_05_01\/operations\/_component_versions_operations.py:516, in ComponentVersionsOperations.create_or_update(self, resource_group_name, workspace_name, name, version, body, **kwargs)  \n       514     map_error(status_code=response.status_code, response=response, error_map=error_map)  \n       515     error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)  \n   \\--&gt; 516     raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)  \n       518 if response.status_code == 200:  \n       519     deserialized = self._deserialize('ComponentVersionData', pipeline_response)  \n     \n   HttpResponseError: (ServiceError) Received 500 from a service request  \n   Code: ServiceError  \n   Message: Received 500 from a service request  \n   Target: POST https:\/\/component.vienna-southeastasia.svc\/component\/v2.0\/subscriptions\/3ceb9ed0-8ef8-49a5-ae9d-c2381ba5752e\/resourceGroups\/resource-group-1\/providers\/Microsoft.MachineLearningServices\/workspaces\/mlops\/componentversions\/?componentName=stock_pred_data_prep&amp;componentVersion=2022-06-17-05-57-08-6940895&amp;validateOnly=False&amp;upgradeIfExists=True  \n   Exception Details:\t(InternalServerError) {  \n   \t  &quot;error&quot;: {  \n   \t    &quot;code&quot;: &quot;ServiceError&quot;,  \n   \t    &quot;severity&quot;: null,  \n   \t    &quot;message&quot;: &quot;Input string was not in a correct format.&quot;,  \n   \t    &quot;messageFormat&quot;: null,  \n   \t    &quot;messageParameters&quot;: null,  \n   \t    &quot;referenceCode&quot;: null,  \n   \t    &quot;detailsUri&quot;: null,  \n   \t    &quot;target&quot;: null,  \n   \t    &quot;details&quot;: [],  \n   \t    &quot;innerError&quot;: null,  \n   \t    &quot;debugInfo&quot;: null,  \n   \t    &quot;additionalInfo&quot;: null  \n   \t  },  \n   \t  &quot;correlation&quot;: {  \n   \t    &quot;operation&quot;: &quot;85a19cb768484844855b3015cc5e60d6&quot;,  \n   \t    &quot;request&quot;: &quot;df050dc38daa8391&quot;  \n   \t  },  \n   \t  &quot;environment&quot;: &quot;southeastasia&quot;,  \n   \t  &quot;location&quot;: &quot;southeastasia&quot;,  \n   \t  &quot;time&quot;: &quot;2022-06-17T05:57:28.1610781+00:00&quot;,  \n   \t  &quot;componentName&quot;: &quot;component&quot;  \n   \t}  \n   \tCode: InternalServerError  \n   \tMessage: {  \n   \t  &quot;error&quot;: {  \n   \t    &quot;code&quot;: &quot;ServiceError&quot;,  \n   \t    &quot;severity&quot;: null,  \n   \t    &quot;message&quot;: &quot;Input string was not in a correct format.&quot;,  \n   \t    &quot;messageFormat&quot;: null,  \n   \t    &quot;messageParameters&quot;: null,  \n   \t    &quot;referenceCode&quot;: null,  \n   \t    &quot;detailsUri&quot;: null,  \n   \t    &quot;target&quot;: null,  \n   \t    &quot;details&quot;: [],  \n   \t    &quot;innerError&quot;: null,  \n   \t    &quot;debugInfo&quot;: null,  \n   \t    &quot;additionalInfo&quot;: null  \n   \t  },  \n   \t  &quot;correlation&quot;: {  \n   \t    &quot;operation&quot;: &quot;85a19cb768484844855b3015cc5e60d6&quot;,  \n   \t    &quot;request&quot;: &quot;df050dc38daa8391&quot;  \n   \t  },  \n   \t  &quot;environment&quot;: &quot;southeastasia&quot;,  \n   \t  &quot;location&quot;: &quot;southeastasia&quot;,  \n   \t  &quot;time&quot;: &quot;2022-06-17T05:57:28.1610781+00:00&quot;,  \n   \t  &quot;componentName&quot;: &quot;component&quot;  \n   \t}  \n   Additional Information:Type: ComponentName  \n   Info: {  \n       &quot;value&quot;: &quot;managementfrontend&quot;  \n   }Type: Correlation  \n   Info: {  \n       &quot;value&quot;: {  \n           &quot;operation&quot;: &quot;85a19cb768484844855b3015cc5e60d6&quot;,  \n           &quot;request&quot;: &quot;8b85fb5624fdd21e&quot;  \n       }  \n   }Type: Environment  \n   Info: {  \n       &quot;value&quot;: &quot;southeastasia&quot;  \n   }Type: Location  \n   Info: {  \n       &quot;value&quot;: &quot;southeastasia&quot;  \n   }Type: Time  \n   Info: {  \n       &quot;value&quot;: &quot;2022-06-17T05:57:28.198017+00:00&quot;  \n   }  \n<\/code><\/pre>\n<p>YML spec:    <\/p>\n<pre><code>   name: stock_pred_data_prep  \n   display_name: Preprocess data for training  \n   description: reads raw price data, normalize and split the data  \n   # version: 1 # Not specifying a version will automatically update the version  \n   type: command  \n   inputs:  \n     data: {type: uri_folder}  \n     test_ratio: {type: number}  \n     window: {type: number}  \n   outputs:  \n     scaler: {type: uri_file}  \n     train_data_x: {type: uri_file}  \n     train_data_y: {type: uri_file}  \n     test_data_x: {type: uri_file}  \n     test_data_y: {type: uri_file}  \n   code: ..\/..  \n   environment:  \n     azureml:tensorflow_sklean_cpu:1.0  \n   command: &gt;-  \n     PYTHONPATH=$PYTHONPATH:$(pwd)   \n     PYTHONPATH=$PYTHONPATH:$(pwd)  python azure_pipeline\/preproc_data\/preproc_data.py   \n         --data=${{inputs.data}} --test_ratio=${{inputs.test_ratio}}   \n         --window=${{inputs.window}}   \n         --scaler=${{outputs.scaler}}   \n         --train_data_x=${{outputs.train_data_x}} --train_data_y=${{outputs.train_data_y}}   \n         --test_data_x=${{outputs.test_data_x}} --test_data_y=${{outputs.test_data_y}}  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error testing batch endpoint",
        "Question_created_time":1655371158430,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/891782\/error-testing-batch-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm trying to deploy a batch endpoint in AzureML. Below are screenshots of the code I'm using.    <\/p>\n<p>The deployment of the endpoint seems to work okay - says it is successful.    <\/p>\n<p>When I come to testing the endpoint - I get the attached errors within the studio relating to mini batch items.    <\/p>\n<p>Any idea of things I can try to fix this?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211949-image.png?platform=QnA\" alt=\"211949-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211935-image.png?platform=QnA\" alt=\"211935-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211995-image.png?platform=QnA\" alt=\"211995-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/212005-image.png?platform=QnA\" alt=\"212005-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/211989-image.png?platform=QnA\" alt=\"211989-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/212006-image.png?platform=QnA\" alt=\"212006-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure-ML>>ImportError: DLL load failed while importing win32file: The specified procedure could not be found.",
        "Question_created_time":1648195247070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/787222\/azure-ml))importerror-dll-load-failed-while-import",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>I have been using the Azure ML python SDK and it has been working fine until I started getting this error:  <br \/>\n&quot;ImportError: DLL load failed while importing win32file: The specified procedure could not be found.&quot; when I tried to access my workspace  <\/p>\n<p>I am using a conda virtual environment with Python 3.9 and I was running all my codes in a jupyter notebook on a windows computer.  <\/p>\n<p>It's been many hours now and I cannot find a solution. Can you help?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is my Hyperdrive step not completing even when the child jobs have completed?",
        "Question_created_time":1655222646607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/889157\/why-is-my-hyperdrive-step-not-completing-even-when",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,    <\/p>\n<p>What conditions need to be met to complete a HyperDriveStep in an Azure ML pipeline?    <\/p>\n<p>Context:    <br \/>\nI'm trying to run a hyperparameter sweep in Azure ML using a pipeline with a HyperDriveStep (HDS) followed by a PythonScriptStep (PSS) . The HDS step has a singular child job of the Sweep type that runs successfully and completes, with a &quot;best_child_by_primary_metric&quot; metric logged (implying that a best model has been identified). However, the HDS keeps on running despite there being nothing else for it to do other than complete and trigger the PSS. The template I've followed is the one <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-parameter-tuning-with-hyperdrive.ipynb\">here<\/a>, as recommended in the Azure ML documentation for the HyperDriveStep Class. There doesn't seem to be anything in the output logs either indicating some computational process is occurring, so I can't figure out what's keeping it idling.    <\/p>\n<p>Thanks in advance    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Online deployment startup failed",
        "Question_created_time":1655197807017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/888458\/online-deployment-startup-failed",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Online deployment (locally) startup failed with this error message (full log is at the end):    <\/p>\n<pre><code>   ModuleNotFoundError: No module named 'sklearn'  \n<\/code><\/pre>\n<p>The import is from this line of the <code>train.py<\/code> python script:    <\/p>\n<pre><code>   from sklearn.preprocessing import StandardScaler  \n<\/code><\/pre>\n<p>By running a local Docker container manually, this above import statement works if I activate the <code>inf-conda-env<\/code> conda environment, where <code>scikit-learn&gt;=1.0.2<\/code> as specified in my environment ile is installed.    <\/p>\n<p>Looking into the full logs, it seems that the container is using the <code>amlenv<\/code> conda environment instead when this error happends. I could not change the actual environment where <code>scikit-learn<\/code> is installed by changing the <code>name<\/code> within both the environment YML file and the deployment YML file. This dependent package is always installed in <code>inf-conda-env<\/code> and the inference server is always run in <code>amlenv<\/code>.    <\/p>\n<p>env_azure.yml:    <\/p>\n<pre><code>   name: myenv  \n   dependencies:  \n     - python=3.7  \n     - pip:  \n       - scikit-learn&gt;=1.0.2  \n<\/code><\/pre>\n<p>blue-deployment.yml:    <\/p>\n<pre><code>   $schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json  \n   name: blue  \n   endpoint_name: george-mlops-endpoint  \n   model: azureml:stock-pred-lstm:2  \n   code_configuration:  \n     code: ..\/  \n     scoring_script: score_azure.py  \n   environment:  \n     name: myenv  \n     conda_file: ..\/env_azure.yml  \n     image: mcr.microsoft.com\/azureml\/tensorflow-2.4-ubuntu18.04-py37-cpu-inference:latest  \n   instance_type: Standard_D2as_v4  \n   instance_count: 1  \n<\/code><\/pre>\n<p>---    <\/p>\n<p>full log:    <\/p>\n<pre><code>   $ az ml online-deployment get-logs -n blue -e $ENDPOINT_NAME_2 --local  \n   2022-06-14T08:54:05,693704187+00:00 - gunicorn\/run   \n   2022-06-14T08:54:05,695924060+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,698181633+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,701762750+00:00 | gunicorn\/run | AzureML Container Runtime Information  \n   2022-06-14T08:54:05,702955089+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,704188929+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,705658377+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,707062223+00:00 - rsyslog\/run   \n   2022-06-14T08:54:05,710995351+00:00 - nginx\/run   \n   2022-06-14T08:54:05,714649671+00:00 | gunicorn\/run | AzureML image information: tensorflow-2.4-ubuntu18.04-py37-cpu-inference:20220516.v10  \n   nginx: [warn] the &quot;user&quot; directive makes sense only if the master process runs with super-user privileges, ignored in \/etc\/nginx\/nginx.conf:1  \n   2022-06-14T08:54:05,721274687+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,722691033+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,723795369+00:00 | gunicorn\/run | PATH environment variable: \/opt\/miniconda\/envs\/inf-conda-env\/bin:\/opt\/miniconda\/condabin:\/opt\/miniconda\/envs\/amlenv\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin  \n   2022-06-14T08:54:05,724812902+00:00 | gunicorn\/run | PYTHONPATH environment variable:   \n   2022-06-14T08:54:05,726167546+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,727421387+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)  \n     \n   certifi==2022.5.18.1  \n   joblib==1.1.0  \n   numpy==1.21.6  \n   scikit-learn==1.0.2  \n   scipy==1.7.3  \n   threadpoolctl==3.1.0  \n     \n   2022-06-14T08:54:05,972350679+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,973666822+00:00 | gunicorn\/run | Entry script directory: \/var\/azureml-app\/stock-pred\/\/.  \n   2022-06-14T08:54:05,974753257+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,975907695+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,977260339+00:00 | gunicorn\/run | Dynamic Python Package Installation  \n   2022-06-14T08:54:05,978331974+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,979721920+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,981003161+00:00 | gunicorn\/run | Dynamic Python package installation is disabled.  \n   2022-06-14T08:54:05,982319204+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:05,983685849+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,984905389+00:00 | gunicorn\/run | AzureML Inference Server  \n   2022-06-14T08:54:05,986270433+00:00 | gunicorn\/run | ###############################################  \n   2022-06-14T08:54:05,987434371+00:00 | gunicorn\/run |   \n   2022-06-14T08:54:06,001278423+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.  \n     \n   Azure ML Inferencing HTTP server v0.6.1  \n     \n     \n   Server Settings  \n     \n   \\---------------  \n     \n   Entry Script Name: score_azure.py  \n   Model Directory: \/var\/azureml-app\/azureml-models\/\/stock-pred-lstm\/2  \n   Worker Count: 1  \n   Worker Timeout (seconds): 300  \n   Server Port: 31311  \n   Application Insights Enabled: false  \n   Application Insights Key: None  \n   Inferencing HTTP server version: azmlinfsrv\/0.6.1  \n     \n     \n   Server Routes  \n     \n   \\---------------  \n     \n   Liveness Probe: GET   127.0.0.1:31311\/  \n   Score:          POST  127.0.0.1:31311\/score  \n     \n   Starting gunicorn 20.1.0  \n   Listening at: http:\/\/0.0.0.0:31311 (26)  \n   Using worker: sync  \n   Booting worker with pid: 69  \n   Exception in worker process  \n   Traceback (most recent call last):  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker  \n       worker.init_process()  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process  \n       self.load_wsgi()  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi  \n       self.wsgi = self.app.wsgi()  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi  \n       self.callable = self.load()  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load  \n       return self.load_wsgiapp()  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp  \n       return util.import_app(self.app_uri)  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app  \n       mod = importlib.import_module(module)  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module  \n       return _bootstrap._gcd_import(name[level:], package, level)  \n     File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import  \n     File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load  \n     File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked  \n     File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked  \n     File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module  \n     File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/entry.py&quot;, line 1, in &lt;module&gt;  \n       import create_app  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/create_app.py&quot;, line 24, in &lt;module&gt;  \n       from routes import main  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/routes.py&quot;, line 39, in &lt;module&gt;  \n       from aml_blueprint import AMLBlueprint  \n     File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 33, in &lt;module&gt;  \n       main_module_spec.loader.exec_module(main)  \n     File &quot;\/var\/azureml-app\/stock-pred\/score_azure.py&quot;, line 7, in &lt;module&gt;  \n       from train import load_data, load_model, load_scaler, extract_x_y  \n     File &quot;\/var\/azureml-app\/stock-pred\/train.py&quot;, line 5, in &lt;module&gt;  \n       from sklearn.preprocessing import StandardScaler  \n   ModuleNotFoundError: No module named 'sklearn'  \n   Worker exiting (pid: 69)  \n   Shutting down: Master  \n   Reason: Worker failed to boot.  \n   2022-06-14T08:54:07,134158894+00:00 - gunicorn\/finish 3 0  \n   2022-06-14T08:54:07,135337927+00:00 - Exit code 3 is not normal. Killing image.  \n   ERROR conda.cli.main_run:execute(34): Subprocess for 'conda run ['runsvdir', '\/var\/runit']' command failed.  (See above for error)  \n   2022-06-14T08:54:07,141403097+00:00 - rsyslog\/finish 0 0  \n   2022-06-14T08:54:07,143002342+00:00 - Exit code 0 is not normal. Restarting rsyslog.  \n   2022-06-14T08:54:07,153991050+00:00 - nginx\/finish 0 0  \n   2022-06-14T08:54:07,156038707+00:00 - Exit code 0 is not normal. Killing image.  \n   runsvdir: no process found  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting error while translating document using Azure translator - \"Cannot access source document location with the current permissions\" InvalidRequest",
        "Question_created_time":1635709097990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/610532\/getting-error-while-translating-document-using-azu",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am using translator resource to translate the one document at a time from the source container through python code.<\/p>\n<p>Following the documentation, generated the container level SAS for existing containers.<\/p>\n<p>Tried different combinations of request body formats to meet the requirement of translating the single file from source container using &quot;Container level SAS&quot;.<\/p>\n<p>I was able to translate various documents but suddenly the python code is failing with the error -  <br \/>\n{ 'status': 'ValidationFailed', 'error': {'code': 'InvalidRequest', 'message': 'Cannot access source document location with the current permissions.', 'target': 'Operation', 'innerError': {'code': 'InvalidDocumentAccessLevel', 'message': 'Cannot access source document location with the current permissions.'}\u200b}, 'summary': {'total': 0, 'failed': 0, 'success': 0, 'inProgress': 0, 'notYetStarted': 0, 'cancelled': 0, 'totalCharacterCharged': 0}\u200b}<\/p>\n<p>When same request bodies are tried for newly created containers, documents are translating successfully.  <br \/>\n** Does existing containers gives this issue sometimes and we should always use the newly created containers?**<\/p>\n<p>Old container's SAS urls are generated with appropriate permissions i.e. Read,list for source and Write.List for Target container.<\/p>\n<p>Please suggest me the correct way.<\/p>\n<p>Also attaching the different request body formats I am using to take single file at a time using &quot;Container level SAS&quot;<\/p>\n<ol>\n<li>  Specifying the file name in source url and target url\n<pre><code>  {\n            &quot;inputs&quot;: [\n                {\n                    &quot;storageType&quot;: &quot;File&quot;,\n                    &quot;source&quot;: {\n                        &quot;sourceUrl&quot;: &quot;https:\/\/myblob.blob.core.windows.net\/src_container\/file.docx?&lt;SAS&gt;&quot;\n                    },\n                    &quot;targets&quot;: [\n                        {   \n                   &quot;targetUrl&quot;:&quot;https:\/myblob.blob.core.windows.net\/container\/&lt;target_blob_name_without_any_extension&gt;? \n                       &lt;SAS&gt;&quot;,\n                            &quot;language&quot;: &quot;fr&quot;\n                        }\n                    ]\n                }\n            ]\n        }\n<\/code><\/pre>\n<\/li>\n<li>  Specifying the file name as suffix in the source    {  <br \/>\n    &quot;inputs&quot;: [  <br \/>\n    {\n<pre><code>            &quot;source&quot;: {\n                &quot;sourceUrl&quot;: &quot;https:\/\/myblob.blob.core.windows.net\/src_container\/file.docx?&lt;SAS&gt;&quot;,\n<\/code><\/pre>\n    &quot;suffix&quot;:&quot;file.docx&quot;  <br \/>\n    },  <br \/>\n    &quot;targets&quot;: [  <br \/>\n    {\n<pre><code>           &quot;targetUrl&quot;:&quot;https:\/myblob.blob.core.windows.net\/container\/&lt;target_blob_name_without_any_extension&gt;? \n               &lt;SAS&gt;&quot;,\n                    &quot;language&quot;: &quot;fr&quot;\n                }\n            ]\n        }\n    ]\n}\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>Which is the correct way of achieving the use case using &quot;Container level SAS&quot;.  <br \/>\n<strong>Am I doing something wrong in request body ?<\/strong>  <br \/>\nQuick help is needed. Can anyone guide me please?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to connect Azure ML studio to Visual Studio?",
        "Question_created_time":1655215688467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/888888\/is-it-possible-to-connect-azure-ml-studio-to-visua",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to connect a model from Azure ML studio to Visual Studio in order to create an user-interactive front-end for the model? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to change input data of \"Web Service Output\" component in Designer in Azure ML Studio",
        "Question_created_time":1654040427400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872177\/unable-to-change-input-data-of-web-service-output",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to complete the following unit in a MS Learn module:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/7-inference-pipeline\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/7-inference-pipeline<\/a>    <\/p>\n<p>I added a &quot;Execute Python Script&quot; between &quot;Score Model&quot; and &quot;Web Service Output&quot; as the following capture and saved the model in Designer.    <br \/>\n(Previously &quot;Score Model&quot; was directly connected to &quot;Web Service Output&quot;.)    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/207247-img1.png?platform=QnA\" alt=\"207247-img1.png\" \/>    <\/p>\n<p>And then I revisited the model, the connection between &quot;Execute Python Script&quot; and &quot;Web Service Output&quot; was disabled, and again &quot;Score Model&quot; was directory connected to &quot;Web Service Output&quot;.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/207248-img2.png?platform=QnA\" alt=\"207248-img2.png\" \/>     <\/p>\n<p>Does anyone tell me how to keep the connection between &quot;Execute Python Script&quot; and &quot;Web Service Output&quot;.    <\/p>\n<p>Best regards,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to create labelling project",
        "Question_created_time":1654602922600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/879956\/unable-to-create-labelling-project",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I've been trying to create a Labeling project in AzureML. I have succesfully registered the datastore (without credentials, so AzureML should use the users's AD Credential), I have succesfully created a dataset from the datastore (approx 15k images in the dataset) and can explore the dataset from the portal.  <\/p>\n<p>When I then create a labelling project, I finish the creation wizard and get back to the label project overview with. For a few seconds the project shows it's initializing but then shows the project as Failed. The only information I get is:  <\/p>\n<blockquote>\n<p>The dataset refresh has failed. Verify the project's datastore credentials are correct and the dataset contains datapoints.  <\/p>\n<\/blockquote>\n<p>However, as far as I can tell the credentials are correct and the dataset does contain datapoints as evidenced by me being able to 'explore' the dataset from the portal.  <\/p>\n<p>What other issues can cause this error and\/or how can I get a more detailed explanation for what went wrong?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How should I create a scoring script for object detection (pytorch) in Azure ML?",
        "Question_created_time":1655225088730,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/889212\/how-should-i-create-a-scoring-script-for-object-de",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi there,    <\/p>\n<p>I have trained a PyTorch vision model on a local computer for object detection and want to deploy it on Azure ML. I have found a similar script for classification using pytorch where they are using the following scoring script. link: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/ml-frameworks\/pytorch\/train-hyperparameter-tune-deploy-with-pytorch\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/ml-frameworks\/pytorch\/train-hyperparameter-tune-deploy-with-pytorch<\/a>    <\/p>\n<pre><code># Copyright (c) Microsoft. All rights reserved.  \n# Licensed under the MIT license.  \n\nimport os  \nimport torch  \nimport torch.nn as nn  \nfrom torchvision import transforms  \nimport json  \n\nfrom azureml.core.model import Model  \n\n\ndef init():  \n    global model  \n    # AZUREML_MODEL_DIR is an environment variable created during deployment.  \n    # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)  \n    # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)  \n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')  \n    model = torch.load(model_path, map_location=lambda storage, loc: storage)  \n    model.eval()  \n\n\ndef run(input_data):  \n    input_data = torch.tensor(json.loads(input_data)['data'])  \n\n    # get prediction  \n    with torch.no_grad():  \n        output = model(input_data)  \n        classes = ['chicken', 'turkey']  \n        softmax = nn.Softmax(dim=1)  \n        pred_probs = softmax(output).numpy()[0]  \n        index = torch.argmax(output, 1)  \n\n    result = {&quot;label&quot;: classes[index], &quot;probability&quot;: str(pred_probs[index])}  \n    return result  \n<\/code><\/pre>\n<p>I have a few questions regarding this script. I am wondering what is 'input_data' in this case, is it an image in jpg format?    <br \/>\nAlso can my 'result' be in any dict format or it should have a specific format?    <\/p>\n<p>I have written a similar script for my purpose.    <\/p>\n<pre><code># Copyright (c) Microsoft. All rights reserved.  \n# Licensed under the MIT license.  \n\nimport os  \nimport torch  \nimport torchvision  \n#import torch.nn as nn  \nfrom torchvision import transforms  \nimport json  \nimport cv2  \nfrom azureml.core.model import Model  \nimport numpy as np  \nfrom PIL import Image  \nimport os  \n\n\ndef init():  \n\n    global model  \n    # AZUREML_MODEL_DIR is an environment variable created during deployment.  \n    # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)  \n    # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)  \n    # model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')  \n    # model = torch.load(model_path, map_location=lambda storage, loc: storage)  \n    # #model_path = Model.get_model_path(model_name='pytorch_external_model-test')  \n    # model = torch.load(model_path)  \n\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'model.pt')  \n    model = torch.load(model_path, map_location=lambda storage, loc: storage)  \n    #model = torch.load(model_path)  \n    model.eval()  \n\n# the function takes the original prediction and the iou threshold.  \ndef apply_nms(orig_prediction, iou_thresh=0.3):  \n# torchvision returns the indices of the bboxes to keep  \nkeep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)  \n  \nfinal_prediction = orig_prediction  \n#print(final_prediction['boxes'])  \nfinal_prediction['boxes'] = final_prediction['boxes'][keep].cpu() # had to add .cpu() after each tensor   \nfinal_prediction['scores'] = final_prediction['scores'][keep].cpu()   \nfinal_prediction['labels'] = final_prediction['labels'][keep].cpu()   \n\nreturn final_prediction  \n\n# def preprocess(input_data): # doesn't convert to tensor, while input for prediction needs to be in tensor  \n#     img = cv2.imread(input_data)  \n#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)  \n#     img_res = cv2.resize(img_rgb, (704, 480), cv2.INTER_AREA)  \n#     # diving by 255  \n#     img_res \/= 255.0  \n#     return img_res  \n\ndef run(input_data):  \n\n    img = Image.open(input_data).convert('RGB')  \n\n    # set up transformation to resize the image  \n    resize = transforms.Resize([704, 480])  \n    img = resize(img)  \n    to_tensor = transforms.ToTensor()  \n\n    # apply transformation and convert to Pytorch tensor  \n    tensor = to_tensor(img) # output shape [3, 704, 480]   \n    #tensor = tensor.unsqueeze(0) # no need for [1, 3, 704, 480]  \n    # link for converting image to tensor https:\/\/towardsdatascience.com\/convert-images-to-tensors-in-pytorch-and-tensorflow-f0ab01383a03  \n\n\n    #input_data = torch.tensor(json.loads(input_data)['data'])  \n    #image = preprocess(input_data)  \n\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  \n\n\n    with torch.no_grad():  \n\n        prediction = model([tensor.to(device)])[0]  \n\n    nms_prediction = apply_nms(prediction, iou_thresh=0.3)  \n\n    result = {&quot;label&quot;: nms_prediction['labels'], &quot;box&quot;: nms_prediction['boxes'], &quot;score&quot;: nms_prediction['scores']}  \n    return result  \n<\/code><\/pre>\n<p>I followed this colab tutorial for training the object detection model. I am not using any transform to make the problem easy for now.    <br \/>\n<a href=\"https:\/\/colab.research.google.com\/drive\/1NziO_b-SW9KmWFh-6C8to9H_QAdpmCBZ?usp=sharing#scrollTo=WOrNovPGh_k6\">https:\/\/colab.research.google.com\/drive\/1NziO_b-SW9KmWFh-6C8to9H_QAdpmCBZ?usp=sharing#scrollTo=WOrNovPGh_k6<\/a>    <\/p>\n<p>Model is deployed successfully. But getting this error     <\/p>\n<p>print(service.get_logs())    <\/p>\n<pre><code>\/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)  \n\/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)  \n\/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)  \n\/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)  \n2022-06-15T00:14:38,162168400+00:00 - gunicorn\/run   \n2022-06-15T00:14:38,166094000+00:00 - rsyslog\/run   \n2022-06-15T00:14:38,171921600+00:00 - iot-server\/run   \nbash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by bash)  \n2022-06-15T00:14:38,190831400+00:00 | gunicorn\/run |   \n2022-06-15T00:14:38,197941200+00:00 | gunicorn\/run | ###############################################  \n2022-06-15T00:14:38,242881800+00:00 | gunicorn\/run | AzureML Container Runtime Information  \n2022-06-15T00:14:38,300863500+00:00 | gunicorn\/run | ###############################################  \n2022-06-15T00:14:38,351919200+00:00 - nginx\/run   \n2022-06-15T00:14:38,377608200+00:00 | gunicorn\/run |   \n2022-06-15T00:14:38,413561500+00:00 | gunicorn\/run |   \n2022-06-15T00:14:38,436442300+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin  \n2022-06-15T00:14:38,472313100+00:00 | gunicorn\/run | PYTHONPATH environment variable:   \n2022-06-15T00:14:38,478958600+00:00 | gunicorn\/run |   \n2022-06-15T00:14:38,501877400+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)  \n\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...  \n\/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)  \n2022-06-15T00:14:38,787582000+00:00 - iot-server\/finish 1 0  \n2022-06-15T00:14:38,793119200+00:00 - Exit code 1 is normal. Not restarting iot-server.  \nadal==1.2.7  \nalbumentations==0.4.6  \napplicationinsights==0.11.10  \nargcomplete==2.0.0  \nattrs==21.4.0  \nazure-common==1.1.28  \nazure-core==1.22.1  \nazure-graphrbac==0.61.1  \nazure-identity==1.7.0  \nazure-mgmt-authorization==2.0.0  \nazure-mgmt-containerregistry==9.1.0  \nazure-mgmt-core==1.3.0  \nazure-mgmt-keyvault==9.3.0  \nazure-mgmt-resource==21.0.0  \nazure-mgmt-storage==20.0.0  \nazureml-core==1.42.0.post1  \nazureml-dataprep==4.0.3  \nazureml-dataprep-native==38.0.0  \nazureml-dataprep-rslex==2.6.3  \nazureml-dataset-runtime==1.42.0  \nazureml-defaults==1.42.0  \nazureml-inference-server-http==0.4.13  \nbackports.tempfile==1.0  \nbackports.weakref==1.0.post1  \nbcrypt==3.2.2  \ncachetools==4.2.4  \ncertifi==2022.5.18.1  \ncffi==1.15.0  \ncharset-normalizer==2.0.12  \nclick==7.1.2  \ncloudpickle==2.1.0  \nconfigparser==3.7.4  \ncontextlib2==21.6.0  \ncontextvars==2.4  \ncryptography==36.0.2  \ncycler==0.11.0  \ndataclasses==0.8  \ndecorator==4.4.2  \ndistro==1.7.0  \ndocker==5.0.3  \ndotnetcore2==3.1.23  \nFlask==1.0.3  \nfusepy==3.0.1  \nfuture==0.18.2  \ngoogle-api-core==2.8.1  \ngoogle-auth==2.8.0  \ngoogleapis-common-protos==1.56.2  \ngunicorn==20.1.0  \nhumanfriendly==10.0  \nidna==3.3  \nimageio==2.15.0  \nimgaug==0.4.0  \nimmutables==0.18  \nimportlib-metadata==4.8.3  \ninference-schema==1.3.0  \nisodate==0.6.1  \nitsdangerous==1.1.0  \njeepney==0.7.1  \nJinja2==3.0.3  \njmespath==0.10.0  \njson-logging-py==0.2  \njsonpickle==2.2.0  \njsonschema==3.2.0  \nkiwisolver==1.3.1  \nknack==0.9.0  \nMarkupSafe==2.0.1  \nmatplotlib==3.3.4  \nmsal==1.18.0  \nmsal-extensions==0.3.1  \nmsrest==0.6.21  \nmsrestazure==0.6.4  \nndg-httpsclient==0.5.1  \nnetworkx==2.5.1  \nnumpy==1.19.5  \noauthlib==3.2.0  \nopencensus==0.9.0  \nopencensus-context==0.1.2  \nopencensus-ext-azure==1.1.4  \nopencv-python==4.6.0.66  \nopencv-python-headless==4.6.0.66  \npackaging==21.3  \nparamiko==2.11.0  \npathspec==0.9.0  \nPillow==8.4.0  \npkginfo==1.8.3  \nportalocker==2.4.0  \nprotobuf==3.19.4  \npsutil==5.9.1  \npyarrow==3.0.0  \npyasn1==0.4.8  \npyasn1-modules==0.2.8  \npycocotools==2.0.4  \npycparser==2.21  \nPygments==2.12.0  \nPyJWT==2.4.0  \nPyNaCl==1.5.0  \npyOpenSSL==22.0.0  \npyparsing==3.0.7  \npyrsistent==0.18.0  \nPySocks==1.7.1  \npython-dateutil==2.8.2  \npytz==2022.1  \nPyWavelets==1.1.1  \nPyYAML==6.0  \nrequests==2.27.1  \nrequests-oauthlib==1.3.1  \nrsa==4.8  \nscikit-image==0.17.2  \nscipy==1.5.4  \nSecretStorage==3.3.2  \nShapely==1.8.2  \nsix==1.16.0  \ntabulate==0.8.9  \ntifffile==2020.9.3  \ntorch==1.10.1  \ntorchvision==0.11.2  \ntyping_extensions==4.1.1  \nurllib3==1.26.9  \nwebsocket-client==1.3.1  \nWerkzeug==1.0.1  \nwrapt==1.12.1  \nzipp==3.6.0  \n\n2022-06-15T00:14:40,561943700+00:00 | gunicorn\/run |   \n2022-06-15T00:14:40,563774900+00:00 | gunicorn\/run | ###############################################  \n2022-06-15T00:14:40,569936200+00:00 | gunicorn\/run | AzureML Inference Server  \n2022-06-15T00:14:40,571682900+00:00 | gunicorn\/run | ###############################################  \n2022-06-15T00:14:40,573373400+00:00 | gunicorn\/run |   \n2022-06-15T00:14:40,580170100+00:00 | gunicorn\/run |   \n2022-06-15T00:14:40,584523000+00:00 | gunicorn\/run | Starting HTTP server  \n2022-06-15T00:14:40,590038900+00:00 | gunicorn\/run |   \nStarting gunicorn 20.1.0  \nListening at: http:\/\/127.0.0.1:31311 (77)  \nUsing worker: sync  \nworker timeout is set to 300  \nBooting worker with pid: 125  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2022-06-15 00:14:45,845 | root | INFO | Starting up app insights client  \nlogging socket was found. logging is available.  \nlogging socket was found. logging is available.  \n2022-06-15 00:14:45,846 | root | INFO | Starting up request id generator  \n2022-06-15 00:14:45,846 | root | INFO | Starting up app insight hooks  \n2022-06-15 00:14:45,847 | root | INFO | Invoking user's init function  \n2022-06-15 00:14:46,111 | root | INFO | Users's init has completed successfully  \n2022-06-15 00:14:46,115 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.  \n2022-06-15 00:14:46,116 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.  \n2022-06-15 00:14:46,121 | root | INFO | Scoring timeout is found from os.environ: 60000 ms  \n2022-06-15 00:14:49,997 | root | INFO | Swagger file not present  \n2022-06-15 00:14:49,998 | root | INFO | 404  \n127.0.0.1 - - [15\/Jun\/2022:00:14:49 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2022-06-15 00:14:54,621 | root | INFO | Swagger file not present  \n2022-06-15 00:14:54,622 | root | INFO | 404  \n127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2022-06-15 00:14:54,974 | root | INFO | Scoring Timer is set to 60.0 seconds  \n2022-06-15 00:14:54,979 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 294, in run_scoring  \n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 341, in invoke_user_with_timer  \n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 322, in timer  \n    result = func(*args, **kwargs)  \nFile &quot;\/var\/azureml-app\/score2.py&quot;, line 57, in run  \n    img = Image.open(input_data).convert('RGB')  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py&quot;, line 2975, in open  \n    fp = builtins.open(filename, &quot;rb&quot;)  \nFileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'  \n\nDuring handling of the above exception, another exception occurred:  \n\nTraceback (most recent call last):  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 270, in score_realtime  \n    service_input, request.headers, request.environ.get(&quot;REQUEST_ID&quot;, &quot;00000000-0000-0000-0000-000000000000&quot;)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 303, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n\n2022-06-15 00:14:54,979 | root | INFO | 500  \n127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 51 &quot;-&quot; &quot;python-requests\/2.26.0&quot;  \n2022-06-15 00:14:54,988 | root | INFO | Scoring Timer is set to 60.0 seconds  \n2022-06-15 00:14:54,988 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 294, in run_scoring  \n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 341, in invoke_user_with_timer  \n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 322, in timer  \n    result = func(*args, **kwargs)  \nFile &quot;\/var\/azureml-app\/score2.py&quot;, line 57, in run  \n    img = Image.open(input_data).convert('RGB')  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py&quot;, line 2975, in open  \n    fp = builtins.open(filename, &quot;rb&quot;)  \nFileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'  \n\nDuring handling of the above exception, another exception occurred:  \n\nTraceback (most recent call last):  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 270, in score_realtime  \n    service_input, request.headers, request.environ.get(&quot;REQUEST_ID&quot;, &quot;00000000-0000-0000-0000-000000000000&quot;)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 303, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n\n2022-06-15 00:14:54,988 | root | INFO | 500  \n127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 51 &quot;-&quot; &quot;python-requests\/2.26.0&quot;  \n2022-06-15 00:14:56,004 | root | INFO | Scoring Timer is set to 60.0 seconds  \n2022-06-15 00:14:56,005 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 294, in run_scoring  \n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 341, in invoke_user_with_timer  \n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 322, in timer  \n    result = func(*args, **kwargs)  \nFile &quot;\/var\/azureml-app\/score2.py&quot;, line 57, in run  \n    img = Image.open(input_data).convert('RGB')  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py&quot;, line 2975, in open  \n    fp = builtins.open(filename, &quot;rb&quot;)  \nFileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'  \n\nDuring handling of the above exception, another exception occurred:  \n\nTraceback (most recent call last):  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 270, in score_realtime  \n    service_input, request.headers, request.environ.get(&quot;REQUEST_ID&quot;, &quot;00000000-0000-0000-0000-000000000000&quot;)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 303, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n\n2022-06-15 00:14:56,005 | root | INFO | 500  \n127.0.0.1 - - [15\/Jun\/2022:00:14:56 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 51 &quot;-&quot; &quot;python-requests\/2.26.0&quot;  \n2022-06-15 00:14:58,028 | root | INFO | Scoring Timer is set to 60.0 seconds  \n2022-06-15 00:14:58,029 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 294, in run_scoring  \n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 341, in invoke_user_with_timer  \n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 322, in timer  \n    result = func(*args, **kwargs)  \nFile &quot;\/var\/azureml-app\/score2.py&quot;, line 57, in run  \n    img = Image.open(input_data).convert('RGB')  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py&quot;, line 2975, in open  \n    fp = builtins.open(filename, &quot;rb&quot;)  \nFileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'  \n\nDuring handling of the above exception, another exception occurred:  \n\nTraceback (most recent call last):  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 270, in score_realtime  \n    service_input, request.headers, request.environ.get(&quot;REQUEST_ID&quot;, &quot;00000000-0000-0000-0000-000000000000&quot;)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 303, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n\n2022-06-15 00:14:58,030 | root | INFO | 500  \n127.0.0.1 - - [15\/Jun\/2022:00:14:58 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 51 &quot;-&quot; &quot;python-requests\/2.26.0&quot;  \nException in worker process  \nTraceback (most recent call last):  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker  \n    worker.init_process()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 142, in init_process  \n    self.run()  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 125, in run  \n    self.run_for_one(timeout)  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 84, in run_for_one  \n    self.wait(timeout)  \nFile &quot;\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 36, in wait  \n    ret = select.select(self.wait_fds, [], [], timeout)  \nFile &quot;\/var\/azureml-server\/routes.py&quot;, line 159, in alarm_handler  \n    raise TimeoutException(error_message)  \ntimeout_exception.TimeoutException  \nWorker exiting (pid: 125)  \nworker timeout is set to 300  \nBooting worker with pid: 157  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2022-06-15 00:16:03,376 | root | INFO | Starting up app insights client  \nlogging socket was found. logging is available.  \nlogging socket was found. logging is available.  \n2022-06-15 00:16:03,376 | root | INFO | Starting up request id generator  \n2022-06-15 00:16:03,377 | root | INFO | Starting up app insight hooks  \n2022-06-15 00:16:03,377 | root | INFO | Invoking user's init function  \n2022-06-15 00:16:03,624 | root | INFO | Users's init has completed successfully  \n2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.  \n2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.  \n2022-06-15 00:16:03,633 | root | INFO | Scoring timeout is found from os.environ: 60000 ms  \n127.0.0.1 - - [15\/Jun\/2022:00:20:12 +0000] &quot;POST \/ HTTP\/1.0&quot; 405 178 &quot;-&quot; &quot;Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36&quot;  \n127.0.0.1 - - [15\/Jun\/2022:00:20:13 +0000] &quot;GET \/.env HTTP\/1.0&quot; 404 232 &quot;-&quot; &quot;Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36&quot;  \n2022-06-15 00:35:48,752 | root | INFO | Swagger file not present  \n2022-06-15 00:35:48,753 | root | INFO | 404  \n127.0.0.1 - - [15\/Jun\/2022:00:35:48 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n<\/code><\/pre>\n<p>result = service.run(input_data=&quot;test_img.jpg&quot;)    <br \/>\nprint(result)    <\/p>\n<pre><code>Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.  \nResponse Code: 502  \nHeaders: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}  \nContent: b&quot;[Errno 2] No such file or directory: 'test_img.jpg'&quot;  \n\n---------------------------------------------------------------------------  \nWebserviceException                       Traceback (most recent call last)  \n&lt;ipython-input-18-c76911546a4f&gt; in &lt;module&gt;  \n----&gt; 1 result = service.run(input_data=&quot;test_img.jpg&quot;)  \n    2 print(result)  \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/aci.py in run(self, input_data)  \n    403                                       'Headers: {}\\n'  \n    404                                       'Content: {}'.format(resp.status_code, resp.headers, resp.content),  \n--&gt; 405                                       logger=module_logger)  \n    406   \n    407     def update(self, image=None, tags=None, properties=None, description=None, auth_enabled=None, ssl_enabled=None,  \n\nWebserviceException: WebserviceException:  \n    Message: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.  \nResponse Code: 502  \nHeaders: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}  \nContent: b&quot;[Errno 2] No such file or directory: 'test_img.jpg'&quot;  \n    InnerException None  \n    ErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;message&quot;: &quot;Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\\nContent: b\\&quot;[Errno 2] No such file or directory: 'test_img.jpg'\\&quot;&quot;  \n    }  \n}  \n<\/code><\/pre>\n<p>What kind of response is needed? I have test_img.jpg file in the same directory.    <\/p>\n<p>Any help is appreciated.    <\/p>\n<p>Thank you.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hi team, I can't see create inference pipeline in my top pane beside submit button on Azure ML designer",
        "Question_created_time":1616146270477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/322365\/hi-team-i-cant-see-create-inference-pipeline-in-my",
        "Question_score_count":2,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>![79621-free-trail-designer.png][1] [1]: \/api\/attachments\/79621-free-trail-designer.png?platform=QnA <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure for Students",
        "Question_created_time":1655176529600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/888003\/azure-for-students",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>eu pago pela assinatura do azure for Students ???<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[SOLVED] AML Pipeline publish error: Identity(object id: __) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions.",
        "Question_created_time":1654848921463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/884432\/(solved)-aml-pipeline-publish-error-identity(objec",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I get the following error while trying to publish some new pipelines to an AML workspace:    <\/p>\n<p>SnapshotException:    <br \/>\nMessage: {    <br \/>\n    &quot;error_details&quot;: {  <br \/>\n        &quot;componentName&quot;: &quot;project&quot;,  <br \/>\n        &quot;correlation&quot;: {  <br \/>\n            &quot;operation&quot;: &quot;038f38ce5375f4cda9b0a50df5bb9c1b&quot;,  <br \/>\n            &quot;request&quot;: &quot;e874ef090203af05&quot;  <br \/>\n        },  <br \/>\n        &quot;environment&quot;: &quot;eastasia&quot;,  <br \/>\n        &quot;error&quot;: {  <br \/>\n            &quot;code&quot;: &quot;UserError&quot;,  <br \/>\n            &quot;innerError&quot;: {  <br \/>\n                &quot;code&quot;: &quot;ForbiddenError&quot;  <br \/>\n            },  <br \/>\n            &quot;message&quot;: &quot;Identity(object id: bb0511d8-d57a-4442-89a1-1986cac268c9) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions. Please refer to <a href=\"https:\/\/aka.ms\/azureml-auth-troubleshooting\">https:\/\/aka.ms\/azureml-auth-troubleshooting<\/a> to fix the permissions issue.&quot;  <br \/>\n        },  <br \/>\n        &quot;location&quot;: &quot;eastasia&quot;,  <br \/>\n        &quot;time&quot;: &quot;2022-06-10T08:07:13.3168371+00:00&quot;  <br \/>\n    },  <br \/>\n    &quot;status_code&quot;: 403,  <br \/>\n    &quot;url&quot;: &quot;__&quot;  <br \/>\n}    <\/p>\n<p>Do note that I'm publishing multiple pipelines to multiple workspaces - only 2 of the pipelines on our Asia workspace are failing with this (and 1 other on Asia completed successfully)... I see that similar issues had existed before and were internal to Azure and fixed promptly, i.e. - <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html<\/a>    <\/p>\n<p>Any idea if this is a similar thing, or did we do something wrong? Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use register trained .ilearner model and deploy it as Real-Time-Inference Endpoint",
        "Question_created_time":1653486198093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/863786\/use-register-trained-ilearner-model-and-deploy-it",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Dear Community, since more than 2 weeks I'm struggeling on Azure Machine Learning Studio. Our Training-Pipeline generates a Trained-Best-Model folder containing the following files <strong>_meta.yaml _samples.json _schema.json conda_env.yaml data.ilearner model_spec.yaml score.py<\/strong> In the designer I can just run my training Pipeline, Update my Inference Pipeline and\u00b4once this finishied the progress, I press the &quot;Deploy&quot; Button. This creates some kind of deployment package, registers the model and deploys it to a kubernetes cluster. I'm completly happy with the setting of my pipeline and my resulting endpoint. But our customer wants us to automate it so there is a weekly deployment shedule on the endpoint. All tutorial and informations I found use other file formats (like .pkl and .onnx) but really not a single Jupyter notebook shows me how a) To Read my mltable Dataset (Type File, contains the folder of the listed filnames above ) and &quot;convert it&quot; to a model b) package this model c) deploy it to an existing kubernetes webservice If i could just automate those 2 clicks from the Inference Pipeline Run in python, it would all be done. But this issue already consumed more like 2 weeks of constant failing. Is it so hard or is it just me? ![205506-image.png][1] [1]: \/api\/attachments\/205506-image.png?platform=QnA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding input and output parameter to a DatabricksStep",
        "Question_created_time":1654710154713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/881980\/adding-input-and-output-parameter-to-a-databrickss",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p><a href=\"\/users\/na\/?userid=bc467a93-95da-4dea-bc82-06951da4cfad\">@romungi-MSFT  <\/a>    <\/p>\n<p>Hello,    <\/p>\n<p>We are using AMLS for creating and registering a pipeline which runs on a pre-defined Databricks cluster.    <br \/>\nIn the AMLS workspace, there is our Databricks notebook which should be executed in the DatabricksStep.    <\/p>\n<p>We want to save a file into a Blob-storage container. Therefore, we have added the parameters &quot;outputs&quot; and &quot;notebook_params&quot; to the DatabricksStep:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209539-image.png?platform=QnA\" alt=\"209539-image.png\" \/>    <\/p>\n<p>We would like to know how we can retrieve the output folder path within the Databricks notebook with the name &quot;basic_DatabricksStep_script.py&quot;.    <br \/>\nWith PythonScriptStep this worked using the following commands:     <\/p>\n<pre><code>import argparse  \nparser = argparse.ArgumentParser()  \nparser.add_argument('output', type=str, dest='output', default='output', help='given output data folder name')   \nargs = parser.parse_args()  \noutput_data_folder_path = args.output  \n<\/code><\/pre>\n<p>How will this work with a DatabricksStep?    <\/p>\n<p>We are aware of this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-use-databricks-as-compute-target.ipynb\">notebook<\/a>, but we need additional support to solve our issue.    <br \/>\nIt would be great if you could provide exemplary code and also show us how we can add the input parameter to the DatabricksStep so that we can read Datasets which are registered in AMLS.    <\/p>\n<p>Thank you in advance for your efforts!    <\/p>\n<p>With best regards    <br \/>\nAlex    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Python code for a generalized lineare model in Azure machine learning",
        "Question_created_time":1654699584787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/881821\/python-code-for-a-generalized-lineare-model-in-azu",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello guys,     <br \/>\nI am currently training a model to price boat types around the world using about 30,000 records of historical sales from the last 7 years. The approach is currently a linear regression in Azure ML studios.     <\/p>\n<p>Using 60 variables such as number of engines, year of construction, bedroom, brand etc. which have already been normalized and split into a training set and a testing set, the purchase price of a given boat is evaluated, depending on the port.     <\/p>\n<p>Now I would like to use a generalized linear model with family gamma and the link function identity to train a better model and thus get a better price estimation.     <\/p>\n<p>Unfortunately there is no module included in Azure machine learning for this. Has anyone ever written code for a GLM in Azure machine learning or can tell me how complex this is?     <\/p>\n<p>I would appreciate any help and have a nice weekend! <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML model predictions do not match scored model",
        "Question_created_time":1644551791223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/731481\/azureml-model-predictions-do-not-match-scored-mode",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have deployed a model to an endpoint but the predictions that come back do not match what is output from the scored model in the experiment.  <\/p>\n<p>The model is a Multiclass Neural Network for classifying emails - it takes approx. 1,000 elements of text and puts them into one of about 18 possible categories.   <\/p>\n<p>Reviewing the scored model outputs in the experiment, the accuracy is reasonable; however once deployed it always predicts any input into a single category with near 100% confidence.  The input is correctly formatted (this is validated in the model output) so I'm assuming something is misconfigured in the model deployment, but I'm not seeing any indication as to what.  <\/p>\n<p>Appreciate any help from MSFT in investigating this issue.  <\/p>\n<p>Cheers, James<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to specify do not allow reuse in Azure Machine Learning designer",
        "Question_created_time":1617640132493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/344626\/how-to-specify-do-not-allow-reuse-in-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_body":"<p>Is there a way in the AML designer to set a pipeline and\/or specific step to now allow reuse between runs?  I've seen quite a few posts on how to do this in code, but I can't seem to find a way to set that property in the designer.<\/p>",
        "Question_closed_time":1617671557013,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>Use the following steps to update a module pipeline parameter:    <\/p>\n<p>At the top of the canvas, select the gear icon.    <br \/>\nIn the Pipeline parameters section, you can view and update the name and default value for all of your pipeline parameter.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/84664-image.png?platform=QnA\" alt=\"84664-image.png\" \/>    <\/p>\n<p>Hope this helps. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Keep getting errors",
        "Question_created_time":1653443560630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/862913\/keep-getting-errors",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,  <br \/>\nI keep getting errors in both ML Studio (classic) and ML Azure Designer. I initially encountered an internal server error 0000 in ML Studio and have attempted to create a dataset cluster (I think) in ML Designer, only to also have Error 500 pop up, so I can't complete the pipeline. I need to do this for school and am frustrated. I'm also trying to see if re-creating the experiment as a different project will work. I need help with this issue and Microsoft support hasn't replied yet.  <br \/>\nThanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NEW Azure ML vs On-Prem SQL",
        "Question_created_time":1638277834353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646058\/new-azure-ml-vs-on-prem-sql",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I understand there was a process how to connect to on-prem sql db from Azure ML studio, but with the transition to the new UI, I don't see the option to connect to the gateway. I have it successfully installed and registered in MS Azure, but from Studio it simply does not offer it as a dataset type when using the Import Data module.  <br \/>\nI can't find any documentation regarding the new UI nor any useful guides for this.  <\/p>\n<p>Would anybody know whether this function is still available in the new studio and if so how can an on-prem gateway be connected?  <\/p>\n<p>Thank you,  <br \/>\nVS<\/p>",
        "Question_closed_time":1638351388393,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=63e55afc-7396-4eb1-8eec-945a013b20aa\">@sorcrow  <\/a>     <\/p>\n<p>Thanks for reaching out to us. I just got confirmation from the pm of AML, on-prem SQL is not supported in AML yet, but it's now on our plan.     <\/p>\n<p>I will forward your feedback to product team as well.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"error accessing azure dataset from local project in pipeline , gives a wrong path of dataset",
        "Question_created_time":1653853868117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/868657\/error-accessing-azure-dataset-from-local-project-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>hi, I am new to azure and i work in a project where I have to launch a pipeline to prep data and train , so first thing I used my_dataset.as_named_input('name_dataset') as an input like this :<\/p>\n<p>data_prep_step = PythonScriptStep(  <br \/>\nscript_name=prep_entry_point,  <br \/>\nsource_directory=source_dir,  <br \/>\narguments=[ &quot;--prep_output&quot;, output_data1],  <br \/>\ncompute_target=pipeline_cluster,  <br \/>\ninputs=[my_dataset.as_named_input(my_dataset)],  <br \/>\nrunconfig=aml_run_config,  <br \/>\nallow_reuse=True  <br \/>\n)<\/p>\n<p>but when testing the pipeline I get the error because of my_dataset.as_named_input('name_dataset') returns diffrent path to my dataset  <br \/>\nwhen testing in Azure ml workspace it works fine , can anyone help me please ..<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Designer - Webservice input\/output disappear",
        "Question_created_time":1653385681273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/861882\/azure-machine-learning-designer-webservice-input-o",
        "Question_score_count":0,
        "Question_answer_count":8,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I'm trying to create an inference pipeline with the AML designer.     <br \/>\nI clicked on the &quot;Create inference pipeline&quot; button:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205064-image.png?platform=QnA\" alt=\"205064-image.png\" \/>    <\/p>\n<p>and now I want to do some changes in the pipeline. I added at the end two more steps and linked the Webservice output component to the last step:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205028-image.png?platform=QnA\" alt=\"205028-image.png\" \/>    <\/p>\n<p>I clicked on save and submit it.     <br \/>\nThe result is the following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204999-image.png?platform=QnA\" alt=\"204999-image.png\" \/>    <\/p>\n<p>The two new steps are present and executed, but the webservice output step is disappeared! I've tried multiple time with the same result.     <br \/>\nThe webservice input step is correctly present at the beginning of the pipeline.    <\/p>\n<p>Also, after making the change and saving correctly, if I exit and reopen the pipeline the step &quot;Web Service Output&quot; is no longer there    <\/p>\n<p>Can you help me?    <\/p>\n<p>Thanks!    <\/p>\n<p>G    <\/p>",
        "Question_closed_time":1654609016260,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=061108cd-43c2-45e6-aefa-0aaa3ab2e335\">@Antonio  <\/a>,     <\/p>\n<p>Sorry for the inconvenience caused.    <br \/>\nThis is a known bug and we've fixed. Could you please retry to see if you can still repro? I tried from my side either manually build an inference pipeline or modify the auto-gen inference pipeline, the web service input\/output components are still there.     <\/p>\n<p>If you can still repro, could you please provide following info for us to investigate?    <\/p>\n<ul>\n<li> your inference pipeline draft URL    <\/li>\n<li>  inference pipeline job URL of which the webservice input\/output components disappear    <\/li>\n<li> Is your workspace in Vnet?    <\/li>\n<\/ul>\n<p>We're also happy to set up a call to investigate, could you please send me an email so that I can send the meeting request?     <br \/>\nWe're based in Beijing (UTC+8).    <\/p>\n<p>Thanks!     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Custom docker based Azure Environment is failing",
        "Question_created_time":1653668695787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/867368\/custom-docker-based-azure-environment-is-failing",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I have an custom docker based environment for running R scripts inside AzureML pipeline. It was working fine last week. Today I see some weird error.    <\/p>\n<p><strong>Response status code does not indicate success: 400 (BaseImage, BaseDockerfile, or BuildContext must be set for Docker-based environments.).    <br \/>\nMicrosoft.RelInfra.Common.Exceptions.ErrorResponseException: BaseImage, BaseDockerfile, or BuildContext must be set for Docker-based environments.<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/206228-image.png?platform=QnA\" alt=\"206228-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can not use AutoML models",
        "Question_created_time":1653642599833,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/866814\/can-not-use-automl-models",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have run an autoML model and in the jobs window of the studio, I can see it worked as I can see all the models generated under different algorithms and their performance. Then in notebook I am trying to retrive the best performing model and I am calling the AUTOML model using:  <\/p>\n<p>local_run = AutoMLRun(experiment, &quot;AutoML_5970dd9a-1dae-4e6b-90ff-47878565822f_0&quot;,outputs=None)  <\/p>\n<p>which works just fine and then:  <\/p>\n<p>best_run, fitted_model = local_run.get_output()  <\/p>\n<p>and there is an error that I dont know how to solve:  TypeError: the JSON object must be str, bytes or bytearray, not NoneType  <\/p>\n<p>So please your help to solve this!  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error Running Azure ML Training Script",
        "Question_created_time":1651574593590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/834730\/error-running-azure-ml-training-script",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,     <\/p>\n<p>I am receiving the following error message when running an experiment script in Azure Machine Learning Studio    <\/p>\n<p><em>&quot;AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling&quot;<\/em>    <\/p>\n<p>Microsoft have stated;    <\/p>\n<p><em>&quot;This is not an error scenario, but is handled like one by Azure AD to handle certain authentication flows. This is not an indication that anything went wrong.&quot;<\/em>    <\/p>\n<p>However my experiment run has failed as can ben seen below;    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/198532-image.png?platform=QnA\" alt=\"198532-image.png\" \/>    <\/p>\n<p>Could someone please advise how to correct this error.. thank you    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Recover a missing AML Run",
        "Question_created_time":1653661664120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/867216\/recover-a-missing-aml-run",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,   <\/p>\n<p>Is it possible to recover an Azure ML Run that seems to have been deleted? I can still see the files in Blob Storage, but it's not showing up in the AML portal.  <\/p>\n<p>Thanks,  <br \/>\nMelissa<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No input to R Module from split data",
        "Question_created_time":1651768794243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/838149\/no-input-to-r-module-from-split-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,  <br \/>\n  I use r script to predict an outcome from training and testing data from classic studio, somehow couldn't input training\/testing data to it.  <\/p>\n<p>  So I used split to input to dataset1, dataset2 ports, but no input, how would it work?  <\/p>\n<p>Plz help!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - A child experiment runs the parent's script not the child's script",
        "Question_created_time":1654187375363,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/874717\/azure-ml-a-child-experiment-runs-the-parents-scrip",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>As from today the behavior of child experiments in Azure Machine Learning has changed. Instead of running the child's script it will run the parent's script again. Anyone have any thoughts on the issue?    <\/p>\n<p>Take the following:    <br \/>\n<strong>Submit the parent with<\/strong>:    <\/p>\n<pre><code>from azureml.core import Experiment, ScriptRunConfig, Workspace  \n  \nws = Workspace.from_config()  \nexp = Experiment(workspace=ws, name=&quot;tests&quot;)  \n  \nconfig = ScriptRunConfig(  \n    source_directory=&quot;.&quot;,  \n    script=&quot;test_parent.py&quot;,  \n    compute_target=&quot;cluster-00&quot;,  \n)  \nrun = exp.submit(config=config)  \n<\/code><\/pre>\n<p><strong>test_parent.py<\/strong>    <\/p>\n<pre><code>from azureml.core import Run, ScriptRunConfig  \n  \nprint(&quot;Inside parent.&quot;)  \n  \nrun = Run.get_context()  \n  \nchild_config = ScriptRunConfig(  \n    source_directory=&quot;.&quot;,  \n    script=&quot;test_child.py&quot;,  \n    compute_target=&quot;cluster-00&quot;,  \n)  \nrun.submit_child(config=child_config)  \n<\/code><\/pre>\n<p><strong>test_child.py<\/strong>    <\/p>\n<pre><code>print(&quot;Inside child.&quot;)  \n<\/code><\/pre>\n<p><strong>std_log.txt of parent run<\/strong>:    <\/p>\n<pre><code>Inside parent.  \nCleaning up all outstanding Run operations, waiting 300.0 seconds  \n2 items cleaning up...  \nCleanup took 0.1929168701171875 seconds  \n  \n<\/code><\/pre>\n<p><strong>std_log.txt of child run<\/strong>:    <\/p>\n<pre><code>Inside parent.  \nleaning up all outstanding Run operations, waiting 300.0 seconds  \n0 items cleaning up...  \nCleanup took 7.152557373046875e-07 seconds  \n  \n<\/code><\/pre>\n<p>Even though the details of the child include the correct script:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/207973-image.png?platform=QnA\" alt=\"207973-image.png\" \/>    <\/p>\n<p>On a side note, things have changed overnight. The interface is slightly different, especially the output of runs, even the file names. Even I was suddenly having permission issues with python's  <code>subprocess.run<\/code>. So, I'm guessing something changed in the SDK I am unaware of.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Passing data between AzureML pipeline steps with OutputFileDatasetConfig: difference between 'inputs\/outputs' and 'arguments'?",
        "Question_created_time":1654156643450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/874019\/passing-data-between-azureml-pipeline-steps-with-o",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>I have been successfully building and operating machine learning pipelines with Azure SDK, but there is something I fail to fully understand, and I'm wondering if my code can be simplified in some way.<\/p>\n<p>Let's say I have a simple pipeline with two steps: the first step processes data located at 'training_data_path' in Blob storage and then saves it to the same location, and the second step reads that processed data to do something else. So my code is as follows:<\/p>\n<pre><code>def_data_store = ws.get_default_datastore()\ntraining_data_path = (def_data_store, 'training_data')\n\nstep_1_config = OutputFileDatasetConfig(destination = training_data_path)\nstep_2_config = OutputFileDatasetConfig(destination = training_data_path)\n\nstep_1 = PythonScriptStep(\n    name=&quot;Step 1&quot;,\n    script_name=&quot;step_1.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    outputs=[step_1_config],\n    arguments = [\n        &quot;--training-data-path&quot;, step_1_config\n        ],    \n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=False\n)\n\nstep_2 = PythonScriptStep(\n    name=&quot;Step 2&quot;,\n    script_name=&quot;step_2.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    inputs=[step_1_config.as_input('training_data')],\n    arguments = [\n        &quot;--training-data-path&quot;, step_2_config\n        ],    \n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>I have two questions about that:<\/p>\n<p>1) Even though the path to the data is the same in each step, it seems like I have to create a separate OutputFileDatasetConfig object for each step. So if my pipeline has 10 steps, I will create step_1_config, step_2_config, step_3_config... Isn't there a way to reuse the same OutputFileDatasetConfig object for multiple steps?<\/p>\n<p>2) As far as I know, in step 2, I could delete the 'inputs' parameter and modify the 'arguments' parameter as follows, the result would be the same.<\/p>\n<pre><code>step_2 = PythonScriptStep(\n    name=&quot;Step 2&quot;,\n    script_name=&quot;step_2.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    arguments = [\n        &quot;--training-data-path&quot;, step_1_config.as_input('training_data')\n        ],    \n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>My question is: is there any difference when specifying the input using both the 'inputs' and 'arguments' parameters Vs. using only the 'arguments' parameter?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":1654261344427,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@ThierryL-3166 I think the recommendation to use separate OutputFileDatasetConfig objects for different steps is to avoid concurrent writes to a single object. As stated in a note in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines#use-outputfiledatasetconfig-for-intermediate-data\">documentation<\/a>:    <\/p>\n<pre><code>Concurrent writes to a OutputFileDatasetConfig will fail. Do not attempt to use a single OutputFileDatasetConfig concurrently. Do not share a single OutputFileDatasetConfig in a multiprocessing situation, such as when using distributed training.  \n<\/code><\/pre>\n<p>If your steps do not run in parallel then you can try to use a single object and check though.    <\/p>\n<p>With respect to using inputs or arguments, If you are using the same for the same operation then arguments would pass the same as input to the script used in the same step and you would need to use an argparser to retrieve the value in the script. Whereas, inputs would provide the same value as the run objects context in the same script. The section <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines#access-datasets-within-your-script\">access datasets within script<\/a> provides an example here for a train and test dataset where train is passed with arguments and test with inputs.    <\/p>\n<pre><code>smaller_dataset = iris_dataset.take_sample(0.1, seed=seed) # 10%  \ntrain, test = smaller_dataset.random_split(percentage=0.8, seed=seed)  \n  \n# In pipeline definition script:  \n# Code for demonstration only: It would be very confusing to split datasets between `arguments` and `inputs`  \ntrain_step = PythonScriptStep(  \n    name=&quot;train_data&quot;,  \n    script_name=&quot;train.py&quot;,  \n    compute_target=cluster,  \n    arguments=['--training-folder', train.as_named_input('train').as_download()],  \n    inputs=[test.as_named_input('test').as_download()]  \n)  \n  \n# In pipeline script  \nparser = argparse.ArgumentParser()  \nparser.add_argument('--training-folder', type=str, dest='train_folder', help='training data folder mounting point')  \nargs = parser.parse_args()  \ntraining_data_folder = args.train_folder  \n  \ntesting_data_folder = Run.get_context().input_datasets['test']  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Studio Quotas for Assisted Labeling and Training Object Detection Model",
        "Question_created_time":1653585502077,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/865733\/azure-ml-studio-quotas-for-assisted-labeling-and-t",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>In an Azure ML Studio labeling project, I have tried to enable Assisted Labeling. I get the error message &quot;Error: There is insufficient quota to create a gpu compute target. You can request more quota and create a custom compute to enable ML assisted labeling.&quot;   <\/p>\n<p>I also get a similar error message when I try to train an object detection model, &quot;\u201cSTANDARD_D2AS_V4 is not supported for image tasks. Please choose a VM type that is in the NC-family or the ND-family.&quot;   <\/p>\n<p>I requested and was granted &quot;Standard NC Family Cluster Dedicated vCPUs\/GPUs. These show up in my quota, but if I go to create a compute target and select GPU, I get a message saying: &quot;You do not have enough quota for the following VM sizes.&quot; followed by a list of all the VMs that it says aren't in my quota including the NC family VMs.  <\/p>\n<p>And I still get the same two error messages saying I don't have enough quota for either Assisted Labeling or training an object detection model.  <\/p>\n<p>Does anyone know what I need to do to get these two services to work?  <\/p>\n<p>Thanks.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Integration with S3",
        "Question_created_time":1627977757003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/499465\/azure-machine-learning-integration-with-s3",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone,  <\/p>\n<p>I have a model in Azure Machine Learning service and the data for that model is residing in one of the S3 buckets of AWS, is there a way i can connect AMLS to AWS S3 as a data store and run my model on top of it.?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I export my project from Azure",
        "Question_created_time":1654324217247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/876500\/how-do-i-export-my-project-from-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi  <\/p>\n<p>I would like to know how I keep the studio and all the elements I have done in Azure.  <\/p>\n<p>I need them for a project but my subscription is expired and I'd like to keep what I've done.  <\/p>\n<p>I can't afford paying for a new subscription.<\/p>",
        "Question_closed_time":1654511768770,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7bce58ab-e1af-426d-8077-d01bec15c6a0\">@David GORGETTE  <\/a> You can export and delete your data from Azure using the guidance from this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-export-delete-data\">documentation<\/a>.     <br \/>\nPlease note Azure ML workspace uses resources like storage account, container registry, app insights and key vault to store information related to ML experiments, jobs and environments. Your run history is basically available from the storage containers along with the supporting data. You can download specific models that are required directly from Azure ML portal for easy identification. I hope this helps!!    <\/p>\n<p> If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do I create a resource group when creating a workspace?",
        "Question_created_time":1638162185497,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/643801\/how-do-i-create-a-resource-group-when-creating-a-w",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am going through the Azure AI training and need to create a workspace under machine learning. When it asks me to select a resource group there are no options. When I want to create a new resource group it says I dont have permissions under my subscription. What do I need to do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure machine learning SDK",
        "Question_created_time":1654035149473,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872050\/azure-machine-learning-sdk",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How to import data not by passing it as an argument,     <br \/>\nI do not want to do as the tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs<\/a><\/p>",
        "Question_closed_time":1654106099667,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=fd7f30ec-b4f1-4575-a425-a49ca6a1a14e\">@ben wu  <\/a>     <\/p>\n<p>Thanks for reaching out to us, there is the code sample from engineering team    <\/p>\n<pre><code>from azureml.core import ScriptRunConfig  \n  \ninput_data=titanic_ds.as_named_input('input_data').as_mount()  \nsrc = ScriptRunConfig(source_directory=script_folder,  \n                      script='train_titanic.py',  \n                      compute_target=compute_target)  \nsrc.run_config.data = {input_data.name: input_data }  \n# Submit the run configuration for your training run  \nrun = experiment.submit(src)  \nrun.wait_for_completion(show_output=True)    \n<\/code><\/pre>\n<p>In your script, you can get the mounted path via environment variable, which is the value you specified in as_named_input. For the sample code above, the environment variable will be input_data.    <\/p>\n<p>I hopet this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is machine learning SDK and designer pricing the same",
        "Question_created_time":1654035275890,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872161\/is-machine-learning-sdk-and-designer-pricing-the-s",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am able to find the pricing the page for SDK or designer, are they pricing the same?<\/p>",
        "Question_closed_time":1654080178613,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=fd7f30ec-b4f1-4575-a425-a49ca6a1a14e\">@ben wu  <\/a> Adding to <a href=\"\/users\/na\/?userid=8005b94c-3fff-0003-0000-000000000000\">@Dave Patrick  <\/a> response, Since you have used the tag azure-machine-learning tag I think you are using the latest version of Azure Machine Learning rather than classic studio. In the case of the new Azure Machine Learning studio and the SDK there will be no charge for using the service. You will only be charged for the compute used for your experiments and other Azure services consumed, including but not limited to Azure Blob Storage, Azure Key Vault, Azure Container Registry and Azure Application Insights. Please check the details of pricing for compute for Azure ML on this <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/machine-learning\/\">page<\/a>.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Real-time Endpoint Security",
        "Question_created_time":1654120145047,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/873592\/azure-ml-real-time-endpoint-security",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Our security team ran a scan against the real-time managed endpoint we just deployed in Azure ML. There was a critical risk regarding an outdated version of Squid being susceptible to a DoS attack. The recommended fix was to &quot;Upgrade to version 5.0.6 or higher for 5.x, 4.15 or higher for 4.x, or contact the vendor for a fix.&quot;.  <\/p>\n<p>Is Squid being used on the managed endpoints (is this an actual issue)?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML : TensorFlowDNN and TensorFlowLinearRegressor are blacklisted by default",
        "Question_created_time":1653464529937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/863297\/automl-tensorflowdnn-and-tensorflowlinearregressor",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am running an AutoML experiment for a regression task, and looking at the YAML file which is generated it seems that TensorFlowLinearRegressor and TensorFlowDNN models are listed as both 'supported_models' and 'blacklist_algos'.    <\/p>\n<p>I tried to deactivate the automatic blacklisting of models by specifying the parameter 'auto_blacklist' to False, and 'blacklist_models' and 'blacklist_algos' parameters to Null, but it doesn't change anything.    <\/p>\n<pre><code>automl_settings = {  \n    &quot;primary_metric&quot;: 'normalized_mean_absolute_error',  \n    &quot;featurization&quot;: 'auto',  \n    &quot;verbosity&quot;: logging.INFO,  \n    &quot;n_cross_validations&quot;: 5,  \n    &quot;auto_blacklist&quot;: False,  \n    &quot;blacklist_models&quot;: None,  \n    &quot;blacklist_algos&quot;: None  \n}  \nrun = experiment.submit(automl_config, show_output=True)  \n<\/code><\/pre>\n<p>The generated YAML file (excerpt):    <\/p>\n<pre><code>&quot;whitelist_models&quot;:null,  \n&quot;blacklist_algos&quot;:[&quot;TensorFlowDNN&quot;,&quot;TensorFlowLinearRegressor&quot;],  \n&quot;supported_models&quot;:[&quot;ElasticNet&quot;,&quot;GradientBoosting&quot;,&quot;LightGBM&quot;,&quot;TensorFlowLinearRegressor&quot;,&quot;TensorFlowDNN&quot;,&quot;LassoLars&quot;,&quot;DecisionTree&quot;,&quot;RandomForest&quot;,&quot;FastLinearRegressor&quot;,&quot;OnlineGradientDescentRegressor&quot;,&quot;ExtremeRandomTrees&quot;,&quot;TabnetRegressor&quot;,&quot;XGBoostRegressor&quot;,&quot;KNN&quot;,&quot;SGD&quot;],  \n&quot;private_models&quot;:[],  \n&quot;auto_blacklist&quot;:false  \n<\/code><\/pre>\n<p>Maybe the problem comes from the fact that Deep learning is set to 'Disabled' in the configuration settings, as shown on the following picture:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205364-image.png?platform=QnA\" alt=\"205364-image.png\" \/>    <\/p>\n<p>Are deep learning models not supported anymore by AutoML?    <\/p>",
        "Question_closed_time":1654236226443,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>@ThierryL-3166  Thanks for the question.     <\/p>\n<p>As mentioned in the below document The following support models in AutoML TensorFlowDNN, TensorFlowLinearRegressor are deprecated.     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.shared.constants.supportedmodels.regression?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.shared.constants.supportedmodels.regression?view=azure-ml-py<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Designer Or SDK",
        "Question_created_time":1654023398370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/871933\/designer-or-sdk",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have tried both of them, I feel like Designer is more convenient but some of the function lack. Will same feature support in Designer or Designer just junior toy? Thx.<\/p>",
        "Question_closed_time":1654037857797,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=3d6a9d61-6cf9-45d8-870d-2fbbf147f56d\">@Chungsun  <\/a>     <\/p>\n<p>It's not the truth. Designer is under develoment, while there are some feature not available in Designer but n SDK, they will be implemented eventually in Designer.     <\/p>\n<p>Moreover, Designer is more friendly to new user who is not good at coding.    <\/p>\n<p>It just depends on your habit and preference.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why PyTorch is using only one GPU ?",
        "Question_created_time":1653503234337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864175\/why-pytorch-is-using-only-one-gpu",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Azure does not use the two GPUs of my node with PyTorch (and Hugging Face). The monitoring tool of Azure shows the GPU usage is stuck at 50%.    <br \/>\nIts a Standard_NC12, so it has two K80s.    <\/p>\n<p>I tried this way :    <br \/>\n<a href=\"https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch\">https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch<\/a>    <br \/>\nand it looked like this in my notebook :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205547-capture-decran-2022-05-25-a-81119-pm.png?platform=QnA\" alt=\"205547-capture-decran-2022-05-25-a-81119-pm.png\" \/>    <\/p>\n<p>I copied the docker file from the curated environments and added the libraries I needed successfully :    <\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220329.v1  \n  \nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/pytorch-1.10  \n  \n# Create conda environment  \nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\  \n    python=3.8 \\  \n    pip=20.2.4 \\  \n    pytorch=1.10.0 \\  \n    torchvision=0.11.1 \\  \n    torchaudio=0.10.0 \\  \n    cudatoolkit=11.1.1 \\  \n    nvidia-apex=0.1.0 \\  \n    gxx_linux-64 \\  \n    -c anaconda -c pytorch -c conda-forge  \n  \n# Prepend path to AzureML conda environment  \nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH  \n  \n# Install pip dependencies  \nRUN pip install 'matplotlib&gt;=3.3,&lt;3.4' \\  \n                'psutil&gt;=5.8,&lt;5.9' \\  \n                'tqdm&gt;=4.59,&lt;4.63' \\  \n                'pandas&gt;=1.3,&lt;1.4' \\  \n                'scipy&gt;=1.5,&lt;1.8' \\  \n                'numpy&gt;=1.10,&lt;1.22' \\  \n                'ipykernel~=6.0' \\  \n                'azureml-core==1.40.0' \\  \n                'azureml-defaults==1.40.0' \\  \n                'azureml-mlflow==1.40.0' \\  \n                'azureml-telemetry==1.40.0' \\  \n                'tensorboard==2.6.0' \\  \n                'tensorflow-gpu==2.6.0' \\  \n                'onnxruntime-gpu&gt;=1.7,&lt;1.10' \\  \n                'horovod==0.23' \\  \n                'future==0.18.2' \\  \n                'wandb' \\  \n                'transformers' \\  \n                'einops' \\  \n                'torch-tb-profiler==0.3.1'  \n  \n  \n# This is needed for mpi to locate libpython  \nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH  \n  \nRUN export CUDA_VISIBLE_DEVICES=0,1  \n<\/code><\/pre>\n<p>I tried everything, I even added the CUDA_VISIBLE_DEVICES=0,1 inside the docker file.    <\/p>\n<p>My cluster is correctly configured because my colleague can use another tool (Detr with Lightning) and use 100% of the computing power.    <br \/>\nI copied his docker file and the result was the same, so our guess is that his tool is automatically managing all GPUs for him.    <\/p>\n<p>Does anyone know why the cluster is using only one GPU ?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"memory outage while running module",
        "Question_created_time":1653902834057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869594\/memory-outage-while-running-module",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am encountering an issue of error 0138, while training the data, at the end it shows memory has been exhausted exception  <\/p>\n<p>I do not think my data has exceed the limit of azure ML studio, is there any way to solve this?<\/p>",
        "Question_closed_time":1653942581987,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d4454683-c6fe-4103-a1a8-d167ab8d04de\">@darya  <\/a>     <\/p>\n<p>Thanks for reaching out to us. This issue seldoms happen.  Could you please share your structure to us and how is your dataset size? Based on the error info, too many steps in your experiment may cause that.     <\/p>\n<p>I would suggest you try to remove some unnecessary one to try and see. If you believe your structure is reasonable, please share it to us. But it should be fine if you have not put too much.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer to help the community if you feel helpful, thanks.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML and ML.net which is better",
        "Question_created_time":1653905877517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869589\/azure-ml-and-ml-net-which-is-better",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am newly starting in machine learning field with basic training now.  <br \/>\nI am not sure about the difference and whichever should be used for beginner <\/p>",
        "Question_closed_time":1653921374097,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=9836544a-a7dc-4344-a8ac-804ab892757e\">@Joel  <\/a>  Thanks for the question. Azure ML is a cloud service where you pay for the compute power that you &quot;burn&quot; whereas ML.NET is a Toolkit for . net that you can run anywhere. You don't pay anything for using ML.NET itself.     <\/p>\n<p>Azure ML Empower data scientists and developers to build, deploy, and manage high-quality models faster and with confidence. Here is the <a href=\"https:\/\/azure.microsoft.com\/en-in\/services\/machine-learning\/#product-overview\">document<\/a> for Azure ML.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How can I access my trained model file in Azure ML?",
        "Question_created_time":1653451827867,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/863039\/how-can-i-access-my-trained-model-file-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am developing a machine learning model with Azure ML using the Python SDK.    <\/p>\n<p>The saved model is in the location shown in the screenshot (from the log file).    <br \/>\nI would like to ask the followings;    <\/p>\n<ol>\n<li> How can I access that location?    <\/li>\n<li> I want to use the saved model in another script. Is it possible to save the model on my local computer (during the training) where my script is?    <\/li>\n<\/ol>\n<p>Thank you.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205314-screenshot-2022-05-25-130647.png?platform=QnA\" alt=\"205314-screenshot-2022-05-25-130647.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tensorflow and Azure machine learning",
        "Question_created_time":1653989511207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/871068\/tensorflow-and-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is azure working well with Tensorflow framework? I don\u2019t see any document about it. Any help is good.<\/p>",
        "Question_closed_time":1653992769017,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=3d6a9d61-6cf9-45d8-870d-2fbbf147f56d\">@Chungsun  <\/a>    <\/p>\n<p>Welcome to the Microsoft Q&amp;A Platform,    <\/p>\n<p>TensorFlow is supported on Azure Machine Learning:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-tensorflow\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-tensorflow<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-functions\/functions-machine-learning-tensorflow?tabs=bash\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-functions\/functions-machine-learning-tensorflow?tabs=bash<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-keras\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-keras<\/a>    <\/p>\n<p>I hope this helps!      <\/p>\n<p>----------    <\/p>\n<p>Please don\u2019t forget to &quot;<strong>Accept the answer<\/strong>&quot; and \u201c<strong>up-vote<\/strong>\u201d wherever the information provided helps you, this can be beneficial to other community members.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Anyways to have multiple webservice output?",
        "Question_created_time":1653904138797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869627\/anyways-to-have-multiple-webservice-output",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is training two web service at the same time doable in studio ? Since I want to train with multiple models but it seems only one would work<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to predict train model time",
        "Question_created_time":1653903513477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869641\/how-to-predict-train-model-time",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How to predict the time for train model for data with 10 millions lines and zero columns with decision tree?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't add modules to Pipeline Design (Azure)",
        "Question_created_time":1653921047177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869925\/cant-add-modules-to-pipeline-design-(azure)",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm doing the training and I have to design a pipeline. However, when adding modules, in the components' column, only 2 modules show (web services related) when there should be at least 20. Of course, all filters are deactivated. I don't know why this happens but I can't continue my work.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiments stuck in queue",
        "Question_created_time":1652977917790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/856662\/experiments-stuck-in-queue",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <br \/>\nI am trying to run some experiments for a data analytics course but every time I hit run, it shoes as 'Queued' and does not run. It used to run but now my experiments- including new ones- are stuck in a queued state.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run Python Script in Azure Machine Learning pipeline",
        "Question_created_time":1652785260630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/852593\/run-python-script-in-azure-machine-learning-pipeli",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi    <\/p>\n<p>I have a python script which will take parameters from Azure Data Factory and automatically register Datasets in Azure ML Workspace. I have already prepared this script. And I have run in the Notebooks and is working fine.    <\/p>\n<p>I want to create a Pipeline in AML and call this python Script which will not have any input datasets and call this pipeline from ADF using PipelineID.     <\/p>\n<p>But when I am creating a Pipeline, system is showing default function azureml_main. I do not want to use this. How to solve this issue    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/202737-image.png?platform=QnA\" alt=\"202737-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parallel training",
        "Question_created_time":1653904605807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869619\/parallel-training",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Can I train models in parallel? Is is possible to train model in parallel on like hyperdrive?<\/p>",
        "Question_closed_time":1653922130807,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=3d6a9d61-6cf9-45d8-870d-2fbbf147f56d\">@Chungsun  <\/a>  Thanks for the question. The max number of parallel tasks is limited by number of cores in the cluster (excluding master node).    <br \/>\nThe demand for parallelism comes from two sources: 1. The cross validation which address multiple combination of train-val datasets &amp; parameters 2. The training algorithm itself which can be parallelized.    <\/p>\n<p>\u2022\tYou can run multiple runs in a distributed fashion across AML clusters, meaning that each cluster node can be running a run in parallel to other nodes running other runs. For instance, that\u2019s what we also do with Pipeline steps, HyperParameter Tunning child runs and for Azure AutoML child runs.    <\/p>\n<p> <a href=\"https:\/\/github.com\/microsoft\/solution-accelerator-many-models\"> https:\/\/aka.ms\/many-models<\/a> is a solution accelerator that will help you walk through to run many models.     <br \/>\nIn the HyperDriveConfig there is AMLcompute max_concurrent_runs map to maximum number of nodes that will be used to run  a hyperparameter tuning run. So there would be 1 execution per node.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Migrate to portal studio",
        "Question_created_time":1653988049527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/871064\/migrate-to-portal-studio",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Experts,  <\/p>\n<p>I just try studio classic which is good but retired soon  <\/p>\n<p>I am moving to the new studio in azure portal. Any guidance for newbie?<\/p>",
        "Question_closed_time":1653988525023,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=e2f80e7a-2be8-4813-bb67-9ef92ac27f43\">@Alexandre  <\/a>     <\/p>\n<p>Welcome to Microsoft Q&amp;A Platform,    <\/p>\n<p>I would start checking the docs below:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset<\/a>    <\/p>\n<p>I hope this helps!      <\/p>\n<p>----------    <\/p>\n<p>Please don\u2019t forget to &quot;<strong>Accept the answer<\/strong>&quot; and \u201c<strong>up-vote<\/strong>\u201d wherever the information provided helps you, this can be beneficial to other community members.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to deploy pipeline in Azure ML Studio?",
        "Question_created_time":1653529001740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864494\/how-to-deploy-pipeline-in-azure-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Doesn't seem to find the button for deploying pipeline...<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Copy experiment within workspace",
        "Question_created_time":1653905030690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869578\/copy-experiment-within-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>How to duplicate experiments within workspace during debugging<\/p>",
        "Question_closed_time":1653987284413,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=e2f80e7a-2be8-4813-bb67-9ef92ac27f43\">@Alexandre  <\/a>     <\/p>\n<p>Are you mentioning studio classic? You can click the save as buttion and then you can save the experience and duplicate it, if you are mentioning studio, sorry, you can not do that.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"inference pipeline option not available",
        "Question_created_time":1626831334850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/483466\/inference-pipeline-option-not-available",
        "Question_score_count":2,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_body":"<p>After running the pipeline, I do not see the dropdown option for create inference pipeline, only the Run or clone option...any idea?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/116463-image.png?platform=QnA\" alt=\"116463-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Notebook files have disaperred",
        "Question_created_time":1652875560357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/854288\/notebook-files-have-disaperred",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>In my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.    <\/p>\n<p>Please your help to solve this as soon as poosible.    <\/p>\n<p>Thank you.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203167-image.png?platform=QnA\" alt=\"203167-image.png\" \/>    <\/p>",
        "Question_closed_time":1652928385600,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>Thanks for reaching out to us. Could you please check the access of Storage?  <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\">https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role<\/a>    <\/p>\n<p>To access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.    <\/p>\n<p>Or, your admin put the data storage behind V-Net and you can not get access to it- <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks<\/a>    <br \/>\nIn this situation, you need to ask permission from your admin.    <\/p>\n<p>Could you please share which situation you are in?     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Volume mount failed with: DataAccessError(PermissionDenied) Azure-ML",
        "Question_created_time":1649877484300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/811757\/volume-mount-failed-with-dataaccesserror(permissio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I have created AzureML experiment where i am ingesting a dataset with azure SQL Server as source. below is the code.  <\/p>\n<pre><code>from azureml.core import Experiment, ScriptRunConfig, Environment\n\ninput_data = ws.datasets.get('azure_sql_data')\n\nexperiment_folder = 'experiment'\nenv = Environment.from_conda_specification(&quot;env&quot;, &quot;environment.yml&quot;)\n\nscript_config = ScriptRunConfig(source_directory=experiment_folder,\n                                script='tranformer.py',\n                                arguments = ['--input-data', input_data.as_named_input('input_data')],\n                                environment=env)\n<\/code><\/pre>\n<p>When i run this experiment i am getting following error. Dataset initialization failed: DataAccessError(PermissionDenied)  <\/p>\n<p>Am i missing something here?  <\/p>\n<p>I can access the azure SQL server data in while running it in aml notebook but when i run experiment i am getting above error.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem with connecting python script with web service output",
        "Question_created_time":1653133927230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/858550\/problem-with-connecting-python-script-with-web-ser",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Azure ML studio got new apperance and some problems happen. I did pipeline like this:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204312-1.png?platform=QnA\" alt=\"204312-1.png\" \/>    <\/p>\n<p>and then created inference pipeline:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204256-2.png?platform=QnA\" alt=\"204256-2.png\" \/>    <\/p>\n<p>I would like to connect python script like this(in the previous version on azure it works) to Web Service Output:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204187-image.png?platform=QnA\" alt=\"204187-image.png\" \/>    <\/p>\n<p>But when i submit it now the connection is changing and execution is not apply.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204304-image.png?platform=QnA\" alt=\"204304-image.png\" \/>    <\/p>\n<p>How to fix this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Install and load Tidymodels package in AML",
        "Question_created_time":1653509127043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864244\/install-and-load-tidymodels-package-in-aml",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying install and load some R packages in the Execute R Script in Azure Machine Learning for to run models, such as <strong>tidymodels, timetk, modeltime, modeltime.ensemble<\/strong>.  <\/p>\n<pre><code>library(forecast)\nlibrary(tidyverse)\nlibrary(lubridate)\ninstall.packages(&quot;quantdates&quot;,repos = &quot;https:\/\/cloud.r-project.org&quot;)\ninstall.packages(&quot;tidymodels&quot;,repos = &quot;https:\/\/cloud.r-project.org&quot;)\nlibrary(quantdates)\nlibrary(tidymodels) \nlibrary(timetk) \nlibrary(modeltime) \nlibrary(modeltime.resample) \nlibrary(modeltime.ensemble)\n<\/code><\/pre>\n<p>However I get the following error:  <\/p>\n<pre><code>Error: package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\nnamespace \u2018rlang\u2019 0.4.5 is already loaded, but &gt;= 1.0.2 is required\nazureml_main(input_dataframe_1), library(tidymodels), tryCatch({\n    attr(package, &quot;LibPath&quot;) &lt;- which.lib.loc\n    ns &lt;- loadNamespace(package, lib.loc)\n    env &lt;- attachNamespace(ns, pos = pos, deps)\n}, error = function(e) {\n    P &lt;- if (!is.null(cc &lt;- conditionCall(e))) \n        paste(&quot; in&quot;, deparse(cc)[1])\n    else &quot;&quot;\n    msg &lt;- gettextf(&quot;package or namespace load failed for %s%s:\\n %s&quot;, sQuote(package), P, conditionMessage(e))\n    if (logical.return) \n        message(paste(&quot;Error:&quot;, msg), domain = NA)\n    else stop(msg, call. = FALSE, domain = NA)\n}), tryCatchList(expr, classes, parentenv, handlers), tryCatchOne(expr, names, parentenv, handlers[[1]]), value[[3]](cond), stop(msg, call. = FALSE, domain = NA), .handleSimpleError(function (e) \n{\n    error_msg &lt;&lt;- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = &quot;\\n&quot;)\n    stop(e)\n}, &quot;package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\\n namespace \u2018rlang\u2019 0.4.5 is already loaded, but &gt;= 1.0.2 is required&quot;, quote(NULL)), h(simpleError(msg, call))\n'.\n---------- End of error message from R  interpreter  ----------\n<\/code><\/pre>\n<p>I have also tried with devtools package for install a particular version but I keep getting the same error with the <strong>rlang package<\/strong>. Sometimes, I get the same error with the <strong>cli package<\/strong>.  <\/p>\n<p>In my local machine, the R code runs fine. I have the R version 4.1.3 and the Azure Machine Learning has the R version 3.5.1.  <\/p>\n<p>Does anyone know how I can solve this problem?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accessing different model versions from same endpoint",
        "Question_created_time":1653539509343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864579\/accessing-different-model-versions-from-same-endpo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am using model versioning and would like to have different model versions accessible via the same endpoint. Any best practices to access the multiple models from the same endpoint.<\/p>",
        "Question_closed_time":1653550999480,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks, You may deploy \u201clocally\u201d to a Azure Machine Learning compute instance, by specifying different port # for each version. They are converted to a URL according to the format https:\/\/&lt;compute instance\u2019s name&gt;-port.region.instances.azureml.ms\/score    <\/p>\n<p>Model v1: service_url = <a href=\"https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score\">https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score<\/a>    <br \/>\nModel v2: service_url = https:\/\/ azure-ml-compute-instance-name-8002.westeurope.instances.azureml.ms\/score    <\/p>\n<p>There\u2019s sample code in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-local-container-notebook-vm\">documentation<\/a>. You can specify port to deploy with the following parameter.    <br \/>\ndeployment_config = LocalWebservice.deploy_configuration(port=8001)    <\/p>\n<p>We recommend using the new ML Endpoints (Preview) <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\">What are endpoints (preview) - Azure Machine Learning | Microsoft Learn<\/a>.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Predictions on new data with a deployed ML model as a pipeline - problem with data input format",
        "Question_created_time":1653475763427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/863614\/predictions-on-new-data-with-a-deployed-ml-model-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My question is somehow related to <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html<\/a> - however, the provided solution does not seem to work.<\/p>\n<p>I am constructing a simple model with heart-disease dataset but I wrap it into Pipeline as I use some featurization steps (scaling, encoding etc.) The full script below:<\/p>\n<pre><code>   import pandas as pd  \n   import numpy as np  \n   from sklearn.preprocessing import MinMaxScaler  \n   from sklearn.compose import ColumnTransformer  \n   from sklearn.preprocessing import OneHotEncoder  \n   from sklearn.pipeline import Pipeline  \n   from sklearn.model_selection import train_test_split  \n   from sklearn.impute import SimpleImputer  \n   from sklearn.linear_model import LogisticRegression  \n   %matplotlib inline  \n   import matplotlib.pyplot as plt  \n   import seaborn as sns  \n   import joblib  \n   import pickle  \n\n   # data input  \n   df = pd.read_csv('heart.csv')  \n\n   # numerical variables  \n   num_cols = ['age',  \n               'trestbps',  \n               'chol',  \n               'thalach',  \n               'oldpeak'  \n   ]  \n\n   # categorical variables  \n   cat_cols = ['sex',  \n               'cp',  \n               'fbs',  \n               'restecg',  \n               'exang',  \n               'slope',  \n               'ca',  \n               'thal']  \n\n   # changing format of the categorical variables  \n   df[cat_cols] = df[cat_cols].apply(lambda x: x.astype('object'))  \n\n   # target variable  \n   y = df['target']  \n\n   # features  \n   X = df.drop(['target'], axis=1)  \n\n   # data split:  \n\n   # random seed  \n   np.random.seed(42)  \n\n   # splitting the data  \n   X_train, X_test, y_train, y_test = train_test_split(X, y,  \n                                                       test_size=0.2,  \n                                                       stratify=y)  \n\n   # double check  \n   X_train.shape, X_test.shape, y_train.shape, y_test.shape  \n\n   # pipeline for numerical data  \n   num_preprocessing = Pipeline([('num_imputer', SimpleImputer(strategy='mean')), # imputing with mean  \n                                                      ('minmaxscaler', MinMaxScaler())]) # scaling  \n\n   # pipeline for categorical data  \n   cat_preprocessing = Pipeline([('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # filling missing values  \n                                                   ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))]) # One Hot Encoding  \n\n   # preprocessor - combining pipelines  \n   preprocessor = ColumnTransformer([  \n                                                              ('categorical', cat_preprocessing, cat_cols),  \n                                                              ('numerical', num_preprocessing, num_cols)  \n                                                              ])  \n\n   # initial model parameters  \n   log_ini_params = {'penalty': 'l2',   \n                     'tol': 0.0073559740277086005,   \n                     'C': 1.1592424247511928,   \n                     'fit_intercept': True,   \n                     'solver': 'liblinear'}  \n\n   # model - Pipeline  \n   log_clf = Pipeline([('preprocessor', preprocessor),  \n                     ('clf', LogisticRegression(**log_ini_params))])  \n\n   log_clf.fit(X_train, y_train)  \n\n   # dumping the model  \n   f = 'model\/log.pkl'  \n   with open(f, 'wb') as file:  \n       pickle.dump(log_clf, file)  \n\n   # loading it  \n   loaded_model = joblib.load(f)  \n\n   # double check on a single datapoint  \n   new_data = pd.DataFrame({'age': 71,  \n                                               'sex': 0,  \n                                               'cp': 0,  \n                                               'trestbps': 112,  \n                                               'chol': 203,  \n                                               'fbs': 0,  \n                                               'restecg': 1,  \n                                               'thalach': 185,  \n                                               'exang': 0,  \n                                               'oldpeak': 0.1,  \n                                               'slope': 2,  \n                                               'ca': 0,  \n                                               'thal': 2  \n                                               }, index=[0])  \n\n   loaded_model.predict(new_data)  \n<\/code><\/pre>\n<p>...and it works just fine. Then I deploy the model to the Azure Web Service using these steps:<\/p>\n<ol>\n<li>  I create the score.py file    import joblib  <br \/>\n    from azureml.core.model import Model  <br \/>\n    import json    def init():  <br \/>\n    global model  <br \/>\n    model_path = Model.get_model_path('log') # logistic  <br \/>\n    print('Model Path is ', model_path)  <br \/>\n    model = joblib.load(model_path)    def run(data):  <br \/>\n    try:  <br \/>\n    data = json.loads(data)  <br \/>\n    result = model.predict(data['data'])  <br \/>\n    # any data type, as long as it is JSON serializable.  <br \/>\n    return {'data' : result.tolist() , 'message' : 'Successfully classified heart diseases'}  <br \/>\n    except Exception as e:  <br \/>\n    error = str(e)  <br \/>\n    return {'data' : error , 'message' : 'Failed to classify heart diseases'}\n<ol start=\"2\">\n<li>  I deploy the model:        from azureml.core import Workspace  <br \/>\n        from azureml.core.webservice import AciWebservice  <br \/>\n        from azureml.core.webservice import Webservice  <br \/>\n        from azureml.core.model import InferenceConfig  <br \/>\n        from azureml.core.environment import Environment  <br \/>\n        from azureml.core import Workspace  <br \/>\n        from azureml.core.model import Model  <br \/>\n        from azureml.core.conda_dependencies import CondaDependencies        ws = Workspace.from_config()        model = Model.register(workspace = ws,  <br \/>\n        model_path ='model\/log.pkl',  <br \/>\n        model_name = 'log',  <br \/>\n        tags = {'version': '1'},  <br \/>\n        description = 'Heart disease classification',  <br \/>\n        )<h1 id=\"to-install-required-packages\">to install required packages<\/h1>\n        env = Environment('env')  <br \/>\n        cd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0'], conda_packages = ['scikit-learn==0.23.2'])  <br \/>\n        env.python.conda_dependencies = cd<h1 id=\"register-environment-to-re-use-later\">Register environment to re-use later<\/h1>\n        env.register(workspace = ws)  <br \/>\n        print('Registered Environment')        myenv = Environment.get(workspace=ws, name='env')        myenv.save_to_directory('.\/environ', overwrite=True)        aciconfig = AciWebservice.deploy_configuration(  <br \/>\n        cpu_cores=1,  <br \/>\n        memory_gb=1,  <br \/>\n        tags={'data':'heart disease classifier'},  <br \/>\n        description='Classification of heart diseases',  <br \/>\n        )        inference_config = InferenceConfig(entry_script='score.py', environment=myenv)        service = Model.deploy(workspace=ws,  <br \/>\n        name='hd-model-log',  <br \/>\n        models=[model],  <br \/>\n        inference_config=inference_config,  <br \/>\n        deployment_config=aciconfig,  <br \/>\n        overwrite = True)        service.wait_for_deployment(show_output=True)  <br \/>\n        url = service.scoring_uri  <br \/>\n        print(url)<\/li>\n<\/ol>\n<\/li>\n<\/ol>\n<p>The deployment is succeded:<\/p>\n<blockquote>\n<p>Succeeded  <br \/>\nACI service creation operation finished, operation &quot;Succeeded&quot;<\/p>\n<\/blockquote>\n<p>But I can not make any predictions with the new data. I try to use:<\/p>\n<pre><code>   import pandas as pd  \n\n   new_data = pd.DataFrame([[71, 0, 0, 112, 203, 0, 1, 185, 0, 0.1, 2, 0, 2],  \n                                                [80, 0, 0, 115, 203, 0, 1, 185, 0, 0.1, 2, 0, 0]],  \n                                               columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'])  \n<\/code><\/pre>\n<p>Following the answer from this topic (<a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html<\/a>) I transform the data:<\/p>\n<pre><code>   test_sample = json.dumps({'data': new_data.to_dict(orient='records')})  \n<\/code><\/pre>\n<p>And try to make some predictions:<\/p>\n<pre><code>   import json  \n   import requests  \n   data = test_sample  \n   headers = {'Content-Type':'application\/json'}  \n   r = requests.post(url, data=data, headers = headers)  \n   print(r.status_code)  \n   print(r.json())  \n<\/code><\/pre>\n<p>However, I encounter an error:<\/p>\n<blockquote>\n<p>200  <br \/>\n{'data': &quot;Expected 2D array, got 1D array instead:\\narray=[{'age': 71, 'sex': 0, 'cp': 0, 'trestbps': 112, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': &gt; 2}\\n {'age': 80, 'sex': 0, 'cp': 0, 'trestbps': 115, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': 0}].\\nReshape your data either using array.reshape(-1, &gt; 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.&quot;, 'message': 'Failed to classify heart diseases'}<\/p>\n<\/blockquote>\n<p>How is it possible to adjust the input data to this form of predictions and add other output like predict_proba so I could store them in a separate output dataset?<\/p>\n<p>I know this error is somehow related either with the &quot;run&quot; part of the score.py file or the last code cell that calls the webservice, but I'm unable to find it.<\/p>\n<p>Best!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run dataset.register method multiple Times",
        "Question_created_time":1653460894327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/863226\/run-dataset-register-method-multiple-times",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi<\/p>\n<p>I am using the following code to register the dataset.  <br \/>\ndataset.register(  <br \/>\nworkspace = ws,  <br \/>\nname = dataset_name,  <br \/>\ntags = tags,  <br \/>\ncreate_new_version = True,  <br \/>\ndescription = &quot;&quot;  <br \/>\n)<\/p>\n<p>When I use the above for the first time too create a dataset , a new version is creation which is version 1. But when I re-run the same command again, one more new version is not created like version 2 is not created. Why? For the second-run my Data is same, Tags are same.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML workspace authorization failing when running via pipeline - OAuth 2.0 device flow error",
        "Question_created_time":1653103826547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/858468\/azure-ml-workspace-authorization-failing-when-runn",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>I followed the instructions here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-machine-learning-pipelines\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-machine-learning-pipelines<\/a> to publish and run a pipeline.    <\/p>\n<p>But the pipeline steps throws the following error:    <\/p>\n<p><em>&quot;error&quot;: {    <br \/>\n        &quot;message&quot;: &quot;AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling. Timestamp: 2022-05-20 18:17:51Z&quot;  <br \/>\n    }<\/em>  <\/p>\n<p>From the error message, it looks like the pipeline step is stuck at the 'interactive authorization' step and timesout after 900.0 sec.    <\/p>\n<p>At the moment we are just testing this in lower environment, hence I have not used service principal for authorization.    <\/p>\n<p>Can someone please suggest how to fix this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio Failed to Authenticate to the compute",
        "Question_created_time":1632489823347,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/565326\/azure-ml-studio-failed-to-authenticate-to-the-comp",
        "Question_score_count":4,
        "Question_answer_count":12,
        "Question_comment_count":10,
        "Question_body":"<p>Hi,     <\/p>\n<p>I have created a compute in my ML Studio and was running it for hours. However, it suddenly disconnected, and when I signed back in, it shows that &quot;    <br \/>\nYou need to be authenticated to the compute to use any Azure SDK. Please use the authenticate button to get authenticated.&quot; But when I click the authenticate button, I got an error with the message saying &quot;InternalServerError&quot;.    <\/p>\n<p>I have tried to sign out and sign back in, delete the current compute and create a new one. Neither worked.    <\/p>\n<p>Does anybody have any suggestions on this?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135060-image.png?platform=QnA\" alt=\"135060-image.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135091-image.png?platform=QnA\" alt=\"135091-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute Instance Creation Failure",
        "Question_created_time":1653413927010,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/862447\/compute-instance-creation-failure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello dear community,  <\/p>\n<p>I am new to Azure with an Azure for Students subscription provided by the University of Waterloo but I am having problems with the Microsoft Azure Machine Learning Studio which is a platform for building and deploying ML models in Azure.  <\/p>\n<p>So I am trying to create a Compute Instance which is a development workstation for building ML models within the studio but I am always receiving a status update saying &quot;Create Failed&quot; after creating one with the following error message:\u00a0  <\/p>\n<p>Provisioning error  <br \/>\n{&quot;error&quot;:{&quot;code&quot;:&quot;SubscriptionRegistrationIsNotFinished&quot;,&quot;message&quot;:&quot;The subscription f70a176d-5ce1-417a-925f-2cc779999263 is being registered, please wait for its completion and retry later.&quot;}}  <\/p>\n<p>Could you please tell me what is the issue( I am assuming it to be relating to the Subscription registration but since I am already able to access Azure with my university email, this shouldn't be the case) ?  <\/p>\n<p>Thank you !  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute Instance Keeps Failing on Azure Machine Learning",
        "Question_created_time":1653284199793,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/859594\/compute-instance-keeps-failing-on-azure-machine-le",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>I am new to Azure Machine Learning. I created a new workspace on Azure Machine Learning Studio and ran Compute Instance, but it keeps failing. I tried recreating the Compute Instances and Workspaces, but I keep getting the following error:  <\/p>\n<p>Provisioning error  <br \/>\n{&quot;error&quot;:{&quot;code&quot;:&quot;SubscriptionRegistrationIsNotFinished&quot;,&quot;message&quot;:&quot;The subscription xxxx-xxxx-xxxx-xxxx-xxxxxxx is being registered, please wait for its completion and retry later.&quot;}}  <\/p>\n<p>As the error message seems to indicate that there is an issue with my subscription, but when I look at my subscriptions, they look to be properly registered. Does anyone have any suggestions on how to resolve this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"UserScriptFilledDisk - what disk?",
        "Question_created_time":1617995934433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/351791\/userscriptfilleddisk-what-disk",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>I am using AZ Machine Learning and have been running python scripts on VMs to train mnist and output some summary statistics on the trained networks. It worked fine for the first few jobs, but when I submitted a few more, all of them failed with a USerScriptFilledDisk error:  <\/p>\n<p>&quot;UserError: AzureMLCompute job failed. UserScriptFilledDisk: User script filled the disk. Consider using VM SKU with larger disk size. If the issue persists contact Azure Support.&quot;  <\/p>\n<p>I am using nodes with only 7GB disk space, but it still does not make sense to me that I should have exceeded that just with mounting mnist and writing less than 1MB of numpy arrays to '.\/outputs\/'. The problem does not seem to be specific to any one or few nodes on my cluster. I made a new cluster and tried running my scripts on it. It still throws the same error. So how can I find out what disk I have filled up and how do fix it and keep it from happening again?  <\/p>\n<p>Thanks in advance!  <\/p>\n<p>More details:  <\/p>\n<p>I created an Azure machine learning compute cluster  <\/p>\n<pre><code>compute_name = os.environ.get(&quot;AML_COMPUTE_CLUSTER_NAME&quot;, &quot;cpu-main1&quot;)\ncompute_min_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MIN_NODES&quot;, 0)\ncompute_max_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MAX_NODES&quot;, 100)\nvm_size = os.environ.get(&quot;AML_COMPUTE_CLUSTER_SKU&quot;, &quot;STANDARD_DS1_V2&quot;)\n\nif compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[compute_name]\nelse:\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n                                                                min_nodes = compute_min_nodes, \n                                                                max_nodes = compute_max_nodes)\n\n    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)    \n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n<\/code><\/pre>\n<p>I added a data set  <\/p>\n<pre><code>workspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='mnist_zip')\ndataset.download(target_path='.', overwrite=True)\n\ndataset = dataset.register(workspace=ws,\n                           name='mnist_zip',\n                           description='zip file with preprocesses mnist data set',\n                           create_new_version=False)\n<\/code><\/pre>\n<p>I submitted jobs to the cluster  <\/p>\n<pre><code>runs = [ 0 for _ in range(30)]\nfor i in range(30):\n    args = ['--dataset', dataset.as_mount(), '--id', i] \n    #also tried '.as_download()' - did not seem to make a difference\n    src = ScriptRunConfig(source_directory=script_folder,\n                          script='script.py', \n                          arguments=args,\n                          compute_target=compute_target,\n                          environment=env)\n\n    runs[i] = exp.submit(config=src)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pickle Load- File Not Found when deploying using Azure ML Studio",
        "Question_created_time":1653375158970,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/861537\/pickle-load-file-not-found-when-deploying-using-az",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have saved a classifier model with pickle using the following code-  <\/p>\n<pre><code>import pickle\nwith open('skm.pickle', 'wb') as fid:\n    pickle.dump(clf, fid) \n<\/code><\/pre>\n<p>Now, during deployment, when I try to load this same model, it is giving an error-  <\/p>\n<pre><code>Error:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>This is the score.py file where I am loading the pickle model and the same file is called during deployment. Also note that, all these files (code, pickle file and related files) are in the same directory.  <\/p>\n<pre><code>%%writefile sklearnscore.py\n\nimport json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport pickle\n\n# Initialize the deployment environment\ndef init():\n    # read in the model file\n    from sklearn.pipeline import Pipeline\n    global obj\n    with open('.\/skm.pickle', 'rb') as f:\n        obj = pickle.load(f)\n<\/code><\/pre>\n<p>I am registering the model using- <code>model = Model.register(ws, model_name=&quot;utility15&quot;, model_path=&quot;.\/skm.pickle&quot;)<\/code>  <\/p>\n<p>And the deployment code is-  <\/p>\n<pre><code>service_name = 'my-custom-env-service-4'\nsklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='Sklearn.yaml')\n\ninference_config = InferenceConfig(entry_script='sklearnscore.py', environment=sklearn_env)\n\naci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4,tags={'Createdby':'xyz'})\n\nservice = Model.deploy(workspace=ws,\n                        name=service_name,\n                        models=[model],\n                        inference_config=inference_config,\n                        deployment_config=aci_config,\n                        overwrite=True)\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>When this script is run, it calls the score.py file and the file not found error comes up for pickle file. I have even tried loading the model without the .\/ thing, but the same error comes up.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute Instances - SubscriptionRegistrationIsNotFinished",
        "Question_created_time":1653323984290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/860702\/compute-instances-subscriptionregistrationisnotfin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>I created a new workspace on Azure Machine Learning Studio and ran Compute Instance, but it keeps failing. I tried recreating the Compute Instances and Workspaces, but I keep getting the following error:  <\/p>\n<p>{&quot;error&quot;:{&quot;code&quot;:&quot;SubscriptionRegistrationIsNotFinished&quot;,&quot;message&quot;:&quot;The subscription xxxxxxx-ffc4-452e-9cb7-40c706e8738f is being registered, please wait for its completion and retry later.&quot;}}  <\/p>\n<p>As the error message seems to indicate that there is an issue with my subscription, but when I look at my subscriptions, they look to be properly registered. Does anyone have any suggestions on how to resolve this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Web Service - An existing connection was forcibly closed by the remote host",
        "Question_created_time":1653362218797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/861245\/azure-ml-web-service-an-existing-connection-was-fo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have some Azure ML Web services (Machine Learning Studio (classic) workspace) that have just stopped responding. I haven't changed anything on my end. The error suggests I might have ran out of credit or something but the service scales automatically. This is a business-critical service that has just stopped responding...  <\/p>\n<p>I've tried redeploying the services but I still get the same error. I also tried 'Deploy Service [New] Preview' but I get another error:   <br \/>\n&quot;Web Service deployment failed. This account does not have sufficient access to the Azure subscription that contains the Workspace. In order to deploy a Web Service to Azure, the same account must be invited to the Workspace and be given access to the Azure subscription that contains the Workspace.&quot;- even though I am logged in on the correct account.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure machine learning SubscriptionNotFound",
        "Question_created_time":1653319804270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/860631\/azure-machine-learning-subscriptionnotfound",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have created a workspace for azure machine learning and I am trying to create processes, but I get the following error: BatchARMResponseError:   <\/p>\n<p>{&quot;error&quot;:{&quot;code&quot;: &quot;SubscriptionNotFound&quot;, &quot;message&quot;: &quot;The specified subscription XXXXXXXXXXXXXXXXXXXXXXXXXX is not found&quot;}}}  <\/p>\n<p>Request error with status code 500.  <br \/>\n    at b (<a href=\"https:\/\/ml.azure.com\/static\/js\/index.29c4b58c.chunk.js\">https:\/\/ml.azure.com\/static\/js\/index.29c4b58c.chunk.js<\/a>) <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use MLFlow models with managed endpoints and private pip",
        "Question_created_time":1650549331407,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/821194\/how-to-use-mlflow-models-with-managed-endpoints-an",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>How do you create a batch endpoint using an MLFlow with a private package installed via a private pip?   <\/p>\n<p>I have tried multiple ways (see this github issue: <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/22441#issuecomment-1104082706\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/22441#issuecomment-1104082706<\/a>) but I'm not really getting anywhere. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Mount AML dataset on Windows",
        "Question_created_time":1653326462743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/860774\/mount-aml-dataset-on-windows",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I came across <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#mount-vs-download\">this page<\/a> which describes how to work with AML datasets. I'm specifically interested in mounting. It states that &quot;Mounting is supported for Linux-based computes&quot;. Is there no way to do this on Windows?    <\/p>\n<p>Thanks,    <br \/>\nYordan    <\/p>",
        "Question_closed_time":1653382797127,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@YordanZaykov-7763 Yes, currently this is only supported for linux based computes for Azure ML. Windows only supports download option.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Consuming ML models on Power BI",
        "Question_created_time":1653284389440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/859568\/consuming-ml-models-on-power-bi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>When I connect the ML model endpoint with Power BI, it doesn't show me the model attributes that match the PBI dataset. Can you please help with the expected data format in Power BI.<\/p>",
        "Question_closed_time":1653287904970,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=78d653c4-ee0a-4cd3-b540-08c38c4bd217\">@Arjun  <\/a> Thanks, Can you try define the input schema and follow the below sample.    <\/p>\n<p> Here is the <a href=\"https:\/\/github.com\/WipadaChan\/pbi_demo_repo\/tree\/master\/03_DeployH2O_PBI\">sample<\/a> to Deploy trained model to Azure ML and use Power BI to score new data.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Studio \"Failed to Authenticate to Compute\"",
        "Question_created_time":1652041246053,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/840948\/azure-ml-studio-failed-to-authenticate-to-compute",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I was working in Azure ML Studio and suddenly I got a yellow banner across the top of my notebook saying   <\/p>\n<p>&quot;You need to be authenticated to the compute to use any Azure SDK. Please use the authenticate button to get authenticated.&quot;  <\/p>\n<p>I clicked the button, but the login doesn't work. Sometimes trying to login just loops the login page over and over. Other times it flickers for a few seconds then says that I could not authenticate. Either way, when I return to ML Studio I now see a red banner over the notebook saying   <\/p>\n<p>&quot;Failed to authenticate to the compute.&quot;  <\/p>\n<p>This has been ongoing for days, and nothing I have tried has solved it. I have restarted the compute, cleared the browser cookies and cache, deleted the compute and created a new one. The only other thread I've found that seemed to have this exact issue was apparently resolved with a hot fix, but it is currently happening to me.  <\/p>\n<p>I can't get any work done since I'm blocked from using any compute.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy inference pipeline with Cross Validate Model component",
        "Question_created_time":1652979147437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/856618\/deploy-inference-pipeline-with-cross-validate-mode",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML Studio I have created a pipeline that uses the Cross Validate Model component. According to the reference docs:    <br \/>\n (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/cross-validate-model#how-to-use-cross-validate-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/cross-validate-model#how-to-use-cross-validate-model<\/a>)    <br \/>\nthis component trains the model multiple times.  Now that I have run the pipeline successfully, I'd like to create an inference pipeline.  Unfortunately, regardless of the type of inference pipeline I choose (&quot;real time&quot; or &quot;batch&quot;) I receive the following message and I don't understand WHY as I have trained the model using the cross  validate model component.  I am new so if I'm missing something &quot;intuitively obvious&quot; I accept that...just need to move my project forward.  Thanks in advance for your help!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203788-image.png?platform=QnA\" alt=\"203788-image.png\" \/>    <\/p>\n<p>Below is my full pipeline:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203787-image.png?platform=QnA\" alt=\"203787-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connect Azure ML with Snowflake using Private endpoint?",
        "Question_created_time":1652948258440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/855820\/connect-azure-ml-with-snowflake-using-private-endp",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Can we connect Azure ML Notebooks directly to Snowflake using Private end-points, my ML Workspace is inside a VNet.<\/p>",
        "Question_closed_time":1653034845860,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=03343194-9922-4c28-abc7-1d7c46b6d2d6\">@Varun  <\/a>     <\/p>\n<p>Thanks for reaching out to us, currently there is no internal way in Azure Machine Learning Studio to connect to Snowflake. I am sorry for all inconveniences.     <\/p>\n<p>But you can run a  Python 3 code to use the Snowflake python connector - <a href=\"https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html\">https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html<\/a>    <\/p>\n<p>With Azure ML Studio, there's no built-in support for SnowFlake, I will forward your feedback to product group to see if there any plan in the future.     <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot for supporting the community.<\/em>     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"To update keys between workspace and storage",
        "Question_created_time":1652953898103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/856066\/to-update-keys-between-workspace-and-storage",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello     <\/p>\n<p>My storage keys have been updated and so I am trying to update to connect with the ML Studio.    <\/p>\n<p>I am following this link:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key<\/a>    <\/p>\n<p>However in this step:    <\/p>\n<h1 id=\"re-register-the-blob-container----\">Re-register the blob container    <\/h1>\n<p>ds_blob = Datastore.register_azure_blob_container(workspace=ws,    <br \/>\n                                          datastore_name='your datastore name',  <br \/>\n                                          container_name='your container name',  <br \/>\n                                          account_name='your storage account name',  <br \/>\n                                          account_key='new storage account key',  <br \/>\n                                          overwrite=True)  <\/p>\n<h1 id=\"re-register-file-shares----\">Re-register file shares    <\/h1>\n<p>ds_file = Datastore.register_azure_file_share(workspace=ws,    <br \/>\n                                      datastore_name='your datastore name',  <br \/>\n                                      file_share_name='your container name',  <br \/>\n                                      account_name='your storage account name',  <br \/>\n                                      account_key='new storage account key',  <br \/>\n                                      overwrite=True)  <\/p>\n<p>I get the following error message: ErrorResponseException: (Immutable) Update to datastore is not allowed. Only credentials of a datastore can be updated.    <\/p>\n<p>Please your help to solve this.    <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accepting ADF parameters in Azure ML Pipeline Python",
        "Question_created_time":1652940523997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/855597\/accepting-adf-parameters-in-azure-ml-pipeline-pyth",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi    <\/p>\n<p>I am using ML Execute activity in ADF and passing the parameters. For Example Business_Unit = ABC    <\/p>\n<p>Now how to access this parameter in Azure ML Pipeline Python Code. What exact command to be used?, is there any documentation for the same?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203602-image.png?platform=QnA\" alt=\"203602-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"no module named azure.storage\" while using ScriptRunConfig to submit run.",
        "Question_created_time":1652751214187,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/851738\/no-module-named-azure-storage-while-using-scriptru",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to download pickle files from blob container and using <em>ScriptRunConfig<\/em> object to submit a Run.   <\/p>\n<p>I am stuck and getting the following error:   <\/p>\n<p><code>ModuleNotFoundError: No module named 'azure.storage'<\/code>  <\/p>\n<p>Any help is appreciated please.......  <\/p>\n<p>my environment.yml file consists of the following below:  <\/p>\n<pre><code>name: azuremlenv\ndependencies:\n- python=3.8\n- pip=21.0.1\n- pip:\n  - azureml-defaults\n  - azureml-core\n  - azureml-mlflow\n  - azureml-sdk\n  - azure-storage\n  - azure-storage-blob\n  - azure-mgmt-datafactory\n  - azure-functions\n  - azure-functions-durable\n  - scikit-learn==0.24.1\n  - pandas==1.2.4\n  - seaborn==0.11.1\n  - tqdm==4.61.2\n  - matplotlib==3.3.4\n  - pandas-schema==0.3.6\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Automated ML Model Deployment to Online Endpoint Stuck in Transitioning",
        "Question_created_time":1650137939707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/814684\/azure-automated-ml-model-deployment-to-online-endp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a model produced by Azure's Automated ML service. I am following this tutorial (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-automl-endpoint?tabs=Studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-automl-endpoint?tabs=Studio<\/a>) to deploy to an online endpoint via the portal. Currently, the endpoint is successfully created but the actual deployment fails. It hangs for around 2.5 hours before crashing on a timeout error. The deployment logs are empty.     <\/p>\n<p>Other posts suggest that this might be due to some kind of issue in the configuration file or specification of dependencies. However, those files are being generated and provided by azure. I am at a loss for how to proceed. Thought about trying to deploy from the CLI but the ml extension fails to install citing version conflicts in Docker. Any advice on what might be going wrong or ways to investigate this would be greatly appreciated!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can an AzureML Notebook on a workspace be linked to an specific AzureML Environment",
        "Question_created_time":1651165609177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/830652\/can-an-azureml-notebook-on-a-workspace-be-linked-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have seen how to link an AzureML Notebook inside a Workspace to a Compute Target within the same Workspace  <\/p>\n<p>I am wondering if it could be also linked to an specific AzureML Environment as the notebook requires software from the container used to instantiate the Environment  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Length of charater is long, ML will pop error.",
        "Question_created_time":1651647844370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/835758\/length-of-charater-is-long-ml-will-pop-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>when I put the source code in the ML studio, if the charater length is long, it will popup the error and cannot submit. can someone help me ? thanks.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/198761-image.png?platform=QnA\" alt=\"198761-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NameError: name 'load_workspace_from_config' is not defined",
        "Question_created_time":1651777443857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/838280\/nameerror-name-load-workspace-from-config-is-not-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>i simply want to get the datastore name from my azure workspace so I can use it in databricks. i found this code   <br \/>\nimport azureml.core  <br \/>\nfrom azureml.core import Workspace, Datastore  <\/p>\n<p>ws = load_workspace_from_config(path=&quot;config.json&quot;)  <br \/>\nds = get_default_datastore(ws)  <br \/>\nprint(ds)  <\/p>\n<p>I am facing error on this that   <br \/>\nNameError: name 'load_workspace_from_config' is not defined<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"PermissionError: [Errno 13] Permission denied\" when trying to access a local file for a conda environment",
        "Question_created_time":1652041850827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/840929\/permissionerror-(errno-13)-permission-denied-when",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>After Azure ML Studio blocking me from using any compute due to an as-of-yet unresolved authentication error, I moved to using a Jupyter Notebook on my local workstation to try to configure my experiments locally then send the job to an Azure compute cluster. I have two lines of Python that tries to create an environment class by accessing a .yml file on my local computer:  <\/p>\n<p>yml_path = r&quot;C:\\Users\\me\\Desktop\\azure_training\\training_env&quot;  <br \/>\npytorch_env = Environment.from_conda_specification(name='pytorch-1.11-gpu', file_path=yml_path)  <\/p>\n<p>This causes the following error:  <\/p>\n<p>PermissionError: [Errno 13] Permission denied: 'C:\\Users\\me\\Desktop\\azure_training\\training_env'  <\/p>\n<p>I am unsure of what is causing this. When the file doesn't need to be private, I have solved permission denied issues in the past that resulted from locally run tools such as PostgreSQL by going to the file's properties&gt;&gt;security and adding the user &quot;Everyone&quot; with full control. I tried doing that in this case, but it had no impact. I still get permission denied even though &quot;Everyone&quot; has full control over the file.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I am unable to create compute instance",
        "Question_created_time":1648817598023,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/797009\/i-am-unable-to-create-compute-instance",
        "Question_score_count":4,
        "Question_answer_count":5,
        "Question_comment_count":3,
        "Question_body":"<p>\u200bI am unable to create compute instance in my azure ml resource. I am using a free trial and already have 6 unused cores left in my quota. I have used central India as my location. While making the compute instance, It shows - &quot;You do not have enough quota for the following VM sizes&quot;.    <\/p>\n<p>I've added a screenshot.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/189174-screenshot-2022-04-01-at-35240-pm.png?platform=QnA\" alt=\"189174-screenshot-2022-04-01-at-35240-pm.png\" \/>    <\/p>\n<p>Please let me know what is the solution to this problem.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"My Azure ML studio is not loading",
        "Question_created_time":1651477263057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/833332\/my-azure-ml-studio-is-not-loading",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,   <\/p>\n<p>I am trying to enter my ML studio, however when I launch it, the window opens and appears to be loading (it says: loading workspace) but it reamins this way for a long time and I cannot access it. I have had this problem for a couple of days now and have tried it on different web browser and the result is the same.  <\/p>\n<p>Please your help or feedback to solve this as soon as possible.  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Code: AuthorizationFailed",
        "Question_created_time":1651917005187,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/840311\/code-authorizationfailed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Unit 4 of 7  <br \/>\nExercise - Back up an Azure virtual machine  <br \/>\nCreate a backup for Azure virtual machines  <\/p>\n<p>I am unable to run the following command in cloud shell to set up the environment:  <br \/>\nRGROUP=$(az group create --name vmbackups --location westus2 --output tsv --query name)  <\/p>\n<p>Following error pop up:  <br \/>\nERROR: (AuthorizationFailed) The client 'live.com#...... does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.......\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.  <br \/>\nCode: AuthorizationFailed  <br \/>\nMessage: The client 'live.com#l...... with object id '.......' does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.....\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.  <\/p>\n<p>When I do refresh, sign out or sign in do not helps. Anybody has any idea what to do?  <br \/>\nThank you  <\/p>",
        "Question_closed_time":1651918064643,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=854a8d3c-feda-48d5-ba7c-744d587335c9\">@Krisztian  <\/a>     <\/p>\n<p>Welcome to Microsoft Q&amp;A community.     <\/p>\n<p>Have you tried to do this first?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/199884-image.png?platform=QnA\" alt=\"199884-image.png\" \/>    <\/p>\n<p>Cheers,    <\/p>\n<p>Please &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Autoscaling issue with AKS attached as ML inference cluster",
        "Question_created_time":1651848877503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/839654\/autoscaling-issue-with-aks-attached-as-ml-inferenc",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>We have a AKS cluster defined inside a VNet. This AKS cluster is used as an Inference cluster for Azure ML and models are deployed on the AKS from ML. Due to this reason, AKS cluster of &quot;loadBalancer&quot; outbound type is created which creates a load balancer of Public IP [a requirement of ML]   <\/p>\n<p>As this is inside a VNet, PublicIP is not routable and to access the scoring endpoints deployed on AKS, we have created a NGINX Ingress controller, with an Internal IP  <\/p>\n<p>Now, everything is working fine, but PODs (and Nodes) aren't Autoscaling. Have enabled cluster autoscaler and per MS advice, not enabled HPA.   <\/p>\n<p>What could be the reason? Can you please advice?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Converting textanalytics result to JSON Format",
        "Question_created_time":1650967532993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/826603\/converting-textanalytics-result-to-json-format",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <br \/>\nI am using the example provided in the Machine Learning Studio Docs for extracting Health Entities from a given string.  <br \/>\nThe code is shown below.  <\/p>\n<p>My question is: what is the easiest way to <strong>convert the output result into JSON format<\/strong>?  <\/p>\n<pre><code>from azure.core.credentials import AzureKeyCredential\nfrom azure.ai.textanalytics import TextAnalyticsClient\nimport json\n\ncredential = AzureKeyCredential(&quot;**********************************&quot;)\nendpoint=&quot;https:\/\/eastus.api.cognitive.microsoft.com\/&quot;\n\ntext_analytics_client = TextAnalyticsClient(endpoint, credential)\n\ndocuments = [&quot;Subject is taking 100mg of ibuprofen twice daily&quot;]\n\npoller = text_analytics_client.begin_analyze_healthcare_entities(documents)\nresult = poller.result()\n\ndocs = [doc for doc in result if not doc.is_error]\n\nprint(&quot;Results of Healthcare Entities Analysis:&quot;)\nfor idx, doc in enumerate(docs):\n    for entity in doc.entities:\n        print(&quot;Entity: {}&quot;.format(entity.text))\n        print(&quot;...Normalized Text: {}&quot;.format(entity.normalized_text))\n        print(&quot;...Category: {}&quot;.format(entity.category))\n        print(&quot;...Subcategory: {}&quot;.format(entity.subcategory))\n        print(&quot;...Offset: {}&quot;.format(entity.offset))\n        print(&quot;...Confidence score: {}&quot;.format(entity.confidence_score))\n        if entity.data_sources is not None:\n            print(&quot;...Data Sources:&quot;)\n            for data_source in entity.data_sources:\n                print(&quot;......Entity ID: {}&quot;.format(data_source.entity_id))\n                print(&quot;......Name: {}&quot;.format(data_source.name))\n        if entity.assertion is not None:\n            print(&quot;...Assertion:&quot;)\n            print(&quot;......Conditionality: {}&quot;.format(entity.assertion.conditionality))\n            print(&quot;......Certainty: {}&quot;.format(entity.assertion.certainty))\n            print(&quot;......Association: {}&quot;.format(entity.assertion.association))\n        for relation in doc.entity_relations:\n            print(&quot;Relation of type: {} has the following roles&quot;.format(relation.relation_type))\n        for role in relation.roles:\n            print(&quot;...Role '{}' with entity '{}'&quot;.format(role.name, role.entity.text))\n    print(&quot;------------------------------------------&quot;)\n<\/code><\/pre>",
        "Question_closed_time":1650982690653,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c7e28bb4-3bff-4f66-9bdf-9c63a80436b1\">@KA  <\/a> The result does not seem to be directly serializable to JSON. I found a library <a href=\"https:\/\/pypi.org\/project\/jsons\/\">JSONS<\/a> that can do the heavy lifting if you are using python 3.5 or higher.     <\/p>\n<p>Install jsons    <\/p>\n<pre><code>pip install jsons  \n<\/code><\/pre>\n<p>Import JSONS and using jsons.dump() on docs object.    <\/p>\n<pre><code>import jsons #import in the import section  \nprint(jsons.dump(docs)) #Printing the json after docs is created  \n<\/code><\/pre>\n<p>This should give a file of this format in this case. Uploaded the file in .txt format since JSON files cannot be uploaded on Q&amp;A, download the file and rename it to .json     <br \/>\nI hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/196624-health.txt?platform=QnA\">196624-health.txt<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Swagger file not present -- Azure Machine Learning",
        "Question_created_time":1624015775073,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/442305\/swagger-file-not-present-azure-machine-learning",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":10,
        "Question_body":"<p>I am currently training and deploying machine learning models through Azure Devops Pipelines to Azure ML Studio.  <\/p>\n<p>When I deploy the model to endpoint through the pipeline to an endpoint I am getting the following error:  <\/p>\n<pre><code>    &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;hackney\/1.17.4&quot;\nSwagger file not present\n&quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;curl\/7.67.0&quot;\nSwagger file not present\n<\/code><\/pre>\n<p>I have no code related to swagger. So I could not understand.  <\/p>\n<p>It was successfully building the endpoint before. It just suddenly popped out.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AFx Library library exception FOR R Modules",
        "Question_created_time":1651358872440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/832546\/afx-library-library-exception-for-r-modules",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_body":"<p>Hi,  <br \/>\n  I output a dataset from port1, input it to another R module Input port 1, but every time, it gives me:  <br \/>\n requestId = 04c3444f096f4ff8b17edd1d055cfa4a errorComponent=Module. taskStatusCode=400. {&quot;Exception&quot;:{&quot;ErrorId&quot;:&quot;LibraryException&quot;,&quot;ErrorCode&quot;:&quot;1000&quot;,&quot;ExceptionType&quot;:&quot;ModuleException&quot;,&quot;Message&quot;:&quot;Error 1000: AFx Library library exception: Column names cannot be null or empty.&quot;,&quot;Exception&quot;:{&quot;Library&quot;:&quot;AFx Library&quot;,&quot;ErrorId&quot;:&quot;EmptyColumnName&quot;,&quot;ErrorCode&quot;:&quot;151&quot;,&quot;ExceptionType&quot;:&quot;LibraryException&quot;,&quot;Message&quot;:&quot;Column names cannot be null or empty.&quot;}}}Error: Error 1000: AFx Library library exception: Column names cannot be null or empty. Process exited with error code -2  <\/p>\n<p>I can not print anything in the second r module, what's wrong?  <\/p>\n<p>NAW.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Filter Based Feature Selection or Permutation Feature Importance",
        "Question_created_time":1651765090787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/838182\/filter-based-feature-selection-or-permutation-feat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi  <\/p>\n<p>I am aware that Feature Based Selection kind of measure the prediction power of each variable before any model has been built.  <\/p>\n<p>I know that Permutation Feature importance measures, once the model has been built, how relevant each variable is. Thanks to this we can prune our model and strike a good balance between accuracy and simplicity. Fair enough.  <\/p>\n<p>However, most of the time I encounter contradictory messages. There is a variable with 0 importance on the Feature Based Selection but it ends up becoming one of the most relevant variables of my model according to its ranking on Permutation Feature importance.  <\/p>\n<p>So I guess I cannot rely on what Feature Based Selection says in order to do a preliminary assessment. I guess I should see it as some theoretical exercise.  <\/p>\n<p>Thank you <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure.ai.textanalytics not resolved in Machine Learning Studio",
        "Question_created_time":1650885782980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/825079\/azure-ai-textanalytics-not-resolved-in-machine-lea",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Hello,  <br \/>\nI am using a Python notebook in the Machine Learning Studio for extracting Health Info from a given text.  <br \/>\nHowever, the Machine Learning Studio refuses to recognize the below line of code:  <\/p>\n<pre><code>from azure.ai.textanalytics import TextAnalyticsClient\n<\/code><\/pre>\n<p>The error received is as below:  <\/p>\n<pre><code>ModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-4-54158a600368&gt; in &lt;module&gt;\n      1 from azure.core.credentials import AzureKeyCredential\n----&gt; 2 from azure.ai.textanalytics import TextAnalyticsClient\n      3 \n      4 \n      5 credential = AzureKeyCredential(&quot;***************************&quot;)\n\nModuleNotFoundError: No module named 'azure.ai'\n<\/code><\/pre>\n<p>Does anyone has an idea what to do here?  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't deploy a VM on the Azure Machine Learning.",
        "Question_created_time":1623772014863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/437136\/cant-deploy-a-vm-on-the-azure-machine-learning",
        "Question_score_count":4,
        "Question_answer_count":6,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105827-image.png?platform=QnA\" alt=\"105827-image.png\" \/>    <\/p>\n<p>I tried to deploy a VM to Azure Machine Learning, but I get the error message &quot;You do not have enough quota for the following VM sizes. Click here to view and request quota.&quot; And the VM cannot be deployed.    <\/p>\n<p>But I have enough quota (24 CPUs).    <\/p>\n<p>What is causing the problem?    <\/p>\n<p>I'm using Azure's Free trial plan.<\/p>",
        "Question_closed_time":1623772934643,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=80eeb45c-8aa8-49ab-81df-1bb291fc79a5\">@ShoM  <\/a> ,    <\/p>\n<p>there are different quotas in Azure:    <\/p>\n<ul>\n<li> There are quotas for <code>vCPUs per Azure Region<\/code>    <\/li>\n<li> In addition there are quotas for <code>vCPUs per VM Series<\/code>    <\/li>\n<\/ul>\n<p>Both quotas (for Azure Region and VM Series) must fit the requirements.    <\/p>\n<p>It seems like the quota for vCPUs per region is ok but you haven't enough vCPUs per VM series.    <br \/>\nYou can check your quotas by the link you marked with the red line in your screenshot.    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is there any way to create automatic datasets in Azure Machine Learning using Azure Data Factory",
        "Question_created_time":1651474101517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/833237\/is-there-any-way-to-create-automatic-datasets-in-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have Storage ADLS account, Azure Data Factory and Azure Machine Learning services. In Azure ML , we create datasets manually and use for training Models. But is there any way where Azure Data Factory takes data from ADLS account and updates as Datasets in Azure ML.   <\/p>\n<p>Only option I see is using Azure ML Notebooks which involves writing Notebooks(which I do not want). From ADF I want this process to be done. I do not have Azure Machine Learning Studio also.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azureml compute instance spark dependencies missing",
        "Question_created_time":1651594378717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/835171\/azureml-compute-instance-spark-dependencies-missin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Currently, I'm trying to use the AzureML SDK's, dataset.to_spark_dataframe() method, and facing a weird error(see below).  <br \/>\nThe ClassNotFoundExceptions suggest that some Jars might be missing from the base environment's Spark classpath. Some sources suggest hadoop-azure concretely: <a href=\"https:\/\/community.cloudera.com\/t5\/Support-Questions\/Class-org-apache-hadoop-fs-azure-NativeAzureFileSystem-not\/m-p\/270675\">https:\/\/community.cloudera.com\/t5\/Support-Questions\/Class-org-apache-hadoop-fs-azure-NativeAzureFileSystem-not\/m-p\/270675<\/a>)<\/p>\n<p>Is there a way to add these dependencies to the environment?<\/p>\n<p>Error:  <br \/>\nAzureMLException: AzureMLException:  <br \/>\nMessage: Execution failed in operation 'to_spark_dataframe' for Dataset(id='54df6c30-fb46-4c75-a084-d10c17cd3795', name='temperatures_parq', version=1, error_code=None, exception_type=Py4JJavaError)  <br \/>\nInnerException An error occurred while calling o39.getFiles.  <br \/>\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found  <br \/>\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2667)  <br \/>\nat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)  <br \/>\nat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)  <br \/>\nat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)  <br \/>\nat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)  <br \/>\nat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)  <br \/>\nat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)  <br \/>\nat com.microsoft.dprep.io.FileSystemStreamInfoHandler.globStatus(FileSystemStreamInfoHandler.scala:46)  <br \/>\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:206)  <br \/>\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:201)  <br \/>\nat com.microsoft.dprep.execution.Storage$.expandHdfsPath(Storage.scala:44)  <br \/>\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.$anonfun$getFiles$1(GetFilesExecutor.scala:18)  <br \/>\nat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)  <br \/>\nat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)  <br \/>\nat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)  <br \/>\nat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)  <br \/>\nat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)  <br \/>\nat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)  <br \/>\nat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)  <br \/>\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.getFiles(GetFilesExecutor.scala:12)  <br \/>\nat com.microsoft.dprep.execution.LariatDataset$.getFiles(LariatDataset.scala:32)  <br \/>\nat com.microsoft.dprep.execution.PySparkExecutor.getFiles(PySparkExecutor.scala:201)  <br \/>\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  <br \/>\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)  <br \/>\nat java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  <br \/>\nat java.base\/java.lang.reflect.Method.invoke(Method.java:566)  <br \/>\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)  <br \/>\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)  <br \/>\nat py4j.Gateway.invoke(Gateway.java:282)  <br \/>\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)  <br \/>\nat py4j.commands.CallCommand.execute(CallCommand.java:79)  <br \/>\nat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)  <br \/>\nat py4j.ClientServerConnection.run(ClientServerConnection.java:106)  <br \/>\nat java.base\/java.lang.Thread.run(Thread.java:829)  <br \/>\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found  <br \/>\nat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2571)  <br \/>\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2665)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"what is the difference between Dataset.Tabular.register_pandas_dataframe and dataset.register",
        "Question_created_time":1651658160987,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/836059\/what-is-the-difference-between-dataset-tabular-reg",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>what is the difference between Dataset.Tabular.register_pandas_dataframe and dataset.register option , which one should I use to register my dataset in Machine learning<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"InvalidPorpertyValue. The size of the specified..........the limit of 20480 characters",
        "Question_created_time":1651656606393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/836030\/invalidporpertyvalue-the-size-of-the-specified-the",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>when we edit the source code at machine learning studio - Designer, seems when the row more than 280 rows, it shows the error like following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/198758-image.png?platform=QnA\" alt=\"198758-image.png\" \/>    <\/p>\n<p>I am not sure whether the rows is exceed or the total number of chacters exceed, anyone encounter this issue before ? how to resolved ? thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unknow error of AzureMLCompute",
        "Question_created_time":1650387670807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/818094\/unknow-error-of-azuremlcompute",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/194423-image.png?platform=QnA\" alt=\"194423-image.png\" \/>    <\/p>\n<p>when I add 2 rows sentence there, (whatever e.g. a= 1), then it shows this error , if I didn't add these 2 rows, it shows normal.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connect to compute instance via ssh",
        "Question_created_time":1626870444287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/484265\/connect-to-compute-instance-via-ssh",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have create a compute instance through the Azure ML Studio. Using the &quot;Applications&quot; list, I can access Jupyter, RStudio, a Terminal and connect via VS Code. But how can I just connect via SSH? I have added my SSH key to the instance while creating it, but cannot connect via the public IP address listed in the node details. I tried this as <code>ssh azureuser@&lt;compute-ip&gt;<\/code>  <\/p>\n<p>In the output of the <code>azure ml compute show<\/code> command in the cloud shell I noticed the values <code>&quot;enable_public_ip&quot;: false<\/code> and <code>&quot;ssh_public_access&quot;: &quot;False&quot;<\/code>, but couldn't find anything regarding how to change these settings. Or is there any way to connect to them without a public ip?  <\/p>",
        "Question_closed_time":1627973477260,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hey Yutong,  <br \/>\nI was just asking about compute instances created though the Azure ML Studio in general. Like the ones you create when you use the ML Studio, then select <em>Compute<\/em> in the sidebar and under <em>Compute Instances<\/em> create a new compute node. During creation, I selected the &quot;Enable SSH access&quot; option.  <\/p>\n<p>I did figure out a solution to my problem of connecting to such an instance a bit later, and will leave it here for others with the same problem. As long as you select &quot;Enable SSH access&quot;, the SSH access does work even though the <code>azure ml compute show<\/code> says <code>&quot;ssh_public_access&quot;: &quot;False&quot;<\/code>. My problem just was that I did not know the user name I had to log in as and also did not know which port I had to connect to. It turns out that the user name is always set to <code>azureuser<\/code> and the port seems to be either <code>50000<\/code> or <code>50001<\/code>. You should therefore be able to connect via <code>ssh  azureuser@&lt;PUBLIC_IP&gt; -p 50000<\/code> or with <code>-p 50001<\/code>. You can find the public IP on the details page of the compute instance. If you want to know for sure which port it is, you can query the azure CLI with   <\/p>\n<pre><code>az resource show --ids \/subscriptions\/{subscriptionId}\/resourceGroups\/{resourceGroupName}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspaceName}\/computes\/{computeName}\n<\/code><\/pre>\n<p>and in the JSON response look under <em>properties.sshSettings<\/em> for <em>adminUserName<\/em> and <em>sshPort<\/em>.  <\/p>\n<p>I just wished that this was documented somewhere in the Azure ML docs. I had to read through the source code of how the Azure ML VSCode extension connects to a compute instance to find this out.  <\/p>\n<p>Is there any easier way to accomplish this? I needed the SSH access to forward specific ports from the compute instance to local and also to set up a Python SSH remote interpreter in IntelliJ<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Multi label classification on Azure ML Designer",
        "Question_created_time":1651216958343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/831308\/multi-label-classification-on-azure-ml-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I would like to build an end-to-end ML pipeline for training a multi-label text classifier. When trying to achieve this, I see that the &quot;Train Model&quot; component does not allow the target label column to be a list of classes (Object type) which would be the case in Multi-label classification problems. Please correct me if I am wrong. Does the Train Model and Score Model components support multi-label classification?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML connectivity with hive metastore",
        "Question_created_time":1649938200287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/812660\/azure-ml-connectivity-with-hive-metastore",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Dear MS team,  <br \/>\nwe're exploring the AML implementation in our org and i found AML can connect to ADLS2 through datastore; but I'm not sure if it can read the hive metastore and read the tables directly?  <\/p>\n<p>( i choose some random tag below as it's not allowing to submit the question, pls ignore the tagging for this question)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Store Raw JSON file from azureml.core.Run",
        "Question_created_time":1651092990657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829188\/store-raw-json-file-from-azureml-core-run",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,   <\/p>\n<p>in the details tab of a pipeline step (in an experiment) one of the last entries is &quot;See all properties&quot;. Below that the Raw JSON file is linked and can be opened. Is there a way to save or access these Raw JSON file within the Python SDK?   <\/p>\n<p>I want to store these file beside the model to guarantee traceability, if we deploy the registered model outside of Azure.  <\/p>\n<p>Thanks for your help <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot create compute instance",
        "Question_created_time":1649411704767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/805743\/cannot-create-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_body":"<p>I'm busy going through the material to prepare for the DP100 Data Science Associate certification. I'm working through the section on Microsoft Azure Machine Learning, and I'm instructed to create a compute instance, but can't create a free one because I don't have enough quota (my available quota appears to be 0) for the required VM (or any VMs for that matter). I haven't created any compute resources yet, so I don't understand why I would have reached any kind of limit already - plus I still have $200 free credit to use. I've also upgraded to pay-as-you-go in hopes that would change something, which it hasn't.   <\/p>\n<p>I've also requested a quota increase since that it what has been suggested for some similar posts, but it seems very strange to me that the default would be 0 quota, and that people would be required to request it? Has anyone else had this issue and solved it?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cancel all child runs in Azure ML",
        "Question_created_time":1649253299717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/802549\/cancel-all-child-runs-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>How to I properly cancel all child runs in an Azure ML experiment? When I use the code below as expected from documentation, I get an error. &quot;RunConfigurationException:  <br \/>\nMessage: Error in deserialization. dict fields don't have list element type information. field=output_data, list_element_type=&lt;class 'azureml.core.runconfig.OutputData'&gt;...} with exception <strong>init<\/strong>() missing 2 required positional arguments: 'datastore_name' and 'relative_path'&quot;<\/p>\n<p>run = Run.get(ws, 'run-id-123456789')<\/p>\n<p>for child in run.get_children():  <br \/>\nprint(child.get_details())  <br \/>\ntry:  <br \/>\nchild.cancel()  <br \/>\nexcept Exception as e:  <br \/>\nprint(e)  <br \/>\ncontinue<\/p>\n<p>The datasets and runs were configured properly because they run just fine.<\/p>",
        "Question_closed_time":1651506755547,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>You should cancel all the children run by canceling the parent.   <\/p>\n<p>Any benefit to cancel child once a time? Just curious <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to implement customized AbstractADLSDatastore in Azure ML SDK",
        "Question_created_time":1650999035973,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/827239\/how-to-implement-customized-abstractadlsdatastore",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hi AzureML team,   <\/p>\n<p>I'm from Linkedin. We are exploring the option of enabling AzureML to training models on our production data. Also we are using ADLS gen2, we have our customized authentication logic to access the data. We probability need to implement customized ADLSDatastore so that training applications can have access to the data. I'm is there a way to do such customization and contribute the AzureML Data SDK?   <\/p>\n<p>Thanks a lot!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Generic framework for Azure machine Learning AutoML - Hyper parameter, featurization techniques",
        "Question_created_time":1650817253897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/824115\/generic-framework-for-azure-machine-learning-autom",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Currently we have implemented multiple Insurance use cases(Claims, Policy) using AutoML in Azure Machine Learning and created real-time endpoints.  <br \/>\nWe have a standard re-usable python scripts available where with few configuration changes, we are reusing this script for multiple use cases and quickly develop endpoints,  <\/p>\n<p>Currently, we need to apply our Insurance domain knowledge and enrich the training data set.  <br \/>\nTo do this, We understand there are features like Hyper parameter tuning, featurization, encoding techniques, etc. We understand that there are python libraries for that, but is there a generic framework\/coding available so that we can make use of this and implement across multiple use cases to increase the model accuracy. This is mainly to reduce the dependency on data scientist and reduce the azure ml implementation time<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the easiest way to get pipeline failure alerts to email in Azure ML?",
        "Question_created_time":1649202478243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/801663\/what-is-the-easiest-way-to-get-pipeline-failure-al",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello Everyone,  <\/p>\n<p>What is the easiest way to get pipeline failure alerts to email in Azure ML?  <br \/>\nI tired to use Azure Logic Apps to react on the ML events, but fun fact that failed or cancelled ML operations don't trigger any event.  <\/p>\n<p>How do you monitor pipeline failures, guys?  <\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"great_expectations package",
        "Question_created_time":1650353065060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817164\/great-expectations-package",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to run great_expectations on an azure machine learning environment, but when I do so it tells me that great_expectations is not a package. My environment is defined by the following code :<\/p>\n<h1 id=\"creating-an-environment\">creating an environment<\/h1>\n<p>from azureml.core.runconfig import RunConfiguration  <br \/>\nfrom azureml.core.conda_dependencies import CondaDependencies  <br \/>\naml_run_config = RunConfiguration()  <br \/>\naml_run_config.target = compute_target<\/p>\n<h1 id=\"aml_run_configenvironmentdockerenabled--true\">aml_run_config.environment.docker.enabled = True<\/h1>\n<h1 id=\"aml_run_configenvironmentdockerbase_image--mcrmicrosoftcomazuremlbaselatest\">aml_run_config.environment.docker.base_image = &quot;mcr.microsoft.com\/azureml\/base:latest&quot;<\/h1>\n<p>aml_run_config.environment.python.user_managed_dependencies = False  <br \/>\nconda_dep = CondaDependencies()  <br \/>\nconda_dep.add_conda_package(&quot;python=3.8&quot;)  <br \/>\nconda_dep.add_conda_package(&quot;pandas&quot;)  <br \/>\nconda_dep.add_conda_package(&quot;packaging&quot;)  <br \/>\nconda_dep.add_conda_package('pip')<\/p>\n<h1 id=\"conda_depadd_pip_packageazureml-defaults\">conda_dep.add_pip_package(&quot;azureml-defaults&quot;)<\/h1>\n<p>conda_dep.add_pip_package(&quot;great_expectations&quot;)  <br \/>\naml_run_config.environment.python.conda_dependencies = conda_dep<\/p>\n<p>In the logs I can see that the package is being downloaded, but it is not being installed, which is kind of strange. Is there somebody who has experience with great_expectations on Azure Machine Learning?<\/p>\n<p>Kind regards,<\/p>\n<p>Olivier Leflere<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure-ml defaults breaking pip",
        "Question_created_time":1651090798580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829098\/azure-ml-defaults-breaking-pip",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,    <\/p>\n<p>I've seen that the azureml-defaults package has been updated to version 1.41.0 updated in the past 2 days.  <a href=\"https:\/\/pypi.org\/project\/azureml-defaults\/\">https:\/\/pypi.org\/project\/azureml-defaults\/<\/a>    <\/p>\n<p>Since that update, I've been unable to update my web service as when the pip was installing the requirements for this dependency - it was left at the below stage in the screenshot.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/197060-image.png?platform=QnA\" alt=\"197060-image.png\" \/>    <\/p>\n<p>It tries to run for 90 mins then times out. Was working perfectly before this update. Have tried decreasing the version as well and doesn't seem to work.    <\/p>\n<p>Thanks,    <\/p>\n<p>Cam    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"New Azure Machine Learning & Excel",
        "Question_created_time":1651222482640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/831512\/new-azure-machine-learning-excel",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi All    <\/p>\n<p>I have been working with Azure Machine Learning Studio (Classic) and have always found its integration with Excel super mega useful.    <\/p>\n<p>All I had to do was to get the URI and the API_Key of my web service and paste them on the Azure Machine Learning Add-In, that I had downloaded. Easy and useful.    <\/p>\n<p>However, with the new Azure Machine Learning studio that does not seem possible any more.     <\/p>\n<p>Under the new Azure Machine Learning studio when I deploy a model I get a REST endpoint and that's it? !? I cannot find anywhere the API_key for my web service. I cannot even find a web service section  as such.     <\/p>\n<ol>\n<li> How do I get the API_Key for the web service I need?    <\/li>\n<li> If I get the API_Key could I use it on the Excel Azure Machine Learning add-in. It looks as if this is no longer an option and we need to start using Power BI instead.    <\/li>\n<li>  I have read this interesting post where someone mentions a work around that consist of creating an Excel macro. Is this the best option? <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html<\/a>     <\/li>\n<\/ol>\n<p>Thank you    <\/p>",
        "Question_closed_time":1651319301697,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for reaching out. The new AzureML integration with Excel isn't supported at this time. More details are provided on this <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html\">thread<\/a>. The alternative approach would be to use a Client or PowerBI to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">consume<\/a> the model. For future reference, you can find your webservice endpoint and keys under Studio &gt; Endpoints &gt; Endpoint &gt; Consume.    <\/p>\n<p>--please don't forget to <code>Accept Answer<\/code> if the reply is helpful. Thanks.--<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Principal Component Analysis is Missing?",
        "Question_created_time":1651249877603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/832052\/principal-component-analysis-is-missing",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Classic ML Studio has PCA. The new one does not have PCA. What to do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Consume scoreing api in excel",
        "Question_created_time":1611073754767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I created a new azure automl experiment and deployed it to an endpoint and can access the scoring URI via postman but how do I consume it in excel? Classic ml studio had the excel addin you can use but I don't see the same for URIs created and deployed from an automl experiment.   <\/p>\n<p>This Microsoft Developer video has a demo of exactly what I'm looking to do around the 32 min mark.  <br \/>\n<a href=\"https:\/\/youtu.be\/9FGuf55_Xtk?t=1915\">https:\/\/youtu.be\/9FGuf55_Xtk?t=1915<\/a>  <\/p>",
        "Question_closed_time":1611147165400,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"#\">@Anonymous  <\/a>  Thanks for the question, Have a look here:    <br \/>\n<a href=\"https:\/\/github.com\/retkowsky\/AzureML_Excel\">https:\/\/github.com\/retkowsky\/AzureML_Excel<\/a>    <\/p>\n<p>There is an Excel macro in the Excel file that call an Azure ML service deployed model.    <br \/>\nThere is a quick description of the process in the Word document available in this repo.    <br \/>\nYou can find here as well the Python notebook for creating &amp; deploying the model. No autoML in it but not a big deal to adapt.    <\/p>\n<p>Please try the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">Consume web services portion<\/a> Azure ML documentation? That could help you get started.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to fix the parameters error  after running the data to produce the evaluate model results",
        "Question_created_time":1650867535663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/824528\/how-to-fix-the-parameters-error-after-running-the",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Currently, our research model results are encountering Mean Absolute Error, Root Mean Squared Error, Relative Absolute Error, Relative Squared Error. I don't know what is the reason for this error, can someone explain it to me.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/195929-278179892-506579081179534-6646709694765864732-n.png?platform=QnA\" alt=\"195929-278179892-506579081179534-6646709694765864732-n.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error in init() function during azurel ML deployment due to model path definition",
        "Question_created_time":1650517247760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/820362\/error-in-init()-function-during-azurel-ml-deployme",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello Team,    <\/p>\n<p>We are trying to deploy a model to Azure ML workspace containing a saved model &amp; One Hot Encoded joblib file.    <br \/>\nWe are facing issue in init() function.    <\/p>\n<p>Please find the below error message:    <\/p>\n<p>&quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.    <\/p>\n<p>PFB screenshot of scoring file:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/194860-image.png?platform=QnA\" alt=\"194860-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Snapshot Creation Issue - Azure ML Pipeline",
        "Question_created_time":1651144125440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/830075\/snapshot-creation-issue-azure-ml-pipeline",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have created new compute cluster, deleted the older versions, deleted blobs in data store, deleted unused files from the notebook instance, tried increasing the SNAPSHOT_MAX_SIZE_BYTES = 2000000000 but none of them are working.    <\/p>\n<p>It was showing the snapshot size issue (300 mb and 200 files allowed) previously so we included     <br \/>\nazureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 4000000000 ,which resolved the issue then, but we are unable to find solution for this one.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/197324-download.png?platform=QnA\" alt=\"197324-download.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Designer Preview data error",
        "Question_created_time":1651158995620,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/830467\/azure-machine-learning-designer-preview-data-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using Azure Machine Learning designer to go through one of the introduction <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/\">Microsoft course<\/a>. I have built a pipeline in Designer, but whenever I try to use &quot;Preview Data&quot; option of any step of the pipeline, this option disappears and nothing happens. The above 2 images reflect the situation before clicking &quot;Preview Data&quot; and right after it.     <br \/>\n<strong>Before:<\/strong>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/197418-azure-error-1.png?platform=QnA\" alt=\"197418-azure-error-1.png\" \/>    <br \/>\n<strong>After:<\/strong>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/197379-azure-error-2.png?platform=QnA\" alt=\"197379-azure-error-2.png\" \/>    <\/p>\n<p>Is this known bug?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Question_created_time":1651101620807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli  <\/p>",
        "Question_closed_time":1651104442393,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for reaching out. You can use compute instance <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal\">terminal<\/a> in AML notebooks to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/samples-notebooks#get-samples-on-azure-machine-learning-compute-instance\">clone<\/a> the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.<\/p>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric.",
        "Question_created_time":1651063933880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/828516\/automlexception-message-could-not-find-a-model-wit",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am trying to make a classification using automl service , I've chosen KNN as model to train and for the primary metric i used accuracy . Based on the automl documentation the metric accuracy can be used with this type of classification task, but I get the error : AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric. when I checked azure ml studio I find this error of the run is that means that the dataset that i am using can be trained on KNN model ? ![197051-image.png][1] [1]: \/api\/attachments\/197051-image.png?platform=QnA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to run Azure cluster (Azure ML) on spot instances?",
        "Question_created_time":1650979096333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/826904\/is-it-possible-to-run-azure-cluster-(azure-ml)-on",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I wonder if it's possible to use spot instances to run experiments in Azure ML as it's implemented for VM <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/virtual-machines\/spot\/\">https:\/\/azure.microsoft.com\/en-us\/services\/virtual-machines\/spot\/<\/a>?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Real-time endpoint doesn't work (error 502)",
        "Question_created_time":1609249050140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/213249\/real-time-endpoint-doesnt-work-(error-502)",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello. I created a training pipeline using the ML designer, and also created a real-time inferencing pipeline after that. The training pipeline ran completely without any error. I also published the real-time inferencing pipeline successfully. In the end, I deployed the real-time inferencing pipeline to AKS and it resulted in a real-time endpoint with a Healthy state.    <\/p>\n<p>However, when I want to test the endpoint from the &quot;<strong>Endpoints<\/strong>&quot; page, it returns nothing! Just a red empty box.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/51985-image.png?platform=QnA\" alt=\"51985-image.png\" \/>    <\/p>\n<p>I tried to run the example consumption codes in the &quot;<strong>Consume<\/strong>&quot; tab in the Notebooks section of the ML Studio.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/52042-image.png?platform=QnA\" alt=\"52042-image.png\" \/>    <\/p>\n<p>But again, it didn't give any results and returned the following error description:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/51986-image.png?platform=QnA\" alt=\"51986-image.png\" \/>    <\/p>\n<p>I don't know what causes this issue. I appreciate if you could help me with this. Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning cannot evaluate model",
        "Question_created_time":1650117583373,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/814652\/azure-machine-learning-cannot-evaluate-model",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I create a trained model in Azure machine learning, when I use it to predict a new set of data, the evaluate model cannot show the result, it's all empty. How can I solve the problem?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/193621-screenshot.png?platform=QnA\" alt=\"193621-screenshot.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endpoints for getting metadata about published models?",
        "Question_created_time":1649425228733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/805976\/endpoints-for-getting-metadata-about-published-mod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My question centers around working with AML models that have been published as web services, as described here:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal<\/a>    <\/p>\n<p>Are there any endpoints or ways of obtaining more detailed information about a published model? For example, the documentation states that inputs to the model are passed in via a &quot;data&quot; property, and obviously, this will vary my the model:    <\/p>\n<p>{    <br \/>\n    &quot;data&quot;:  <br \/>\n        [  <br \/>\n            &lt;model-specific-data-structure&gt;  <br \/>\n        ]  <br \/>\n}    <\/p>\n<p>Is there a way to programatically find out what the model expects as input?     <\/p>\n<p>The full 'wish-list' of metadata info we'd like is listed here:     <\/p>\n<ul>\n<li> What models are available for serving    <\/li>\n<li> What is the model prediction endpoint    <\/li>\n<li> What are the required inputs and their data types    <\/li>\n<li> What are the model outputs and data types    <\/li>\n<\/ul>\n<p>Are there any endpoints or any way at getting to this information?    <\/p>",
        "Question_closed_time":1649630016347,
        "Answer_score_count":0.0,
        "Answer_comment_count":6.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=32325e98-f4ed-442a-83f3-7d1edc203dea\">@MK RP  <\/a>    <\/p>\n<p>Thanks for reaching out to us, I will answer your question below, at the meantime, if you feel like I am not getting your point well, please point it out and correct me.    <\/p>\n<p>I think you are mentioning how to monitor published model and collect data, there are several choice depends on the data you want to collect:    <\/p>\n<ol>\n<li> Collect data from models in production - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection<\/a>    <\/li>\n<\/ol>\n<p>The following data can be collected:    <\/p>\n<p><strong>Model input data<\/strong> from web services deployed in an AKS cluster. Voice audio, images, and video are not collected.    <br \/>\n<strong>Model predictions<\/strong> using production input data.    <\/p>\n<p>Once collection is enabled, the data you collect helps you:    <\/p>\n<p>Monitor data drifts on the production data you collect.    <br \/>\nAnalyze collected data using Power BI or Azure Databricks    <br \/>\nMake better decisions about when to retrain or optimize your model.    <br \/>\nRetrain your model with the collected data.    <\/p>\n<p>2 . Monitor and collect data from ML web service endpoints - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights<\/a>    <\/p>\n<p>You can use Azure Application Insights to collect the following data from an endpoint:    <\/p>\n<p>Output data    <br \/>\nResponses    <br \/>\nRequest rates, response times, and failure rates    <br \/>\nDependency rates, response times, and failure rates    <br \/>\nExceptions    <\/p>\n<p>3 . More details from Data Drift - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python<\/a>    <\/p>\n<p>With Azure Machine Learning dataset monitors (preview), you can:    <\/p>\n<p>Analyze drift in your data to understand how it changes over time.    <br \/>\nMonitor model data for differences between training and serving datasets. Start by collecting model data from deployed models.    <br \/>\nMonitor new data for differences between any baseline and target dataset.    <br \/>\nProfile features in data to track how statistical properties change over time.    <br \/>\nSet up alerts on data drift for early warnings to potential issues.    <br \/>\nCreate a new dataset version when you determine the data has drifted too much.    <\/p>\n<p>Hope above information helps, please let us know if you need further helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Studio does not connect to Azure Table Storage",
        "Question_created_time":1650452975323,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/819266\/azure-machine-learning-studio-does-not-connect-to",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>I am trying to create a DataStore in Azure Machine learning to read data from Azure Table Storage.  <\/p>\n<p>There is no option available, Is it really possible to make this connection?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why couldn't I open file?",
        "Question_created_time":1650412678503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/818328\/why-couldnt-i-open-file",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I input a data file, then when I run this trained model, it says:  <\/p>\n<p> [1] &quot;Loading variable port1...&quot;  <br \/>\n[Information]         package 'magrittr' successfully unpacked and MD5 sums checked  <br \/>\n[Information]         package 'xgboost' successfully unpacked and MD5 sums checked  <br \/>\n[Information]         Warning messages:  <br \/>\n[Information]         1: In eval(ei, envir) : NAs introduced by coercion  <br \/>\n[Information]         2: In eval(ei, envir) : NAs introduced by coercion  <br \/>\n[Stop]     DllModuleMethod::Execute. Duration = 00:01:00.8680701  <br \/>\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:  <br \/>\n---------- Start of error message from R ----------  <br \/>\ncan not open file &quot;9c40b049d4c7d584393d08195471b7e&quot;  <\/p>\n<p>can not open file &quot;9c40b049d4c7d584393d08195471b7e&quot;  <br \/>\n----------- End of error message from R -----------  <\/p>\n<p>I cut the big file to 600 recrods and re-run it, this time:  <br \/>\n   [1] &quot;Loading variable port1...&quot;  <br \/>\n[Information]         [1] &quot;before install packages&quot;  <br \/>\n[Information]         package 'magrittr' successfully unpacked and MD5 sums checked  <br \/>\n[Information]         package 'xgboost' successfully unpacked and MD5 sums checked  <br \/>\n[Information]         [1] &quot;after load packages...&quot;  <br \/>\n[Information]         Warning message:  <br \/>\n[Information]         In eval(ei, envir) : NAs introduced by coercion  <br \/>\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:08.6862974  <br \/>\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:  <br \/>\n---------- Start of error message from R ----------  <br \/>\ncan not open file &quot;1&quot;  <\/p>\n<p>can not open file &quot;1&quot;  <br \/>\n----------- End of error message from R -----------  <\/p>\n<p>What is the problem?  <\/p>\n<p>Plz help asap!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't open Machine learning studio (classic)",
        "Question_created_time":1650350198420,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817073\/cant-open-machine-learning-studio-(classic)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>While opening ml studio (classic) , shows a pop up message like it will retire on 31 August 2024 . Couldn't close the message<\/p>",
        "Question_closed_time":1650491049673,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=065b67d4-0031-46e3-b16b-02416c45d955\">@Asheekha  <\/a>     <\/p>\n<p>Sorry about your experience again, I checked internally about the issue and my colleague confirmed that this is a known issue of Chrome browser, which can be fixed by cleaning the cookie.     <\/p>\n<p>Please try to clean the cookies and I hope this helps! Please let me know if you are still blocked by this issue.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer to help the community, thanks a lot.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Run experiment fails when using a pre-build Docker image as environment",
        "Question_created_time":1644997645313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/737518\/run-experiment-fails-when-using-a-pre-build-docker",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>My co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.  <br \/>\nIn a separate script, they have registered these environments with the command <code>myenv.register(workspace=ws)<\/code>. In another script, I should use their environment for testing our model.  <\/p>\n<p>In order to get one of their environments, I use the command  <code>registered_env = Environment.get(ws, 'the-specific-environment-name')<\/code>  <\/p>\n<p>Unfortunately, this does not work when I use <code>registered_env<\/code> for the experiment. I get the error &quot;Authentication failed for container registry name_of_their_container_registry.azurecr.io&quot;. The experiment run works perfectly when I copy their environment definition code into my script instead of using the command  <code>registered_env = Environment.get(ws, 'the-specific-environment-name')<\/code>.  <\/p>\n<p>However, I cannot copy everytime their environment definition code into my script.  <br \/>\nHow can I get the environment into my script which has been defined in another script?  <\/p>\n<p>This StackOverFlow post is quite related to my problem:  <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\">https:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der<\/a>  <\/p>\n<p>To illustrate what my problem is, here are some code samples.  <\/p>\n<p>This code sample is working:  <\/p>\n<pre><code>registry = ContainerRegistry()\nregistry.address = &lt;DockerRegistryAddress&gt;\nregistry.username = &lt;UserName&gt;\nregistry.password = &lt;Password&gt;\nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)\n\nexemplarily_env_docker_image.python.user_managed_dependencies = True\n\n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\nexemplarily_env_docker_image.register(workspace=ws)\n\nmodel = Model(ws, 'exemplarily_model')\n\ninference_config = InferenceConfig(environment=exemplarily_env_docker_image, \n                                   source_directory='.\/source_dir', \n                                   entry_script='.\/score.py') \n\n\ndeployment_config = LocalWebservice.deploy_configuration(port=6789)\n\nservice = Model.deploy(\n    ws,\n    &quot;myservice&quot;,\n    [model],\n    inference_config,\n    deployment_config,\n    overwrite=True,\n)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.get_logs())\n<\/code><\/pre>\n<p>Now, I do a small change and the code sample is <strong>not<\/strong> working anymore:  <\/p>\n<pre><code>registry = ContainerRegistry()\nregistry.address = &lt;DockerRegistryAddress&gt;\nregistry.username = &lt;UserName&gt;\nregistry.password = &lt;Password&gt;\nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)\n\nexemplarily_env_docker_image.python.user_managed_dependencies = True\n\n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\nexemplarily_env_docker_image.register(workspace=ws)\n\nmodel = Model(ws, 'exemplarily_model')\n\nreg_env = Environment.get(ws, &quot;exemplarily-env_Docker-image-AzureRegistry&quot;)\ninference_config = InferenceConfig(environment=reg_env, \n                                   source_directory='.\/source_dir', \n                                   entry_script='.\/score.py') \n\ndeployment_config = LocalWebservice.deploy_configuration(port=6789)\n\nservice = Model.deploy(\n    ws,\n    &quot;myservice&quot;,\n    [model],\n    inference_config,\n    deployment_config,\n    overwrite=True,\n)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.get_logs())\n<\/code><\/pre>\n<p>What is working:  <\/p>\n<pre><code>registry = ContainerRegistry()\nregistry.address = &lt;DockerRegistryAddress&gt;\nregistry.username = &lt;UserName&gt;\nregistry.password = &lt;Password&gt;\nexemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', &lt;DockerImageAddress&gt;, container_registry=registry, conda_specification=None, pip_requirements=None)\n\nexemplarily_env_docker_image.python.user_managed_dependencies = True\n\n# Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\nexemplarily_env_docker_image.save_to_directory(path=&quot;.\/env&quot;, overwrite=True)\n\nmodel = Model(ws, 'exemplarily_model')\n\nreg_env = Environment.load_from_directory(path=&quot;.\/env&quot;)\ninference_config = InferenceConfig(environment=reg_env, \n                                   source_directory='.\/source_dir', \n                                   entry_script='.\/score.py') \n\ndeployment_config = LocalWebservice.deploy_configuration(port=6789)\n\nservice = Model.deploy(\n    ws,\n    &quot;myservice&quot;,\n    [model],\n    inference_config,\n    deployment_config,\n    overwrite=True,\n)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.get_logs())\n<\/code><\/pre>\n<p>Why is the middle code sample not working? Is this a bug?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure SQL Managed Instance PREDICT with an ONNX model",
        "Question_created_time":1650460466510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/819485\/azure-sql-managed-instance-predict-with-an-onnx-mo",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I repeat the example from <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql-edge\/deploy-onnx\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql-edge\/deploy-onnx<\/a> &quot;Deploy and make predictions with an ONNX model and SQL machine learning&quot; In this quickstart, you'll learn how to train a model, convert it to ONNX, deploy it to Azure SQL Edge, and then run native PREDICT on data using the uploaded ONNX model.    <\/p>\n<p>Successfully create a model using Python, convert to onnx format, I test the model using Python, save the model to the database, load the necessary data and try to execute the SQL query    <br \/>\nUSE onnx    <br \/>\nDECLARE <a href=\"\/users\/na\/?userid=0f55de7e-bffd-0003-0000-000000000000\">@\u9ed8  <\/a> VARBINARY(max) = (    <br \/>\n    SELECT DATA  <br \/>\n    FROM dbo.models  <br \/>\n    WHERE id = 1  <br \/>\n    );  <br \/>\nWITH predict_input    <br \/>\nAS (    <br \/>\n    SELECT TOP (1000) [id]  <br \/>\n    , CRIM  <br \/>\n    , ZN  <br \/>\n    , INDUS  <br \/>\n    , CHAS  <br \/>\n    , NOX  <br \/>\n    , RM  <br \/>\n    , AGE  <br \/>\n    , DIS  <br \/>\n    , RAD  <br \/>\n    , TAX  <br \/>\n    , PTRATIO  <br \/>\n    , B  <br \/>\n    , LSTAT  <br \/>\nFROM [dbo].[features]    <br \/>\n)    <br \/>\nSELECT predict_input.id    <br \/>\n, p.variable1 AS MEDV    <br \/>\nFROM PREDICT(MODEL = <a href=\"\/users\/na\/?userid=0f55de7e-bffd-0003-0000-000000000000\">@\u9ed8  <\/a>, DATA = predict_input, RUNTIME=ONNX) WITH (variable1 FLOAT) AS p;    <\/p>\n<p>As a result I get an error Msg 102, Level 16, State 5, Line 27 Incorrect syntax near 'RUNTIME'.    <\/p>\n<p>I can't figure out what's wrong. The documentation clearly says &quot;The RUNTIME = ONNX argument is only available in Azure SQL Edge, Azure Synapse Analytics, and is in Preview in Azure SQL Managed Instance.&quot;<\/p>",
        "Question_closed_time":1650461393250,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I think there is a misunderstanding here. The quickstart article named &quot;<strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql-edge\/deploy-onnx\">Deploy and make predictions with an ONNX model and SQL machine learning<\/a><\/strong>&quot; can be successfully implemented only with Azure SQL Edge and cannot be implemented with Azure SQL Managed Instance.    <\/p>\n<p>You cannot have an ONNX model and make predictions with it on Azure SQL Managed Instance. Please deploy Azure SQL Edge on an IoT device using <strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql-edge\/deploy-portal\">this<\/a><\/strong> documentation.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Loading pickle object in entry script in Azure ML",
        "Question_created_time":1633278181287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/575512\/loading-pickle-object-in-entry-script-in-azure-ml",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have an entry script that loads a pickled tokenizer object from Tensorflow and the model itself. When I try to deploy, locally or otherwise, I get an error saying something broke in the init function in the score.py script. Commenting out the tokenizer and the deployment works so I'm sure it's because of it. This is how I define the function:  <\/p>\n<pre><code>def init():\n    global tokenizer, model\n    tokenizer_path = os.path.join('.\/objs', 'tokenizer.pkl') # tried absolute path as well, didn't work\n    tokenizer = pickle.load(tokenizer_path)\n    # tokenizer = pickle.load(open(tokenizer_path, 'rb')) # also tried this, didn't work\n    model = tf.keras.models.load_model(os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.h5'))\n<\/code><\/pre>\n<p>Is that the correct way to load a pickle object in the entry script? Any tips would be appreciated. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can we use Azure Machine Learning solution during an educational session with 20 students ?",
        "Question_created_time":1650359134483,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817296\/how-can-we-use-azure-machine-learning-solution-dur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How can we use Azure Machine Learning solution during an educational session with 20 students ? Can we share compute and storage resources between students?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question about ML output",
        "Question_created_time":1650351269333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817010\/question-about-ml-output",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Dear Support,    <\/p>\n<p>I have draft a pipeline as following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/194175-image.png?platform=QnA\" alt=\"194175-image.png\" \/>    <\/p>\n<p>you can see it has 2 webservice output,    <\/p>\n<p>may I know where I can see the 2 output and how to use it ? thnaks. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Reading dataset after uploading to storage",
        "Question_created_time":1650301669787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/816330\/reading-dataset-after-uploading-to-storage",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>hi,  <\/p>\n<p>I created various datasets but within my python notebook, how do i read it?  <\/p>\n<p>So currently if this is what I have:  <\/p>\n<p>x_train_df = pd.read_csv('data_reviews\/x_train.csv')  <\/p>\n<p>what should I replace it with?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Training a TensorFlow model in Azure ML",
        "Question_created_time":1649367124903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/804968\/training-a-tensorflow-model-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I am following the link below for training a TensorFlow model in Azure ML:  <\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb<\/a>  <\/p>\n<p>However, as my training dataset is in a container named &quot;sample-datasets&quot; in ADLS Gen2, I changed the following code (in the above link) to refer to the paths in my data lake. So I replaced code A (in the link above) with code B (my code)  <\/p>\n<p>Code A:  <\/p>\n<p>urllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-labels-idx1-ubyte.gz',  <br \/>\nfilename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-labels-idx1-ubyte.gz',  <br \/>\nfilename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))  <\/p>\n<p>Code B:  <\/p>\n<p>from azureml.core.dataset import Dataset  <br \/>\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))  <br \/>\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))  <\/p>\n<p>But I receive the following error:  <\/p>\n<p>HTTPError: HTTP Error 401: Server failed to authenticate the request. Please refer to the information in the www-authenticate header.  <\/p>\n<p>Can you please let me know how I can train the model using my data which are stored in the data lake? More precisely, how my Python code can copy the training dataset from my data lake into data_folder?  <\/p>\n<p>PS: Please note that I have already granted the Blob Storage data Contributor role on my data lake storage account to my Azure ML workspace as a managed identity. <\/p>",
        "Question_closed_time":1649420498973,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><em>anonymous user<\/em> I have not worked on ADLS scenarios with Azure ML but I have added the ADLS tag to this thread for others to chip in and add their views.     <\/p>\n<p>Based on the <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/storageservices\/data-lake-storage-gen2\">documentation<\/a> for ADLS REST API it supports Azure Active Directory (Azure AD), Shared Key, and shared access signature (SAS) authorization with the APIs that are available to download the files from its storage. So, I think a direct download might not work in this case without authentication.     <\/p>\n<p>I think the easiest way to get your files locally from ADLS is to use the python SDK to authenticate using account key or AD as listed <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/data-lake-storage-directory-file-acl-python\">here<\/a>.    <\/p>\n<p>If you have many files that needs to be downloaded and referenced in your ML experiments then you may also consider to use the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/import-data\">import data<\/a> module of designer for designer experiments or register them as <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-connect-data-ui?tabs=credential\">dataset<\/a> from dataset tab of ml.azure.com which can also be referenced using the Azure ML SDK.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Machine Learning Stuck Quota",
        "Question_created_time":1650055277367,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/814382\/machine-learning-stuck-quota",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>My machine learning workspace is stuck on quota and when I want to delete it is not deleted even if I wait for 2 hours, what should I do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azue machine Learning",
        "Question_created_time":1649945649033,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/812800\/azue-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello all,  <\/p>\n<p>Any tips to run an Azure ML  exercise to help to create a pattern in names of professional occupations in a field ?    <\/p>\n<p>I have thousands of ways the people have written their professional occupation and would like to run an ML to help to make some pattern to this names of occupations.  <\/p>\n<p>Any idea \/ tips \/ examples will be appreciated   <\/p>\n<p>Best regards  <br \/>\nPaulo<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio Versioning",
        "Question_created_time":1649276461560,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/803089\/azure-ml-studio-versioning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Is there a way to pass in a specific version number parameter to render the studio UI that will exclude new \/ preview features?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deleting workspace resources after account automatically logged out by microsoft.",
        "Question_created_time":1649349071340,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/804671\/deleting-workspace-resources-after-account-automat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Dear Team,   <\/p>\n<p>My workspace on ML studio was logged ou and when I tried logging in it asked security details that I provided. I got a repy stating that the microsoft account will be validated within 1 month(30 days). I would like to delete all my resources and other compute instances so that I will not be billed for a daily charge. But to do so I am unable to login due to the 30 day timeline.  Any support on deleting this resource woul be much appreciated.  Thanks, Aakash.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Formato di serializzazione eventi",
        "Question_created_time":1649832685723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/810747\/formato-di-serializzazione-eventi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Buongiorno, nel output di un processo di analisi di flusso non posso cambiare formato da JSON a CVS come spiegato dal tutorial Microsoft &quot;Previsioni meteo usando i dati del sensore dall'hub IoT in Machine Learning Studio (versione classica)&quot;.  <br \/>\nQualcuno ha qualche idea di come risolvere?  <br \/>\nGrazie.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Notebook",
        "Question_created_time":1603705986700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/139062\/azure-notebook",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I can't create a project in Azure Notebooks. It shows on the page to migrate my notebooks. So, which notebooks should I use from the alternatives for use Jupyter noteboks on cloud?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"synapse analytics datastores from Azure ML",
        "Question_created_time":1649596287577,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/807044\/synapse-analytics-datastores-from-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I use Azure ML (designer) as data mining pourpose.    <br \/>\nAND use synapse for datapreparation.    <\/p>\n<p>After I executed data preparation prosess, i want to use the prepared data from Azure ML environment,,, but I can not select Azure Synapse data sourse  from Azure ML side as datastores.    <\/p>\n<p>Is there any work around? Or you just do not support it?    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use custom environment in Azure Machine Learning Designer",
        "Question_created_time":1647597231527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/777745\/use-custom-environment-in-azure-machine-learning-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <\/p>\n<p>I would like to know if there is the possibility to use a custom environment (created from the AML portal) for the execution of a Python Script Step in the Azure Machine Learning Designer (only using the designer, not using azureml sdk to publish the pipeline from the code).   <\/p>\n<p>Thanks,  <br \/>\nG<\/p>",
        "Question_closed_time":1648494342677,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Thanks for your feedback. Based on your comments above, it seems you want to configure a custom environment in AML designer and install unsupported python libraries. These are the supported <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment\">Custom Environments<\/a>. However, in AML designer, the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-designer-python\">execute python script component<\/a> enables you to write custom python scripts and install python libraries. This particular <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/execute-python-script\">document<\/a> shows how to configure execute python script. You can install packages that aren't in the preinstalled list by using the following command:<\/p>\n<pre><code>import os  \nos.system(f&quot;pip install scikit-misc&quot;)  \n<\/code><\/pre>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"KeyError 'raw_data'",
        "Question_created_time":1649434434750,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/806241\/keyerror-raw-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there,  <\/p>\n<p>I am testing my deployed model on AKS using Postman. To be able to do so, I do a kubectl port-forward on an azureml-fe pod (toward port 8001). My deployment is successful, I am also able to get the swagger documentation interrogating my model.  <\/p>\n<p>However, when running a request on the \/score endpoint I get an error linked to azure libraries. Here are the logs from the pod. I get the error even with a very simple run function that just returns a fixed value like  <\/p>\n<pre><code>@input_schema('input_data', sample_input)\n@output_schema(sample_output)\ndef run(input_data):\n    return json.dumps({&quot;hello&quot;:&quot;world&quot;})\n<\/code><\/pre>\n<p>Here are logs.  <\/p>\n<pre><code>2022-04-08 15:44:28,832 | root | INFO | Validation Request Content-Type\n2022-04-08 15:44:28,833 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 65, in run_scoring\n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 102, in invoke_user_with_timer\n    params = prepare_user_params(input, headers, aml_request._rawHttpRequested)\n  File &quot;\/var\/azureml-server\/routes_common.py&quot;, line 132, in prepare_user_params\n    params = {main.run_input_parameter_name: input[main.wrapped_parameter_name]}\nKeyError: 'raw_data'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_61774fe85dfca66c0af06d4aa0c015f2\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request\n    rv = self.dispatch_request()\n  File &quot;\/azureml-envs\/azureml_61774fe85dfca66c0af06d4aa0c015f2\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request\n    return self.view_functions[rule.endpoint](**req.view_args)\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 44, in score_realtime\n    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 74, in run_scoring\n    raise RunFunctionException(str(exc))\nrun_function_exception.RunFunctionException\n\n2022-04-08 15:44:28,834 | root | INFO | 500\n127.0.0.1 - - [08\/Apr\/2022:15:44:28 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 10 &quot;-&quot; &quot;PostmanRuntime\/7.29.0&quot;\n<\/code><\/pre>\n<p>Could you please help?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML Model Accuracy Metrics",
        "Question_created_time":1649318824207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/803749\/azure-automl-model-accuracy-metrics",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello Everyone , I have deployed a ML Model over a REST Endpoint successfully and the model is trained using Azure AutoML . I am successfully able to send data to the model via the endpoint and get back the predicted output . Sending of data is done in JSON format through a python script and the received data is print as output by the python script .I am able to view trained model metrics like accuracy , error rates , root mean squared errors etc .. through the Azure ML Studio User Interface but is there any way of accessing these error or accuracy metrics through the endpoint using a python script ? I know that there is ML flow but in that case the whole training should be done using a python script and that is not suitable for my case and the other one is logging APIs which don't give me error or accuracy metrics but give others which are not needed for my usage. In a nutshell I want to access model accuracy metrics of the already trained and deployed model via an API or endpoint . Also is there any place in azure storage where these accuracy metrics are stored and if they can be accessed via an Endpoint ? Please help me on this issue . Thank you all :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Studio and Private Endpoint issue",
        "Question_created_time":1646161833773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/755259\/ml-studio-and-private-endpoint-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>We are trying to setup a Machine Learning Workspace and only have it accessible via Private Endpoint Connection.  When we have it this setup and try to connect from our company workstations it loads the page but we get an &quot;Error Loading recent runs&quot;    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/179012-image.png?platform=QnA\" alt=\"179012-image.png\" \/>    <\/p>\n<p>If we run this from a VM inside Azure it is fine.      <\/p>\n<p>We do have a VPN Gateway set up to access our on-prem which works for other Vnets we have in Azure.  We peered the VNET that ML sits in with VNET where Gateway network is setup.  unfortunately we had  a 3rd party set up the original connection and did not fully document.   We have tried to match all settings we have in the working VNET with the ML Vnet but can't seem to see what we are missing.  I also can't seem to find what logs to check to see where connections are being blocked.      <br \/>\nHoping I explained our issue will enough.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I extend the waiting time of Azure speech-to-text API in Python?",
        "Question_created_time":1649087644937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/799565\/how-do-i-extend-the-waiting-time-of-azure-speech-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>When using speech-to-text to transfer audio file to text, I found that the function would stop working if human voices haven't occurred for about 5 seconds. In my case, what I want to transfer is audios of interviews, which would often contain some advertisements or music in the middle of it, and when this happens, the speech-to-text would only transfer the first half of the whole audio, and report an error that &quot;No speech could be recognized&quot;.  <br \/>\nIn this case, how can I extend the waiting time of that in order to transfer the whole file in Python codes?  <\/p>",
        "Question_closed_time":1649205144237,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=00357ba6-6a38-41a9-b332-d623f51e682e\">@Muyao Hu  <\/a>     <\/p>\n<p>I think there are two solutions you can have a try in Python SDK:     <\/p>\n<ol>\n<li> There is a 'set_property' method on the config to allow you to set parameters to your request, which can change the default silence time:: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property<\/a>    <\/li>\n<li> This way you can set the EndSilenceTimeout (PropertyIDs in Pyhton: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields<\/a>)    <\/li>\n<\/ol>\n<p>Please notice, the time is as &quot;ms&quot;. Hope above helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks!<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"list of folder names as input for ParallelRunStep-class",
        "Question_created_time":1647256395817,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771015\/list-of-folder-names-as-input-for-parallelrunstep",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>In this <a href=\"https:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/07B%20-%20Creating%20a%20Batch%20Inferencing%20Service.ipynb\">example<\/a>, all data files for the parallel run step are stored in <strong>one<\/strong> folder.    <\/p>\n<p>I also want to create a parallel run step. The task for each of the several <strong>folders<\/strong>, in which the multiple data files are stored, is exactly identical.     <\/p>\n<p>The folders:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182769-image.png?platform=QnA\" alt=\"182769-image.png\" \/>    <\/p>\n<p>The content of each folder:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182833-image.png?platform=QnA\" alt=\"182833-image.png\" \/>    <\/p>\n<p>How should I define the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py\">ParallelRunStep<\/a>-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?    <br \/>\nTwo folders should run simultaneously in parallel.    <\/p>\n<p>Moreover, I would like to ask how to get <strong>only<\/strong> the stored folder names or folder paths from a given directory path of a blob storage container.    <\/p>",
        "Question_closed_time":1647858343237,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>@@AlexanderPakakis-0994 Thanks, An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first &quot;merge&quot; those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how publish the pipeline endpoint and test it ?",
        "Question_created_time":1649315875193,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/803725\/how-publish-the-pipeline-endpoint-and-test-it",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>we have build a pipeline and would like to publish as service, may I know how to test the it works or not  ?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190855-image.png?platform=QnA\" alt=\"190855-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure SDK previous step output to multiple steps as input",
        "Question_created_time":1649214311427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/801687\/azure-sdk-previous-step-output-to-multiple-steps-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a output from previous step and want to use it as input to multiple steps.    <br \/>\nBut, when I run the experiment, the pipeline looks like this    <\/p>\n<p>Here is my code    <\/p>\n<pre><code>source_directory=&quot;.\/test&quot;  \ndesigner1_config = ScriptRunConfig(source_directory=source_directory,  \n                                 command=[&quot;python&quot;, &quot;designer1.py&quot;,   \n                                          &quot;--output_test1&quot;, output_test1], #   \n                                 compute_target=aml_compute,  \n                                 environment=env_py)  \n  \ndesigner1_step = CommandStep(name=&quot;designer_step&quot;,   \n                           inputs=[input_dept_fun_d],  \n                           outputs=[output_test1], #  \n                           runconfig=designer1_config,  \n                           allow_reuse=True)  \n\n\nsource_directory=&quot;.\/test&quot;  \ndesigner2_config = ScriptRunConfig(source_directory=source_directory,  \n                                 command=[&quot;python&quot;, &quot;designer2.py&quot;], #   \n                                 compute_target=aml_compute,  \n                                 environment=env_py)  \n  \ndesigner2_step = CommandStep(name=&quot;designer2_step&quot;,   \n                           inputs=[input_dept_fun_d, output_test1],  \n                           outputs=[], #  \n                           runconfig=designer2_config,  \n                           allow_reuse=True)  \n<\/code><\/pre>\n<p>Use 2 steps, it shows picture 1    <\/p>\n<pre><code>step_sequence = [designer1_step, designer2_step]  \n<\/code><\/pre>\n<p>Use 1 step, it shows picture 2    <\/p>\n<pre><code>step_sequence = [designer2_step]  \n  \n<\/code><\/pre>\n<p>Submit the experiement    <\/p>\n<pre><code>pipeline = Pipeline(workspace=ws, steps=step_sequence)  \npipeline_run = Experiment(workspace=ws, name='pipeline').submit(config=pipeline, regenerate_outputs=True)  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190374-image.png?platform=QnA\" alt=\"190374-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190373-image.png?platform=QnA\" alt=\"190373-image.png\" \/>    <\/p>\n<p>Here's what I want    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190392-image.png?platform=QnA\" alt=\"190392-image.png\" \/>    <\/p>",
        "Question_closed_time":1649312364293,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>@MiaZhangWHQWistron-2092 Based on the setup for designer2_step the inputs are the original input of step1 and the output of step1. The second screen shot seems appropriate and the designer has just replicated the original input dataset for step2. The connection that you are referring to is irrelevant because the same dataset is used, and designer only displays it for simplicity.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Reload skipped images in Data Labelling project?",
        "Question_created_time":1642700153863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/703399\/reload-skipped-images-in-data-labelling-project",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi  <br \/>\nI ran a data labeling project on Azure ml which had 20k images. We annotated about 4k images while the rest images were skipped. Is there a way to go back through skipped images again and reload them back into the system?  <br \/>\nI'd greatly appreciate your help in resolving this issue.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML data labeling change polygon color",
        "Question_created_time":1647528569083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/776555\/azure-ml-data-labeling-change-polygon-color",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>We are currently annotating images in a data labeling instance segmentation (polygon) project. Our images are rather blueish, which makes it difficult to use the polygon &quot;draw polygon region&quot; tool, which draws the polygon in blue.  <\/p>\n<p>Is it possible to change the color to, for example, black?  <\/p>\n<p>Thanks and BR,  <br \/>\nMaite<\/p>",
        "Question_closed_time":1647596267230,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=54dc3768-e4dc-41b2-8290-e72ad5c207f3\">@Maite  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I am sorry we are using only blue for the polygon color. I will forward your feedback to product team for future release.     <\/p>\n<p>One workaround may help with your scenario is, you can change the brightness to &quot;-100&quot; when you draw and revert the brightness back when you done as below screenshot. This will help to make things clear.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/184541-image.png?platform=QnA\" alt=\"184541-image.png\" \/>    <\/p>\n<p>Hope this helps and thanks for the feedback again.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Enabling Model Data Collector for ACI through az ml deploy",
        "Question_created_time":1648735779630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/795453\/enabling-model-data-collector-for-aci-through-az-m",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,<\/p>\n<p>I want to create a release pipeline in DevOps that deploys a model to ACI, I have a PowerShell script that deploys using the az ml package. However even though I set the model data collector flag in the deploy command, the endpoint does not collect the inputs. I have tried deploying the same model, using the exact same score.py, but deployed programmatically through azureml.core.webservice and it worked just fine with collection data, so the problem is elsewhere.<\/p>\n<p>I have deployed my model using the following command in a PowerShell script (paraphrasing some of the arguments):<\/p>\n<blockquote>\n<p>az ml model deploy -n $name --model $model -g $resource-group -w $workspace --es $entry_script_path --cf $conda_file_path --dc $deployment_config_path --md True --overwrite -v<\/p>\n<\/blockquote>\n<p>Notice that I have set the --md argument to True, which is the model data collector flag.<\/p>\n<p>And in my score.py, I have imported the ModelDataCollector, initialized it and I call collect. I have something like this:<\/p>\n<blockquote>\n<p>from azureml.monitoring import ModelDataCollector<\/p>\n<p>def init():  <br \/>\nglobal model, scaler, input_name, label_name, inputs_dc, prediction_dc<\/p>\n<pre><code># variables to monitor model input and output data\ninputs_dc = ModelDataCollector(&quot;model&quot;, designation=&quot;inputs&quot;)\n<\/code><\/pre>\n<p>input_sample = pd.DataFrame(sample})  <br \/>\n@input_schema('data',PandasParameterType(input_sample))  <br \/>\n@output_schema(NumpyParameterType(np.array([0])))  <br \/>\ndef run(data):  <br \/>\ntry:  <br \/>\ninputs_dc.collect(data)  <\/p>\n<h1 id=\"model-inference--\">model inference  <\/h1>\n<p>result = model.predict(data)  <br \/>\nreturn {&quot;result&quot;: result.tolist()}  <br \/>\nexcept Exception as e:  <br \/>\nresult = e  <br \/>\nreturn {&quot;result&quot;: result}<\/p>\n<\/blockquote>\n<p>However I deploy my model using the PowerShell script, and everything goes fine. The endpoint is callable, healthy and outputs correct results. But the data does not get saved in the storage account or in application insights (which I have enabled, and can see is enabled on the endpoint as well.<\/p>\n<p>In my deployment config I see the following:<\/p>\n<blockquote>\n<p>Data collection is not enabled. Set environment variable ML_MODEL_DC_STORAGE_ENABLED to 'true' to enable.<\/p>\n<\/blockquote>\n<p>How do I go about that? I have enabled Data collection in my deployment command, why does it not work, and how can I set the environmental variable?  <br \/>\nI tried adding it to my conda_env.yml which is part of the deployment command &quot;--cf $conda_file_path&quot; like so:<\/p>\n<blockquote>\n<p>name: my_env  <br \/>\ndependencies:  <\/p>\n<ul>\n<li> python=3.6.2  <\/li>\n<li> pip:  <\/li>\n<li> numpy  <\/li>\n<li> onnxruntime  <\/li>\n<li> joblib  <\/li>\n<li> azureml-core~=1.10.0  <\/li>\n<li> azureml-defaults~=1.10.0  <\/li>\n<li> scikit-learn==0.22.2.post1  <\/li>\n<li> inference-schema  <\/li>\n<li> inference-schema[numpy-support]  <\/li>\n<li> azureml-monitoring  <br \/>\nchannels:  <\/li>\n<li> anaconda  <\/li>\n<li> conda-forge  <br \/>\nvariables:  <br \/>\nML_MODEL_DC_STORAGE_ENABLED = true<\/li>\n<\/ul>\n<\/blockquote>\n<p>But that just produces another error. How do I solve this problem?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML webservice deployment with custom Environment - \/var\/runit does not exist",
        "Question_created_time":1648579663380,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/792417\/azureml-webservice-deployment-with-custom-environm",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everyone.    <\/p>\n<p>I'm struggling to deploy a model with a custom environment through the azureml SDK.    <\/p>\n<p>I have built a docker image locally and pushed it to azure container registry to use it for environment instantiating. This is how my dockerfile looks like:    <\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04  \nFROM python:3.9.12  \n  \n# Keeps Python from generating .pyc files in the container  \nENV PYTHONDONTWRITEBYTECODE=1  \n  \n# Turns off buffering for easier container logging  \nENV PYTHONUNBUFFERED=1  \n  \n# Install requirement for deploying the service  \nRUN apt-get update  \nRUN apt-get install -y runit  \n  \n# Install pip requirements  \nRUN pip install --upgrade pip  \nCOPY requirements.txt .  \nRUN pip install azureml-defaults  \nRUN pip install -r requirements.txt  \n<\/code><\/pre>\n<p>I want to deploy the webservice locally for testing, so I am following the steps according to official documentation:    <\/p>\n<pre><code>ws = Workspace(subscription_id='***', resource_group='***', workspace_name='***')  \n  \nmodel = Model.register(ws, model_name='***', model_path='.\/Azure_Deployment\/Algorithm')  \n  \ncontainer = ContainerRegistry()  \ncontainer.address = '***'  \nmyenv = Environment.from_docker_image('***', '***\/***-img:v1', container)  \n  \ninference_config = InferenceConfig(environment=myenv, source_directory='.\/Azure_Deployment', entry_script='echo_score.py',)  \n  \ndeployment_config = LocalWebservice.deploy_configuration(port=6789)  \n  \nservice = Model.deploy(ws, &quot;myservice&quot;, [model], inference_config, deployment_config, overwrite=True,)  \nservice.wait_for_deployment(show_output=True)  \n<\/code><\/pre>\n<p>This is what I get from the logs:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/188074-logs-2.png?platform=QnA\" alt=\"188074-logs-2.png\" \/>    <\/p>\n<p>Checking into the resulting container for the service I can see indeed there is no \/runit folder inside \/var. There is also no other folders created for the service besides the azureml-app containing my model's files.    <\/p>\n<p>I would really appreciate any insights to what's going on here as I have no clue at this point.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is scoring done in azure ml?",
        "Question_created_time":1649152330267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/800586\/how-is-scoring-done-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Suppose I have 50 features in my dataset, but after feature engineering(one hot encoding or tf-idf)  I get 200 feature colums. The model is trained on these 200 features and is deployed and now we have a rest endpoint for the model. Now the customer will hit the endpoint with 50 features but the model is expecting 200 columns. Where will the conversion of 50 to 200 features takes place?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"A\/B testing using Azure Container Instance.",
        "Question_created_time":1648100125823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/785262\/a-b-testing-using-azure-container-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have two ML models A and B registered in my workspace and I want to deploy them to Azure Container Instance and perform A\/B testing or continuous rollout or Canary deployment. Can it be done without using AKS and only on ACI.<\/p>",
        "Question_closed_time":1648171136617,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=8d6b3f04-f6f3-4fa5-95d3-dbd939677f31\">@HARISH KUMAR  <\/a>     <\/p>\n<p>Thanks for reaching out to us. I can understand you want to deploy your ML models to ACI to do the A\/B test. For question can models to be deployed only ACI, the answer is yes, but please be aware that ACI has some limitation compared to AKS, please check if ACI is a good choice for your model:    <\/p>\n<p>About models:    <br \/>\nACI is suitable only for small models that are under 1 GB in size.    <br \/>\nWe recommend using single-node AKS to dev-test larger models.    <br \/>\nThe number of models to be deployed is limited to 1,000 models per deployment (per container).    <\/p>\n<p>About Vnet:    <br \/>\nWhen using Azure Container Instances in a virtual network, the virtual network must be in the same resource group as your Azure Machine Learning workspace.    <br \/>\nWhen using Azure Container Instances inside the virtual network, the Azure Container Registry (ACR) for your workspace cannot also be in the virtual network.    <\/p>\n<p>Other points:    <br \/>\nprefer not to manage your own Kubernetes cluster    <br \/>\nAre OK with having only a single replica of your service, which may impact uptime    <br \/>\nYou are advised to debug locally before deploying to the web service,    <\/p>\n<p>AKS Advantages for your reference as well:    <br \/>\nFast response time    <br \/>\nAutoscaling of the deployed service    <br \/>\nLogging    <br \/>\nModel data collection    <br \/>\nAuthentication    <br \/>\nTLS termination    <br \/>\nHardware acceleration options such as GPU and field-programmable gate arrays (FPGA)    <\/p>\n<p>If you feel like ACI fulfill your need, then you can follow below guidance to do the deployment:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#deploy-to-aci\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#deploy-to-aci<\/a>    <\/p>\n<p>Hope this helps, please let me know if you have more questions.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to run conda package manager. AzureML uses conda to provision python",
        "Question_created_time":1648968542177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/798162\/unable-to-run-conda-package-manager-azureml-uses-c",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi I was trying to run the 14. 'Interpret Models' exercise from  <a href=\"https:\/\/aka.ms\/mslearn-dp100\">https:\/\/aka.ms\/mslearn-dp100<\/a> in Azure ML Jupyter notebook, and was met with following error:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/189503-image.png?platform=QnA\" alt=\"189503-image.png\" \/>    <\/p>\n<p>i have installed the relevant packages and was unsure how to resolve it<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azureml: Metadata mismatch for dask dataframe after using filter()",
        "Question_created_time":1647425925947,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/774453\/azureml-metadata-mismatch-for-dask-dataframe-after",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I noticed weird behaviour when filtering an azureml <code>TabularDataset<\/code> instance using <code>filter()<\/code> and converting it to a dask dataframe afterwards. Here is my code to recreate the issue:<\/p>\n<p>Imports:<\/p>\n<pre><code>from azureml.core import Dataset\nfrom azureml.data import TabularDataset\nimport dask.dataframe as ddf\nimport pandas as pd\n<\/code><\/pre>\n<p>Register a dask dataframe to the datastore and load it as a <code>TabularDataset<\/code>:<\/p>\n<pre><code>test_df = pd.DataFrame({&quot;id&quot;: [3,4,5], &quot;price&quot;: [199, 98, 50]})\ntest_dask = ddf.from_pandas(test_df, chunksize=1)\n\nDataset.Tabular.register_dask_dataframe(test_dask, datastore, name='bug_test')\n\ndataset = TabularDataset.get_by_name(workspace, name='bug_test')\n<\/code><\/pre>\n<p>Now printing the loaded dataset after converting it to dask dataframe works (almost) well (almost, since there is weird indexing as the 0 appears two times):<\/p>\n<pre><code>loaded_dask = dataset.to_dask_dataframe()\nprint(loaded_dask.compute())\n\n&gt;&gt; \n\n          id  price  __null_dask_index__\n       0   3    199                   0\n       0   4     98                    1\n       1   5     50                    2\n<\/code><\/pre>\n<p>We now want to filter for rows where <code>id<\/code> equals to 5, which works perfectly when it is filtered after converting it to dask dataframe with <code>loaded_dask[loaded_dask.id == 5].compute()<\/code><\/p>\n<p>Now computing the dask dataframe after filtering with the <code>filter()<\/code> method throws following exception, either no data or no datatype is found (for full error message see below):<\/p>\n<pre><code>filtered_ds = dataset.filter(dataset[&quot;id&quot;] == 5)\nfiltered_ds.to_dask_dataframe().compute()\n\n&gt;&gt; \n\n    ValueError: Metadata mismatch found in `from_delayed`.\n\n    Partition type: `pandas.core.frame.DataFrame`\n    +-----------------------+-------+----------+\n    | Column                | Found | Expected |\n    +-----------------------+-------+----------+\n    | '__null_dask_index__' | -     | int32    |\n    | 'id'                  | -     | int32    |\n    | 'price'               | -     | int32    |\n    +-----------------------+-------+----------+\n<\/code><\/pre>\n<p>Note: When filtering for invalid values, e.g. for <code>dataset[&quot;id&quot;] == 6<\/code> it correctly returns me an empty dataframe<\/p>\n<p>Also a weird behaviour happens when playing around with the <code>dtypes<\/code> parameter in <code>to_dask_dataframe()<\/code>. When specifying types for only one column, datatypes can suddenly be found:<\/p>\n<pre><code>filtered_ds.to_dask_dataframe(dtypes={&quot;id&quot;: &quot;object&quot;}).compute()\n\n&gt;&gt;\n\n    ValueError: Metadata mismatch found in `from_delayed`.\n\n    Partition type: `pandas.core.frame.DataFrame`\n    +-----------------------+-------+----------+\n    | Column                | Found | Expected |\n    +-----------------------+-------+----------+\n    | '__null_dask_index__' | int64 | -        |\n    | 'id'                  | int64 | object   |\n    | 'price'               | int64 | -        |\n    +-----------------------+-------+----------+\n<\/code><\/pre>\n<p>but setting <code>dtypes={&quot;id&quot;: &quot;int64&quot;, &quot;price&quot;: &quot;int64&quot;, &quot;__null_dask_index__&quot;: &quot;int64&quot;}<\/code> leads again to the same ValueError as before that either no data or no datatype is found (full error ouput):<\/p>\n<pre><code>filtered_ds.to_dask_dataframe(dtypes={&quot;id&quot;: &quot;int64&quot;, &quot;price&quot;: &quot;int64&quot;, &quot;__null_dask_index__&quot;: &quot;int64&quot;}).compute()\n\n&gt;&gt;\n\n    Traceback (most recent call last):\n      File &quot;\\bug_analysis.py&quot;, line 117, in &lt;module&gt;\n        filtered_ds.to_dask_dataframe(dtypes={&quot;id&quot;: &quot;int64&quot;, &quot;price&quot;: &quot;int64&quot;, &quot;__null_dask_index__&quot;: &quot;int64&quot;}).compute()\n      File &quot;\\venv\\lib\\site-packages\\dask\\base.py&quot;, line 290, in compute\n        (result,) = compute(self, traverse=False, **kwargs)\n      File &quot;\\envs\\venv\\lib\\site-packages\\dask\\base.py&quot;, line 573, in compute\n        results = schedule(dsk, keys, **kwargs)\n      File &quot;\\venv\\lib\\site-packages\\dask\\threaded.py&quot;, line 81, in get\n        results = get_async(\n      File &quot;\\venv\\lib\\site-packages\\dask\\local.py&quot;, line 506, in get_async\n        raise_exception(exc, tb)\n      File &quot;\\venv\\lib\\site-packages\\dask\\local.py&quot;, line 314, in reraise\n        raise exc\n      File &quot;\\venv\\lib\\site-packages\\dask\\local.py&quot;, line 219, in execute_task\n        result = _execute_task(task, data)\n      File &quot;\\venv\\lib\\site-packages\\dask\\core.py&quot;, line 119, in _execute_task\n        return func(*(_execute_task(a, cache) for a in args))\n      File &quot;\\venv\\lib\\site-packages\\dask\\dataframe\\utils.py&quot;, line 407, in check_meta\n        raise ValueError(\n    ValueError: Metadata mismatch found in `from_delayed`.\n\n    Partition type: `pandas.core.frame.DataFrame`\n    +-----------------------+-------+----------+\n    | Column                | Found | Expected |\n    +-----------------------+-------+----------+\n    | '__null_dask_index__' | -     | int64    |\n    | 'id'                  | -     | int64    |\n    | 'price'               | -     | int64    |\n    +-----------------------+-------+----------+\n<\/code><\/pre>\n<p>The exceptions are raised when the dask dataframes are computed with <code>compute()<\/code>.<\/p>\n<p>I am aware that I used two experimental methods ( <code>TabularDataset.to_dask_dataframe()<\/code> and <code>TabularDataset.filter()<\/code> ), so is this a bug or am I using the methods incorrectly at some point?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploying an ML Model to ACI with a secured workspace in a VNet",
        "Question_created_time":1649065504527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/799037\/deploying-an-ml-model-to-aci-with-a-secured-worksp",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to deploy an ML model to an ACI in a VNet. I have followed the guide to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-create-secure-workspace\">setup a secure workspace<\/a>, and also noted that if deploying to ACI, the container registry must not be in the same vnet.     <br \/>\nI have deployed the container registry:    <\/p>\n<ul>\n<li> outside of the vnet in the same resource group    <\/li>\n<li> Allowed admin user in the CR    <\/li>\n<li> Disabled public access    <\/li>\n<li> Allowed trusted microsoft services    <\/li>\n<li> Created a private endpoint for private access for the worskpace to access (needed this for image builds on my training runs)    <\/li>\n<li> Allowed subnet delegation on the Scoring subnet for the containerGroups service as shown <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=python#enable-azure-container-instances-aci\">here<\/a>    <\/li>\n<\/ul>\n<p>Now when I am trying to deploy the model to a container instance, I get this failure    <\/p>\n<pre><code>   Error:  \n   {  \n     &quot;code&quot;: &quot;InaccessibleImage&quot;,  \n     &quot;statusCode&quot;: 400,  \n     &quot;message&quot;: &quot;ACI Service request failed. Reason: The image '&lt;containerRegName&gt;.azurecr.io\/azureml\/azureml_&lt;imageHash&gt;' in container group '&lt;serviceName&gt;-qcloi6KnEkOQ6CTdniybhQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/learn.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.&quot;  \n   }  \n<\/code><\/pre>\n<p>After speaking to the docs team where the guides address this deployment strategy (<a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/90053#event-6318471048\">here<\/a>), the only response is to use AKS. AKS won't be feasible right now for this project and the documentation seems to suggest that this is possible.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning submit real-time inference error",
        "Question_created_time":1648476067633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/790255\/machine-learning-submit-real-time-inference-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When I submit successfully at design, but submit the 'real time inference' is error, I just copy the action of the sample ,that is ok, but when I re-create a new one, it shows the error message, who can help me ? Thank you very much !<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187586-untitled.png?platform=QnA\" alt=\"187586-untitled.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Authorization: Bearer [token] Error",
        "Question_created_time":1648478793750,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/790341\/authorization-bearer-(token)-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>My Azure ML studio web service used to run fine but is unavailable for me to use now. Anybody know a fix?  <\/p>\n<p>Error Message: Could not authorize the request. Make sure the request has an Authorization header with a bearer token, of the form &quot;Authorization: Bearer [token]&quot;. See online help to find which tokens are valid for this request.  <br \/>\nSite Path: \/workspaces\/fde0912ad97d4a94b9b2baaafd54c3e1\/webservices\/378f095e8260497697790a6d65fe9ff8\/endpoints\/default  <br \/>\nActivity ID: 82e53138-b3b9-4a94-8695-0b8152c505ac  <br \/>\nRequest ID: e3e8fbe7-6161-411b-9c2c-e2a609436353  <br \/>\nWorkspace ID: fde0912ad97d4a94b9b2baaafd54c3e1  <br \/>\nWorkspace Type: Free  <br \/>\nUser Role: Owner  <br \/>\nTenant ID: f8cdef31-a31e-4b4a-93e4-5f571e91255a<\/p>",
        "Question_closed_time":1649047941240,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=4f826b11-7b14-4523-b00c-cbe2449313bf\">@dasa8  <\/a>     <\/p>\n<p>Update: The bug has been confirmed and the ETA is 2-3 weeks for the bug fixing. I am sorry for all the inconveniences.     <\/p>\n<p>The workaround for now is to use studio classic portal to manage the classic web service as below screenshot:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/189568-microsoftteams-image-9.png?platform=QnA\" alt=\"189568-microsoftteams-image-9.png\" \/>    <\/p>\n<p>Thanks for the understanding and sorry for the experience again.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot!<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Export Data Row Number",
        "Question_created_time":1646064764830,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/753636\/export-data-row-number",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>In the Export Data module within AML Designer, it is currently limiting the number of rows per batch to 50. It looks like this used to be a parameter that was adjustable within the interface on the old Studio but now it is not. When we try to update the environment variable it says that the variable is already set and errors out. Are there any other ways to adjust the number of rows per batch and\/or is this parameter going to come back in a future version of the Export Data module?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while creating pipeline between first and second page - first step runs get error when second steps start",
        "Question_created_time":1647462322017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775279\/error-while-creating-pipeline-between-first-and-se",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<h1 id=\"first-step-of-pipeline\">first step of pipeline<\/h1>\n<p>data_prep_step = PythonScriptStep(  <br \/>\nscript_name='data_prep.py',  <br \/>\nsource_directory='.\/src',  <br \/>\narguments=[&quot;--data_path&quot;, dataset.as_mount(), &quot;--out_folder&quot;, output_data],  <br \/>\ncompute_target='cpu-cluster',  <br \/>\nrunconfig=aml_run_config,  <br \/>\nallow_reuse=True  <br \/>\n)<\/p>\n<h1 id=\"second-step-of-pipeline\">second step of pipeline<\/h1>\n<p>train_step = PythonScriptStep(  <br \/>\nscript_name='train.py',  <br \/>\nsource_directory='.\/src',  <br \/>\narguments=[&quot;--output_folder&quot;, output_data.as_input()],  <br \/>\ncompute_target='cpu-cluster',  <br \/>\nrunconfig=aml_run_config,  <br \/>\nallow_reuse=True  <br \/>\n)<\/p>\n<h1 id=\"run\">run<\/h1>\n<p>train_pipeline = Pipeline(workspace = ws, steps = [data_prep_step, train_step])  <br \/>\nexperiment = Experiment(workspace = ws, name = 'training-pipeline' )  <br \/>\npipeline_run = experiment.submit(train_pipeline)<\/p>\n<h1 id=\"code-first-step-completes-i-get-error-when-second-step-starts\">code first step completes, I get error when second step starts<\/h1>\n<h1 id=\"code-for-first-step-below\">code for first step below<\/h1>\n<p>def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):  <br \/>\nfiles = []  <br \/>\nfor filename in os.listdir(SOURCE):  <br \/>\nfile = os.path.join(SOURCE, filename)  <br \/>\nif os.path.getsize(file) &gt; 0:  <br \/>\nfiles.append(filename)  <br \/>\nelse:  <br \/>\nprint(filename + &quot; is zero length, so ignoring.&quot;)<\/p>\n<pre><code>training_length = int(len(files) * SPLIT_SIZE)\ntesting_length = int(len(files) - training_length)\nshuffled_set = random.sample(files, len(files))\ntraining_set = shuffled_set[0:training_length]\ntesting_set = shuffled_set[training_length:]\n\nfor filename in training_set:\n    this_file = os.path.join(SOURCE, filename)\n    destination = os.path.join(TRAINING, filename)\n    copy(this_file, TRAINING)\n\nfor filename in testing_set:\n    this_file = os.path.join(SOURCE, filename)\n    destination = os.path.join(TESTING, filename)\n    copy(this_file, TESTING)\n<\/code><\/pre>\n<p>run = Run.get_context()  <br \/>\nif <strong>name<\/strong> == &quot;<strong>main<\/strong>&quot;:<\/p>\n<pre><code>parser = argparse.ArgumentParser()\nparser.add_argument('--data_path',\n                    type=str,\n                    help='Path to uploaded data')\nparser.add_argument('--out_folder', \n                   type=str\n\n                   )\n#parser.add_argument('--data_path_test', \n#                    type=str,\n#                   help='Path to test dataflow')\n#args = parser.parse_args()\nargs = parser.parse_args()\noutput_folder = args.out_folder\ninputs = args.data_path\n\ntry:\n    os.makedirs(os.path.join(output_folder, '\/train\/defect'), exist_ok=True) #'args.data_path_folder\/train\/defect\/')\n    os.makedirs(os.path.join(output_folder, '\/train\/no-defect'), exist_ok=True) #'args.data_path_folder\/train\/no-defect\/')\n    os.makedirs(os.path.join(output_folder, '\/test\/defect'), exist_ok=True) #'args.data_path_folder\/test\/defect\/')\n    os.makedirs(os.path.join(output_folder, '\/test\/no-defect'), exist_ok=True) #'args.data_path_folder\/test\/no-defect\/')\n    #os.mkdir('\/tmp\/cats-v-dogs\/training\/dogs')\n    #os.mkdir('\/tmp\/cats-v-dogs\/testing\/cats')\n    #os.mkdir('\/tmp\/cats-v-dogs\/testing\/dogs')\nexcept OSError:\n    pass\n\ntrain_datagen = ImageDataGenerator(\nrescale = 1.\/255)\nval_datagen = ImageDataGenerator(\nrescale = 1.\/255)\ntest_datagen = ImageDataGenerator(\nrescale = 1.\/255)\n\nclass_mode = 'binary'\nbatch_size = 5\n\n\nNO_DEFECT_SOURCE_DIR =  os.path.join(inputs, &quot;Good&quot;)\nTRAINING_NO_DEFECT_DIR = os.path.join(output_folder, '\/train\/no-defect') #'output_folder\/train\/no-defect\/'   #os.path.join(args.data_path_train, &quot;no-defect\/&quot;)\nTESTING_NO_DEFECT_DIR =  os.path.join(output_folder, '\/test\/no-defect') #'output_folder\/test\/no-defect\/'    #os.path.join(args.data_path_test, &quot;no-defect\/&quot;)\nDEFECT_SOURCE_DIR = os.path.join(inputs, &quot;Defective&quot;)\nTRAINING_DEFECT_DIR = os.path.join(output_folder, '\/train\/defect') #'output_folder\/train\/defect\/' #os.path.join(args.data_path_train, &quot;defect\/&quot;)\nTESTING_DEFECT_DIR = os.path.join(output_folder, '\/test\/defect') #'output_folder\/test\/defect\/' #os.path.join(args.data_path_test, &quot;defect\/&quot;)\n\nsplit_size = .8\nsplit_data(NO_DEFECT_SOURCE_DIR, TRAINING_NO_DEFECT_DIR, TESTING_NO_DEFECT_DIR, split_size)\nsplit_data(DEFECT_SOURCE_DIR, TRAINING_DEFECT_DIR, TESTING_DEFECT_DIR, split_size)\n<\/code><\/pre>\n<h1 id=\"error-received-below\">error received below<\/h1>\n<p>{'code': data-capability.DatasetMountSession:input_915071c1.ExecutionError, 'message':  <br \/>\nError Code: ScriptExecution.StreamAccess.NotFound  <br \/>\n, 'target': , 'category': UserError, 'error_details': [{'key': NonCompliantReason, 'value':  <br \/>\nError Code: ScriptExecution.StreamAccess.NotFound  <br \/>\nFailed Step: 92a8bfed-63f0-497a-bbcf-b0bfa1be2d9a  <br \/>\nError Message: ScriptExecutionException was caused by StreamAccessException.  <br \/>\nStreamAccessException was caused by NotFoundException.  <br \/>\nFound no resources for the input provided: 'https:\/\/mich7068071609.blob.core.windows.net\/azureml-blobstore-e23f8d3d-4bfa-4d73-8330-db867b66a523\/dataset\/3c085033-67b7-4c25-8e29-1e58a993e90a\/prepped\/'  <br \/>\n| session_id=067cfe37-82a4-46e1-900c-8184e503ebfb}, {'key': StackTrace, 'value': File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/capability_session.py&quot;, line 47, in start  <br \/>\n(data_path, sub_data_path) = session.start()<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py&quot;, line 171, in start  <br \/>\nif self._is_single_file:<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py&quot;, line 119, in _is_single_file  <br \/>\npath = dataflow._to_pyrecords()[0][temp_column]<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 756, in _to_pyrecords  <br \/>\nintermediate_files = _write_preppy_with_fallback('Dataflow.to_pyrecords', self, span_context=to_dprep_span_context(span.get_context()))<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py&quot;, line 190, in _write_preppy_with_fallback  <br \/>\n_execute_with_fallback(activity, dataflow_to_execute, force_clex=force_clex, span_context=span_context)<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py&quot;, line 238, in _execute_with_fallback  <br \/>\nclex_execute()<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py&quot;, line 219, in clex_execute  <br \/>\nspan_context=span_context<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py&quot;, line 38, in wrapper  <br \/>\nreturn send_message_func(op_code, message, cancellation_token)<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 154, in execute_anonymous_activity  <br \/>\nresponse = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 291, in send_message  <br \/>\nraise_engine_error(response['error'])<\/p>\n<p>File &quot;\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py&quot;, line 10, in raise_engine_error  <br \/>\nraise ExecutionError(error_response)  <br \/>\n}, ], 'inner_e<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feeding PipelineData to HyperDriveStep results in: TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'",
        "Question_created_time":1647906103627,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/781351\/feeding-pipelinedata-to-hyperdrivestep-results-in",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When I try to feed PipelineData into HyperDriveStep like here:<\/p>\n<pre><code>        data_datastore = Datastore(ws, datastore_name)\n        dataset = Dataset.File.from_files([data_datastore.path(&quot;&quot;)]).as_named_input('data')\n\n        steps = []\n\n        datastore = ws.get_default_datastore()\n\n        transformed_data = PipelineData(datastore=datastore, name=&quot;transformed_data&quot;)\n        transformation_step = PythonScriptStep(script_name=&quot;demo_transform_data.py&quot;,\n                                        arguments=[&quot;--input&quot;, dataset, &quot;--output&quot;, transformed_data],\n                                        inputs=[dataset],\n                                        outputs=[transformed_data],\n                                        compute_target=cpu_compute,\n                                        runconfig=cpu_run_config)\n        steps.append(transformation_step)\n\n        hp_search_step = HyperDriveStep(\n            name='hp_search_step',\n            hyperdrive_config=HyperDriveConfig(\n                run_config=ScriptRunConfig(\n                    source_directory='.', \n                    script='demo_train.py',\n                    arguments=['--input', transformed_data],\n                    compute_target=cpu_compute,\n                    environment=environment\n                ),\n                hyperparameter_sampling=RandomParameterSampling({\n                    '--learning_rate': choice(1e-1, 1e-2, 1e-3),\n                    '--hidden_size': choice(32, 64),\n                }),\n                primary_metric_name='loss',\n                primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n                max_total_runs=4,\n                max_concurrent_runs=2\n            ),\n            inputs=[transformed_data],\n            outputs=[]\n        )\n        steps.append(hp_search_step)\n\n        exp = Experiment(workspace=ws, name=f'hyperdrive-search')\n        pipeline_run = exp.submit(Pipeline(ws, steps))   **# Line 110 in the exception below**\n<\/code><\/pre>\n<p>...then I getting the following exception:<\/p>\n<pre><code>    Traceback (most recent call last):\n      File &quot;bug_repro.py&quot;, line 110, in &lt;module&gt;\n        pipeline_run = exp.submit(Pipeline(ws, steps))\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/core\/_experiment_method.py&quot;, line 104, in wrapper\n        return init_func(self, *args, **kwargs)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/pipeline.py&quot;, line 180, in __init__\n        self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1497, in build\n        graph = self.construct(name, steps)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1519, in construct\n        self.process_collection(steps)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1555, in process_collection\n        builder.process_collection(collection)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1846, in process_collection\n        self._base_builder.process_collection(item)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1549, in process_collection\n        return self.process_step(collection)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1593, in process_step\n        node = step.create_node(self._graph, self._default_datastore, self._context)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 271, in create_node\n        context._experiment_name)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 347, in _get_hyperdrive_config\n        experiment_name, telemetry_values)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 38, in _create_experiment_dto\n        platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 664, in _get_platform_config\n        platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 678, in _get_platform_config_data_from_run_config\n        run_config = get_run_config_from_script_run(self.run_config)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/core\/script_run_config.py&quot;, line 85, in get_run_config_from_script_run\n        run_config.arguments = deepcopy(script_run_config.arguments)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 150, in deepcopy\n        y = copier(x, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 215, in _deepcopy_list\n        append(deepcopy(a, memo))\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 180, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 280, in _reconstruct\n        state = deepcopy(state, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 150, in deepcopy\n        y = copier(x, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 240, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 180, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 280, in _reconstruct\n        state = deepcopy(state, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 150, in deepcopy\n        y = copier(x, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 240, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 180, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py&quot;, line 274, in _reconstruct\n        y = func(*args)\n      File &quot;\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copyreg.py&quot;, line 88, in __newobj__\n        return cls.__new__(cls, *args)\n    TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n<\/code><\/pre>\n<p>When I replace &quot;PipelineData&quot; with:<\/p>\n<pre><code>OutputFileDatasetConfig().register_on_complete(name=&quot;xxx&quot;)\n<\/code><\/pre>\n<p>...then it works, but:<\/p>\n<ul>\n<li>   I don't like that I need to register the dataset externally even though it's used only within the pipeline.<\/li>\n<li>   It seems to mess up step reusing - i.e., even though some steps in the pipeline may have &quot;allow_reuse=True&quot;, if they are dependent on the data via OutputFileDatasetConfig().register_on_complete, they will need to be re-computed on every run of the pipeline.<\/li>\n<\/ul>\n<p>My questions:  <\/p>\n<ol>\n<li> Is there a way to feed PipelineData into HyperDriveStep correctly?  <\/li>\n<li> Are there any other ways recommended to feed intermediate data to HyperDriveStep, but also allow reuse for any steps dependent on that intermediate data?  <\/li>\n<li> If it's by design that PipelineData is not allowed in HyperDriveStep, could the AzureML team please make the error message less cryptic?<\/li>\n<\/ol>\n<p>I'd appreciate your help!  <br \/>\nThanks,  <br \/>\nSebastian<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Testing Data Problem",
        "Question_created_time":1647528251100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/776565\/testing-data-problem",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Any ideas what this could be? Trying to upload a test data to test the model. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/184242-image.png?platform=QnA\" alt=\"184242-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Synapse Analytics Auto ML Predict No module named 'azureml.automl'",
        "Question_created_time":1648542317563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/791601\/synapse-analytics-auto-ml-predict-no-module-named",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>ref: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788637\/azure-synapse-ml-predict-errno-20-not-a-directory.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788637\/azure-synapse-ml-predict-errno-20-not-a-directory.html<\/a>    <\/p>\n<p>I get the following error with Apache Spark version 3.1 : ModuleNotFoundError: No module named 'azureml.automl'    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187798-image.png?platform=QnA\" alt=\"187798-image.png\" \/>    <\/p>\n<p>with version 2.4     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187872-image.png?platform=QnA\" alt=\"187872-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Comment s\u00e9lectionner Standard_DS11_v2",
        "Question_created_time":1638368598000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/647767\/comment-s-lectionner-standard-ds11-v2",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Bonjour    <br \/>\nJe suis le cours en ligne concernant l'impl\u00e9mentation d'algorithmes de machine learning    <br \/>\nA l'\u00e9tape Create compute resources    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute<\/a>    <\/p>\n<p>On me demande Search for and select Standard_DS11_v2    <\/p>\n<p>Hors, l'interface me dit que je n'ai pas les quotas disponibles.    <br \/>\nJ'utilise l'offre d'essai \u00e0 200 USD.    <br \/>\nComment faire pour que cela fonctionne ?    <br \/>\nCordialement    <br \/>\nThibaut<\/p>",
        "Question_closed_time":1638432598510,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=e0b4def2-2525-4e3c-954a-129251c1bdb4\">@Thibaut Jacquin  <\/a> For a free account only 200$ credit is available and not all compute can be created or selected because of this limitation. You can choose a lower priced VM and proceed with the creation of compute or upgrade to a pay-as-you-go account for your subscription and select the required compute type. I hope this helps.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error running Experiment script (Azure Notebook - Python SDK)",
        "Question_created_time":1648360151510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788720\/error-running-experiment-script-(azure-notebook-py",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am running the Azure ML Python example from here, <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py#run\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py#run<\/a>    <\/p>\n<p>Specifically this section of the example;    <\/p>\n<pre><code>from azureml.core.experiment import Experiment  \nfrom azureml.core import ScriptRunConfig  \n  \nscript_run_config = ScriptRunConfig(source_directory=os.getcwd(), script=&quot;train.ipynb&quot;, run_config=compute_config)  \nexperiment = Experiment(workspace=ws, name=&quot;compute_target_test&quot;)  \nrun = experiment.submit(config=script_run_config)  \nrun.wait_for_completion(show_output=True)  \n<\/code><\/pre>\n<p>When I execute the above code I receive the error;    <br \/>\nmessage': &quot;User program failed with NameError: name 'true' is not defined&quot;    <\/p>\n<p>The log file gives the following details;    <\/p>\n<p> File &quot;train.ipynb&quot;, line 67, in &lt;module&gt;    <br \/>\n    &quot;notebookHasBeenCompleted&quot;: true  <br \/>\nNameError: name 'true' is not defined    <\/p>\n<p>The problem is the train.ipynb file does not contain 67 lines.    <\/p>\n<p>Could anyone provide some assistance as to how to resolve this.    <\/p>\n<p>Thanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine  learning AutoML Fail",
        "Question_created_time":1648706020587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/794697\/azure-machine-learning-automl-fail",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi ,    <\/p>\n<p>I use the fakenews data to try azure machine learning automl , but always train model fail and I tried reducing the feature field  , but still fail    <\/p>\n<p>Error message :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/188507-image.png?platform=QnA\" alt=\"188507-image.png\" \/>    <\/p>\n<p>Run timed out. No model completed training in the specified time. Possible solutions:     <\/p>\n<ol>\n<li> Please check if there are enough compute resources to run the experiment.     <\/li>\n<li> Increase experiment timeout when creating a run.     <\/li>\n<li> Subsample your dataset to decrease featurization\/training time out    <\/li>\n<\/ol>\n<p>compute machine : STANDARD_DS12_V2    <\/p>\n<p>data source  : <a href=\"https:\/\/www.kaggle.com\/c\/fake-news\/data\">https:\/\/www.kaggle.com\/c\/fake-news\/data<\/a>    <\/p>\n<p>Is any good idea or suggestions ?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"change location of Azure ML workspace?",
        "Question_created_time":1643794457387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/719406\/change-location-of-azure-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi , i would like to know if it is possible to change the location of AzureML workspace after creating it ?  <br \/>\nRight now i do not find any option to change it manually on the UI. We want to move the server location to a different country.  <br \/>\nAny leads would be helpful. Thanks<\/p>",
        "Question_closed_time":1643796022067,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Based on the below document, ML workspace can't be moved across region. Probably, you will have to create a new resource in target region and move artifacts \/ pipelines \/ child resources to it (not so familiar with ML)     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/move-support-resources#microsoftmachinelearning\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/move-support-resources#microsoftmachinelearning<\/a>    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations<\/a>    <\/p>\n<p>----------    <\/p>\n<p>Please don't forget to <strong>Accept Answer<\/strong> and <strong>Up-vote<\/strong> if the response helped -- Vaibhav<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Submitting a job to Azure ML from Synapse workspace",
        "Question_created_time":1648588740927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/792681\/submitting-a-job-to-azure-ml-from-synapse-workspac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Assume a data scientist who is coding inside a Synapse notebook, aims to submit his AutoML job to Azure ML. Also assume that we already created the Azure ML workspace, and linked it to Synapse, and also gave Synapse workspace the contributor access to Azure ML workspace. Also the data scientist has the Azure reader role at the synapse workspace level. Data scientist run the following code according to this link (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial<\/a>)    <\/p>\n<p>from azureml.core import Workspace    <\/p>\n<p>subscription_id = &quot;xxxxxx&quot; #you should be owner or contributor    <br \/>\nresource_group = &quot;xxxxx&quot; #you should be owner or contributor    <br \/>\nworkspace_name = &quot;xxxxx&quot; #your workspace name    <br \/>\nworkspace_region = &quot;xxxxx&quot; #your region    <\/p>\n<p>ws = Workspace(workspace_name = workspace_name,    <br \/>\n               subscription_id = subscription_id,  <br \/>\n               resource_group = resource_group)  <\/p>\n<p>However, he receives an error that says he does not have the required contributor\/owner roles at the subscription and resource group level. But we (as the synapse administrators) we don't want to give him the contributor\/owner role at the subscription and resource group name    <\/p>\n<p>Question: How the data scientist can submit his job without letting him to have the required contributor\/owner role. Can he use the managed identity of the Synapse workspace to connect to the Azure ML workspace?    <\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":1648620290573,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <em>anonymous user<\/em>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>Make sure your <code>Service principal<\/code> or <code>Managed Service Identity (MSI)<\/code> must have &quot;<strong>Contributor<\/strong>&quot; access to the AML workspace.    <\/p>\n<\/blockquote>\n<p> If the model is registered in Azure Machine Learning, then you can choose either of the following two supported ways of authentication.    <\/p>\n<ul>\n<li> <strong>Through service principal:<\/strong> You can use service principal client ID and secret directly to authenticate to AML workspace. Service principal must have &quot;Contributor&quot; access to the AML workspace.    <\/li>\n<li> <strong>Through linked service:<\/strong> You can use linked service to authenticate to AML workspace. Linked service can use &quot;service principal&quot; or Synapse workspace's &quot;Managed Service Identity (MSI)&quot; for authentication. &quot;Service principal&quot; or &quot;Managed Service Identity (MSI)&quot; must have &quot;Contributor&quot; access to the AML workspace.    <\/li>\n<\/ul>\n<p>Here is the complete walkthrough of authenticating AML workspace with Azure Synapse Analytics:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/188130-synapse-aml-predict.gif?platform=QnA\" alt=\"188130-synapse-aml-predict.gif\" \/>      <\/p>\n<p>For more details, refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pools<\/a>.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"feature in new generation of classic studio",
        "Question_created_time":1648513803980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/791041\/feature-in-new-generation-of-classic-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>hi:  <\/p>\n<p>I have a question regarding to the new generation as I have already known that the classic old version of machine learning studio is retiring in August 2024.  <\/p>\n<p>I wonder if all the features will be continouslty supported in the new generation of new version of studio in the future?  <\/p>",
        "Question_closed_time":1648525475910,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=3f0f48d2-f878-404d-bae7-0861ffefc027\">@dontbelazy  <\/a>     <\/p>\n<p>Thanks for reaching out to us here, I just answered your question under your previous thread. Not every feature in Studio (classic) will be back as the same, but most of the previous features\/ functions will be covered in the Azure Machine Learning Studio (V2).    <\/p>\n<p>Please go ahead to do the migration first, if you face any issue or you feel like some of the features missing, please let us know, we can help.    <\/p>\n<p>Generally, the new studio will provide a better experience.    <\/p>\n<p>Hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks.<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Data Labeling images removed from dataset still being display when \"data label\"",
        "Question_created_time":1648547078293,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/791637\/azure-ml-data-labeling-images-removed-from-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I created a labeling project by creating a new dataset that imports files from local. Afterwards, some images previously uploaded need to be replaced by a new images (we decided to change some details of the display).   <\/p>\n<p>However, when creating a new version of the dataset with the updated images (this works well) and refreshing the project, the images display when &quot;label data&quot; remain unchanged (also the on-demand incremental refresh date doesnt change, I assume because the images have the same name so project doesnt recognize something has changed.)  <\/p>\n<p>I tried deleting images from the dataset thinking about reloading them, but the project also doesnt stop showing deleted images.  <\/p>\n<p>Is there a way I can get my new image versions correctly displayed without having to create a new project?  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureMLCompute job failed",
        "Question_created_time":1647081369547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769672\/azuremlcompute-job-failed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have created a simple pipeline in Azure ML studio.  <br \/>\nThe pipeline contains only one module &quot;Import Data&quot; which is set up as follows:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182456-image.png?platform=QnA\" alt=\"![182463-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182456-image.png?platform=QnA\">2<\/a><\/p>\n<p>This is a very small dataset that can be found here: <a href=\"https:\/\/archive.ics.uci.edu\/ml\/datasets\/adult\">https:\/\/archive.ics.uci.edu\/ml\/datasets\/adult<\/a><\/p>\n<p>The validation passed and I can see the sample data.<\/p>\n<p>I have tried to run this pipeline twice and both runs:  <\/p>\n<ol>\n<li> Took very long time - over 30 minutes  <\/li>\n<li> Failed with the message &quot;AzureMLCompute job failed. InternalError: Server encountered an internal error. Please try again after some time&quot;<\/li>\n<\/ol>\n<p>When I look at the error logs of the module I see the following:<\/p>\n<blockquote>\n<p>Job failed, job RunId is cff2da53-1726-4092-9887-c7cb3c57dd81. Error: {&quot;Error&quot;:{&quot;Code&quot;:&quot;ServiceError&quot;,&quot;Severity&quot;:null,&quot;Message&quot;:&quot;AzureMLCompute job failed.\\nInternalError: Server encountered an internal error. Please try again after some time&quot;,&quot;MessageFormat&quot;:null,&quot;MessageParameters&quot;:null,&quot;ReferenceCode&quot;:null,&quot;DetailsUri&quot;:null,&quot;Target&quot;:null,&quot;Details&quot;:[],&quot;InnerError&quot;:null,&quot;DebugInfo&quot;:null,&quot;AdditionalInfo&quot;:null},&quot;Correlation&quot;:{&quot;operation&quot;:&quot;be4e18a418e8ad6b924b509d8a353404&quot;,&quot;request&quot;:&quot;124bf413bb074f22&quot;},&quot;Environment&quot;:&quot;eastus&quot;,&quot;Location&quot;:&quot;eastus&quot;,&quot;Time&quot;:&quot;2022-03-12T10:25:01.2364098+00:00&quot;,&quot;ComponentName&quot;:&quot;globaljobdispatcher&quot;}<\/p>\n<\/blockquote>\n<p>I am using the following compute:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182415-image.png?platform=QnA\" alt=\"182415-image.png\" \/><\/p>\n<p>Even though this is marked as an internal server error, since I tried more than once - I think something is wrong with one of my settings.<\/p>\n<p>Would appreciate help with this.<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Synapse ML predict [Errno 20] Not a directory",
        "Question_created_time":1648335577807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788637\/azure-synapse-ml-predict-(errno-20)-not-a-director",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I follow the official tutotial from microsoft: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a>    <\/p>\n<p>But when I execute:    <\/p>\n<pre><code>#Bind model within Spark session  \nmodel = pcontext.bind_model(  \n    return_types=RETURN_TYPES,   \n    runtime=RUNTIME,   \n    model_alias=&quot;Sales&quot;, #This alias will be used in PREDICT call to refer  this   model  \n    model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI  \n    aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed  \n).register()  \n<\/code><\/pre>\n<p>I\u00b4ve got:    <\/p>\n<p><code>NotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'<\/code>    <br \/>\n<code>Traceback (most recent call last):<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_context.py&quot;, line 47, in bind_model<\/code>    <br \/>\n<code>udf = _create_udf(<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_udf.py&quot;, line 104, in _create_udf<\/code>    <br \/>\n<code>model_runtime = runtime_gen._create_runtime()<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 103, in _create_runtime<\/code>    <br \/>\n<code>if self._check_model_runtime_compatibility(model_runtime):<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 166, in _check_model_runtime_compatibility<\/code>    <br \/>\n<code>model_wrapper = self._load()<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 78, in _load<\/code>    <br \/>\n<code>return SynapsePredictModelCache._get_or_load(<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_cache.py&quot;, line 172, in _get_or_load<\/code>    <br \/>\n<code>model = load_model(runtime, model_uri, functions)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 257, in load_model<\/code>    <br \/>\n<code>model = loader.load(model_uri, functions)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 122, in load<\/code>    <br \/>\n<code>model = self._load(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 215, in _load<\/code>    <br \/>\n<code>return self._load_mlflow(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 59, in _load_mlflow<\/code>    <br \/>\n<code>model = mlflow.pyfunc.load_model(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/<\/code><strong><code>init<\/code><\/strong><code>.py&quot;, line 640, in load_model<\/code>    <br \/>\n<code>model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py&quot;, line 124, in load<\/code>    <br \/>\n<code>with open(path) as f:<\/code>    <\/p>\n<p><code>NotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'<\/code>    <\/p>\n<p>How can I fix that error ?<\/p>",
        "Question_closed_time":1648466772193,
        "Answer_score_count":1.0,
        "Answer_comment_count":7.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6fb8f1e1-5543-4ff8-8a13-ff62f23e652f\">@Thilo Barth  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.     <\/p>\n<blockquote>\n<p>(UPDATE:29\/3\/2022): You will experiencing this error message if you model does not contains all the required files in the ML model.    <\/p>\n<\/blockquote>\n<p>As per the repro, I had created two ML models named:     <\/p>\n<blockquote>\n<p><strong>sklearn_regression_model:<\/strong> Which contains only <code>sklearn_regression_model.pkl<\/code> file.    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187737-image.png?platform=QnA\" alt=\"187737-image.png\" \/>    <\/p>\n<blockquote>\n<p>When I predict for MLFLOW packaged model named <code>sklearn_regression_model<\/code>, getting same error as shown above:    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187791-image.png?platform=QnA\" alt=\"187791-image.png\" \/>    <\/p>\n<blockquote>\n<p><strong>linear_regression<\/strong>: Which contains the below files:    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187724-image.png?platform=QnA\" alt=\"187724-image.png\" \/>    <\/p>\n<blockquote>\n<p>When I predict for MLFLOW packaged model named <code>linear_regression<\/code>, it works as excepted.    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187704-image.png?platform=QnA\" alt=\"187704-image.png\" \/>    <\/p>\n<hr \/>\n<blockquote>\n<p> It should be AML_MODEL_URI = &quot;&lt;aml model uri&gt;&quot; #In URI &quot;:x&quot;  =&gt; <code>Rossman_Sales:2<\/code>    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187488-image.png?platform=QnA\" alt=\"187488-image.png\" \/>    <\/p>\n<blockquote>\n<p>Before running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.    <\/p>\n<\/blockquote>\n<pre><code>#Set model URI  \n       #Set AML URI, if trained model is registered in AML  \n          AML_MODEL_URI = &quot;&lt;aml model uri&gt;&quot; #In URI &quot;:x&quot; signifies model version in AML. You can   choose which model version you want to run. If &quot;:x&quot; is not provided then by default   latest version will be picked.  \n  \n       #Set ADLS URI, if trained model is uploaded in ADLS  \n          ADLS_MODEL_URI = &quot;abfss:\/\/&lt;filesystemname&gt;@&lt;account name&gt;.dfs.core.windows.net\/&lt;model   mlflow folder path&gt;&quot;  \n<\/code><\/pre>\n<p><strong>Model URI from AML Workspace:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;aml:\/\/mlflow_sklearn:1&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p><strong>Model URI uploaded to ADLS Gen2:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Key for ML Endpoint",
        "Question_created_time":1648186512237,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/787004\/key-for-ml-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am new to Azure.  <br \/>\nI have created ML endpoint and when I try to access, I see a message &quot;Unauthorized, no token matched&quot;.  <br \/>\nI know its Key based Auth.  <br \/>\nwhere can I find this key? can someone help me?  <\/p>\n<p>regards,  <\/p>\n<p>Rohan<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning Studio",
        "Question_created_time":1648415916797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/789066\/machine-learning-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi:  <\/p>\n<p>I wonder when will the classic Machine Learning Studio retire?  <\/p>\n<p>Also in order to save my data and file, any preparation or migration should be done to avoid any loss?  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1648423257900,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=3f0f48d2-f878-404d-bae7-0861ffefc027\">@dontbelazy  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I think you are mentioning Azure Machine Learning Studio(classic). Machine Learning Studio (classic) will retire on 31 August 2024.     <\/p>\n<p>From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic). Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources.    <\/p>\n<p>Required action to avoid loss:     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">Follow these steps<\/a> to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/#:%7E:text=Consumed%20Azure%20resources%20%28e.g.%20compute%2C%20storage%29%20%28No%20Azure,%24-%20%2B%20per%20vCPU%20hour%20Edition%3A%20Basic%20Enterprise\">pricing<\/a> here.    <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks!<\/em>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error Visualizing Azure Machine Learning Reain Model",
        "Question_created_time":1647259942970,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771183\/error-visualizing-azure-machine-learning-reain-mod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I imported my own data to Azure Machine Learning Model.   <\/p>\n<p>When trying to visualize my trained model, to view which variables affect more and how the two class boosted decision tree has been constructed I get the following error  <\/p>\n<p><em><strong>Error getting visualization data. {&quot;Error&quot;:{&quot;Code&quot;:&quot;UserError&quot;,&quot;Message&quot;:&quot;Metadata for item visualization does not exist&quot;,&quot;Target&quot;:null,&quot;Details&quot;:[],&quot;InnerError&quot;:null,&quot;DebugInfo&quot;:null}}<\/strong><\/em>  <\/p>\n<p>Does anyone know how to solve it?   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"500 Internal Server Error Azure ml studio (classic)",
        "Question_created_time":1648325290653,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788677\/500-internal-server-error-azure-ml-studio-(classic",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187193-image.png?platform=QnA\" alt=\"187193-image.png\" \/>    <\/p>\n<p>I've some problem i try to run my application on my apache2 web server everything good but when my app send api to azure ml studio it's show status code : &quot;500 Internal Server Error &quot;.    <br \/>\nSo i open my local(dev) app and send api again result is good    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187158-image.png?platform=QnA\" alt=\"187158-image.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187159-image.png?platform=QnA\" alt=\"187159-image.png\" \/>    <br \/>\nthen I want to know what is happening now or I do something wrong?    <\/p>\n<p>this is my proxypass    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187195-image.png?platform=QnA\" alt=\"187195-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use the value of a PipelineParameter (passed from DataFactory) in a blob path for an OutputFileDatasetConfig object (in an ML pipeline)",
        "Question_created_time":1648036709603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/784006\/use-the-value-of-a-pipelineparameter-(passed-from",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>Is it possible to use a PipelineParameter (defined in a DataFactory 'Machine Learning Execute Pipeline' activity) during the creation of a OutputFileDatasetConfig object in said Machine Learning pipeline?    <\/p>\n<p>My DataFactory pipeline runs on a schedule (via a trigger) and executes an Azure ML pipeline which does data preparation and model training.    <br \/>\nThe trigger start date is passed as a parameter 'date_time' to the ML pipeline.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/185886-datafactory.jpg?platform=QnA\" alt=\"185886-datafactory.jpg\" \/>    <\/p>\n<p>In my ML pipeline, I want to save the model artifacts (trained in a PythonScriptStep) to a blob path (default_datastore + 'output_model\/{date_time}') which contains the value of the 'date_time' parameter. But I can't figure out a way to use the value of 'date_time' during the creation of the OutputFileDatasetConfig object (maybe there is a simple way to save model artifacts than to use a OutputFileDatasetConfig object?).    <\/p>\n<p>As a temporary hack, I am using a variable 'today_date' in my ML pipeline definition which contains today's date, and I use this variable to build the destination path of OutputFileDatasetConfig.    <br \/>\nBut the ideal solution would be to get the actual date directly from the DataFactory trigger parameter.    <br \/>\nThis is how I do now in my ML pipeline (not ideal):    <\/p>\n<pre><code>import datetime  \ntoday_date = datetime.date.today().strftime('%Y%m%d')  \nmodel_output_path = (def_data_store, f&quot;output_model\/{today_date}&quot;)  \noutput_config = OutputFileDatasetConfig(destination = model_output_path)  \n<\/code><\/pre>\n<p>This is what I tried in order to get the value of PipelineParameter, but it didn't work:    <\/p>\n<pre><code>pipeline_parameter = PipelineParameter(name=&quot;date_time&quot;, default_value=today_date)  \nmodel_output_path = (def_data_store, f&quot;output_model\/{pipeline_parameter}&quot;)  \noutput_config = OutputFileDatasetConfig(destination = model_output_path)  \n<\/code><\/pre>\n<p>It seems the only way to get the value of the PipelineParameter is through an argument inside a PythonScriptStep.    <br \/>\nI don't think I can create the OutputFileDatasetConfig object INSIDE the PythonScriptStep.    <br \/>\nIs there any other way to easily save model artifacts to a specific blob path which contains the value of a PipelineParameter?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Result with coordinator convertion",
        "Question_created_time":1648416629250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/789141\/result-with-coordinator-convertion",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I wonder how could I convert the result of boundingbox of form recognizer into image coordinate to visualize the overlay image and recognized data.  <\/p>\n<p>I could not have that accomplished because it is not similar to normal coordinates.<\/p>",
        "Question_closed_time":1648418537720,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=675b496d-8c11-4d56-a399-76cce4799d41\">@masterhunter  <\/a>    <\/p>\n<p>Thank you for reaching out to us, I think you have questions about the value of boundingBoxes, below I will give an example to explain it so that you can convert it to the coordinate you want to use:    <\/p>\n<p>Example:    <\/p>\n<pre><code>   'boundingBox': [  \n                57.1,  \n                683.3,  \n                100.2,  \n                683.3,  \n                100.2,  \n                673.3,  \n                57.1,  \n                673.3  \n              ]  \n<\/code><\/pre>\n<p>Those values represent the vertices of the bounding box as below:    <\/p>\n<pre><code>  (57.1,683.3) X1,Y1----&gt;x2,y2(100.2,683.3)  \n                  |                |  \n                  |                |  \n  (57.1,673.3) X4,Y4&lt;----x3,y3(100.2,673.3)  \n<\/code><\/pre>\n<p>The (0,0) is on the bottom left as you can see.    <\/p>\n<pre><code>\/\/ Azure Bounding box is like this                       \n\/\/                                                     0----&gt;1  \n\/\/                                                    |     |  \n\/\/                                         Y          |     |  \n\/\/                                         \u2191         3&lt;----2  \n\/\/                                  Origin . \u2192 X  \n<\/code><\/pre>\n<p>If you want to measure the boundingBoxes, you can use above vertices to do the calculation.    <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><strong>-Please kindly accept the answer if you feel helpful, thanks!<\/strong>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Get the list of input data in real time azure ml webservice",
        "Question_created_time":1647338919760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/772716\/get-the-list-of-input-data-in-real-time-azure-ml-w",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I am new to azure ml and I have a question about Real-time inference .   <br \/>\nafter deploying the service on ACI how can I get the list of input data that I should enter to make a prediction using python code from the parameters of the webservice ( endpoint , api key , webservice name , workspace,..)   <\/p>\n<p>thank you <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio is bugged out and can not create a Microsoft ticket under MSDN. Need a few suggestions",
        "Question_created_time":1647349970220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/772790\/azure-ml-studio-is-bugged-out-and-can-not-create-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>ML studio is, by default picking up Python 3.6 kernel, even when I'm specifying use Python 3.8 AzureML kernel. In UI, it's changed but not actually.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/183312-image.png?platform=QnA\" alt=\"183312-image.png\" \/>    <\/p>",
        "Question_closed_time":1647451118727,
        "Answer_score_count":0.0,
        "Answer_comment_count":6.0,
        "Answer_body":"<p>Hi, thanks for reaching out.  It looks like the command you ran isn't supported. A better command to test kernel changes is shown below:  <\/p>\n<pre><code>from platform import python_version\nprint(python_version())\n<\/code><\/pre>\n<p>Hope this helps!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure function in Python 3.8 invoking Azure ML",
        "Question_created_time":1648172045810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/786745\/azure-function-in-python-3-8-invoking-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am working on an Azure Function which is written in Python 3.8. Azure function in Azure in Python is deployed in Linux. The Azure function is invoking Azure ML pipeline. When invoking the pipeline I am seeing the following exception:  <\/p>\n<p>Exception: NotImplementedError: Linux distribution debian 11. does not have automatic support. .NET Core 2.1 can still be used via dotnetcore2 if the required dependencies are installed. Visit <a href=\"https:\/\/aka.ms\/dotnet-install-linux\">https:\/\/aka.ms\/dotnet-install-linux<\/a> for Linux distro specific .NET Core install instructions. Follow your distro specific instructions to install dotnet-runtime-* and replace * with 2.1  <\/p>\n<p>I have tried installing dotnetcore2 runtime via requirements.txt file but still getting the error. Any help is appreciated.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"FileNotFoundError: [Errno 2]  - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_created_time":1639738776307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/667458\/filenotfounderror-(errno-2)-score-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I am following the steps on this tutorial:    <br \/>\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">tutorial-score-model-predict-spark-pool<\/a>    <br \/>\nand <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/656548\/what-is-aml-model-uri-predict-in-serverless-apache-1.html?childToView=666142#comment-666142\">what-is-aml-model-uri-predict-in-serverless-apache-1.html<\/a>    <br \/>\nI tried to used a model created with AutoML and another from designer and I am getting this error: <em>FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmp5xd2_hyr\/MLmodel'<\/em>    <\/p>\n<p>I added the DATA_FILE:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158543-1-image.png?platform=QnA\" alt=\"158543-1-image.png\" \/>     <br \/>\nI am getting this error (I am using Synapse):    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158505-2-image.png?platform=QnA\" alt=\"158505-2-image.png\" \/>    <\/p>\n<p>Kind regards,    <br \/>\nAnaid    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"PermissionDeniedError when trying to save a Tensorflow model checkpoint",
        "Question_created_time":1643818966130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/720040\/permissiondeniederror-when-trying-to-save-a-tensor",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":12,
        "Question_body":"<p>Hi,   <\/p>\n<p>We are using the <strong>Azure Machine Learning Studio<\/strong> to run pipelines in which computer vision models are trained using <strong>Tensorflow<\/strong> (v2.4.0).  <br \/>\nOur input data (images &amp; annotations) are stored on our <strong>Azure Blob Storage<\/strong> account.  <br \/>\nThe saved models are also saved to the same Azure Blob Storage account  <\/p>\n<p>We have several different pipelines (for different projects) that all worked perfectly fine for the last months... up until last week.  <br \/>\nEvery pipeline (that worked before) results in the exact same error now.  <br \/>\nEverything (image loading, preprocessing, augmentations, ...) works fine.  <br \/>\nThe training step starts and the first epoch is trained.  <br \/>\nHowever after the first epoch is done training, the error occurs.  <\/p>\n<p><code>tensorflow\/core\/framework\/op_kernel.cc:1763] OP_REQUIRES failed at save_restore_v2_ops.cc:157 : Permission denied: \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model\/variables\/variables_temp\/part-00000-of-00001.data-00000-of-00001.tempstate5255274353572806690; Read-only file system<\/code>  <br \/>\n...  <br \/>\n<code>Epoch 00001: val_loss improved from inf to 0.10273, saving model to \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model   Cleaning up all outstanding Run operations, waiting 300.0 seconds   2 items cleaning up...   Cleanup took 0.19626808166503906 seconds<\/code>  <br \/>\n...  <br \/>\n<code>tensorflow.python.framework.errors_impl.PermissionDeniedError: \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model\/variables\/variables_temp\/part-00000-of-00001.data-00000-of-00001.tempstate5255274353572806690; Read-only file system [Op:SaveV2]<\/code>  <\/p>\n<p>We get a <strong>PermissionDeniedError<\/strong> while trying to save a temporary file, apparently because it's a <strong>read-only file system<\/strong>.  <br \/>\nIf we take a look at this temporary file in the Azure storage account there is nothing that points out it would be read-only.  <br \/>\nThere's also no difference in settings between this file and other files that we were able to read\/write.  <\/p>\n<p>I have already been able to find what direction to search in.  <br \/>\nIn the training pipeline step we have always been using <strong>Model Checkpoint<\/strong> (if the validation is better than the current saved checkpoint, the model checkpoint is saved).  <br \/>\nBy deleting the Model Checkpoint callback, the error does not occur.  <br \/>\nThis is not a solution of course, as we do need these model checkpoints.  <br \/>\nIt does show however that it has something to do with these model checkpoints.  <\/p>\n<p>I am not sure what else I can try to solve this issue.  <\/p>\n<p>Kind regards  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Recommended way to get to know the location of various folders within a Docker image",
        "Question_created_time":1646753339290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/763779\/recommended-way-to-get-to-know-the-location-of-var",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am creating a pipeline in Azure Machine Learning Studio. The pipeline consists of various steps of the type &quot;PythonScriptStep&quot;. In each step I need to read from the input data and write data to the defined output folder of the type &quot;PipelineData&quot;.  <\/p>\n<p>Until yesterday, I used the environment variables of the build docker image to get to know various locations, e.g. the location of the &quot;wd&quot;-directoy.  <br \/>\nThe directory folder path of the &quot;wd&quot;-directoy was stored in the environment variable 'AZ_BATCHAI_JOB_TEMP'. Now, as it seems to me, the environment variable name has been changed.  The directory folder path of the &quot;wd&quot;-directoy can now be found in the environment variable 'AZUREML_CR_DATA_CAPABILITY_PATH'.   <\/p>\n<p>The environment variable 'AZ_BATCHAI_JOB_MOUNT_ROOT' has been removed completely.  <\/p>\n<p>Since environment variable names are changing from one day to another and are not constant, I would like to ask for the recommended way to get to know the location of various folders within the Docker image.  <\/p>\n<p>With best regards  <br \/>\nAlexander Pakakis<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In multi step pipeline execution, how to maintain the data type of the columns when pass the dataset to next step",
        "Question_created_time":1645805304397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/751127\/in-multi-step-pipeline-execution-how-to-maintain-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>i am building a pipeline with multiple steps.<\/p>\n<ol>\n<li>  Step 1 - Read the data from tabular dataset(with proper data types) , apply transformation and create an output dataset which will be passed as input to the step 2. However when i opened this dataset from the pipeline run log, the datatype all become string instead of maintaining the original data types of the input tabular data set<\/li>\n<li>  Step 2 - use the output dataset of step 1 as input and apply some more transformations. However i have some logic based on data types which doesn't work because intermediate data set does not maintain the same data structure<\/li>\n<\/ol>\n<p>is there anyway we can maintain the original data types\/schema structure in the intermediate datasets?<\/p>\n<p>Here is some snippets on my code :<\/p>\n<p>feature_work = (  <br \/>\nOutputFileDatasetConfig(  <br \/>\nname=&quot;data_enhanced_add_global_variables&quot;,  <br \/>\ndestination=(def_blob_store, &quot;data\/processed\/output\/1&quot;),  <br \/>\n)  <br \/>\n.read_delimited_files()  <br \/>\n.as_upload(overwrite=True)<\/p>\n<p>feature_engineering_step_1 = PythonScriptStep(name = &quot;1_feature_engineering&quot;,  <br \/>\n#source_directory = experiment_folder,  <br \/>\nscript_name = &quot;1_feature_engineering.py&quot;,  <br \/>\narguments = ['--input-data', data_aggregate_DS.as_named_input('raw_data'),  <br \/>\n'--prepped-data', feature_work],  <br \/>\n#outputs=[prepped_data_folder],  <br \/>\noutputs=[feature_work],  <br \/>\ncompute_target = compute_name,  <br \/>\nrunconfig = pipeline_run_config,  <br \/>\nallow_reuse = True)<\/p>\n<h1 id=\"step-2\">Step 2<\/h1>\n<p>feature_engineering_step_2 = PythonScriptStep(name = &quot;2_feature_engineering&quot;,  <br \/>\n#source_directory = experiment_folder,  <br \/>\nscript_name = &quot;2_feature_engineering.py&quot;,  <br \/>\narguments = ['--input-data', feature_work.as_input(name='raw_data'),  <br \/>\n'--prepped-data', feature_work1],  <br \/>\noutputs=[feature_work1],  <br \/>\ncompute_target = compute_name,  <br \/>\nrunconfig = pipeline_run_config,  <br \/>\nallow_reuse = True)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to sign into Azure Machine Learning Studio (classic), page constantly refreshes.",
        "Question_created_time":1647878967167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/780770\/unable-to-sign-into-azure-machine-learning-studio",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am trying to sign into my Free Workspace within the Microsoft Azure Machine Learning Studio (classic).   <\/p>\n<p>I am trying to access the RICT2 Prediction and Classification Experiment: <a href=\"https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0\">https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0<\/a>  <\/p>\n<p>The page refreshes inexplicably on a loop several times, before displaying a sign-in error.  <\/p>\n<p>Would anyone be able to assist?  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning algorithms questions",
        "Question_created_time":1647856847267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/780362\/machine-learning-algorithms-questions",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi :  <\/p>\n<p>I am planing to use k-means to form algorithm to do project. However, I am aware that there are certain shortcomings to find the optimal groups using k-means.  <\/p>\n<p>Could you please tell the limitation and provide me with a detailed example?  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1647898847903,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello @hideonbush again,  <\/p>\n<p>Generally to think about k-means, please refer to below cons and pros. If you can provide more details and how you want to develop your project, I can share more:  <\/p>\n<p>Pros:  <\/p>\n<ul>\n<li> K-means is very simple, highly flexible, and efficient.   <\/li>\n<li> Easy to adjust and interpret the clustering results. Easy to explain the results in contrast to Neural Networks.  <\/li>\n<li> The efficiency of k-means implies that the algorithm is good at segmenting a dataset.  <\/li>\n<li> An instance can change cluster (move to another cluster) when the centroids are recomputed  <\/li>\n<\/ul>\n<p>Cons  <\/p>\n<ul>\n<li> It does not allow to develop the most optimal set of clusters and the number of clusters must be decided before the analysis. How many clusters to include is left at the discretion of the researcher. This involves a combination of common sense, domain knowledge, and statistical tools. Too many clusters tell you nothing because of the groups becoming very small and there are too many of them.   <\/li>\n<li> When doing the analysis, the k-means algorithm will randomly select several different places from which to develop clusters. This can be good or bad depending on where the algorithm chooses to begin at. From there, the center of the clusters is recalculated until an adequate &quot;center'' is found for the number of clusters requested.  <\/li>\n<li> The order of the data input has an impact on the final results.  <\/li>\n<\/ul>\n<p>Hope this helps!  <\/p>\n<p>Regards,  <br \/>\nYutong  <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks.<\/em>  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure job requires interactive authentication every time",
        "Question_created_time":1647457870313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775236\/azure-job-requires-interactive-authentication-ever",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm running a neural network on azure and it's working except it requires me to sign in with a device code for every job that runs. This is an issue for when I want to run long studies with multiple jobs and can't authenticate every job.   <\/p>\n<p>I've tried to use the azure CLI authentication with the following code:  <\/p>\n<pre><code>cli_auth = AzureCliAuthentication()\nws = Workspace(subscription_id=&quot;id&quot;,\n               resource_group=&quot;rsgp&quot;,\n               workspace_name=&quot;ws&quot;, auth=cli_auth)\n<\/code><\/pre>\n<p>When I do that, I recieve the error: &quot;Could not retrieve user token. Please run 'az login'&quot;  <br \/>\nThis happens when I login using az login before a run as well.   <\/p>\n<p>I've also tried using the default credential before calling the workspace instead of using CLI, using this code:   <\/p>\n<pre><code>credential = DefaultAzureCredential()\n\n\nclient = ResourceManagementClient(\n    credential=credential,\n    subscription_id=&quot;id&quot;\n)\n<\/code><\/pre>\n<p>This is functional, but I still need to log in manually for every job.   <\/p>\n<p>Any help would be appreciated! Thanks!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Project in Data Labeling not working, getting only \"Loading project details\"",
        "Question_created_time":1647676305203,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778679\/project-in-data-labeling-not-working-getting-only",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Project in Azure Machine Learning Studio in Data Labeling was working, we did label it every day. One day we just could not open it, it showed only <em><strong>Loading project details..<\/strong><\/em> for hours.  <br \/>\nSAS token is working, <strong>it also work for our admin account, but not for Labellers<\/strong>.   <br \/>\nDo you have any idea?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Customizing a curated environment after cloning it doesn't seem to work",
        "Question_created_time":1647484027330,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775490\/azure-ml-customizing-a-curated-environment-after-c",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am building an ML pipeline which runs data preparation and training scripts relying both on Scikit-learn and Tensorflow libraries.    <\/p>\n<p>Since Azure ML curated environments only include one library or the other, I followed instructions regarding how to customize a curated environment (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments<\/a>) to add additional libraries.    <\/p>\n<p>I am adding the 'tensorflow' package to an existing curated environment as follows:    <\/p>\n<pre><code>USE_CURATED_ENV = True  \n\n# Use and customize a curated environment provided by Azure  \nif USE_CURATED_ENV :  \n\n    curated_environment = Environment.get(workspace=ws, name=&quot;AzureML-sklearn-0.24-ubuntu18.04-py37-cpu&quot;)  \n      \n    # Clone the curated environment in order to add customized libraries  \n    curated_clone = curated_environment.clone(&quot;customize_curated&quot;)  \n      \n    # Add necessary libraries to the existing curated environment  \n    conda_dep = CondaDependencies()  \n    conda_dep.add_conda_package(&quot;tensorflow&quot;)  \n    curated_clone.python.conda_dependencies=conda_dep  \n  \n    # Associate the environment with the run configuration  \n    aml_run_config.environment = curated_clone  \n\n# Use a customized environment with specified packages only  \nelse:  \n    aml_run_config.environment.python.user_managed_dependencies = False  \n      \n    # Add some packages relied on by data preparation step  \n    aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(  \n        conda_packages=['pandas','scikit-learn','tensorflow'],   \n        pip_packages=['azureml-sdk', 'azureml-dataset-runtime[fuse,pandas]'],   \n        pin_sdk_version=False)  \n<\/code><\/pre>\n<p>However, when I run the pipeline, it fails on &quot;import tensorflow&quot;, saying that such package doesn't exist.    <br \/>\nI tried replacing <strong>conda_dep.add_conda_package(&quot;tensorflow&quot;)<\/strong> by <strong>conda_dep.add_pip_package(&quot;tensorflow&quot;)<\/strong>, but same error.    <\/p>\n<p>The alternative (when <strong>USE_CURATED_ENV = False<\/strong>) seems to work.    <br \/>\nI don't understand why it doesn't work when cloning an existing curated environment.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Replacement for Azure ML Classic Excel Add In",
        "Question_created_time":1647680517643,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>As far as I can tell there is no way to use the Excel add in for Azure ML using the new Azure ML service, it only works for the Classic. Is there any plan to provide a replacement add in that brings this functionality to the new Azure ML before Classic stops being supported in 2024?<\/p>",
        "Question_closed_time":1647857647663,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=325bba53-0a8f-4bf1-ab22-527f5cbac10d\">@Tim Cahill  <\/a>  Thanks for the question. Currently it's on roadmap to support in the near  future.  Excel add in feature similar to studio classic, it will be built on top on v2 online endpoints.    <br \/>\nCurrently, managed endpoints are not integrated with Designer, we need to first provide capability to do a no code designer deployment on v2 online endpoints and integrating excel add in for v2 endpoints.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Local compute not found error when running a hyperparameter search",
        "Question_created_time":1647273614647,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771547\/local-compute-not-found-error-when-running-a-hyper",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am new to Azure and am trying to run a hyperparameter search on my neural network. I can run my code fine when I'm submitting a single job to examine a parameter, but when I run a hyperparameter search with the same configurations I get the following error:<\/p>\n<p>&quot;ComputeTargetNotFound: Compute Target with name local not found in provided workspace&quot;<\/p>\n<p>Any help would be appreciated!<\/p>\n<pre><code> from azureml.core import Workspace\n    from azureml.core import Experiment \n    from azureml.core import Environment\n    from azureml.core import ScriptRunConfig\n    from azureml.core.environment import CondaDependencies\n    from azureml.train.hyperdrive import HyperDriveConfig\n    from azureml.train.hyperdrive import choice\n    from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, PrimaryMetricGoal\n    from azureml.core.compute import ComputeTarget\n\n\n    ws = Workspace.from_config()\n    env = Environment.get(workspace=ws, name=&quot;AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu&quot;)\n    curated_clone1 = env.clone(&quot;customize_curated&quot;)\n    conda_dep = CondaDependencies().add_conda_package(&quot;scikit-learn&quot;)\n    curated_clone1.python.conda_dependencies=conda_dep\n\n\n    curated_clone1.register(ws)\n\n    param_sampling = RandomParameterSampling( {\n            'learning_rate': choice(0.001, 0.0001, 0.00001),\n\n        }\n    )\n\n    early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n\n    src = ScriptRunConfig(source_directory='.\/', script='loadv1.py',  environment=curated_clone1)\n\n    hd_config = HyperDriveConfig(run_config=src,\n                                 hyperparameter_sampling=param_sampling,\n                                 policy=early_termination_policy,\n                                 primary_metric_name=&quot;loss&quot;,\n                                 primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n                                 max_total_runs=100,\n                                 max_concurrent_runs=4)\n\n\n    experiment = Experiment(workspace=ws, name='day3-experiment-data')\n    #run = experiment.submit(src)\n    hyperdrive_run = experiment.submit(hd_config)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ParallelRunStep doesn\u00b4t support multiple input datasets",
        "Question_created_time":1647759270327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/779233\/parallelrunstep-doesn-t-support-multiple-input-dat",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Currently we are using the parallelrunstep in AML, Is there any workaround\/other approach to support distribute datasets in the parallel run step.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to make use of Labelled Images in AzureML Designer?",
        "Question_created_time":1628873927937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/513343\/how-to-make-use-of-labelled-images-in-azureml-desi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello! I have been labeling images in AzureML Data Labeling. I wish to use this labelled set in Designer, to prototype some model ideas. However, I cannot get this to work. Any output (Dataset, COCO or csv) seems not to be compatible with &quot;Convert to Image Directory&quot;.     <\/p>\n<p>My question is quite similar to one asked over a year ago - <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im.html<\/a> - the answer suggests a result was imminent. Has there been any update?     <\/p>\n<p>If there is not one individual module capable of parsing this information, is there a way to use multiple modules to import the data?     <\/p>\n<p>Thanks!    <\/p>\n<p>EDIT: The problem is also discussed here:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset.html<\/a>    <br \/>\nIs there a cleaner solution yet? Or is downloading it, converting to pandas, then reuploading the best thing to do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML workspace blob structure \/ Can I safely delete these blobs?",
        "Question_created_time":1647500925610,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775834\/azure-ml-workspace-blob-structure-can-i-safely-del",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I am trying to figure out the folder structure of Azure ML workspace in my storage account.  <br \/>\nI want to be able to delete old pipeline runs and experiments that have piled up in my workspace directly from Azure Storage Explorer without breaking the system.  <br \/>\nMy datastores and folder structure are as follows:  <\/p>\n<p>Datastore: workspaceartifactstore  <br \/>\nBlob container: azureml  <br \/>\nFolder structure:  <br \/>\n\u251c\u2500 ComputeRecord  <br \/>\n\u251c\u2500 Dataset  <br \/>\n\u251c\u2500 ExperimentRun  <br \/>\n\u251c\u2500 LocalUpload  <\/p>\n<p>Datastore: workspaceblobstore (Default)  <br \/>\nBlob container: azureml-blobstore-<em>(a series of numbers)<\/em>  <br \/>\nFolder structure:  <br \/>\n\u251c\u2500 azureml  <br \/>\n\u2502   \u251c\u2500\u2500 <em>(a series of numbers)<\/em>-setup  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 _tracer.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 azureml_globals.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 context_managers.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 job_prep.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 log_history_status.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 request_utilities.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 run_token_provider.py  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 utility_context_managers.py  <br \/>\n\u2502   \u251c\u2500\u2500 <em>(another series of numbers)<\/em>-setup  <br \/>\n\u2502    \u2502     \u251c\u2500\u2500 <em>sames files as above<\/em>  <\/p>\n<p>It would help if I understood what does each of these containers actually store.  <br \/>\nI already tried to delete all blobs stored in 'workspaceblobstore', but it didn't remove any pipeline or experiment from ML Studio.  <br \/>\nI have a few datasets registered in my workspace, and I don't want to delete them (nor unregister them).  <\/p>\n<p>Can I set a data retention policy on both containers in order to delete old blobs?  <br \/>\nCan I safely delete the blobs (folders) stored in 'workspaceartifactstore' too? Will they be recreated automatically when I run a new experiment?  <br \/>\nWhy are there two separate 'azureml' and 'azureml-blobstore-<em>(a series of numbers)<\/em>' containers? Is it possible to merge them?  <\/p>\n<p>Thanks.  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":1647528776467,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, thanks for reaching out. I've worked on a <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/60501\">similar inquiry<\/a> and the advise is to not delete data stored in default datastore to avoid weird errors. The option to easily delete experiment runs is on the roadmap. Here's a similar <a href=\"https:\/\/stackoverflow.com\/questions\/57497332\/how-to-delete-an-experiment-from-an-azure-machine-learning-workspace\">thread<\/a>. Feel free to raise and track feature request on <a href=\"https:\/\/feedback.azure.com\/d365community\/forum\/b9a0c624-ad25-ec11-b6e6-000d3a4f09d0\">ideas portal<\/a>.    <\/p>\n<blockquote>\n<p>According to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#prerequisites\">documentation<\/a>, when you create a workspace, an Azure blob container and an Azure file share are automatically registered as datastores to the workspace. They're named workspaceblobstore and workspacefilestore, respectively. The workspaceblobstore is used to store workspace artifacts and your machine learning experiment logs. It's also set as the default datastore and can't be deleted from the workspace. The workspacefilestore is used to store notebooks and R scripts authorized via compute instance.    <\/p>\n<\/blockquote>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to lable Table with no column in Azure Form Recognizer",
        "Question_created_time":1647507167407,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775939\/how-to-lable-table-with-no-column-in-azure-form-re",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a PDF file which will contains some data like below structure.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/183990-image.png?platform=QnA\" alt=\"183990-image.png\" \/>    <\/p>\n<p>I want to use Azure Form Recognizer to get the data.    <\/p>\n<p>How can I set the label with Table.    <\/p>\n<p>While tagging with Table, it need to specify the Column and Row.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Form recognizer to report on missing information in (near) real-time",
        "Question_created_time":1647481005860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775440\/form-recognizer-to-report-on-missing-information-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi community,   <br \/>\nI'm interested in what Azure Form Recogniser or another tool can do for us in terms of screening the correctness of uploaded applications. Think of applications for funding grants.  I haven't built any models yet, just wondering how feasible the below is.  A solution doesn't have to involve AI at all, but must be able to 'read' the uploaded documents.  <\/p>\n<p>A client uploads a set of standard documents (usually scanned PDF's)  using a file upload in our .net application.    <br \/>\nCan we:  <\/p>\n<ol>\n<li> Use form recogniser to extract key value pairs, after training a custom model.  <\/li>\n<li> Run a loop over these pairs to find missing information e.g. they forgot to add their date of birth, or didn't enter their income.  <\/li>\n<li> Report back to the user the missing information so they can correct the document and reupload them?  <br \/>\nPreferably in real time?  So they hit submit on the webpage, it extracts, analyses and provides a result in a few seconds?  <\/li>\n<\/ol>",
        "Question_closed_time":1647513011953,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=d4ec46af-03e5-46ab-ace4-d0dd3b8d93ba\">@Andrew Robertson  <\/a> Yes, you can use Azure form recognizer to analyze a document that is passed to the API and use the result of the analyze operation to report any missing fields in the form back to the user. This is the most widely used use case by most of the customers.     <\/p>\n<p>Form recognizer comes with a set of prebuilt APIs where it can extract common information from invoices, business cards, receipts etc. If you have a form that does not conform to the prebuilt API standards you need to create a custom model to extract the text in the form of a tags and their key:value pairs. The custom models require some basic training with some test forms and if all the forms that need extraction follow the same layout or guidelines the extraction results will be good.     <\/p>\n<p>In the case of custom forms the results are provided in almost real time where the form is submitted or <a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/form-recognizer-api-v3-0-preview-2\/operations\/AnalyzeDocument\">POST<\/a> request is sent to the API and an operation id is returned to retrieve the results using <a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/form-recognizer-api-v3-0-preview-2\/operations\/GetAnalyzeDocumentResult\">GET<\/a>.  Depending on your pricing tier of your resource if you intend to perform these actions synchronously you might have to limit the rate of requests sent to the API to avoid any TPS errors. If you are using async operations with a slight delay to fetch the results then you can design an application that can take large number of documents and provide results to the users within a short span of time.     <\/p>\n<p>I hope the above information is helpful.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Getting error on Local Machine Learning Execution",
        "Question_created_time":1647417258117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/774178\/getting-error-on-local-machine-learning-execution",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>On Local machine learning,  <br \/>\nDevelopment platform is not bad.  <br \/>\nBut prediction environment got error.<\/p>\n<p>I show a log.<\/p>\n<p>Traceback (most recent call last):  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/luigi\/worker.py&quot;, line 191, in run  <br \/>\nnew_deps = self._run_get_new_deps()  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/luigi\/worker.py&quot;, line 133, in _run_get_new_deps  <br \/>\ntask_gen = self.task.run()  <br \/>\nFile &quot;tasks\/run_load.py&quot;, line 1115, in run  <br \/>\nlocal_run = experiment.submit(automl_config, show_output=True)  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py&quot;, line 220, in submit  <br \/>\nrun = submit_func(config, self.workspace, self.name, **kwargs)  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 103, in _automl_static_submit  <br \/>\nshow_output)  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 213, in _start_execution  <br \/>\nignored_dependencies=package_utilities._PACKAGES_TO_IGNORE_VERSIONS  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/package_utilities.py&quot;, line 446, in _get_package_incompatibilities  <br \/>\nconda_list_packages = _all_dependencies_conda_list()  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/package_utilities.py&quot;, line 338, in _all_dependencies_conda_list  <br \/>\nstdout=subprocess.PIPE, stderr=subprocess.PIPE)  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py&quot;, line 403, in run  <br \/>\nwith Popen(*popenargs, **kwargs) as process:  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py&quot;, line 707, in <strong>init<\/strong>  <br \/>\nrestore_signals, start_new_session)  <br \/>\nFile &quot;\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py&quot;, line 1333, in _execute_child  <br \/>\nraise child_exception_type(errno_num, err_msg)  <br \/>\nPermissionError: [Errno 13] Permission denied<\/p>\n<p>But log contains very few information.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Load the most recent data from Date partitioned folder",
        "Question_created_time":1646726960863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/763313\/load-the-most-recent-data-from-date-partitioned-fo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have set up a pipeline with Azure Data Factory in order to move data from my on-premises Oracle DB to parquet files in an Azure blob container every 10 days.  <br \/>\nThe folder structure of my blob container is as follows:  <\/p>\n<blockquote>\n<p>onpremises\/2022\/02\/18\/file1.parquet  <br \/>\nonpremises\/2022\/02\/18\/file2.parquet  <br \/>\nonpremises\/2022\/02\/18\/file3.parquet  <\/p>\n<p>onpremises\/2022\/02\/28\/file1.parquet  <br \/>\nonpremises\/2022\/02\/28\/file2.parquet  <br \/>\nonpremises\/2022\/02\/28\/file3.parquet  <\/p>\n<p>onpremises\/2022\/03\/08\/file1.parquet  <br \/>\nonpremises\/2022\/03\/08\/file2.parquet  <br \/>\nonpremises\/2022\/03\/08\/file3.parquet  <\/p>\n<p>...  <\/p>\n<\/blockquote>\n<p>Now I'm trying to set up a pipeline in Azure ML which will run every time new data is coming into this container.  <br \/>\nIn my script below, I start by getting a reference to my container before calling the function 'from_parquet_files' to read from Parquet files.  <br \/>\nProblem: the script reads all files from every folder and adds a data column to the dataset (I believe it is because of the parameter 'partition_format').  <\/p>\n<pre><code>from azureml.core import Workspace, Datastore\n\n# Get a reference to the workspace\nws = Workspace.from_config()\n\n# Reference to the datastore 'onpremises' from which we will contruct our dataset\ndata_store = Datastore(ws, &quot;onpremises&quot;)\n\nfrom azureml.core import Dataset\n\n# Create a dataset from the data stored in datastore 'onpremises' at the specified path\nspecs_dataset = Dataset.Tabular.from_parquet_files(path=(data_store, ''), partition_format='\/{PartitionDate:yyyy\/MM\/dd}\/')\n\n# Register the dataset to the workspace. Increments the version if dataset already exists.\nspecs_dataset.register(workspace=ws, name=&quot;specs&quot;, description=&quot;Specs data from on-premises&quot;, create_new_version=True)\n<\/code><\/pre>\n<p>What I would like to do is to read only the most recent set of files (in my case, files listed under 'onpremises\/2022\/03\/08\/').  <br \/>\nAs the pipeline will run automatically, it should detect what is the most recent data among the folder structure.  <br \/>\nIs there a simple way to achieve this programmatically?  <\/p>\n<p>Thanks in advance.  <\/p>",
        "Question_closed_time":1646813594767,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>@ThierryL-3166 You could only pass the required files by getting the year, month and day from the timestamp or date output. If your pipeline runs on schedule, you could list all the paths for all the days since the last run and load the files. I think something like below should work.    <\/p>\n<pre><code># create tabular dataset from multiple paths  \nfrom datetime import date  \nfrom datetime import timedelta  \n  \ntoday = date.today()  \n  \nyesterday = today - timedelta(1)  \n      \nd1 = today.strftime(&quot;%Y\/%m\/%d&quot;)  \nd2=yesterday.strftime(&quot;%Y\/%m\/%d&quot;)   \n  \n  \npath1 = 'onpremises\/'+ d1 + '\/*.parquet'  \npath2 = 'onpremises\/'+ d2 + '\/*.parquet'  \n  \ndata_paths = [(datastore, path1),(datastore, path2)]  \ntabular_dataset = Dataset.Tabular.from_parquet_files(path=data_paths)  \n<\/code><\/pre>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Scheduling Jupyter notebook run in AzureML",
        "Question_created_time":1647243630153,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/770720\/scheduling-jupyter-notebook-run-in-azureml",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI am trying to run my jupyter notebook in azure ml by scheduling. I noticed  some methods to schedule by ml pipeline. But I need to run my jupyter notebook file (.pynb) by scheduling every midnight. Please help me regarding this.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Time series forecasting AutoML Automatic featurization groupby specific column values",
        "Question_created_time":1647278425307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771703\/time-series-forecasting-automl-automatic-featuriza",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <br \/>\nI'm training time-series forecasting models with Azure AutoML.  <\/p>\n<p>As far as I\u2019m concerned, featurization techniques such as Normalization and Scaling or Impute missing values, are applied by columns.   <\/p>\n<p>Given that I\u2019m dealing with time-series data, is there a way to apply these kinds of featurization using a group by some column values? Otherwise, I feel the transformations applied make no sense at all.  <\/p>\n<p>For instance, If I want to predict product demand from different stores, would be possible to impute missing values from one article given the median of that article (not the one of the column) modifying AutoML Automatic featurization? Or standardize the target values for each article separately?  <\/p>\n<p>Thanks in Advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer- Language Detection",
        "Question_created_time":1647103939673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769728\/azure-ml-designer-language-detection",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>We have a clustering model in AzureML designer and we are using the &quot;Preprocess Text&quot; component to clean the messages.    <br \/>\nBut, the messages can be in different languages and in the dropdown of the Language in the &quot;Preprocess Text&quot; component there is only English and no other language. Is there a way to detect the language of a text in azureml designer?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182400-capture.png?platform=QnA\" alt=\"182400-capture.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deep learning",
        "Question_created_time":1647180028657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/770128\/deep-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Which algorithm is most suitable for face reorganization attendance system?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The file limit in Azure ML studio",
        "Question_created_time":1647197880180,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/770207\/the-file-limit-in-azure-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi, when I submitted my work in Azure ML studio, it showed an error like this.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182478-screenshot-2022-03-13-115250.jpg?platform=QnA\" alt=\"182478-screenshot-2022-03-13-115250.jpg\" \/>    <\/p>\n<p>My folder contains around 50000 files, and even if I uploaded my files onto the datasets, I still need to download them to my current workplace. Is there a way to directly use the file from datasets or increase the snapshot size? I really appreciate any help you can provide.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Multiple new errors when deploying to ACI webservice",
        "Question_created_time":1647268740933,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771372\/multiple-new-errors-when-deploying-to-aci-webservi",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I've deployed an ACI webservice a few months ago on Azure ML. The scoring script references an object in a container in Azure blob, and everything worked fine. I now want to increate the size of the deployment config, and tried redeploying. It failed, and I don't know what changed. I didn't touch the code or notebooks. It's instantly failing, 5 seconds into running Model.deploy..  <\/p>\n<p>I first get a    <\/p>\n<pre><code>WebserviceException:\nMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\n<\/code><\/pre>\n<p>Then clicking on more info, I get: <code>The specified blob does not exist. RequestId:f2302ade-901e-0014-667b-37d663000000 Time:2022-03-14T08:14:42.7864874Z<\/code>  <\/p>\n<p>There's also this error in the logs:  <code>Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found<\/code>. Should it not create a new container registry and a new Docker image if one does not exist? It did the many times I deployed a service before. Why is it still referencing an old container? It should have created a new one...   <\/p>\n<p>The blob definitely exists and it worked before. The error doesn't make any sense. It's not a code issue. I even tried removing every registered model, endpoint, and even regenerated access keys and recreated the containers and blobs; same error. I also removed the old container registry. Also nothing.    <\/p>\n<p>It doesn't even work on a LocalWebService. Again, nothing's changed in the scoring script or deployment notebook I had...   <\/p>\n<p>Entire error:  <\/p>\n<pre><code>Tips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nFailedService deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\nMore information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&amp;sr=b&amp;sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&amp;st=2022-03-14T09%3A49%3A48Z&amp;se=2022-03-14T17%3A54%3A48Z&amp;sp=r\nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 404,\n  &quot;message&quot;: &quot;No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..&quot;,\n  &quot;details&quot;: []\n}\n\n---------------------------------------------------------------------------\nWebserviceException                       Traceback (most recent call last)\n\/tmp\/ipykernel_32412\/349779865.py in &lt;module&gt;\n      8 )\n      9 \n---&gt; 10 service.wait_for_deployment(show_output=True)\n     11 print(service.state)\n\n\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output, timeout_sec)\n    917                     logs_response = 'Current sub-operation type not known, more logs unavailable.'\n    918 \n--&gt; 919                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n    920                                           'service state: {}\\n'\n    921                                           'Operation ID: {}\\n'\n\nWebserviceException: WebserviceException:\n Message: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\nMore information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&amp;sr=b&amp;sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&amp;st=2022-03-14T09%3A49%3A48Z&amp;se=2022-03-14T17%3A54%3A48Z&amp;sp=r\nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 404,\n  &quot;message&quot;: &quot;No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..&quot;,\n  &quot;details&quot;: []\n}\n InnerException None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\\nMore information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&amp;sr=b&amp;sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&amp;st=2022-03-14T09%3A49%3A48Z&amp;se=2022-03-14T17%3A54%3A48Z&amp;sp=r\\nError:\\n{\\n  \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n  \\&quot;statusCode\\&quot;: 404,\\n  \\&quot;message\\&quot;: \\&quot;No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..\\&quot;,\\n  \\&quot;details\\&quot;: []\\n}&quot;\n    }\n}\n<\/code><\/pre>\n<p><strong>EDIT<\/strong>: I removed everything. Recreated EVERYTHING. And now, somehow the entry script is wrong when I didn't touch it. Someone please help here so that I move on from this service already.   <\/p>\n<pre><code>{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.&quot;\n    }\n  ]\n}\n InnerException None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: ffaab603-0358-4b87-b1c9-8e5ee3390bf7\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n  \\&quot;statusCode\\&quot;: 400,\\n  \\&quot;message\\&quot;: \\&quot;Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\\&quot;,\\n  \\&quot;details\\&quot;: [\\n    {\\n      \\&quot;code\\&quot;: \\&quot;CrashLoopBackOff\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\\&quot;\\n    }\\n  ]\\n}&quot;\n    }\n}\n<\/code><\/pre>\n<p>Entire error log when testing on a LocalWebService:  <\/p>\n<pre><code>Container Logs:\n2022-03-14T14:13:04,088795292+00:00 - rsyslog\/run \n2022-03-14T14:13:04,096166698+00:00 - iot-server\/run \n2022-03-14T14:13:04,096661705+00:00 - gunicorn\/run \nDynamic Python package installation is disabled.\nStarting HTTP server\n2022-03-14T14:13:04,096254199+00:00 - nginx\/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-03-14T14:13:04,184522169+00:00 - iot-server\/finish 1 0\n2022-03-14T14:13:04,186354496+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 20.1.0\nListening at: http:\/\/127.0.0.1:31311 (14)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 42\n2022-03-14 14:13:04.894347: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib:\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib:\n2022-03-14 14:13:04.894395: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nSPARK_HOME not set. Skipping PySpark Initialization.\nException in worker process\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker\n    worker.init_process()\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process\n    self.load_wsgi()\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load\n    return self.load_wsgiapp()\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/importlib\/__init__.py&quot;, line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 978, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 961, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 950, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 678, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 205, in _call_with_frames_removed\n  File &quot;\/var\/azureml-server\/entry.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/var\/azureml-server\/create_app.py&quot;, line 4, in &lt;module&gt;\n    from routes_common import main\n  File &quot;\/var\/azureml-server\/routes_common.py&quot;, line 32, in &lt;module&gt;\n    from aml_blueprint import AMLBlueprint\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 28, in &lt;module&gt;\n    main_module_spec.loader.exec_module(main)\n  File &quot;\/var\/azureml-app\/arabic_sentiment\/score.py&quot;, line 7, in &lt;module&gt;\n    from azureml.core.model import Model\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/core\/__init__.py&quot;, line 13, in &lt;module&gt;\n    from .workspace import Workspace\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/core\/workspace.py&quot;, line 22, in &lt;module&gt;\n    from azureml._project import _commands\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/_project\/_commands.py&quot;, line 29, in &lt;module&gt;\n    from azure.mgmt.resource import ResourceManagementClient\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/__init__.py&quot;, line 9, in &lt;module&gt;\n    from .managedapplications import ApplicationClient\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/__init__.py&quot;, line 9, in &lt;module&gt;\n    from ._application_client import ApplicationClient\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/_application_client.py&quot;, line 18, in &lt;module&gt;\n    from .operations import ApplicationClientOperationsMixin, ApplicationDefinitionsOperations, ApplicationsOperations\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/operations\/__init__.py&quot;, line 9, in &lt;module&gt;\n    from ._application_client_operations import ApplicationClientOperationsMixin\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/operations\/_application_client_operations.py&quot;, line 17, in &lt;module&gt;\n    from azure.core.tracing.decorator import distributed_trace\n  File &quot;\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/core\/tracing\/decorator.py&quot;, line 31, in &lt;module&gt;\n    from typing_extensions import ParamSpec\nImportError: cannot import name 'ParamSpec'\nWorker exiting (pid: 42)\nShutting down: Master\nReason: Worker failed to boot.\n2022-03-14T14:13:06,839815591+00:00 - gunicorn\/finish 3 0\n2022-03-14T14:13:06,841371413+00:00 - Exit code 3 is not normal. Killing image.\n\nError: Container has crashed. Did your init method fail?\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"After Web service deployment, getting column name not found error",
        "Question_created_time":1646646691503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/761638\/after-web-service-deployment-getting-column-name-n",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>After converting the categorical variables to indicator values built the model using numeric &amp; indicator values variable. Web service deployment was successful, but how ever while checking for Test response its returning error stating that:  <\/p>\n<p>Select Columns in dataset: Error 0001: Column with name or index &quot; product_ Sugar_content_No_ Sugar&quot; not found  <br \/>\nReport Error.  <br \/>\n Where, &quot;product_ Sugar_content_No_ Sugar&quot; is indicator column which is already added during model building.  <\/p>\n<p>Can any one please help me to resolve this error.   <\/p>\n<p>I am getting this error only when i am using both numeric &amp; indicator variables for model, but if i use only numeric variables i am able to get the Test response output.  <\/p>\n<p>Request your support.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is Azure ML custom Environment Autosave version generated",
        "Question_created_time":1634123620240,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/588969\/how-is-azure-ml-custom-environment-autosave-versio",
        "Question_score_count":4,
        "Question_answer_count":4,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,   <br \/>\nThe training notebook points to the specified environment version but once the run is submitted, the run picks up the env with version=autosave... instead of the version I had  specified which leads to failure of the run submitted.  <br \/>\nCould you help me understand how this autosave environment version gets created once the run is submitted.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure TabularDataset wrongly loads Parquet?",
        "Question_created_time":1647121761043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769866\/azure-tabulardataset-wrongly-loads-parquet",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Below I give a <strong>concrete example where <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#azureml-data-tabulardataset-to-pandas-dataframe\">azureml Python api<\/a> fails to correctly read Parquet files<\/strong>.    <br \/>\nMore precisely, the data gets displaced. It may clarify <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/119459\/parquet-file-registered-in-a-tabluar-format-is-loa.html\">this issue where data could not be publicly shared<\/a> posted by <a href=\"\/users\/na\/?userid=4a620447-698a-489f-a385-6bfee5b37d2e\">@Kengo Wada  <\/a>.    <\/p>\n<p>Setup: Python 3.8 + azureml-core=1.36.0 + azureml-dataprep=2.26.0 + pyarrow=7.0.0    <\/p>\n<p>The data is attached<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182488-error.log?platform=QnA\">182488-error.log<\/a>    <\/p>\n<p>The code demonstrating the issue is given below.     <br \/>\nIt uses an input data to create a table of strings along with some None values, stores in Parquet format, and reads either directly or through TabularDataset.    <\/p>\n<pre><code>from azureml.core import Workspace, Dataset  \nimport tempfile  \nimport pandas as pd  \nimport hashlib  \n  \n# prepare data: list of hashs with some None values  \ndf = pd.read_csv(&quot;error.log&quot;)  \nmask = df.isna().any(1)  \ndf.id = df.id.map(lambda s:hashlib.sha512(str(s).encode()).hexdigest() if s else None)  \ndf.loc[mask,'id'] = None  \n\n# configure Azure storage  \nws = Workspace.from_config()  \ndstore = ws.datastores.get('my_datastore')  \ndstore_path = 'my_path'  \ntarget = (dstore,dstore_path)  \n\n# write to Azure storage  \nwith tempfile.TemporaryDirectory() as tmpdir:  \n    df.to_parquet(f'{tmpdir}\/df.parquet')  \n    ds=Dataset.File.upload_directory(tmpdir,target,overwrite=True)  \n  \n# read by two ways: download and open in pandas or use the Azure connector  \nwith tempfile.TemporaryDirectory() as tmpdir:  \n    ds=Dataset.File.from_files(target)  \n    ds.download(tmpdir)  \n    df1 = pd.read_parquet(tmpdir)  \n    ds = Dataset.Tabular.from_parquet_files(target)  \n    df2 = ds.to_pandas_dataframe()  \n  \n# comparison fails, the data seems displaced :-(  \npd.testing.assert_frame_equal(df1,df2)  \n<\/code><\/pre>\n<p>FWD: <a href=\"\/users\/na\/?userid=0e711f59-976b-4899-a912-2f0dd680421a\">@Ramr-msft  <\/a> <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dataset access- azure cloud, notebook, blobstore",
        "Question_created_time":1647268826120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771337\/dataset-access-azure-cloud-notebook-blobstore",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>From my online azure Notebook, how can I access a Dataset that I uploaded to blobstore. I have uploaded 5000 images for training a CNN deep learning model and there seem to be no easy access from the notebook.   <\/p>\n<ul>\n<li> I have my python script with a tensorflow datagenerator that draws images from a folder.  <\/li>\n<li> I have uploaded all images to my datasets under blobstorage.  <\/li>\n<li> I now want to specify the path to that dataset.  <\/li>\n<\/ul>\n<p>Seems so simple, yet all online tutorials is about accessing cloud data from your local notebook.   <br \/>\nThis should not be that difficult!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Module Not Found Error when launching parameter study",
        "Question_created_time":1647126154127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769904\/module-not-found-error-when-launching-parameter-st",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am a new user to Azure ML, and I would like to use the service to perform a parameter study for a ML model.  I was able to launch a single job to test one parameter (e.g. learning rate = 0.01), but I am having trouble launching multiple jobs to cover several parameters (e.g. learning rates = 0.1, 0.01, or 0.001).     <\/p>\n<p>I generally followed the hyperparameter tuning guide (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters<\/a>), but when I run the code below, the jobs fail with the error &quot;User program failed with ModuleNotFoundError: No module named 'sklearn'&quot;. Can someone help me identify what I am doing incorrectly?  I tried to add the conda dependency (as shown) to fix this error, but it still did not work.    <\/p>\n<p>Thank you!    <\/p>\n<pre><code>from azureml.core import Workspace  \nfrom azureml.core import Experiment   \nfrom azureml.core import Environment  \nfrom azureml.core import ScriptRunConfig  \nfrom azureml.core.environment import CondaDependencies  \nfrom azureml.train.hyperdrive import HyperDriveConfig  \nfrom azureml.train.hyperdrive import choice  \nfrom azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, PrimaryMetricGoal  \nfrom azureml.core.compute import ComputeTarget  \n  \n  \nws = Workspace.from_config()  \nenv = Environment.get(workspace=ws, name=&quot;AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu&quot;)  \ncurated_clone1 = env.clone(&quot;customize_curated&quot;)  \nconda_dep = CondaDependencies().add_conda_package(&quot;scikit-learn&quot;)  \ncurated_clone1.python.conda_dependencies=conda_dep  \n  \n  \ncurated_clone1.register(ws)  \nmyvm = ComputeTarget(workspace=ws, name='cpu3')  \nparam_sampling = RandomParameterSampling( {  \n        'learning_rate': choice(0.001, 0.0001, 0.00001),  \n          \n    }  \n)  \n  \nearly_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)  \n  \nsrc = ScriptRunConfig(source_directory='.\/', script='loadv1.py', compute_target = myvm, environment=curated_clone1)  \nsrc.run_config.target = myvm  \nhd_config = HyperDriveConfig(run_config=src,  \n                             hyperparameter_sampling=param_sampling,  \n                             policy=early_termination_policy,  \n                             primary_metric_name=&quot;loss&quot;,  \n                             primary_metric_goal=PrimaryMetricGoal.MINIMIZE,  \n                             max_total_runs=100,  \n                             max_concurrent_runs=4)  \n  \n  \nexperiment = Experiment(workspace=ws, name='day2-experiment-data')  \n#run = experiment.submit(src)  \nhyperdrive_run = experiment.submit(hd_config)  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"dataset.to_pandas_dataframe() throws a DatabaseConnectionException",
        "Question_created_time":1646912554290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/767054\/dataset-to-pandas-dataframe()-throws-a-databasecon",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <\/p>\n<p>I try to access a Azure ML Dataset in python and get the following error message:    <\/p>\n<pre><code>Execution failed in operation 'to_pandas_dataframe' for Dataset(id='[data.id]', name='[data.name]', version=1, error_code=ScriptExecution.DatabaseConnection.Unexpected,error_message=ScriptExecutionException was caused by DatabaseConnectionException.\\n  DatabaseConnectionException was caused by UnexpectedException.\\n    'MSSQL' encountered unexpected exception of type 'AggregateException' with HResult 'x80131500' while opening connection to server ([REDACTED]), database ([REDACTED]).\\n      Failed due to inner exception of type: AggregateException\\n| session_id=[session-id]) ErrorCode: ScriptExecution.DatabaseConnection.Unexpected  \n<\/code><\/pre>\n<p>It is a Tabular Dataset created from a Azure SQL database datasource.    <br \/>\nFor the access from the studio to the database a service principal is used.    <br \/>\nI can access all the resources mentioned above in the standard ui.    <\/p>\n<p>The &quot;sample usage&quot; in the &quot;consume&quot; tab of the dataset was used for accessing the dataset in python.    <br \/>\nRegarding environments i tried python 3.6 and 3.8 locally and in a compute instance of the ML studio.    <br \/>\nHowever the same error keeps coming.    <\/p>\n<p>I also tried to use sync-keys as described in this question:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/644562\/datasetto-pandas-dataframe-throws-a-scriptexecutio.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/644562\/datasetto-pandas-dataframe-throws-a-scriptexecutio.html<\/a>    <\/p>\n<p>Best Regards,    <br \/>\nGerhard<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Register Trained Model in Azure Machine Learning",
        "Question_created_time":1646841384953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/765721\/register-trained-model-in-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm training a Azure Machine learning model  using script via python SDK. I'm able to see the environment creation and the model getting trained in std_log in output&amp;logs folder. After the Model training I try to dump the model, but I don't see the model in any folder.     <\/p>\n<p>If possible I want to register the model directly into the Model section in Azure ML rather than dumping it in the pickle file.    <\/p>\n<p>I'm following this documentation a reference for model training <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train<\/a>    <\/p>\n<p>Below is the output log snapshot for the model training run.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/181468-image.png?platform=QnA\" alt=\"181468-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to run CD Pipeline to Deploy ML Model - Pipeline was successful months ago",
        "Question_created_time":1646739646433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/763631\/not-able-to-run-cd-pipeline-to-deploy-ml-model-pip",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hey ya all. :)    <\/p>\n<p>I have created a CI-Pipeline for Model Training and a Release Pipeline for deployment. I am using the Azure ML CLI Extension and a service principal User to get access to all Azure Ressources that are needed do run such a pipeline.    <\/p>\n<p>The CI Pipeline is running perfectly, no errors or any suspicious things to see...    <br \/>\nSince a few weeks the CD-Pipeline doesn't run successfully due to an error in the step &quot;Deploy to ML Service on ACI&quot;.    <\/p>\n<p>I thought this is caused by invalid permissions for my service principals but the SP has all rights on all resources in my Resource Group.    <\/p>\n<p>So i tried to do the Deployment by using the Python SDK. And there i am able to successfully deploy my model. ( I used the same artifact to deploy as for the CD Pipeline)    <\/p>\n<p>Well, i have no idea what happened, because nothing changed since the Pipeline ran successfully in July 2021.    <\/p>\n<p>Does anyone of have an idea what could be the cause?    <\/p>\n<p>This is the log of the failed Task. That debug log happens every 2 seconds until the pipeline fails:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/180985-cd-log.png?platform=QnA\" alt=\"180985-cd-log.png\" \/>    <\/p>\n<p>This is my Pipeline:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/180984-cd-pipe.png?platform=QnA\" alt=\"180984-cd-pipe.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ERROR: The provided hyperparameter space cannot be interpreted",
        "Question_created_time":1646489041427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/760594\/error-the-provided-hyperparameter-space-cannot-be",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_body":"<p>I'm training a KNN classifier from sklearn, and I want to use BayersianParameterSampling for hypertununing parameters. I have this code:   <\/p>\n<pre><code>run_config = ScriptRunConfig(\n    source_directory='.', script='train.py', arguments=['--input-data', input_ds.as_named_input('data')], \n    environment=_env, compute_target=cluster\n)\n\nhyper_params = BayesianParameterSampling(parameter_space={\n    '--n_neighbors': choice(range(5, 11)),\n    '--weights': choice('uniform', 'distance'),\n    '--leaf_size': choice(range(30, 101)),\n    '--p': choice(1, 2)\n})\n\nhd_config = HyperDriveConfig(\n    run_config=run_config, hyperparameter_sampling=hyper_params, policy=None, \n    primary_metric_name='AUC', primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n    max_total_runs=80, max_concurrent_runs=2)\n\nexperiment = Experiment(ws, 'churn-hyperdrive')\nhyperdrive_run = experiment.submit(hd_config)\n\nhyperdrive_run.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>When I submit the experiment, I get an error saying there's something wrong with the parameter space I have. I'm passing the parameters as arguments to a simple script, train.py, which only parses the args, sets the values in the KNN classifier, logs a few metrics, and saves the model.  <\/p>\n<p>What am I doing wrong here? I've went over everything multiple times, and I don't think there's a mistake. The error I'm getting:  <\/p>\n<pre><code>&quot;&lt;START&gt;[2022-03-05T13:56:17.215074][API][INFO]Experiment created&lt;END&gt;\\n&quot;&quot;&lt;START&gt;[2022-03-05T13:56:18.343781][GENERATOR][ERROR]Exception in creating bayesian optimization: ArgumentException:\\n\\tMessage: Got an invalid parameter space for [Random sampling]: [The provided hyperparameter space cannot be interpreted.]\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n        \\&quot;message\\&quot;: \\&quot;Got an invalid parameter space for [Random sampling]: [The provided hyperparameter space cannot be interpreted.]\\&quot;,\\n        \\&quot;inner_error\\&quot;: {\\n            \\&quot;code\\&quot;: \\&quot;BadArgument\\&quot;,\\n            \\&quot;inner_error\\&quot;: {\\n                \\&quot;code\\&quot;: \\&quot;ArgumentInvalid\\&quot;\\n            }\\n        }\\n    }\\n}.&lt;END&gt;\\n&quot;&quot;&lt;START&gt;[2022-03-05T13:56:18.343632][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space&lt;END&gt;\\n&quot;\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Microsoft Machine Learning on Azure",
        "Question_created_time":1646624032697,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/761239\/microsoft-machine-learning-on-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/180419-screenshot-2022-03-07-at-111837-am.png?platform=QnA\" alt=\"180419-screenshot-2022-03-07-at-111837-am.png\" \/>    <\/p>\n<p>The website continue to refresh and reload. Is there a way to resolve this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Response 502 error in Azure Machine Learning Studio Notebook",
        "Question_created_time":1643768437050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/718999\/response-502-error-in-azure-machine-learning-studi",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I copied over code from my training course into the Notebook in Azure Machine Learning Studio. After I run the code, I get the error - &lt;Response [502]&gt;. Please help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to solve \"max file size reached..\" issue on Azure ML notebook?",
        "Question_created_time":1646248822733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/756887\/how-to-solve-max-file-size-reached-issue-on-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Azure machine learning studio slows down. I get message like &quot;Max file size reached&quot; on the notebook quite often.  <br \/>\nCan anyone please tell me how to get rid of this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What are valid Azure ML Workspace connection argument options?",
        "Question_created_time":1646219078177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/756279\/what-are-valid-azure-ml-workspace-connection-argum",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to build an Azure ML environment with two python packages I have in Azure Devops.    <br \/>\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK:    <br \/>\n<code>ws.set_connection(name=&quot;ConnectionName&quot;,         category = &quot;PythonFeed&quot;,        target = &quot;https:\/\/pkgs.dev.azure.com\/&quot;,         authType = &quot;PAT&quot;,         value = PAT_TOKEN)<\/code>    <\/p>\n<p>However, for the other I need to get the package from git. The documentation of the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#azureml-core-workspace-workspace-set-connection\">Python SDK<\/a> and the underlying <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/workspace-connections\/create\">REST API<\/a> don't give the options for the arguments, only that they need to be strings (see links).    <\/p>\n<p>My question: what are the options for the following arguments:    <\/p>\n<ul>\n<li> authType    <\/li>\n<li> category    <\/li>\n<li> valueFormat    <\/li>\n<\/ul>\n<p>And what do I need to set for target link, so that I can connect to the Azure DevOps repository with potentially different authentication?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Pipeline pyarrow dependency for installing transformers",
        "Question_created_time":1646062523127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/753625\/azure-ml-pipeline-pyarrow-dependency-for-installin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was trying to import transformers in AzureML designer pipeline, it says for importing transformers and datasets the version of pyarrow needs to &gt;=3.0.0, but then after upgrading pyarrow's version to 3.0.0 and importing transformers pyarrow version is reset to original version of 0.16.0. attaching few error samples. please have a look.  <\/p>\n<blockquote>\n<p>Got exception when invoking script: 'RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):To use datasets, the module pyarrow&gt;=3.0.0 is required, and the current version of pyarrow doesn't match this condition.If you are running this in a Google Colab, you should probably just restart the runtime to use the right version of pyarrow.' azureml-designer-core 0.0.68 requires pyarrow==0.16.0, but you'll have pyarrow 3.0.0 which is incompatible.  <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"After deploying an Azure ML model to a container instance, call to the model fails when using the code provided in the \"Consume\" section of the endpoint (Python and C#).",
        "Question_created_time":1646656866430,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/762071\/after-deploying-an-azure-ml-model-to-a-container-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I have trained a model in Azure Auto-ML and deployed the model to a container instance.   <\/p>\n<p>Now when I am trying to use the Python code provided in the Endpoint's &quot;Consume&quot; section I get the following error:   <\/p>\n<blockquote>\n<p>The request failed with status code: 502  <br \/>\nContent-Length: 55  <br \/>\nContent-Type: text\/html; charset=utf-8  <br \/>\nDate: Mon, 07 Mar 2022 12:32:07 GMT  <br \/>\nServer: nginx\/1.14.0 (Ubuntu)  <br \/>\nX-Ms-Request-Id: 768c2eb5-10f3-4e8a-9412-3fcfc0f6d648  <br \/>\nX-Ms-Run-Function-Failed: True  <br \/>\nConnection: close  <\/p>\n<hr \/>\n<p>JSONDecodeError                           Traceback (most recent call last)  <br \/>\n&lt;ipython-input-1-6eeff158e915&gt; in &lt;module&gt;  <br \/>\n     48     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure  <br \/>\n     49     print(error.info())  <br \/>\n---&gt; 50     print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))  <\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/<strong>init<\/strong>.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)  <br \/>\n    352             parse_int is None and parse_float is None and  <br \/>\n    353             parse_constant is None and object_pairs_hook is None and not kw):  <br \/>\n--&gt; 354         return _default_decoder.decode(s)  <br \/>\n    355     if cls is None:  <br \/>\n    356         cls = JSONDecoder  <\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in decode(self, s, _w)  <br \/>\n    337   <br \/>\n    338         &quot;&quot;&quot;  <br \/>\n--&gt; 339         obj, end = self.raw_decode(s, idx=_w(s, 0).end())  <br \/>\n    340         end = _w(s, end).end()  <br \/>\n    341         if end != len(s):  <\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in raw_decode(self, s, idx)  <br \/>\n    355             obj, end = self.scan_once(s, idx)  <br \/>\n    356         except StopIteration as err:  <br \/>\n--&gt; 357             raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None  <br \/>\n    358         return obj, end  <\/p>\n<p>JSONDecodeError: Expecting value: line 1 column 1 (char 0)  <\/p>\n<\/blockquote>\n<p>If I use C# code provided in the Endpoint's &quot;Consume&quot; section I get the following error:   <\/p>\n<blockquote>\n<p>The request failed with status code: BadGateway  <br \/>\nConnection: keep-alive  <br \/>\nX-Ms-Request-Id: 5c3543cf-29ac-46a3-a9fb-dcb6a0041b08  <br \/>\nX-Ms-Run-Function-Failed: True  <br \/>\nDate: Mon, 07 Mar 2022 12:38:32 GMT  <br \/>\nServer: nginx\/1.14.0 (Ubuntu)  <\/p>\n<p>'&lt;=' not supported between instances of 'str' and 'int'  <\/p>\n<\/blockquote>\n<p>Could you please help me with this issue? I am not sure what do to if Microsoft's provided code is erroring out, don't know what else to do.  <\/p>\n<p>The Python code I am using is:   <\/p>\n<pre><code>import urllib.request\nimport json\nimport os\nimport ssl\n\ndef allowSelfSignedHttps(allowed):\n    # bypass the server certificate verification on client side\n    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n        ssl._create_default_https_context = ssl._create_unverified_context\n\nallowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n\ndata = {\n    &quot;Inputs&quot;: {\n        &quot;data&quot;:\n        [\n            {\n                &quot;SaleDate&quot;: &quot;2022-02-08T00:00:00.000Z&quot;,\n                &quot;OfferingGroupId&quot;: &quot;0&quot;,\n                &quot;week_of_year&quot;: &quot;7&quot;,\n                &quot;month_of_year&quot;: &quot;2&quot;,\n                &quot;day_of_week&quot;: &quot;1&quot;\n            },\n        ]\n    },\n    &quot;GlobalParameters&quot;: {\n        &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n    }\n}\n\nbody = str.encode(json.dumps(data))\n\nurl = 'http:\/\/4a0427c2-30d4-477e-85f5-dfdfdfdfdsfdff623f.uksouth.azurecontainer.io\/score'\napi_key = '' # Replace this with the API key for the web service\nheaders = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n\nreq = urllib.request.Request(url, body, headers)\n\ntry:\n    response = urllib.request.urlopen(req)\n\n    result = response.read()\n    print(result)\nexcept urllib.error.HTTPError as error:\n    print(&quot;The request failed with status code: &quot; + str(error.code))\n\n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    print(error.info())\n    print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n<\/code><\/pre>\n<p>The C# code I am using is:   <\/p>\n<pre><code>using System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Net.Http;\nusing System.Net.Http.Headers;\nusing System.Text;\nusing System.Threading.Tasks;\nusing Newtonsoft.Json;\n\nnamespace MLModelAPICall\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            InvokeRequestResponseService().Wait();\n        }\n\n        static async Task InvokeRequestResponseService()\n        {\n            var handler = new HttpClientHandler()\n            {\n                ClientCertificateOptions = ClientCertificateOption.Manual,\n                ServerCertificateCustomValidationCallback =\n                        (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n            };\n            using (var client = new HttpClient(handler))\n            {\n                \/\/ Request data goes here\n                var scoreRequest = new\n                {\n                    Inputs = new Dictionary&lt;string, List&lt;Dictionary&lt;string, string&gt;&gt;&gt;()\n                    {\n                        {\n                            &quot;data&quot;,\n                            new List&lt;Dictionary&lt;string, string&gt;&gt;()\n                            {\n                                new Dictionary&lt;string, string&gt;()\n                                {\n                                    {\n                                        &quot;SaleDate&quot;, &quot;2022-02-08T00:00:00.000Z&quot;\n                                    },\n                                    {\n                                        &quot;OfferingGroupId&quot;, &quot;0&quot;\n                                    },\n                                    {\n                                        &quot;week_of_year&quot;, &quot;7&quot;\n                                    },\n                                    {\n                                        &quot;month_of_year&quot;, &quot;2&quot;\n                                    },\n                                    {\n                                        &quot;day_of_week&quot;, &quot;1&quot;\n                                    }\n                                }\n                            }\n                        }\n                    },\n                    GlobalParameters = new Dictionary&lt;string, string&gt;()\n                    {\n                        {\n                            &quot;quantiles&quot;, &quot;0.025,0.975&quot;\n                        }\n                    }\n                };\n\n\n                const string apiKey = &quot;&quot;; \/\/ Replace this with the API key for the web service\n                client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(&quot;Bearer&quot;, apiKey);\n                client.BaseAddress = new Uri(&quot;http:\/\/4a0427c2-30d4-477e-85f5-xxxxxxxxxxxxx.uksouth.azurecontainer.io\/score&quot;);\n\n                \/\/ WARNING: The 'await' statement below can result in a deadlock\n                \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                \/\/ One way to address this would be to call ConfigureAwait(false)\n                \/\/ so that the execution does not attempt to resume on the original context.\n                \/\/ For instance, replace code such as:\n                \/\/      result = await DoSomeTask()\n                \/\/ with the following:\n                \/\/      result = await DoSomeTask().ConfigureAwait(false)\n\n                var requestString = JsonConvert.SerializeObject(scoreRequest);\n                var content = new StringContent(requestString);\n\n                content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application\/json&quot;);\n\n                HttpResponseMessage response = await client.PostAsync(&quot;&quot;, content);\n\n                if (response.IsSuccessStatusCode)\n                {\n                    string result = await response.Content.ReadAsStringAsync();\n                    Console.WriteLine(&quot;Result: {0}&quot;, result);\n                }\n                else\n                {\n                    Console.WriteLine(string.Format(&quot;The request failed with status code: {0}&quot;, response.StatusCode));\n\n                    \/\/ Print the headers - they include the requert ID and the timestamp,\n                    \/\/ which are useful for debugging the failure\n                    Console.WriteLine(response.Headers.ToString());\n\n                    string responseContent = await response.Content.ReadAsStringAsync();\n                    Console.WriteLine(responseContent);\n                    Console.ReadLine();\n                }\n            }\n        }\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to pass test data to  my deployed model in azure ml through function app",
        "Question_created_time":1646371928903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/759087\/how-to-pass-test-data-to-my-deployed-model-in-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>i am trying to make predictions for the model which is deployed in azure ml through function app<\/p>\n<p>1) my data is in azure blob storage  <br \/>\n2) i want to pass that data to model ( which is deployed ) for predictions  <br \/>\n3) once predictions is over i want to save that file again into blob storage<\/p>\n<p>all above has to be done through function app <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/179897-ask1.png?platform=QnA\" alt=\"179897-ask1.png\" \/><\/p>\n<p>i dont have any idea on how to do it , any suggestions<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I have a problem with the Speech Studio",
        "Question_created_time":1646313560160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/757970\/i-have-a-problem-with-the-speech-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a problem with the <strong><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/179721-screenshot.png?platform=QnA\" alt=\"**Speech Studio**,\" \/><\/strong> before I could make audio voices of more than 10 thousand characters, today it tells me that they only allow me to make 3 thousand characters, I don't understand why, what has been the problem that they lowered the characters so much with what which one can I work<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Reference trigger metadata in pipeline runs azureml",
        "Question_created_time":1645183760857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/741645\/reference-trigger-metadata-in-pipeline-runs-azurem",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have defined a pipeline using the azure ml sdk and defined a Pipeline parameter to be parsed as a timestamp.  <br \/>\nNow, I want to create a schedule that takes the timestamp of the trigger and pass it as the aforementioned pipeline parameter.  <br \/>\nSo far, I do not see how to get this<\/p>\n<p>Code:<\/p>\n<p>from azureml.pipeline.core import Pipeline, PipelineParameter, Workspace  <br \/>\nfrom azureml.pipeline.steps import PythonScriptStep<\/p>\n<p>cutoff_time = PipelineParameter(name=&quot;cutoff_time&quot;, default_value='2022-1-1')<\/p>\n<p>my_step = PythonScriptStep(  <br \/>\nname=&quot;My Step&quot;,  <br \/>\nsource_directory=&quot;dir&quot;,  <br \/>\nscript_name=&quot;my_script.py&quot;,  <br \/>\narguments=['--cutoff_time', cutoff_time],  <br \/>\nrunconfig=aml_run_config,  <br \/>\nallow_reuse=True  <br \/>\n)<\/p>\n<p>ws = Workspace.from_config()  <br \/>\npipeline = Pipeline(workspace=ws, steps=[my_step])  <br \/>\npublished_pipeline = pipeline.publish('my_pipeline_name')<\/p>\n<h1 id=\"schedule\">Schedule<\/h1>\n<p>recurrence = ScheduleRecurrence(frequency='Day', interval=1, hours=[0])  <br \/>\nrecurring_schedule = Schedule.create_for_pipeline_endpoint(ws,  <br \/>\nname='My schedule',  <br \/>\ndescription='Description',  <br \/>\npipeline_id=pipeline_published.id,  <br \/>\nexperiment_name='My experiment',  <br \/>\nrecurrence=recurrence)<\/p>\n<p>How do I tell AzureML to take the timestamp trigger as my Pipeline Param? In other words, how can I get the metadata of the trigger as a variable available to my pipeline run?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Microsoft Azure Machine Learning Studio - Error durind Deploy <Response [502]> Automated ML",
        "Question_created_time":1646161278517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/755239\/microsoft-azure-machine-learning-studio-error-duri",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/179002-error.png?platform=QnA\" alt=\"179002-error.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access file in a storage account residing in different tenant to ML Service in another tenant via IP based SAS restricted access",
        "Question_created_time":1645593594070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747081\/access-file-in-a-storage-account-residing-in-diffe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I have a storage account residing in tenant-A and machine learning service in tenant-B. When I try to read file from storage account in tenant-A via SAS (with IP restriction) in the jupyter notebook running on compute in ML service in tenant-B, it is not accessible and failing with 403 (Forbidden).  <\/p>\n<p>But when I try to access the file without IP restriction, I am able to read it in the notebook.  <br \/>\nCan you please help in understanding why it is happening and possible fix for the problem?  <\/p>\n<p>Please note, the public IP of ML compute is being used for whitelisting in SAS.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Kernel not connected",
        "Question_created_time":1645626985700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747823\/kernel-not-connected",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have an azureml studio with a notebook and suddenly since today, I cant run notebooks cells anymore.  It says kernel not connected.  <br \/>\nI cant either open the terminal it never loads.  <\/p>\n<p>I restarted the compute instance several time, but that didnt fix the problem  <\/p>",
        "Question_closed_time":1646131552130,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=0b725e52-0000-0003-0000-000000000000\">@Luis Valencia  <\/a>    <\/p>\n<p>There was an issue causing the &quot;kernal not connected&quot; issue, but it has been fixed. Please let us know if you are still blocked by this issue. Thanks a lot!    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Synapse - 'No Azure Cognitive Service Linked Service are available'",
        "Question_created_time":1644147139677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/724155\/synapse-no-azure-cognitive-service-linked-service",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am following this guide  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-cognitive-services-sentiment\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-cognitive-services-sentiment<\/a><\/p>\n<p>But when I get to selecting 'Machine Learning - Predict with a Model', then I choose 'Sentiment Analysis'<\/p>\n<p>But the first dropdown is greyed out for me and reads:  <br \/>\nAzure Cognitive Services linked service: No Azure Cognitive Service Linked Service are available<\/p>\n<p>I had one created, then created another. AKV and link service tested with specific key.<\/p>\n<p>Anyone know how I can get it to recognize the Cognitive Service Linked Server?<\/p>\n<p>Thanks<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171659-image.png?platform=QnA\" alt=\"![171660-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171659-image.png?platform=QnA\">2<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171628-image.png?platform=QnA\" alt=\"171628-image.png\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure machine learning - environment - add conda dependancies by sdk  for training on a compute instance",
        "Question_created_time":1645625095433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747638\/azure-machine-learning-environment-add-conda-depen",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":9,
        "Question_body":"<p>hello guys, i m a bit confused   <\/p>\n<p>i need to add joblib package to a tensorflow 2.7 environment so as to load the needed datas during the train on the compute instance  <\/p>\n<p><strong>1) i start by making an environnment clone:<\/strong>  <\/p>\n<pre><code>env = Environment.get(workspace=ws, name=&quot;AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu&quot;)\ncurated_clone = env.clone(&quot;customize_curated&quot;)\n<\/code><\/pre>\n<p><strong>2) i add conda dependancies  at the python key (like the MS example)<\/strong>  <\/p>\n<pre><code>conda_dep = CondaDependencies()\nconda_dep.add_pip_package(&quot;joblib==1.0.1&quot;)\ncurated_clone.python.conda_dependencies=conda_dep\n<\/code><\/pre>\n<p><strong>3) registration<\/strong>  <\/p>\n<pre><code>curated_clone.register(workspace=ws)\n<\/code><\/pre>\n<p>i meet an error when i train the  model by using the registred environment caus joblib is missing  <\/p>\n<p>but if i modify the dockerfile of the environmment by adding joblib directly on studio, everything is ok  <br \/>\ncould you please explain me what i m doing wrong with the sdk  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio AutoML Hyperparameter Optimization & Algorithm Selection",
        "Question_created_time":1646043411497,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/753198\/azure-ml-studio-automl-hyperparameter-optimization",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Which method (Grid Search, Bayesian Search, Random Search, ...) is used in Azure ML Studio AutoML per default to optimize model hyperparameters in order to increase model accuracy? In the SDK you can choose which method you want to use (according to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters<\/a>), but I could not find any information about the Studio execept another asked question, but the provided answer was not clear to me (<a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl.html<\/a>).    <\/p>\n<p>And how exactly does Azure ML Studio AutoML search for possible algorithms\/ how does the tool choose, which algorithm to use next?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where to look for Source Code while implementing Azure Machine learning?",
        "Question_created_time":1645806024193,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/751130\/where-to-look-for-source-code-while-implementing-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am implementing a training pipeline using Azure Machine learning Pipeline architecture. I am interested in looking at the Source code, for example Hyper-drive step class or python-script step class. Where should I look for Source code?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning studio for designer function connected with excel?",
        "Question_created_time":1645970050413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/752248\/azure-machine-learning-studio-for-designer-functio",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am using Azure machine learning studio, which has been changed since last year.    <\/p>\n<p>Previously, the Azure Machine Learning designer function of the Classic version could be applied to Excel by importing the App function to Excel and downloading it. Like the picture below!    <\/p>\n<p>Has the function that can be linked to Excel be lost in this Azure Machine Learning Studio? it's very difficult....    <\/p>\n<p>If there is a function, can you tell me how to do it?    <\/p>\n<p>And I wonder if there are any lectures that explain the new azure machine learning designer features.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/178194-azure2.png?platform=QnA\" alt=\"178194-azure2.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/178202-azure1.png?platform=QnA\" alt=\"178202-azure1.png\" \/>    <\/p>",
        "Question_closed_time":1646044643350,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=3b41fd96-f090-42a6-b421-e5af3d214f5f\">@Robin Jang  <\/a> The designer studio does not have an add-in for excel. This is only available with the classic version of Azure Machine Learning.     <br \/>\nIf you are new to Azure machine learning designer I would recommend to start with the tutorials from Microsoft Learn available <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/browse\/?filter-products=machine&amp;products=azure-machine-learning\">here<\/a>.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Trigger Azure ML Pipeline from Azure Data Factory",
        "Question_created_time":1645081864137,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/739240\/trigger-azure-ml-pipeline-from-azure-data-factory",
        "Question_score_count":5,
        "Question_answer_count":2,
        "Question_comment_count":10,
        "Question_body":"<p>I have created and published a Azure ML pipeline. I want to trigger the ML pipeline from Azure Data Factory.  <\/p>\n<p>In ADF, i have chosen Machine learning execute pipeline and created the linked service to azure machine learning and able to choose the published pipeline endpoint. However while running, i am getting the below error. I couldn't find much information how to resolve the error.   <\/p>\n<p>&quot;Convert Failed. The value type 'System.String', in key 'azureCloudType' is not expected type 'Microsoft.DataTransfer.Common.Models.AzureCloudType&quot;<\/p>",
        "Question_closed_time":1645111953530,
        "Answer_score_count":3.0,
        "Answer_comment_count":14.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=0cab9490-181d-4799-9dfb-834a723c261c\">@Vinoth Kumar K  <\/a> ,    <br \/>\nWelcome to Microsoft Q&amp;A platform and thankyou for posting your query.     <br \/>\nAs per the details you have shared in the query, it looks like a product bug. I have raised this issue with the internal Product team. Once I hear back from them, I will keep everyone posted on this. Thanks for your patience!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"RuntimeError: Java gateway process exited before sending its port number when deploying Pyspark model to Azure Container Instance (Issue #23158)",
        "Question_created_time":1645557644517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/746493\/runtimeerror-java-gateway-process-exited-before-se",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi, I raised my issue in a GitHub repo for <strong>azure-sdk-for-python<\/strong> too:  <\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/23158\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/23158<\/a>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Replace SKLearn with supported code",
        "Question_created_time":1645627689823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747835\/replace-sklearn-with-supported-code",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <br \/>\nAny ideas on how to rewrite this code to supported Python code?  <br \/>\nThis code in a demo does not run well:<\/p>\n<p>WARNING:azureml.train.sklearn:'SKLearn' estimator is deprecated<\/p>\n<p>from azureml.train.sklearn import SKLearn<\/p>\n<p>estimator = SKLearn(source_directory='.\/Scripts',  <br \/>\ncompute_target=compute_target,  <br \/>\nentry_script='train.py',  <br \/>\ninputs=[tabular.as_named_input('training')],  <br \/>\npip_packages=['azureml-dataprep[fuse,pandas]','joblib==0.14.1','azureml-interpret','azureml-contrib-interpret','matplotlib','scikit-learn==0.22.1','seaborn'])<\/p>\n<p>run = experiment.submit(estimator)  <br \/>\nrun<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Datetime Issue",
        "Question_created_time":1623315431723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/430158\/azureml-datetime-issue",
        "Question_score_count":5,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am coming across an issue to do with retaining the datetime values in the datasets that I have uploaded to AzureML.    <br \/>\nThis issue can be replicated in the following ways:    <\/p>\n<ol>\n<li> Create a pandas dataframe with a column of datetime strings and parse them accordingly        d = {&quot;Date&quot;: [&quot;2020-03-06&quot;, &quot;2021-01-05&quot;, &quot;2016-01-30&quot;, &quot;2019-12-14&quot;]}  <br \/>\n    df = pd.DataFrame(data=d)  <br \/>\n    df[&quot;Date&quot;] = pd.to_datetime(df[&quot;Date&quot;], format=&quot;%Y-%m-%d&quot;)  <\/li>\n<\/ol>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104079-image.png?platform=QnA\" alt=\"104079-image.png\" \/>    <\/p>\n<ol start=\"2\">\n<li> Save this dataframe as a .parquet    <\/li>\n<li> Upload to Azure Blob    <\/li>\n<li> Create a Tabular Dataset object with the uploaded file    <\/li>\n<\/ol>\n<p>datastore = workspace.get_default_datastore()    <br \/>\ndatastore_path = [(datastore, &quot;filename.parquet&quot;)]    <br \/>\nazureml_df = Dataset.Tabular.from_parquet_files(path=datastore_path)    <\/p>\n<p>Printing the dataframe results in the following:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104157-image.png?platform=QnA\" alt=\"104157-image.png\" \/>    <br \/>\nThe datetime values are now different.    <br \/>\nTo investigate further, we can cast the datetime to int:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104181-image.png?platform=QnA\" alt=\"104181-image.png\" \/>    <br \/>\nwhich gives us a 15 digit number.    <\/p>\n<p>We also cast the original df to int:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104119-image.png?platform=QnA\" alt=\"104119-image.png\" \/>    <br \/>\nwhich instead gives us an 18 digit number.     <\/p>\n<p>This 18 digit number represents the number of nanoseconds since UNIX epoch. Three trailing zeroes are stripped from the number when creating the Tabular Dataset object through azureml-sdk, resulting in an incorrect datetime being read. Keep in mind that if you were to download the parquet from Azure Blob, the values are still intact, meaning the issue is with AzureML and potentially the Dataset method, <em>from_parquet_files<\/em>. A simple workaround would be to multiply this column by 1000 then convert it back to datetime again but I would like to know if there's something I'm missing in between reading the parquet from AzureML or if the problem is on Azure's side.     <\/p>\n<p>Regards,    <br \/>\nMuhammad    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use batch endpoints (preview) in Azure Machine Learning studio tutorial",
        "Question_created_time":1645721296993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/749684\/how-to-use-batch-endpoints-(preview)-in-azure-mach",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I have been following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoints-studio\">this tutorial<\/a> on how to use batch endpoints.    <\/p>\n<p>When I attempt to select environment I am not greeted with the same as on the tutorial, please see below screenshot. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/177555-image.png?platform=QnA\" alt=\"177555-image.png\" \/>     <\/p>\n<p>What are the steps in continuing this tutorial in terms of selecting an environment?    <\/p>\n<p>Kind Regards,     <\/p>\n<p>Adam N    <\/p>",
        "Question_closed_time":1645778988953,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=8e959a69-1284-4179-8605-95f47abea57f\">@AdamNevin-8126  <\/a> Currently, the scoring and dependencies files are generated only for mlflow models that are registered with Azure ML workspace.     <br \/>\nFor example after running this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/track-and-monitor-experiments\/using-mlflow\/train-local\/train-local.ipynb\">notebook<\/a> locally I registered the model and the folder with Azure ML workspace from the models tab.     <br \/>\nThis registered model can be selected while creating the batch endpoint and the dependencies are automatically created without the need of selecting a custom environment.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/177784-image.png?platform=QnA\" alt=\"177784-image.png\" \/>    <\/p>\n<p>If you are using a different framework model then the dependencies or scoring files need to be provided along with selection of custom environment. The custom environments though first need to be created from the Environments tab by providing a YAML file. After adding a custom environment you can proceed to select the environment on this screen and deploy the endpoint.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/177767-image.png?platform=QnA\" alt=\"177767-image.png\" \/>    <\/p>\n<p>Hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning: I cannot find experiment's user logs located in logs\/user folder",
        "Question_created_time":1645621539517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747549\/azure-machine-learning-i-cannot-find-experiments-u",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am running experiments in Azure Machine Learning using ParallelRunStep, and I cannot get the user folder with logs as defined in readme.txt file with the log folder structure.  <br \/>\nI cannot find log\/user folder with &quot;Logs generated when loading and running user's scripts.&quot;<\/p>\n<p>readme.txt file states:  <br \/>\nParallelRunStep has two major parts:  <\/p>\n<ol>\n<li> Scheduling, progress tracking and file concatenation for append_row.  <\/li>\n<li> Processing mini batch by calling the entry script.  <br \/>\nThe agent manager on each node start agents.  <br \/>\nAn agent gets mini batch and calls the entry script against the mini batch.    The &quot;logs&quot; folder has user, sys and perf sub folders.\n    The user folder includes messages from the entry script in processing mini batches.\n    The sys folder includes messages from #1 and non-entry script log from #2.\n    The perf folder includes periodical checking result of resource usage.<\/li>\n<\/ol>\n<p>In majority case, users can find the processing messages from the user folder.  <br \/>\nUsers need to check sys folder for messages beyond processing mini batches.  <br \/>\nlogs\/  <br \/>\nazureml\/: Logs from azureml dependencies. e.g. azureml.dataprep  <br \/>\nuser\/ : Logs generated when loading and running user's scripts.  <br \/>\nerror\/ : Logs of errors encountered while loading and running entry script.  <br \/>\nstderr\/ : stderr output of user's scripts.  <br \/>\nstdout\/ : stdout output of user's scripts.  <br \/>\nentry_script_log\/ : Logs generated by loggers of EntryScript()  <br \/>\n&lt;node seq&gt; :  <br \/>\nprocessNNN.log.txt : Logs generated by loggers of EntryScript() from each process.<\/p>",
        "Question_closed_time":1645670223417,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=60ea0bc6-9958-4a72-a07f-c7f2ff477569\">@Calabria Montero, Salvador (SGRE SE D FP&amp;DC WEF)  <\/a> Thanks for the question. Please follow the doc to view and log files for a run. Interactive logging sessions are typically used in notebook environments. The method Experiment.start_logging() starts an interactive logging session. Any metrics logged during the session are added to the run record in the experiment. The method run.complete() ends the sessions and marks the run as completed.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics#view-and-download-log-files-for-a-run\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics#view-and-download-log-files-for-a-run<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How does autoML actually calculate feature importance?",
        "Question_created_time":1645707636143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/749298\/how-does-automl-actually-calculate-feature-importa",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Do they use a sklearn feature selection method? I want to learn how they actually decide what features are more important than others (the ones shown in explain model). Going through the generated code doesn't reveal much to me.  <br \/>\nI see ExtraTreesRegressor, LGBMRegressor, PreFittedSoftVotingRegressor but I don't know if they're used for feature importance or something else.  <\/p>\n<p>Any advice really appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML Pipeline as an Artifacts in Azure Devops CI\/CD",
        "Question_created_time":1645623751260,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/747636\/aml-pipeline-as-an-artifacts-in-azure-devops-ci-cd",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a script that has multiple steps to preprocess, train, register model, and publish an AML pipeline.  <\/p>\n<p>Here is the code for AML pipeline:  <\/p>\n<pre><code>step_sequence = StepSequence(steps=[step1, step2,step3])\n    pipeline = Pipeline(workspace=ws, steps=step_sequence)\n\n    pipeline.validate()\n\n    # Submit a pipeline\n    pipeline.submit(experiment_name=e.experiment_name_train)\n    print(&quot;Pipeline submitted for execution.&quot;)\n\n    # Publish a pipeline\n    published_pipeline = pipeline.publish(\n        name='SomeName',\n        description=&quot;some Desc&quot;,\n        version=e.build_id\n    )\n    #Publish the pipeline to its versioned endpoint URI\n    publish_pipeline_to_endpoint(ws, published_pipeline)\n<\/code><\/pre>\n<p>In CI pipeline, we want publish the AML pipeline as an artifact so that it can be used in CD pipeline and deploy the same AML pipeline in test and prod.  <\/p>\n<p>Not just a model, we want to deploy whole AML pipeline.  <\/p>\n<p>Is there a way to do this?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problems with the creation of a compute instance using azure cli",
        "Question_created_time":1645190462707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/741739\/problems-with-the-creation-of-a-compute-instance-u",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello, I am introducing the concept of MLOps and right now I have a problem when I create a compute instance from devops. In order to create the compute instance from a devops pipeline, I use the azure cli to do this with the following code:    <\/p>\n<p>az ml computetarget create computeinstance -g $(RESOURCE_GROUP) -w $(WORKSPACE_NAME) -n $(amlcompute.instanceName) -s $(amlcompute.instancevmSize) -v    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/175810-ins3.png?platform=QnA\" alt=\"175810-ins3.png\" \/>    <\/p>\n<p>the command creates the compute instance, but I can't use the ML notebooks as the compute doesn't appear to be available. I have searched the web and everywhere they use the same cli code to create the compute instance.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/175829-ins1.png?platform=QnA\" alt=\"175829-ins1.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/175847-ins2.png?platform=QnA\" alt=\"175847-ins2.png\" \/>    <\/p>\n<p>I would appreciate knowing why it doesn't work this way    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MemoryError: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
        "Question_created_time":1645539137690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/745993\/memoryerror-unable-to-allocate-3-35-gib-for-an-arr",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I'm trying to deploy a model using Azure Machine Learning. In the init() method of the score.py (the entry script), I try to load in a Google Word2Vec model (<a href=\"https:\/\/mccormickml.com\/2016\/04\/12\/googles-pretrained-word2vec-model-in-python\/\">https:\/\/mccormickml.com\/2016\/04\/12\/googles-pretrained-word2vec-model-in-python\/<\/a>). When trying to create an endpoint, the following exception is thrown:   <\/p>\n<p>MemoryError: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32  <\/p>\n<p>I'm using a Standard_DS12_v2 compute instance, from which I would expect that the specified ram and storage should be sufficient to handle the 3.35 GiB.   <\/p>\n<p>Any suggested solutions? Thanks a lot<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML and Power BI integration",
        "Question_created_time":1645173232983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/741401\/azure-ml-and-power-bi-integration",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am following this tutorial to integrate Azure ML and Power BI:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-designer-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-designer-model<\/a>    <\/p>\n<p>The model Deployment stage is failing with the following error:     <\/p>\n<p>Deploy: Failed on Waiting real-time endpoint creation.     <br \/>\nDetails: AzureML service API error.     <br \/>\nWARNING:<strong>main<\/strong>:Looking for secret AML_MODEL_DC_STORAGE WARNING:<strong>main<\/strong>:no config found, using configfile INFO:azure.storage.common.storageclient:    <\/p>\n<p>...    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploying from Azure ML studio Designer is giving error in deploying real time inference endpoint",
        "Question_created_time":1645328557520,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/742817\/deploying-from-azure-ml-studio-designer-is-giving",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>2022\/02\/20 03:25:31 Downloading source code...  <br \/>\n2022\/02\/20 03:25:32 Finished downloading source code  <br \/>\n2022\/02\/20 03:25:32 Creating Docker network: acb_default_network, driver: 'bridge'  <br \/>\n2022\/02\/20 03:25:32 Successfully set up Docker network: acb_default_network  <br \/>\n2022\/02\/20 03:25:32 Setting up Docker configuration...  <br \/>\n2022\/02\/20 03:25:33 Successfully set up Docker configuration  <br \/>\n2022\/02\/20 03:25:33 Logging in to registry: c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io  <br \/>\n2022\/02\/20 03:25:33 Successfully logged into c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io  <br \/>\n2022\/02\/20 03:25:33 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'  <br \/>\n2022\/02\/20 03:25:33 Scanning for dependencies...  <br \/>\n2022\/02\/20 03:25:34 Successfully scanned dependencies  <br \/>\n2022\/02\/20 03:25:34 Launching container with name: acb_step_0  <br \/>\nSending build context to Docker daemon  66.56kB  <\/p>\n<p>Step 1\/21 : FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e  <br \/>\nmcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e: Pulling from azureml\/openmpi3.1.2-ubuntu18.04  <br \/>\n68e7bb398b9f: Already exists  <br \/>\n893c92dab848: Pulling fs layer  <br \/>\na0757eae439e: Pulling fs layer  <br \/>\nee2957a13303: Pulling fs layer  <br \/>\nf49a3daea774: Pulling fs layer  <br \/>\ncab73971ce79: Pulling fs layer  <br \/>\nc3d7fbfdaca2: Pulling fs layer  <br \/>\n0976efdf0829: Pulling fs layer  <br \/>\nd02e6f607e12: Pulling fs layer  <br \/>\nf49a3daea774: Waiting  <br \/>\ncab73971ce79: Waiting  <br \/>\nc3d7fbfdaca2: Waiting  <br \/>\n0976efdf0829: Waiting  <br \/>\nd02e6f607e12: Waiting  <br \/>\nee2957a13303: Verifying Checksum  <br \/>\nee2957a13303: Download complete  <br \/>\nf49a3daea774: Verifying Checksum  <br \/>\nf49a3daea774: Download complete  <br \/>\ncab73971ce79: Verifying Checksum  <br \/>\ncab73971ce79: Download complete  <br \/>\nc3d7fbfdaca2: Verifying Checksum  <br \/>\nc3d7fbfdaca2: Download complete  <br \/>\n0976efdf0829: Verifying Checksum  <br \/>\n0976efdf0829: Download complete  <br \/>\n893c92dab848: Verifying Checksum  <br \/>\n893c92dab848: Download complete  <br \/>\nd02e6f607e12: Verifying Checksum  <br \/>\nd02e6f607e12: Download complete  <br \/>\na0757eae439e: Verifying Checksum  <br \/>\na0757eae439e: Download complete  <br \/>\n893c92dab848: Pull complete  <br \/>\na0757eae439e: Pull complete  <br \/>\nee2957a13303: Pull complete  <br \/>\nf49a3daea774: Pull complete  <br \/>\ncab73971ce79: Pull complete  <br \/>\nc3d7fbfdaca2: Pull complete  <br \/>\n0976efdf0829: Pull complete  <br \/>\nd02e6f607e12: Pull complete  <br \/>\nDigest: sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e  <br \/>\nStatus: Downloaded newer image for mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e  <br \/>\n ---&gt; 8926027fde41  <br \/>\nStep 2\/21 : USER root  <br \/>\n ---&gt; Running in 0b57828c9289  <br \/>\nRemoving intermediate container 0b57828c9289  <br \/>\n ---&gt; 370ef8ee2d0f  <br \/>\nStep 3\/21 : RUN mkdir -p $HOME\/.cache  <br \/>\n ---&gt; Running in 3eee95c47f9f  <br \/>\nRemoving intermediate container 3eee95c47f9f  <br \/>\n ---&gt; 415459035e6d  <br \/>\nStep 4\/21 : WORKDIR \/  <br \/>\n ---&gt; Running in 08c6f83df4b1  <br \/>\nRemoving intermediate container 08c6f83df4b1  <br \/>\n ---&gt; 4216bc82e697  <br \/>\nStep 5\/21 : COPY azureml-environment-setup\/99brokenproxy \/etc\/apt\/apt.conf.d\/  <br \/>\n ---&gt; 03b433a4a6b8  <br \/>\nStep 6\/21 : RUN if dpkg --compare-versions <code>conda --version | grep -oE '[^ ]+$'<\/code> lt 4.4.11; then conda install conda==4.4.11; fi  <br \/>\n ---&gt; Running in a59290010c77  <br \/>\nRemoving intermediate container a59290010c77  <br \/>\n ---&gt; 5bc601b6dd21  <br \/>\nStep 7\/21 : COPY azureml-environment-setup\/mutated_conda_dependencies.yml azureml-environment-setup\/mutated_conda_dependencies.yml  <br \/>\n ---&gt; d43a193f0f3e  <br \/>\nStep 8\/21 : RUN ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} + &amp;&amp; ldconfig  <br \/>\n ---&gt; Running in 6f1452f548f8  <br \/>\nCollecting package metadata (repodata.json): ...working...   <br \/>\ndone  <br \/>\nSolving environment: ...working... done  <\/p>\n<p>Downloading and Extracting Packages  <\/p>\n<p>libblas-3.9.0        | 12 KB     |            |   0%   <br \/>\nlibblas-3.9.0        | 12 KB     | ########## | 100%   <\/p>\n<p>readline-7.0         | 391 KB    |            |   0%   <br \/>\nreadline-7.0         | 391 KB    | ########## | 100%   <\/p>\n<p>tk-8.6.12            | 3.3 MB    |            |   0%   <br \/>\ntk-8.6.12            | 3.3 MB    | #####1     |  51%   <br \/>\ntk-8.6.12            | 3.3 MB    | ########## | 100%   <br \/>\ntk-8.6.12            | 3.3 MB    | ########## | 100%   <\/p>\n<p>six-1.16.0           | 14 KB     |            |   0%   <br \/>\nsix-1.16.0           | 14 KB     | ########## | 100%   <\/p>\n<p>sqlite-3.28.0        | 1.9 MB    |            |   0%   <br \/>\nsqlite-3.28.0        | 1.9 MB    | ########## | 100%   <br \/>\nsqlite-3.28.0        | 1.9 MB    | ########## | 100%   <\/p>\n<p>ncurses-6.3          | 1012 KB   |            |   0%   <br \/>\nncurses-6.3          | 1012 KB   | ########## | 100%   <br \/>\nncurses-6.3          | 1012 KB   | ########## | 100%   <\/p>\n<p>libgfortran-ng-11.2. | 19 KB     |            |   0%   <br \/>\nlibgfortran-ng-11.2. | 19 KB     | ########## | 100%   <\/p>\n<p>openssl-1.1.1l       | 2.1 MB    |            |   0%   <br \/>\nopenssl-1.1.1l       | 2.1 MB    | ########## | 100%   <br \/>\nopenssl-1.1.1l       | 2.1 MB    | ########## | 100%   <\/p>\n<p>zlib-1.2.11          | 86 KB     |            |   0%   <br \/>\nzlib-1.2.11          | 86 KB     | ########## | 100%   <\/p>\n<p>libcblas-3.9.0       | 12 KB     |            |   0%   <br \/>\nlibcblas-3.9.0       | 12 KB     | ########## | 100%   <\/p>\n<p>libgomp-11.2.0       | 426 KB    |            |   0%   <br \/>\nlibgomp-11.2.0       | 426 KB    | ########## | 100%   <\/p>\n<p>_libgcc_mutex-0.1    | 3 KB      |            |   0%   <br \/>\n_libgcc_mutex-0.1    | 3 KB      | ########## | 100%   <\/p>\n<p>libzlib-1.2.11       | 59 KB     |            |   0%   <br \/>\nlibzlib-1.2.11       | 59 KB     | ########## | 100%   <\/p>\n<p>libffi-3.2.1         | 47 KB     |            |   0%   <br \/>\nlibffi-3.2.1         | 47 KB     | ########## | 100%   <\/p>\n<p>pip-20.2.4           | 1.1 MB    |            |   0%   <br \/>\npip-20.2.4           | 1.1 MB    | ########## | 100%   <br \/>\npip-20.2.4           | 1.1 MB    | ########## | 100%   <\/p>\n<p>setuptools-58.0.4    | 966 KB    |            |   0%   <br \/>\nsetuptools-58.0.4    | 966 KB    | ########## | 100%   <br \/>\nsetuptools-58.0.4    | 966 KB    | ########## | 100%   <\/p>\n<p>xz-5.2.5             | 343 KB    |            |   0%   <br \/>\nxz-5.2.5             | 343 KB    | ########## | 100%   <br \/>\nxz-5.2.5             | 343 KB    | ########## | 100%   <\/p>\n<p>python_abi-3.6       | 4 KB      |            |   0%   <br \/>\npython_abi-3.6       | 4 KB      | ########## | 100%   <\/p>\n<p>numpy-1.19.5         | 5.3 MB    |            |   0%   <br \/>\nnumpy-1.19.5         | 5.3 MB    | ######9    |  70%   <br \/>\nnumpy-1.19.5         | 5.3 MB    | ########## | 100%   <br \/>\nnumpy-1.19.5         | 5.3 MB    | ########## | 100%   <\/p>\n<p>joblib-1.1.0         | 210 KB    |            |   0%   <br \/>\njoblib-1.1.0         | 210 KB    | ########## | 100%   <\/p>\n<p>libgfortran5-11.2.0  | 1.7 MB    |            |   0%   <br \/>\nlibgfortran5-11.2.0  | 1.7 MB    | ########## | 100%   <br \/>\nlibgfortran5-11.2.0  | 1.7 MB    | ########## | 100%   <\/p>\n<p>ca-certificates-2021 | 139 KB    |            |   0%   <br \/>\nca-certificates-2021 | 139 KB    | ########## | 100%   <\/p>\n<p>wheel-0.37.1         | 31 KB     |            |   0%   <br \/>\nwheel-0.37.1         | 31 KB     | ########## | 100%   <\/p>\n<p>_openmp_mutex-4.5    | 22 KB     |            |   0%   <br \/>\n_openmp_mutex-4.5    | 22 KB     | ########## | 100%   <\/p>\n<p>scikit-surprise-1.0. | 636 KB    |            |   0%   <br \/>\nscikit-surprise-1.0. | 636 KB    | ########## | 100%   <br \/>\nscikit-surprise-1.0. | 636 KB    | ########## | 100%   <\/p>\n<p>libopenblas-0.3.18   | 9.6 MB    |            |   0%   <br \/>\nlibopenblas-0.3.18   | 9.6 MB    | ######2    |  63%   <br \/>\nlibopenblas-0.3.18   | 9.6 MB    | #########8 |  99%   <br \/>\nlibopenblas-0.3.18   | 9.6 MB    | ########## | 100%   <\/p>\n<p>libgcc-ng-11.2.0     | 904 KB    |            |   0%   <br \/>\nlibgcc-ng-11.2.0     | 904 KB    | ########## | 100%   <br \/>\nlibgcc-ng-11.2.0     | 904 KB    | ########## | 100%   <\/p>\n<p>libstdcxx-ng-11.2.0  | 4.2 MB    |            |   0%   <br \/>\nlibstdcxx-ng-11.2.0  | 4.2 MB    | ########## | 100%   <br \/>\nlibstdcxx-ng-11.2.0  | 4.2 MB    | ########## | 100%   <\/p>\n<p>python-3.6.8         | 30.1 MB   |            |   0%   <br \/>\npython-3.6.8         | 30.1 MB   | #6         |  17%   <br \/>\npython-3.6.8         | 30.1 MB   | ######2    |  63%   <br \/>\npython-3.6.8         | 30.1 MB   | ########## | 100%   <br \/>\npython-3.6.8         | 30.1 MB   | ########## | 100%   <\/p>\n<p>liblapack-3.9.0      | 12 KB     |            |   0%   <br \/>\nliblapack-3.9.0      | 12 KB     | ########## | 100%   <br \/>\nPreparing transaction: ...working... done  <br \/>\nVerifying transaction: ...working... done  <br \/>\nExecuting transaction: ...working... done  <br \/>\nInstalling pip dependencies: ...working...   <br \/>\nRan pip subprocess with arguments:  <br \/>\n['\/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt']  <br \/>\nPip subprocess output:  <br \/>\nCollecting azureml-designer-classic-modules==0.0.161  <br \/>\n  Downloading azureml_designer_classic_modules-0.0.161-py3-none-any.whl (403 kB)  <br \/>\nCollecting en_core_web_sm  <br \/>\n  Downloading <a href=\"https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz\">https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz<\/a> (11.1 MB)  <br \/>\nCollecting spacy==2.1.7  <br \/>\n  Downloading spacy-2.1.7-cp36-cp36m-manylinux1_x86_64.whl (30.8 MB)  <br \/>\nCollecting azureml-model-management-sdk  <br \/>\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)  <br \/>\nCollecting azure-storage-blob==1.5.0  <br \/>\n  Downloading azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)  <br \/>\nCollecting azureml-designer-internal==0.0.56  <br \/>\n  Downloading azureml_designer_internal-0.0.56-py3-none-any.whl (28 kB)  <br \/>\nCollecting seaborn==0.10.0  <br \/>\n  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)  <br \/>\nCollecting gensim==3.8.3  <br \/>\n  Downloading gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)  <br \/>\nCollecting lightgbm==3.2.1  <br \/>\n  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)  <br \/>\nCollecting chardet==3.0.4  <br \/>\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)  <br \/>\nCollecting joblib==0.14.0  <br \/>\n  Downloading joblib-0.14.0-py2.py3-none-any.whl (294 kB)  <br \/>\nCollecting scipy==1.4.1  <br \/>\n  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)  <br \/>\nCollecting nimbusml==1.6.1  <br \/>\n  Downloading nimbusml-1.6.1-cp36-none-manylinux1_x86_64.whl (105.2 MB)  <br \/>\nCollecting matplotlib==3.1.3  <br \/>\n  Downloading matplotlib-3.1.3-cp36-cp36m-manylinux1_x86_64.whl (13.1 MB)  <br \/>\nCollecting pandas==1.0.4  <br \/>\n  Downloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)  <br \/>\nCollecting scikit-learn==0.22.2  <br \/>\n  Downloading scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)  <br \/>\nCollecting imbalanced-learn==0.4.3  <br \/>\n  Downloading imbalanced_learn-0.4.3-py3-none-any.whl (166 kB)  <br \/>\nCollecting Pillow==8.3.2  <br \/>\n  Downloading Pillow-8.3.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)  <br \/>\nCollecting azureml-interpret==1.36.0  <br \/>\n  Downloading azureml_interpret-1.36.0-py3-none-any.whl (52 kB)  <br \/>\nCollecting blis&lt;0.3.0,&gt;=0.2.2  <br \/>\n  Downloading blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)  <br \/>\nCollecting plac&lt;1.0.0,&gt;=0.9.6  <br \/>\n  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)  <br \/>\nRequirement already satisfied, skipping upgrade: numpy&gt;=1.15.0 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from spacy==2.1.7-&gt;-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 3)) (1.19.5)  <br \/>\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0  <br \/>\n  Downloading murmurhash-1.0.6-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)  <br \/>\nCollecting cymem&lt;2.1.0,&gt;=2.0.2  <br \/>\n  Downloading cymem-2.0.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)  <br \/>\nCollecting srsly&lt;1.1.0,&gt;=0.0.6  <br \/>\n  Downloading srsly-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (184 kB)  <br \/>\nCollecting requests&lt;3.0.0,&gt;=2.13.0  <br \/>\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)  <br \/>\nCollecting thinc&lt;7.1.0,&gt;=7.0.8  <br \/>\n  Downloading thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)  <br \/>\nCollecting preshed&lt;2.1.0,&gt;=2.0.1  <br \/>\n  Downloading preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83 kB)  <br \/>\nCollecting wasabi&lt;1.1.0,&gt;=0.2.0  <br \/>\n  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)  <br \/>\nRequirement already satisfied, skipping upgrade: six&gt;=1.10 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from azureml-model-management-sdk-&gt;-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 4)) (1.16.0)  <br \/>\nCollecting adal&gt;=0.4.5  <br \/>\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)  <br \/>\nCollecting dill&gt;=0.2.7.1  <br \/>\n  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)  <br \/>\nCollecting python-dateutil&gt;=2.5.3  <br \/>\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)  <br \/>\nCollecting liac-arff&gt;=2.1.1  <br \/>\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)  <br \/>\nCollecting pytz&gt;=2017.2  <br \/>\n  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)  <br \/>\nCollecting azure-storage-common~=1.4  <br \/>\n  Downloading azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)  <br \/>\nCollecting azure-common&gt;=1.1.5  <br \/>\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)  <br \/>\nCollecting azureml-pipeline-core==1.36.0  <br \/>\n  Downloading azureml_pipeline_core-1.36.0-py3-none-any.whl (313 kB)  <br \/>\nCollecting azureml-defaults==1.36.0  <br \/>\n  Downloading azureml_defaults-1.36.0-py3-none-any.whl (3.0 kB)  <br \/>\nCollecting azureml-telemetry==1.36.0.*  <br \/>\n  Downloading azureml_telemetry-1.36.0-py3-none-any.whl (30 kB)  <br \/>\nCollecting cffi==1.12.3  <br \/>\n  Downloading cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl (430 kB)  <br \/>\nCollecting azureml-designer-core==0.0.68  <br \/>\n  Downloading azureml_designer_core-0.0.68-py3-none-any.whl (101 kB)  <br \/>\nCollecting smart-open&gt;=1.8.1  <br \/>\n  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)  <br \/>\nRequirement already satisfied, skipping upgrade: wheel in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from lightgbm==3.2.1-&gt;azureml-designer-classic-modules==0.0.161-&gt;-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (0.37.1)  <br \/>\nCollecting dotnetcore2&gt;=2.1.2  <br \/>\n  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)  <br \/>\nCollecting kiwisolver&gt;=1.0.1  <br \/>\n  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)  <br \/>\nCollecting cycler&gt;=0.10  <br \/>\n  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)  <br \/>\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1  <br \/>\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)  <br \/>\nCollecting interpret-community==0.21.*  <br \/>\n  Downloading interpret_community-0.21.0-py3-none-any.whl (136 kB)  <br \/>\nCollecting azureml-core~=1.36.0  <br \/>\n  Downloading azureml_core-1.36.0.post2-py3-none-any.whl (2.4 MB)  <br \/>\nCollecting certifi&gt;=2017.4.17  <br \/>\n  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)  <br \/>\nCollecting idna&lt;4,&gt;=2.5; python_version &gt;= &quot;3&quot;  <br \/>\n  Downloading idna-3.3-py3-none-any.whl (61 kB)  <br \/>\nCollecting charset-normalizer~=2.0.0; python_version &gt;= &quot;3&quot;  <br \/>\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)  <br \/>\nCollecting urllib3&lt;1.27,&gt;=1.21.1  <br \/>\n  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)  <br \/>\nCollecting tqdm&lt;5.0.0,&gt;=4.10.0  <br \/>\n  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)  <br \/>\nCollecting PyJWT&lt;3,&gt;=1.0.0  <br \/>\n  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)  <br \/>\nCollecting cryptography&gt;=1.1.0  <br \/>\n  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)  <br \/>\nCollecting configparser==3.7.4  <br \/>\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)  <br \/>\nCollecting json-logging-py==0.2  <br \/>\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)  <br \/>\nCollecting azureml-inference-server-http~=0.4.1  <br \/>\n  Downloading azureml_inference_server_http-0.4.9-py3-none-any.whl (52 kB)  <br \/>\nCollecting azureml-dataset-runtime[fuse]~=1.36.0  <br \/>\n  Downloading azureml_dataset_runtime-1.36.0-py3-none-any.whl (3.5 kB)  <br \/>\nCollecting applicationinsights  <br \/>\n  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)  <br \/>\nCollecting pycparser  <br \/>\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)  <br \/>\nCollecting pycryptodomex==3.7.3  <br \/>\n  Downloading pycryptodomex-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (7.5 MB)  <br \/>\nCollecting pyarrow==0.16.0  <br \/>\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)  <br \/>\nCollecting distro==1.4.0  <br \/>\n  Downloading distro-1.4.0-py2.py3-none-any.whl (17 kB)  <br \/>\nCollecting ruamel.yaml==0.16.10  <br \/>\n  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)  <br \/>\nCollecting more-itertools==6.0.0  <br \/>\n  Downloading more_itertools-6.0.0-py3-none-any.whl (52 kB)  <br \/>\nCollecting jsonschema==3.0.1  <br \/>\n  Downloading jsonschema-3.0.1-py2.py3-none-any.whl (54 kB)  <br \/>\nCollecting interpret-core[required]&lt;=0.2.6,&gt;=0.1.20  <br \/>\n  Downloading interpret_core-0.2.6-py3-none-any.whl (6.5 MB)  <br \/>\nCollecting packaging  <br \/>\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)  <br \/>\nCollecting shap&lt;=0.39.0,&gt;=0.20.0  <br \/>\n  Downloading shap-0.39.0.tar.gz (356 kB)  <br \/>\nCollecting numba&lt;0.54.0  <br \/>\n  Downloading numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)  <br \/>\nCollecting ndg-httpsclient&lt;=0.5.1  <br \/>\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)  <br \/>\nCollecting jmespath&lt;1.0.0  <br \/>\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)  <br \/>\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0  <br \/>\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)  <br \/>\nCollecting backports.tempfile  <br \/>\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)  <br \/>\nCollecting msrest&lt;1.0.0,&gt;=0.5.1  <br \/>\n  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)  <br \/>\nCollecting azure-mgmt-containerregistry&gt;=2.0.0  <br \/>\n  Downloading azure_mgmt_containerregistry-9.0.0-py3-none-any.whl (937 kB)  <br \/>\nCollecting jsonpickle&lt;3.0.0  <br \/>\n  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)  <br \/>\nCollecting SecretStorage&lt;4.0.0  <br \/>\n  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)  <br \/>\nCollecting azure-mgmt-keyvault&lt;10.0.0,&gt;=0.40.0  <br \/>\n  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)  <br \/>\nCollecting pathspec&lt;1.0.0  <br \/>\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)  <br \/>\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0  <br \/>\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)  <br \/>\nCollecting contextlib2&lt;22.0.0  <br \/>\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)  <br \/>\nCollecting msrestazure&lt;=0.6.4,&gt;=0.4.33  <br \/>\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)  <br \/>\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1  <br \/>\n  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)  <br \/>\nCollecting pyopenssl&lt;21.0.0  <br \/>\n  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)  <br \/>\nCollecting docker&lt;6.0.0  <br \/>\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)  <br \/>\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0  <br \/>\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)  <br \/>\nCollecting sanic-cors~=1.0.1  <br \/>\n  Downloading Sanic_Cors-1.0.1-py2.py3-none-any.whl (17 kB)  <br \/>\nCollecting inference-schema~=1.3.1  <br \/>\n  Downloading inference_schema-1.3.1-py3-none-any.whl (20 kB)  <br \/>\nCollecting protobuf~=3.17.3  <br \/>\n  Downloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)  <br \/>\nCollecting grpcio-tools~=1.38.1  <br \/>\n  Downloading grpcio_tools-1.38.1-cp36-cp36m-manylinux2014_x86_64.whl (2.5 MB)  <br \/>\nCollecting aiohttp~=3.7.4.post0  <br \/>\n  Downloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)  <br \/>\nCollecting aiotask-context~=0.6.1  <br \/>\n  Downloading aiotask_context-0.6.1-py3-none-any.whl (3.5 kB)  <br \/>\nCollecting opencensus-ext-azure~=1.1.0  <br \/>\n  Downloading opencensus_ext_azure-1.1.1-py2.py3-none-any.whl (42 kB)  <br \/>\nCollecting gunicorn==20.1.0; platform_system != &quot;Windows&quot;  <br \/>\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)  <br \/>\nCollecting tritonclient[all]~=2.11.0  <br \/>\n  Downloading tritonclient-2.11.0-py3-none-manylinux1_x86_64.whl (7.7 MB)  <\/p>\n<p>failed  <br \/>\n [91m  <\/p>\n<p>==&gt; WARNING: A newer version of conda exists. &lt;==  <br \/>\n  current version: 4.9.2  <br \/>\n  latest version: 4.11.0  <\/p>\n<p>Please update conda by running  <\/p>\n<pre><code>$ conda update -n base -c defaults conda\n<\/code><\/pre>\n<p>Pip subprocess error:  <br \/>\nERROR: Could not find a version that satisfies the requirement sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults==1.36.0-&gt;azureml-designer-internal==0.0.56-&gt;azureml-designer-classic-modules==0.0.161-&gt;-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (from versions: 0.1.0, 0.1.1, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.4, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 18.12.0, 19.3.1, 19.6.0, 19.6.2, 19.6.3, 19.9.0, 19.12.0, 19.12.2, 19.12.3, 19.12.4, 19.12.5, 20.3.0, 20.6.0, 20.6.1, 20.6.2, 20.6.3, 20.9.0, 20.9.1, 20.12.0, 20.12.1, 20.12.2, 20.12.3, 20.12.4, 20.12.5, 20.12.6)  <br \/>\nERROR: No matching distribution found for sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1-&gt;azureml-defaults==1.36.0-&gt;azureml-designer-internal==0.0.56-&gt;azureml-designer-classic-modules==0.0.161-&gt;-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1))  <\/p>\n<p>CondaEnvException: Pip failed  <\/p>\n<p> [0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} + &amp;&amp; ldconfig' returned a non-zero code: 1  <br \/>\n2022\/02\/20 03:27:17 Container failed during run: acb_step_0. No retries remaining.  <br \/>\nfailed to run step ID: acb_step_0: exit status 1  <\/p>\n<p>Run ID: cf6 failed after 1m47s. Error: failed during run, err: exit status 1  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export metadata file of componenets and its parameters  of trained and submitted model  in AzureML  designer",
        "Question_created_time":1645272036680,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/742573\/export-metadata-file-of-componenets-and-its-parame",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello , I'm new to azureML and I have a question about Azure ML designer , after creating  a workflow (drag and drop components , let's say problem of linear  regression ) can I export, download a file of the  metadata of the workflow that  contains the names of components used and its parameters.  <br \/>\nif it's possible can automate the process of creating a workflow in azureML designer by using already exsiting metadata file (json, xml , yaml ... ) similar to the one mentioned previously.   <\/p>\n<p>if there any other services in azure that's capable of solving this issue please feel free to mention it   <\/p>\n<p>thank youu.<\/p>",
        "Question_closed_time":1645441227963,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=ca3ed354-350d-4b5d-be80-486f8db9ec5b\">@Achraf DRIDI  <\/a> Yes, you can export your designer experiment as a pipeline. The option to export is available from the designer from the top right hand corner. This is basically a cli command that helps you export the experiment in two ways.    <\/p>\n<ol>\n<li> Shallow     <\/li>\n<li> Deep    <\/li>\n<\/ol>\n<p><strong>UPDATE<\/strong>    <br \/>\nThe feature mentioned above is in private preview and not available to all users. Exact ETA not available at this point of time.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How long does it take to use a resource after you creat it?",
        "Question_created_time":1645195183417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/741883\/how-long-does-it-take-to-use-a-resource-after-you",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I cannot see my machine learning resource I created.  <br \/>\nAfter you create a resource under the resource group, how long does it take to actually see it and start using it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning app for Excel incorrect positive and negative sentiment - feedback?",
        "Question_created_time":1645107466670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/740005\/azure-machine-learning-app-for-excel-incorrect-pos",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>We have just trialled the Azure ML excel add in and used the sentiment analyser. The majority of results are coming back with false positive and negative results. Where would we feedback our results to support development and is there support out there for new users? Ended up here and the support ticket system was unclear as to which ticket area to allocate.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failed to test real time end point",
        "Question_created_time":1616676852747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/331539\/failed-to-test-real-time-end-point",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am able to deploy model successfully but every time when am testing endpoint I get this error.   <br \/>\nFailed to test real-time endpoint. Service temporarily unavailable. Please try again later.  <\/p>\n<p>Can somebody help here to fix this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Private endpoint in hub-and-spoke architecture (Try to access a storage account in my different vnets)",
        "Question_created_time":1644509273567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/730824\/private-endpoint-in-hub-and-spoke-architecture-(tr",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm trying to register a dataset in my different Azure Machine Learning workspaces (of each vnet spoke) but for that <strong>I need to connect from my ML workspaces to my storage account<\/strong> (dev or prod) located in the vnet 'spoke-pdata'. (screenshot)     <\/p>\n<p>The datastore (refer to storage account) is already register with Access key.     <br \/>\nI have already checked:    <\/p>\n<ul>\n<li> peering between my hub and my different spoke    <\/li>\n<li> private dns zone (privatelink.blob.core.windows.net) in my hub vnet with <strong>record set for storage<\/strong>     <\/li>\n<li> all virtual network links between hub and each spoke (privatelink blob)    <\/li>\n<li> private dns zone (privatelink.api.azureml.ms) in my hub vnet with <strong>record set for each azure machine learning<\/strong>     <\/li>\n<li> all virtual network links between hub and each spoke (privatelink azureml)    <\/li>\n<li> storage account roles for each azure ML    <\/li>\n<li> contributor role for each azure ml in storage account (to be sure it's not role issue)    <\/li>\n<li> NSG off for storage account     <\/li>\n<\/ul>\n<p>When I set ''All network'' in network of my storage account, Azure ML is connected to my storage account and I can register my dataset... So it's a network issue.    <br \/>\nI tried nslookup in AML and I can get the private ip of my storage account:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173224-unknown.png?platform=QnA\" alt=\"173224-unknown.png\" \/>    <\/p>\n<p>What did I forget? Maybe I misunderstood the concept of private endpoint... From my point of view, I just need a private endpoint connected to a private dns. And in case there are two different vnet, I need to connect them with a private link and a vnet peering.     <br \/>\nI read the documentation but did not find a similar case... I am still confused.    <\/p>\n<p>Error:     <br \/>\n*    <\/p>\n<blockquote>\n<p>ScriptExecutionException was caused by StreamAccessException.    <br \/>\n  StreamAccessException was caused by AuthenticationException.    <br \/>\n    Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthorizationFailure'. Please make sure the SAS token or the account key is correct.    <br \/>\n      Failed due to inner exception of type: StorageException    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173262-effij.png?platform=QnA\" alt=\"173262-effij.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clean Up instructions at the end of the module to stop compute resources.",
        "Question_created_time":1643823950947,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/720158\/clean-up-instructions-at-the-end-of-the-module-to",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I am currently doing cloudskillschallenge for getting certified in Azure Data Scientist course and I came across a point in <strong>Module 6 : &quot;Use automated machine learning in Azure Machine Learning&quot;<\/strong> that says &quot;After completing each module, be sure to follow the Clean Up instructions at the end of the module to stop your compute resources. Stopping your compute ensures your subscription won't be charged for compute resources.&quot;  <\/p>\n<p>I have opted for the free trial in Azure portal and would like to know how to do the said process of removing the instructions.  <\/p>\n<p>Regards,  <br \/>\nTuhin  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Batch Endpoint: How to correctly submit dataset to batch endpoint",
        "Question_created_time":1644854452957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/734672\/azure-ml-batch-endpoint-how-to-correctly-submit-da",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I built a model using auto ML and deployed it as a batch endpoint.  <br \/>\nWhen I re-use the same dataset  I used to train the data I get an error:  <\/p>\n<blockquote>\n<p>ValueError: Length mismatch: Expected axis has 1 elements, new values have 7 elements  <\/p>\n<\/blockquote>\n<p>I assume, I have to convert the whole thing into some kind of batch first?  <br \/>\nI didn't find documentation on how to convert a structured table dataset to a batch. Does anyone know how to do this?  <\/p>\n<p>Thank you for the help, best, Max  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML deployment fails",
        "Question_created_time":1644780118307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/733521\/azure-ml-deployment-fails",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to deploy an ML model as a WebService using <code>Azure ML Endpoints<\/code>, but it fails. Below is the code and the error I get. I'm using azureml-core SDK for this.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173839-model-deploy-error.png?platform=QnA\" alt=\"173839-model-deploy-error.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173855-error.png?platform=QnA\" alt=\"173855-error.png\" \/>    <\/p>\n<p>I'm using this link as a reference for my deployment:    <br \/>\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpqie8i33i\/MLmodel'  - Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pool",
        "Question_created_time":1643645716927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/716755\/filenotfounderror-(errno-2)-no-such-file-or-direct",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,<\/p>\n<p>I am following the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">tutorial<\/a> score machine learning models using PREDICT.<\/p>\n<p>I receive the following error: FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpqie8i33i\/MLmodel'<\/p>\n<p>In a previous <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/667458\/filenotfounderror-errno-2-score-machine-learning-m.html?childToView=674770#comment-674770\">post<\/a> it was advised to ensure to upload the mlflow folder to AML, not the parent folder to AML.<\/p>\n<p>Could I get a bit more clarity on these steps as I was unable to solve my issue.<\/p>\n<p>Thanks in advance,<\/p>\n<p>Adam  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169944-image.png?platform=QnA\" alt=\"![169973-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169944-image.png?platform=QnA\">3<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Python Azure SDK Having Trouble Importing tsv data; pandas error",
        "Question_created_time":1644536309460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/731321\/python-azure-sdk-having-trouble-importing-tsv-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to get some cosmos data into an azure ml compute instance. I've done this a bunch of times but for some reason this particular set of data is giving me trouble, and I'm not sure why. I've removed all punctuation and special characters from the source data and the data is small enough for pandas to handle. I tried to download an entire stream but that failed so I downloaded a partial stream. The only glitch was a partial row of data on the final row but that is an artifact of a partial stream download, not the underlying data. Here's a link to one of the source files on cosmos that has caused issue:<\/p>\n<p><a href=\"https:\/\/aad.cosmos15.osdinfra.net\/cosmos\/xbox.quality.prod\/shares\/IEBKS.PartnerProd\/cooked\/xcloud\/xCloudBi\/AdrianAntico\/Retention-\">https:\/\/aad.cosmos15.osdinfra.net\/cosmos\/xbox.quality.prod\/shares\/IEBKS.PartnerProd\/cooked\/xcloud\/xCloudBi\/AdrianAntico\/Retention-<\/a>  <br \/>\nEngagement\/LatencyServerFrameV2Raw_2022_01-12_14.tsv?property=info<\/p>\n<p>Here's the code I'm running in a compute instance to transfer data from blob storage to the compute instance directory:<\/p>\n<pre><code>import os\nimport azureml\nfrom azureml.core import Workspace, Dataset\nimport pandas as pd\n\n# Root Path\nRootPath = os.getcwd()\n\n# MetaData # I hid the values below but they work\nsubscription_id = '' \nresource_group = ''\nworkspace_name = ''\n\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\ninlist = [\n  'LatencyServerFrameV2Raw_2022_01-12_14',\n  'LatencyServerFrameV2Raw_2022_01-15_18',\n  'LatencyServerFrameV2Raw_2022_01-19_22',\n  'LatencyServerFrameV2Raw_2022_01-23_26',\n  'LatencyServerFrameV2Raw_2022_01-27_30',\n  'LatencyServerFrameV2Raw_2022_01-31_03',\n  'LatencyServerFrameV2Raw_2022_02-04_07']\n\n\n# Import all data\nfor dd in inlist:  \n  dataset = Dataset.get_by_name(workspace, name=f&quot;{dd}.tsv&quot;)\n  Path1 = RootPath + f&quot;\/Latency\/NanoLatencyRawData\/{dd}.csv&quot;\n  df = dataset.to_pandas_dataframe()                                                  # the error occurs on this step !!!!!\n  del dataset\n  df.to_csv(Path1)\n  del df\n<\/code><\/pre>\n<p>UserErrorException: UserErrorException:  <br \/>\nMessage: Execution failed in operation 'to_pandas_dataframe' for Dataset(id='7cea1b1e-30df-4536-a859-d0931e52962a', name='LatencyServerFrameV2Raw_2022_02-04_07.tsv', version=3, error_code=ScriptExecution.StreamAccess.Validation,error_message=ScriptExecutionException was caused by StreamAccessException.  <br \/>\nStreamAccessException was caused by ValidationException.  <br \/>\nUnable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: [REDACTED]  <br \/>\nFailed due to inner exception of type: DecoderFallbackException  <br \/>\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7) ErrorCode: ScriptExecution.StreamAccess.Validation  <br \/>\nInnerException  <br \/>\nError Code: ScriptExecution.StreamAccess.Validation<\/p>\n<blockquote>\n<p>&gt;&gt; dataset<\/p>\n<\/blockquote>\n<p>{  <br \/>\n&quot;source&quot;: [  <br \/>\n&quot;('retention_engagement_dimention', '\/local\/data\/cooked\/xcloud\/xCloudBi\/AdrianAntico\/Retention-Engagement\/LatencyServerFrameV2Raw_2022_02-04_07.tsv')&quot;  <br \/>\n],  <br \/>\n&quot;definition&quot;: [  <br \/>\n&quot;GetDatastoreFiles&quot;,  <br \/>\n&quot;ParseDelimited&quot;,  <br \/>\n&quot;DropColumns&quot;,  <br \/>\n&quot;SetColumnTypes&quot;  <br \/>\n],  <br \/>\n&quot;registration&quot;: {  <br \/>\n&quot;id&quot;: &quot;7cea1b1e-30df-4536-a859-d0931e52962a&quot;,  <br \/>\n&quot;name&quot;: &quot;LatencyServerFrameV2Raw_2022_02-04_07.tsv&quot;,  <br \/>\n&quot;version&quot;: 3,  <br \/>\n&quot;workspace&quot;: &quot;Workspace.create(name='xCloudML', subscription_id='09b5fdb3-165d-4e2b-8ca0-34f998d176d5', resource_group='xCloudData')&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>Validation Error Code: InvalidEncoding  <br \/>\nValidation Target: TextFile  <br \/>\nFailed Step: 10a002a3-6c2b-4173-9b00-43cb4d8d0011  <br \/>\nError Message: ScriptExecutionException was caused by StreamAccessException.  <br \/>\nStreamAccessException was caused by ValidationException.  <br \/>\nUnable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: Unable to translate bytes [EF] at index 382 from specified code page to Unicode.  <br \/>\nUnable to translate bytes [EF] at index 382 from specified code page to Unicode.  <br \/>\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Execution failed in operation 'to_pandas_dataframe' for Dataset(id='7cea1b1e-30df-4536-a859-d0931e52962a', name='LatencyServerFrameV2Raw_2022_02-04_07.tsv', version=3, error_code=ScriptExecution.StreamAccess.Validation,error_message=ScriptExecutionException was caused by StreamAccessException.\\n StreamAccessException was caused by ValidationException.\\n Unable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: [REDACTED]\\n Failed due to inner exception of type: DecoderFallbackException\\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7) ErrorCode: ScriptExecution.StreamAccess.Validation&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to edit azure machine learning PATH?",
        "Question_created_time":1626631760570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/480031\/how-to-edit-azure-machine-learning-path",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>how to edit azure machine learning path?  <\/p>\n<p>I'm trying to run a script and I'm getting this error message:  <br \/>\nExecutableNotFound: failed to execute 'dot', make sure the Graphviz executables are on your systems' PATH<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I solve this ML Studio Classic error ?",
        "Question_created_time":1644552367593,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/731370\/how-do-i-solve-this-ml-studio-classic-error",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173364-error-image.png?platform=QnA\" alt=\"173364-error-image.png\" \/>    <\/p>\n<p>Hi,     <\/p>\n<p>I just used the platform for 2 days and I'm now unable to enter to access my models I have created. Not sure if it's a problem with my account or just the whole server is down... I understand we need to switch to Azure Machine Learning by 31 August 2024 looks like there is still time right? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Real-time inferencing with azure ml model and send output to databricks",
        "Question_created_time":1644441202260,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/729370\/real-time-inferencing-with-azure-ml-model-and-send",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,  <br \/>\nI've built and registered a basic ml model in azure ml studio and I will get an aks cluster for the purpose of doing real-time inferencing with the model. So our pipipline would be we get the real time data from eventhub in databricks and store it into datalake(datastore) near real-time then azure ml model will get the input data from datalake, inference the data and generate output and send the output back to the databricks. and finally we want to visualize the output in powerbi.  <br \/>\nBut I'm just wondering if it's possible to do it as I'm new to azure ml. I was thinking to use stream analytics but seems like I can't get an approval from my company for using stream analytics for this pipeline.  <\/p>\n<p>Anyone who could help me on this would be every much appreciated. and I'd appreicate it if you could tell me how to connct azure ml model and databricks using API as well.   <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to import Microsoft.RelInfra.Common.Exception so that it could be properly handled?",
        "Question_created_time":1643997368443,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/723386\/how-to-import-microsoft-relinfra-common-exception",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am working on creating a Pipeline Endpoint and want to handle the exception if incorrect Pipeline endpoint name is passed to the constructor:  <\/p>\n<p><em>PipelineEndpoint.get(workspace, name='xyz')<\/em>  <\/p>\n<p>In this case, I am seeing a <em>&quot;Microsoft.RelInfra.Common.Exceptions.ErrorResponseException:PipelineEndpoint name xyz not found in workspace&quot;<\/em>.  <\/p>\n<p>From where to import this exception class??  <\/p>\n<p>Please advise.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"After deploying getting error 502 while generating forecast in Azure Ml through Code",
        "Question_created_time":1644405738470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/728627\/after-deploying-getting-error-502-while-generating",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <br \/>\nAfter doing the deployment task, i am not able to generate the forecast through code pipeline of Azure Ml.  <br \/>\nthis is my run.py file:<\/p>\n<p>def run(df, url, api_key):  <br \/>\nallowSelfSignedHttps(True)  <br \/>\nif api_key == 'uu':  <br \/>\napi_key = ''  <br \/>\ndata = []  <br \/>\nfor index, row in list(df.iterrows()):  <br \/>\ndata.append(dict(row))<\/p>\n<pre><code>data = {\n\n    &quot;data&quot;: data\n}\n\nbody = str.encode(json.dumps(data))\nheaders = {'Content-Type': 'application\/json',\n           'Authorization': ('Bearer ' + api_key)}\n\nreq = urllib.request.Request(url, body, headers)\nprint(url, api_key)\ntry:\n    response = urllib.request.urlopen(req)\n    result = response.read()\n    print(result)\nexcept urllib.error.HTTPError as error:\n    print(&quot;The request failed with status code: &quot; + str(error.code))\n\n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    print(error.info())\n    # print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n\ndata = json.loads(json.load(response))\ndf= pd.json_normalize(data[result])\ndata = data.get('forecast', None)\nreturn data\n<\/code><\/pre>\n<p>Error: 502<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Subscription Cost",
        "Question_created_time":1644315390737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/726898\/azure-subscription-cost",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>my azure subscription cost is decreasing everyday. Knowing that i have deleted everything from my workspace and in my azureml workspace don't have any cluster, I don't know why it is still decreasing.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/172214-image.png?platform=QnA\" alt=\"172214-image.png\" \/>    <\/p>",
        "Question_closed_time":1644316889220,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>If you want to review your costs and what resources are being charged, then the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/cost-management-billing-overview#understand-cost-management\">Cost Analysis blade<\/a> will allow you to drill down work this out. Please let us know if this helps    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Execute R Script - characters not displaying on saved image",
        "Question_created_time":1643900146447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721637\/execute-r-script-characters-not-displaying-on-save",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p><strong>Updated this question with new information:<\/strong><\/p>\n<p>Using Azure ML Studio &amp; Execute R Script to run some existing models. I need to generate outputs with saved plots which I am doing with the openxlsx package and saving the outputs to some azure cloud storage. This part all works well. The problem is that the plots do not have characters displayed correctly, instead they are &quot;squares&quot;<\/p>\n<p>I have recreated the problem with some repeatable code using the data in ggplot2. This is the relevant code snippet that I am running in an &quot;azureml_main&quot; function. This example I actually copied from another azure help page to keep things simple and compatible as possible : <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Tutorial-Base-R-Graphics-in-AzureML-2\">https:\/\/gallery.azure.ai\/Experiment\/Tutorial-Base-R-Graphics-in-AzureML-2<\/a><\/p>\n<pre><code>  imageName &lt;- &quot;testplot.png&quot;  \n  png(imageName)  \n  plot(price ~ carat, data = diamonds, main = &quot;Price vs Carat&quot;)  \n  dev.off()  \n  wb &lt;- createWorkbook()  \n  addWorksheet(wb, &quot;testplotsheet&quot;, gridLines = TRUE)  \n  insertImage(wb, &quot;testplotsheet&quot;, imageName)  \n  saveWorkbook(wb, file = xlName, overwrite = TRUE)  \n<\/code><\/pre>\n<p>On retrieving the saved excel workbook, this is what the image looks like<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171081-savedpng-nochars.jpg?platform=QnA\" alt=\"171081-savedpng-nochars.jpg\" \/><\/p>\n<p>The problem is to get characters to display correctly. The same problem occurs in tiff, jpg svg formats. But pdf displays fonts! On further investigation I am wondering if there are actually any system fonts installed on this compute cluster machine because the folders \/usr\/lib\/share\/fonts &amp; \/usr\/share\/fonts do not exist<\/p>\n<p>Can anyone at microsoft check &amp; confirm this (seems a bit of an oversight?) or advise where the fonts are installed for this &quot;Execute R script&quot; machine<\/p>\n<p>Here are some data from the azureml instance sessionInfo<\/p>\n<blockquote>\n<p>R version 3.5.1 (2018-07-02)  <br \/>\nPlatform: x86_64-conda_cos6-linux-gnu (64-bit)  <br \/>\nRunning under: Ubuntu 18.04.6 LTS<\/p>\n<p>Matrix products: default  <br \/>\nBLAS: \/azureml-envs\/azureml_6ff64eff0a652bbe0bb1d84fc0884554\/lib\/R\/lib\/libRblas.so  <br \/>\nLAPACK: \/azureml-envs\/azureml_6ff64eff0a652bbe0bb1d84fc0884554\/lib\/R\/lib\/libRlapack.so<\/p>\n<p>locale:  <br \/>\n<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171081-savedpng-nochars.jpg?platform=QnA\">1<\/a> LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8  <br \/>\n[4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8  <br \/>\n[7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C  <br \/>\n[10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C<\/p>\n<p>attached base packages:  <br \/>\n<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171081-savedpng-nochars.jpg?platform=QnA\">1<\/a> stats graphics grDevices utils datasets methods base<\/p>\n<p>other attached packages:  <br \/>\n<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171081-savedpng-nochars.jpg?platform=QnA\">1<\/a> httr_1.4.1 RODBC_1.3-16 tibble_3.0.1 tidyr_1.0.2  <br \/>\n[5] stringr_1.4.0 data.table_1.12.8 azuremlsdk_1.10.0 openxlsx_4.2.5  <br \/>\n[9] dplyr_0.8.5 jsonlite_1.6.1 reticulate_1.12<\/p>\n<p>loaded via a namespace (and not attached):  <br \/>\n<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171081-savedpng-nochars.jpg?platform=QnA\">1<\/a> Rcpp_1.0.8 magrittr_1.5 tidyselect_1.0.0 lattice_0.20-41  <br \/>\n[5] R6_2.4.1 rlang_1.0.1 tools_3.5.1 grid_3.5.1  <br \/>\n[9] ellipsis_0.3.0 assertthat_0.2.1 lifecycle_0.2.0 crayon_1.3.4  <br \/>\n[13] Matrix_1.2-18 zip_2.2.0 purrr_0.3.4 vctrs_0.2.4  <br \/>\n[17] glue_1.4.0 stringi_1.4.3 compiler_3.5.1 pillar_1.4.3  <br \/>\n[21] pkgconfig_2.0.3<\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Hyperdrive warm start error",
        "Question_created_time":1644098638560,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/723990\/azure-ml-hyperdrive-warm-start-error",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I've attempted to do a warm start on an Azure ML Hyperdrive run, following this tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters#warm-start-hyperparameter-tuning-optional\">how-to-tune-hyperparameters<\/a>    <\/p>\n<p>I am given the following error after 15 minutes: Hyperdrive is unable to further process the experiment due to some internal error. Experiment has been marked as failed. Reason: MaxDeliveryCountExceeded, ErrorDescription: Message could not be consumed after 5 delivery attempts.    <\/p>\n<p>This is the only feedback in the hyperdrive.txt log, and it is the only log with anything in it. Does anyone have any insight into what this error could mean and how to resolve it?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Executing pipeline in AML from Logic Apps stopped working",
        "Question_created_time":1639583614587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/664994\/executing-pipeline-in-aml-from-logic-apps-stopped",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello! I have a few logic apps for my company that trigger ML pipelines at specific time intervals. I followed the documentation on how to set up a logic app and trigger pipeline to the letter and for the past 2 months everything was working fine and my logic apps were able to trigger the ML pipelines with no issues. However, on 12\/08\/2021 at exactly in between 1:30PM - 2:30PM CST, every single pipeline starting failing and they continue to do so up until now. I noticed that we are now receiving this error on every execution:  <\/p>\n<p>&quot;UserError: Response status code does not indicate success: 400 (User starting the run is not an owner or assigned user to the Compute Instance). User starting the run is not an owner or assigned user to the Compute Instance&quot;  <\/p>\n<p>My Logic apps are setup with &quot;Managed Identities&quot; of Owners (like the documentation explains). My last successful run for all the logic apps was on 12\/08 before 1:30PM CST. Did something change on both Azure Logic Apps and Azure ML that is now causing this issue? Any help is greatly appreciated as this is impacting my company's business.<\/p>",
        "Question_closed_time":1639690591763,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>I ran into this same issue in a slightly different context. I didn't manage to figure out the root cause but managed to resolve it in practice by standing up a Compute Cluster instead of a Compute Instance (see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python<\/a>)<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learing - Batch Scoring with ParallelRunConfig output_action='summary_only'",
        "Question_created_time":1643895433557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721542\/azure-machine-learing-batch-scoring-with-parallelr",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have deployed a batch inferencing service and I want to save minibatch results in a json format. My understanding after reading the ParallelRunConfig documentation is that for output_action=&quot;append_row&quot; you can return only list or pandas dataframe objects in the run() function.   <br \/>\nI have tried to change output_action='summary_only' but nothing is saved into the datastore anymore.   <br \/>\nI could not find any examples on how to use  output_action='summary_only' except the below explanation, which does not give details on how to store the output:  <\/p>\n<p><em>'append_row' \u2013 All values output by run() method invocations will be aggregated into one unique file named parallel_run_step.txt that is created in the output location.  <br \/>\n'summary_only' \u2013 User script is expected to store the output by itself. An output row is still expected for each successful input item processed. The system uses this output only for error threshold calculation (ignoring the actual value of the row).<\/em>  <\/p>\n<p>Do you know how can I save the results of each minibatch of the run() function as a json into the datastore?  <\/p>\n<p>Thank you,  <br \/>\nDaniel   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"RunHistory finalization failed: ServiceException: \tCode: 400",
        "Question_created_time":1643880887487,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721282\/runhistory-finalization-failed-serviceexception-co",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to log my model metrics and hyperparam space in the run metrics.     <br \/>\nI tried to also reduce the variable lengths throughout but still get consistently the following error:     <br \/>\ni find in the documentation that we can only have 15 columns for every row in the run metric.    <br \/>\n <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity<\/a> . But is there a way to increase this capacity? Thanks    <\/p>\n<p> Is there a way to increase this capacity?     <\/p>\n<pre><code>RunHistory finalization failed: ServiceException:  \n Code: 400  \n Message: (UserError) A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n Details:  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See  \n  \n<\/code><\/pre>",
        "Question_closed_time":1643903062357,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2dc066be-691a-47bd-9f7a-67e426d994d9\">@Antara Das  <\/a> Some of the limits are soft limits which can be increased for a subscription or a workspace. Usually these limits can be increased by using a support case with appropriate usage scenario mentioned in the details of the case. Once the case is submitted it is reviewed by the service team and the limits are increased if it is possible to do so.     <\/p>\n<p>Please create a support case from Azure portal and use the following settings from the drop downs and mention the summary detail as &quot;Increase limit of columns per metric row&quot;    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171018-image.png?platform=QnA\" alt=\"171018-image.png\" \/>    <\/p>\n<p>If you do not have a valid support subscription we could help you with a one time free support case that could help you to create one for this scenario.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"'message': 'User errors were found in at least one of the child runs.'",
        "Question_created_time":1643808927707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/719823\/message-user-errors-were-found-in-at-least-one-of",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>image_config_yolov5 = AutoMLImageConfig(task=ImageTask.IMAGE_OBJECT_DETECTION,    <br \/>\n                                        compute_target=compute_target,  <br \/>\n                                        training_data=training_dataset,  <br \/>\n                                        validation_data=validation_dataset,  <br \/>\n                                        hyperparameter_sampling=GridParameterSampling({'model_name': choice('yolov5')}),  <br \/>\n                                        iterations=1)  <br \/>\nautoml_image_run = experiment.submit(image_config_yolov5)    <br \/>\nautoml_image_run.wait_for_completion(wait_post_processing=True)    <\/p>\n<p>while running this code am getting this error. Am not getting what this error means.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/170498-cfapture.png?platform=QnA\" alt=\"170498-cfapture.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I query perform SQL query by joining table 1 from (Prodution) database 1 to table 2 from (Production) databse 2? The result to be saved as a table in database 3 (Development)",
        "Question_created_time":1643778504613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/719171\/can-i-query-perform-sql-query-by-joining-table-1-f",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Perform AZURE SQL query by joining table 1 from (Azure Prodution) database 1 to table 2 from (Azure Production) database 2?   <br \/>\nThe result to be saved as a table in database 3 (Development)  <\/p>\n<p>Eg.   <\/p>\n<p>SELECT  T1.CustomerID, T2.CustomerName  <br \/>\nFROM database1.SalesTable AS T1  <br \/>\nLEFT JOIN database2.CustomerTable AS T2  <\/p>\n<p>ON database1.SalesTable.CustomerID = database2.CustomerTable  <\/p>",
        "Question_closed_time":1643780375360,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hey,  <br \/>\nIt is possible by couple of ways:<\/p>\n<p>1) Create an external table in either of the Production database:  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql\/database\/elastic-query-getting-started-vertical\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql\/database\/elastic-query-getting-started-vertical<\/a><\/p>\n<p>Then in Azure data factory use a copy activity to have your query as source and your sink as the table 3 in database dev.  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/connector-sql-server\">https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/connector-sql-server<\/a><\/p>\n<p>But based on the amount of data there might be performance issues due to elastic query so we can go with the below approach :<\/p>\n<p>2) use data flow to join both the data from table 1 and table 2 and copy into table 3<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Random Forest",
        "Question_created_time":1642600143767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/701327\/random-forest",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p> I am currently working on Career Guidance prediction using Machine Learning.  <\/p>\n<p>The dataset has 38 features. For feature selection I tried using mutual_info_classif for getting the mutual information of my features and got the list of important features.  <\/p>\n<p>The Second approach I followed is using SelectKBest with mutual_info_classif as my score_func. On this approach I got some other list of features.  <\/p>\n<p>Is it normal to get different results ?  <br \/>\nCan anyone please help me out?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best Practise\/How to deploy one algorihtm many models",
        "Question_created_time":1642980954963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/706471\/best-practise-how-to-deploy-one-algorihtm-many-mod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Greetings,  <br \/>\nI plan to use LightGBM for forecasting. However, I could have upwards of 3000 nodes I plan to forecast. This would mean tuning them all initially and then training them as and when they require a forecast. I wanted to use Azure ML and call it as a service but not seeing from the documentation or searches for the best way to deploy a single algorithm, use it to tune and then later call it for training. Is this something Azure supports or am I better just creating my own web app and API to that than using Azure ML Studio?  <\/p>\n<p>Any help would be greatly appreciated. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - error during the creation Create a control script",
        "Question_created_time":1643753509637,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/718873\/azure-machine-learning-error-during-the-creation-c",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am reproducing this tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a>     \/   Create a control script. The next observations appear in the console.    <\/p>\n<p>I will thank you if some ideas are shared with me to face this issue.    <\/p>\n<p>Regards    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/170304-image.png?platform=QnA\" alt=\"170304-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/170305-image.png?platform=QnA\" alt=\"170305-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/170333-image.png?platform=QnA\" alt=\"170333-image.png\" \/>    <\/p>",
        "Question_closed_time":1643789056330,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2caa2c24-ad4a-4fc1-a593-45ebcad8dcaa\">@Anth0ny Camp0s  <\/a> I believe the error is because in the config command you are using the script parameter <code>hello.py<\/code> which is in <code>.\/src<\/code> directory but because you are already in <code>.\/src<\/code> directory on the terminal and the <code>source_directory<\/code> parameter also mentions to use <code>.\/src<\/code> as the path to the file the following error is indicated in the message.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/170491-image.png?platform=QnA\" alt=\"170491-image.png\" \/>    <\/p>\n<p>If you navigate back to <code>get-started<\/code> directory in your terminal and run the script <code>run-hello.py<\/code> your experiment should be created successfully.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning - Deployment of real-time endpoint works in westeurope but fails in eastus.",
        "Question_created_time":1643123451253,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/709396\/azure-machine-learning-deployment-of-real-time-end",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I encountered the following situation when I run a Python real-time deployment Notebook script in 2 different Resource Groups, one is based in eastus and the other in westeurope:    <br \/>\nIt works for the westeurope Resource Group: <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/168381-weast-europe-run.png?platform=QnA\" alt=\"168381-weast-europe-run.png\" \/>    <br \/>\nWhen I run it in eastus Resource Group I get the following error: <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/168347-east-us-error.png?platform=QnA\" alt=\"168347-east-us-error.png\" \/>    <\/p>\n<p>Notebook configuration: Standard_DS12_v2 (4 cores, 28 GB RAM, 56 GB disk) and azureml.core.VERSION==1.34.0 for both Resource Groups.    <\/p>\n<p>Has anyone encountered this problem before?     <\/p>\n<p>Let me know if any other details are needed.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml' in ML Studio",
        "Question_created_time":1643140351313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/709861\/modulenotfounderror-no-module-named-azureml-in-ml",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am learning Azure ML from Microsoft tutorials, <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\">here<\/a>. The third tutorial is giving me the following error.    <\/p>\n<pre><code>[stderr]Traceback (most recent call last):  \n[stderr]  File &quot;train.py&quot;, line 8, in &lt;module&gt;  \n[stderr]    from azureml.core import Run  \n[stderr]ModuleNotFoundError: No module named 'azureml'  \n[stderr]  \n<\/code><\/pre>\n<p>Working with Azure ML Studio and submitting the code to the environment, I am unable to find how to resolve this error.    <\/p>\n<p>I have checked that the package is installed (running on Azure ML studio so this is a basic assumption, but I have tested as well). Following is the code 'run-pytorch.py' which calls the script 'train.py'    <\/p>\n<pre><code># run-pytorch.py  \nfrom azureml.core import Workspace  \nfrom azureml.core import Experiment  \nfrom azureml.core import Environment  \nfrom azureml.core import ScriptRunConfig  \n  \nif __name__ == &quot;__main__&quot;:  \n    ws = Workspace.from_config()  \n    experiment = Experiment(workspace=ws, name='day1-experiment-train')  \n    config = ScriptRunConfig(source_directory='.\/src',  \n                             script='train.py',  \n                             compute_target='cpu-cluster')  \n  \n    # set up pytorch environment  \n    env = Environment.from_conda_specification(  \n        name='pytorch-env',  \n        file_path='pytorch-env.yml'  \n    )  \n    config.run_config.environment = env  \n  \n    run = experiment.submit(config)  \n  \n    aml_url = run.get_portal_url()  \n    print(aml_url)  \n    print('Success...!!!')  \n<\/code><\/pre>\n<p>The code snippet for train.py is as follows    <\/p>\n<pre><code># train.py  \nimport os  \nimport argparse  \nimport torch  \nimport torch.optim as optim  \nimport torchvision  \nimport torchvision.transforms as transforms  \nfrom model import Net  \nfrom azureml.core import Run  \n...  \n...  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Migrar experimentos , n\u00e3o dados, do ML Classic para portal.azure.com",
        "Question_created_time":1643664196263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/717183\/migrar-experimentos-n-o-dados-do-ml-classic-para-p",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Tive que abrir uma conta paga no portal azure e gostaria de migrar os experimentos do ML Classic para l\u00e1.  <br \/>\nEu j\u00e1 sei como fazer com os dados, a quest\u00e3o s\u00e3o os \u00edcones arraste e solte.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ML how should my score script look like to deploy my ml model",
        "Question_created_time":1643317719657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/713048\/azure-ml-how-should-my-score-script-look-like-to-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\nI've created made an basic ml model just for the demo purpose and    <br \/>\nhere is the sample output from the model that I want to send to the eventhub from azure ml,    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169203-image.png?platform=QnA\" alt=\"169203-image.png\" \/>    <\/p>\n<p>I know I need score.py script when deploying the model and I wonder how the score script should be like to get the desired output that I want.    <\/p>\n<p>any help would be very appreciated.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The azure cli command \"az ml attach folder\" is directly adding .azureml directory to .amlignore , so where to put config.json when using Azure devops pipeline to submit script to aml workspace?",
        "Question_created_time":1643414978747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/714713\/the-azure-cli-command-az-ml-attach-folder-is-direc",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello MS team,<\/p>\n<p>I am using Azure devOps pipeline to submit a control script to the Azure-ML workspace. This control script in turn kicks off the Azure-ML pipeline containing pythonscriptsteps and hyperdrive step.<\/p>\n<p><strong>My directory structure:<\/strong><\/p>\n<p>.  <br \/>\n\u251c\u2500\u2500\u2500.vscode  <br \/>\n\u251c\u2500\u2500\u2500Automation  <br \/>\n\u251c\u2500\u2500\u2500Build  <br \/>\n\u2514\u2500\u2500\u2500Source  <br \/>\n\u251c\u2500\u2500\u2500.azureml  <br \/>\n\u251c\u2500\u2500\u2500.vscode  <br \/>\n\u251c\u2500\u2500\u2500amlcode  <br \/>\n\u2502 \u251c\u2500\u2500\u2500projectcode  <br \/>\n\u2502 \u2514\u2500\u2500\u2500<strong>pycache<\/strong>  <br \/>\n\u251c\u2500\u2500\u2500config  <br \/>\n\u251c\u2500\u2500\u2500Data  <br \/>\n\u251c\u2500\u2500\u2500setup  <br \/>\n\u251c\u2500\u2500\u2500tests  <br \/>\n\u2502 \u251c\u2500\u2500\u2500.pytest_cache  <br \/>\n\u2502 \u2502 \u2514\u2500\u2500\u2500v  <br \/>\n\u2502 \u2502 \u2514\u2500\u2500\u2500cache  <br \/>\n\u2502 \u2514\u2500\u2500\u2500<strong>pycache<\/strong>  <br \/>\n\u2514\u2500\u2500\u2500<strong>pycache<\/strong><\/p>\n<p>So here one of the azure cli task in Azure DevOps pipeline uses:<\/p>\n<p><em>az ml folder attach -w $(azureml.workspaceName) -g $(azureml.resourceGroup)<\/em><\/p>\n<p><strong>This command attaches my whole directory to the AML workspace and automatically creates &quot;.amlignore&quot; and &quot;.azureml&quot; is automatically added to that.<\/strong><\/p>\n<p>So it is throwing an authentication error as the <em>config.json()<\/em> is not found because it is generally put in the path <em>\/.azureml<\/em>.<\/p>\n<p>Where to put the config.json() then? What is the best practice?<\/p>",
        "Question_closed_time":1643613417497,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6755dac2-30f1-48a2-9d0d-4d2c96edc5d4\">@Shivapriya Katta  <\/a> The command az ml folder attach will create the directories and add the config file to .azureml to ensure the workspace resources are easily accessible. You can lookup the note section of the command for <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/reference-azure-machine-learning-cli\">reference<\/a>.    <\/p>\n<blockquote>\n<p>This command creates a .azureml subdirectory that contains example runconfig and conda environment files. It also contains a config.json file that is used to communicate with your Azure Machine Learning workspace.    <\/p>\n<\/blockquote>\n<p>The authentication error in your case could be because <code>az login<\/code> command might have been missed which allows the cli to authenticate interactively or service principal or MI and then run rest of the commands. You can try to run <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/authenticate-azure-cli\">this<\/a> and check if the attach works successfully.     <\/p>\n<p>Also, with the devops pipeline I am not sure if <code>az devops login<\/code>  is required to be run but if the above command fails even after <code>az login<\/code> authentication you can try <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/devops\/cli\/?view=azure-devops\">az devops login<\/a>.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to parameterize the sharable url of an azure ml notebook?",
        "Question_created_time":1643398754623,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/714542\/is-it-possible-to-parameterize-the-sharable-url-of",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I would like to share the link to a Jupyter notebook (stored in azure ml studio) with the parameters of the notebook already updated. I see I can automatically get a sharable link for the notebook. Is it possible to parameterize this link? If not, is there an equivalent alternative?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how do I deploy a ml model with cpu cluster?",
        "Question_created_time":1643474757900,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/715101\/how-do-i-deploy-a-ml-model-with-cpu-cluster",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi..I'm new to Azure ML and I've been trying to deploy a ml model I've created and registered.  <br \/>\nSince I can't deploy a model to aci or aks and don't have those clusters,I need to deploy the model using my cpu cluster.  <br \/>\nI'm looking up docs but couldn't find any tutorial for deploying a model with cpu cluster.  <br \/>\nSo I wonder if any of azure ml experts here could help me with doing this..  <\/p>\n<p>I would appreciate your help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning conda env package(pyenchant)",
        "Question_created_time":1643330999837,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/713217\/machine-learning-conda-env-package(pyenchant)",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have pip install pyenchant, but It doesn't seem to be working.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169225-image.png?platform=QnA\" alt=\"169225-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169252-image.png?platform=QnA\" alt=\"169252-image.png\" \/>    <\/p>\n<p>Is there any other way?    <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/21083059\/enchant-c-library-not-found-while-installing-pyenchant-using-pip-on-osx\">https:\/\/stackoverflow.com\/questions\/21083059\/enchant-c-library-not-found-while-installing-pyenchant-using-pip-on-osx<\/a>    <br \/>\nI looked it up but do not know where to put it    <br \/>\nThanks!<\/p>",
        "Question_closed_time":1643357543967,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c427e306-40a4-4da4-b489-b3f6aae251d7\">@Yongchao Liu (Neusoft America Inc)  <\/a> Based on the error it looks like you also need to ensure the enchant C library is available to use for the package. Based on the pip install <a href=\"https:\/\/pyenchant.github.io\/pyenchant\/install.html#installation\">page<\/a> of pyenchant, the package will not work directly out of the box using pip.    <\/p>\n<blockquote>\n<p>In general, PyEnchant will not work out of the box after having been installed with pip. See the Installation section for more details.    <\/p>\n<\/blockquote>\n<p>Since you are using Linux, this is the guidance on the installation page.    <\/p>\n<blockquote>\n<p>The quickest way is to install libenchant using the package manager of your current distribution. PyEnchant tries to be compatible with a large number of libenchant versions. If you find an incompatibility with your libenchant installation, feel free to open a bug report.    <\/p>\n<p>To detect the libenchant binaries, PyEnchant uses ctypes.util.find_library(), which requires ldconfig, gcc, objdump or ld to be installed. This is the case on most major distributions, however statically linked distributions (like Alpine Linux) might not bring along binutils by default.    <\/p>\n<\/blockquote>\n<p>I believe you are using the ubuntu flavor of the azureml base image, In this case I think adding <a href=\"https:\/\/ubuntu.pkgs.org\/20.04\/ubuntu-main-amd64\/libenchant-2-dev_2.2.8-1_amd64.deb.html\">libenchant-2-dev<\/a> as dependency in your YAML should work.     <\/p>\n<pre><code>-libenchant-2-dev=2.2.8  \n<\/code><\/pre>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to migrate a completed Azure data labelling project to Custom Vision ?",
        "Question_created_time":1643343651050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/713444\/is-it-possible-to-migrate-a-completed-azure-data-l",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I've recently labelled approx. 3500 images for a multi-class classification project and wondered if I could use the Custom Vision service to train the data (for a prototype demo) ?  <\/p>\n<p>If not, is there a way to access the model created using the Auto Labelling feature and use it as an end point (In Javascript) ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error 1000 on Microsoft Machine Learning",
        "Question_created_time":1643361646673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/713788\/error-1000-on-microsoft-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi everyone,    <br \/>\nI'm using Azure Studio (Microsoft Machine Learning Studio (classic)) to run R script.    <\/p>\n<p>I'm trying to run a loop to find auc on 1,000 times.    <\/p>\n<p>The loop and the code run perfectly when the iterator is up to 100, and fail on 1,000.    <\/p>\n<p>The error is:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/169422-image.png?platform=QnA\" alt=\"169422-image.png\" \/>    <\/p>\n<p>Thanks for your help!    <\/p>\n<p>The full script is:    <br \/>\n    install.packages (&quot;AUC&quot;, repos= &quot;https:\/\/cran.microsoft.com\/snapshot\/2022-01-13\/&quot;)  <\/p>\n<pre><code># Map 1-based optional input ports to variables  \nuniversal_bank.df &lt;- maml.mapInputPort(1) # class: data.frame  \n  \nComputeUAC &lt;- function( seed ){  \n  #split data  \n  set.seed( seed )  \n  train.index &lt;- sample(1:dim( universal_bank.df )[1], dim( universal_bank.df )*0.6)  \n  train.df &lt;- universal_bank.df[train.index , ]  \n  valid.df &lt;- universal_bank.df[-train.index , ]  \n    \n  library(party)  \n  tr &lt;- ctree( Personal.Loan ~. , data = train.df  )  \n  plot(tr, type = &quot;simple&quot;)  \n  \n  pred &lt;- predict( tr, newdata = valid.df )  \n    \n  \n  library(AUC)  \n  r &lt;- roc( pred, as.factor(valid.df$Personal.Loan) )  \n  #plot(r)  \n  UAC &lt;- auc(r)  \n    \n  return ( UAC )  \n  \n}  \n  \nUAC_arr &lt;- c()  \nfor( seed in c(1:10000)){  \n  UAC_arr &lt;- c( UAC_arr , ComputeUAC( seed ) )  \n}  \n  \nboxplot(UAC_arr);  \n  \nUAC_arr.df &lt;- as.data.frame( UAC_arr )  \n  \n# Select data.frame to be sent to the output Dataset port  \nmaml.mapOutputPort(&quot;UAC_arr.df&quot;);  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azuer ml How can I use model version 1 if I delete model  version  1",
        "Question_created_time":1642560823080,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/700512\/azuer-ml-how-can-i-use-model-version-1-if-i-delete",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/166176-image.png?platform=QnA\" alt=\"166176-image.png\" \/>    <\/p>\n<p>I don't know where to find version 1    <\/p>\n<p>Thanks <\/p>",
        "Question_closed_time":1642596489783,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c427e306-40a4-4da4-b489-b3f6aae251d7\">@Yongchao Liu (Neusoft America Inc)  <\/a> Usually if you click on the model the previous versions are available to view and use. If you have deleted the previous versions then I think it is no longer available.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/166393-image.png?platform=QnA\" alt=\"166393-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Car damage detection using azure machine learning or azure artificial intelligence",
        "Question_created_time":1643020905263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/707265\/car-damage-detection-using-azure-machine-learning",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi. Can someone please guide me how to detect damages in the car from car images using Azure Machine Learning or Azure AI?   <\/p>\n<p>I'm planning to use image classification computer vision solution as a first step to classify if car is damaged or not, then as a second step use object detection to identify which parts of the car are damaged.  <\/p>\n<p>I'm a beginner in AI and ML. Am I going with the correct approach or is there any other way to solve my problem?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't test real-time endpoint",
        "Question_created_time":1642850859443,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/705771\/cant-test-real-time-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,    <\/p>\n<p>The text box where I am meant to enter the input to test my endpoint doesn't let me enter anything. The deployment state is currently healthy.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/167290-image.png?platform=QnA\" alt=\"167290-image.png\" \/>    <\/p>\n<p>I can test the webservice directly without any issues. I also have the same issue with multiple browsers!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Models not being registered when pipeline is triggered using REST endpoint",
        "Question_created_time":1641571746503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/687290\/models-not-being-registered-when-pipeline-is-trigg",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a pipeline with two python script steps. The first script performs some data cleaning, and the second one trains a model, saves it in the 'outputs' folder, and finally calls the <code>Model.register()<\/code> function to register the updated model file. Just to be clear, the registration is being done in the script that trains the model (which runs on the cloud), <em>not<\/em> the script that starts the experiment (which runs on my laptop).  <\/p>\n<p>It works as it should when I run the experiment using the <code>Experiment.submit()<\/code> function call, but when I run the published pipeline using the REST endpoint, the model doesn't get registered. I can see the REST call recorded as a new experiment, and the 'outputs' folder of the second step has a model file too. But the new model doesn't get registered for some reason.   <\/p>\n<p>Does anyone know what's going wrong here?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"One tenant ID ( Root inheriter ) and another subsction ID creating problem for Azure ML-SDK",
        "Question_created_time":1642202294597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/696233\/one-tenant-id-(-root-inheriter-)-and-another-subsc",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello everyone,<\/p>\n<p>My laptop is borrowed from University Tech Department since I am a GTA there. Though I opened my own account taking Microsoft Azure subscription ( one month free ) when I'm trying to create a workspace and other related stuff using AzureML-SDK it sends me the following error message:<\/p>\n<p>&quot;&quot;  <br \/>\nMessage: You are currently logged-in to 762ebf40-80b2-40ba ********* tenant. You don't have access to &lt;74595002-4d5f-4c26-871c-*********&gt; subscription, please check if it is in this tenant.  <br \/>\nAll the subscriptions that you have access to in this tenant are =  <br \/>\n[SubscriptionInfo(subscription_name='Azure subscription 1', subscription_id='74595002-4d5f-4c****************')].  <br \/>\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azure ml<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/165322-azure-sub.jpg?platform=QnA\" alt=\"165322-azure-sub.jpg\" \/>-SDK.  <br \/>\n&quot;&quot;<\/p>\n<p>Since it was owned by the tech department I believe it has access to the administration's azure subscription - which I can't find a way to get around to have access of my subscription to use AzureML-SDK.<\/p>\n<p>The last user ( in the photo ) is from the tech department - who is the administrative user of this laptop. Could the knowledgeable admins\/members kindly suggest what can I do to keep using azure using my own subscription? Any kind suggestion is much appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Get API",
        "Question_created_time":1642420332357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/697928\/azure-get-api",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>We are trying to develop a python code which will return a json of all VMs for given Azure region along with its vCPU, Ram, pricing as per OS etc.     <\/p>\n<p>However after one hour it is getting expired. Here is the reference link for the API we are using.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/virtual-machine-sizes\/list#code-try-0\">https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/virtual-machine-sizes\/list#code-try-0<\/a>    <\/p>\n<p>How can we extend this one hour expiry to 1-3months?     <\/p>\n<p>Regards,     <br \/>\nShreeshail<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issues with SQL Alchemy whilst deploying real time endpoint on ACI",
        "Question_created_time":1642105094927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/694586\/issues-with-sql-alchemy-whilst-deploying-real-time",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I'm trying to deploy an image to an ACI using Azure Machine Learning. One of the requirements\/installations is sqlalchemy.  <\/p>\n<p>When building the image, sqlalchemy seems to install correctly. However, when I try to import the sqlalchemy modules within the code, the deployment to the ACI fails and I can't work out why.  <\/p>\n<p>Anyone had any similar issues - let me know if I need to provide any more info.  <\/p>\n<p>Thanks,  <\/p>\n<p>Cam<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Specify disk storage type",
        "Question_created_time":1636713894743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/625035\/azure-machine-learning-specify-disk-storage-type",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>Is there a way to specify the disk storage type for Compute instances?     <br \/>\nBoth the Azure portal and ARM templates do not have an option to define the disk storage type, which defaults to the P10 disks (Premium SSD).     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/148883-azureml-compute.png?platform=QnA\" alt=\"148883-azureml-compute.png\" \/>Thanks    <\/p>",
        "Question_closed_time":1636952401093,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=41b4924d-c8f5-4ca4-9844-0c0af46eb5d5\">@Simon Magrin  <\/a>  Thanks, Currently There's no way to change the disk storage type for CIs or compute clusters. We have added this to our product backlog item to support in the near future.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Cannot find created compute instance",
        "Question_created_time":1642537079270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/700065\/cannot-find-created-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have created a compute instance and it is not available at the compute instances list. Instead it shows a &quot;create new&quot; button.    <br \/>\nI can see the instance at usage+quotas but when I click on it , it says the compute instance cannot be found.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/165990-screenshot-2022-01-18-221429.jpg?platform=QnA\" alt=\"165990-screenshot-2022-01-18-221429.jpg\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/166155-screenshot-2022-01-18-221538.jpg?platform=QnA\" alt=\"166155-screenshot-2022-01-18-221538.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dark Cluster",
        "Question_created_time":1642592185800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/701109\/dark-cluster",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I would like to know how to integrate dark cluster with Azure Compute Target (Cluster).  <\/p>\n<p>As a suggestion, I think there should be an option to create a dark cluster in Azure ML Studio.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem: AML Designer - Batch Inference Pipeline",
        "Question_created_time":1639744934170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/667479\/problem-aml-designer-batch-inference-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi Team,     <\/p>\n<p>When I Submit the Batch Inference Pipeline. It is working.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158498-1-image-designer.png?platform=QnA\" alt=\"158498-1-image-designer.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158597-2-image-designer.png?platform=QnA\" alt=\"158597-2-image-designer.png\" \/>    <\/p>\n<p>After submitting, I can see the file:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158519-3-image-designer.png?platform=QnA\" alt=\"158519-3-image-designer.png\" \/>    <\/p>\n<p>Then when I Publish, the file is not in the Datastore. The file is not generated again. I didn't get an error.    <\/p>\n<p>Kind regards,     <br \/>\nAnaid    <\/p>",
        "Question_closed_time":1642583796710,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=4bb27b25-616e-491c-b986-136b5bf96f77\">@Anaid  <\/a>     <\/p>\n<p>Hi,    <\/p>\n<p>I\u2019ve enabled one-time Free Technical Support for you.  To create the support request, please do the following:     <\/p>\n<p>\u2022            Go to the Health Advisory section within the Azure Portal: <a href=\"https:\/\/aka.ms\/healthadvisories\">https:\/\/aka.ms\/healthadvisories<\/a>      <br \/>\n\u2022            Select the Issue Name &quot;You have been enabled for one-time Free Technical Support&quot;     <br \/>\n\u2022            Details will populate below in the Summary Tab within the reading pane and you can click on the link &quot;Create a Support Request&quot; to the right of the message    <\/p>\n<p>Let me know what your support request number is so that I can keep track of your case. If you run into any issues, feel free to let me know.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to load .ipynb file in Azure Machine Learning Workspace",
        "Question_created_time":1642489248987,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/699144\/unable-to-load-ipynb-file-in-azure-machine-learnin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey all,    <\/p>\n<p>I experienced the issue below. To summarize, I cannot open .ipynb file in my azure machine learning workspace.    <\/p>\n<p>I have tried and ensure that the notebooks are under ~\/cloudfiles\/code\/Users\/ folder so it is visible to Jupyter environment.     <\/p>\n<p>Can anyone give suggestions\/guidance on how to resolve the issue?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/165932-image.png?platform=QnA\" alt=\"165932-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Notebook, Kernel Not Connected or Was Deleted",
        "Question_created_time":1642481695177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/698918\/azure-ml-notebook-kernel-not-connected-or-was-dele",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was installing OpenCV in Azure ML - Tensorflow Kernel, when it suddenly fails. After that, I tried to connect to various kernels but failed to launch any of them. It keeps saying that the kernel was not connected or was deleted. May I know how to fix the problem? Many thanks    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/165867-screen-shot-2022-01-18-at-123957-pm.png?platform=QnA\" alt=\"165867-screen-shot-2022-01-18-at-123957-pm.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Question_created_time":1642414997297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/697789\/import-ml-model-from-adls-to-azure-ml-using-databr",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI have stored some ml model in my ADLS and I want to register the model to Azure ML using databricks.  <br \/>\nTried to use the following codes to register my ml model but keep encountering an error that the path cannot be found.<\/p>\n<p>import urllib.request  <br \/>\nfrom azureml.core.model import Model<\/p>\n<h1 id=\"register-a-model\">Register a model<\/h1>\n<p>model = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',  <br \/>\nmodel_name = &quot;pretrained-classifier&quot;,  <br \/>\ndescription = &quot;Pretrained Classifier&quot;,  <br \/>\nworkspace=ws)<\/p>",
        "Question_closed_time":1642438310977,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=ad14abdc-d75c-4489-859e-28e2aba507a8\">@Yuzu  <\/a> Using the databricks file path for registering a model is not supported. When using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#azureml-core-model-model-register\">model.register()<\/a> you need to download the model locally and then use the path of the model or the folder in which the model is present to register the same.     <\/p>\n<blockquote>\n<p>model_path    <\/p>\n<p>The path on the local file system where the model assets are located. This can be a direct pointer to a single file or folder. If pointing to a folder, the child_paths parameter can be used to specify individual files to bundle together as the Model object, as opposed to using the entire contents of the folder.    <\/p>\n<\/blockquote>\n<p>This sample <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb\">notebook<\/a> should help you with using the method.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"WebserviceException when deploying image",
        "Question_created_time":1642151764693,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/695283\/webserviceexception-when-deploying-image",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,   <br \/>\nI created a model and an image in AML using mlflow.azaureml.build_image. I am able to create the image successfully.   <br \/>\nI tried to deploy the image but i encountered an error.   <\/p>\n<p>webservice_name = &quot;model-image2&quot;  <br \/>\nwebservice_deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)  <br \/>\naci_webservice = Webservice.deploy_from_image(name=webservice_name, image=model_image, deployment_config=webservice_deployment_config,workspace=ws)  <br \/>\naci_webservice.wait_for_deployment(show_output=True)  <\/p>\n<p>It gave an error which is &quot;WebserviceException&quot;  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pipeline stops at train model stage",
        "Question_created_time":1642031139267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/693063\/pipeline-stops-at-train-model-stage",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello there,     <\/p>\n<p>When I am running the following steps of the pipeline, I'm getting this error at the &quot;train model&quot; stage.     <\/p>\n<p>Can anyone explain why I'm getting this error? <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/164552-pipeline-train.jpeg?platform=QnA\" alt=\"164552-pipeline-train.jpeg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Executing pipeline in AML from ADF suddenly stopped working",
        "Question_created_time":1639398869747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/661588\/executing-pipeline-in-aml-from-adf-suddenly-stoppe",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have a pipeline defined in Azure Machine Learning. It was launched every day with Azure Data Factory with Machine Learning Execute Pipeline activity. This solution worked without any issues for a few weeks, but since 12\/09\/2021 all pipeline runs have failed with error: User starting the run is not an owner or assigned user to the Compute Instance.  <br \/>\nI did not change anything in ADF or AML.   <\/p>\n<p>Should I assign compute to ADF? How to do this?<\/p>",
        "Question_closed_time":1639690537337,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I ran into this same issue in a slightly different context. I didn't manage to figure out the root cause but managed to resolve it in practice by standing up a Compute Cluster instead of a Compute Instance (see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python<\/a>)<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Delete failed and cancelled runs automatically regularly in AzureML experiments",
        "Question_created_time":1641907647207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/690810\/delete-failed-and-cancelled-runs-automatically-reg",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all, AzureML experiments excellently helps us sort our runs.  <br \/>\nThere are atleast daily 100 runs or more in our workspace. Some of these runs fail. I was wondering if there is a way in AzureML to automatically delete the failed runs, because now we have to manually delete them which is not feasible everytime.  <br \/>\nI am aware of Azure LCM, but was wondering if something similar exists to manage our failed runs or any runs that does not have a 'completed' status.  <br \/>\nAny lead would be helpful.  <\/p>\n<p>Thanks :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"python 3.8 kernel \/ change conda environment in azureml",
        "Question_created_time":1641900858460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/690792\/python-3-8-kernel-change-conda-environment-in-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<ol>\n<li>  Kernel - I dont know how to activate the Greyed out kernel python 3.8, R and Python 3.6 are ok, should be no trick right?<\/li>\n<li>  Activate conda environment - i want to activate say anaconda 3.8 (azureml_py38) inside the terminal, but after that, how to run a notebook? normally u go to web browser, but there is no such one in cloud, and the existing notebook wont get changed..? right?<\/li>\n<\/ol>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/163897-image.png?platform=QnA\" alt=\"![163840-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/163897-image.png?platform=QnA\">1<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"SqlDataReference usage fails from yaml based AzureML pipeline",
        "Question_created_time":1641464197140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/685525\/sqldatareference-usage-fails-from-yaml-based-azure",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I am trying to deploy a DataTransferStep with azureml pipeline    <\/p>\n<p>source -&gt; SQL database    <br \/>\nsink -&gt; Azure Blob    <\/p>\n<p>using yaml pipelines    <\/p>\n<p>additonal comments:    <\/p>\n<hr \/>\n<p>This is built similar to pipeline class as in     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py<\/a>    <br \/>\nNote: I have deployed successfully yaml other pipelines that  uses PythonScriptStep successfully previously    <\/p>\n<p>my pipeline fails as below    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/162851-s1.png?platform=QnA\" alt=\"162851-s1.png\" \/>    <\/p>\n<p>The above one is built using following yaml snippet<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/163053-snippet.png?platform=QnA\" alt=\"163053-snippet.png\" \/>    <\/p>\n<p>it fails mentioning &quot;<strong>The SQL Source payload is invalid: Cannot specify 'sqlReaderQuery', 'storedProcedureParameters' at the same time&quot;<\/strong>. whereas only sqlReaderQuery is only provided by me in yaml. storedProcedureParameters takes a default value of None as per <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.sql_data_reference.sqldatareference?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.sql_data_reference.sqldatareference?view=azure-ml-py<\/a> . I have debugged inside azureml code and verified storedProcedureParameters  is None too.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/162814-image.png?platform=QnA\" alt=\"162814-image.png\" \/>    <\/p>\n<p>in executionlogs.txt its also found that an additional <strong>stored procedure parameters: 0 ()<\/strong> is printed.    <br \/>\n Copy source: SQL server database: xxxxxxxx, servername: xxxxxxxxxxxxx, serverUri: xxxxxxx-dev.database.windows.netAuthentication: AuthencationType=SqlAuthentication, table: dummy, query: SELECT TOP (100) * FROM dml.annotations, stored procedure parameters: 0 ()    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/162837-sqlq.png?platform=QnA\" alt=\"162837-sqlq.png\" \/>    <\/p>\n<p>I tried numerous combinations to avoid this default value of 0 () coming for stored procedure parameters since it is the summary of  the issue as per logs and nothing worked.    <\/p>\n<p>additional analysis:     <\/p>\n<hr \/>\n<p>I tried to implement same as direct code in azureml notebook ( here yaml is not present ) i see that the data transfer from sql to blob  works perfectly fine in notebook.    <\/p>\n<p>so question is when written via yaml why is it not working and creating a error by adding a default value to  stored procedure parameters of  SqlDataReference, how to fix it ???*    <\/p>\n<p>Also tried in various software versions:    <br \/>\nazureml-core 1.26 and 1.36    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to tain a ML model with CSV filles and not dataframes?",
        "Question_created_time":1641828520987,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/689654\/how-to-tain-a-ml-model-with-csv-filles-and-not-dat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have a dataset composed of different csv files (a lot of them) with the same metadata that I have added to the Azure blob storage and now I would like to run a regression ML model with this data in Azure ML, however I want to train the model based on the csv files and not on each line of the files (not on each dataframe). How can I do this? Is it possible in Azure ML design?  <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why does PowerBI not see my custom Azure AI model?",
        "Question_created_time":1641415247077,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/684845\/why-does-powerbi-not-see-my-custom-azure-ai-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <br \/>\nI created custom Azure AI model what I would like to use in PowerBI.    <br \/>\nWhen I open a dataset in PowerBI and after select the &quot;Azure Machine learning&quot; after the pop-up window is empty but I suppose it should contain my custom model(s).    <br \/>\nI followed the below articles:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate\">https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate<\/a>    <\/p>\n<p>Kind regards    <br \/>\nTom    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/162671-powerbi-azure-ai.png?platform=QnA\" alt=\"162671-powerbi-azure-ai.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/162606-azure-ai-model.png?platform=QnA\" alt=\"162606-azure-ai-model.png\" \/>    <\/p>",
        "Question_closed_time":1641419590033,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The product group for Power Bi actively monitors questions over at    <br \/>\n<a href=\"https:\/\/community.powerbi.com\/\">https:\/\/community.powerbi.com\/<\/a>       <\/p>\n<p>--please don't forget to <code>upvote<\/code> and <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/145510-image.png?platform=QnA\" alt=\"145510-image.png\" \/> if the reply is helpful--    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"I am not able to configure run in automated ML run?",
        "Question_created_time":1641292863803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/682916\/i-am-not-able-to-configure-run-in-automated-ml-run",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am currently learning getting started with Machine learning on azure I had to set up my ML studio and import the dataset and later on to create an automate ML run and to configure a run. After I fill out the name of the experiment, target column and when I click on next I am not able to configure the run and move to the next step. Can someone please guide me what should I do next?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute instance not setting MLFlow's URIs correctly for R",
        "Question_created_time":1640647322290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/676727\/compute-instance-not-setting-mlflows-uris-correctl",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi!    <\/p>\n<p>I am trying to set up my ML pipeline on Azure Machine Learning's compute instances. My model is in R, but I found that <a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\">the azureml sdk for R<\/a> is deprecated in favour of Azure's CLI (v2), so I am following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-cli\">the documentation<\/a> on how to set up my pipelines and as all of it is written with Python in mind, not everything translates directly to R and I have found the workaround for some things, but not all of them.    <\/p>\n<p>My main issue is with MLFlow as I want to use Azure's Experiments to track my experiments and after following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-cli-runs?tabs=mlflow\">the documentation<\/a> to do it with CLI (v2):    <\/p>\n<ul>\n<li> Compute Instances set the MLFlow's tracking URI via the environment variable <code>MLFLOW_TRACKING_URI<\/code> to match my resource's URI. The problem is that the URI is in the shape <code>azureml:\/\/&lt;path&gt;<\/code> which works correctly on Python when installing <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-mlflow\/?view=azure-ml-py\">azureml-mlflow python package<\/a>, but it doesn't work on R as that is not a supported format. After several hours of googling, I found a <a href=\"https:\/\/github.com\/sdonohoo\/azureml.mlflow\">github repo<\/a> which states that the URI must be changed to <code>https:\/\/<\/code> and that allows to log metrics.    <\/li>\n<li> Still, the problem persists when I want to log artifacts via <code>mlflow_log_artifact<\/code> as changing the <code>MLFLOW_TRACKING_URI<\/code> doesn't change the URI to which artifacts are logged, so MLFlow is trying to upload the file to the previous URI schemes (the one starting with <code>azureml:\/\/<\/code>) which fails with the following error:    <\/li>\n<\/ul>\n<blockquote>\n<p>MlflowException: Could not find a registered artifact repository for: azureml:\/\/experiments\/&lt;name&gt;\/runs\/&lt;run ID&gt;\/artifacts. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models', 'http', 'https', 'mlflow-artifacts']    <\/p>\n<\/blockquote>\n<p>I don't know where to submit my issue as:    <\/p>\n<ol>\n<li> It could be related to <code>azureml-mlflow<\/code> not working correctly when trying to use MLFlow's R wrapper    <\/li>\n<li> It could be related to the need of having an <code>azureml-mlflow<\/code>'s package for R    <\/li>\n<li> It could be related to the Compute Instance not setting the artifact URI correctly when creating the experiments    <\/li>\n<\/ol>\n<p>My workaround for now is to store my artifacts as raw outputs of the experiments, but <strong>is there a way I can set this up correctly for R?<\/strong>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unicertainity quantification in Azure ML model",
        "Question_created_time":1640957755590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/680275\/unicertainity-quantification-in-azure-ml-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have run different models in Azure ML under different algorithms (mainly Decision Forest Regression and linear Regression) and I can evaluate the performance of each model by compering the predicted value with the actual input value I have added in the label column. However, I would like to now quantify the uncertainty of the models or the confidence of the prediction by the models. I am looking and have yet to find a way on how to infer uncertainty from the models trained in Azure?  <br \/>\nSo please any help or advice on this subject would be greatly appreciated.  <br \/>\nThank you very much!  <\/p>\n<p>Maria Castano.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Quantify conformity or compliance between different datasets",
        "Question_created_time":1641225921097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/681917\/quantify-conformity-or-compliance-between-differen",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <br \/>\nI have generated regression model using Azure design for a specific dataset of which I know the value to be predicted so I can evaluate the model performance and tune hyper-parameters. But now I would like to apply this trained model to a new and different dataset of which I do not know the values to be predicted during the regression so I cannot quantify the performance of the model for this testing dataset. However, for doing so I would like to see if the testing dataset is representative or similar to the trained dataset to evaluate if the prediction will be accurate. Is there a way in Azure to measure the conformity or compliance of a testing dataset to be similar or comparable to the training dataset?  <br \/>\nThank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot Create Batch Inference ParallelRunStep Pipeline",
        "Question_created_time":1639579721297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/664931\/cannot-create-batch-inference-parallelrunstep-pipe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Firstly, here is my entry script,    <br \/>\ndeploy model code,    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157942-entry-sript.png?platform=QnA\" alt=\"157942-entry-sript.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157933-deploy-model.png?platform=QnA\" alt=\"157933-deploy-model.png\" \/>    <\/p>\n<p>My run keeps failing with the same errors<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157926-error.png?platform=QnA\" alt=\"157926-error.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157927-error2.png?platform=QnA\" alt=\"157927-error2.png\" \/>    <\/p>\n<p>I'm not sure if the entry script is failing to read the model or whether I have some authorisation issues.    <br \/>\nI have made so many attempts by adding datasets used in config file with SAS tokens from the respective containers, I even have     <br \/>\nowner authority access from containers and blob data reader etc, but nothing seems to work. Even when I register the model,    <br \/>\nI don't seem to have an AZURE_MODEL_DIR enviroment variable. Any advice would be much welcome<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I use a working pipeline",
        "Question_created_time":1640685619343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/677175\/how-can-i-use-a-working-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I created a working pipeline in azure machine learning studio but I am stuck how i can use it with a live dataset. Could anybody help to me in this issue? I dont have such option to deploy it.    <\/p>\n<p>thank you in advance    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/160869-pipeline.png?platform=QnA\" alt=\"160869-pipeline.png\" \/>    <\/p>",
        "Question_closed_time":1640726658680,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, please review <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy#test-the-real-time-endpoint\">Test the real-time endpoint<\/a> for more details on how to test your model. You can consume your model using a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service\">Client<\/a> or <a href=\"https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate\">PowerBI<\/a>.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"On Azure ML, how to import another jupyter notebook from a notebook?",
        "Question_created_time":1640321644830,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/674563\/on-azure-ml-how-to-import-another-jupyter-notebook",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm working on Azure ML and want to import another jupyter notebook from a notebook.   <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NameError when trying to run an ScriptRunConfig in Azure Machine Learning",
        "Question_created_time":1640331391010,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/674712\/nameerror-when-trying-to-run-an-scriptrunconfig-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to deploy a locally trained RandomForest model into Azure Machine Learning Studio.<\/p>\n<p><strong>training code (whentrain.ipynb) :<\/strong><\/p>\n<pre><code>#import libs and packages\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom math import sqrt\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\n\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom azureml.core import Workspace, Dataset\n\n# get existing workspace\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\n# get the datastore to upload prepared data\ndatastore = workspace.get_default_datastore()\n\n# load the dataset which is placed in the data folder\ndataset = Dataset.Tabular.from_delimited_files(datastore.path('UI\/12-23-2021_023530_UTC\/prepped_data101121.csv'))\ndataset = dataset.to_pandas_dataframe()\n\n# Create the outputs directories to save the model and images\nos.makedirs('outputs\/model', exist_ok=True)\nos.makedirs('outputs\/output', exist_ok=True)\ndataset['Date'] = pd.to_datetime(dataset['Date'])\ndataset = dataset.set_index('Date')\n###\nscaler = MinMaxScaler()\n\n#inputs\nX = dataset.iloc[:, 1:]\n#output\ny = dataset.iloc[:, :1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42, shuffle=True)\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n\n###\n\nmodel1 = RandomForestRegressor(n_estimators = 6,\n                                   max_depth = 10,\n                                   min_samples_leaf= 1,\n                                   oob_score = 'True',\n                                   random_state=42)\nmodel1.fit(X_train, y_train.values.ravel())\n\ny_pred2 = model1.predict(X_test)\n<\/code><\/pre>\n<p><strong>And here is the code on the estimator part (estimator.ipynb):<\/strong><\/p>\n<pre><code>from azureml.core import Experiment\nfrom azureml.core import Workspace\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.dnn import TensorFlow\nfrom azureml.widgets import RunDetails\n\nimport os\n\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\nexp = Experiment(workspace=workspace, name='azure-exp')\ncluster_name = &quot;gpucluster&quot;\n\ntry:\n    compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n    print('Found existing compute target')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',\n                                                           max_nodes=1)\n\n    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n\n    compute_target.wait_for_completion(show_output=True)  # , min_node_count=None, timeout_in_minutes=20)\n    # For a more detailed view of current AmlCompute status, use get_status()\n    print(compute_target.get_status().serialize())\nfrom azureml.core import ScriptRunConfig\nsource_directory = os.getcwd()\n\nfrom azureml.core import Environment\n\nmyenv = Environment(&quot;user-managed-env&quot;)\nmyenv.python.user_managed_dependencies =True\nfrom azureml.core import Dataset\ntest_data_ds = Dataset.get_by_name(workspace, name='prepped_data101121')\n\nsrc = ScriptRunConfig(source_directory=source_directory,\n                      script='whentrain.ipynb',\n\n                      arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],\n                      compute_target=compute_target,\n                      environment=myenv)\nrun = exp.submit(src)\nRunDetails(run).show()\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>The error that happens in <strong>run.wait_for_completion<\/strong> states :<\/p>\n<pre><code>[stderr]Traceback (most recent call last):\n[stderr]  File &quot;whentrain.ipynb&quot;, line 107, in &lt;module&gt;\n[stderr]    &quot;notebookHasBeenCompleted&quot;: true\n[stderr]NameError: name 'true' is not defined\n[stderr]\n<\/code><\/pre>\n<p>As you can see in my whentrain.ipynb, it does not even reach line 107, and I could not find where this error come from. So how do I fix it?<\/p>\n<p>I'm running the Notebook on Python 3.<\/p>\n<p><strong>UPDATE:<\/strong><\/p>\n<p>Okay, after a little adjustment that should not affect the whole code (I just removed some extra columns, added model save code in whentrain.ipynb making use of import os) it's now giving me somewhat the same error.<\/p>\n<pre><code>[stderr]Traceback (most recent call last):\n[stderr]  File &quot;whentrain.ipynb&quot;, line 115, in &lt;module&gt;\n[stderr]    &quot;source_hidden&quot;: false,\n[stderr]NameError: name 'false' is not defined\n[stderr]\n<\/code><\/pre>",
        "Question_closed_time":1640628230640,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b72317d8-d212-487c-8510-7d965e8d135f\">@Ash  <\/a> Ok, I think the issue is here.     <\/p>\n<pre><code>src = ScriptRunConfig(source_directory=source_directory,  \n                       script='whentrain.ipynb',  \n                            \n                       arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],  \n                       compute_target=compute_target,  \n                       environment=myenv)  \n<\/code><\/pre>\n<p>The script parameter is set to the notebook &quot;whentrain.ipynb&quot;, This should be a python script *.py which can train your model. Since you are using the notebook filename the entire source of jupyter notebook is loaded and it fails with these errors. You can lookup samples on azure ml notebook github repo for <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-amlcompute\/train.py\">reference<\/a>. I think if you can convert your whentrain.ipynb file to a python script whentrain.py and save it the current folder structure you should be able to use it in this step.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Studio: terminal not connected to compute instance",
        "Question_created_time":1640103723223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/671276\/azure-machine-learning-studio-terminal-not-connect",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am struggling with &quot;Current terminal is encountering some issues&quot;.  I have tried switching compute or restarting compute, but to no avail.  Any suggestion for diagnosing and fixing the problem will be appreciated.  Thank.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/159394-terminalnotavailable.jpg?platform=QnA\" alt=\"159394-terminalnotavailable.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a cross-sectional, unified security check list for Azure?",
        "Question_created_time":1638435378937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/648921\/is-there-a-cross-sectional-unified-security-check",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have been used Azure for the first time, and I am overwelmed by the huge quantity of information about Azure.    <\/p>\n<p>I think that the information about security on Azure is not unified.    <\/p>\n<p>For example, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/identity-management-best-practices\">Identity Management and access control security best practices<\/a> page, sometimes there are multiple best practices per one section header.    <br \/>\nHowever, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">Security recommendations for Blob storage<\/a> page,security recommendations are documented in the form of table, one issue per one row.    <\/p>\n<p>I wish there was a cross-sectional, unified security check list for Azure as follows.    <\/p>\n<ul>\n<li> We could select Azure services we use.    <\/li>\n<li> When we select the services, the security check list are displayed or could be downloaded as text file.    <\/li>\n<li> The security check list are documented so that we can easily understand what we should do. (where on the Azure portal UI, which item, or how to do set the item which is related to security, etc)    <\/li>\n<\/ul>\n<p>I have used Azure services as follows.    <\/p>\n<ul>\n<li> Azure Data Factory    <\/li>\n<li> Azure Data Lake Storage Gen2    <\/li>\n<li> Azure Functions (App Service)    <\/li>\n<li> Azure Database for MySQL    <\/li>\n<li> Azure Machine Learning    <\/li>\n<li> Azure Monitor (for Application Insights)    <\/li>\n<\/ul>\n<p>Even if I take one service (for example, Azure Data Lake Storage Gen2), I think that I have to check at least two pages (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">here<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/paas-applications-using-storage\">here<\/a> ).    <br \/>\nHowever, I'm not sure if it's covered. Do you have any good ideas?    <\/p>\n<p>Regards.<\/p>",
        "Question_closed_time":1638553979010,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=c624669d-08b4-4372-b158-6b43fc05d41a\">@Makoto Oda  <\/a>,    <\/p>\n<p>Thanks for using Microsoft Q&amp;A!!    <\/p>\n<p>I do not think that we have a single document which can provide you a consolidated view of security across all Azure services.  You may need to go through the documentation available for individual services to get the required information.  However, you can try checking - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/\">Azure security documentation<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/framework\/security\/overview\">Security considerations for Azure Architecture center<\/a> if this helps you getting anything specific you are looking in Azure at higher level.     <\/p>\n<p>Hope this helps.    <\/p>\n<p>Thanks    <br \/>\nSaurabh    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Token authentication failed: 'utf-8' codec can't decode byte 0xe4 in position 0: invalid continuation byte",
        "Question_created_time":1640198898043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/672951\/token-authentication-failed-utf-8-codec-cant-decod",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p><strong>I'm trying to send the json data from azure ml to eventhub using codes below<\/strong><\/p>\n<p>import json  <br \/>\nd = result.to_dict(orient='records')  <br \/>\ndata = json.dumps(d,ensure_ascii=False)<\/p>\n<p>import asyncio  <br \/>\nfrom azure.eventhub.aio import EventHubProducerClient  <br \/>\nfrom azure.eventhub import EventData  <br \/>\nimport time  <br \/>\nconn_sting = &quot;Endpoint=***&quot;  <br \/>\nasync def run():  <br \/>\nproducer = EventHubProducerClient.from_connection_string(conn_str=conn_string)  <br \/>\nasync with producer:<\/p>\n<pre><code>event_data_batch = await producer.create_batch(partition_id='0')\nevent_data_batch.add(EventData(data))\n\n\nawait producer.send_batch(event_data_batch)\n<\/code><\/pre>\n<p>nest_asyncio.apply()  <br \/>\nloop = asyncio.get_event_loop()  <br \/>\nloop.run_until_complete(run())  <br \/>\nprint(&quot;sent to eventhub&quot;)<\/p>\n<p><strong>and getting follwing error..<\/strong><\/p>\n<p>Token authentication failed: 'utf-8' codec can't decode byte 0xe4 in  <br \/>\nposition 0: invalid continuation byte  <br \/>\nToken authentication failed: 'utf-8' codec can't decode byte 0xe4 in  <br \/>\nposition 0: invalid continuation byte<\/p>\n<p><strong>anyone could help debug the error? thanks<\/strong><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to use \"join data\" to combine multiple datasets into one using Azure Machine Learning Studio Designer",
        "Question_created_time":1639646320353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/666021\/unable-to-use-join-data-to-combine-multiple-datase",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>How can I combine mutiple datasets into one using Azure Machine Learning Studio?    <\/p>\n<p>(The following graph doesn't work)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158185-screenshot-2021-12-16-170009.png?platform=QnA\" alt=\"158185-screenshot-2021-12-16-170009.png\" \/>    <\/p>\n<p>Same Question:     <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/70376362\/unable-to-use-join-data-to-combine-multiple-datasets-into-one-using-azure-mach\">https:\/\/stackoverflow.com\/questions\/70376362\/unable-to-use-join-data-to-combine-multiple-datasets-into-one-using-azure-mach<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Storage for Azure ML Workspace",
        "Question_created_time":1626270141667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/475803\/storage-for-azure-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_body":"<p>Hello:  <\/p>\n<p>When I create Azure ML Workspace, why I cannot use existing storage, why I have to create new one?  <\/p>\n<p>Any clarification will help me to educate.  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot open a terminal in compute instances",
        "Question_created_time":1615232316253,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/304418\/cannot-open-a-terminal-in-compute-instances",
        "Question_score_count":2,
        "Question_answer_count":3,
        "Question_comment_count":4,
        "Question_body":"<p>I am trying to complete the learning exercises in the Microsoft Learning module &quot;Explore and analyze data with Python&quot; with a trial subscription to Azure. In any compute instances that I start, I cannot connect to the terminal and get the error &quot;<em>Invalid terminal: Unable connect to terminal, please close the tab and restart your current compute and retry Trace ID : 5b4a5ee5-c5cf-4f66-b054-71a81417bdbc<\/em> &quot;. I have tried restarting the instance, in addition to deleting the VM and starting a new instance but still encounter the same error which happens in both Edge and Chrome browsers. Is there something that I am missing in connecting to the terminal in these notebooks? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why can't I see web app bot in the market place?",
        "Question_created_time":1640039500510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/670277\/why-cant-i-see-web-app-bot-in-the-market-place",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I've tried to look everywhere in the marketplace, however, I can't seem to find a web app bot. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connect Azure ML notebook to azure VM",
        "Question_created_time":1639928946803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/668659\/connect-azure-ml-notebook-to-azure-vm",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey All,  <\/p>\n<p>I want to connect to my VM in order to get access to files on the VM from my notebook. Is it possible?  <\/p>\n<p>can someone help me with it?  <\/p>\n<p>thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure endpoint in decimal notation",
        "Question_created_time":1639603918890,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/665285\/azure-endpoint-in-decimal-notation",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I've set up an Azure endpoint and I'm trying to communicate with it using some old software that can only read decimal notation. The scientific notation the endpoint occasionally delivers is breaking it. Is there a way to configure the endpoint to return only decimal notation? Ideally just with the correct header like &quot;application\/jsonlegacy&quot; or something?<\/p>",
        "Question_closed_time":1639637934830,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=f32931a2-cf4c-4d9d-bf15-d0fd70f7b4aa\">@Jonathan Horton  <\/a> Returning a decimal value from an endpoint should be possible. I think this depends on the training of the experiment if the ML studio is used. I have an <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/\">experiment<\/a> which returns decimals. You can use a similar setup with Apply transformation module or Apply Math operation if using the newer version of the studio.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158096-image.png?platform=QnA\" alt=\"158096-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"RuntimeError: Load model failed - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_created_time":1638981543063,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/656548\/runtimeerror-load-model-failed-score-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I am following the steps on this tutorial:    <br \/>\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">tutorial-score-model-predict-spark-pool<\/a>    <br \/>\nI tried to used a model created with AutoML and another from designer and I am getting this error: <em>RuntimeError: Load model failed<\/em>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/155981-capture.png?platform=QnA\" alt=\"155981-capture.png\" \/>    <\/p>\n<p>I am using the model according to this: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html?childToView=637754#comment-637754\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html?childToView=637754#comment-637754<\/a>     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/156021-2.png?platform=QnA\" alt=\"156021-2.png\" \/>    <\/p>\n<p>Thank you for your help.    <\/p>",
        "Question_closed_time":1639460160303,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=4bb27b25-616e-491c-b986-136b5bf96f77\">@Anaid  <\/a>,    <\/p>\n<p>Before running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.    <\/p>\n<pre><code>#Set model URI  \n       #Set AML URI, if trained model is registered in AML  \n          AML_MODEL_URI = &quot;&lt;aml model uri&gt;&quot; #In URI &quot;:x&quot; signifies model version in AML. You can   choose which model version you want to run. If &quot;:x&quot; is not provided then by default   latest version will be picked.  \n  \n       #Set ADLS URI, if trained model is uploaded in ADLS  \n          ADLS_MODEL_URI = &quot;abfss:\/\/&lt;filesystemname&gt;@&lt;account name&gt;.dfs.core.windows.net\/&lt;model   mlflow folder path&gt;&quot;  \n<\/code><\/pre>\n<p><strong>Model URI from AML Workspace:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;aml:\/\/mlflow_sklearn:1&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p><strong>Model URI uploaded to ADLS Gen2:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Failure when submitting pipe line",
        "Question_created_time":1598970144413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/83451\/failure-when-submitting-pipe-line",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>Doing exam training using my free subscription (Exam DP-100: Designing and Implementing a Data Science Solution on Azure).    <br \/>\nGot in to problem in the following mudule, <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data<\/a>.    <br \/>\nGets following error in my pipe line in Microsoft Azure Machine Learning:    <br \/>\nUnable to get image details : Unable to fetch workspace resources: Not Found response body: {&quot;error&quot;:{&quot;code&quot;:&quot;ResourceNotFound&quot;,&quot;m<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Auto ML JobConfigurationMaxSizeExceeded error when using a cluster",
        "Question_created_time":1638916697927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/655421\/azure-auto-ml-jobconfigurationmaxsizeexceeded-erro",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am running into the following error when I try to run Automated ML through the studio on a GPU compute cluster:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/155791-image.png?platform=QnA\" alt=\"155791-image.png\" \/>    <\/p>\n<p>The attempted run is on a registered tabulated dataset in filestore and is a simple regression case. Strangely, it works just fine with the CPU compute <em>instance<\/em> I use for my other pipelines. I have been able to run it a few times using that and wanted to uprade to a cluster only to be hit by this error. I found online that it could be a case of having the following setting: AZUREML_COMPUTE_USE_COMMON_RUNTIME:false; but I am not sure where to put this in when just running from the web studio.    <\/p>\n<p>Thank you for your help!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Workspace contributor cannot access Compute Instance",
        "Question_created_time":1639128960857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/659117\/azure-ml-workspace-contributor-cannot-access-compu",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,  <\/p>\n<p>Until 2021\/12\/7, every user whose role is Contributor can use the same Compute Instance to run an Experiment.  <br \/>\nOn 2021\/12\/8, only the owner of Compute Instance can access.  <br \/>\nHow can I still use shared Compute Instance?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML: Upload File to Step Run's Output - Authentication Error",
        "Question_created_time":1630074811383,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530817\/azure-ml-upload-file-to-step-runs-output-authentic",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>During a PythonScriptStep in an Azure ML Pipeline, I'm saving a model as joblib pickle dump to a directory in a Blob Container in the Azure Blob Storage which I've created during the setup of the Azure ML Workspace. Afterwards I'm trying to upload this model file to the step run's output directory using    <\/p>\n<pre><code>   Run.upload_file (name, path_or_stream)  \n<\/code><\/pre>\n<p>(for the function's documentation, see <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-<\/a>)    <\/p>\n<p>Some time ago when I created the script using the azureml-sdk version 1.18.0, everything worked fine. Now, I've updated the script's functionalities and upgraded the azureml-sdk to version 1.33.0 during the process and the upload function now runs into the following error:    <\/p>\n<pre><code>   Traceback (most recent call last):  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 64, in upload_blob_from_stream  \n       validate_content=True)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 93, in execute_func_with_reset  \n       return ClientBase._execute_func_internal(backoff, retries, module_logger, func, reset_func, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 367, in _execute_func_internal  \n       left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 399, in _handle_retry  \n       raise error  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 358, in _execute_func_internal  \n       response = func(*args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 614, in create_blob_from_stream  \n       initialization_vector=iv  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in _upload_blob_chunks  \n       range_ids = [f.result() for f in futures]  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in &lt;listcomp&gt;  \n       range_ids = [f.result() for f in futures]  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 435, in result  \n       return self.__get_result()  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 384, in __get_result  \n       raise self._exception  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run  \n       result = self.fn(*self.args, **self.kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 210, in process_chunk  \n       return self._upload_chunk_with_progress(chunk_offset, chunk_bytes)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 224, in _upload_chunk_with_progress  \n       range_id = self._upload_chunk(chunk_offset, chunk_data)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 269, in _upload_chunk  \n       timeout=self.timeout,  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 1013, in _put_block  \n       self._perform_request(request)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 432, in _perform_request  \n       raise ex  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 357, in _perform_request  \n       raise ex  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 343, in _perform_request  \n       HTTPError(response.status, response.message, response.headers, response.body))  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py&quot;, line 115, in _http_error_handler  \n       raise ex  \n   azure.common.AzureHttpError: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed  \n   &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.  \n   RequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000  \n   Time:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw  \n   2021-08-27T13:19:56Z  \n   2021-08-28T13:29:56Z  \n   \/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl  \n     \n   2019-07-07  \n   b  \n     \n   &lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;  \n     \n   During handling of the above exception, another exception occurred:  \n     \n   Traceback (most recent call last):  \n     File &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/...\/azureml-setup\/context_manager_injector.py&quot;, line 243, in execute_with_context  \n       runpy.run_path(sys.argv[0], globals(), run_name=&quot;__main__&quot;)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 263, in run_path  \n       pkg_name=pkg_name, script_name=fname)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 96, in _run_module_code  \n       mod_name, mod_spec, pkg_name, script_name)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 85, in _run_code  \n       exec(code, run_globals)  \n     File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;  \n       main()  \n     File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main  \n       path_or_stream=model_path)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped  \n       return func(self, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file  \n       datastore_name=datastore_name)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact  \n       return self.upload_artifact_from_path(artifact, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path  \n       return self.upload_artifact_from_stream(stream, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream  \n       content_type=content_type, session=session)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact  \n       timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream  \n       raise AzureMLException._with_error(azureml_error, inner_exception=e)  \n   azureml._common.exceptions.AzureMLException: AzureMLException:  \n   \tMessage: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.  \n   \tStorageAccount: mystorage  \n   \tContainerName: azureml  \n   \tStatusCode: 403  \n   \tInnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed  \n   &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.  \n   RequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000  \n   Time:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw  \n   2021-08-27T13:19:56Z  \n   2021-08-28T13:29:56Z  \n   \/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl  \n     \n   2019-07-07  \n   b  \n     \n   &lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;  \n   \tErrorResponse   \n   {  \n       &quot;error&quot;: {  \n           &quot;code&quot;: &quot;UserError&quot;,  \n           &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,  \n           &quot;inner_error&quot;: {  \n               &quot;code&quot;: &quot;Auth&quot;,  \n               &quot;inner_error&quot;: {  \n                   &quot;code&quot;: &quot;Authorization&quot;  \n               }  \n           }  \n       }  \n   }  \n     \n   During handling of the above exception, another exception occurred:  \n     \n   Traceback (most recent call last):  \n     File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;  \n       main()  \n     File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main  \n       path_or_stream=model_path)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped  \n       return func(self, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file  \n       datastore_name=datastore_name)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact  \n       return self.upload_artifact_from_path(artifact, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path  \n       return self.upload_artifact_from_stream(stream, *args, **kwargs)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream  \n       content_type=content_type, session=session)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact  \n       timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)  \n     File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream  \n       raise AzureMLException._with_error(azureml_error, inner_exception=e)  \n   UserScriptException: UserScriptException:  \n   \tMessage: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.  \n   \tStorageAccount: mystorage  \n   \tContainerName: azureml  \n   \tStatusCode: 403  \n   \tInnerException AzureMLException:  \n   \tMessage: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.  \n   \tStorageAccount: mystorage  \n   \tContainerName: azureml  \n   \tStatusCode: 403  \n   \tInnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed  \n   &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.  \n   RequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000  \n   Time:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw  \n   2021-08-27T13:19:56Z  \n   2021-08-28T13:29:56Z  \n   \/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl  \n     \n   2019-07-07  \n   b  \n     \n   &lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;  \n   \tErrorResponse   \n   {  \n       &quot;error&quot;: {  \n           &quot;code&quot;: &quot;UserError&quot;,  \n           &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: verovisionstorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,  \n           &quot;inner_error&quot;: {  \n               &quot;code&quot;: &quot;Auth&quot;,  \n               &quot;inner_error&quot;: {  \n                   &quot;code&quot;: &quot;Authorization&quot;  \n               }  \n           }  \n       }  \n   }  \n   \tErrorResponse   \n   {  \n       &quot;error&quot;: {  \n           &quot;code&quot;: &quot;UserError&quot;,  \n           &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;  \n       }  \n   }  \n<\/code><\/pre>\n<p>As far as I can tell from the code of the azureml.core.Run class and the subsequent function calls, the Run object tries to upload the file to the step run's output directory using SAS-Token-Authentication (which fails). This documentation article is linked in the code (but I don't know if this relates to the issue): <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example\">https:\/\/learn.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example<\/a>    <\/p>\n<p>Did anybody encounter this error as well and knows what causes it or how it can be resolved?    <\/p>\n<p>Best,    <br \/>\nJonas<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"getting an error when trying to deploy azure ml model",
        "Question_created_time":1639419111370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/662007\/getting-an-error-when-trying-to-deploy-azure-ml-mo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm new to Azure ML so I have very little knowledge of this service..    <br \/>\nI've built a dummy regression model using automl package and now I'm trying to deploy it.    <br \/>\nI looked up some docs and followed a tutorial I found to deploy the model and I'm getting some errors..    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157189-image.png?platform=QnA\" alt=\"157189-image.png\" \/> &lt;- this is the error I'm currently getting    <br \/>\nI think there is a problem with my score.py so I'm attaching the photo here as well.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157272-image.png?platform=QnA\" alt=\"157272-image.png\" \/>    <\/p>\n<p>and this is the output i need to print out through the model..    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/157242-image.png?platform=QnA\" alt=\"157242-image.png\" \/>    <\/p>\n<p>I'd appreciate it much if somebody could give me some help     <\/p>\n<p>thank you    <\/p>",
        "Question_closed_time":1639459821473,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,     <\/p>\n<p>Thanks for reaching out to us. From the above error it looks like the package did not install successfully. A more detailed procedure to install the SDK is available directly in the documentation: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py<\/a>    <\/p>\n<p>How to set up the environment: <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/python-sdk\/tutorials\/automl-with-azureml#3-setup-a-new-conda-environment\">https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/python-sdk\/tutorials\/automl-with-azureml#3-setup-a-new-conda-environment<\/a>    <\/p>\n<p>You can test if you have set the env correct by below code:    <\/p>\n<pre><code>import azureml.core  \n  \nprint(&quot;This notebook was created using version 1.35.0 of the Azure ML SDK.&quot;)  \nprint(&quot;You are currently using version&quot;, azureml.core.VERSION, &quot;of the Azure ML SDK.&quot;)  \nassert (  \n    azureml.core.VERSION &gt;= &quot;1.35&quot;  \n), &quot;Please upgrade the Azure ML SDK by running '!pip install --upgrade azureml-sdk' then restart the kernel.&quot;  \n<\/code><\/pre>\n<p>There are some prerequisites to deploy models:     <\/p>\n<ul>\n<li> An Azure Machine Learning workspace. For more information, see Create an Azure Machine Learning workspace. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace<\/a>     <\/li>\n<li> A model. The examples in this article use a pre-trained model.    <\/li>\n<li> The Azure Machine Learning software development kit (SDK) for Python. <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro<\/a>    <\/li>\n<li> A machine that can run Docker, such as a compute instance. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance<\/a>    <\/li>\n<\/ul>\n<p>More information please refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#prerequisites\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#prerequisites<\/a>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to connect Azure ML to Eventhub",
        "Question_created_time":1639361629193,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/660845\/how-to-connect-azure-ml-to-eventhub",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi I'm new to Azure ML so I have little knowledge of it..  <br \/>\nI've created a basic regression ML model using auto ml package inJjupyeter notebook  <br \/>\nand now I have to deploy the model and send the output to the eventhub..  <\/p>\n<p>I'm wondering if anyone could help me with deploying the model and connecting it to the eventhub  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I use my segnet trained in MATLAB converted to ONNX model in C#?",
        "Question_created_time":1639153730207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/659647\/how-do-i-use-my-segnet-trained-in-matlab-converted",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>The segnet is trained on 32x32 Greyscale tiles and has 0 and 255 labels and  I need inference run in C#. I see examples for Object detection but don't see any model implementations for segmentation.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Changes@ML Studio( Classic)",
        "Question_created_time":1639106845297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/658668\/changes@ml-studio(-classic)",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone  <\/p>\n<p>I am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, the new creation of Machine Learning Studio (classic) resources will not be available.'  <\/p>\n<p>As mentioned above, Can you please be specific about which services won't be available?   <br \/>\nAs I have created my account on 10 Dec 2021 and I am still able to use all the services like Regression algorithms, Classification algorithms, etc.  <\/p>\n<p>Can someone please provide more clarity on the above issues?  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use LightGBM algorithms in Azure Machine Learning Designer",
        "Question_created_time":1639119129643,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/658828\/use-lightgbm-algorithms-in-azure-machine-learning",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Wonder anyone can help on this. My customer wonder if Azure Machine Learning Designer (GUI) can support using Python open library e.g. LightGBM algorithms to develop machine learning model. It seems that it is supported but could not find a supporting document.  <br \/>\nThe customer is currently using Python programming with LightGBM algorithms etc to develop machine learning model with other ML tool. Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Dockerfile on Azure Environment with python poetry",
        "Question_created_time":1638821054557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/653688\/custom-dockerfile-on-azure-environment-with-python",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am new to docker and environments. This could be basics but i have been trying to install packages in my pyproject.toml file in Dockerfile without success.   <\/p>\n<p>I have tried using poetry to export requirements.txt file  and using it with the   <br \/>\nEnvironment.from_pip_requirements('requirements.txt') function and a Dockerfile.   <\/p>\n<p>But could there be any elegant solution to use toml file directly for creating a custom environment ?  <\/p>",
        "Question_closed_time":1638981076963,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Thanks for the response, <a href=\"\/users\/na\/?userid=1cea772e-bffd-0003-0000-000000000000\">@Ram R  <\/a>     <br \/>\nUsing  the Dockerfile :     <\/p>\n<pre><code>FROM python:3.8-slim-buster  \nENV PYTHONUNBUFFERED=1 \\  \n    PYTHONDONTWRITEBYTECODE=1 \\  \n    PIP_NO_CACHE_DIR=1 \\  \n    PIP_DISABLE_PIP_VERSION_CHECK=1 \\  \n    POETRY_VERSION=1.1.7 \\  \n    PYLINT_VERSION=2.9.4  \n  \nRUN pip install pylint==$PYLINT_VERSION \\  \n    &amp;&amp; pip install &quot;poetry==$POETRY_VERSION&quot;   \n  \nCOPY pyproject.toml .\/  \nRUN poetry config virtualenvs.create false   \n<\/code><\/pre>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"How to Register a ML model using MLflow",
        "Question_created_time":1638981630093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/656507\/how-to-register-a-ml-model-using-mlflow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,     <\/p>\n<p>I have a PyTorch model which I have pushed into the <strong>dbfs<\/strong> now I want to serve the model using MLflow. I saw that the model needs to be in <strong>python_function model<\/strong>.    <\/p>\n<p>To do that I did the following methods    <\/p>\n<ol>\n<li> load the model from dbfs using torch load option    <\/li>\n<li> Then save the model in python_function model using the pyfunc.save_model function    <\/li>\n<li> After this when I register the model I get a decode error    <\/li>\n<\/ol>\n<p>I'm not training any model in the Databricks.    <\/p>\n<pre><code>   import mlflow  \n   import mlflow.pyfunc  \n   from torch import load as torch_load  \n     \n   py_model = torch_load( &quot;\/dbfs\/FileStore\/ml\/ner_model&quot; , map_location = torch_device(ner_gpu_device))  \n   mlflow.pytorch.save_model(py_model,path=&quot;\/dbfs\/FileStore\/pyfunc\/ner_model&quot;)  \n     \n   model = mlflow.pyfunc.load_model(&quot;\/dbfs\/FileStore\/pyfunc\/ner_model&quot;)  \n   mlflow.register_model(model,&quot;ner_model&quot;)  \n     \n   # loading the python_function model to register  \n   model = mlflow.pyfunc.load_model(&quot;\/dbfs\/FileStore\/pyfunc\/ner_model&quot;)  \n   model_version = mlflow.register_model(model,&quot;ner_model&quot;)  \n<\/code><\/pre>\n<p><strong>this is the error which I get while running the register model line<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/156022-image.png?platform=QnA\" alt=\"156022-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How Do I Create a ModelDirectory Type FileDataset",
        "Question_created_time":1621299075643,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398468\/how-do-i-create-a-modeldirectory-type-filedataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to build a solution that automates part of the model deployment within the Azure ML designer. I am able to build a model with the designer, and then execute a python script block to extract the trained_model_outputs folder from the model training block. I have precisely matched the folder structure that Azure ML designer assigns to the model's FileDataset  <\/p>\n<p>When I register the trained_model_outputs as a FileDataset, it assigns it the type AnyDirectory. This is a problem, as when I try to build it into the inference pipeline, the designer rejects it, saying it must be a ModelDirectory, even though there shouldn't be any functional difference between the two.  <\/p>\n<p>I have seen that I can expose the ModelDirectory class as below, however I cannot find the API documentation online about this class anywhere, and I can't review it's source code as it isn't in the standard SDK:  <\/p>\n<p>from azureml.studio.core.io.model_directory import ModelDirectory  <\/p>\n<p>Can you provide a code snippet or similar that I can use to leverage this class when creating the FileDataset so that the model dataset gains the ModelDirectory type attribute?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Compute (instance or cluster) times out mounting blob storage with BFSMountError",
        "Question_created_time":1637782411833,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/639949\/azure-ml-compute-(instance-or-cluster)-times-out-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>We've recently spun up an Azure ML environment to do some initial testing of its capabilities. A little background, we have quite a few different other services deployed, all encapsulated in our VNET which has no ingress or egress to the internet, just a VPN GW to our offices. We are leveraging private endpoints and private link capabilities across the board.    <\/p>\n<p>We explicitly followed the instructions of setting up a secure ML workspace (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-create-secure-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-create-secure-workspace<\/a>). We are using private endpoints for the workspace, storage, ACR, KV, and everything ML-related is in its own subnet within our VNET. Compute instances and\/or clusters are also deployed to the same subnet.    <\/p>\n<p>When we try and run one of the sample designer packages, Automobile Price Prediction, we get the following error whether using a compute instance or a compute cluster:    <\/p>\n<p><strong>AzureMLCompute job failed.    <br \/>\nBFSMountError: Unable to mount blob fuse file system    <br \/>\n\tInfo: Mounting of azureml-blobstore-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX container from ${storageaccountname} account timed out  <br \/>\n\tInfo: Failed to setup runtime for job execution: Job environment preparation failed on ${Compute IP Address} with err exit status 1.<\/strong>  <\/p>\n<p>Any ideas or things to look at?    <\/p>\n<p>Thanks in advance    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create deploy a Deep learning model as Function app",
        "Question_created_time":1638553622740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/651132\/how-to-create-deploy-a-deep-learning-model-as-func",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a DL model which sizes around 3.5 gigs and I'm creating a HTTP trigger to hit the model, all works fine when I test it in my local machine. When I start deploying the model as Function App into Azure, deployment breaks midway.  <\/p>\n<p>Also how can I link a <strong>gpu<\/strong> compute to the function app for the model to run.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Something went wrong with AZUREML_COMPUTE_USE COMMON_RUNTIME",
        "Question_created_time":1635026593690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/601551\/something-went-wrong-with-azureml-compute-use-comm",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Suddenly, we had some problems with python module import.  <\/p>\n<p>Here the same error on stackoverflow  <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/69554336\/azure-ml-release-bug-azureml-compute-use-common-runtime\">https:\/\/stackoverflow.com\/questions\/69554336\/azure-ml-release-bug-azureml-compute-use-common-runtime<\/a>  <\/p>\n<p>Run ID - 3c50cae1-b463-4ec1-afd5-c92393b2167c<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"is there a way to delete azureml runs using the python sdk?",
        "Question_created_time":1638386026283,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/648089\/is-there-a-way-to-delete-azureml-runs-using-the-py",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was wondering if it was possible to delete particular runs using the Python SDK.   <br \/>\nthis would be rather useful to delete old failed runs.  <br \/>\nit already has functions such as cancel(), fail(), submit(). <\/p>",
        "Question_closed_time":1638494197370,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2dc066be-691a-47bd-9f7a-67e426d994d9\">@Antara Das  <\/a>  Thanks, Run history documents, which may contain personal user information, are stored in the storage account in blob storage, in subfolders of \/azureml. You can download and delete the data from the portal.    <\/p>\n<p> Here is the document to delete workspace data.     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-export-delete-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-export-delete-data<\/a>    <\/p>\n<p>There is a Private Preview for deleting an experiment, however such functionality does not delete the intermediate data generated for the run or any child run.    <br \/>\n\u2022 Not deleted:    <br \/>\no Files in azureml-blobstore-GUID\/azureml\/{run_id}    <br \/>\no Code snapshot (zip files)    <br \/>\no Pipeline intermediate data and child runs    <br \/>\no Metric data    <\/p>\n<p>\u2022 Deleted    <br \/>\no The output folder content    <br \/>\no Log files<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"ML Notebooks PATH set for python3.6 not matter what kernel you use",
        "Question_created_time":1638785774433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/652960\/ml-notebooks-path-set-for-python3-6-not-matter-wha",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I've trying to run <a href=\"https:\/\/colab.research.google.com\/drive\/15UwYDsnNeldJFHJ9NdgYBYeo6xPmSelP\">this notebook<\/a> in AzureML which requires python 3.7 or higher. I'm trying with the built-in Python 3.8 kernel but the PATH contains reference to the 3.6 kernel and therefore pip and python versions are 3.6, not 3.8:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/155301-image.png?platform=QnA\" alt=\"155301-image.png\" \/>    <\/p>\n<p>I've created a new environment and can check that it works through the terminal, but I can't change the path of the notebook server, despite a correct kernel spec.    <\/p>\n<p>Help!    <\/p>\n<p>Amadeus    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML Model - Test Interface",
        "Question_created_time":1638313645353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646763\/azure-automl-model-test-interface",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi Guys. New in the Azure AutoML space.     <br \/>\nI followed through the steps and successfully deployed a model on web:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/153843-image.png?platform=QnA\" alt=\"153843-image.png\" \/>    <\/p>\n<p>When I go into &quot;Test&quot; tab, the interface with dialog boxes is missing, and it's displaying raw code:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/153790-image.png?platform=QnA\" alt=\"153790-image.png\" \/>    <\/p>\n<p>Just wanted to check if anyone knew how I could get the dialog boxes or UI ? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Many Azure ML subresources do not support tags and tags in cost report",
        "Question_created_time":1638463996317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/649517\/many-azure-ml-subresources-do-not-support-tags-and",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Tags are supported on Azure Machine learning, but the most cost generating part in Azure ML usage is related to sub-resources that do not support tags in cost report as shown here.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/tag-support#microsoftmachinelearningservices\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/tag-support#microsoftmachinelearningservices<\/a>     <\/p>\n<p>It seems that Azure ML also leverages other services and hence flagged with the resource name of the emitting service (Azure ML workspace) with no tags propagated, and unfortunately these are the most expensive and are not covered by tagging mechanism.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"automate failed runs delete using life cycle management ?",
        "Question_created_time":1638290477030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646383\/automate-failed-runs-delete-using-life-cycle-manag",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>i would be interested in knowing if there is an elegant method of deleting the Failed , cancelled runs on AzureML using the life cycle management ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is AML_MODEL_URI - PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_created_time":1637180271803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all,     <\/p>\n<p>I am following the steps on this tutorial:     <br \/>\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a>      <\/p>\n<p>I don't know what is the AML_MODEL_URI. I thought it was the REST endpoint or the Swagger URI from the endpoint.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150362-image.png?platform=QnA\" alt=\"150362-image.png\" \/>    <\/p>\n<p>But it is not working. I am getting this error on Synapse: &quot;RuntimeError: Load model failed    <br \/>\nTraceback (most recent call last):&quot;    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150308-image.png?platform=QnA\" alt=\"150308-image.png\" \/>    <\/p>\n<p>I appreciate you help.    <\/p>\n<p>Kind regards,     <br \/>\nAnaid     <\/p>",
        "Question_closed_time":1637667545273,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=4bb27b25-616e-491c-b986-136b5bf96f77\">@Anaid  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>AML_MODEL_URL is the same name of the model in the ML workspace with (follow the format of <code>aml:\/\/<\/code> + Name of the Model).    <\/p>\n<\/blockquote>\n<p>Example: <code>aml:\/\/sklearn_regression_model:1<\/code> (follow the format of <code>aml:\/\/<\/code> + Name of the Model).    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/153599-image.png?platform=QnA\" alt=\"153599-image.png\" \/>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Using the Custom Module in AzureML Designer Created from Notebook",
        "Question_created_time":1638334248197,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646978\/using-the-custom-module-in-azureml-designer-create",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Following the steps in the notebook I am able to create a Module and I also can see the module in the AzureML designer (Under Custom module).  <br \/>\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-how-to-use-modulestep.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-how-to-use-modulestep.ipynb<\/a><\/p>\n<p>Creating pipeline with ModuleStep and running a pipeline from notebook is also possible. But while trying to use the module in the designer, and trying to run a pipeline in an experiment, getting following error,  <br \/>\n<em><strong>Error<\/strong><\/em>  <br \/>\nCan't build command text for [ModelExplainer], moduleId [ed91c7cf-028f-4867-a228-b32f74cb8ff2] executionId [e4436bd8]: Assignment for parameter Target is not specified<\/p>\n<p>Where ModelExplainer is the experiment name.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML maximum columns supported",
        "Question_created_time":1638323249770,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646730\/azure-automl-maximum-columns-supported",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,   <\/p>\n<p>  Is there any documentation on the maximum columns supported by the AML both on the Portal and SDK?  <\/p>\n<p>  I tried to input a training sets with more than 60k columns and the process failed on the portal but still running on my notebooks.  <\/p>\n<p>  Wonder is there any limits on the number of columns that we can put it?  <\/p>\n<p>Thanks! <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Moving contents from one container to other in storage blob",
        "Question_created_time":1638289735473,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646381\/moving-contents-from-one-container-to-other-in-sto",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is there a way to move container contents from one Container to another without using SAS tokens or keys using Python SDK in AzureML?  <br \/>\nThere are lot of resources which site the possibilities of moving containers. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error - AttributeError: 'function' object has no attribute 'service_context'",
        "Question_created_time":1638262419597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/645756\/error-attributeerror-function-object-has-no-attrib",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I am trying out some code on Azure machine learning notebook however I keep getting this error as stated above.     <br \/>\nCan anyone please help    <br \/>\nI tried to re-login    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/153662-capture.png?platform=QnA\" alt=\"153662-capture.png\" \/>    <\/p>\n<p>Regards    <br \/>\nLyon    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I get the experimentID inside a running pipeline script?",
        "Question_created_time":1638292741140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646416\/how-do-i-get-the-experimentid-inside-a-running-pip",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I'm writing a ML pipeline.  <\/p>\n<p>At the end of a script I have to write the output to a SQL database, and I would need the ExperimentID as a field of the output dataframe.  <\/p>\n<p>Is there a way for me to find within the running script in which experiment it's being run?  <br \/>\nOr is there a way for me to input the ExperimentID as a parameter to the pipeline at launch? From what I understand parameters are defined before the experiment is created so that's a bit confusing.  <\/p>\n<p>In case this is too complicated, is there a way I can somehow chain the pipeline output inside a script to the experiment it's being run?   <\/p>\n<p>Thank you very much,<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML Featurisation Error",
        "Question_created_time":1638154550033,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/643670\/azure-automl-featurisation-error",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>According the following doc, I should be able to to turn on FeaturizationConfig in the settings:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>    <\/p>\n<p>However I'm getting the following error when I try to change the switch to 'FeaturizationConfig' when setting up the AutoML experiment:    <\/p>\n<blockquote>\n<p>ConfigException: ConfigException: Message: Invalid argument(s) 'featurizationconfig' specified. Supported value(s): 'off, auto'    <\/p>\n<\/blockquote>\n<p>The following is my settings:    <\/p>\n<blockquote>\n<p>import logging    <\/p>\n<p>automl_settings = {    <br \/>\n    &quot;iteration_timeout_minutes&quot;: 15,    <br \/>\n    &quot;experiment_timeout_hours&quot;: 0.3,    <br \/>\n    &quot;enable_early_stopping&quot;: True,    <br \/>\n    &quot;primary_metric&quot;: 'spearman_correlation',    <br \/>\n    &quot;featurization&quot;: 'FeaturizationConfig',    <br \/>\n    &quot;verbosity&quot;: logging.INFO,    <br \/>\n    &quot;n_cross_validations&quot;: 5    <br \/>\n}    <\/p>\n<\/blockquote>",
        "Question_closed_time":1638189983847,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6760e7be-77ee-4c41-9c63-8bbcdab1aaae\">@SoonJoo@Genting  <\/a> Thanks, Previously, it was a black-box preprocessing, with user\u2019s preprocess=True\/False setting.    <br \/>\nNew change includes deprecation of <code>preprocess<\/code> and introduction of new field <code>featurization<\/code>, where featurization = \u2018auto\u2019 (for automatic featurization, comparable to preprocess=True) \/ \u2018off\u2019 (to turn off featurization, comparable to preprocess=False) \/ FeaturizationConfig (object to pass in customized configuration on featurization setting).    <\/p>\n<p>For more information on custom featurization as well as how to construct FeaturizationConfig is in this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features#customize-featurization\">documentation<\/a>.    <br \/>\nWe also have a notebook available with example in our git <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression-explanation-featurization\/auto-ml-regression-explanation-featurization.ipynb\">repo<\/a>.    <br \/>\nUsage example:    <\/p>\n<pre><code>from azureml.automl.core.featurization import FeaturizationConfig  \n  \nfeaturization_config = FeaturizationConfig()  \nfeaturization_config.add_column_purpose('Column2', 'Categorical')  \nfeaturization_config.add_column_purpose('Column5', 'Categorical')  \n  \nautoml_config = AutoMLConfig(task = 'classification', compute_target=compute_target, featurization=featurization_config, **automl_settings )  \nremote_run = experiment.submit(automl_config, show_output = False)  \n<\/code><\/pre>\n<p>For classification &amp; regression you do have the option to turn off automatic featurization.     <\/p>\n<p>featurization    <br \/>\nstr or FeaturizationConfig    <br \/>\n'auto' \/ 'off' \/ FeaturizationConfig Indicator for whether featurization step should be done automatically or not, or whether customized featurization should be used.    <br \/>\n\u2026    <br \/>\nNote: Timeseries features are handled separately when the task type is set to forecasting independent of this parameter.    <\/p>\n<p>\u2022\t<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\">AutoMLConfig Class<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can I use compressed data on TabularDataset?",
        "Question_created_time":1638234150553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/645118\/can-i-use-compressed-data-on-tabulardataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a question about <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#tabulardataset\">the source of TabularDataset on Azure Machine Learnigng<\/a>.    <\/p>\n<p>Can I use compressed data saved Azure Data Lake Storage Gen2 like below on TablarDataset without expansion?    <\/p>\n<ul>\n<li> csv with bzip2(.bz2)    <\/li>\n<li> parquet with gzip(gz)    <\/li>\n<li> parquet with snappy    <\/li>\n<\/ul>",
        "Question_closed_time":1638238520327,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, tabular dataset does not support compressed files. You'll need to extract the data as shown <a href=\"https:\/\/medium.com\/mlearning-ai\/load-json-gz-files-to-azure-ml-dataset-b7039ec9da34\">here<\/a> for example before creating a tabular dataset. However, file dataset supports any format.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Internal server error while deploying scoring endpoint",
        "Question_created_time":1638274714127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646024\/internal-server-error-while-deploying-scoring-endp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Dear Azure community,  <\/p>\n<p>Unfortunately, I am currently failing to deploy a scoring endpoint via ml studio or via the azure cli. I always get an internal server error (500). It's not because of the qutoas (I already requested additional ones).  <\/p>\n<p>The specific configurations and models would be those from the Azure Samples on GitHub (<em>azureml-examples\\cli\\endpoints\\online\\model-1\\onlinescoring\\score.py<\/em> <strong>and<\/strong> <em>azureml-examples\\cli\\endpoints\\online\\managed\\sample\\endpoint.yml and blue-deployment.yml<\/em>  <\/p>\n<p>My own configurations are based on this 1:1. Both configurations are not a problem locally and run smoothly. The server error only comes when deploying online.  <\/p>\n<p>Unfortunately I don't have any further error information from the 500.  <\/p>\n<p>Region: West Europe  <br \/>\nSubscription: Visual Studio Enterprise - MPN  <\/p>\n<p>Has anyone ever had this problem? Could someone please help me here?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot access the storage account with the given account key. Please verify that the account key is valid.",
        "Question_created_time":1629992057303,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/529375\/cannot-access-the-storage-account-with-the-given-a",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Azure ML Users, my model fails on the 2nd module with the error:    <br \/>\nAzureMLCompute job failed.    <br \/>\nBFSMountError: Unable to mount blob fuse file system    <br \/>\nInfo: Could not mount Azure Blob Container azureml-blobstore-547333bb-90a5-4a1c-b9a2-958870d93883 at workspaceblobstore: <strong>Unauthorized<\/strong>. Cannot access the storage account with the given account key. Please verify that the account key is valid.    <br \/>\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.    <\/p>\n<p>The only 2 things I did outside the Azure defaults was in creating the Azure ML workspace resource:    <\/p>\n<ol>\n<li> I created my own new Storage Account.     <\/li>\n<li> created my own Container Registry    <\/li>\n<\/ol>\n<p>I did this so that I could select the lowest priced type in setting up all my resources. Previously, my models ran from Designer, no issues. thank you.    <\/p>\n<p>And how do I run this a command?    <br \/>\n&quot;az ml workspace sync-keys -w myworkspace -g myresourcegroup&quot; to sync up the key again    <\/p>\n<p>screen shot of storage account, showing ML worksspace has access.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/126843-azure-storage-error1.png?platform=QnA\" alt=\"126843-azure-storage-error1.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"dataset.to_pandas_dataframe() throws a ScriptExecution.StreamAccess.Authentication error",
        "Question_created_time":1638194224630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/644562\/dataset-to-pandas-dataframe()-throws-a-scriptexecu",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Azure fails to connect with the Dataset citing 403 inspite of SAS token  <br \/>\nThis appears when we try to load the data as a pandas dataframe . dataset = Dataset.get_by_name() works<\/p>\n<p>Error message:<\/p>\n<p>{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Execution failed in operation 'to_pandas_dataframe' for Dataset(id='data id', name='dataset name', error_code=ScriptExecution.StreamAccess.Authentication,error_message=ScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by AuthenticationException.\\r\\n Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n Failed due to inner exception of type: StorageException\\r\\n| session_id=session_id) ErrorCode: ScriptExecution.StreamAccess.Authentication&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":1638278963500,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The problem was solved by updating the account keys in the workspace.  <br \/>\naz ml workspace sync-keys -w mlw-kundenscore -g rg-datascience<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Where are registered models saved in storage containers?",
        "Question_created_time":1637664392747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/637656\/where-are-registered-models-saved-in-storage-conta",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Have a small doubt. i could run a pipeline successfully and also register the model. I can locate the model on the AzureML UI .  <br \/>\nModel.get_model_path() shows that it is located in azureml-models\/model-name\/..   <\/p>\n<p>But was wondering where exactly they are stored in storage account? Becasue i dont find and container azureml-model listed.   <\/p>\n<p>Any lead on this will be helpful<\/p>",
        "Question_closed_time":1637886171657,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p> <a href=\"\/users\/na\/?userid=2dc066be-691a-47bd-9f7a-67e426d994d9\">@Antara Das  <\/a>  Thanks for the details. there is not an azureml-models container, run.register_model() copies the model files to the azureml container. <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Loosen azureml-dataprep requirements to cloudpickle<=2.0.0",
        "Question_created_time":1637242355487,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/632441\/loosen-azureml-dataprep-requirements-to-cloudpickl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I couldn\u2019t find a specific github repo for azureml-dataprep so I decided to also write you here. Can you forward it to the devs?  <\/p>\n<p>azureml-dataprep (which is a depedency for azureml-dataset-runtime) has requirement cloudpickle&lt;2.0.0 and &gt;=1.1.0. However there is to my knowledage no breaking features going from cloudpickle==1.6.0 to cloudpickle==2.0.0. cloudpickle==2.0.0 introduces some very effective tools for serializing helper scripts which is very helful when working with azureml. So azureml-dataprep should allow cloudpickle&lt;=2.0.0  <\/p>\n<p>Intro to new cloudpickle:  <br \/>\n<a href=\"https:\/\/github.com\/cloudpipe\/cloudpickle#overriding-pickles-serialization-mechanism-for-importable-constructs\">https:\/\/github.com\/cloudpipe\/cloudpickle#overriding-pickles-serialization-mechanism-for-importable-constructs<\/a>  <br \/>\nPR:  <br \/>\n<a href=\"https:\/\/github.com\/cloudpipe\/cloudpickle\/pull\/417\">https:\/\/github.com\/cloudpipe\/cloudpickle\/pull\/417<\/a>  <br \/>\nGithub issue:  <br \/>\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1637\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1637<\/a>  <\/p>",
        "Question_closed_time":1637290125060,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=a10bf22e-b97c-4af2-89b9-23142e132503\">@Thomas H  <\/a>     <\/p>\n<p>Thank you so much for the contribute, I have sent an email to the author for the PR review and merge.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to call my model endpoint that predicts a cars price",
        "Question_created_time":1626832849557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/483566\/how-to-call-my-model-endpoint-that-predicts-a-cars",
        "Question_score_count":0,
        "Question_answer_count":6,
        "Question_comment_count":0,
        "Question_body":"<p>How do I call my model? Do I need to write a client? or can it call from a browser by filling out a form? Thanks. I currently can &quot;test&quot; it using a Notebook python script. Can I make it private so it doesn't get spammed and end up billing my for consumption.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to use pre-defined designer modules when building pipelines using python-sdk?",
        "Question_created_time":1636017242333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/615328\/is-it-possible-to-use-pre-defined-designer-modules",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hey, I am trying to build ML pipelines using the python-sdk. I am wondering if I can use those pre-defined modules from Designer when building pipelines using the python-sdk?<\/p>",
        "Question_closed_time":1636079210010,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=e1f49cb3-80a0-42db-98e1-dae1d9419473\">@Chris-2395  <\/a>     <\/p>\n<p>Thanks for reaching out to us. But this currently is under development and we have no exact ETA for it.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to update the labelled tags in the azure machine learning ?",
        "Question_created_time":1637728063797,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/638862\/how-to-update-the-labelled-tags-in-the-azure-machi",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/151940-test-img.png?platform=QnA\" alt=\"151940-test-img.png\" \/>  <br \/>\nHow can I edit the existing tags and it will update to the tags in labelled images.  <br \/>\nFor example :  <br \/>\nEdit the tags['test1'] to new tag['Breeze'] and the tags['test1] in the image will replace with the new tag ['Breeze']  <br \/>\nHow can I do it in the azure UI or by using python<\/p>",
        "Question_closed_time":1637743807057,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2dae0229-1f81-4758-967b-90d1919f4e0f\">@Zi Xiang Yan  <\/a> You can edit the tags using the Details tab -&gt; Label Classes screen of your project from the portal. If the project is in paused state you can add new labels and choose the required option to continue or start over by keeping existing labels or removing all labels and relabel.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/152182-image.png?platform=QnA\" alt=\"152182-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Got error \"TimeseriesDfUniqueTargetValueGrain\" with AutoML",
        "Question_created_time":1637800802320,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/640215\/got-error-timeseriesdfuniquetargetvaluegrain-with",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>&quot;message&quot;: &quot;The input data contains time series with only unique target values. One such series that displays this behavior is the time series 5962. Please only provide series with non-unique target values.&quot;  <\/p>\n<p>Got this error when trying to use AutoML training time series models. I am not sure what this error means and where to find this time series 5962. Could someone please explain what is going wrong with this data and where do I find time series 5962?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML private notebooks (multiple user\/project)",
        "Question_created_time":1637769772467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/639765\/azure-ml-private-notebooks-(multiple-user-project)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello all,  <\/p>\n<p><em>Use case:<\/em>  <br \/>\nActually, I would like to prevent some users (guest user for example) from viewing some notebooks with sensitive data. I started by creating several Azure ML workspaces but given the limit of storage accounts (250 per subscription), I shared the same storage account for several workspaces... And  I was surprised that the same notebooks were shared in all workspaces for all users.  <\/p>\n<p>So, I try to understand how to work on Azure Machine Learning while managing notebook access.   <\/p>\n<ol>\n<li> Multiple workspace with multiple storage account = Limited in the long term as we have a lot of projects (max 250 storage acc)...  <\/li>\n<li> Multiple workspace  with same storage account  = all notebooks shared...Impossible to work with guest users...  <\/li>\n<\/ol>\n<p><em><strong>Because these two issues, I was wondering:<\/strong><\/em>  <\/p>\n<ul>\n<li> What is the way to limit access to some Azure Machine Learning Notebooks?  <\/li>\n<li> Is there any good practice about multiple project with AML workspaces ? (One workspace per project or one workspace per environment)  <\/li>\n<\/ul>\n<p>Kind regards,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to spin up Azure DBX cluster despite numerous quota increase request",
        "Question_created_time":1637257327543,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/632708\/unable-to-spin-up-azure-dbx-cluster-despite-numero",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team,   <\/p>\n<p>We are unable to spin up even a basic Azure DBX cluster since yesterday because of the following error. We have made numerous requests for quota increase, but to no avail.   <\/p>\n<p>Cluster terminated.Reason: Azure Operation Not Allowed Exception  <\/p>\n<p>Error code: OperationNotAllowed, error message: Operation could not be completed as it results in exceeding approved standardDSv2Family Cores quota. Additional details - Deployment Model: Resource Manager, Location: westus, Current Limit: 10, Current Usage: 8, Additional Required: 8, (Minimum) New Limit Required: 16.   <\/p>\n<p><strong>Request Summary \/ New Limit:  DSv2 Series, (US) West US \/ 120<\/strong>  <br \/>\n My request for DSv2 Series, West US for 120 CPU was approved this morning, and yet I am unable to spin up the cluster. Any help is greatly appreciated! <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Data Labeling - Refresh",
        "Question_created_time":1636385510357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/619198\/azure-machine-learning-data-labeling-refresh",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I've started a new Data labeling project in Azure Machine Learning and I configured the incremental refresh.   <\/p>\n<p>How often is the data refreshed? Is it possible to force a refresh manually? Is it possible to execute this command via SDK (Python or PowerShell)?  <\/p>\n<p>Thanks.  <\/p>\n<p>G<\/p>",
        "Question_closed_time":1636424689197,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, data is <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-image-labeling-projects#--configure-incremental-refresh\">refreshed<\/a> within 24hrs. Currently, incremental refresh is only enabled using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-image-labeling-projects#details-tab\">portal<\/a> and there's no option to trigger refresh manually.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to run python 2.7 scripts on a computer cluster",
        "Question_created_time":1637171846430,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/631040\/how-to-run-python-2-7-scripts-on-a-computer-cluste",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am aware that azureml will drop support for python 2.7, but I have got some old codes and have to finish training the models. Since I will not use the codes afterwards anyway, so I do not want to spend much time to port to python 3.  <\/p>\n<p>As I tried to run the codes in python 2.7 on a compute cluster, I got the error <code>ImportError: cannot import name OutputFileDatasetConfig<\/code> coming from this line:  <br \/>\n<code>from azureml.data import OutputFileDatasetConfig<\/code>   <br \/>\nThe environment, that I have created for python 2.7, has azureml-core v1.1.5. I cannot find any documentation for this version, so I do not know, if it supports <code>OutputFileDatasetConfig<\/code>.  <\/p>\n<p>Can someone tell me, how I can run my codes in python 2.7 on compute clusters? Thanks!   <\/p>",
        "Question_closed_time":1637207379763,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=0f653a2d-e976-46b6-9242-19e12e493242\">@Lu  <\/a>     <\/p>\n<p>Thanks for reaching out to us. I have not found any official document either.     <\/p>\n<p>In this scenario, I think the quickest way to solve the problem is to raise a support ticket.    <\/p>\n<p>Let me know if you have no support plan, please share the ticket id since I will forward this issue to product team to see what we can do more.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Local Deployment Azure ML failed with error",
        "Question_created_time":1631297380170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/547716\/local-deployment-azure-ml-failed-with-error",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am a beginner in the Azure. I am using this tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a> of setting a dummy script for a local web service but many errors are coming up. It is strange because I am using an h5 file (model involving Keras and tensor flow) in place of onxx file. I used the code    <\/p>\n<pre><code>from azureml.core import Environment  \nfrom azureml.core.model import InferenceConfig  \n  \nenv = Environment(name=&quot;myenv&quot;)  \nconda_dep = CondaDependencies()  \nconda_dep.add_conda_package(&quot;tensorflow&quot;)  \nconda_dep.add_conda_package(&quot;pip&quot;)  \nconda_dep.add_pip_package(&quot;azureml-core&quot;)  \nconda_dep.add_pip_package(&quot;azureml-contrib-services&quot;)  \nconda_dep.add_pip_package(&quot;azureml.api&quot;)  \nenv.python.conda_dependencies=conda_dep  \ninference_config = InferenceConfig(  \n    environment=env,  \n    source_directory=&quot;.\/source_dir&quot;,  \n    entry_script=&quot;.\/echo_score.py&quot;,  \n<\/code><\/pre>\n<p>)    <\/p>\n<p>I am trying to deploy the model local using Webservice. But always getting some error. I have tried many times but does not work. I am always getting some error. It is bizarre.    <\/p>\n<p> $ conda update -n base -c defaults conda    <\/p>\n<p>Pip subprocess error:    <br \/>\nERROR: Could not find a version that satisfies the requirement azureml.api (from -r \/azureml-environment-setup\/condaenv.811vr6y8.requirements.txt (line 4)) (from versions: none)    <br \/>\nERROR: No matching distribution found for azureml.api (from -r \/azureml-environment-setup\/condaenv.811vr6y8.requirements.txt (line 4))    <\/p>\n<p>CondaEnvException: Pip failed    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scaling and load balancing with deployed machine learning containers - ACI + Application Gateway vs AKS?",
        "Question_created_time":1637592050953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/636334\/scaling-and-load-balancing-with-deployed-machine-l",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have been working on a deployment solution for machine learning models. Our objective is to minimize the internal development effort while maintaining high availability and full control over the API. Our first solution is a deployment as azure webservice to ACI using the <code>azureml.core.model.Model.deploy<\/code> method with a deployment config <code>azureml.core.webservice.AciWebservice<\/code>.  <br \/>\nWe quickly noticed that our initial deployment configuration was not powerful enough and wanted to upgrade the hardware. Here is the first issue: it seems that the ACI webservice does not support any GPU instances. So my first question is: which service is recommended to deploy models that require GPU for inference?  <br \/>\nHowever, we first wanted to deploy the same image onto a more powerful CPU. When doing this, we got the error  <br \/>\n &quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;. After deleting and redeploying, the scoring URI changes, which is a problem for us. As we cannot predict the load and resource requirements at this point, we need a way of (auto-) scaling the containers and also to update single container resource requirements, without changing the endpoint. As this seems to be impossible using the scoring URI provided by azureml endpoint, I had the feeling that we need to hide the azureml endpoint behind a load balancer. Is this the intended way of doing it? If so, should I use application gateway or traffic manager? If I use application gateway, how do I configure the VPC such that the containers managed by azureml are available to application gateway? Or should I completely abandon ACI and go with AKS? It would be great to get some expert feedback on this as I feel like every single of these questions leads me down a rabbit hole and I cannot continue the actual project if I first have to learn about &gt;10 azure services and all cross combinations of those.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Terminal is blank, while compute instance is running",
        "Question_created_time":1637237700637,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/632304\/terminal-is-blank-while-compute-instance-is-runnin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>For about 2 or 3 days, the terminal hasn't been showing properly.     <br \/>\nIf I open a new terminal, it shows properly. After I switch to another terminal\/script\/notebook tab, and then switch back to the previous terminal tab, it is then blank (see screenshot below). I tried on 2 different compute instances as well as in 2 different browsers incl. edge, the same problem remains.     <br \/>\nDoes anyone have the same problem and the solution?     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150579-blank-terminal.png?platform=QnA\" alt=\"150579-blank-terminal.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"IoT Edge custom machine learning module reported error status",
        "Question_created_time":1637069073437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/629089\/iot-edge-custom-machine-learning-module-reported-e",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,     <\/p>\n<p>I have developed a ML solution based on <a href=\"https:\/\/github.com\/Azure\/ai-toolkit-iot-edge\/tree\/master\/IoT%20Edge%20anomaly%20detection%20tutorial\">this<\/a> tutorial.     <br \/>\nI adapted the Python notebook to run into an existing ML workspace.      <br \/>\nUnfortunately, when I tried to create Docker image, it failed with error 500. I found out that the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.image?view=azure-ml-py\">Image class<\/a> is deprecated (suppose this was the reason of the error), so I relied on the Environment class (in particular <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\">this<\/a> documentation) and everything worked fine.     <br \/>\nAlso, testing the model as Web Service ACI endpoint works correctly, providing the result:    <br \/>\n <em>['{&quot;machine&quot;: {&quot;temperature&quot;: 31.16469009, &quot;pressure&quot;: 2.158002669}, &quot;ambient&quot;: {&quot;temperature&quot;: 21.17794693, &quot;humidity&quot;: 25}, &quot;timeCreated&quot;: &quot;2017-10-27T18:14:02.4911177Z&quot;, <strong>&quot;anomaly&quot;: false}'<\/strong>]<\/em>     <\/p>\n<p>The issue I need support is the following: after deploying the ML model as container to the Edge device (in this case a Ubuntu VM created using <a href=\"https:\/\/raw.githubusercontent.com\/Azure\/iotedge-vm-deploy\/master\/edgeDeploy.json\">this<\/a> template), the ML module reported an error:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/149726-2021-11-16-12h28-16.png?platform=QnA\" alt=\"149726-2021-11-16-12h28-16.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/149789-2021-11-16-12h27-46.png?platform=QnA\" alt=\"149789-2021-11-16-12h27-46.png\" \/>    <\/p>\n<p>No logs are displayed, neither through VM SSH access, nor through the Portal.     <\/p>\n<p>The only information that I found out is this one:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/149746-2021-11-16-12h30-37.png?platform=QnA\" alt=\"149746-2021-11-16-12h30-37.png\" \/>    <\/p>\n<p>I checked multiple times the correctness of the image URI for the ML module, and I'm pretty confident that it is, since the ACI is based on it and the Web Service test was succeded.     <\/p>\n<p>What could be the problem here?     <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failed to install python 3.5",
        "Question_created_time":1636717036753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/625123\/failed-to-install-python-3-5",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I need a conda environment with python 3.5.     <\/p>\n<p>While I was creating one, it showed in the specification that python 3.5 would be installed. But after the environment was created, python version was 3.8 instead of python 3.5 (pls. see the screenshot below)    <br \/>\nI tried to create a new env with python 3.5 twice, but always python 3.8 in the end.    <\/p>\n<p>I found someone had similar issue <a href=\"https:\/\/stackoverflow.com\/questions\/54072811\/how-to-change-the-python-version-in-azure-machine-learning-sdk-containerimage-wi\">here<\/a>, but I didn't find solution to this issue.    <\/p>\n<p>Can someone explain why it happens? Thanks!    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/148835-cannot-install-py35.png?platform=QnA\" alt=\"148835-cannot-install-py35.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML lab : Error in deparse1(call): could not find function \"deparse1\" when executing R Script",
        "Question_created_time":1637247331003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/632506\/aml-lab-error-in-deparse1(call)-could-not-find-fun",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there<\/p>\n<p>My Azure ML lab model was running fine until today when I get this error when running an R script:<\/p>\n<p>Error in deparse1(call): could not find function &quot;deparse1&quot;<\/p>\n<p>I tried the suggestion to set the env var &quot;AZUREML_COMPUTE_USE_COMMON_RUNTIME&quot; : &quot;false&quot; but still failing<\/p>\n<p>Full error:<\/p>\n<blockquote>\n<p>AmlExceptionMessage:User program failed with FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from R interpreter ----------  <br \/>\nGot exception when invoking script: 'Script failed with error message:  <br \/>\nError in deparse1(call): could not find function &quot;deparse1&quot;<\/p>\n<p>azureml_main(input_dataframe_1, input_dataframe_2), mine_rules_general(), mine_rules(.GlobalEnv$df, base_str, conf, NULL, aggregate_categories, multilevel, params), apriori(.GlobalEnv$dataset, parameter = params), .handleSimpleError(function (e)  <br \/>\n{  <br \/>\nerror_msg &lt;&lt;- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = &quot;\\n&quot;)  <br \/>\nstop(e)  <br \/>\n}, &quot;could not find function \\&quot;deparse1\\&quot;&quot;, quote(deparse1(call))), h(simpleError(msg, call))  <br \/>\n'.  <br \/>\n---------- End of error message from R interpreter ----------<\/p>\n<p>ModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from R interpreter ----------  <br \/>\nGot exception when invoking script: 'Script failed with error message:  <br \/>\nError in deparse1(call): could not find function &quot;deparse1&quot;<\/p>\n<p>azureml_main(input_dataframe_1, input_dataframe_2), mine_rules_general(), mine_rules(.GlobalEnv$df, base_str, conf, NULL, aggregate_categories, multilevel, params), apriori(.GlobalEnv$dataset, parameter = params), .handleSimpleError(function (e)  <br \/>\n{  <br \/>\nerror_msg &lt;&lt;- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = &quot;\\n&quot;)  <br \/>\nstop(e)  <br \/>\n}, &quot;could not find function \\&quot;deparse1\\&quot;&quot;, quote(deparse1(call))), h(simpleError(msg, call))  <br \/>\n'.  <br \/>\n---------- End of error message from R interpreter ----------<\/p>\n<\/blockquote>\n<p>Would much appreciate any help on this<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best Approach to Clientside Machine Learning for Text Classification",
        "Question_created_time":1637112667940,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/629917\/best-approach-to-clientside-machine-learning-for-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have approximately 100k rows of text data (initially PDF documents that have been OCR). Most are rows of less than 5000 characters. Each of the source documents are addressed to some department. These are typically in the form of the below examples where the target department would 'Urology' (there are several departments).    <\/p>\n<ul>\n<li> Urologly Department  <\/li>\n<li> Urologly Clinic  <\/li>\n<li> Urology Out Patients  <\/li>\n<li> Urology  <\/li>\n<li> Dear urology team  <\/li>\n<\/ul>\n<p>I have read a bit on ML Text Analysis and it seems I should be able to make a pretty good model by reviewing several hundred documents for each department (I have built an App to help me do this) and manually Classifying those documents. Some documents may mention urology but are actually addressed to another department. Typically the addressed department text is at the top third (first 3-7 lines) of the text body.               <\/p>\n<p>I cannot use any online tools, i.e. I can't upload any of the Document text to servers to process I need a client side library. I have read and completed several tutorials using the ML.net but these are pretty basic (sentiment, entity detection without any initial training), and read an excellent blog at <a href=\"+https:\/\/monkeylearn.com\/blog\/how-to-create-text-classifiers-machine-learning\/\">MonkeyLearn<\/a>: which seems to acknowledge that can do what I imagine I should be able to do.    <\/p>\n<p>So can anybody point me in the right direction, can I use some offline Microsoft client library to complete my task? Is there some other Open Source client library i should look at. Will I have to learn Go, or python to complete the task (currently a C# dev).   <\/p>\n<p>Note: I could get fairly good matches simply using SQL Text search and a bit of C# with plenty of hard coded rules, but I thought I'd try ML -- however its a nest of complications at the moment   and i am going around in circles.       <\/p>\n<p>Many Thanks  <br \/>\nMike.        <\/p>",
        "Question_closed_time":1637144398317,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=68a37785-70de-4e30-ac8d-ab0658ca67f4\">@Mike Shapleski  <\/a> I see two possible solutions for your scenario.    <\/p>\n<ol>\n<li> Extracting text from your documents using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/computer-vision\/vision-api-how-to-topics\/call-read-api\">computer vision API<\/a> and passing the required text as input to Azure <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/text-analytics-for-health\/overview?tabs=ner\">Text Analytics for Health API<\/a>    <\/li>\n<li> Using <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/search\/search-what-is-azure-search\">Azure cognitive search<\/a> to upload the documents and creating a search service and enabling specific <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/search\/cognitive-search-predefined-skills\">skills<\/a> on the service to extract PII data or entities    <\/li>\n<\/ol>\n<p>The first solution can help you achieve this and ensure everything is offline or using docker containers without uploading any of your data to any storage externally. For billing purposes the containers need to connect to a metering endpoint on Azure to bill your usage of both these services(<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/computer-vision\/computer-vision-how-to-install-containers?tabs=version-3-2\">Computer Vision API<\/a> &amp; <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/text-analytics-for-health\/how-to\/use-containers\">Azure text analytics<\/a> containers). Also, you can use C# client library to call the local endpoint of these containers. The setup could take time to configure docker containers and passing the PDF documents to the computer vision read API to extract text. The extracted text can then be directly used or stored, to call the text analytics for health API.    <\/p>\n<p>The second solution can be used to index all the documents by using the search service by having your data in the cloud or behind a firewall to index the documents and make them searchable. There are some skills that can be enabled on the search service to extract entities and other PII information but this may not extract the same data as text analytics for health. This solution can be faster to setup because you can directly query your data after uploading the documents.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"build an AZURE ML enviroment from docker image in dockerhub",
        "Question_created_time":1635963924763,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/614519\/build-an-azure-ml-enviroment-from-docker-image-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I want to use <a href=\"https:\/\/hub.docker.com\/layers\/shi2yu3\/mainz\/v7_nccl2804\/images\/sha256-298ca59f25e56ff8d0f3faeb7493618ff7d69149e6a92283ed3176a215b8da8d?context=explore\">https:\/\/hub.docker.com\/layers\/shi2yu3\/mainz\/v7_nccl2804\/images\/sha256-298ca59f25e56ff8d0f3faeb7493618ff7d69149e6a92283ed3176a215b8da8d?context=explore<\/a> in Azure ML as an environment for model training and testing. Any idea how to do this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML kernel",
        "Question_created_time":1637143159873,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/630550\/azure-ml-kernel",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I installed custom env and added it to jupyter on my compute instance.     <br \/>\nYet, when I run the code error says that it occurs under base env (azureml_py38)    <\/p>\n<p>see the pic. Can you help me?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150128-capture.png?platform=QnA\" alt=\"150128-capture.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML workspace: IP addresses of compute instances and clusters",
        "Question_created_time":1636666325000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/624341\/azureml-workspace-ip-addresses-of-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>For the compute instances\/clusters in our AzureML studio workspace to communicate with our Snowflake server, we need to provide their IP addresses to Snowflake admin for whitelisting.  <\/p>\n<ol>\n<li> When a compute instance is created, it comes with a static IP address, which is random. Is it possible to limit the IP addresses to a pre-defined range so that our snowflake admin can whitelist the range, instead of individual IP address of each compute instance?  <\/li>\n<li> When a cluster is created, the IP address changes each time it is scaled up from 0 nodes. This makes it impossible to whitelist. Is it possible to limit the IP address to a pre-defined range as well?  <br \/>\nOur AzureML workspace is currently not behind any virtual network yet. Any suggestions about the direction to secure our workspace and facilitate its outbound communication (especially with snowflake servers) are highly appreciated. Thanks! <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning studio Classic",
        "Question_created_time":1635868717057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/612915\/azure-machine-learning-studio-classic",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone  <br \/>\nI am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.'  <\/p>\n<p>As mentioned above, what do resources mean? Can you be please specific which services won't be available? Web services? Experiments? Projects?  <\/p>\n<p>Will I be able to create new BLANK EXPERIMENTS after December 2021?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where can and should I save a trained model?",
        "Question_created_time":1636989187060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/627680\/where-can-and-should-i-save-a-trained-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am new to Azure and am currently having a problem with saving a CNN model that is created by my training script. I am currently trying to save it in my project folder under the 'outputs' directory yet the model refuses to be saved. The size is over 300 MB so that may be a further problem. I have looked around for a solution but have not seen much that could help me. I am using PyTorch and am trying to save my model using the torch.save(...) function into a .tar file. Now, my question is how and where should one save the models generated by a training script and how would one ultimately load that same model to then use it for inference? Any help is greatly appreciated :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"clean up resources",
        "Question_created_time":1636923021220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/626538\/clean-up-resources",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am trying to learn about machine learning and using the free resources. I read here about cleaning up resources:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#clean-up-resources\">https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#clean-up-resources<\/a>    <\/p>\n<p>I was wondering how this works.     <\/p>\n<p>Suppose I am trying to build a recommender app:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#recommender\">https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#recommender<\/a>    <\/p>\n<p>This will easily take a few hours. If I delete the resource I would have to start over again. Surely Microsoft cannot have meant it like that, right? How do I go about using my free resources without busing my limits.    <\/p>\n<p>Thanks,    <\/p>\n<p>Naveen<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Nvidia gpu virtual machine on azure",
        "Question_created_time":1636877222933,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/626330\/nvidia-gpu-virtual-machine-on-azure",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I would want to create a nvidia gpu-intel\/amd cpu combination in my virtual machine but unable to find a &quot;size&quot; type NV8as_v4 (amd raedon graphics card &amp; amd cpu).  <br \/>\nBut I wanted nvidia gpu for simulating and remote display purposed to my local machine.  <br \/>\nI wanted region availability and suitable nvidia gpu for simulation purposes.  <br \/>\nRequest for relevant solutions or methods in this regard.  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Endpoint Record Limit",
        "Question_created_time":1636729296570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/625373\/azureml-endpoint-record-limit",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p> I have a customer who is receiving a 424 error when they try to pass 13k records to an endpoint for inference but succeeding when passing 6k records. My questions are:  <br \/>\nWhat are the record limits for managed endpoints and does this vary by compute?  <br \/>\nIs there a way to reconfigure this limitation or is the best solution to have them loop over the records if they're over the limit?  <br \/>\n74900502&gt;<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML realtime endpoint provisioning fail",
        "Question_created_time":1632622407193,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566381\/azure-ml-realtime-endpoint-provisioning-fail",
        "Question_score_count":2,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135273-screenshot-2021-09-26-074403.png?platform=QnA\" alt=\"135272-screenshot-2021-09-26-074403.png\" \/>When creating the azure ml real-time endpoint, at the end of the journey the provisioning is falling. The reason for the failure is not included. Have anyone have an idea why that is happening and how to solve that?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to move all the ai models (service endpoints) from one compute cluster to another cluster in azure  without any effects",
        "Question_created_time":1636704232043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/624851\/how-to-move-all-the-ai-models-(service-endpoints)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><strong>I have machine learning models which is deployed in Azure aks in 'x' Cluster , Now i want to move this models and its endpoint in another cluster which is 'y' within same workspace and subscription ,So how to do this without any changes to its rest endpoint as this endpoints are in production use already.<\/strong>  <\/p>\n<p><strong>also if this is not possible then can i upgrade my x cluster with newer version without affecting my endpoints<\/strong>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Check Azure ML Instance Type",
        "Question_created_time":1636608553670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/623173\/check-azure-ml-instance-type",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How do i check current instance of AzureML type ? Where menu can i acces to see the type ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Trouble Accessig the Machine Learning resource on my Azure for Students account",
        "Question_created_time":1636577704690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/622698\/trouble-accessig-the-machine-learning-resource-on",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to create a machine learning resource with my Azure for Students account, but every time I hit create it tells me that I need to upgrade my account to access it. I have confirmed that I do have an azure for students account, I don't know why I can't create the resource. Any guidance would be helpful. Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Attached AKS not available in Azure ML Create Model Deployment UI",
        "Question_created_time":1636497254520,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/621129\/attached-aks-not-available-in-azure-ml-create-mode",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have AKS cluster attached with Azure ML for inference cluster,    <br \/>\nBut when i try to create End point using UI, kubernetes cluster is not available in the drop down menu    <br \/>\nwhy the AKS cluster that attached in Azure ML is not available in the drop down menu?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/147944-capture.png?platform=QnA\" alt=\"147944-capture.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error 404: AciDeploymentFailed",
        "Question_created_time":1635187234100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/603277\/error-404-acideploymentfailed",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>I am trying to deploy a machine learning model through an ACI (Azure Container Instances) service. I am working in Python and I followed the following code (from the official documentation : <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli<\/a>) :<\/p>\n<p>from azureml.core import Workspace<\/p>\n<pre><code>from azureml.core import Workspace  \n\n# Connect to workspace  \nws = Workspace(subscription_id=&quot;my-subscription-id&quot;,  \n               resource_group=&quot;my-ressource-group-name&quot;,  \n               workspace_name=&quot;my-workspace-name&quot;)  \n\nfrom azureml.core.model import Model  \n\nmodel = Model.register(workspace = ws,  \n                       model_path= 'model.pkl',  \n                       model_name = 'my-model',  \n                       description = 'my-description')  \n\n\n\n%%writefile score.py  \n\nimport os  \nimport dill  \nimport joblib  \n\ndef init():  \n    global model  \n    # Get the path where the deployed model can be found  \n    model_path = os.getenv('AZUREML_MODEL_DIR')  \n\n    # Load existing model  \n    model = joblib.load('model.pkl')  \n\n# Handle request to the service  \ndef run(data):  \n    try:  \n        # Pick out the text property of the JSON request  \n        # Expected JSON details {&quot;text&quot;: &quot;some text to evaluate&quot;}  \n        data = json.loads(data)  \n        prediction = model.predict(data['text'])  \n        return prediction  \n    except Exception as e:  \n        error = str(e)  \n        return error  \n\n\nfrom azureml.core.environment import Environment  \n\n# Name environment and call requirements file  \n# requirements: numpy, tensorflow  \nmyenv = Environment.from_pip_requirements(name = 'myenv', file_path = 'requirements.txt')  \n\nfrom azureml.core.model import InferenceConfig  \n\n# Create inference configuration  \ninference_config = InferenceConfig(environment=myenv, entry_script='score.py')  \n\nfrom azureml.core.webservice import AciWebservice #AksWebservice  \n\n# Set the virtual machine capabilities  \ndeployment_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 3)  \n\n\nfrom azureml.core.model import Model  \n\n# Deploy ML model (Azure Container Instances)  \nservice = Model.deploy(workspace=ws,  \n                       name='my-service-name',  \n                       models=[model],  \n                       inference_config=inference_config,  \n                       deployment_config=deployment_config)  \n\nservice.wait_for_deployment(show_output = True)  \n<\/code><\/pre>\n<p>I succeded once with the previous code. I noticed that the Model.deploy created a container registry with a specific name 6e07ce2cc4ac4838b42d35cda8d38616.  <br \/>\nThe API was working well and I wanted to deploy an other model from scratch. I deleted the service and model from Azure ML Studio and the container registry from Azure ressources.<\/p>\n<p>Unfortunately I am not able to deploy again anything.<\/p>\n<p>For the last step (the Model.deploy step), I have the following error message :<\/p>\n<blockquote>\n<p>Service deployment polling reached non-successful terminal state, current service state: Unhealthy  <br \/>\nOperation ID: 46243f9b-3833-4650-8d47-3ac54a39dc5e  <br \/>\nMore information can be found here: <a href=\"https:\/\/machinelearnin2812599115.blob.core.windows.net\/azureml\/ImageLogs\/46245f8b-3833-4659-8d47-3ac54a39dc5e\/build.log?sv=2019-07-07&amp;sr=b&amp;sig=45kgNS4sbSZrQH%2Fp29Rhxzb7qC5Nf1hJ%2BLbRDpXJolk%3D&amp;st=2021-10-25T17%3A20%3A49Z&amp;se=2021-10-27T01%3A24%3A49Z&amp;sp=r\">https:\/\/machinelearnin2812599115.blob.core.windows.net\/azureml\/ImageLogs\/46245f8b-3833-4659-8d47-3ac54a39dc5e\/build.log?sv=2019-07-07&amp;sr=b&amp;sig=45kgNS4sbSZrQH%2Fp29Rhxzb7qC5Nf1hJ%2BLbRDpXJolk%3D&amp;st=2021-10-25T17%3A20%3A49Z&amp;se=2021-10-27T01%3A24%3A49Z&amp;sp=r<\/a>  <br \/>\nError:  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;AciDeploymentFailed&quot;,  <br \/>\n&quot;statusCode&quot;: 404,  <br \/>\n&quot;message&quot;: &quot;No definition exists for Environment with Name: myenv Version: Autosave_2021-10-25T17:24:43Z_b1d066bf Reason: Container &gt; registry 6e07ce2cc4ac4838b42d35cda8d38616.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private &gt; link and retry..&quot;,  <br \/>\n&quot;details&quot;: []  <br \/>\n}<\/p>\n<\/blockquote>\n<p>I do not understand why the first time a new container registry was well created, but now it seems that it is sought (the message is saying that container registry identified by name 6e07ce2cc4ac4838b42d35cda8d38616 is missing). I never found where I can force the creation of a new container registry ressource in Python, neither specify a name for it in AciWebservice.deploy_configuration or Model.deploy.<\/p>\n<p>I tried to create the container registry by hand, but this time, this is the container that cannot be created. The output is the folloiwing :<\/p>\n<blockquote>\n<p>Tips: You can try get_logs(): <a href=\"https:\/\/aka.ms\/debugimage#dockerlog\">https:\/\/aka.ms\/debugimage#dockerlog<\/a> or local deployment: <a href=\"https:\/\/aka.ms\/debugimage#debug-locally\">https:\/\/aka.ms\/debugimage#debug-locally<\/a> to debug if deployment takes longer than 10 minutes.  <br \/>\nRunning  <br \/>\n2021-10-25 19:25:10+02:00 Creating Container Registry if not exists.  <br \/>\n2021-10-25 19:25:10+02:00 Registering the environment.  <br \/>\n2021-10-25 19:25:13+02:00 Building image..  <br \/>\n2021-10-25 19:30:45+02:00 Generating deployment configuration.  <br \/>\n2021-10-25 19:30:46+02:00 Submitting deployment to compute.  <br \/>\nFailed<\/p>\n<p>Service deployment polling reached non-successful terminal state, current service state: Unhealthy  <br \/>\nOperation ID: 93780de6-7662-40d8-ab9e-4e1556ef880f  <br \/>\nCurrent sub-operation type not known, more logs unavailable.  <br \/>\nError:  <br \/>\n{  <br \/>\n&quot;code&quot;: &quot;InaccessibleImage&quot;,  <br \/>\n&quot;statusCode&quot;: 400,  <br \/>\n&quot;message&quot;: &quot;ACI Service request failed. Reason: The image '6e07ce2cc4ac4838b42d35cda8d38616.azurecr.io\/azureml\/azureml_684133370d8916c87f6230d213976ca5' in container group 'my-service-name-LM4HbqzEBEi0LTXNqNOGFQ' is not accessible. Please check the image and registry credential.. Refer to <a href=\"https:\/\/learn.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account\">https:\/\/learn.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account<\/a> and make sure Admin user is enabled for your container registry.&quot;  <br \/>\n}<\/p>\n<\/blockquote>\n<p>I tried to follow the recommandation of the last message saying to set Admin user enabled for the container registry. Unfortunately the same error message appears again and I am stuck here...<\/p>\n<p>Does anyone could help me omving on with this? The best solution would be I think to delete totally this 6e07ce2cc4ac4838b42d35cda8d38616 container registry but I can't find where the reference is set so Model.deploy always fall to find it.<\/p>\n<p>An other solution would be to force Model.deploy to generate a new container registry, but I could find how to make that.<\/p>\n<p>I need your help !<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Importing\/Exporting Data from SQL Server in Live Endpoint",
        "Question_created_time":1635886704310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/613262\/importing-exporting-data-from-sql-server-in-live-e",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm currently migrating an experiment &amp; webservice over from AzureML Classic to the new AzureML.    <\/p>\n<p>One of the actions the classic webservice did was export data into SQL Server during the run. In the new Azure ML, I have created a new pipeline with an export data module (essentially replicating how it was in classic), however, after reading the docs I'm told this would be removed in a live endpoint? <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data<\/a>    <\/p>\n<p>I need to store the data that is output from the pipeline somewhere. What are the best practice solutions to do this?     <\/p>\n<p>Give me a shout if you need any more info \/ I've not explained the problem well enough!    <\/p>\n<p>Thanks,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issues about Azure Machine Learning Studio",
        "Question_created_time":1635889112067,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/613237\/issues-about-azure-machine-learning-studio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I used the churn hotel prediction model available in the Azure AI platform, the run worked well but when I deploy the model to predict new data I got this error   <\/p>\n<p>Error Message: Edit Metadata : Error 0001: Column with name or index &quot;RoomType-Large&quot; not found  <br \/>\nSite Path: \/subscriptions\/8d1139f0-a7bc-4570-bee1-96cdc6cc3ebe\/resourceGroups\/CIAD_rg\/providers\/Microsoft.MachineLearning\/webServices\/HotelChurnPredic.2021.10.29.14.54.54.485\/test  <br \/>\nActivity ID: 82e53138-b3b9-4a94-8695-0b8152c505ac  <br \/>\nRequest ID: 60e1fa59-3e40-4c6e-a572-ec0db880c60e  <br \/>\nWorkspace ID: 1b056c4b2e4049019cfaa7c025124ed7  <br \/>\nSubscription ID: 8d1139f0-a7bc-4570-bee1-96cdc6cc3ebe  <br \/>\nWorkspace Type: PaidStandard  <br \/>\nUser Role: Owner  <br \/>\nTenant ID: d55854d3-e3d2-49fa-a866-89c3f2165d95  <\/p>\n<p>The link for the model: <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Hotel-Churn-Predictive-Exp\">https:\/\/gallery.azure.ai\/Experiment\/Hotel-Churn-Predictive-Exp<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use model created in Azure AutoML",
        "Question_created_time":1636445777447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/620181\/how-to-use-model-created-in-azure-automl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Absolute Azure beginner here.  <\/p>\n<p>I created a forecast model, and I can forecast next month when I deploy and test the model on Azure.  <\/p>\n<p>However, I would like to read the pickle file, turn it and predict more than only the next month, let's say one year.   <\/p>\n<p>Then I would like to do something like this:  <\/p>\n<pre><code>y_pred = model.predict(x_test)\n<\/code><\/pre>\n<p>How can I achieve this? I tried reading the pickle file but it only returns an object which I am unsure of what to do with.  <\/p>\n<p>Kind regards and thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"LSTM Algorithm regarding accuracy",
        "Question_created_time":1636431320857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/619877\/lstm-algorithm-regarding-accuracy",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,  <\/p>\n<pre><code>  I have implemented LSTM algorithm for my project ,It is giving accuracy o.13 which is very low , Is there any way to increase my accuracy\n<\/code><\/pre>\n<p>kindly respond ,waiting for guidance please help  <\/p>\n<p>Let me know if any additional information required  <\/p>\n<p>Thanks in advance<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to Build an User Specific Machine Learning Model?",
        "Question_created_time":1636444026477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/620019\/how-to-build-an-user-specific-machine-learning-mod",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>As a company, we are planning to build an easy, user-specific navigation recommender. This tool will make recommendations based on the user's navigation search history. We are familiar with Azure ML Studio, yet wondering how we can train user-specific machine learning models and give users recommendations through them. So, instead of building one big machine learning model for all users, we are looking for training and inferencing user-specific machine learning models.   <\/p>\n<p>We really appreciate any help you can provide.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MLnet Choosing an Algorithm for ranking categories matching a sentence",
        "Question_created_time":1636351700077,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/618483\/mlnet-choosing-an-algorithm-for-ranking-categories",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am looking to train a model to suggest tags\/categories for a given text string.   <\/p>\n<p>eg: &quot;the fox is weak and limping&quot; = [1-animal],[34-weak],[2667-injury],[16-foot] (a list of tags each with probabilities generated by past associations)  <\/p>\n<p>This data would be trained from a data set of many instances of text each with a corresponding string representing the list of tags that match the text.  <\/p>\n<p>Is there a way to featurize the text AND the result tags? And apply an algorithm to cross reference them?  <br \/>\nThe closest I have come is the idea of duplicating each of the training data rows so that each row has only one tag at a time.  <\/p>\n<p>I have been researching this question for a week and am thinking the problem is how I am asking it! Everything I have read does not hint at an existing algorithm to match this use case so should I look towards manipulating the data to a different structure.  <\/p>\n<p>Any help greatly appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Naming the NSG, PIP and NLB resources",
        "Question_created_time":1635766129500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/611217\/azure-machine-learning-naming-the-nsg-pip-and-nlb",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, is there a way to predefine the Load balancer, Network security group and Public IP resource names for the Compute instances (as posted <a href=\"https:\/\/twitter.com\/simonmagrin\/status\/1455124512438054916?s=20\">here<\/a>), rather than Azure randomly generate names for those three specific resources? Happy to use <strong>az cli<\/strong>, PowerShell or ARM to predefine these resources. Thanks    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/145475-2021-11-01-21-45-38-test-microsoft-azure.png?platform=QnA\" alt=\"145475-2021-11-01-21-45-38-test-microsoft-azure.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure cosmos db as a datastore in ml",
        "Question_created_time":1597331768270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66297\/azure-cosmos-db-as-a-datastore-in-ml",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I'm wondering if I can register azure cosmos db as a datastore in azure machine learning?     <br \/>\nFrom your documentation, it seems not <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore%28class%29?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore%28class%29?view=azure-ml-py<\/a>    <\/p>\n<ul>\n<li> Do you have a plan to implement the feature in near future?     <\/li>\n<li> Any recommended alternative solutions for now?     <\/li>\n<\/ul>\n<p>Thanks.    <\/p>",
        "Question_closed_time":1597444998180,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, thanks for reaching out. Currently, Cosmos DB isn't a supported datasource when using <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types\">Azure ML datastores<\/a>. However, the product team are aware of this request and will provide updates accordingly. An alternative for now will be to use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/import-from-cosmos-db\">Azure ML Studio (Classic)<\/a> which supports Cosmos DB as data source. You can also try a heuristic approach via <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/execute-python-script\">Execute Python Script module<\/a> in Designer to import data using <a href=\"https:\/\/stackoverflow.com\/questions\/44249604\/how-to-read-data-from-azures-cosmosdb-in-python\">python<\/a>. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"open a csv file",
        "Question_created_time":1636324623930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/618167\/open-a-csv-file",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have a very basic question. I have a CSV file saved in a blob. I need to open that file in ML Studio. whenever I reference the file I just get an error that the file doesn't exist. Please help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"About the end of Machine Learning Studio (classic)#2",
        "Question_created_time":1636119906810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/616952\/about-the-end-of-machine-learning-studio-(classic)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>hello.  <\/p>\n<p>I am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.  <\/p>\n<p>Is the following interpretation correct?  <\/p>\n<p>Things you can't do from 1 December 2021  <br \/>\n-Creating a workspace for Machine Learning Studio (classic)  <br \/>\n-Creating a web service plan for Machine Learning Studio (classic)  <\/p>\n<p>What you can do until 1 December 2021  <br \/>\n-Creating new Machine Learning Studio (classic) experiments  <br \/>\n-Creating new Machine Learning Studio (classic) trained models  <br \/>\n-Creating a new Machine Learning Studio (classic) web service<\/p>",
        "Question_closed_time":1636209342130,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, customers will not be able to create new ML Studio(classic) workspaces after Dec 1, 2021. However, customers can create or update experiments\/web services in existing workspaces until Aug 31, 2024.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"my script stops running without any message explaining the reason",
        "Question_created_time":1634306015143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/592153\/my-script-stops-running-without-any-message-explai",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Please see the screenshots below. Once it said terminated but without reason:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/140829-screenshot-2021-10-13-221133.png?platform=QnA\" alt=\"140829-screenshot-2021-10-13-221133.png\" \/>    <br \/>\nThe other time there was nothing just stopped:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/140846-screenshot-2021-10-13-215523.png?platform=QnA\" alt=\"140846-screenshot-2021-10-13-215523.png\" \/>    <\/p>",
        "Question_closed_time":1635818701493,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,  <\/p>\n<p>Hope you have solved this issue and we are sorry not seeing your response. Since this issue happened without any error details, support ticket would be the best way to debug that. Please let me know if you still need that. Thanks.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"About the end of Machine Learning Studio (classic)",
        "Question_created_time":1635690920907,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/610432\/about-the-end-of-machine-learning-studio-(classic)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>hello.  <\/p>\n<p>I am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.'  <\/p>\n<p>As mentioned above, what do resources mean?  <br \/>\nIs it possible to continue creating experiments and web sales, and using APIs from outside until 2024?<\/p>",
        "Question_closed_time":1635733766197,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6fde402b-b49f-41d7-8640-5316dd9a5cd2\">@gatsby53  <\/a> ,    <\/p>\n<p>Thanks for reaching out to us here. There are several important dates.    <\/p>\n<p>Beginning 1 December 2021, you will <strong>not be able to create new<\/strong> Machine Learning Studio (classic) resources. You can still work on your <strong>existing resource<\/strong> from 1 December 2021 to 31 August 2024.    <\/p>\n<p>Support for Machine Learning Studio (classic) will end on 31 August 2024. We recommend you transition to Azure Machine Learning by that date.    <\/p>\n<p>Please refer to this guidance for how to migrate your project for better experience.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure AutoML deployment to PowerBI",
        "Question_created_time":1635966824653,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/614605\/azure-automl-deployment-to-powerbi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have deployed an Azure AutoML model and the test seems to look fine (shows all input variables and actually runs the test properly).  But, when I try to use the model in PowerBI, PBI only shows ONE input variable.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use a working pipeline on live dataset?",
        "Question_created_time":1635766961413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/611229\/how-to-use-a-working-pipeline-on-live-dataset",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <br \/>\nI would like to ask a bit help in my custom pipeline because I am stuck at that point where my custom pipeline is working and published but I cannot test it with &quot;live&quot; dataset.    <br \/>\nI tried to follow this article but I have not found my algorithm's name also the endpoint and model menus are empty:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/deploy-model\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/deploy-model<\/a>    <br \/>\nCould anyone help  how to use my custom pipeline at live dataset?    <br \/>\nThank you<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/145460-pipeline.png?platform=QnA\" alt=\"145460-pipeline.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is Designer so slow to execute?",
        "Question_created_time":1601819361423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/116085\/why-is-designer-so-slow-to-execute",
        "Question_score_count":2,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_body":"<p>I'm running the simple tutorials, preparing for DP 100. I was wondering why the execution of Designer Pipelines is so slow, even when running very simple operations and minuscule DataFrames such as Automobile price data (Raw). I also may start working for a company that has been using Azure for Machine Learning and the interviewer commented something along the lines of being it very very slow.  <\/p>\n<p>If a very simple model training pipeline on a 200 records DataFrame took almost 20 minutes, I keep wondering how long it would take to compute a real world data pipeline.  <\/p>\n<p>Any insights? Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiments stuck as queued",
        "Question_created_time":1635394156133,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/606918\/experiments-stuck-as-queued",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have been trying to run experiments through Azure Machine Learning and today they have all been stuck as Queued and nothing is progressing.  I have tried cancelling them but whenever I try to run an experiment is just shows as 'Queued'.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML notebook kernel changes but not really",
        "Question_created_time":1633792808087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/584151\/azure-ml-notebook-kernel-changes-but-not-really",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi, I'm starting to use the ML notebooks in Azure and I'm facing the following issue:    <br \/>\nI create a new conda env and enable it via ipykernel, following the documentation<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/139074-image.png?platform=QnA\">1<\/a>, and install the Pyserini library.    <br \/>\nOn a notebook, I am able to import the library no problem with <code>import pyserini<\/code>, but when I try <code>!python -m pyserini.index<\/code>, it throws me the following error:    <\/p>\n<pre><code>Exception: No matching jar file found in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/pyserini\/resources\/jars  \n<\/code><\/pre>\n<p>Even though I'm not using the AzureML3.6 env    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/139074-image.png?platform=QnA\" alt=\"139074-image.png\" \/>    <\/p>\n<p>My workaround so far has been installing the same library on AzureML3.6, but in the end, it has some incompatibilities with Python 3.6    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting below error while creating dataset",
        "Question_created_time":1633749762887,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/583883\/getting-below-error-while-creating-dataset",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by NotFoundException.\\r\\n Found no resources for the input provided: '[REDACTED]'\\r\\n| session_id=9d60cf18-54e5-457a-910d-5dcd223fa0a0&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>Code I am using is<\/p>\n<h1 id=\"-----------------------------------------------------\">-----------------------------------------------------<\/h1>\n<h1 id=\"import-required-azureml-classes\">Import required azureml classes<\/h1>\n<h1 id=\"------------------------------------------------------1\">-----------------------------------------------------<\/h1>\n<p>from azureml.core import Workspace, Datastore, Dataset<\/p>\n<h1 id=\"------------------------------------------------------2\">-----------------------------------------------------<\/h1>\n<h1 id=\"access-the-workspace-from-the-configjson\">Access the workspace from the config.json<\/h1>\n<h1 id=\"------------------------------------------------------3\">-----------------------------------------------------<\/h1>\n<p>ws = Workspace.from_config(path=&quot;.\/config&quot;)<\/p>\n<h1 id=\"------------------------------------------------------4\">-----------------------------------------------------<\/h1>\n<h1 id=\"access-datastore-by-its-name\">Access datastore by its name<\/h1>\n<h1 id=\"------------------------------------------------------5\">-----------------------------------------------------<\/h1>\n<p>az_store = Datastore.get(ws, &quot;workspaceblobstore&quot;)<\/p>\n<h1 id=\"------------------------------------------------------6\">-----------------------------------------------------<\/h1>\n<h1 id=\"create-and-register-the-dataset\">Create and register the dataset<\/h1>\n<h1 id=\"------------------------------------------------------7\">-----------------------------------------------------<\/h1>\n<h1 id=\"create-the-path-of-the-csv-file\">Create the path of the csv file<\/h1>\n<p>csv_path = [(az_store, &quot;azureml\/EmployeeAC1.csv&quot;)]<\/p>\n<h1 id=\"create-the-dataset\">Create the dataset<\/h1>\n<h1 id=\"create-the-dataset-1\">Create the dataset<\/h1>\n<p>loan_dataset = Dataset.Tabular.from_delimited_files(path=csv_path)<\/p>\n<p>loan_dataset = loan_dataset.register(workspace=ws,  <br \/>\nname=&quot;Employee Using SDK&quot;,  <br \/>\ncreate_new_version=True)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Discontinuation of Azure ML Studio (Classic)",
        "Question_created_time":1635919954397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/613623\/discontinuation-of-azure-ml-studio-(classic)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone  <\/p>\n<p>I am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.'  <\/p>\n<p>As mentioned above, what do resources mean? Can you please be specific about which services won't be available? Web services? Experiments? Projects?  <\/p>\n<p>Will I be able to create new BLANK EXPERIMENTS after December 2021?  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML Hyper Drive - Stuck",
        "Question_created_time":1635931220580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/613972\/aml-hyper-drive-stuck",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using a HyperDriveStep in a Pipeline and often get stuck in HyperDriveStep.   <br \/>\nI am using our company subscription and we have sufficient cores allocated for our ML development.   <\/p>\n<p>We have plan to use this on production very soon. Is it production ready (HyperDriveStep in AML)....!!!??  <\/p>\n<p>Here is the HyperDrive Execution log: I have canceled the child run after 16 hours of waiting......!!!!!  <\/p>\n<p>[2021-11-02 16:01:15Z] Submitting 1 runs, first five are: 5523baba:941f5822-2f1f-4075-a475-5980aa8c6d45  <br \/>\n[2021-11-02 16:03:18Z] Completing processing run id 941f5822-2f1f-4075-a475-5980aa8c6d45.  <br \/>\n[2021-11-02 16:03:18Z] Submitting 1 runs, first five are: 059c259e:7b1e6c57-6469-43cf-8ca7-f05837f0a8fc  <br \/>\n[2021-11-03 08:11:23Z] Execution of experiment canceled, update experiment status and cancel submitted nodes  <\/p>\n<p>My Run ID is : 7e90bbd9-c843-46e0-a611-7810d15a8c92  <\/p>\n<p>Is there anyone can help us on this....!!!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Long Running Experiment",
        "Question_created_time":1635794626850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/611813\/long-running-experiment",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am running a Machine Learning experiment in  Azure Machine Learning Studio (not classic version). The total time of each step in the experiment is 7.5 min, however the overall execution time of the run was 20.5 min. Could someone please explain why there is such a large discrepancy between the total time the experiment took to run compared to the total of each step and what can be done to improve performance.  <\/p>\n<p>Thanks for your help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to activate conda enviornment in AzureML when deploying pipeline with custom docker container",
        "Question_created_time":1635611670527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/610084\/unable-to-activate-conda-enviornment-in-azureml-wh",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have trouble using the environment I've created in a custom docker container while deploying an AzureML pipeline.<\/p>\n<p>Here is what I am doing:<\/p>\n<ol>\n<li>  I create a container which builds a conda enviornment along with other requirements.<\/li>\n<li>  The above container is create on Azure Pipelines and stored on a private azure container repository.<\/li>\n<li>  I pull this container in my pipeline using the below:    aml_run_config.environment.docker.base_image = &quot;xxxx&quot;  <br \/>\n    aml_run_config.environment.docker.base_image_registry.address = (  <br \/>\n    &quot;xxxx.azurecr.io&quot;  <br \/>\n    )  <br \/>\n    aml_run_config.environment.docker.base_image_registry.username = (  <br \/>\n    &quot;xxxx&quot;  <br \/>\n    )  <br \/>\n    aml_run_config.environment.docker.base_image_registry.password = (  <br \/>\n    xxxx  <br \/>\n    )<\/li>\n<\/ol>\n<p>After that I tried two things:<\/p>\n<ol>\n<li>  Use a PythonScriptStep() to call my forecast.py<\/li>\n<li>  Use a CommandStep() with command = &quot;conda run -n build_env python src\/forecast.py&quot;<\/li>\n<\/ol>\n<p>build_env is the name of my conda env<\/p>\n<p>In both cases I get a ModuleNotFoundError for pandas (the first library I use).<\/p>\n<p>If I pull my docker container locally and try exactly the same command, it works fine.<\/p>\n<p>What am I missing?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to Connect Azure MySQL server in Azure Machine Learning Studio",
        "Question_created_time":1635536784630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/609742\/how-to-connect-azure-mysql-server-in-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure machine learning studio I am trying to connect an azure mysql server as a datastore. The azure mysql server was created by a colleague and I have the credentials to connect properly. However, after entering the credentials and creating a datastore, I cannot select the datastore from the dropdown in order to create a dataset. Does machine learning studio have the ability to connect to an azure mysql server?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"About creating a computing cluster with Azure Machine Learning",
        "Question_created_time":1635431417297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/607903\/about-creating-a-computing-cluster-with-azure-mach",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello.  <br \/>\nYou can only select up to one maximum node when Create an Azure Machine Learning compute cluster. How do I select multiple nodes?<\/p>",
        "Question_closed_time":1635456257703,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, you can only select min and max number of nodes that you want to provision. The compute will autoscale to a maximum of this node count when a job is submitted. For more details, review <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python\">Create an AML Compute Cluster<\/a>.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Studio Notebook failing to run simple print statement",
        "Question_created_time":1633027832257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/573362\/azure-machine-learning-studio-notebook-failing-to",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm attempting to run a simple <code>print<\/code> statement in an Azure Machine Learning Studio Notebook and the cell shows status 'Queued' for several minutes, then fails with the message:     <\/p>\n<p>&quot;Web socket error: Your request for data wasn\u2019t sent, your network is possibly blocking websocket. Please configure your workspace to allowing websocket requests. Learn More troubleshoot link.    <br \/>\nTrace ID : 90e47983-d9d0-491f-8834-ac50d4e62156&quot;    <\/p>\n<p>As far as I can see, there are no options on the Workspace (SAW-ML-TEST) having to do with websockets, etc.  I've attempted to log off and back on several times. I've attempted to start and stop my compute instance several times.    <\/p>\n<p>See screenshot for more details:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/136792-screen-shot-2021-09-30-at-14628-pm.png?platform=QnA\" alt=\"136792-screen-shot-2021-09-30-at-14628-pm.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Difference in processing time between Azure Machine Learning Studio and Azure Machine Learning Studio (classic)",
        "Question_created_time":1635432791567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/607943\/difference-in-processing-time-between-azure-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I used to use Azure Machine Learning Studio (classic).  <br \/>\nCreating the same workout in Azure Machine Learning Studio takes about 20 times longer than classic.  <br \/>\nVirtual machine size is Standard_DS3_v2 (4 core\u300114 GB RAM\u300128 GB disk).  <br \/>\nSteps that have been executed once will be processed quickly from the next time onward, but steps that have been changed even slightly will take 20 times longer than classic.  <\/p>\n<p>How can I process at the same speed as classic?<\/p>",
        "Question_closed_time":1635458665073,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for your feedback. AML classic studio appears to be faster in some cases because it uses a Fixed Compute (and always available). However, AML Classic lacks flexibility and scalability that the new platform offers. With designer, you have greater flexibility but depending on the task (e.g. smaller tasks), the processing time may seem longer than classic due to overhead for preparing each step. For smaller tasks, majority of execution time is spent on overhead. Furthermore, when input data changes, it may take longer. If no changes are made, the pipeline would automatically use the cached result of that module, so it should be faster compared to the first run. The product team are aware of this limitation and working to improve the experience. For compute heavy tasks, we recommend you pick a larger VM to improve processing speeds. Please review this document for ways to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-optimize-data-processing\">Optimize Data Processing<\/a>. Feel free to submit feedback directly to the product team by using the 'smiley' feedback icon in Azure ML Studio. Other Similar Posts: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/170450\/\">(1)<\/a>, <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/116085\/why-is-designer-so-slow-to-execute.html\">(2)<\/a>.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Tuning help for Time Series Forecasting model in Azure (AMLS \/ AutoML)",
        "Question_created_time":1635468147490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/608424\/tuning-help-for-time-series-forecasting-model-in-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Casting a wide here for some urgent assistance with ML Tuning.  Looking for a specialist with time series forecasting model experience in azure... someone who knows the inner workings and can help tune things... needs to know how to alter the Alpha hyper-param in AMLS\/AutoML.  The documentation is short in describing the tuning needed.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML for each client in SaaS",
        "Question_created_time":1606883207173,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/182640\/ml-for-each-client-in-saas",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I work for a SaaS and am wanting to release a Machine learning model in a standard structure but with specific learning for each client. That is the training is defined in our software by the client (azure SQL) and then we want to apply that to a trained model for the client to then use in our software.   <\/p>\n<p>What is the best way to do this.   <\/p>\n<p>a. A separate ML model for each client \/ continuous training via web endpoint to import the data and consume   <br \/>\nb. A single ML that has an extra category for ClientID and we pass that into the model?  <\/p>\n<p>Are there any tips, tricks or hacks for Azure ML \/ Studio?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy a ML Model",
        "Question_created_time":1633960741913,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/585717\/unable-to-deploy-a-ml-model",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>I tried to deploy my machine learning model from python (using PyCharm 2018, python 3.9).  <br \/>\nHowever I encountered the following error but when I run &quot;az login&quot; all my subscription information is displayed.  <br \/>\nCan anyone advise?<\/p>\n<p>You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\nInteractive authentication successfully completed.  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 1653, in _get_arm_token_with_refresh  <br \/>\nif (_get_exp_time(access_token) - time.time()) &lt; _TOKEN_REFRESH_THRESHOLD_SEC:  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 1720, in _get_exp_time  <br \/>\ndecode_json = jwt.decode(access_token, verify=False)  <br \/>\nTypeError: decode() got an unexpected keyword argument 'verify'<\/p>\n<p>During handling of the above exception, another exception occurred:<\/p>\n<p>Traceback (most recent call last):  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 276, in wrapper  <br \/>\nreturn test_function(self, *args, **kwargs)  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 427, in _get_arm_token  <br \/>\nreturn self._get_arm_token_using_interactive_auth()  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 521, in _get_arm_token_using_interactive_auth  <br \/>\narm_token = _get_arm_token_with_refresh(profile_object, cloud_type, ACCOUNT, CONFIG, SESSION,  <br \/>\nFile &quot;C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py&quot;, line 1660, in _get_arm_token_with_refresh  <br \/>\nraise AuthenticationException(&quot;Could not retrieve user token. Please run 'az login'&quot;,  <br \/>\nazureml.exceptions._azureml_exception.AuthenticationException: AuthenticationException:  <br \/>\nMessage: Could not retrieve user token. Please run 'az login'  <br \/>\nInnerException decode() got an unexpected keyword argument 'verify'  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;inner_error&quot;: {  <br \/>\n&quot;code&quot;: &quot;Authentication&quot;  <br \/>\n},  <br \/>\n&quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to deploy R script web service via Azure CLI",
        "Question_created_time":1635213453407,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/603664\/how-to-deploy-r-script-web-service-via-azure-cli",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello everyone,    <\/p>\n<p>I am tring to deploy R script as a web service using Azure Machine Learning. I created pipeline as below.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/143603-001.png?platform=QnA\" alt=\"143603-001.png\" \/>    <\/p>\n<p>I can deploy the model and endpoint from [Deploy] button but I cannot control some properties: i.e. resource name, dns name.    <\/p>\n<p>It seems that the <code>az ml model deploy<\/code> command can be used to deploy the endpoint.     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#using-the-azure-cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#using-the-azure-cli<\/a>    <\/p>\n<p>I have no information for <code>inferenceconfig.json<\/code>. How to write <code>score.py<\/code> to execute R script? Is it any example?    <\/p>",
        "Question_closed_time":1635283098257,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, the following document describes how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli#define-an-inference-configuration\">define an inference configuration<\/a>.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How do you see ALL predictors by influence not just the top predictors of AutoML training reports?",
        "Question_created_time":1635159990897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/602784\/how-do-you-see-all-predictors-by-influence-not-jus",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/143408-top-predictors.png?platform=QnA\" alt=\"143408-top-predictors.png\" \/>    <\/p>\n<p>The &quot;top predictors by influence&quot; in the training reports of AutoML regression models is very useful (see reference image), but I'm looking for a way to display all of the predictors, not just the top 10. Any way I can visualise this either in the training report or using the data tables themselves would be very useful.<\/p>",
        "Question_closed_time":1635215186563,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, PowerBi is not currently supported here on Q&amp;A. Please post your question on the <a href=\"https:\/\/community.powerbi.com\/\">PowerBI community forum<\/a> for faster response. Thanks.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error when running ML Algorithms",
        "Question_created_time":1635152541867,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/602539\/error-when-running-ml-algorithms",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello    <\/p>\n<p>I am trying to run some ML algorithms but I get the folliwing mistake and I do  not know how to proceed. Please let me know what I can do to fix this.    <\/p>\n<p> <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/143396-image.png?platform=QnA\" alt=\"143396-image.png\" \/>    <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot start and delete compute",
        "Question_created_time":1634651667563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/595819\/cannot-start-and-delete-compute",
        "Question_score_count":1,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hi  <br \/>\nI worked ML Azure practice at office and home. But in the morning, the compute cannot start when I work at home.  <br \/>\nThe alter as follows:  <br \/>\n&quot;Failed to start compute  <br \/>\nTrace ID : f1b5cabf-123a-470d-8a44-11631264118eClient request ID : 5967255a-9901-4717-a78e-2c350d3f6498Service request ID : 0fbd2dd4-2aea-4d00-b5ce-958ed7846f2e &quot;  <br \/>\nAnd I find the ID number changed in alter every time when I start the compute  <\/p>\n<p>&quot;Failed to start compute  <br \/>\nTrace ID : 515db030-c027-422c-9ddf-67a17f8e1e89Client request ID : ee8db673-63e9-4bc0-adec-b5d2db4e606aService request ID : e9a8a652-5c35-48c5-a381-58d1d1fa1e89&quot;  <\/p>\n<p>Now, I try to delete compute and it is running more than 50min for deleting, cannot finish. I don\u2019t know how to figure it now.   <br \/>\nCan I build a new compute for my course practice, even this one still keep deleting?  <br \/>\nYan  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[Azure][ML][Python SDK][Environment][Docker] Docker copy missing context",
        "Question_created_time":1634739305317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/597612\/(azure)(ml)(python-sdk)(environment)(docker)-docke",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am trying to create an Azure ML Environment using a Dockerfile but it contains the 'COPY' instruction.    <\/p>\n<p>From the documentation of Environment.from_dockerfile ( <a href=\"https:\/\/learn.microsoft.com\/fr-fr\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none-\">https:\/\/learn.microsoft.com\/fr-fr\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none-<\/a> ), I can not find a way to give it some files along with the Dockerfile itself.    <\/p>\n<p>So, how to pass context to enable using COPY in the Dockerfile ?    <\/p>\n<p>Thank you for your time !<\/p>",
        "Question_closed_time":1634774742763,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Docker context is not supported with AzureML Python SDK at the moment. Context support will added later this year<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Equation from linear regression model",
        "Question_created_time":1634735454220,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/597388\/equation-from-linear-regression-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,   <\/p>\n<p>I have run a linear regression model considering several variables applying tune model hyperparameters in design. I am now interested in obtaining the equation of this regression model that considers the coefficients of the inputs of the model, but I cannot find how to get this result.  <br \/>\nPlease let me know how I might accomplish this.  <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Upload Custom Algorithms to Azure ML Designer (Studio)",
        "Question_created_time":1625060259073,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458133\/upload-custom-algorithms-to-azure-ml-designer-(stu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible in some way to extend or customize Azure ML Designer (Studio) to upload and allow selection of custom developed algorithms for <strong>training<\/strong> models.  The context  is to be able to provide power or citizen data scientists with home grown algorithms in a drag and drop manner as enabled by Azure ML Designer Studio whilst still protecting internal IP.   <br \/>\nAlternately is there a possibility of exposing dockerized\/containerized algorithms for <strong>training<\/strong> via the Designer interface.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model predictions",
        "Question_created_time":1634657889403,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/596074\/model-predictions",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI build a Bagged GLM model on azure studio with tons of data split 50\/50 as training and testing input. Mow I am trying to deploy it as web service, it wont let me to input from the start point.<\/p>\n<p>1) Where should I input a simple data to the model? Before the loop for bagging when I got a single request? Would the result same for fast requests\/input?  <br \/>\nbeggin&lt;-function(trainx,testx,length_divisor=4,iterations=100)  <br \/>\nprediction&lt;-foreach(m=1:iterations, .combine=rbind) %dopar% {  <br \/>\npredict(glm,newdata=testx, na.action=na.omit)  <br \/>\n}  <br \/>\ndata.set&lt;-rowMeans(prediction)  <br \/>\n2) Another model built using use r-script modules. Each time it predicts almost the same value using our algorithm not from the studio, the variation of the result was trivial to the .0xx<\/p>\n<p>Thanks  <br \/>\nN.A.W.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to handle growing\/changing datasets?",
        "Question_created_time":1634718031020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/596990\/how-to-handle-growing-changing-datasets",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We are in the situation whereby we have datasets that are updated frequently so we have to retrain regularly on that new data. However it seems there is no way to expand a dataset and use the dataset versioning. This is what I'm currently testing, but there are some problems with it:  <\/p>\n<p>Create dataset from datastore and add new images to the datastore. This expands the dataset as we want and also updates the labeling job such that the new data can be labeled. This is handy since we don't have different labeling jobs for the same project. However if we want to export that dataset to use for training (Export &gt; Export as Azure ML Dataset) it creates a new dataset, is it possible to export into a new version of a dataset? That way we can reuse the training code and the correct version is automatically stored.   <\/p>\n<p>Kind regards<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Path to already registered model file for docker image construction",
        "Question_created_time":1634580956150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/594682\/path-to-already-registered-model-file-for-docker-i",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>I'm attempting to create a docker image containing my already registered model; working with my currently working python code. My question is - what is the Model directory?     <\/p>\n<p>In this guide:     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-extend-prebuilt-docker-image-inference\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-extend-prebuilt-docker-image-inference<\/a>     <br \/>\nit states:     <\/p>\n<blockquote>\n<p>If the model and code need to be built into the image, the following environment variables need to be set in the Dockerfile:    <\/p>\n<p>AZUREML_ENTRY_SCRIPT: The entry script of your code. This file contains the init() and run() methods.    <br \/>\nAZUREML_MODEL_DIR: The directory that contains the model file(s). The entry script should use this directory as the root directory of the model.    <\/p>\n<\/blockquote>\n<p>It then goes on to give an example with this line:     <br \/>\nCOPY &lt;model_directory&gt; \/var\/azureml-app\/azureml-models    <br \/>\nBasically, I'm trying to figure out what &lt;model_directory&gt; should be.     <\/p>\n<p>My dockerfile is currently:     <\/p>\n<pre><code>FROM python:3  \n  \nCOPY *.py \/opt\/azureml-app \\  \n    requirements.txt \/opt\/azureml-app \\  \n    .\/model.pkl \/opt\/azureml-app\/azureml-models  \n  \nRUN pip install -r requirements.txt   \n  \nENV AZUREML_ENTRY_SCRIPT=trivialEntryScript.py \\  \n    AZUREML_MODEL_DIR=\/opt\/azureml-app\/azureml-models  \n  \nENTRYPOINT python \/opt\/azureml-app\/trivialEntryScript.py   \n<\/code><\/pre>\n<p>The only files in the directory I'm building from are model.pkl, trivialEntryScript.py, requirements.txt and my Dockerfile. The folder structure is notebooks: myName\/dockerTesting. I do have other directories, eg myName\/mainCode which is where I ran my actual model training and registering. However, I manually added the model.pkl file into the dockerTesting  folder (which I probably shouldn't need to do anyways?).     <\/p>\n<p>I've tried the following:     <br \/>\ndockerfile as shown - error file does not exist    <br \/>\ndockerfile COPY model.pkl \/opt\/azureml-app\/azureml-models (eg no .\/ in front of model.pkl) - error file does not exist    <\/p>\n<p>My confusion is a bit more general - I have no idea where the actual registered models are stored in terms of actual filepaths; eg when I registered model.pkl in the first place, its not in myName\/mainCode where I trained it, though it does show up in the registered models tab. If I run a script that is only:    <\/p>\n<pre><code>print( Model.get_model_path(model_name) )  \n<\/code><\/pre>\n<p>It will tell me my model isn't found in Cache or my current working directory - regardless of if I run in mainCode or dockerTesting. However, if I run the exact same command in the init method of a entryScript after deploying my model with an inference config and whatnot, it will load the model (deploying the model seems to download it to cache - but from Where? How do I put the original location into my docker file???).     <\/p>\n<p>trivialEntryScript is literally just the basic entry script from: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best compute cluster for training large image datasets !",
        "Question_created_time":1633703536287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/583349\/best-compute-cluster-for-training-large-image-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Good morning,  <br \/>\nI have a a dataset that consist of 99000 (256 x 256 pixels) images. I am trying to use this dataset to training a generative advesarial network (GAN) for at least a 1,000 epoch.   <br \/>\nCurrently, I am using a standard_NC24r (24 cores, 224 GB RAM, 1440 GB disk) GPU  (4 x NVIDIA Tesla K80) cluster but the training is slow. It takes about 3000 seconds to train 1 epoch. This implies it would take at least a month to complete training.  <br \/>\nIs a cluster that I can used to speed up training?  <\/p>\n<p>Thanks for your help in advance  <\/p>\n<p>Many thanks  <\/p>\n<p>Roland<\/p>",
        "Question_closed_time":1633928472660,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=5554be0b-de3f-4849-9c04-ab53140c4523\">@Okwen, Roland T  <\/a> Thanks, Instead of bigger machines with more memory, there are techniques to be used with Aml Compute for larger datasets. The <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\">Parallel Run<\/a> Step is an AzureML Pipeline Step which enables parallel processing or data partitions across multiple workers on multiple nodes. PRS (ParallelRunStep) is designed for embarrassingly parallel workload, e.g. train many models, batch inference, etc.    <\/p>\n<p>Also look into using some of the curated images provided for compute clusters.    <br \/>\nSpecifically look into the DASK image.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-curated-environments\">Curated environments - Azure Machine Learning | Microsoft Learn<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Cannot upload local files to AzureML datastore (python SDK)",
        "Question_created_time":1594197439043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/43980\/cannot-upload-local-files-to-azureml-datastore-(py",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everybody,    <\/p>\n<p>I just started learning how to use MS Azure and I got stuck with an apparently trivial issue.    <\/p>\n<p>I have my own pet ML project, a python script that runs a classification analysis with Tensorflow and Keras.    <br \/>\nIt runs smoothly locally and I am happy with it.    <\/p>\n<p>Now I am trying to run this script on Azure ML, hoping to take advantage from the available computing power and in general gaining some experience with the Azure services. I am a bit old style and I like the idea of running my code on my local IDE, rahter than running it in a notebook. Because of this, I focused on the python SDK libraries.    <\/p>\n<p>I created a free trial account on Azure and create a workspace. In order to adapt my original code to the     <br \/>\nnew task, I followed the example in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml?WT.mc_id=aisummit-github-amynic\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml?WT.mc_id=aisummit-github-amynic<\/a>    <\/p>\n<p>The problem arises when I try to upload my locally-stored training data to the datastore of the workspace. The data is savedlocally in a parquet file, about 70Mb in size. The transfer fails after some time with a ProtocolError. After that it keeps retrying and failing with a NewConnectionError.    <\/p>\n<p>The snippet that reproduces the error is:    <\/p>\n<pre><code>import numpy as np  \nimport pandas as pd  \nfrom os.path import join as osjoin  \n  \nimport azureml.core  \nfrom azureml.core import Workspace,Experiment,Dataset,Datastore  \nfrom azureml.core.compute import AmlCompute,ComputeTarget  \n  \nworkdir = &quot;.&quot;  \n# Set up Azure Workspace  \n# load workspace configuration from the config.json file in the current folder.  \ntry:  \n    ws = Workspace.from_config()  \nexcept:  \n    print(&quot;Could not load AML workspace&quot;)  \n  \n  \ndatadir= osjoin(workdir,&quot;data&quot;)  \nlocal_files = [ osjoin(datadir,f) for f in listdir(datadir) if &quot;.parquet&quot; in f ]  \n  \n# get the datastore to upload prepared data  \ndatastore = ws.get_default_datastore()  \ndatastore.upload_files(files=local_files, target_path=None, show_progress=True)  \n  \n  \n<\/code><\/pre>\n<p>Everything runs smoothly until the last line. What happens is that the program starts to upload the file,    <br \/>\nI can see that there is outbound traffic from my VPN monitor. From the upload speed and the size of the file, I would say that it uploads it completely or close to that, then I get this message * :    <\/p>\n<pre><code>WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(&quot;(10054, 'WSAECONNRESET')&quot;))': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \nWARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x000002210A8BAF48&gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \nWARNING - Retrying (Retry(total=0, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x000002210B446748&gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \nWARNING - Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x000002210A8B5148&gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \nWARNING - Retrying (Retry(total=1, connect=1, read=3, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x000002210A891288&gt;, 'Connection to creditfraudws2493375317.blob.core.windows.net timed out. (connect timeout=20)')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \nWARNING - Retrying (Retry(total=0, connect=0, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x000002210A8BD3C8&gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&amp;blockid=TURBd01...TURB...RA%3D%3D  \n  \n<\/code><\/pre>\n<p>From the initial ProtocolError, I understand that the Azure cloud server bounces me back, but it is    <br \/>\nunclear to me why. Checking the workspace from the Azure portal, I would guess that the container of the workspace is still empty, but I am not 100% sure if I checked that correctly.    <\/p>\n<p>Maybe I misunderstood the different components of the storage services in AzureML and I not using    <br \/>\nthe API correctly. Am I doing something wrong? Is there a way for me to extract more information about    <br \/>\nthe reasons for this error?    <\/p>\n<p>Thanks a lot in advance for any help you can provide    <\/p>\n<p>[*] (I manually edited portions of the error message obfuscating the blobstore name)    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access company's fileshare from Azure ML Compute",
        "Question_created_time":1633621586400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/581725\/access-companys-fileshare-from-azure-ml-compute",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have been doing some searching around and can't seem to find anything particularly related to this question. Is it possible to connect to a local fileshare system from an Azure ML instance? Basically, I have a large amount of data in the form of images stored on a local drive and would like to use ml.azure to train and make predictions on this data. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cost of running a compute, other tasks",
        "Question_created_time":1634318912257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/592299\/cost-of-running-a-compute-other-tasks",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi;  <\/p>\n<p>First off, where can I find the costs for all the different things I can run in Azure ML? Not just a compute, but editing a notebook, connecting to a datastore, splitting a datastore, etc. Basically where is the price list?  <\/p>\n<p>Second, where can I find what I will be charged for things I ran in the last hour? I want to see what I'm spending before a month is up and the charge is then 100x what I expected (and can afford).  <\/p>\n<p>thanks - dave<\/p>",
        "Question_closed_time":1634347958867,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, you can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/cost-management-billing-overview\">Azure Cost Management<\/a> to manage Azure costs, please review the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/costs\/quick-acm-cost-analysis\">quickstart<\/a> document. Also, the following document provides detailed information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-plan-manage-cost\">plan and manage cost for AML<\/a>.<\/p>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Cannot Run Notebook",
        "Question_created_time":1613062788243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/269426\/cannot-run-notebook",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>When I go to Run a script in my Notebook on the Azure Learning Studio, there is no icon or option to run it. Even if the Compute is running, I still do not have the \u25b7 button needed to Run it. I am an owner, but perhaps there could be some issue with my subscription or might be platform issue with the portal UI itself? Please help.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/67065-role-again-2.png?platform=QnA\" alt=\"67065-role-again-2.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure compute not provisioning nodes",
        "Question_created_time":1634279482907,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/591559\/azure-compute-not-provisioning-nodes",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Azure ML is not creating nodes despite having quota. Cluster just shows Resizing 0 -&gt;2 nodes and continues to circle for hours. Using training instance standard_DS11_V2 in central India  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Test data for time sequential data",
        "Question_created_time":1633802017540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/584120\/test-data-for-time-sequential-data",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi all;  <\/p>\n<p>If I am trying to predict: the weather, the stock market, coffee sales per city, etc. there is no good way I can see to break out the data for training vs test data. For the weather case, training with Honolulu weather isn't going to do well testing with Denver weather.  <\/p>\n<p>Is it a good approach to train with the data for 5 years ago to 1 year ago. The test with the most recent year of data?  <\/p>\n<p>Or is there a better approach?  <\/p>\n<p>thanks - dave<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound using AutoML.",
        "Question_created_time":1634120760290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/588934\/datastore-workspaceblobstore-access-failed-errorco",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Why remote run is getting &quot;Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound&quot; when using automl?  <\/p>\n<p>I've attached datastore to workspace and I'm able to create Tabular dataset using blob URL.  <\/p>\n<p>But it crashes when submittting experiment with auto ml.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploying model from Azure ML to AKS inference cluster failing with 504 error",
        "Question_created_time":1634117582693,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/588825\/deploying-model-from-azure-ml-to-aks-inference-clu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We are trying to deploy model from ML onto Inference cluster in AKS. While training is successful, during deployment it fails with 504 error. Not sure if this is due to an issue on ML end or on AKS<\/p>\n<p>WebserviceException:  <br \/>\nMessage: Received bad response from Model Management Service:  <br \/>\nResponse Code: 504  <br \/>\nHeaders: {'Server': 'nginx\/1.21.1', 'Date': 'Wed, 13 Oct 2021 08:13:26 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '180.024'}  <br \/>\nContent: b'&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;504 Gateway Time-out&lt;\/title&gt;&lt;\/head&gt;\\r\\n&lt;body&gt;\\r\\n&lt;center&gt;&lt;h1&gt;504 Gateway Time-out&lt;\/h1&gt;&lt;\/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;\/center&gt;\\r\\n&lt;\/body&gt;\\r\\n&lt;\/html&gt;\\r\\n'  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Received bad response from Model Management Service:\\nResponse Code: 504\\nHeaders: {'Server': 'nginx\/1.21.1', 'Date': 'Wed, 13 Oct 2021 08:13:26 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '180.024'}\\nContent: b'&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;504 Gateway Time-out&lt;\/title&gt;&lt;\/head&gt;\\r\\n&lt;body&gt;\\r\\n&lt;center&gt;&lt;h1&gt;504 Gateway Time-out&lt;\/h1&gt;&lt;\/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;\/center&gt;\\r\\n&lt;\/body&gt;\\r\\n&lt;\/html&gt;\\r\\n'&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What's the correct tooling to use cognitive services to identity SPECIFIC items?",
        "Question_created_time":1634146030337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/589463\/whats-the-correct-tooling-to-use-cognitive-service",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Scenario: I have three children and need to sort their garments as they are cleaned. I would like to be able to hold a garment up to a camera, and for the application to recognise the actual garment, so that it can tell me who it (currently) belongs to.  <\/p>\n<p>What approach should I use to teach an application to find a specific item? Obviously just noticing that it is a &quot;t-shirt&quot; or &quot;trousers&quot; isn't enough in this case; I need to identify individual items.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why can't I access the Dataset class using azureml.core?",
        "Question_created_time":1634060274827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/587772\/why-cant-i-access-the-dataset-class-using-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am unable to use Dataset class in azureml.core with new version of azureml.core==1.35.0  <\/p>\n<p><em>ImportError: cannot import name 'Dataset' from 'azureml.core'<\/em>  <\/p>\n<p><strong>Also, I am unable to downgrade or reinstall azureml.core to a lower version (1.32.0).<\/strong> Please find the snapshot below of pip install azureml.core==1.32.0  <\/p>\n<p>Can someone please guide me to a possible alternative. I need to use the Dataset methods -   <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I set a cost limit?",
        "Question_created_time":1633801837460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/584194\/can-i-set-a-cost-limit",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi all;  <\/p>\n<p>When I run a compute to train a model, is there a way to set a maximum charge for that run? And if it hits that number, it stops?  <\/p>\n<p>I have this nightmare that I set a training model to run and when done, it's a $12,000.00 charge.  <\/p>\n<p>thanks - dave<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Trouble downloading and loading files in python script module",
        "Question_created_time":1633726401097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/583739\/trouble-downloading-and-loading-files-in-python-sc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm currently trying to create an endpoint in Azure ML studio designer, I'm trying to download a ML model pickle file from a blob container and use it in the pipeline to make predictions in new data. But when I try to download the file and load into the script I always get an error. Here follows the code snippet I'm trying to run and the error returned.   <\/p>\n<p><strong>Code Snippet<\/strong>  <\/p>\n<p> origin = dataframe1['Key'].unique()[0].lower()  <br \/>\n run = Run.get_context(allow_offline = True)  <br \/>\nws = run.experiment.workspace  <br \/>\ndatastore = Datastore(ws, 'models_datastore')  <br \/>\ndatastore.download('Downloads\/\/', prefix = 'Model_{origin}\/\/vectorizer.pkl')  <br \/>\nmodel = pickle.load(open('Downloads\/\/vectorizer.pkl', 'rb'))  <\/p>\n<p><strong>Error returned<\/strong>  <\/p>\n<p>Got exception when invoking script at line 23 in function azureml_main: 'FileNotFoundError: [Errno 2] No such file or directory: 'Downloads\/\/vectorizer.pkl''.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pipeline does not run new data",
        "Question_created_time":1633192729123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/575144\/pipeline-does-not-run-new-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi -  <br \/>\nI created and published a pipeline that pulls data from an Azure SQL table, processes, models and then appends the output to an Azure SQL table. The Azure SQL table is updated with new data every day or two. In my script, I want to model on data that has been added two days before today with the following script:<\/p>\n<p>from datetime import date, timedelta  <br \/>\nyesterday = date.today() - timedelta(days=2)  <br \/>\nyesterday.strftime(&quot;%Y-%m-%d&quot;)  <br \/>\nprint(yesterday)<\/p>\n<h1 id=\"keep-data-that-is-2-days-ago-only\">keep data that is 2 days ago only<\/h1>\n<p>data_prior = data[data['MatterOpenDate'] == str(yesterday)]  <br \/>\nprint(data_prior.head())<\/p>\n<p>while True:  <br \/>\nanswer = data_prior.empty  <br \/>\nif answer == False:  <br \/>\nprint('Continue Process')  <br \/>\nbreak  <br \/>\nelif answer == True:  <br \/>\nprint('Empty dataset')  <br \/>\nrun.complete()  <br \/>\nexit()<\/p>\n<p>When I first ran my pipeline it worked great. I published this experiment, etc. and created a reoccurring schedule to run once a day every day.<\/p>\n<p>BUT the schedule continues to run the exact same data as the original run even when there is new data being uploaded. Why and what do I need to do for the script to run 'naturally' as written?<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploying model in Azure ML confusion",
        "Question_created_time":1632945969247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/571518\/deploying-model-in-azure-ml-confusion",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm following a tutorial (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a>) on how to deploy a model to Azure, and I had a few questions that have had confused a bit. I had a ready model that I trained using a notebook in Azure ML and have saved the model in a folder (as .h5) in my compute directory (Users\/username\/projectname\/models).    <\/p>\n<p>1- Can I deploy from the Azure ML Notebook section? So I create a .py file (or can I do it in a .ipynb notebook?), connect to my workspace, and register the model through there? I have my model stored in the models folder, so can I just reference that from an <code>azureml.core.Run<\/code> object?    <\/p>\n<p>2- When I create my entry scripts and inference and deployment configurations, do they have to be in separate files or does that not matter? Same for the code to deploy the model.    <\/p>\n<p>3- What model extensions are supported? Is .h5 fine?    <\/p>\n<p>4- When I deploy successfully, do I get an endpoint or uri I can connect to from anywhere?    <\/p>\n<p>I know this is a bit all over the place, but any clarifications would be appreciated. <\/p>",
        "Question_closed_time":1633027344787,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi, thanks for reaching out. Here's the workflow for deploying a model:    <\/p>\n<ol>\n<li> Register the model    <\/li>\n<li> Prepare an entry script    <\/li>\n<li> Prepare an inference configuration    <\/li>\n<li> Deploy the model locally to ensure everything works    <\/li>\n<li> Choose a compute target    <\/li>\n<li> Re-deploy the model to the cloud    <\/li>\n<li> Test the resulting web service    <\/li>\n<\/ol>\n<p>You can perform the above steps through AML notebooks. However, you <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-dummy-entry-script\">entry script<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-an-inference-configuration\">deployment configuration<\/a> need to be in separate files. After <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#deploy-your-machine-learning-model\">deployment<\/a>, you obtain an endpoint for <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">calling the webservice<\/a>. Model with extension .h5 is supported.    <\/p>\n<p>You can create new or reference an existing environment in your config, here's information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\">create\/use software environments<\/a>. Also, here's another <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\">example<\/a> (Deploy the model in ACI section) of how to create a scoring script. Please review the following <a href=\"https:\/\/www.tensorflow.org\/guide\/keras\/save_and_serialize\">document<\/a> for details on how to save and load Keras models.    <\/p>\n<pre><code>%%writefile score.py  \nimport json  \nimport numpy as np  \nimport os  \nimport tensorflow as tf  \n  \nfrom azureml.core.model import Model  \n  \ndef init():  \n    global tf_model  \n    model_root = os.getenv('AZUREML_MODEL_DIR')  \n    # the name of the folder in which to look for tensorflow model files  \n    tf_model_folder = 'model'  \n      \n    tf_model = tf.saved_model.load(os.path.join(model_root, tf_model_folder))  \n  \ndef run(raw_data):  \n    data = np.array(json.loads(raw_data)['data'], dtype=np.float32)  \n      \n    # make prediction  \n    out = tf_model(data)  \n    y_hat = np.argmax(out, axis=1)  \n  \n    return y_hat.tolist()  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"InternalServerError when I try to open jupyter lab in a compute instance in Machine Learning Studio",
        "Question_created_time":1632656732000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566360\/internalservererror-when-i-try-to-open-jupyter-lab",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to launch Jupyter lab on a compute instance inside Machine Learning Studio.  <br \/>\nIt keeps giving me this Error.  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;ServiceError&quot;,  <br \/>\n&quot;severity&quot;: null,  <br \/>\n&quot;message&quot;: &quot;InternalServerError&quot;,  <br \/>\n&quot;messageFormat&quot;: null,  <br \/>\n&quot;messageParameters&quot;: null,  <br \/>\n&quot;referenceCode&quot;: null,  <br \/>\n&quot;detailsUri&quot;: null,  <br \/>\n&quot;target&quot;: null,  <br \/>\n&quot;details&quot;: [],  <br \/>\n&quot;innerError&quot;: null,  <br \/>\n&quot;debugInfo&quot;: null,  <br \/>\n&quot;additionalInfo&quot;: null  <br \/>\n},  <br \/>\n&quot;correlation&quot;: {  <br \/>\n&quot;operation&quot;: &quot;87079acea847584aae25f2f02e96a4cb&quot;,  <br \/>\n&quot;request&quot;: &quot;2718ebcb2e21004c&quot;  <br \/>\n},  <br \/>\n&quot;environment&quot;: &quot;eastus&quot;,  <br \/>\n&quot;location&quot;: &quot;eastus&quot;,  <br \/>\n&quot;time&quot;: &quot;2021-09-26T11:42:36.0001935+00:00&quot;,  <br \/>\n&quot;componentName&quot;: &quot;notebook-instance-proxy&quot;  <br \/>\n}<\/p>\n<p>Instance Details are:  <br \/>\nStandard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Model",
        "Question_created_time":1631260693017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/546916\/azure-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to use Gaussian NB, Bernoulli NB, and K nearest neighbor but I don't know if Azure Machine Learning has those models.  <br \/>\nPlease reply.   <br \/>\nThank you very much.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Read JSON in ML Pipeline",
        "Question_created_time":1631259308947,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/547031\/read-json-in-ml-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We created a ML pipline that downloads data from an external CRM system, predicts certain things based on the new data and uploads the results to the external CRM. For the upload a json file, that contains information on the metadata is mandatory. The json file sits in our datastore. We need to open the json file and update its content based on the new predictions. Unfortunately we are not able to load and read the json file in our Python script.  <br \/>\nFirst we create a datastore path --&gt; datastore_paths = [(ds, 'Metadata\/XXX_metadata.json')]  <br \/>\nThen we create a FileDataset  --&gt; json_file = Dataset.File.from_files(path=datastore_paths)  <br \/>\nThen we try to open the Json file --&gt;  <br \/>\nf=open(json_file)  <br \/>\ndata_json=json.load(f)  <br \/>\nWe get the following error message --&gt; expected str, bytes or os.PathLike object, not FileDataset  <br \/>\nSo far we were not able to find any solution for our problem, Any help or input is highly appreciated. Many thanks in advance !!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run a pipeline using cvs files from a folder in the datastore",
        "Question_created_time":1630494672977,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/535935\/run-a-pipeline-using-cvs-files-from-a-folder-in-th",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I want to run a model using as input CVS files in a folder (UI\/date) in the default datastore. I want the model to train based on the CVS files and to pick a random between them as each file represents an object to be randomly selected.  <\/p>\n<p>I already have in design the pipeline I want to use; is just that I want to run it with the files of the datastore and not from a tabular dataset. I have tried to call these folder by a python script using os.listdir and then read_cvs, however the path for this folder doesn\u2019t seem valid. I have done this activity in python using the path of folder in my computer and it works. But I don\u2019t know how to proceed in python.  <\/p>\n<p>Thank you for your help.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureMLCompute job failed. UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.",
        "Question_created_time":1630327734917,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/532922\/azuremlcompute-job-failed-userprocesskilledbysyste",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Can anybody help me on below mentioned below error, same thing i ran previously using same AML compute cluster but didn't get issue. But now its giving like this.  <br \/>\nI don't understand where out of memory issue coming.  <\/p>\n<p>AzureMLCompute job failed.  <br \/>\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.  <\/p>\n<pre><code>Reason: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.\nCause: killed\nTaskIndex: \nNodeIp: 10.0.0.11\nNodeId: tvmps_bf6163b7d0d8755f028c834b88478cac2e05488f7c3d5fe3b2c518b98ef2a186_d\nReason: Job failed with non-zero exit Code\nReason: Out of memory error\nBatchNodeId: tvmps_bf6163b7d0d8755f028c834b88478cac2e05488f7c3d5fe3b2c518b98ef2a186_d\nRoleInstanceName: 9e7b1aec-9e01-41a0-94bb-5ac4407e4d2d-AzureBatch-Deployment_7\nVmId: c90d75ad-37a5-4c8b-a40d-f411ad459be1\nErrorCode: OutOfMemoryError\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"unable to set holiday country parameter in Forecastingparameters when running Auto-ml from Python Notebook in azure ml studio",
        "Question_created_time":1630327508670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/532921\/unable-to-set-holiday-country-parameter-in-forecas",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As the question suggests, I am trying to setup an Azure Auto-ML experiment from Jupyter Notebook from Azure ML Workspace, and trying to configure the holiday country for the forecasting parameters.    <\/p>\n<p>MSDN for <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.forecasting_parameters.forecastingparameters?view=azure-ml-py\">ForecastingParameters <\/a>  Class suggests all the Holiday Country related parameters have been deprecated.    <\/p>\n<p>I have also tried using the parameter for Holiday Country in the AutoMLConfig but in MSDN the country parameter has also been deprecated. AutoMLConfig <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\">AutoMLConfig<\/a>    <\/p>\n<p>Does anyone know how can I use Country Region settings in either ForecastingParameters or AutoMLConfig?    <\/p>\n<p><strong>My Attempt with Forecasting Parameters:<\/strong>    <\/p>\n<pre><code> forecastingParam_dict = {   'time_column_name':'DateColumn',  \n                            'forecast_horizon':365,  \n                            'time_series_id_column_names': 'GroupColumn',  \n                            'target_lags':None,  \n                            'feature_lags':None,  \n                            'target_rolling_window_size':None,  \n                            'holiday_country':'GB',                             # &lt;-- Tried both values with no luck  \n                            'country_or_region_for_holidays':'GB',              # &lt;-- Tried both values with no luck  \n                            'use_stl':'season_trend',  \n                            'short_series_handling':True,  \n                            'short_series_handling_configuration': 'auto',  \n                            'freq':'D',  \n                            'target_aggregation_function':None,  \n                            'validate_parameters':True,  \n                }   \n  \n  \nfcpm = ForecastingParameters.from_parameters_dict(forecastingParam_dict,  \n                                                  validate_params=True ,  \n                                                  show_deprecate_warnings=True)  \n<\/code><\/pre>\n<p><strong>My Attempt with AutoMLConfig:<\/strong>    <\/p>\n<pre><code>automl_settings = {  \n                    'enable_early_stopping':True,  \n                    'enable_ensembling':True,  \n                    'enable_stack_ensembling':False,  \n                    'ensemble_iterations':15,  \n                    'enable_onnx_compatible_models':False,  \n                    'max_cores_per_iteration':-1,  \n                    'send_telemetry':True,  \n                    'blacklist_algos':['TensorFlowDNN','TensorFlowLinearRegressor'],  \n                    'enable_dnn':False,  \n                    'enable_code_generation':False,  \n                    'experiment_exit_score':None,  \n                    'experiment_timeout_minutes':360,  \n                    'featurization':'auto',  \n                    'is_timeseries':True,  \n                    'iteration_timeout_minutes':360,  \n                    'country_or_region':'GB',                 # &lt;-- Tried both values with no luck  \n                    'country_or_region_for_holidays':'GB',    # &lt;-- Tried both values with no luck  \n                    'max_concurrent_iterations':1,  \n                    'metric_operation':'minimize',  \n                    'model_explainability':True,  \n                    'n_cross_validations':5,  \n                    'primary_metric':'normalized_root_mean_squared_error',  \n                    'task_type':'regression',  \n                    'validation_size':None,  \n                    'test_size':None,  \n                    'label_column_name':'Sales',  \n                    'target_lags':None,  \n                    'enable_batch_run':True,  \n                    'enable_run_restructure':True  \n                    }  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is Azure Machine learning has its services available for On-Premises platform ?",
        "Question_created_time":1633599590813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/581226\/is-azure-machine-learning-has-its-services-availab",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,  <br \/>\nI wanted to know if we have On-premises platform available in Azure Machine Learning. Could you please provide the detail information regarding this ?  <\/p>\n<p>Also, I want to know the security aspects this Azure machine learning provides for Healthcare domain.  <\/p>\n<p>TIA  <\/p>\n<p>Aditi G<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Which azure service should I use.",
        "Question_created_time":1633510606170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/579427\/which-azure-service-should-i-use",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>So I have a pretty big on-premise ssms database and I want to use some data from it in azure Machine Learning.   <br \/>\nI need to use just a small amount of data from my db, from certain tables.  <br \/>\nAlso this data updates from time to time.  <br \/>\nI want you to help me with the choice of correct azure service for my purpose.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot install azureml-sdk without dependency conflicts",
        "Question_created_time":1631182445263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/545669\/cannot-install-azureml-sdk-without-dependency-conf",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to install the latest azureml-sdk (1.34.0) inside a new conda env (with python 3.7) but the installation ends with the following error:    <\/p>\n<p>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.    <br \/>\nknack 0.7.2 requires argcomplete, which is not installed.    <br \/>\nknack 0.7.2 requires colorama, which is not installed.    <br \/>\nknack 0.7.2 requires pygments, which is not installed.    <br \/>\nazure-functions-devops-build 0.0.22 requires jinja2, which is not installed.    <br \/>\nazure-cli-core 2.10.0 requires argcomplete~=1.8, which is not installed.    <br \/>\nazure-cli-core 2.10.0 requires colorama~=0.4.1, which is not installed.    <br \/>\nazure-cli 2.10.0 requires azure-mgmt-keyvault~=2.2.0, but you have azure-mgmt-keyvault 9.1.0 which is incompatible.    <br \/>\nazure-cli 2.10.0 requires cryptography&lt;3.0.0,&gt;=2.3.1, but you have cryptography 3.4.8 which is incompatible.    <br \/>\nazure-cli-core 2.10.0 requires azure-mgmt-core==1.0.0, but you have azure-mgmt-core 1.3.0 which is incompatible.    <br \/>\nazure-cli-core 2.10.0 requires msal~=1.0.0, but you have msal 1.14.0 which is incompatible.    <br \/>\nazure-cli-core 2.10.0 requires msal-extensions~=0.1.3, but you have msal-extensions 0.2.2 which is incompatible.    <\/p>\n<p>How can I solve it?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130764-image.png?platform=QnA\" alt=\"130764-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting 500 errors after model deployment",
        "Question_created_time":1632915546127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/570879\/getting-500-errors-after-model-deployment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am trying to deploy a model using     <br \/>\n       InferenceConfig  <br \/>\n . It deploys successfully, both locally and to an ACI, but whenever I make a request to it I get a     <br \/>\n       &lt;Response [500]&gt;  <br \/>\n error. My code is based on what is found in this example <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#call-into-your-model\">here<\/a>. I believe the     <br \/>\n       init  <br \/>\n and     <br \/>\n       run  <br \/>\n parts of my entry script are correct, as when I call the run function without it being involved in a deployment the data does go through it correctly. Investigating the endpoint on the Azure portal makes it look ok to, it has a &quot;healthy&quot; status.     <\/p>\n<p>Is there any advice about how to fix this? Or how I can modify what I have to get around it? I have attached code below    <\/p>\n<p>These are my deployment logs:    <\/p>\n<pre><code>2021-09-30T08:55:33,882785000+00:00 - iot-server\/run   \n2021-09-30T08:55:33,893848100+00:00 - gunicorn\/run   \nDynamic Python package installation is disabled.  \nStarting HTTP server  \n2021-09-30T08:55:33,903826800+00:00 - rsyslog\/run   \n2021-09-30T08:55:33,932288900+00:00 - nginx\/run   \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...  \n2021-09-30T08:55:34,629656500+00:00 - iot-server\/finish 1 0  \n2021-09-30T08:55:34,631347500+00:00 - Exit code 1 is normal. Not restarting iot-server.  \nStarting gunicorn 20.1.0  \nListening at: http:\/\/127.0.0.1:31311 (63)  \nUsing worker: sync  \nworker timeout is set to 300  \nBooting worker with pid: 87  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2021-09-30 08:55:36,257 | root | INFO | Starting up app insights client  \nlogging socket was found. logging is available.  \nlogging socket was found. logging is available.  \n2021-09-30 08:55:36,258 | root | INFO | Starting up request id generator  \n2021-09-30 08:55:36,260 | root | INFO | Starting up app insight hooks  \n2021-09-30 08:55:36,260 | root | INFO | Invoking user's init function  \n2021-09-30 08:55:36,423 | root | INFO | Users's init has completed successfully  \n2021-09-30 08:55:36,430 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.  \n2021-09-30 08:55:36,430 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.  \n2021-09-30 08:55:36,432 | root | INFO | Scoring timeout is found from os.environ: 60000 ms  \n2021-09-30 08:56:19,493 | root | INFO | Swagger file not present  \n2021-09-30 08:56:19,493 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:56:19 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2021-09-30 08:56:19,594 | root | INFO | Swagger file not present  \n2021-09-30 08:56:19,595 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:56:19 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2021-09-30 08:56:23,093 | root | INFO | Swagger file not present  \n2021-09-30 08:56:23,093 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:56:23 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2021-09-30 08:56:24,193 | root | INFO | Swagger file not present  \n2021-09-30 08:56:24,194 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:56:24 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n2021-09-30 08:56:47,726 | root | INFO | Scoring Timer is set to 60.0 seconds  \n2021-09-30 08:56:47,727 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 65, in run_scoring  \n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 110, in invoke_user_with_timer  \n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 92, in timer  \n    result = func(*args, **kwargs)  \nTypeError: run() got an unexpected keyword argument 'input'  \n  \nDuring handling of the above exception, another exception occurred:  \n  \nTraceback (most recent call last):  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 44, in score_realtime  \n    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 74, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n  \n2021-09-30 08:56:47,728 | root | INFO | 500  \n127.0.0.1 - - [30\/Sep\/2021:08:56:47 +0000] &quot;POST \/score HTTP\/1.0&quot; 500 48 &quot;-&quot; &quot;python-requests\/2.25.1&quot;  \n2021-09-30 08:57:25,014 | root | INFO | Swagger file not present  \n2021-09-30 08:57:25,014 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:57:25 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \nException in worker process  \nTraceback (most recent call last):  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker  \n    worker.init_process()  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 142, in init_process  \n    self.run()  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 125, in run  \n    self.run_for_one(timeout)  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 84, in run_for_one  \n    self.wait(timeout)  \n  File &quot;\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 36, in wait  \n    ret = select.select(self.wait_fds, [], [], timeout)  \n  File &quot;\/var\/azureml-server\/routes_common.py&quot;, line 153, in alarm_handler  \n    raise TimeoutException(error_message)  \ntimeout_exception.TimeoutException  \nWorker exiting (pid: 87)  \nworker timeout is set to 300  \nBooting worker with pid: 145  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2021-09-30 08:57:48,727 | root | INFO | Starting up app insights client  \nlogging socket was found. logging is available.  \nlogging socket was found. logging is available.  \n2021-09-30 08:57:48,732 | root | INFO | Starting up request id generator  \n2021-09-30 08:57:48,732 | root | INFO | Starting up app insight hooks  \n2021-09-30 08:57:48,733 | root | INFO | Invoking user's init function  \n2021-09-30 08:57:48,827 | root | INFO | Users's init has completed successfully  \n2021-09-30 08:57:48,833 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.  \n2021-09-30 08:57:48,834 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.  \n2021-09-30 08:57:48,835 | root | INFO | Scoring timeout is found from os.environ: 60000 ms  \n2021-09-30 08:58:10,161 | root | INFO | Swagger file not present  \n2021-09-30 08:58:10,162 | root | INFO | 404  \n127.0.0.1 - - [30\/Sep\/2021:08:58:10 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  \n<\/code><\/pre>\n<p>If I run the command     <br \/>\n       azmlinfsrv --model_dir . --entry_script entry_script.py  <br \/>\n to see how the entry script works locally, I get the output:    <\/p>\n<pre><code>Azure ML Inferencing HTTP server v0.4.1  \n  \n  \nServer Settings  \n---------------  \nEntry Script Name: entry_script.py  \nModel Directory: .\/  \nWorker Count: 1  \nServer Port: 5001  \nApplication Insights Enabled: false  \nApplication Insights Key: None  \n  \n  \nServer Routes  \n---------------  \nLiveness Probe: GET   127.0.0.1:5001\/  \nScore:          POST  127.0.0.1:5001\/score  \n  \nStarting gunicorn 20.1.0  \nConnection in use: ('0.0.0.0', 5001)  \nRetrying in 1 second.  \nConnection in use: ('0.0.0.0', 5001)  \nRetrying in 1 second.  \nConnection in use: ('0.0.0.0', 5001)  \n<\/code><\/pre>\n<p>entry_script.py:    <\/p>\n<pre><code>import json  \nimport numpy as np  \nimport os  \nimport onnxruntime  \n  \n# Called when the service is loaded  \ndef init():  \n    # Get the path to the deployed model file and load it  \n    global sess  \n    sess = onnxruntime.InferenceSession(  \n        os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;model.onnx&quot;)  \n    )  \n  \ndef run(raw_data, session = None):  \n    if session != None: sess = session  \n    try:  \n        # Get the input data as a numpy array  \n        data = np.array(json.loads(raw_data)['data'], dtype=np.float32)  \n        # Get a prediction from the model  \n  \n        first_input_name = sess.get_inputs()[0].name  \n        first_output_name = sess.get_outputs()[0].name  \n  \n        test = sess.run(  \n            [first_output_name], {first_input_name: data}  \n        )  \n        result = test[0].tolist()  \n  \n        # Return the predictions as JSON  \n        return json.dumps({&quot;result&quot;:result})  \n    except Exception as e:  \n        result = str(e)  \n        return {&quot;error&quot;: result}  \n<\/code><\/pre>\n<p>Deploy Code:    <\/p>\n<pre><code>service_env = Environment(name='service-env')  \npython_packages = ['numpy', 'onnxruntime']  \nfor package in python_packages:  \n    service_env.python.conda_dependencies.add_pip_package(package)  \ninference_config = InferenceConfig(source_directory=&quot;.\/source_dir&quot;,  \n                                   entry_script=&quot;.\/entry_script.py&quot;,  \n                                   environment=service_env)  \n  \ndeployment_config = AciWebservice.deploy_configuration(  \n    cpu_cores=0.5, memory_gb=1, auth_enabled=True  \n)  \n  \nservice = Model.deploy(  \n    ws,  \n    &quot;myservice&quot;,  \n    [model],  \n    inference_config,  \n    deployment_config,  \n    overwrite=True,  \n)  \nservice.wait_for_deployment(show_output=True)  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to access to Microsoft Machine Learning Studio",
        "Question_created_time":1633356705613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/576536\/not-able-to-access-to-microsoft-machine-learning-s",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When I tried to login into my account, it keeps prompting me &quot;We couldn't sign you in. Please try again.&quot;. And I'm using signing in the usual account. Please help. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Auto ML processor never utilized, utilization below 10%",
        "Question_created_time":1633373617237,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/576887\/auto-ml-processor-never-utilized-utilization-below",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to run an Automated ML run with a 5Gb .csv file as the dataset. I've selected the Standard_D8_v3 (8 cores, 32 GB RAM, 200 GB disk) for my compute cluster and it allows 2 nodes.    <\/p>\n<p>When it starts out initially the CPU Utilization spikes to 80%, but then stays below 1% for as long as I'll let it run, which has been over a day. I see this utilization measure under the &quot;Monitoring (preview)&quot; tab of the run, and I've also setup configured Metrics at the Workspace level, which reflect the same thing. The CPUMemoryUtilization never raises.    <\/p>\n<p>No models have ever appeared in the &quot;models&quot; tab.    <\/p>\n<p>The first run continually indicates &quot;Setting up the run&quot;, but the one child run indicates &quot;running&quot;. I think I've got a managed ID issue.    <\/p>\n<p>I suspect the training never starts. Is there an error I can look for in the logs? I'm not even sure which log would have it. I'll post them here if needed.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/137450-screen-shot-2021-10-04-at-14224-pm.png?platform=QnA\" alt=\"137450-screen-shot-2021-10-04-at-14224-pm.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"InternalServerError when launching Jupyterlabs in Azure Machine Learning workspace",
        "Question_created_time":1632877552993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569900\/internalservererror-when-launching-jupyterlabs-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>My workspace is in EastUS2.  <br \/>\nI have created compute instances from multiple sku's and I always receive the following error when creating instances:<\/p>\n<p><em>{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;ServiceError&quot;,  <br \/>\n&quot;severity&quot;: null,  <br \/>\n&quot;message&quot;: &quot;InternalServerError&quot;,  <br \/>\n&quot;messageFormat&quot;: null,  <br \/>\n&quot;messageParameters&quot;: null,  <br \/>\n&quot;referenceCode&quot;: null,  <br \/>\n&quot;detailsUri&quot;: null,  <br \/>\n&quot;target&quot;: null,  <br \/>\n&quot;details&quot;: [],  <br \/>\n&quot;innerError&quot;: null,  <br \/>\n&quot;debugInfo&quot;: null,  <br \/>\n&quot;additionalInfo&quot;: null  <br \/>\n},  <br \/>\n&quot;correlation&quot;: {  <br \/>\n&quot;operation&quot;: &quot;f0bc2b1a27a3534eb83eac4f3f71fedf&quot;,  <br \/>\n&quot;request&quot;: &quot;589656f8c89b684a&quot;  <br \/>\n},  <br \/>\n&quot;environment&quot;: &quot;eastus2&quot;,  <br \/>\n&quot;location&quot;: &quot;eastus2&quot;,  <br \/>\n&quot;time&quot;: &quot;2021-09-29T01:01:09.3745269+00:00&quot;,  <br \/>\n&quot;componentName&quot;: &quot;notebook-instance-proxy&quot;  <br \/>\n}<\/em><\/p>\n<p>What can I do to resolve this issue? I have tried restarting, recreating, and testing other sku's.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use ML to detect key from set of value(s)",
        "Question_created_time":1633257609393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/575394\/how-to-use-ml-to-detect-key-from-set-of-value(s)",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have a CSV file with first row as header &amp; after that each row has set of values for each column. Each row in the CSV correspond to some field in the DB. user has to manually map the header attributes to Business fields (or DB fields).  <\/p>\n<p>I want to use ML to learn from existing values, when single or set of values are provided then it should detect the key. Overall I want to avoid manual mapping. One can think going forward there is no more header row in the CSV file.  <\/p>\n<p>Is any services (preferably Azure) to machine learn from set of key-value pairs. When a value is provided then it should detect the keys? Please note this does not involve any OCR, my data is in CSV form.  <\/p>\n<p>Atul<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployment from Designer fails in every possible way",
        "Question_created_time":1632862175993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569925\/deployment-from-designer-fails-in-every-possible-w",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I trained a model with Designer, created a real-time inference pipeline which was succesfully submitted. When deploying to either ACI or AKS it fails and I get the error &quot;ModuleNotFoundError: No module named 'azureml.api'&quot;. I've had no problems deploying this model many times in the past and haven't changed anything. Even if I use one of the sample pipelines (automobiles basic), I get the same error when deploying to real-time. <\/p>",
        "Question_closed_time":1632968850120,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>It's an known issue caused by unexpected module version upgrade. It's been resolved by applying hotfix to all regions. For users, please rerun training pipeline by check on &quot;Regenerate Output&quot;, and run corresponding inference pipeline and try deployment again.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can I create a workspace in Azure that multiple people can use?",
        "Question_created_time":1632780178700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/568295\/can-i-create-a-workspace-in-azure-that-multiple-pe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi! I'm wondering if it's possible to create a workspace in Azure for multiple to use? I have a group of students who will run a lab using ML Studio and I'd like for when the Machine Learning workspace question comes up, they can select an already created workspace. Is that possible? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error in Azure Machine Learning Notebook Using Managed Identity to Authenticate to other resources",
        "Question_created_time":1633032949577,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/573433\/error-in-azure-machine-learning-notebook-using-man",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to access Azure Digital Twins(ADT) resources in an AML notebook via Managed Identity. I've granted access to the workspace in ADT's IAM.     <br \/>\nI found out that whatever I put for client_id, it takes more than 2 mins to get back and error showing    <br \/>\n<code>ManagedIdentityCredential.get_token failed: Unexpected response 'None'<\/code>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/136737-image.png?platform=QnA\" alt=\"136737-image.png\" \/>    <\/p>\n<p>Is there anything that I did wrong? Is AML supporting MSI to access other Azure resources now?    <br \/>\n(I've tried ways using secrets to authenticate to ADT and it worked. I'm looking for a way that there's no secret needed.)    <\/p>\n<p>Thank you!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I'm getting Error: Internal server error.",
        "Question_created_time":1632823517743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569010\/im-getting-error-internal-server-error",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I get this Internal server error. I am able to work with datasets , but as I try to work with workspace.from_config I get &quot;DecodeError: Not enough segments&quot; this error <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issue starting labeling project",
        "Question_created_time":1631780569863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/554539\/issue-starting-labeling-project",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>We have a 500.000 image labeling project in progress. The team was receiving some errors that indicated no work was queued even though the project was only 3% complete.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132586-242115502-983432182220136-1351421978890006110-n.png?platform=QnA\" alt=\"132586-242115502-983432182220136-1351421978890006110-n.png\" \/>    <\/p>\n<p>We paused the project and attempted to restart to see if that would clear out the issue but when trying to restart an error is being thrown &quot;Failed&quot; with no additional information.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132616-screenshot-2021-09-16-102056.png?platform=QnA\" alt=\"132616-screenshot-2021-09-16-102056.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML endpoint shows 502 bad gateway",
        "Question_created_time":1632920919200,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/571062\/azureml-endpoint-shows-502-bad-gateway",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I deployed my model from local machine, but I can't predict with the API.    <\/p>\n<p>When I checked this endpoint with this command    <\/p>\n<p>curl -v <a href=\"http:\/\/6b3138f3-b4aa-44d3-873d-32255fb5ab50.eastus2.azurecontainer.io\/score\">http:\/\/6b3138f3-b4aa-44d3-873d-32255fb5ab50.eastus2.azurecontainer.io\/score<\/a>    <\/p>\n<p>it shows 502 bad gateway. (but without &quot;\/score&quot;, it looks fine)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/136352-image.png?platform=QnA\" alt=\"136352-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permission denied: '.\/outputs'",
        "Question_created_time":1632664334123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566533\/permission-denied-outputs",
        "Question_score_count":4,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>When I tried to run experiments in azure ml notebook using azure ml python SDK it giving an error message as permission denied.  <br \/>\nI am also facing the same issue when I am trying to save CSV files in the same folder as the notebook saved.<\/p>\n<p>compute instance using : STANDARD_DS3_V2  <br \/>\ncode -  <br \/>\nexperi = Experiment(workspace=ws,name=&quot;newsampleexperiment12&quot;)  <br \/>\nrun = experi.start_logging()<\/p>\n<p>error message :<\/p>\n<p>PermissionError Traceback (most recent call last)  <br \/>\n&lt;ipython-input-7-8946b6d7df18&gt; in &lt;module&gt;  <br \/>\n----&gt; 1 run = experi.start_logging()<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py in start_logging(self, *args, **kwargs)  <br \/>\n259 &quot;&quot;&quot;  <br \/>\n260 from azureml.core.run import Run  <br \/>\n--&gt; 261 return Run._start_logging(self, *args, _parent_logger=self._logger, **kwargs)  <br \/>\n262  <br \/>\n263 @_check_for_experiment_id<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _start_logging(experiment, name, run_id, outputs, snapshot_directory, **kwargs)  <br \/>\n586 typev2 = RunTypeV2(orchestrator=&quot;External&quot;, traits=['unspecified'])  <br \/>\n587 run = Run._create(experiment, name=name, run_id=run_id, outputs=outputs,  <br \/>\n--&gt; 588 properties=properties, typev2=typev2, **kwargs)  <br \/>\n589 run._client.start()  <br \/>\n590 if snapshot_directory:<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _create(experiment, name, run_id, outputs, properties, tags, typev2, display_name, **kwargs)  <br \/>\n706 properties=properties, tags=tags, typev2=typev2,  <br \/>\n707 display_name=display_name)  <br \/>\n--&gt; 708 return Run._dto_to_run(experiment, run_dto, outputs=outputs, **kwargs)  <br \/>\n709  <br \/>\n710 @property<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _dto_to_run(experiment, run_dto, outputs, **kwargs)  <br \/>\n198 :rtype: Run  <br \/>\n199 &quot;&quot;&quot;  <br \/>\n--&gt; 200 return Run(experiment, run_dto.run_id, outputs=outputs, _run_dto=run_dto, **kwargs)  <br \/>\n201  <br \/>\n202 @classmethod<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in <strong>init<\/strong>(self, experiment, run_id, outputs, **kwargs)  <br \/>\n171  <br \/>\n172 &quot;&quot;&quot;  <br \/>\n--&gt; 173 super(Run, self).<strong>init<\/strong>(experiment, run_id, outputs=outputs, **kwargs)  <br \/>\n174 self._parent_run = None  <br \/>\n175<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_run_impl\/run_base.py in <strong>init<\/strong>(self, experiment, run_id, outputs, logs, _run_dto, _worker_pool, _user_agent, _ident, _batch_upload_metrics, py_wd, deny_list, flush_eager, redirect_output_stream, **kwargs)  <br \/>\n76 for output in outputs:  <br \/>\n77 try:  <br \/>\n---&gt; 78 os.makedirs(output)  <br \/>\n79 except OSError as exception:  <br \/>\n80 if exception.errno != errno.EEXIST:<\/p>\n<p>\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/os.py in makedirs(name, mode, exist_ok)  <br \/>\n218 return  <br \/>\n219 try:  <br \/>\n--&gt; 220 mkdir(name, mode)  <br \/>\n221 except OSError:  <br \/>\n222 # Cannot rely on checking for EEXIST, since the operating system<\/p>\n<p>PermissionError: [Errno 13] Permission denied: '.\/outputs'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio vs Azure ML Classic - K-Means",
        "Question_created_time":1632846849270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569616\/azure-ml-studio-vs-azure-ml-classic-k-means",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,     <br \/>\nWe have been using ML Classic and are testing and deploying to Azure ML Studio. As per the documentation for migration (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a> ) we decided to test the output results using the same algorithm (K-Means) and using the same dataset and parameters. The output was then compared and the results differ. Can someone help me understand why or why not this is expected and any other topics to consider between the two enviornments?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Argument pass to Docker Container Azure ML inference",
        "Question_created_time":1632856020243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569816\/custom-argument-pass-to-docker-container-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello Team,   <\/p>\n<p>I'm trying to pass the arguments to Azure ML docker. I have created an environment like this.  <\/p>\n<pre><code>env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/conda_dependencies.yml' )\n<\/code><\/pre>\n<p>Am I passing the arguments correct?   <\/p>\n<pre><code>DOCKER_ARGUMENTS = [&quot;--shm-size&quot;,&quot;32G&quot;]  # increase shared memory\nenv.docker.arguments = DOCKER_ARGUMENTS\n<\/code><\/pre>\n<p>The main goal of this project is to deploy a model on the AKS inference cluster. I have successfully deployed the model. When I try to get predictions from the model I got this error   <\/p>\n<blockquote>\n<p>It is possible that data loaders workers are out of shared memory. Please try to raise your shared memory limit  <\/p>\n<\/blockquote>\n<p>How can I do that if that's not the correct way to pass arguments?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy GPU enbaled in a studio notebook locally",
        "Question_created_time":1632702738960,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566714\/deploy-gpu-enbaled-in-a-studio-notebook-locally",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello there, team. I'm attempting to deploy a model locally in my ML studio notebook, which has GPU compute power. But when I try to run my model, I get an error.  <\/p>\n<blockquote>\n<p>Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from azure ml  <\/p>\n<\/blockquote>\n<p>I'm using this  <\/p>\n<pre><code>env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/new_cuda_dep.yml' ) #environment  using\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=env , source_directory='.' ,)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Consume AzureML Studio Output as dataframe",
        "Question_created_time":1632824148170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569086\/consume-azureml-studio-output-as-dataframe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <br \/>\n    I'm performing some experiments in AzureML studio with Automl. I trained the model with no-code option and trying to evaluate the same in notebooks. However, the output comes in form of bytes. Is there a way to get it in form a dataframe ?   <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135932-image.png?platform=QnA\" alt=\"135932-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What are the main advantages of Azure AutoML compared to FLAML as a paid service?",
        "Question_created_time":1632771141767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/568026\/what-are-the-main-advantages-of-azure-automl-compa",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I've studying the Python SDK documentation for Azure Automated ML and also a little bit o FLAML documentation. Both of them seems very similar to me in terms of code, so the only advantages I've noticed for Azure AutoML are the explicability diagram and the easy deployment by user interface. Are there any other advantages\/differences?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Document Translator Access Error",
        "Question_created_time":1632627969450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566297\/document-translator-access-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using AML to run python to translate documents (document translator) given the current bug, i am using the region endpoint (endpoint = &quot;https:\/\/australiaeast.api.cognitive.microsoft.com\/translator\/text\/batch\/v1.0&quot;)  <\/p>\n<p>The request sends (I get a 202) response.   <\/p>\n<p>When I run python to get the job status, I receive 200 :  <\/p>\n<p><em>&quot;200  <br \/>\n{&quot;id&quot;:&quot;b2e26de0-55c0-44c4-83ca-5c4315ec5bcd&quot;,&quot;createdDateTimeUtc&quot;:&quot;2021-09-26T03:33:19.9387768Z&quot;,&quot;lastActionDateTimeUtc&quot;:&quot;2021-09-26T03:33:20.5718544Z&quot;,&quot;status&quot;:&quot;ValidationFailed&quot;,&quot;error&quot;:{&quot;code&quot;:&quot;InvalidRequest&quot;,&quot;message&quot;:&quot;Cannot access source document location with the current permissions.&quot;,&quot;target&quot;:&quot;Operation&quot;,&quot;innerError&quot;:{&quot;code&quot;:&quot;InvalidDocumentAccessLevel&quot;,&quot;message&quot;:&quot;Cannot access source document location with the current permissions.&quot;}},&quot;summary&quot;:{&quot;total&quot;:0,&quot;failed&quot;:0,&quot;success&quot;:0,&quot;inProgress&quot;:0,&quot;notYetStarted&quot;:0,&quot;cancelled&quot;:0,&quot;totalCharacterCharged&quot;:0}}&quot;<\/em>  <\/p>\n<p>I am using a SAS generated URL+ URI from Storage Explorer, and have also tried to use SAS tokens generated from Azure Portal. I am generating these tokens at the Container level, as I'm trying to translate 3 documents.   <\/p>\n<p>Anyway I try to generate a SAS token, it always send fine, but I always get the above error. I even attempted to use a file specific SAS.   <\/p>\n<p>I am not using the user delegate SAS token in the portal. I haven't set up anything else in my Azure portal.   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure-cli-ml Version: '1.33.0', 'Error': WebserviceException. Can't deploy model into ACI",
        "Question_created_time":1632679013550,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/566564\/azure-cli-ml-version-1-33-0-error-webserviceexcept",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am trying to deploy with Azure DevOps my ktrain model, which is in a folder and has to loaded as a folder, to ACI, but I got this error:  <\/p>\n<p>021-09-26T16:10:35.2295468Z ERROR: {'Azure-cli-ml Version': '1.33.0', 'Error': WebserviceException:  <br \/>\n2021-09-26T16:10:35.2296197Z Message: Received bad response from Resource Provider:  <br \/>\n2021-09-26T16:10:35.2296590Z Response Code: 404  <br \/>\n2021-09-26T16:10:35.2298648Z Headers: {'Date': 'Sun, 26 Sep 2021 16:10:35 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '656a1432-d67d-4ad7-859d-f1408af3192f', 'x-ms-client-session-id': '3df8af72-17d1-46a7-88ea-21c9adce345f', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.037', 'Content-Encoding': 'gzip'}  <br \/>\n2021-09-26T16:10:35.2301435Z Content: b'{&quot;code&quot;:&quot;NotFound&quot;,&quot;statusCode&quot;:404,&quot;message&quot;:&quot;The specified resource was not found.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;OperationNotFound&quot;,&quot;message&quot;:&quot;There is no operation with id 7c10e5b9-2c13-48d4-82d0-10feba0ef679&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;656a1432-d67d-4ad7-859d-f1408af3192f&quot;}}'  <br \/>\n2021-09-26T16:10:35.2302322Z InnerException None  <br \/>\n2021-09-26T16:10:35.2302601Z ErrorResponse  <br \/>\n2021-09-26T16:10:35.2302853Z {  <br \/>\n2021-09-26T16:10:35.2303108Z &quot;error&quot;: {  <br \/>\n2021-09-26T16:10:35.2306300Z &quot;message&quot;: &quot;Received bad response from Resource Provider:\\nResponse Code: 404\\nHeaders: {'Date': 'Sun, 26 Sep 2021 16:10:35 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '656a1432-d67d-4ad7-859d-f1408af3192f', 'x-ms-client-session-id': '3df8af72-17d1-46a7-88ea-21c9adce345f', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.037', 'Content-Encoding': 'gzip'}\\nContent: b'{&quot;code&quot;:&quot;NotFound&quot;,&quot;statusCode&quot;:404,&quot;message&quot;:&quot;The specified resource was not found.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;OperationNotFound&quot;,&quot;message&quot;:&quot;There is no operation with id 7c10e5b9-2c13-48d4-82d0-10feba0ef679&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;656a1432-d67d-4ad7-859d-f1408af3192f&quot;}}'&quot;  <br \/>\n2021-09-26T16:10:35.2308796Z }  <br \/>\n2021-09-26T16:10:35.2309029Z }}`  <\/p>\n<p>My scoring script is below for init(). I have tried using both get_model_path and AZUREML_MODEL_DIR, but they don't work. For the latter, the deployment will keep running, and sometimes for the former.  <\/p>\n<pre><code>def init():\n    global model\n    logging.basicConfig(level=logging.DEBUG)\n    #  load the model from file into a global object\n    model_path = Model.get_model_path('mgsa')#, _workspace=ws)\n    print(model_path)\n    #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs')\n    model = ktrain.load_predictor(model_path)`\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to dynamically score models in Azure ML?",
        "Question_created_time":1632739965043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/567358\/how-to-dynamically-score-models-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I'm currently migrating from Machine Learning Studio to Azure Machine learning, and I am having some trouble replicating one of the experiments.  <\/p>\n<p>So, when using Studio, we had a blob storage where we stored all our trained models (ILearner files). Then, we had an experiment that imported one of these models and imported a dataset, and proceeded to score that model against the dataset.  <\/p>\n<p>This was made using the Load Trained Model module. However in Azure ML this module no longer exists and I'm having trouble finding a new way of replicating this experiment. Is there something I'm missing or is it no longer possible to do something like this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I transfer a csv file on an Azure Machine Learning compute instance directory back to the Datastore?",
        "Question_created_time":1632158641093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/559227\/how-can-i-transfer-a-csv-file-on-an-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I posted a similar question last week and didn't get a response to that yet so I'm posting another one now.  <\/p>\n<p>The code below is what I use to pull data into the compute instance from the Datastore. I transfer data from a Datastore to the compute instance and then save the data to my directory as a csv. The data originates from a SCOPE script and is transferred from Cosmos to the Datastore via Azure Data Factory.   <\/p>\n<p>Once the data is in the directory as a csv, I then utilize R to pull in the data into an RStudio session and then I run various tasks that create new data sets. I also save these new data sets to the compute instance directory as csv's. These new data sets are the ones I'd like to push back to the Datastore so they can be transferred elsewhere via Azure Data Factory and later consumed by a PowerBI app we're looking to create.  <\/p>\n<p>I tried using Designer and it ran for 4 days without completing before I cancelled the job and started looking for an alternative route. I don't know if it would have completed or if it ran into memory issues and simply didn't fail. When I pull data into the compute instance from the datastore it takes less than a few minutes to complete so I'm not sure why it would take Designer multiple days to attempt to do the reverse operation.  <\/p>\n<p>I've looked through a bunch of documentation and I am not able to find anything that tells us how we can transfer data from the compute instance back to the Datastore aside from Designer which is too slow or unable to handle.  <\/p>\n<p>This task seems like one that should be obvious for use and a major selling point of Azure Machine Learning so I'm a bit dumbfounded to see that this is a challenge figuring out how to do and that the documentation doesn't clearly show users how to achieve this task, assuming it's even possible. If it's not possible then I need to figure out a whole new system to use to get my work done. If it's not possible, the Azure Machine Learning team should enable this functionality as soon as possible.   <\/p>\n<pre><code># Azure management\nfrom azureml.core import Workspace, Dataset\n\n# MetaData\nsubscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\nresource_group = 'xCloudData'\nworkspace_name = 'xCloudML'\n\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\n# 1. Retention_Engagement_CombinedData\ndataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n\n# 2. TitleNameJoin\ndataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')\n<\/code><\/pre>",
        "Question_closed_time":1632211214827,
        "Answer_score_count":1.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=1e7638a3-d560-4c0d-85b3-9061fd2bc218\">@Adrian Antico (TEKsystems, Inc.)  <\/a> Have you tried the following to upload data to your datastore?    <\/p>\n<pre><code>from azureml.core import Workspace  \nws = Workspace.from_config()  \ndatastore = ws.get_default_datastore()  \n  \ndatastore.upload(src_dir='.\/data',  \n                 target_path='datasets\/',  \n                 overwrite=True)  \n<\/code><\/pre>\n<p>I think <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_storage_datastore.azureblobdatastore?view=azure-ml-py#upload-src-dir--target-path-none--overwrite-false--show-progress-true-\">datastore.upload()<\/a> should work for you to upload the required datafiles from your compute instance to datastore.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Workspace",
        "Question_created_time":1632495617397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/565561\/azure-machine-learning-workspace",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I'm facing several difficulties in starting Exercise Part 1: Create a Microsoft Azure Machine Learning Workspace.    <\/p>\n<p>1-It is always sending me to a page that I have two options: start free or pay as you go; when I choose the 'start free&quot; option, I'm facing an additional problem is that the name on my CC is not correct :-(. I've tried several cards but it didn't work.    <\/p>\n<p>Would you please support me.    <\/p>\n<p> I'm reachable via the following email: samihamandi<a href=\"\/users\/na\/?userid=1a0ca004-0000-0003-0000-000000000000\">@r\u00e9alisations   <\/a>.com    <\/p>\n<p>BR,    <br \/>\nSami Hamandi<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"InternalServerError when starting a GPU pipeline step",
        "Question_created_time":1632415728727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/564212\/internalservererror-when-starting-a-gpu-pipeline-s",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello!  <\/p>\n<p>I have been using Azure ML pipelines for some time now. Starting this week (at least - it may be a couple of weeks since I had previously used it) my pipeline runs are failing to start steps that run on GPU clusters.  <\/p>\n<p>I have a simple pipeline defined and triggered using the Python SDK, with three PipelineScriptSteps, the first of which runs on a CPU while the second runs on a GPU. The first step starts and runs as expected (and has now cached the output), however, when it moves on to the second step, it fails to start the GPU instance. It sits for ~30 mins preparing, then fails with an InternalServerError.  <\/p>\n<p>I also tried manually starting the relevant cluster in advance by setting a minimum size of 1. This successfully started the instance but the pipeline step still fails in the same way.  <\/p>\n<p>Any suggestions as to how I can get this working again?  <\/p>\n<p>David<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Python SDK Error \"RunIDConflict\"",
        "Question_created_time":1612451511860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/259049\/azure-machine-learning-python-sdk-error-runidconfl",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":7,
        "Question_body":"<p>Hello everybody,  <\/p>\n<p>I am currently learning Azure Machine Learning using the learning paths and labs. The lab scripts give me the following error I could not find anywhere yet.  <\/p>\n<p>&quot;Run IDs must be unique within a workspace and can only be used once. Ensure multiple runs with the same ID are not submitted simultaneously.&quot;  <\/p>\n<p>I am running the scripts locally. I have tried both Jupyter Notebook and VS Code. The error occurs exactly after 65 seconds when running experiment scripts. Both <a href=\"https:\/\/github.com\/MicrosoftDocs\/mslearn-aml-labs\/blob\/master\/01-Getting_Started_with_Azure_ML.ipynb\">lab 1<\/a> with script config and <a href=\"https:\/\/github.com\/MicrosoftDocs\/mslearn-aml-labs\/blob\/master\/02-Training_Models.ipynb\">lab 2<\/a> with an estimator give me the error. Running experiments directly within the IPython script works and I can see the results in the Azure web GUI. My SDK version is 1.21. When I did this in May 2020 with SDK version 1.15 I did not receive this error.  <\/p>\n<p>The respective code blocks that throw the errors copied from the lab scripts:  <\/p>\n<p>Lab 1:  <\/p>\n<pre><code>import os\nimport sys\nfrom azureml.core import Experiment, ScriptRunConfig\nfrom azureml.widgets import RunDetails\n\n\n# Create a script config\nscript_config = ScriptRunConfig(source_directory=experiment_folder, \n                      script='diabetes_experiment.py') \n\n# submit the experiment\nexperiment = Experiment(workspace = ws, name = 'diabetes-experiment')\nrun = experiment.submit(config=script_config)\nRunDetails(run).show()\nrun.wait_for_completion()\n<\/code><\/pre>\n<p>Lab 2:  <\/p>\n<pre><code>from azureml.train.estimator import Estimator\nfrom azureml.core import Experiment\n\n# Create an estimator\nestimator = Estimator(source_directory=training_folder,\n                      entry_script='diabetes_training.py',\n                      compute_target='local',\n                      conda_packages=['scikit-learn']\n                      )\n\n# Create an experiment\nexperiment_name = 'diabetes-training'\nexperiment = Experiment(workspace = ws, name = experiment_name)\n\n# Run the experiment based on the estimator\nrun = experiment.submit(config=estimator)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>Can you tell me how to fix this error? Thanks in advance.  <\/p>\n<p>Regards  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Test dataset contains invalid data.  ( Error 0018 ) in Azure ML Studio  Evaluate Recommender",
        "Question_created_time":1631430278073,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/548501\/test-dataset-contains-invalid-data-(-error-0018-)",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am doing a crop recommender system using the Matchbox recommender system in Azure ml studio.  <br \/>\nwhile splitting the dataset using Recommender split, it won't be split. but I split while using split rows, it works.<\/p>\n<p>but when evaluating recommender it shows error like 'Test dataset contains invalid data'  <br \/>\nhow to overcome this issue?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/131249-rate.png?platform=QnA\" alt=\"![131250-rate.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/131249-rate.png?platform=QnA\">2<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/131268-mlz.png?platform=QnA\" alt=\"131268-mlz.png\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question for Azure ML Studio Classic",
        "Question_created_time":1632106981540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/558101\/question-for-azure-ml-studio-classic",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, saw the post on <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>, would like to get some clarifications.    <\/p>\n<ol>\n<li> &quot;Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources. Through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) resources.&quot;    <br \/>\nIf I am just interested in creating the experiments, creating the ML models using the click-and-drag, is it still supported? Ie, i want to create new experiment, new model, new dataset, from now till 2024. I am focused more on the creating of ML model and evaluation, not so much on the deployment. What does the resources mean?     <\/li>\n<li> what are the options for students to migrate to Azure machine learning, if they do not have credit card to setup an azure account? What if the students are from private institutions, ie not from government affiliated organizations? Or is there a support granted to the students, if they have a .edu email account?    <\/li>\n<\/ol>\n<p>thank you and apologies if the queries are out of place. Not sure where can i get for help. thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"deployment issue in Azure.",
        "Question_created_time":1632128817590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/558600\/deployment-issue-in-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am a beginner in Azure ML. I am have successfully deployed my  NLP model  in Azure for sentiment analysis. Then I go to the workspace and Azure Machine Learning services. When I go to the endpoints, I get a 'Test' option. But when I put a  sentence for example  'I love to play football' in the test section the only  things come up in the Test result  <br \/>\nis {}. Can any one help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How AI\/Machine learning works in translator",
        "Question_created_time":1632270279733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/561221\/how-ai-machine-learning-works-in-translator",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am an undergraduate community college student in Richmond, VA.    <\/p>\n<p>I am wondering if you can help me understand how the translator works or if you can connect me with another expert who might be able to help me learn exactly how google translate works.   <\/p>\n<p>Questions:  <\/p>\n<p>If you enter the same phrase into the translator multiple times, does the program learn from it?  If so, how?  <\/p>\n<p> Does the translator take what people enter into the translator, store it and use it to output a common translation?  <\/p>\n<p>Here is a scenario.  Let's say I wrote something in english and then translated it word for word into farsi.  Then, I took my farsi work, inputed into google translate, and the output was a translation almost word for work with my english translation.  IF I keep doing that, would the translator &quot;deep learn&quot; and correct itself so that it exactly matched my english translation? What  about if I kept hitting the reverse arrow, and changing a word here or there, until both the farsi and english sentences inside the translator, match exactly what I originally wrote? Would the translator learn from that? In that way could I have &quot;taught&quot; the translator the most common way to interpret sentences in either language?  Is there a way to prove that someone used a translator to write something?  IF someone is trying to prove that someone else used a translator  to create a literary work, instead of writing it themselves, can they fairly say that the translator's translation matching word for word is indisputable, undeniable proof of their accusation?  <\/p>\n<p>Very Respectfully,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Remove a published python script from designer in \"Microsoft Auzre Machine Learning\" framework ?",
        "Question_created_time":1631266291247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/547166\/remove-a-published-python-script-from-designer-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,  <\/p>\n<p>I created a module that i have published using   <\/p>\n<pre><code>from azureml.pipeline.core.graph import InputPortDef, OutputPortDef\nfrom azureml.pipeline.core.module import Module\n\ndatastore = ws.get_default_datastore()\n\np_in = InputPortDef(\n    name=&quot;p_in&quot;, \n    default_datastore_mode=&quot;mount&quot;, \n    default_data_reference_name=datastore.name, \n    label=&quot;Donn\u00e9es de production&quot;\n    )\n\nmodule = Module.create(ws, name=&quot;Well Clustering&quot;, description=&quot;use well prod to create n class of producters&quot;)\nentry_version = module.publish_python_script(&quot;main.py&quot;, &quot;initial&quot;, \n                                             inputs=[p_in], outputs=[], params = { &quot;n_classes&quot;: 4},\n                                             version=&quot;1&quot;, source_directory=&quot;.&quot;)\n<\/code><\/pre>\n<p>It works and  i can see it in the Designer as a &quot;Custom Module&quot; with the right version, but how can i &quot;unregister it&quot;<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML compute not able to access Azure MLS workspace blob( not in vnet) during automl experiment execution",
        "Question_created_time":1631627630167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/551634\/azure-ml-compute-not-able-to-access-azure-mls-work",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>I'm trying to run the automl code from the examples (<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/automated-machine-learning\/regression-explanation-featurization\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/automated-machine-learning\/regression-explanation-featurization<\/a>)  in Azure MLS which is not in virtual network. While running the experiment, it is getting failed with the below error.    <\/p>\n<blockquote>\n<p>AzureMLCompute job failed.    <br \/>\nBFSMountError: Unable to mount blob fuse file system    <br \/>\nInfo: Could not mount Azure Blob Container azureml-blobstore-xxxx at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.    <br \/>\n Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.4 with err exit status 1.    <\/p>\n<\/blockquote>\n<p>Not sure why the AzureML is not able to access its own blobstorage to place the model artifacts.    <br \/>\nThe AzureML and the workspace blob both are not in virtual network.    <\/p>\n<p>Workarounds tried:    <\/p>\n<ol>\n<li> Tried to register the workspace blob container (azureml-blobstore-&lt;ID&gt;) as per the link here (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data<\/a>), but still getting the same error.    <\/li>\n<\/ol>\n<p>Note: The workspace blob storage keys are synced and can able to access the notebooks and data in AzureML, Is this causing the issue?    <\/p>\n<p>As per the ticket :- <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no.html<\/a>    <\/p>\n<p>Are the storage keys cached in the storage connection strings at the backend ? however the error message is different, in the reference ticket it says not able to access the resource, but in my case it is not able mount to the azure-ml-&lt;ID&gt; container.    <\/p>\n<p>Could you please help on it.    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Auto ML model endpoint deployment (Container Instance): Error No module named 'azureml.api'",
        "Question_created_time":1628773443990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/511349\/auto-ml-model-endpoint-deployment-(container-insta",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to deploy a model trained using AutoML directly from the Portal but the deployment to Container Instance fails. From the logs I can read the errors reported below.<\/p>\n<p>I am not sure what's the problem, it only appeared recently and fun fact is that if I try to deploy a model that was trained about 10 days ago it works without problem.  <br \/>\nDid anything change in the meantime? What am I missing?<\/p>\n<p>Exception in worker process  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;\/var\/azureml-server\/routes_common.py&quot;, line 37, in &lt;module&gt;  <br \/>\nfrom azureml.api.exceptions.ClientSideException import ClientSideException  <br \/>\nModuleNotFoundError: No module named 'azureml.api'<\/p>\n<p>and<\/p>\n<p>Traceback (most recent call last):  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker  <br \/>\nworker.init_process()  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process  <br \/>\nself.load_wsgi()  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi  <br \/>\nself.wsgi = self.app.wsgi()  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi  <br \/>\nself.callable = self.load()  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load  <br \/>\nreturn self.load_wsgiapp()  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp  <br \/>\nreturn util.import_app(self.app_uri)  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app  <br \/>\nmod = importlib.import_module(module)  <br \/>\nFile &quot;\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/importlib\/<strong>init<\/strong>.py&quot;, line 126, in import_module  <br \/>\nreturn _bootstrap._gcd_import(name[level:], package, level)  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 978, in _gcd_import  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 961, in _find_and_load  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 950, in _find_and_load_unlocked  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 678, in exec_module  <br \/>\nFile &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 205, in _call_with_frames_removed  <br \/>\nFile &quot;\/var\/azureml-server\/entry.py&quot;, line 1, in &lt;module&gt;  <br \/>\nimport create_app  <br \/>\nFile &quot;\/var\/azureml-server\/create_app.py&quot;, line 4, in &lt;module&gt;  <br \/>\nfrom routes_common import main  <br \/>\nFile &quot;\/var\/azureml-server\/routes_common.py&quot;, line 39, in &lt;module&gt;  <br \/>\nfrom azure.ml.api.exceptions.ClientSideException import ClientSideException  <br \/>\nModuleNotFoundError: No module named 'azure.ml'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"sizing cloud resources for an AI credit risk analysis application",
        "Question_created_time":1632292183837,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/561581\/sizing-cloud-resources-for-an-ai-credit-risk-analy",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>AI SaaS\/CRM solution focused on enhancing b2b credit risk analysis. The customer is trying to size his solution in Azure cloud for investors  <br \/>\nbut isn\u2019t clear on how much compute, networking, etc he\u2019ll need and if any of that is included in the AI\/ML framework solutions Azure cloud  offers.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"File Dataset not supported in Automated ML",
        "Question_created_time":1632158977537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/559228\/file-dataset-not-supported-in-automated-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>I'm trying to select a File dataset (file from Power BI) in Automated ML for a Regressive Machine Learning Model. However, Machine learning studio is displaying the dataset name under unsupported dataset (Screenshot attached). I wanted to know why the Power BI file is not being supported in the Automated ML? Additionally, I wanted to know what is the way I can upload the Power BI file (.pbix extension) in Machine learning studio to train the Regressive machine learning model?     <\/p>\n<p>Please let me know if you need any details from me.    <\/p>\n<p>Regards,    <br \/>\nAmbarish <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/133615-screenshot.png?platform=QnA\" alt=\"133615-screenshot.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Workspace Windows Server Compute Instance",
        "Question_created_time":1626842114250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/483713\/azure-ml-workspace-windows-server-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>  Would like to know is Windows Server Compute Instance available in Azure ML Workspace?  <\/p>\n<p>  I do understand there is DSVM for windows, but it won't have direct link to datasources and the jupyter notebook, or it is possible for me to link the compute once I have created the VM?  <\/p>\n<p>  I'm having a problem to migrate a conda environment from Windows to Linux, may I know what is the best practice for such migration?  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":1628119217447,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6760e7be-77ee-4c41-9c63-8bbcdab1aaae\">@SoonJoo@Genting  <\/a> Hello, I have reached out to DSVM, actually they support Azure service and JupyterNotebook.<\/p>\n<p>As the document said:<\/p>\n<blockquote>\n<p>&gt; It also allows you to access services on the Azure cloud platform. Azure provides several compute, storage, data analytics, and other services that you can administer and access from your DSVM.<\/p>\n<p>To administer your Azure subscription and cloud resources, you have two options:<\/p>\n<p>Use your browser and go to the Azure portal.<\/p>\n<p>Use PowerShell scripts. Run Azure PowerShell from a shortcut on the desktop or from the Start menu. See the Microsoft Azure PowerShell documentation for full details.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#manage-azure-resources\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#manage-azure-resources<\/a><\/p>\n<blockquote>\n<p>To start the Jupyter Notebook, select the Jupyter Notebook icon on the Start menu or on the desktop. In the DSVM command prompt, you can also run the command jupyter notebook from the directory where you have existing notebooks or where you want to create new notebooks.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#use-jupyter-notebooks\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#use-jupyter-notebooks<\/a><\/p>\n<p>Hope this helps.<\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML Data Labeling remains at \"Initializing\" state",
        "Question_created_time":1632142944040,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/558956\/azureml-data-labeling-remains-at-initializing-stat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I've created two Data Label projects, one with ML assistance and one without.  <br \/>\nBoth of these projects have been in the &quot;initializing&quot; state for days (4 days at the time of this post).  <\/p>\n<p>Is there a place to check progress and what is the expected time it should take for a labeling project to be ready?  <\/p>\n<p>Are there best practices perhaps that might speed this process up?  <\/p>\n<p>The dataset has about 2,000 JPG images in it, so I can't imagine anything taking that long to even just index them.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clean Data Error",
        "Question_created_time":1631932138293,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/557185\/clean-data-error",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I'm getting an error trying to clean a data module in Azure Machine Learning Studio (classic).    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/133292-snag-23559db.png?platform=QnA\" alt=\"133292-snag-23559db.png\" \/>    <\/p>\n<p>Below is the full log. I've tried logging out and back into my Azure account to no avail. Is there something wrong with my credentials?    <\/p>\n<blockquote>\n<p>Record Starts at UTC 09\/18\/2021 02:19:08:    <\/p>\n<p>Run the job:&quot;\/dll &quot;Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run&quot; \/Output0 &quot;....\\Cleaned dataset\\Cleaned dataset.dataset&quot; \/Output1 &quot;....\\Cleaning transformation\\Cleaning transformation.itransform&quot; \/inputData &quot;....\\Dataset\\Dataset.csv&quot; \/columnsToClean &quot;%7B%22isFilter%22%3Atrue%2C%22rules%22%3A%5B%7B%22ruleType%22%3A%22ColumnNames%22%2C%22columns%22%3A%5B%22symboling%22%5D%2C%22exclude%22%3Afalse%7D%5D%7D&quot; \/minRatio &quot;0&quot; \/maxRatio &quot;1&quot; \/cleaningMode &quot;Replace with mean&quot; \/colsWithAllMissing &quot;Remove&quot; \/indicatorColumns &quot;False&quot;  \/ContextFile &quot;...._context\\ContextFile.txt&quot;&quot;    <br \/>\n[Start] Program::Main    <br \/>\n[Start]     DataLabModuleDescriptionParser::ParseModuleDescriptionString    <br \/>\n[Stop]     DataLabModuleDescriptionParser::ParseModuleDescriptionString. Duration = 00:00:00.0024833    <br \/>\n[Start]     DllModuleMethod::DllModuleMethod    <br \/>\n[Stop]     DllModuleMethod::DllModuleMethod. Duration = 00:00:00.0000264    <br \/>\n[Start]     DllModuleMethod::Execute    <br \/>\n[Start]         DataLabModuleBinder::BindModuleMethod    <br \/>\n[Verbose]             moduleMethodDescription Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run    <br \/>\n[Verbose]             assemblyFullName Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca    <br \/>\n[Start]             DataLabModuleBinder::LoadModuleAssembly    <br \/>\n[Verbose]                 Loaded moduleAssembly Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca    <br \/>\n[Stop]             DataLabModuleBinder::LoadModuleAssembly. Duration = 00:00:00.0090461    <br \/>\n[Verbose]             moduleTypeName Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData    <br \/>\n[Verbose]             moduleMethodName Run    <br \/>\n[Information]             Module FriendlyName : Clean Missing Data    <br \/>\n[Information]             Module Release Status : Release    <br \/>\n[Stop]         DataLabModuleBinder::BindModuleMethod. Duration = 00:00:00.0102317    <br \/>\n[Start]         ParameterArgumentBinder::InitializeParameterValues    <br \/>\n[Verbose]             parameterInfos count = 10    <br \/>\n[Verbose]             parameterInfos[0] name = inputData , type = Microsoft.Numerics.Data.Local.DataTable    <br \/>\n[Start]             DataTableCsvHandler::HandleArgumentString    <br \/>\n[Stop]             DataTableCsvHandler::HandleArgumentString. Duration = 00:00:00.1604789    <br \/>\n[Verbose]             parameterInfos<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/133292-snag-23559db.png?platform=QnA\">1<\/a> name = columnsToClean , type = Microsoft.Analytics.Modules.Common.Dll.ColumnSelection    <br \/>\n[Verbose]             parameterInfos[2] name = minRatio , type = System.Double    <br \/>\n[Verbose]             Converted string '0' to value of type System.Double    <br \/>\n[Verbose]             parameterInfos[3] name = maxRatio , type = System.Double    <br \/>\n[Verbose]             Converted string '1' to value of type System.Double    <br \/>\n[Verbose]             parameterInfos[4] name = cleaningMode , type = Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+CleanMissingDataHandlingPolicy    <br \/>\n[Verbose]             Converted string 'Replace with mean' to enum of type Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+CleanMissingDataHandlingPolicy    <br \/>\n[Verbose]             parameterInfos[5] name = replacementValue , type = System.String    <br \/>\n[Verbose]             Set optional parameter replacementValue value to NULL    <br \/>\n[Verbose]             parameterInfos[6] name = colsWithAllMissing , type = Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+ColumnsWithAllValuesMissing    <br \/>\n[Verbose]             Converted string 'Remove' to enum of type Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+ColumnsWithAllValuesMissing    <br \/>\n[Verbose]             parameterInfos[7] name = indicatorColumns , type = System.Boolean    <br \/>\n[Verbose]             Converted string 'False' to value of type System.Boolean    <br \/>\n[Verbose]             parameterInfos[8] name = iterations , type = System.Int32    <br \/>\n[Verbose]             Set optional parameter iterations value to NULL    <br \/>\n[Verbose]             parameterInfos[9] name = iterationsPCA , type = System.Int32    <br \/>\n[Verbose]             Set optional parameter iterationsPCA value to NULL    <br \/>\n[Stop]         ParameterArgumentBinder::InitializeParameterValues. Duration = 00:00:00.4304001    <br \/>\n[Verbose]         Begin invoking method Run ...     <br \/>\n[Verbose]         End invoking method Run    <br \/>\n[Start]         DataLabOutputManager::ManageModuleReturnValue    <br \/>\n[Verbose]             moduleReturnType = System.Tuple<code>2[T1,T2]     [Start]             DataLabOutputManager::ConvertTupleOutputToFiles     [Verbose]                 tupleType = System.Tuple<\/code>2[Microsoft.Numerics.Data.Local.DataTable,Microsoft.Analytics.MachineLearning.ITransform<code>2[Microsoft.Numerics.Data.Local.DataTable,Microsoft.Numerics.Data.Local.DataTable]]     [Verbose]                 outputName Output0     [Start]                 DataTableDatasetHandler::HandleOutput     [Start]                     SidecarFiles::CreateVisualizationFiles     [Information]                         Creating Cleaned dataset.visualization with key visualization...     [Stop]                     SidecarFiles::CreateVisualizationFiles. Duration = 00:00:00.0704111     [Start]                     SidecarFiles::CreateDatatableSchemaFile     [Information]                         SidecarFiles::CreateDatatableSchemaFile creating &quot;..\\..\\Cleaned dataset\\Cleaned dataset.schema&quot;     [Stop]                     SidecarFiles::CreateDatatableSchemaFile. Duration = 00:00:00.0071185     [Start]                     SidecarFiles::CreateMetadataFile     [Information]                         SidecarFiles::CreateMetadataFile creating &quot;..\\..\\Cleaned dataset\\Cleaned dataset.metadata&quot;     [Stop]                     SidecarFiles::CreateMetadataFile. Duration = 00:00:00.0019639     [Stop]                 DataTableDatasetHandler::HandleOutput. Duration = 00:00:00.1898522     [Verbose]                 outputName Output1     [Start]                 CustomSerializationHandler::HandleOutput     [Start]                     DotNetSerializationHandler::HandleOutput     [Start]                         SidecarFiles::CreateRuntimeInfoFile     [Information]                             SidecarFiles::CreateRuntimeInfoFile creating &quot;..\\..\\Cleaning transformation\\Cleaning transformation.runtimeinfo&quot;     [Information]                             SidecarFileWritter::WriteRuntimeInfoToFile setting Language info for &quot;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform&quot;     [ModuleOutput] SidecarFileWritter::WriteRuntimeInfoToFile setting Language info for &quot;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform&quot;     [ModuleOutput] Setting Languge to DotNet.     [Stop]                         SidecarFiles::CreateRuntimeInfoFile. Duration = 00:00:00.0016640     [Start]                         SidecarFiles::CreateMetadataFile     [Information]                             SidecarFiles::CreateMetadataFile creating &quot;..\\..\\Cleaning transformation\\Cleaning transformation.metadata&quot;     [Stop]                         SidecarFiles::CreateMetadataFile. Duration = 00:00:00.0003313     [Stop]                     DotNetSerializationHandler::HandleOutput. Duration = 00:00:00.0045472     [Stop]                 CustomSerializationHandler::HandleOutput. Duration = 00:00:00.0050090     [Stop]             DataLabOutputManager::ConvertTupleOutputToFiles. Duration = 00:00:00.2003385     [Stop]         DataLabOutputManager::ManageModuleReturnValue. Duration = 00:00:00.2017888     [Verbose]         {&quot;InputParameters&quot;:{&quot;DataTable&quot;:[{&quot;Rows&quot;:205,&quot;Columns&quot;:26,&quot;estimatedSize&quot;:12574720,&quot;ColumnTypes&quot;:{&quot;System.Int32&quot;:5,&quot;System.Nullable<\/code>1[System.Int32]&quot;:4,&quot;System.String&quot;:10,&quot;System.Double&quot;:5,&quot;System.Nullable<code>1[System.Double]&quot;:2},&quot;IsComplete&quot;:true,&quot;Statistics&quot;:{&quot;0&quot;:[0.8341463414634146,1.0,-2.0,3.0,1.2453068281055315,6.0,0.0],&quot;1&quot;:[122.0,115.0,65.0,256.0,35.442167530553256,51.0,41.0],&quot;2&quot;:[22,0],&quot;3&quot;:[2,0],&quot;4&quot;:[2,0],&quot;5&quot;:[2,2],&quot;6&quot;:[5,0],&quot;7&quot;:[3,0],&quot;8&quot;:[2,0],&quot;9&quot;:[98.756585365853581,97.0,86.6,120.9,6.0217756850255721,53.0,0.0],&quot;10&quot;:[174.04926829268285,173.2,141.1,208.1,12.337288526555183,75.0,0.0],&quot;11&quot;:[65.907804878048722,65.5,60.3,72.3,2.1452038526871831,44.0,0.0],&quot;12&quot;:[53.724878048780596,54.1,47.8,59.8,2.4435219699049036,49.0,0.0],&quot;13&quot;:[2555.5658536585365,2414.0,1488.0,4066.0,520.68020350163874,171.0,0.0],&quot;14&quot;:[7,0],&quot;15&quot;:[7,0],&quot;16&quot;:[126.90731707317073,120.0,61.0,326.0,41.642693438179847,44.0,0.0],&quot;17&quot;:[8,0],&quot;18&quot;:[3.3297512437810943,3.31,2.54,3.94,0.27353873182959904,38.0,4.0],&quot;19&quot;:[3.2554228855721377,3.29,2.07,4.17,0.31671745337703111,36.0,4.0],&quot;20&quot;:[10.142536585365862,9.0,7.0,23.0,3.9720403218632976,32.0,0.0],&quot;21&quot;:[104.25615763546799,95.0,48.0,288.0,39.714368786793578,59.0,2.0],&quot;22&quot;:[5125.3694581280788,5200.0,4150.0,6600.0,479.33455983341668,23.0,2.0],&quot;23&quot;:[25.219512195121951,24.0,13.0,49.0,6.5421416530016216,29.0,0.0],&quot;24&quot;:[30.751219512195121,30.0,16.0,54.0,6.886443130941827,30.0,0.0],&quot;25&quot;:[13207.129353233831,10295.0,5118.0,45400.0,7947.066341939274,186.0,4.0]}}],&quot;Generic&quot;:{&quot;columnsToClean&quot;:&quot;{\\&quot;isFilter\\&quot;:true,\\&quot;rules\\&quot;:[{\\&quot;ruleType\\&quot;:\\&quot;ColumnNames\\&quot;,\\&quot;columns\\&quot;:[\\&quot;symboling\\&quot;],\\&quot;exclude\\&quot;:false}]}&quot;,&quot;minRatio&quot;:0.0,&quot;maxRatio&quot;:1.0,&quot;cleaningMode&quot;:&quot;ReplaceWithMean&quot;,&quot;colsWithAllMissing&quot;:&quot;Remove&quot;,&quot;indicatorColumns&quot;:false}},&quot;OutputParameters&quot;:[&quot;Parameter with no known logging method, Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform&quot;,{&quot;Rows&quot;:205,&quot;Columns&quot;:26,&quot;estimatedSize&quot;:0,&quot;ColumnTypes&quot;:{&quot;System.Int32&quot;:5,&quot;System.Nullable<\/code>1[System.Int32]&quot;:4,&quot;System.String&quot;:10,&quot;System.Double&quot;:5,&quot;System.Nullable`1[System.Double]&quot;:2},&quot;IsComplete&quot;:true,&quot;Statistics&quot;:{&quot;0&quot;:[0.8341463414634146,1.0,-2.0,3.0,1.2453068281055315,6.0,0.0],&quot;1&quot;:[122.0,115.0,65.0,256.0,35.442167530553256,51.0,41.0],&quot;2&quot;:[22,0],&quot;3&quot;:[2,0],&quot;4&quot;:[2,0],&quot;5&quot;:[2,2],&quot;6&quot;:[5,0],&quot;7&quot;:[3,0],&quot;8&quot;:[2,0],&quot;9&quot;:[98.756585365853581,97.0,86.6,120.9,6.0217756850255721,53.0,0.0],&quot;10&quot;:[174.04926829268285,173.2,141.1,208.1,12.337288526555183,75.0,0.0],&quot;11&quot;:[65.907804878048722,65.5,60.3,72.3,2.1452038526871831,44.0,0.0],&quot;12&quot;:[53.724878048780596,54.1,47.8,59.8,2.4435219699049036,49.0,0.0],&quot;13&quot;:[2555.5658536585365,2414.0,1488.0,4066.0,520.68020350163874,171.0,0.0],&quot;14&quot;:[7,0],&quot;15&quot;:[7,0],&quot;16&quot;:[126.90731707317073,120.0,61.0,326.0,41.642693438179847,44.0,0.0],&quot;17&quot;:[8,0],&quot;18&quot;:[3.3297512437810943,3.31,2.54,3.94,0.27353873182959904,38.0,4.0],&quot;19&quot;:[3.2554228855721377,3.29,2.07,4.17,0.31671745337703111,36.0,4.0],&quot;20&quot;:[10.142536585365862,9.0,7.0,23.0,3.9720403218632976,32.0,0.0],&quot;21&quot;:[104.25615763546799,95.0,48.0,288.0,39.714368786793578,59.0,2.0],&quot;22&quot;:[5125.3694581280788,5200.0,4150.0,6600.0,479.33455983341668,23.0,2.0],&quot;23&quot;:[25.219512195121951,24.0,13.0,49.0,6.5421416530016216,29.0,0.0],&quot;24&quot;:[30.751219512195121,30.0,16.0,54.0,6.886443130941827,30.0,0.0],&quot;25&quot;:[13207.129353233831,10295.0,5118.0,45400.0,7947.066341939274,186.0,4.0]}}],&quot;ModuleType&quot;:&quot;Microsoft.Analytics.Modules.CleanMissingData.Dll&quot;,&quot;ModuleVersion&quot;:&quot; Version=6.0.0.0&quot;,&quot;AdditionalModuleInfo&quot;:&quot;Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run&quot;,&quot;Errors&quot;:&quot;&quot;,&quot;Warnings&quot;:[],&quot;Duration&quot;:&quot;00:00:00.7323002&quot;}    <br \/>\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:00.7557727    <br \/>\n[Stop] Program::Main. Duration = 00:00:00.8973350    <br \/>\nModule finished after a runtime of 00:00:00.9843864 with exit code 0    <br \/>\nExecution failed due to exception:taskStatusCode=400. Failed to upload W:\\jw\\e\\Cleaned dataset\\Cleaned dataset.dataset to Uri experimentoutput\/4a90c8cd-cc1d-4de0-97b2-aebb1285e140\/4a90c8cd-cc1d-4de0-97b2-aebb1285e140.dataset. This is an Azure storage request failure with status code 404. The request id is 5052585f-501e-000b-2933-acd43e000000 and the error message is The specified resource does not exist.. Possible reasons for such failure: (1) Invalid storage account or credential (2) Invalid SAS token (3) Concurrent jobs trying to upload files to the same blob at the same time. If those are not your case, please consider it as a transient error and retry.    <\/p>\n<p>Record Ends at UTC 09\/18\/2021 02:19:09.    <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio constantly reloads the page",
        "Question_created_time":1632076586477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/557872\/azure-ml-studio-constantly-reloads-the-page",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi!    <\/p>\n<p>Browser every time reload page when I try to open my experiments (<a href=\"https:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/ccb760e2e68248638a3281e03067021f#Workspace\/Experiments\/ListExperiments\">https:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/ccb760e2e68248638a3281e03067021f#Workspace\/Experiments\/ListExperiments<\/a>)    <\/p>\n<p>I check it on firefox 92.0 and chrome 93.0.4577.82 ubuntu 20.04    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/133383-screenshot-from-2021-09-19-21-32-31.png?platform=QnA\" alt=\"133383-screenshot-from-2021-09-19-21-32-31.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy Azure ML pipeline as web App: Inference Pipeline Error (No Model)",
        "Question_created_time":1631885782377,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/556603\/deploy-azure-ml-pipeline-as-web-app-inference-pipe",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/133050-capture.jpg?platform=QnA\" alt=\"133050-capture.jpg\" \/>    <\/p>\n<p>Since Azure ML Studio (classic) is ending, I want to recreate my Pipeline (see image), it works when I run it, but how can I deploy the Pipeline? I get an error when I want to create Batch Inference Pipeline ['Cannot create inference pipeline because there is no trained model in this pipeline.'].    <\/p>\n<p>How can I deploy this pipeline and get endpoints?    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Designer: Cannot create inference because there is no model on this pipeline",
        "Question_created_time":1603790266017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/140838\/azure-designer-cannot-create-inference-because-the",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have created a pipeline in <strong>Azure Designer<\/strong> and trying to deploy this as a batch prediction.  <\/p>\n<p>When I click &quot;Create Inference Pipeline&quot; and &quot;Batch Inference Pipeline&quot; I get this error message:  <br \/>\n<em><strong>Cannot create inference because there is no model on this pipeline.<\/strong><\/em>  <\/p>\n<p>How can I deploy this as a batch prediction?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Support for Azure Machine Learning workspace with Azure Kubernetes Service 1.21.X",
        "Question_created_time":1631726396763,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/553605\/support-for-azure-machine-learning-workspace-with",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>Currently Azure Machine Learning Worksapce doesnt support Azure Kubernetes Service 1.21.X, when will this support be available ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML: User errors were found in at least one of the child runs",
        "Question_created_time":1630835455217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/540302\/azure-ml-user-errors-were-found-in-at-least-one-of",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I am trying to perform hyperparameter tuning, but I keep getting the error in my Question Title. I am new to Azure, and I am not sure if it is some error in my script. Could someone advise please?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129278-image.png?platform=QnA\" alt=\"129278-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129364-image.png?platform=QnA\" alt=\"129364-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129328-image.png?platform=QnA\" alt=\"129328-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129373-image.png?platform=QnA\" alt=\"129373-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning\u306b\u3064\u3044\u3066\u306e\u8cea\u554f",
        "Question_created_time":1631251067517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/546760\/machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>\u63b2\u984c\u306e\u4ef6\u306b\u3064\u304d\u307e\u3057\u3066\u3001\u73fe\u5728Machine Learning\u3092\u4f7f\u7528\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002  <br \/>\n\u305d\u3053\u3067\u8cea\u554f\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u30c7\u30b6\u30a4\u30ca\u30fc\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066\u5b66\u7fd2\u7d50\u679c\u3092CSV\u3067\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001  <br \/>\nExport Data\u30e2\u30c7\u30eb\u3067CSV\u5f62\u5f0f\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u3066\u3082CSV\u3067\u306f\u306a\u3044\u5f62\u5f0f\u3067\u5171\u6709\u305b\u308c\u3066\u3057\u307e\u3046\u306e\u3067\u3059\u304c\u3001\u539f\u56e0\u304c\u308f\u304b\u3089\u306a\u3044\u72b6\u6cc1\u3067\u3059\u3002  <br \/>\n\u3054\u6559\u793a\u306e\u307b\u3069\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3044\u305f\u3057\u307e\u3059\u3002<\/p>",
        "Question_closed_time":1631268910237,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=8f940edc-4c98-48e4-8a54-287e99830334\">@\u6817\u7530\u771f\u5b5d  <\/a> Are you referring to the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data\">export data module<\/a> of the designer from ml.azure.com?    <br \/>\nI think I understand the issue, Are you seeing that the .csv format of file is not listed on the blob storage?    <\/p>\n<p>Since the input is a dataframe directory to export module the output format selected should still be the format you selected, in this case CSV. The file name extension only might be missing. You can still open the csv file in excel and it will recognize the delimiters and headers so you can convert it into excel files.     <\/p>\n<p>You can also avoid this by providing the .csv extension in the path itself in export settings and file will be exported as a csv file directly.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/131128-image.png?platform=QnA\" alt=\"131128-image.png\" \/>    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Retirement Announcement - Transition to Azure Machine Learning by 31 August 2024",
        "Question_created_time":1630044593657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530215\/retirement-announcement-transition-to-azure-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Because Azure Machine Learning now provides rich, consolidated capabilities for model training and deploying,\u202fwe'll retire the older Machine Learning Studio (classic) service on 31 August 2024. Please transition to using Azure Machine Learning by that date. If you have a question, please post it in this thread.  <\/p>",
        "Question_closed_time":1630044774267,
        "Answer_score_count":0.0,
        "Answer_comment_count":6.0,
        "Answer_body":"<p>Follow these steps to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view pricing <a href=\"https:\/\/azure.microsoft.com\/pricing\/details\/machine-learning\/\">here<\/a>.    <\/p>\n<ul>\n<li> Steps to migrate <a href=\"https:\/\/learn.microsoft.com\/azure\/machine-learning\/migrate-overview\">link<\/a>    <\/li>\n<li> Price <a href=\"https:\/\/azure.microsoft.com\/pricing\/details\/machine-learning\/#:%7E:text=Consumed%20Azure%20resources%20%28e.g.%20compute%2C%20storage%29%20%28No%20Azure,%24-%20%2B%20per%20vCPU%20hour%20Edition%3A%20Basic%20Enterprise\">link<\/a>    <\/li>\n<\/ul>\n<p>If you have any additional queries regarding this retirement, please use comments on this thread to ask your specific queries and we will try our best to answer those queries.    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Azure Percept DK: How to collect network inference performance on a pre-trained model?",
        "Question_created_time":1631223450427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/546407\/azure-percept-dk-how-to-collect-network-inference",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Looking for some metric, for example latency in milliseconds, that can represent the <strong>inference<\/strong> time of a pre-trained model using the Azure Percept DK.  <\/p>\n<p>For example, I have been training a network or creating a network in TensorFlow and would like to test it on the Azure Percept DK.  I would like to see any performance improvements or latency metrics that represent the changes I am making to my network to track <strong>inference performance<\/strong> overtime.  <\/p>\n<p>Is there any way to get this information from the Percept Devkit?  I see telemetry information but this doesn't seem like the performance numbers I am seeking.  <\/p>\n<p>If easier to make an example, is this feature available for any of the pre-trained models supplied with the devkit I can test on to see the model inference performance?   <\/p>\n<p>Are there any guides or precedence for collecting network performance on this device?  Not looking for the precision\/recall\/mAP percents here, more network latency times.  <\/p>\n<p>Thanks.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom computer vision for surface calculations on digital floor maps",
        "Question_created_time":1631108624923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/544199\/custom-computer-vision-for-surface-calculations-on",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I am working on a project to calculate surface area from digital floor maps. I am currently experimenting with azure cognitive services - Custom computer vision. However I don't know if this is the right track.   <\/p>\n<p>If possible I would like to use a existent tool instead of reinventing the wheel. Has anyone experience with this and can provide me with some guidance?  <\/p>",
        "Question_closed_time":1631217055323,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Sure, thanks for clarifying. I agree, an out of box approach would be to use computer vision or custom vision to detect objects and then use the metadata to calculate the surface area. I haven't seen an existing solution using Azure Cognitive services at the moment, so you'd most likely have to use a heuristic approach.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Convert File Dataset into a Dataframe to use in a pipeline",
        "Question_created_time":1630504637667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/536168\/convert-file-dataset-into-a-dataframe-to-use-in-a",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,   <\/p>\n<p>I would like to convert a file dataset into a dataframe using a python script to use the data in a pipeline. I need to use the file dataset as i want to train my model using the files and not the table.  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED",
        "Question_created_time":1631128926847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/544656\/failed-to-run-cublas-routine-cublas-status-executi",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi, I am trying to train a model on AZURE AML A100.   <\/p>\n<p>I have trained the same model on my GPU server before with  tensorflow_gpu-1.15.5,    python 3.7,  Gcc 7.5.0, cuDNN 7.6.5 , cuda 10.0  <\/p>\n<p>I used a docker file to curated the same env, so I am sure it has tensorflow_gpu-1.15.5,    python 3.7,  cuDNN 7.6.5 , cuda 10.0. The only thing I am not sure is Gcc 7.5.0.  <\/p>\n<p>However, I am keeping getting the error message  <\/p>\n<p> <em>start training  <br \/>\n2021-09-08 18:18:21.911226: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0  <br \/>\n2021-09-08 18:58:09.545333: E tensorflow\/stream_executor\/cuda\/cuda_blas.cc:428] failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED  <br \/>\n2021-09-08 18:58:09.545451: I tensorflow\/stream_executor\/stream.cc:1990] [stream=0x55ae14908d10,impl=0x55ae14907470] did not wait for [stream=0x55ae14908a90,impl=0x55ae149074a0]  <br \/>\n2021-09-08 18:58:09.545478: F tensorflow\/core\/common_runtime\/gpu\/gpu_util.cc:342] CPU-&gt;GPU Memcpy failed  <br \/>\n2021-09-08 18:58:09.545528: I tensorflow\/stream_executor\/stream.cc:4938] [stream=0x55ae14908d10,impl=0x55ae14907470] did not memcpy host-to-device; source: 0x7fe9f749b000  <br \/>\n2021-09-08 18:58:09.545529: I tensorflow\/stream_executor\/stream.cc:4938] [stream=0x55ae14908d10,impl=0x55ae14907470] did not memcpy host-to-device; source: 0x7fe9f74a1600  <br \/>\nbash: line 1:    96 Aborted                 (core dumped) python $AZ_BATCHAI_JOB_TEMP\/azureml\/hydranet_prod_base_tf_1_15_5_1631122651_ba72eb11\/azureml-setup\/context_manager_injector.py &quot;-i&quot; &quot;ProjectPythonPath:context_managers.ProjectPythonPath&quot; &quot;-i&quot; &quot;Dataset:context_managers.Datasets&quot; &quot;-i&quot; &quot;RunHistory:context_managers.RunHistory&quot; &quot;-i&quot; &quot;TrackUserError:context_managers.TrackUserError&quot; &quot;-i&quot; &quot;UserExceptions:context_managers.UserExceptions&quot; &quot;main_aml.py&quot; &quot;--note&quot; &quot;hydranet_prod_base_tf_1_15_5&quot; &quot;--mount_path&quot; &quot;DatasetConsumptionConfig:data_folder&quot; &quot;--conf&quot; &quot;conf\/aml.conf&quot; &quot;--job&quot; &quot;train&quot; &quot;--in_train_feat_path&quot; &quot;account_clean_sq_distribution.10.null.feat.jsonl|opportunity_clean_sq_distribution.10.null.feat.jsonl|contact_clean_sq_distribution.10.null.feat.jsonl|lead_clean_sq_distribution.10.null.feat.jsonl|customerprofile_clean_sq_distribution.10.null.feat.jsonl|train.prioritysetexact.account.noise-level-0.feat.jsonl|train.prioritysetexact.opportunity.noise-level-0.feat.jsonl|train.prioritysetexact.contact.noise-level-0.feat.jsonl|train.prioritysetexact.lead.noise-level-0.feat.jsonl&quot; &quot;--in_dev_feat_path&quot; &quot;measurement.contact.noise-level-0.20201202.feat.jsonl&quot; &quot;--in_wikisql_train_feat_path&quot; &quot;wikisql.train.noise-level-0.20201202.feat.jsonl&quot; &quot;--out_subset_feat_dir&quot; &quot;outputs\\subset_feat_dir&quot; &quot;--in_bert_root_path&quot; &quot;DatasetConsumptionConfig:base_model_folder&quot;  <br \/>\n2021\/09\/08 18:58:11 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/6670d3e3-260e-46c2-bdb4-8fb42942abe0\/job-1\/hydranet_prod_base_t_82b9b21d-3ac5-4f55-a692-5b84119e9daa\/wd\/runTaskLetTask_error.json  <br \/>\n2021\/09\/08 18:58:11 Wrapper cmd failed with err: exit status 134  <br \/>\n2021\/09\/08 18:58:11 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.19:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.19:16384\/sendlogstoartifacts\/status<\/a>  <br \/>\n2021\/09\/08 18:58:11 Send process info logs to master server succeeded  <br \/>\n2021\/09\/08 18:58:11 mpirun version string: {  <br \/>\nmpirun (Open MPI) 3.1.2  <br \/>\nReport bugs to <a href=\"http:\/\/www.open-mpi.org\/community\/help\/\">http:\/\/www.open-mpi.org\/community\/help\/<\/a>  <br \/>\n}  <br \/>\n2021\/09\/08 18:58:11 Not exporting to RunHistory as the exporter is either stopped or there is no data.  <br \/>\nStopped: false  <br \/>\nOriginalData: 2  <br \/>\nFilteredData: 0.  <br \/>\n2021\/09\/08 18:58:11 Process Exiting with Code:  134  <br \/>\n2021\/09\/08 18:58:11 All App Insights Logs was sent successfully or the close timeout of 10 was reached<\/em>   <\/p>\n<p>I searched the message in the title, and the common solution of adding   <\/p>\n<p> <em>config = tf.compat.v1.ConfigProto()  <br \/>\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9  <br \/>\nconfig.gpu_options.allow_growth = True  <br \/>\nconfig.gpu_options.polling_inactive_delay_msecs = 10  <br \/>\nsession = tf.compat.v1.Session(config=config)<\/em>    <\/p>\n<p>did not work.  <\/p>\n<p>One final idea is that this set-up does not work on RTX 3xxx. However, I am not sure what kind of GPU Azure is using.  <\/p>\n<p>Could anyone help? Thank you!!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Need to do a Face detection on rtsp stream using Azure services",
        "Question_created_time":1631162999540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/545213\/need-to-do-a-face-detection-on-rtsp-stream-using-a",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I would like to use some of the Azure service for my project. Idea is to stream encoded video stream (h264), expecting Azure to decode and perform face detection on it in real time. What are the best services to use it.  <br \/>\nOne option I explore is to use computer vision\/face Api with media services, however computed vision API requires image in jpeg\/bif format which requires reencoding of decoding stream, or I need to do screen grab, which I dont want to do as it will increase latency.  <br \/>\nIf there is service which does ML operations on raw frame decoded by media services would help here.<\/p>",
        "Question_closed_time":1631183295583,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=88d23319-305b-49af-9869-3932b5769dd3\">@Saurabh Singh Sengar  <\/a> The service that offers the capability to enable identification of faces in real time with streaming video is <a href=\"https:\/\/azure.microsoft.com\/en-us\/products\/video-analyzer\/#overview\">Azure Video Analyzer.<\/a> It should support HLS and other popular formats, you can take a look at the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-video-analyzer\/video-analyzer-docs\/quotas-limitations\">limitations and quotas<\/a> from the documentation.     <\/p>\n<p>With computer vision or face API you need to capture the frame or a screen shot and pass the same to the API to get the results.     <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"reID machine learning inference",
        "Question_created_time":1631163287910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/545271\/reid-machine-learning-inference",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to do reID operation on a person's face, so that it give me different numerical value for different faces, which can be map to person's identity. I couldn't find any ready to use reID model with Azure, please let me know what is the work involved in it ?  <br \/>\nCan I use some open source reID trained model like caffe\/pytorch and use with some of the Azure service to inference using it.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is the STANDARD_NC6_PROMO VM slow ?",
        "Question_created_time":1619490632293,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/372837\/why-is-the-standard-nc6-promo-vm-slow",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Subscription ID : e30f2093-840c-43cf-8aa6-35923b617406    <\/p>\n<p>I have created a Machine Learning resource and then uploaded a Jupyter Notebook that I have previously runned in Google Colab.    <br \/>\nIn the Google Colab free GPU my Deep Learning model for Object Localization (Yolov5) runs in a heavier model (Yolov5l.pt for 100 epochs) in 4.5 hours and in Azure my model in its slightest version (Yolov5s.pt) runs for 12 hours and it is only in the half of the process (41 epochs out of 100).    <\/p>\n<p>Why is it so slow ?    <\/p>\n<p>What can I change to make it faster ?    <\/p>\n<p>FYI: In the second image I show you that I have uploaded in this place my training dataset.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91487-screenshot-7.png?platform=QnA\" alt=\"91487-screenshot-7.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91488-screenshot-8.png?platform=QnA\" alt=\"91488-screenshot-8.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning (AutoML) export data to SharePoint",
        "Question_created_time":1631064917827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543361\/azure-machine-learning-(automl)-export-data-to-sha",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using Azure Machine Learning Studio to design pipelines to analyze data.  <br \/>\nIs there any possibility to export data to sharepoint?<\/p>",
        "Question_closed_time":1631084842440,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi @MiaZhangWHQWistron-2092     <br \/>\nPer my research, there is no way to export data from Azure Machine Learning Studio to SharePoint directly.    <\/p>\n<p>As an alternative, you could export data to Azure SQL database first:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-to-azure-sql-database\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-to-azure-sql-database<\/a>    <\/p>\n<p>Then export data from Azure SQL database to SharePoint list:    <br \/>\n<a href=\"https:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/39170.azure-sql-db-with-sharepoint-online-as-external-list-using-business-connectivity-services.aspx\">https:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/39170.azure-sql-db-with-sharepoint-online-as-external-list-using-business-connectivity-services.aspx<\/a>    <\/p>\n<hr \/>\n<p>If an Answer is helpful, please click &quot;<strong>Accept Answer<\/strong>&quot; and upvote it.    <\/p>\n<p>Note: Please follow the steps in <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/email-notifications\">our documentation<\/a> to enable e-mail notifications if you want to receive the related email notification for this thread.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why would I need to register a machine learning model with azure endpoint?",
        "Question_created_time":1630340796540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/533161\/why-would-i-need-to-register-a-machine-learning-mo",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nIt appears to me that the types of models that can be registered using the azure SDK should come from sklearn, Keras, etc and be converted into a pickle file and after registration, you can send the request to the endpoint.  <\/p>\n<p>I can think of a very limited number of cases where you just want to create a backend system that only returns the model prediction. In most cases, the backend of a front end application would take care of all the calculations and sometimes also decide which models to run and maybe combine the results before sending the output to the frontend. For this reason, you might want to implement the complex logic in rest API such as Flask. In this case, why would I call another endpoint from the flask application to run the model, instead of simply loading the pickle file in the flask project?  <\/p>\n<p>What are the cases where you are registering with Azure endpointst and actually using the endpoints to make a prediction in azure from you trained model? Are you limited to specific libraries to create the pickles? what if you need to process the input before making the predictions?   <\/p>\n<p>thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hiding secrets in raw JSON [AML]",
        "Question_created_time":1631001392253,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/542247\/hiding-secrets-in-raw-json-(aml)",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>On AML in the RUN View you can see firstly the command which was run on AML and the &quot;Raw JSON&quot; which displays the whole runDefinition and more.    <br \/>\nWe want to do something as described here <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-github-actions-machine-learning?McasTsid=28375\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-github-actions-machine-learning?McasTsid=28375<\/a> but without waiting for the results. This means that the RUN has to have credentials to push the trained model to some location.    <\/p>\n<p>This is an issue as we currently can not restrict access or mask secrets in the &quot;Raw JSON&quot;. The command section in the Run view contains the same issue as this section can contain secrets too.    <\/p>\n<p>We use <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/job?view=azure-cli-latest\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/job?view=azure-cli-latest<\/a> to create a Run, but the issue would be the same if any other method would be used to trigger a Run.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Exit Code 143",
        "Question_created_time":1631037752020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543071\/azure-machine-learning-exit-code-143",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi There,   <br \/>\nI am running a very simple pipeline that contains a dataset and a SQL transformation task. When i run the two tasks i get an error : 2021\/09\/07 17:49:47 Wrapper cmd failed with err: exit status 143 which i can't seem to find anywhere. I am running a compute VM DS1.   <br \/>\nany direction?  <br \/>\nThanks,  <\/p>",
        "Question_closed_time":1631040059280,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Incase anyone is wondering, you must increase the compute with more memory to avoid this...<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"How to resolve error - Creating conda environment failed with exit code: 1?",
        "Question_created_time":1629557858217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/522968\/how-to-resolve-error-creating-conda-environment-fa",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I am getting this error when I run script  <strong>job_submit.py<\/strong>. I do not know how to debug this issue, would appreciate help to solve this.    <\/p>\n<p>PS: I have just started learning azure so I am not sure what I am missing.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/125147-image.png?platform=QnA\" alt=\"125147-image.png\" \/>    <\/p>\n<h2 id=\"script_to_runpy----\">script_to_run.py    <\/h2>\n<pre><code>   from azureml.core import Workspace, Dataset, Run  \n     \n   ws = Workspace.from_config()  \n   az_dataset = Dataset.get_by_name(workspace=ws, name='titanic-dataset')  \n     \n   # Get the context of the experiment  \n   new_run = Run.get_context()  \n     \n   df = az_dataset.to_pandas_dataframe()  \n   ### count the observations  \n   total_obs = len(df)  \n   ### get the gender count  \n   gender_count = df['Sex'].value_counts()  \n     \n     \n   # log the metrics to workspace  \n   new_run.log(name = &quot;Total observations&quot;, value = total_obs)  \n   ### Log the gender data values  \n   for val in df['Sex'].unique():  \n       new_run.log(name = val, value = gender_count[val])  \n     \n   # complete an experiment run  \n   new_run.complete()  \n<\/code><\/pre>\n<h2 id=\"job_submitpy----\">job_submit.py    <\/h2>\n<pre><code>   from azureml.core import Workspace, Datastore, Dataset, Experiment, ScriptRunConfig, Environment  \n   # Access workspace  \n   ws = Workspace.from_config()  \n   # create an experiment object  \n   exp = Experiment(workspace=ws, name = &quot;Titanic_exp&quot;)  \n     \n   # create custom env - myenv  \n   myenv = Environment(name = 'MyEnvironment')  \n   # to install dependencies  \n   from azureml.core.environment import CondaDependencies  \n     \n   # from CondaDependencies class we need to create an object which will have all the required dependencies  \n   # create the dependencies object  \n   packages = CondaDependencies.create(conda_packages=['pandas', 'scikit-learn']) # this will have list of all packages we will need  \n   myenv.python.conda_dependencies = packages # this will tell to install the packages  \n     \n   # register environment to workspace so that we have access to it  \n   myenv.register(ws)  \n     \n   # create a script configuration for custom env  \n   script_config = ScriptRunConfig(source_directory = '.', script = &quot;script_to_run.py&quot;, environment = myenv)  \n     \n   new_run = exp.submit(config = script_config)  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployemnt Time out error in AKS and Endpoint stuck in \"Transitioning\" state.",
        "Question_created_time":1630906705210,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/540740\/deployemnt-time-out-error-in-aks-and-endpoint-stuc",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Working on the deployment of 170 ML models using ML studio and azure Kubernetes service which is referred on the below doc link &quot;https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-deploy-azure-kubernetes-service.md&quot;.     <\/p>\n<p>We are training the model using python script with the custom environment and we are registering the ml model on the  Azure ML services. Once we register the mode we are deploying it on the AKS by using the container images.     <\/p>\n<p>While deploying the ML model we are able to deploy up to 10 to 11 models per pod for each Node in AKS. When we try to deploy the model on the same node we are getting deployment timeout error and we are getting the below error message.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129464-deployment-error.png?platform=QnA\" alt=\"129464-deployment-error.png\" \/>    <\/p>\n<p>For deploying the model in Azure Kubernetes Service using python language with below sample code.    <\/p>\n<pre><code> #  Create an environment and add conda dependencies to it and for this creating our environment and building the custom container image.  \n        myenv = Environment(name = Deployment_name)  \n        myenv.python.conda_dependencies = CondaDependencies.create(pip_packages)  \n      \n          \n    #  Inference_Conifiguration  \n        inf_config = InferenceConfig(environment= myenv, entry_script='.\/Script_file.py')  \n      \n      \n    # Deployment_Conifiguration  \n        deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, cpu_cores_limit = 2, memory_gb_limit = 2, traffic_percentile = 10)  \n      \n    #  AKS cluster compute target   \n        aks_target = ComputeTarget(ws, 'pipeline')  \n         \n      \n   #  Deploying the model in AKS server  \n          service = Model.deploy(ws, Deployment_name, model_1, inf_config,  \n                      deployment_config, aks_target, overwrite=True)  \n      \n           service.wait_for_deployment(show_output=True)  \n<\/code><\/pre>\n<p>We also checked on the azure documentation and we could able to find any configuration or deployment setup for aks nodes.    <\/p>\n<p>Can you please provide us more clarification regarding &quot;The number of models to be deployed is limited to 1,000 models per deployment (per container)&quot; and Can you please give insight\/feedback on how to increase the number of ml models that can be deployed in each node in Azure Kubernetes Service? Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the best way to deploy my machine learning model using GPUs, specifically as a web based API?",
        "Question_created_time":1630916125883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/541074\/what-is-the-best-way-to-deploy-my-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to find the best way to run my machine learning models on GPUs for inference as an http request. Do Azure functions support GPUs? if not, what are other options I can look into?  <\/p>\n<p>note: I also want to use packaged models, not necessarily ones of my own creation (such as <a href=\"https:\/\/github.com\/JaidedAI\/EasyOCR\">easyOCR<\/a> for python)  <\/p>",
        "Question_closed_time":1630921359623,
        "Answer_score_count":1.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p>Hi,    <\/p>\n<p>If you need GPU support on ML inference the only supported option is the Azure Kubernetes Service as stated in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-inferencing-gpus\">this documentation<\/a>    <\/p>\n<p>For guidance on deploying an ML model to AKS, please refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python\">this documenation on deploying to AKS<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Train Clustering Model Error 1000",
        "Question_created_time":1630520655430,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/536571\/train-clustering-model-error-1000",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>This error occurs when I add a Metadata editor.    <br \/>\nI want to Make the Fraud column a label for K-mean classification.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/128328-0.png?platform=QnA\" alt=\"128328-0.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/128329-1.png?platform=QnA\" alt=\"128329-1.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/128352-2.png?platform=QnA\" alt=\"128352-2.png\" \/>    <\/p>\n<p>I tried to add another metadata editor to exclude Fraud from the features, but the previous  editor seems to have already taken care of that.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Collaborate on Azure Machine Learning Project",
        "Question_created_time":1596973683450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/62694\/collaborate-on-azure-machine-learning-project",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I just recently became a Microsoft Certified Azure Data Scientist Associate. So I am looking for data scientist novices to join me practice on open datasets on kaggle to build machine learning models and do predictions using Azure ML. We will start with Titanic competition. If interested please visit my github link: <a href=\"https:\/\/github.com\/ivombi\/Titanic-Machine-Learning-from-Disaster\">https:\/\/github.com\/ivombi\/Titanic-Machine-Learning-from-Disaster<\/a> or send a request on LinkedIn using my full name: Kubam Ivo Mbi.   <br \/>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how many models can be deployed in single node in azure kubernetes service?",
        "Question_created_time":1630746472547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/540001\/how-many-models-can-be-deployed-in-single-node-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Working on deployment of 170 ml models using ML studio and azure Kubernetes service which is referred on the  below doc  link &quot;https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-deploy-azure-kubernetes-service.md&quot;.     <\/p>\n<p>We are training the model using python script with the custom environment and we are registering the ml model on the  Azure ML services. Once we register the mode we are deploying it on the AKS by using the container images.     <\/p>\n<p>While deploying the ML model we are able to deploy up 10 to 11 models per pods for each Node in AKS. When we try to deploy the model on the same node we are getting deployment timeout error and we are getting the below error message.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129300-image-2021-09-04t13-25-12-512z.png?platform=QnA\" alt=\"129300-image-2021-09-04t13-25-12-512z.png\" \/>    <\/p>",
        "Question_closed_time":1630758725400,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=f023f08d-7d4a-4ac5-ba62-e9d37f7e7c70\">@suvedharan  <\/a>     <\/p>\n<p>The number of models to be deployed is limited to 1,000 models per deployment (per container).    <\/p>\n<p>Autoscaling for Azure ML model deployments is azureml-fe, which is a smart request router. Since all inference requests go through it, it has the necessary data to automatically scale the deployed model(s).    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python\">more details<\/a>    <\/p>\n<p>If the Answer is helpful, please click <code>Accept Answer<\/code> and <strong>up-vote<\/strong>, so that it can help others in the community looking for help on similar topics.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Question on Azure Features and Limitations for Free and Paid Version",
        "Question_created_time":1630749021297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/539984\/question-on-azure-features-and-limitations-for-fre",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <\/p>\n<p>I am a student from University of Wollonggong Malaysia KDU Penang. I am planning to do a final year project that utilises machine learning to perform image and handwriting recognition using cloud computing. Therefore I would like to understand if there are related products that are provided on Azure. For the free tier and\/or Azure for student, what are the available product(s) that may satisfy my project requirements and what are its limitations. Similarly for the paid version, what additional features are provided and how are the pricings calculated?   <\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Apply SQL Transformation Error : Failed when create table error 1000",
        "Question_created_time":1629294395873,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/518856\/apply-sql-transformation-error-failed-when-create",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I connected 2 tables to &quot;Apply SQL Transformation&quot; box and when i ran the code the following error appears (screenshots attached). csv files downloaded from web for i have shared link below.<\/p>\n<p><strong>Link 1<\/strong> : <a href=\"https:\/\/docs.google.com\/spreadsheets\/d\/1aeZllwICUG7Q_rEgtNm4zj9pVV4iJaND6uUbou0qOp8\/pub?gid=873193374&amp;single=true&amp;output=csv\">https:\/\/docs.google.com\/spreadsheets\/d\/1aeZllwICUG7Q_rEgtNm4zj9pVV4iJaND6uUbou0qOp8\/pub?gid=873193374&amp;single=true&amp;output=csv<\/a>  <br \/>\n<strong>Link 2<\/strong> : <a href=\"https:\/\/docs.google.com\/spreadsheets\/d\/1xnMNKqB2tCdOecXt3WWjIUxbAk5rrvbYfbJLrfzFrjc\/pub?gid=1144892773&amp;single=true&amp;output=csv\">https:\/\/docs.google.com\/spreadsheets\/d\/1xnMNKqB2tCdOecXt3WWjIUxbAk5rrvbYfbJLrfzFrjc\/pub?gid=1144892773&amp;single=true&amp;output=csv<\/a><\/p>\n<p><strong>Error details<\/strong> : requestId = cf031a39f0684e2786d1fb4768c898ce errorComponent=Module. taskStatusCode=400. {&quot;Exception&quot;:{&quot;ErrorId&quot;:&quot;LibraryException&quot;,&quot;ErrorCode&quot;:&quot;1000&quot;,&quot;ExceptionType&quot;:&quot;ModuleException&quot;,&quot;Message&quot;:&quot;Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: &quot;,&quot;Exception&quot;:{&quot;Library&quot;:&quot;SQLiteQueryRunner Library&quot;,&quot;ErrorId&quot;:&quot;SQLiteCreateTableFailed&quot;,&quot;ErrorCode&quot;:&quot;3&quot;,&quot;ExceptionType&quot;:&quot;LibraryException&quot;,&quot;Message&quot;:&quot;Failed when create table: &quot;,&quot;Exception&quot;:{&quot;ExceptionType&quot;:&quot;Exception&quot;,&quot;Message&quot;:&quot;SQL logic error or missing database\\r\\nunrecognized token: \\&quot;\\&quot;PK\\u0003\\u0004\\u0014\\&quot;&quot;}}}}Error: Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: Process exited with error code -2<\/p>\n<p>Very much appreciate it if someone could explain the way out since i am new to Azure ML.<\/p>\n<p>SQL query that i used is provided below<\/p>\n<p>select title_year, movie_title, category, <code>Won?<\/code>  <br \/>\nfrom t1, t2  <br \/>\nwhere t1.movie_title = t2.Nominee  <br \/>\nand <code>Won?<\/code> = &quot;YES&quot;  <br \/>\norder by title_year desc<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/124238-error-1000.png?platform=QnA\" alt=\"124238-error-1000.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/124280-experiment.png?platform=QnA\" alt=\"124280-experiment.png\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model Predicted results  vary if data is fed from sql trasnformation block",
        "Question_created_time":1629196292650,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/517122\/model-predicted-results-vary-if-data-is-fed-from-s",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <br \/>\nI created a model to read training and testing data from 2 respective  cosmos db tables and used an sql transformation block to rename the column names and used it for training and in score model as shown in snapshot (modela.jpg) . The Predicted parameter (scored label) is very much different and incorrect (refer  onlysqltrans.jpg)    <br \/>\nWhen I use a &quot;convert to csv&quot; block connected to output of sql transformation block (refer modelb.jpg for model diagram )  and then use it in training , I get expected results ( refer withcsvblock.jpg)  .     <br \/>\nThe Mean Absolute error in first case was 51.2 while in modelb was only 0.09    <\/p>\n<p>I used a convert to dataset block after sql transform block and used that to connect to training model    <br \/>\nbut that too gave the same result as modela output    <\/p>\n<p>In case you want to see what sql transformation i used    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123904-modelb.jpg?platform=QnA\" alt=\"123904-modelb.jpg\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123936-withcsvblock.jpg?platform=QnA\" alt=\"123936-withcsvblock.jpg\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123945-modela.jpg?platform=QnA\" alt=\"123945-modela.jpg\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123992-onlysqltrans.jpg?platform=QnA\" alt=\"123992-onlysqltrans.jpg\" \/>    <\/p>\n<pre><code>  select  &quot;['CombiTimeTable.y[1]']&quot; as av1 ,&quot;['CombiTimeTable.y[2]']&quot; as av2,&quot;['CombiTimeTable.y[3]']&quot; as av3,&quot;['CombiTimeTable.y[4]']&quot; as av4,&quot;['CombiTimeTable.y[5]']&quot; as av5,&quot;['CombiTimeTable.y[6]']&quot; as av6,&quot;['CombiTimeTable.y[7]']&quot; as av7,&quot;['CombiTimeTable.y[8]']&quot; as av8,&quot;['CombiTimeTable.y[9]']&quot;  as av9 from t1  \n<\/code><\/pre>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ValidationException: The data points should have at least 50 rows for a valid regression or classification task with cv 5.",
        "Question_created_time":1629986755287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/529189\/validationexception-the-data-points-should-have-at",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to run a autoML model as follows:<\/p>\n<p>automl_settings = {  <br \/>\n&quot;n_cross_validations&quot;: 5  <br \/>\n}<\/p>\n<p>automl_config = AutoMLConfig(task = 'regression',  <br \/>\ncompute_target = compute_target,  <br \/>\ntraining_data = train_data.filter(train_data['location']==l),  <br \/>\nlabel_column_name = label,  <br \/>\n**automl_settings)<\/p>\n<p>remote_run = experiment.submit(automl_config, show_output=True)<\/p>\n<p>And I get: ValidationException: The data points should have at least 50 rows for a valid regression or classification task with cv 5.<\/p>\n<p>The data has more than 250 rows. Moreover, when I changed the cv number, nothing changed. Does anybody have any idea what might be happening?<\/p>",
        "Question_closed_time":1630572887363,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,  <\/p>\n<p>Hope you have solved this issue. If you are still blocked by this, please feel free to let us know. We can either investigate deeper if we can have more details, or we can help you to enable a support ticket if you do not have a support plan. Thanks.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"why the ML data only result in 1 point?",
        "Question_created_time":1629379772053,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/520581\/why-the-ml-data-only-result-in-1-point",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/124761-%E6%88%AA%E5%B1%8F2021-08-19-%E4%B8%8B%E5%8D%8892818.png?platform=QnA\" alt=\"124761-%E6%88%AA%E5%B1%8F2021-08-19-%E4%B8%8B%E5%8D%8892818.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Issues with Azure ML Studio - Kernel",
        "Question_created_time":1628265638423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/504524\/issues-with-azure-ml-studio-kernel",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <br \/>\n I am facing issues with Azure ML Studio and kernel associated with the Compute instance.    <br \/>\nI am unable to run the sample example codes using Jupyter.    <br \/>\nIt always shows Queueing the Cells in Jupyter notebook while running each cell from the Notebooks option.    <\/p>\n<p>I have also tried from Jupyter application in the Compute Instance. It is also throwing some error associated with Python Kernel.    <\/p>\n<p>I see there are <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/252893\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c-1.html\">similar issue raised in the past<\/a> but still open.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/121198-image.png?platform=QnA\" alt=\"121198-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"pipelines stuck on preparing stage forever.",
        "Question_created_time":1630478522800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/535410\/pipelines-stuck-on-preparing-stage-forever",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Unable to execute pipelines on the STANDARD_D16S_V3. It is stuck on the prepare stage forever. But the same pipeline executed without trouble 2 weeks ago.   <br \/>\nAlso now AutoML are stuck on 'Not Started' stage.   <br \/>\nThe compute instances and compute clusters were again recreated, just to ensure if there were some issues with our previous computes. We have faced the issue where suddenly the computes have slowed down but this time they just dont get ahead of the prepare stage.   <br \/>\nTo be noted, this occurs only in case of pipelines and automl.   <br \/>\nAt the same time we are getting billed for the compute resources.   <br \/>\nWhat can be possibly wrong here?   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Drifting Sample in azure machine learning studio does not finish backfill",
        "Question_created_time":1630488394320,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/535756\/drifting-sample-in-azure-machine-learning-studio-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to run the sample tutorial on data\/model drifting in azure machine learning samples. When I run the backfill command is waiting for the target cluster in the queue and it does not start, after waiting for a very long time.    <\/p>\n<p>Is it a common issue? How to run the example? I thought was a question of simply run it .. but it does not finish the run..    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/128244-screenshot-2021-09-01-at-102508.png?platform=QnA\" alt=\"128244-screenshot-2021-09-01-at-102508.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The standard d16_v3 is extremely slow",
        "Question_created_time":1629815195147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/526081\/the-standard-d16-v3-is-extremely-slow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>d16_v3 compute instance takes forever just for a simple preprocessing of a 4 GB chunk size of tabular data from the azure blob storage. This action is executed by a pipeline here and it is stuck on the preparing stage for a long time. ~2 weeks the pipeline was through within an hour.   <\/p>\n<p>what could possibly go wrong here? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[Bug] azureml-train Python package deprecated but did receive an update which is not in line with azureml-train-core",
        "Question_created_time":1629973035930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/528959\/(bug)-azureml-train-python-package-deprecated-but",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>The Python package <a href=\"https:\/\/pypi.org\/project\/azureml-train\/\">azureml-train<\/a> is deprecated and seems basically a wrapper around <a href=\"https:\/\/pypi.org\/project\/azureml-train-core\/\">azureml-train-core<\/a>. When installing <code>azureml-train<\/code>, if I'm correct it tries to install the <code>azureml-train-core<\/code> package with the same version number. However, on the 24th of August 2021 the <code>azureml-train<\/code> package was <a href=\"https:\/\/pypi.org\/project\/azureml-train\/#history\">updated<\/a> to version 1.33.1 whereas <code>azureml-train-core<\/code> <a href=\"https:\/\/pypi.org\/project\/azureml-train-core\/#history\">wasn't updated<\/a>. This causes the installation of <code>azureml-train<\/code> to fail.   <\/p>\n<p>I would suggest to remove version 1.33.1 of <code>azureml-train<\/code> such that it still can be installed.  <br \/>\nOtherwise, I'm curious why this situation is the case.  <\/p>",
        "Question_closed_time":1629981340733,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b3ae76bb-30c9-45f0-9c89-d61eac6d87f6\">@SjoerdGn  <\/a> Yes, this is a bug in the release cycle that was pushed to pypi, This also caused other packages to get updated.    <\/p>\n<p><a href=\"https:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/\">https:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/<\/a>    <br \/>\n<a href=\"https:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/\">https:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/<\/a>    <\/p>\n<p><a href=\"https:\/\/pypi.org\/project\/azureml-sdk\/#history\">azureml-sdk 1.33.0.post1<\/a> is released now to ensure the correct versions are installed with the SDK. As you mentioned above azureml-train 1.33.1 is not required and can be removed.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can't deploy a real time endpoint in azure Auto ML",
        "Question_created_time":1628186151087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/503097\/cant-deploy-a-real-time-endpoint-in-azure-auto-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I've trained a model using Auto ML and I want to try to deploy it to a Kubernetes service, I've got a pretty simple inference cluster. But no matter how low I set the CPU and memory reserve capacity it always says there isn't enough resources to deploy. Do I need to upgrade my cluster or is this a known issue with a current solution? It seems to me to be quite random as other times I was able to deploy other models with no problems at all. And even if I try to deploy it as a container instance it gets stuck in transitioning state indefinetely . Hope someone might clarify this issue and propose some kind of workaround.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to change the scoring URI in ML Service deployment",
        "Question_created_time":1630356655677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/533289\/is-it-possible-to-change-the-scoring-uri-in-ml-ser",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm trying to deploy a model as an endpoint in azure ML Studio. model.deploy call returns service which has a scoring_uri. I'm wondering if it is possible to change the scoring_uri from \/score to something else more appropriate. Or potentially register multiple of the uri's under the same FQDN like \/score, \/test, \/retrain under same principal guid service name.<\/p>\n<p>inference_config = InferenceConfig(entry_script=ENTRY_SCRIPT, environment=keras_env)  <br \/>\naci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)<\/p>\n<p>service = Model.deploy(workspace=ws,  <br \/>\nname=SERVICE_NAME,  <br \/>\nmodels=[model],  <br \/>\ninference_config=inference_config,  <br \/>\ndeployment_config=aci_config,  <br \/>\noverwrite=True)  <br \/>\nservice.wait_for_deployment(show_output=True)<\/p>\n<p>uri = service.scoring_uri<\/p>\n<p><a href=\"http:\/\/XXXXXXXX-XXXX-4000-XXXX-aa1a5e7XXXXX.westus2.azurecontainer.io\/score\">http:\/\/XXXXXXXX-XXXX-4000-XXXX-aa1a5e7XXXXX.westus2.azurecontainer.io\/score<\/a><\/p>\n<p>Can we change the last part from \/score to something else? like \/test or register multiple endpoints.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problems with Azure ML Designer",
        "Question_created_time":1630234227267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/531796\/problems-with-azure-ml-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to follow Learning Path <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-classification-model-azure-machine-learning-designer\/\">Create a Classification Model with Azure Machine Learning Designer<\/a>.<\/p>\n<p>There are some problems that I faced. I use latest version of Chromium for this.  <br \/>\n* When I hit submit, the process gets stuck to queued unless I refresh the page.  <br \/>\n* After submit, the database I selected get replaced with an empty dataset.  <br \/>\n* Maximising and minimising window or changing screen size also had a bad effect on the save. Although I save the pipeline, its name gets back to default when I leave full screen or enter full screen.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Designer python script to save Dataset data as csv to compute instance directories",
        "Question_created_time":1630351702510,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/533352\/designer-python-script-to-save-dataset-data-as-csv",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a set of custom Python and R scripts to execute a machine learning pipeline for analysis purposes. The steps are as follows:  <\/p>\n<ol>\n<li> With Python, Convert Datastore data to csv that gets saved in the compute instance directory  <\/li>\n<li> With R, pull in the csv data and run some feature engineering, build a machine learning model, and save scoring data to directory as csv  <\/li>\n<li> Push csv data back to Datastore  <\/li>\n<\/ol>\n<p>The first issue I'm encountering in Designer is the first step, saving Datastore data as csv to the compute instance directory. I created a function called azureml_main() that internally pulls in the Datastore data and saves it as csv to the directory. I have run the code that's inside the function a bunch of times but when I try to have it run in the Python script node in Designer it fails.   <\/p>\n<h1 id=\"error-message--\">Error message:  <\/h1>\n<p>AmlExceptionMessage:User program failed with FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.  <br \/>\n---------- End of error message from Python  interpreter  ----------  <\/p>\n<p>ModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.  <br \/>\n---------- End of error message from Python  interpreter  ----------  <\/p>\n<p>\/\/ Python script inside Python node in Designer.  <br \/>\n\/\/ The script MUST contain a function named azureml_main  <br \/>\n\/\/ which is the entry point for this module.  <\/p>\n<p>import pandas as pd  <\/p>\n<p>\/\/ The entry point function MUST have two input arguments.  <br \/>\n\/\/ If the input port is not connected, the corresponding  <br \/>\n\/\/ dataframe argument will be None.  <br \/>\n\/\/   Param&lt;dataframe1&gt;: a pandas.DataFrame  <br \/>\n\/\/   Param&lt;dataframe2&gt;: a pandas.DataFrame  <\/p>\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n    # Azure management\n    from azureml.core import Workspace, Dataset\n\n    # MetaData\n    subscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\n    resource_group = 'xCloudData'\n    workspace_name = 'xCloudML'\n\n    # Create workspace \n    workspace = Workspace(subscription_id, resource_group, workspace_name)\n\n    # 1. Retention_Engagement_CombinedData\n    dataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n\n    # 2. TitleNameJoin\n    dataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')\n\n\n\nazureml_main()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployment failed - InternalServerError",
        "Question_created_time":1630015001840,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/529757\/deployment-failed-internalservererror",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <\/p>\n<p>I just created a free Azure account. I want to create an an Azure Machine Learning workspace (create a resource), but it seems that the the deployment fails. I receive the following error:  <\/p>\n<p>&quot;code&quot;: &quot;InternalServerError&quot;,  <br \/>\n&quot;message&quot;: &quot;Received 400 from a service request&quot;  <\/p>\n<p>What should I do?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ml model with power virtual agents.",
        "Question_created_time":1630294796910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/532187\/azure-ml-model-with-power-virtual-agents",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>can anyone help me how to integrate Azure ML model with power virtual agents and publish it in team's...  <\/p>\n<p>Thank's in advance  <\/p>\n<p>waiting for reply:)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to see azureml python virtual env in VSCode",
        "Question_created_time":1627995036793,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/499892\/not-able-to-see-azureml-python-virtual-env-in-vsco",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I created a python virtual environment in Azure ML compute instance and have linked my VSCode with the compute instance but I am not able to access that virtual environment.  <br \/>\nIs it something I am missing?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Pipeline Step started to fail with no apparent reason.",
        "Question_created_time":1630021622550,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/529730\/azure-machine-learning-pipeline-step-started-to-fa",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>The PythonScript steps, which consume only PipelineData started to fail with no apparent reason. No changes were made to any of the step scripts or pipeline building scripts, but newly built pipelines fail with the same error in the same place. There is no such problem with resubmitting the same pipeline created a couple of days ago. Is it somehow connected to the recent AML update?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/126897-image.png?platform=QnA\" alt=\"126897-image.png\" \/>    <\/p>\n<p>the 70_driver_log.txt contents are:    <\/p>\n<pre><code>[2021-08-26T22:36:12.024855] After variable expansion, calling script [preprocess\/EvaluateStage1Models.py] with arguments: **...**  \nbash: line 1:   111 Illegal instruction     (core dumped) \/azureml-envs\/azureml_**...**  \n<\/code><\/pre>\n<p>RunIDs:    <\/p>\n<ol>\n<li> 70a1ec8a-ab32-48da-8aa8-077a03839cb7 - newly made one (failed)    <\/li>\n<li> 6649f74f-54be-4ede-8f01-23fe1de78eb9 - old resubmitted one (ok)    <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Vision for student",
        "Question_created_time":1630134876857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/531378\/custom-vision-for-student",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I registered Microsoft Azure with student account for senior project in my university and I wonder how long that I can use Custom Vision (1month or 1 year)?, I would like to know the algorithm inside the Custom Vision for object detection?, which domain is good for the big model for object detection, and can I export the project to share with my friend to label pictures in project?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"why is spanish not showing in preprocess text module in Azure ML designer?",
        "Question_created_time":1630021974807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/529798\/why-is-spanish-not-showing-in-preprocess-text-modu",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi everyone,     <\/p>\n<p>I'm migrating a NPL model created in ML Studio (classic) to Azure ML designer. When I try to configure the language in the Preprocess Text module the list only displays English.     <\/p>\n<p>Is Spanish available for this module? Or is there a way to enable more languages that include spanish.     <\/p>\n<p>Thanks in advance for a solution\/answer     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/126942-image.png?platform=QnA\" alt=\"126942-image.png\" \/>    <\/p>",
        "Question_closed_time":1630055668337,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6e10eaad-f4b9-43b1-8abc-89bc1ebaa079\">@Benjamin Kutz  <\/a> This module only supports English. Please refer the documentation of the module <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/preprocess-text\">here<\/a>.    <br \/>\nWe will check with the team internally to confirm if there is a roadmap to extend this to other languages. Thanks!!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Question on Retirement of Microsoft Machine Learning Studio (Classic)",
        "Question_created_time":1630053623617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530482\/question-on-retirement-of-microsoft-machine-learni",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I can check if I can still use Microsoft Machine Learning Studio (Classic) to create \u201cnew experiment\u201d &amp; \u201cnew web services\u201d until Aug 2024?  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question on Retirement of Microsoft Machine Learning Studio (Classic)",
        "Question_created_time":1630052967747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530463\/question-on-retirement-of-microsoft-machine-learni",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I can check if I can still use Microsoft Machine Learning Studio (Classic) to create \u201cnew experiment\u201d &amp; \u201cnew web services\u201d until Aug 2024?  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to apply activation functions in Azure Machine Learning studio",
        "Question_created_time":1629883772423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/527245\/how-to-apply-activation-functions-in-azure-machine",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to be able to apply activation functions in pipeline flow in Azure Mazhine Learning. According to every documentation and Q&amp;A there should be the option of selecting Hidden layer specification: Define a custom architecture. but as you can see in the image below there is only one option in the drop down menu.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/126331-untitled.png?platform=QnA\" alt=\"126331-untitled.png\" \/>    <\/p>\n<p>What do I need to do to get more options, and if there are none why have a drop down menu?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access to NCasT4_v3-series and ND A100 v4-series VMs",
        "Question_created_time":1629921673763,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/528034\/access-to-ncast4-v3-series-and-nd-a100-v4-series-v",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How could I request quota for the NCasT4_v3-series and ND A100 v4-series VMs for Machine Learning services and as regular VMs  <\/p>\n<p>They both do not appear as an option on the usual form to request quota increase in any of the 4 US regions I looked  <\/p>\n<p>Thanks  <\/p>\n<p>Manuel<\/p>",
        "Question_closed_time":1629922551630,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=8de1093a-60f2-479b-b811-ff2bab24e3cd\">@Manuel Reyes Gomez  <\/a> ,    <\/p>\n<p>the VM series NCasT4_v3 and ND A100 v4 are only available in 3 US regions (both series together)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/126428-image.png?platform=QnA\" alt=\"126428-image.png\" \/>    <\/p>\n<p>Source: <a href=\"https:\/\/azure.microsoft.com\/en-us\/global-infrastructure\/services\/?products=virtual-machines&amp;regions=us-central,us-east,us-east-2,us-north-central,us-south-central,us-west-central,us-west,us-west-2,us-west-3\">https:\/\/azure.microsoft.com\/en-us\/global-infrastructure\/services\/?products=virtual-machines&amp;regions=us-central,us-east,us-east-2,us-north-central,us-south-central,us-west-central,us-west,us-west-2,us-west-3<\/a>    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to deploy a scikit learn regression model as a web service?",
        "Question_created_time":1629821122530,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/526203\/how-to-deploy-a-scikit-learn-regression-model-as-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I find the documentation related with ML model deployment overwhelming and I'm struggling with the most basic &quot;Hello world&quot; tutorial even after several days of research.  <\/p>\n<p>All I want is to deploy the most basic model as a web service that can be consumed via an API through Power BI or any other web app to serve as a POC.  Then we can think about &quot;scale&quot;, &quot;dockers&quot;, &quot;containers&quot;, etc...  <\/p>\n<p>This is my code in Python 3.6:  <\/p>\n<pre><code>import joblib\n\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import Ridge    \n\ndataset_x, dataset_y = load_diabetes(return_X_y=True)\n\nmodel = Ridge().fit(dataset_x, dataset_y)\n\njoblib.dump(model, 'sklearn_regression_model.pkl')\n<\/code><\/pre>\n<p>This model as features as an array like:  <\/p>\n<pre><code>array([[ 0.03807591,  0.05068012],[ ... , ...]])\n<\/code><\/pre>\n<p>As you can see, I've got the model serialized into a sklearn_regression_model.pkl file, I've also got the ML environment setup in Azure ML, a compute instance, I'm familiar with Python and the designer and prefer notebooks.  <\/p>\n<p>How can I deploy this model through an API like:  <\/p>\n<p>https:\/\/api.xxx.com&amp;parameters....  <\/p>\n<p>Thanks for any help!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer: Could not find member 'intellectualPropertyPublisher'",
        "Question_created_time":1629829259160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/526276\/azure-ml-designer-could-not-find-member-intellectu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>From today (Aug 24th, 2021) I'm receiving the following error message when submit any operation in Azure Machine Learning Designer with a dataset:  <\/p>\n<p><strong>Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'<\/strong>  <\/p>\n<p>Complete error message:  <\/p>\n<p><strong>UserError: Job submission to AzureML Compute encountered an Exception with status code , Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'. Path 'properties.intellectualPropertyPublisher', line 309, position 36.<\/strong>  <\/p>\n<p>I'm seeing there's new items in user interface, maybe could be an updating error? Someone is receiving something that? There's something I can do?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Availibility of VM-Type NC6_Promo for region southeastasia not possible with terraform scripting",
        "Question_created_time":1629529670457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/522855\/availibility-of-vm-type-nc6-promo-for-region-south",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I got this error &quot;STANDARD_NC6_PROMO is not supported in region southeastasia. Please choose a different VM size&quot;. Please advise?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\u201cFailure Exception: OSError: [Errno 30] Read-only file system\u201d when using AzureML in Python Azure Function",
        "Question_created_time":1597403151470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/67126\/failure-exception-oserror-(errno-30)-read-only-fil",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p><strong>Issue<\/strong>  <br \/>\nI am trying prepare and then submit a new experiment to Azure Machine Learning from an Azure Function in Python. I therefore register a new dataset for my Azure ML workspace, which contains the training data for my ML model using <code>dataset.register(...<\/code>. However, when I try to create this dataset with the following line of code  <\/p>\n<pre><code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n<\/code><\/pre>\n<p>then I get a <code>Failure Exception: OSError: [Errno 30] Read-only file system ...<\/code>.  <\/p>\n<p><strong>Ideas<\/strong>  <\/p>\n<ol>\n<li> I know that I shouldn't write to the file system from within an Azure function if possible. But I actually don't want to write anything to the local file system. I only want to create the dataset as a reference to my blob storage under <code>datastore_path<\/code> and then register this to my Azure Machine Learning workspace. But it seems that the method <code>from_delimited_files<\/code> is trying to write to the file system anyway (maybe some caching?).  <\/li>\n<li> I also know that there is a temp folder in which writing temporary files is permitted. However, I belive I cannot really control where this method is writing data. I already tried changing the current working directory to this temp folder just before the function call using <code>os.chdir(tempfile.gettempdir())<\/code>, but that didn't help.  <\/li>\n<\/ol>\n<p>Any other ideas? I don't think I am doing something particularly unusually...  <\/p>\n<p><strong>Details<\/strong>  <br \/>\nI am using python 3.7 and azureml-sdk 1.9.0 and I can run the python script locally without problems. I currently deploy from VSCode using the Azure Functions extension version 0.23.0 (and an Azure DevOps pipeline for CI\/CD).  <\/p>\n<p>Here is my full stack trace:  <\/p>\n<pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Functions.HttpTrigger_Train\n ---&gt; Microsoft.Azure.WebJobs.Script.Workers.Rpc.RpcException: Result: Failure\nException: OSError: [Errno 30] Read-only file system: '\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/bin\/deps.lock'\nStack:   File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 345, in _handle__invocation_request\n    self.__run_sync_func, invocation_id, fi.func, args)\n  File &quot;\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 480, in __run_sync_func\n    return func(**params)\n  File &quot;\/home\/site\/wwwroot\/HttpTrigger_Train\/__init__.py&quot;, line 11, in main\n    train()\n  File &quot;\/home\/site\/wwwroot\/shared_code\/train.py&quot;, line 70, in train\n    dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py&quot;, line 126, in wrapper\n    return func(*args, **kwargs)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/dataset_factory.py&quot;, line 308, in from_delimited_files\n    quoting=support_multi_line)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/readers.py&quot;, line 100, in read_csv\n    df = Dataflow._path_to_get_files_block(path, archive_options)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 2387, in _path_to_get_files_block\n    return datastore_to_dataflow(path)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 41, in datastore_to_dataflow\n    datastore, datastore_value = get_datastore_value(source)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 83, in get_datastore_value\n    _set_auth_type(workspace)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 134, in _set_auth_type\n    get_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.SERVICEPRINCIPAL, json.dumps(auth)))\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 18, in get_engine_api\n    _engine_api = EngineAPI()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 55, in __init__\n    self._message_channel = launch_engine()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 300, in launch_engine\n    dependencies_path = runtime.ensure_dependencies()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 141, in ensure_dependencies\n    with _FileLock(deps_lock_path, raise_on_timeout=timeout_exception):\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 113, in __enter__\n    self.acquire()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 72, in acquire\n    self.lockfile = os.open(self.lockfile_path, os.O_CREAT | os.O_EXCL | os.O_RDWR)\n\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker.InvokeCore(Object[] parameters, FunctionInvocationContext context) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/Workers\/WorkerFunctionInvoker.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase.Invoke(Object[] parameters) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionInvokerBase.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator.Coerce[T](Task`1 src) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionGenerator.cs:line 225\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2.InvokeAsync(Object instance, Object[] arguments) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:line 52\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.InvokeAsync(IFunctionInvoker invoker, ParameterHelper parameterHelper, CancellationTokenSource timeoutTokenSource, CancellationTokenSource functionCancellationTokenSource, Boolean throwOnTimeout, TimeSpan timerInterval, IFunctionInstance instance) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 587\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithWatchersAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 532\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, IFunctionOutputDefinition outputDefinition, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 470\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 278\n   --- End of inner exception stack trace ---\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 325\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.TryExecuteAsyncCore(IFunctionInstanceEx functionInstance, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 117\n<\/code><\/pre>",
        "Question_closed_time":1597616477787,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The issue was an incompatible OS version in my virtual environment.    <\/p>\n<p>A huge thanks goes to <a href=\"https:\/\/learn.microsoft.com\/answers\/users\/111253\/pramodvalavala-msft.html\">PramodValavala-MSFT<\/a> for his idea to create a docker container! Following his suggestion, I suddenly got the following error message for the  <code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)<\/code> command:    <\/p>\n<blockquote>\n<p>Exception: NotImplementedError: Unsupported Linux distribution debian 10.    <\/p>\n<\/blockquote>\n<p>which reminded me of the following warning in the azure machine learning documentation:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/17829-image.png?platform=QnA\" alt=\"17829-image.png\" \/>    <\/p>\n<p>Choosing the predefined docker image <code>2.0-python3.7<\/code> (running Debian 9) instead of  <code>3.0-python3.7<\/code> (running Debian 10) solved the issue (see <a href=\"https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python\">https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python<\/a>).    <\/p>\n<p>I suspect that the default virtual environment, which I was using originally, also ran on an incompatible OS.    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"I have a experiment stuck in qued status",
        "Question_created_time":1629427429697,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/521369\/i-have-a-experiment-stuck-in-qued-status",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have a time series experiment which is indefinitely stuck on queued status. It was successfully running before . But I added a new module for installing a new R library from repository and following that everything is queued.  <br \/>\nI created a new copy of the experiment and deleted the old one but still it seems to be running. Please help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Disable Scheduled pipeline endpoint",
        "Question_created_time":1618457299767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/358052\/disable-scheduled-pipeline-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi there,  <\/p>\n<p>I am following the microsoft learn tutorials, and one of them had us publish a pipeline with a schedule.   <\/p>\n<blockquote>\n<p>recurrence = ScheduleRecurrence(frequency=&quot;Week&quot;, interval=1, week_days=[&quot;Monday&quot;], time_of_day=&quot;00:00&quot;)  <br \/>\nweekly_schedule = Schedule.create(ws, name=&quot;weekly-diabetes-training&quot;,   <br \/>\n                                 description=&quot;Based on time&quot;,  <br \/>\n                                pipeline_id=published_pipeline.id,   <br \/>\n                                 experiment_name='mslearn-diabetes-pipeline',   <br \/>\n                                recurrence=recurrence)  <\/p>\n<\/blockquote>\n<p>Now I'd like to delete that pipeline, but when I try to delete it in the Pipelines &gt; Pipeline Endpoints section, I get an error saying that a pipeline with a schedule cannot be disabled.  <\/p>\n<p>There is no code provided to remove or delete the schedule. Can anyone provide the python code necessary to remove the schedule from the pipeline so I can delete it?  <\/p>\n<p>Thank you kindly,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Input data sample training clarifications",
        "Question_created_time":1629368813483,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/520325\/input-data-sample-training-clarifications",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Dear users and experts,  <br \/>\nI am not clear about how is used the input data sample.  <br \/>\nI have a csv file with 5 fields and 20k lines entries.  <br \/>\nWhen I run a classification training, does the 20k entries used ? Or the algorithm split this data sample randomly?  <\/p>\n<p>My final goal is to ensure that I am training on the desired examples I am providing, in order to make my training better when I find some new examples on which the algortihm is doing wrong.  <\/p>\n<p>Best regards.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azuremlsdk for R hangs on update while solving environment",
        "Question_created_time":1624849818327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/453836\/azuremlsdk-for-r-hangs-on-update-while-solving-env",
        "Question_score_count":2,
        "Question_answer_count":4,
        "Question_comment_count":6,
        "Question_body":"<p>I haven't used azuremlsdk for R in a few weeks. When I tried to use it today it said it had to update, the update seems to get stuck on step 17.  <\/p>\n<p>This is the last message before it timeouts in 1h 30m.  <\/p>\n<p>Step 17\/23 : RUN conda install -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -c r -y r-essentials=3.6.0 rpy2 r-checkpoint &amp;&amp; pip install --no-cache-dir azureml-defaults ---&gt; Running in 30337f6502b4 Solving environment: ...working...  <\/p>\n<p>I have tried updating miniconda from the anaconda prompt and I've tried deleting my azureml resource and creating a new one. Any ideas what is going on?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"i cannot make labeling project enabled",
        "Question_created_time":1629489536580,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/522604\/i-cannot-make-labeling-project-enabled",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have a labeling project.  <br \/>\nIt is now stopped.  <br \/>\nWhen I click &quot;Resume&quot;, something happens on for several hours, then a message that an error &quot;Failed&quot; has occurred and that's it.  <br \/>\nthe project remains unavailable.  <br \/>\nNo changes have been made to it since the stop.  <\/p>\n<p>What is the reason for the error? Can I get around it somehow? or somehow copy this project so as not to lose the markup that has already been done in it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Session expired error",
        "Question_created_time":1628612239597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/508381\/session-expired-error",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello everyone, I know this might be seen frequently, but most of the common answers have been unable to help me fix what I'm experiencing.  <br \/>\nI had been working with azure machine learning studio perfectly, until monday.  <br \/>\nI tried entering the portal and was greeted with the your session has expired error.  <br \/>\nI read a bit in the web, erased the cache, logged out, restarted the machine, even incognito mode. None of that worked (Chrome).  <br \/>\nSo I went to my fallback explorer. Edge, and it worked! I could work yesterday with edge, no issues.  <br \/>\nToday, I woke up and discovered the error. I decided to check in another brower (Firefox) and Internet Explorer. The error manifested in all of them now.  <br \/>\nAfter that, I saw that a few had the error popup when the timezone in the office settings was set up incorrectly, but this wasn't my case.  <br \/>\nAs added information, when I checked the console, the error that popped was a 401 Unauthorized error.  <\/p>\n<p>Thank you for your attention, and I really hope someone can help!  <\/p>\n<p>P.D. It seems to be an intermittent issue, I am not sure what triggers it. But as of today I'm able to access roughly 3\/5 of the time without issue. As I am relaying in this for several projects, this has impeded my advance of them. Thank you all regardless.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I cannot see the progress of my modules run on Azure ML. Its stuck at the first module",
        "Question_created_time":1629204002400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/517242\/i-cannot-see-the-progress-of-my-modules-run-on-azu",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p> When I run my ML on Azure ML Designer. I am unable to see the progress of the modules. The program runs at the back end however the designer interface seems to be stuck at the first module of Designer. If an error happens in any module, i dont get to know as I still see it stuck at the first module. I am using ML compute in US East  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - Uses invalid Pytorch version when training",
        "Question_created_time":1629119160593,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/515579\/azure-machine-learning-uses-invalid-pytorch-versio",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am training my models via Azure Machine Learning.<\/p>\n<p>On other day, my training is running with GPU support, however today I found my training is running on a CPU.  <br \/>\nI'm not modified training environment, only training script was modified.  <br \/>\nMy computing cluster is NC6v3 - have a GPU.<\/p>\n<p>I investigate a situation, and I found training script is running on PyTorch 1.6.0.  <br \/>\nOn other day, it ran on Pytorch 1.8.1.  <br \/>\nI think my &quot;don't use GPU&quot; problem is caused by the situation that CUDA toolkit version is not suitable for Pytorch version.<\/p>\n<p>Then, I output a installed package to the log.  <br \/>\nThe log says 'Pytorch 1.8.1 was installed, however uses 1.6.0'.  <br \/>\nI confused by this weird circumstances.  <br \/>\nCan someone tell me the solution?<\/p>\n<p>&lt;My code snippet&gt;  <br \/>\n&lt;&lt;conda_dependencies.yaml&gt;&gt;<\/p>\n<p>channels:  <\/p>\n<ul>\n<li> conda-forge  <\/li>\n<li> pytorch  <\/li>\n<li> nvidia  <br \/>\ndependencies:  <\/li>\n<li> python=3.8.10  <\/li>\n<li> mesa-libgl-cos6-x86_64  <\/li>\n<li> cudatoolkit=11.1  <\/li>\n<li> pytorch==1.8.1  <\/li>\n<li> torchvision==0.9.1  <\/li>\n<li> tqdm  <\/li>\n<li> scikit-learn  <\/li>\n<li> matplotlib  <\/li>\n<li> pandas  <\/li>\n<li> pip &lt; 20.3  <\/li>\n<li> pip:  <\/li>\n<li> azureml-defaults  <\/li>\n<li> opencv-python-headless  <\/li>\n<li> pillow==8.2.0<\/li>\n<\/ul>\n<p>&lt;&lt;Environment definition&gt;&gt;  <br \/>\nenvironment_definition_file = experiment_dir \/ 'conda_dependencies.yaml'  <br \/>\nenvironment_name = 'pytorch-1.8.1-gpu'  <br \/>\nbase_image_name = 'mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04'  <br \/>\nenvironment = Environment.from_docker_image(environment_name, base_image_name, conda_specification = environment_definition_file)  <br \/>\ndocker_run_config = DockerConfiguration(use_docker=True)<\/p>\n<p>script_run_config = ScriptRunConfig(  <br \/>\nsource_directory = experiment_dir,  <br \/>\nscript = SCRIPT_FILE_NAME,  <br \/>\narguments = arguments,  <br \/>\ncompute_target = compute_target,  <br \/>\ndocker_runtime_config = docker_run_config,  <br \/>\nenvironment = environment)<\/p>\n<p>&lt;&lt;Output a log in the training script&gt;&gt;  <br \/>\nimport torch  <br \/>\nimport pip<\/p>\n<p>pip.main(['list'])  <br \/>\nprint(f'PyTorch version: {torch.<strong>version<\/strong>}')<\/p>\n<p>&lt;My logs&gt;  <br \/>\nPackage Version<\/p>\n<hr \/>\n<p>adal 1.2.7  <br \/>\napplicationinsights 0.11.10  <br \/>\n(omission)  <br \/>\ntorch 1.8.1  <br \/>\ntorchvision 0.9.0a0  <br \/>\n(omission)<\/p>\n<p>PyTorch version: 1.6.0<\/p>",
        "Question_closed_time":1629156299363,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for reaching out. These are the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.dnn.pytorch?view=azure-ml-py\">supported versions<\/a> for PyTorch. Please refer to this document for creating a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-pytorch#create-a-custom-environment\">custom environment<\/a>. As shown, you'll need to use versions &lt;= 1.6.0. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"mapInputPort error",
        "Question_created_time":1628930290343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/513716\/mapinputport-error",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>unable to execute maml.mapInputPort(1) on microsoft azure machine learning studio. please help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"'NoneType' error on trained models (unresolvable error)",
        "Question_created_time":1629137715607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/515918\/nonetype-error-on-trained-models-(unresolvable-err",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, have been struggling with this error for a while now. So the training of the model is fine, working well. However, after training when I try to retrieved the train model from the workspace and make a prediction, sometimes it give me this error. It seems to be related to space remaining on the machine? I am guessing the old models are being over-written and they are gone. But the metrics such as their accuracy or log loss is still showing on the monitoring tab. There are no stackoverflow answers related to this error, can I get any help?<\/p>\n<p>This is the code used to retrieved the saved models.  <br \/>\n<strong>CURRENT_RUN = Experiment(ws, experiment_name).workspace.get_run(RUNID)  <br \/>\nbest_run, best_model = CURRENT_RUN.get_output()<\/strong><\/p>\n<p>Message: object of type 'NoneType' has no len()  <br \/>\nInnerException: TypeError: object of type 'NoneType' has no len()  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;SystemError&quot;,  <br \/>\n&quot;message&quot;: &quot;Encountered an internal AutoML error. Error Message\/Code: PredictionException. Additional Info: PredictionException:\\n\\tMessage: object of type 'NoneType' has no len()\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n \\&quot;error\\&quot;: {\\n \\&quot;message\\&quot;: \\&quot;object of type 'NoneType' has no len()\\&quot;,\\n \\&quot;target\\&quot;: \\&quot;CalibratedModel\\&quot;,\\n \\&quot;reference_code\\&quot;: \\&quot;CalibratedModel\\&quot;\\n }\\n}&quot;,  <br \/>\n&quot;details_uri&quot;: &quot;https:\/\/aka.ms\/automltroubleshoot&quot;,  <br \/>\n&quot;target&quot;: &quot;CalibratedModel&quot;,  <br \/>\n&quot;inner_error&quot;: {  <br \/>\n&quot;code&quot;: &quot;ClientError&quot;,  <br \/>\n&quot;inner_error&quot;: {  <br \/>\n&quot;code&quot;: &quot;AutoMLInternal&quot;  <br \/>\n}  <br \/>\n},  <br \/>\n&quot;reference_code&quot;: &quot;CalibratedModel&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I build the environment in the computing cluster using pip?",
        "Question_created_time":1628609652357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/508278\/can-i-build-the-environment-in-the-computing-clust",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to train AI model, and in the VM instance executing the command below worked well<\/p>\n<pre><code>pip install -r requirement.txt\npython ~\n<\/code><\/pre>\n<p>Then in order to train the Ai model in the same environment in the VM computing cluster, in the Python 3.8 - AzureML notebook I executed below (I'm sorry I couldn't attach the screenshot)<\/p>\n<pre><code>import azureml.core\nfrom azureml.core import Workspace\nimport os\nfrom azureml.core import ScriptRunConfig\nfrom azureml.core import Datastore\nfrom azureml.core import Experiment\nfrom azureml.core import Dataset\nfrom azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\nfrom azureml.core import Environment\nimport datetime\n\ncluster_name = 'high-2x-v100-1'\ngpu_name = 'Standard_NC12s_v3'\nexperiment_name = 'training_agent_print'\nhyperparameters = [\n    '--max_train_time', '172800'\n]\nscript_folder = '.\/script_folder'\n\n# workspace\nws = Workspace.from_config()\nprint(ws.name, ws.location, ws.resource_group, sep='\\t')\n\n# compute cluster\ncompute_name = os.environ.get(&quot;AML_COMPUTE_CLUSTER_NAME&quot;, cluster_name)\ncompute_min_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MIN_NODES&quot;, 0)\ncompute_max_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MAX_NODES&quot;, 4)\nvm_size = os.environ.get(&quot;AML_COMPUTE_CLUSTER_SKU&quot;, gpu_name)\n\nif compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[compute_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('found compute target. just use it. ' + compute_name)\nelse:\n    print('creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                min_nodes=compute_min_nodes,\n                                                                max_nodes=compute_max_nodes)\n    compute_target = ComputeTarget.create(\n        ws, compute_name, provisioning_config)\n\n# environment\nenv = Environment.from_pip_requirements(name = &quot;m8-pip-training&quot;, file_path = &quot;.\/requirements.txt&quot;)\nexp = Experiment(workspace=ws,name=experiment_name)\n\n# run\nsrc = ScriptRunConfig(source_directory=script_folder,\n    script='main.py',\n    arguments=hyperparameters,\n    compute_target=compute_target,\n    environment=env\n)\nrun = exp.submit(config=src)\n<\/code><\/pre>\n<p>as a result, in the 20_image_build_log.txt file, I got the log as below<\/p>\n<pre><code>==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 4.9.2\n  latest version: 4.10.3\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\nPip subprocess error:\nERROR: Could not find a version that satisfies the requirement parlai==1.3.0 (from -r \/azureml-environment-setup\/condaenv.5svatkzc.requirements.txt (line 55)) (from versions: 0.1.20200409, 0.1.20200416, 0.1.20200610, 0.1.20200713, 0.1.20200716, 0.8.0, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4)\nERROR: No matching distribution found for parlai==1.3.0 (from -r \/azureml-environment-setup\/condaenv.5svatkzc.requirements.txt (line 55))\n\n\nCondaEnvException: Pip failed\n\n [0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_ba289e67ead35c3dbaac125150111737 -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} + &amp;&amp; ldconfig' returned a non-zero code: 1\n2021\/08\/10 15:13:41 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 1\n\nRun ID: caj failed after 2m24s. Error: failed during run, err: exit status 1\n<\/code><\/pre>\n<p>Ans the experiment failed. I have 3 questions  <\/p>\n<ol>\n<li> Why computing cluster is using conda to build image even though I export the file from pip?  <\/li>\n<li> Can I build the environment using pip?  <\/li>\n<li> As there is WARNING, if I can update the conda to latest version, the experiment might not faile. Can I update the conda in the computing cluster?<\/li>\n<\/ol>\n<p>Thank you so much<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Execure R scripting and R Desktop output varies",
        "Question_created_time":1626086340790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/472103\/execure-r-scripting-and-r-desktop-output-varies",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,  <br \/>\nExecuting a model with Execute R Script in Azure ML produces a different result compared to  R desktop (R 4.1.0)  <br \/>\nHere are step I followed  <br \/>\na. With Azure ML studio ,Imported the 2 data sets Testb.csv and Testc,csv   <br \/>\nand  using the 2 datasets , executed the R script ( see AzureMLR.txt)  <br \/>\nand executed the almost same script in R Desktop ( except i had to read from csv files instead from the ports) ( see RDesktopcode.txt)  <\/p>\n<p>I see a big difference in output produced by both  <br \/>\nRefer this snapshot where one on left is from AzureML and right is R Desktop  <\/p>\n<p>You may to rename testb.txt and textc.txt as csv files to use them . I could not upload csv files so changed to txt files  <\/p>\n<p>THanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't connect Azure Machine Learning to hierarchical namespace storage account",
        "Question_created_time":1628837885567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/512512\/cant-connect-azure-machine-learning-to-hierarchica",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When trying to connect Azure ML to a Storage account on ARM, I get this error:  <\/p>\n<pre><code>{\n  &quot;code&quot;: &quot;DeploymentFailed&quot;,\n  &quot;message&quot;: &quot;At least one resource deployment operation failed. Please list deployment operations for details. Please see https:\/\/aka.ms\/DeployOperations for usage details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;BadRequest&quot;,\n      &quot;message&quot;: &quot;Cannot use storage with HNS enabled.&quot;\n    }\n  ]\n}\n    \n<\/code><\/pre>\n<p>But when reading the documentation, it seems like ADLS Gen2 (which requires HNS) should be supported. How do I get this fixed?  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pulling ML Models from MLFLow in a VM in Azure to the VM that Pipeline Runs",
        "Question_created_time":1629093489833,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/514806\/pulling-ml-models-from-mlflow-in-a-vm-in-azure-to",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have a pipeline in a repo in Azure Devops for evaluating ML model performances after each commit. Currently models are manually put into repo. We also have a MLFlow server in a VM in Azure, so instead of putting models manually into the repo we want to pull models from MLFlow which also resides in a Azure VM into the VM that pipeline runs. Is there a way to accomplish this by using service connections or something?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Real-time enpoint and AutoML models",
        "Question_created_time":1629033615787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/514207\/real-time-enpoint-and-automl-models",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>Hi Azure community,     <\/p>\n<p>I am experiencing a probem with Real-time endopoint when trying to deploy models trained using AutoML.     <\/p>\n<p>Since deploying AutoML models directly from the portal has some problems due to recent changes in azureml-defaults==1.33.0 (see here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/511349\/auto-model-deployment-in-container-instance-no-mod.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/511349\/auto-model-deployment-in-container-instance-no-mod.html<\/a>), I found a work around and managed to deploy AutoML models to real-time-endpoint using the script in attachment (<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123179-automl-endpoint-deploy-workaround.txt?platform=QnA\">123179-automl-endpoint-deploy-workaround.txt<\/a>).    <\/p>\n<p>All it does is to create a conda environment from a yml file (<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/123353-conda-env-v-1-0-0.txt?platform=QnA\">123353-conda-env-v-1-0-0.txt<\/a>) to solve the issues introduced with azureml-defaults==1.33.0 and use the same entry scripts that are available after AutoML training.    <br \/>\n<strong>This works in most cases but for ExtremeRandomTrees models.<\/strong>  In these cases I get the following error message:    <\/p>\n<p><em>Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.<\/em>    <\/p>\n<p>Do you have any idea what the is problem here? Is there any particular package I should add to the conda enviroment?     <br \/>\nI cannot find anything similar on the web, so I decided to ask here.    <\/p>\n<p>Also, these real-time-endopoints got stuck in <strong>transitioning<\/strong> state and I cannot simply remove them from the Portal. How could I remove them instead?    <\/p>\n<p>Any idea and help would be very much appreciated thanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cuda not compatible with PyTorch installation error while training the model with 8xA100",
        "Question_created_time":1629092753013,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/514710\/cuda-not-compatible-with-pytorch-installation-erro",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I tried to train the model with A100 computing cluster  <br \/>\nI implemented the totally same command I used for V100 computing cluster, but it doesn't work and I got the error like below<\/p>\n<pre><code>\/azureml-envs\/azureml_9f42dddb00266f3582208ef8cdab4701\/lib\/python3.7\/site-packages\/torch\/cuda\/__init__.py:104: UserWarning:   \nA100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.  \nThe current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.  \nIf you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https:\/\/pytorch.org\/get-started\/locally\/  \n<\/code><\/pre>\n<p>so I visited <a href=\"https:\/\/pytorch.org\/get-started\/locally\/\">https:\/\/pytorch.org\/get-started\/locally\/<\/a> and followed to implement <code>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch<\/code> but it doesn't work. Neither did <code>conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia<\/code><\/p>\n<p>warnings.warn(incompatible_device_warn.format(device_name, capability, &quot; &quot;.join(arch_list), device_name))<\/p>\n<p>so I visited <a href=\"https:\/\/pytorch.org\/get-started\/locally\/\">https:\/\/pytorch.org\/get-started\/locally\/<\/a> and followed to implement <code>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch<\/code> but it doesn't work. Neither did <code>conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia<\/code><\/p>\n<p>How can I solve this problem?<\/p>\n<p>Thank you so much<\/p>\n<p>Add:  <br \/>\nIn the conda environment below,<\/p>\n<blockquote>\n<p>channels:  <\/p>\n<ul>\n<li> anaconda  <\/li>\n<li> defaults  <br \/>\ndependencies:  <\/li>\n<li> argon2-cffi=20.1.0=py37h27cfd23_1  <\/li>\n<li> async_generator=1.10=py37h28b3542_0  <\/li>\n<li> attrs=20.2.0=py_0  <\/li>\n<li> backcall=0.2.0=pyhd3eb1b0_0  <\/li>\n<li> blas=1.0=mkl  <\/li>\n<li> bleach=3.3.1=pyhd3eb1b0_0  <\/li>\n<li> ca-certificates=2021.7.5=h06a4308_1  <\/li>\n<li> certifi=2021.5.30=py37h06a4308_0  <\/li>\n<li> cffi=1.14.6=py37h400218f_0  <\/li>\n<li> cycler=0.10.0=py37_0  <\/li>\n<li> dbus=1.13.18=hb2f20db_0  <\/li>\n<li> defusedxml=0.7.1=pyhd3eb1b0_0  <\/li>\n<li> entrypoints=0.3=py37_0  <\/li>\n<li> expat=2.3.0=h2531618_2  <\/li>\n<li> fontconfig=2.13.1=h6c09931_0  <\/li>\n<li> freetype=2.10.4=h5ab3b9f_0  <\/li>\n<li> glib=2.68.1=h36276a3_0  <\/li>\n<li> gst-plugins-base=1.14.0=h8213a91_2  <\/li>\n<li> gstreamer=1.14.0=h28cd5cc_2  <\/li>\n<li> icu=58.2=he6710b0_3  <\/li>\n<li> importlib_metadata=3.10.0=hd3eb1b0_0  <\/li>\n<li> intel-openmp=2021.2.0=h06a4308_610  <\/li>\n<li> ipykernel=5.3.4=py37h5ca1d4c_0  <\/li>\n<li> ipython_genutils=0.2.0=pyhd3eb1b0_1  <\/li>\n<li> jpeg=9b=h024ee3a_2  <\/li>\n<li> jsonschema=3.2.0=py_2  <\/li>\n<li> jupyter_client=6.1.12=pyhd3eb1b0_0  <\/li>\n<li> jupyter_core=4.7.1=py37h06a4308_0  <\/li>\n<li> jupyterlab_pygments=0.1.2=py_0  <\/li>\n<li> kiwisolver=1.3.1=py37h2531618_0  <\/li>\n<li> lcms2=2.12=h3be6417_0  <\/li>\n<li> ld_impl_linux-64=2.33.1=h53a641e_7  <\/li>\n<li> libedit=3.1.20191231=h14c3975_1  <\/li>\n<li> libffi=3.3=he6710b0_2  <\/li>\n<li> libgcc-ng=9.1.0=hdf63c60_0  <\/li>\n<li> libpng=1.6.37=hbc83047_0  <\/li>\n<li> libsodium=1.0.18=h7b6447c_0  <\/li>\n<li> libstdcxx-ng=9.1.0=hdf63c60_0  <\/li>\n<li> libtiff=4.1.0=h2733197_1  <\/li>\n<li> libuuid=1.0.3=h1bed415_2  <\/li>\n<li> libxcb=1.14=h7b6447c_0  <\/li>\n<li> libxml2=2.9.10=hb55368b_3  <\/li>\n<li> lz4-c=1.9.3=h2531618_0  <\/li>\n<li> markupsafe=1.1.1=py37h14c3975_1  <\/li>\n<li> matplotlib=3.3.4=py37h06a4308_0  <\/li>\n<li> matplotlib-base=3.3.4=py37h62a2d02_0  <\/li>\n<li> mistune=0.8.4=py37h14c3975_1001  <\/li>\n<li> mkl=2021.2.0=h06a4308_296  <\/li>\n<li> mkl-service=2.3.0=py37h27cfd23_1  <\/li>\n<li> mkl_fft=1.3.0=py37h42c9631_2  <\/li>\n<li> mkl_random=1.2.1=py37ha9443f7_2  <\/li>\n<li> nbclient=0.5.3=pyhd3eb1b0_0  <\/li>\n<li> nbconvert=6.1.0=py37h06a4308_0  <\/li>\n<li> nbformat=5.1.3=pyhd3eb1b0_0  <\/li>\n<li> ncurses=6.2=he6710b0_1  <\/li>\n<li> nest-asyncio=1.5.1=pyhd3eb1b0_0  <\/li>\n<li> notebook=6.4.0=py37h06a4308_0  <\/li>\n<li> olefile=0.46=py37_0  <\/li>\n<li> openjpeg=2.3.0=h05c96fa_1  <\/li>\n<li> openssl=1.1.1k=h27cfd23_0  <\/li>\n<li> pandocfilters=1.4.3=py37h06a4308_1  <\/li>\n<li> parso=0.8.2=pyhd3eb1b0_0  <\/li>\n<li> pcre=8.44=he6710b0_0  <\/li>\n<li> pickleshare=0.7.5=pyhd3eb1b0_1003  <\/li>\n<li> pip=20.2.4=py37_0  <\/li>\n<li> prometheus_client=0.11.0=pyhd3eb1b0_0  <\/li>\n<li> ptyprocess=0.7.0=pyhd3eb1b0_2  <\/li>\n<li> pycparser=2.20=py_2  <\/li>\n<li> pyparsing=2.4.7=pyhd3eb1b0_0  <\/li>\n<li> pyqt=5.9.2=py37h05f1152_2  <\/li>\n<li> pyrsistent=0.17.3=py37h7b6447c_0  <\/li>\n<li> python=3.7.9=h7579374_0  <\/li>\n<li> python-dateutil=2.8.1=pyhd3eb1b0_0  <\/li>\n<li> qt=5.9.7=h5867ecd_1  <\/li>\n<li> readline=8.0=h7b6447c_0  <\/li>\n<li> send2trash=1.5.0=pyhd3eb1b0_1  <\/li>\n<li> setuptools=50.3.0=py37hb0f4dca_1  <\/li>\n<li> sip=4.19.8=py37hf484d3e_0  <\/li>\n<li> six=1.15.0=py37h06a4308_0  <\/li>\n<li> sqlite=3.33.0=h62c20be_0  <\/li>\n<li> terminado=0.9.4=py37h06a4308_0  <\/li>\n<li> testpath=0.5.0=pyhd3eb1b0_0  <\/li>\n<li> tk=8.6.10=hbc83047_0  <\/li>\n<li> tornado=6.0.4=py37h7b6447c_1  <\/li>\n<li> traitlets=5.0.5=pyhd3eb1b0_0  <\/li>\n<li> wcwidth=0.2.5=py_0  <\/li>\n<li> webencodings=0.5.1=py37_1  <\/li>\n<li> wheel=0.35.1=py_0  <\/li>\n<li> xz=5.2.5=h7b6447c_0  <\/li>\n<li> zeromq=4.3.4=h2531618_0  <\/li>\n<li> zlib=1.2.11=h7b6447c_3  <\/li>\n<li> zstd=1.4.9=haebb681_0  <\/li>\n<li> pip:  <\/li>\n<li> absl-py==0.12.0  <\/li>\n<li> adal==1.2.7  <\/li>\n<li> alabaster==0.7.12  <\/li>\n<li> antlr4-python3-runtime==4.8  <\/li>\n<li> azure-common==1.1.27  <\/li>\n<li> azure-core==1.16.0  <\/li>\n<li> azure-graphrbac==0.61.1  <\/li>\n<li> azure-mgmt-authorization==0.61.0  <\/li>\n<li> azure-mgmt-containerregistry==8.0.0  <\/li>\n<li> azure-mgmt-core==1.3.0  <\/li>\n<li> azure-mgmt-keyvault==9.0.0  <\/li>\n<li> azure-mgmt-resource==13.0.0  <\/li>\n<li> azure-mgmt-storage==11.2.0  <\/li>\n<li> azureml-core==1.32.0  <\/li>\n<li> babel==2.9.0  <\/li>\n<li> backports-tempfile==1.0  <\/li>\n<li> backports-weakref==1.0.post1  <\/li>\n<li> boto3==1.9.246  <\/li>\n<li> botocore==1.12.246  <\/li>\n<li> cachetools==4.2.2  <\/li>\n<li> chardet==4.0.0  <\/li>\n<li> coloredlogs==14.0  <\/li>\n<li> contextlib2==0.6.0.post1  <\/li>\n<li> cryptography==3.4.7  <\/li>\n<li> datasets==1.4.1  <\/li>\n<li> decorator==5.0.7  <\/li>\n<li> dill==0.3.3  <\/li>\n<li> docformatter==1.3  <\/li>\n<li> docker==4.4.4  <\/li>\n<li> docutils==0.15.2  <\/li>\n<li> emoji==0.5.4  <\/li>\n<li> filelock==3.0.12  <\/li>\n<li> flake8==3.7.8  <\/li>\n<li> flake8-bugbear==19.8.0  <\/li>\n<li> fsspec==2021.4.0  <\/li>\n<li> fvcore==0.1.1.post20200716  <\/li>\n<li> gitdb2==2.0.5  <\/li>\n<li> gitpython==3.0.3  <\/li>\n<li> google-auth==1.30.0  <\/li>\n<li> google-auth-oauthlib==0.4.4  <\/li>\n<li> grpcio==1.37.0  <\/li>\n<li> huggingface-hub==0.0.2  <\/li>\n<li> humanfriendly==9.1  <\/li>\n<li> hydra-core==1.0.6  <\/li>\n<li> idna==2.10  <\/li>\n<li> imagesize==1.2.0  <\/li>\n<li> importlib-metadata==4.0.1  <\/li>\n<li> importlib-resources==5.1.2  <\/li>\n<li> ipython==7.19.0  <\/li>\n<li> isodate==0.6.0  <\/li>\n<li> jedi==0.18.0  <\/li>\n<li> jeepney==0.7.0  <\/li>\n<li> jinja2==2.11.3  <\/li>\n<li> jmespath==0.10.0  <\/li>\n<li> joblib==0.14.1  <\/li>\n<li> jsonlines==1.2.0  <\/li>\n<li> jsonpickle==2.0.0  <\/li>\n<li> markdown==3.3.4  <\/li>\n<li> markdown-it-py==0.5.8  <\/li>\n<li> mccabe==0.6.1  <\/li>\n<li> more-itertools==8.7.0  <\/li>\n<li> msrest==0.6.21  <\/li>\n<li> msrestazure==0.6.4  <\/li>\n<li> multiprocess==0.70.11.1  <\/li>\n<li> myst-parser==0.12.10  <\/li>\n<li> ndg-httpsclient==0.5.1  <\/li>\n<li> nltk==3.4.5  <\/li>\n<li> numpy==1.17.5  <\/li>\n<li> oauthlib==3.1.0  <\/li>\n<li> omegaconf==2.0.6  <\/li>\n<li> packaging==20.9  <\/li>\n<li> pandas==1.1.1  <\/li>\n<li> pathspec==0.8.1  <\/li>\n<li> pexpect==4.7.0  <\/li>\n<li> pillow==8.1.1  <\/li>\n<li> pluggy==0.13.1  <\/li>\n<li> portalocker==2.3.0  <\/li>\n<li> prompt-toolkit==3.0.18  <\/li>\n<li> protobuf==3.15.8  <\/li>\n<li> py==1.10.0  <\/li>\n<li> py-gfm==1.0.2  <\/li>\n<li> py-rouge==1.1  <\/li>\n<li> pyarrow==4.0.0  <\/li>\n<li> pyasn1==0.4.8  <\/li>\n<li> pyasn1-modules==0.2.8  <\/li>\n<li> pycodestyle==2.5.0  <\/li>\n<li> pyflakes==2.1.1  <\/li>\n<li> pygments==2.8.1  <\/li>\n<li> pyjwt==2.1.0  <\/li>\n<li> pyopenssl==20.0.1  <\/li>\n<li> pytest==5.3.2  <\/li>\n<li> pytest-datadir==1.3.1  <\/li>\n<li> pytest-regressions==2.1.1  <\/li>\n<li> pytz==2021.1  <\/li>\n<li> pyyaml==5.4  <\/li>\n<li> pyzmq==18.1.0  <\/li>\n<li> regex==2020.1.8  <\/li>\n<li> requests==2.25.1  <\/li>\n<li> requests-mock==1.7.0  <\/li>\n<li> requests-oauthlib==1.3.0  <\/li>\n<li> rsa==4.7.2  <\/li>\n<li> ruamel-yaml==0.17.4  <\/li>\n<li> ruamel-yaml-clib==0.2.6  <\/li>\n<li> s3transfer==0.2.1  <\/li>\n<li> scikit-learn==0.23.1  <\/li>\n<li> scipy==1.4.1  <\/li>\n<li> secretstorage==3.3.1  <\/li>\n<li> sh==1.12.14  <\/li>\n<li> smmap==4.0.0  <\/li>\n<li> smmap2==3.0.1  <\/li>\n<li> snowballstemmer==2.1.0  <\/li>\n<li> sphinx==2.2.2  <\/li>\n<li> sphinx-autodoc-typehints==1.10.3  <\/li>\n<li> sphinx-rtd-theme==0.4.3  <\/li>\n<li> sphinxcontrib-applehelp==1.0.2  <\/li>\n<li> sphinxcontrib-devhelp==1.0.2  <\/li>\n<li> sphinxcontrib-htmlhelp==1.0.3  <\/li>\n<li> sphinxcontrib-jsmath==1.0.1  <\/li>\n<li> sphinxcontrib-qthelp==1.0.3  <\/li>\n<li> sphinxcontrib-serializinghtml==1.1.4  <\/li>\n<li> subword-nmt==0.3.7  <\/li>\n<li> tabulate==0.8.9  <\/li>\n<li> tensorboard==2.3.0  <\/li>\n<li> tensorboard-plugin-wit==1.8.0  <\/li>\n<li> tensorboardx==2.1  <\/li>\n<li> termcolor==1.1.0  <\/li>\n<li> threadpoolctl==2.1.0  <\/li>\n<li> tokenizers==0.10.2  <\/li>\n<li> torch==1.8.1  <\/li>\n<li> torchtext==0.9.1  <\/li>\n<li> tqdm==4.36.1  <\/li>\n<li> typing-extensions==3.7.4.1  <\/li>\n<li> unidecode==1.1.1  <\/li>\n<li> untokenize==0.1.1  <\/li>\n<li> urllib3==1.25.11  <\/li>\n<li> websocket-client==0.56.0  <\/li>\n<li> websocket-server==0.4  <\/li>\n<li> werkzeug==1.0.1  <\/li>\n<li> xxhash==2.0.2  <\/li>\n<li> yacs==0.1.8  <\/li>\n<li> zipp==3.4.1<\/li>\n<\/ul>\n<\/blockquote>\n<p>I implemented <code>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch<\/code>, and export to yml file.  <br \/>\nThen in order to create job to computing cliuster I implemented below<\/p>\n<pre><code>#A100ver  \ncluster_name = 'high-A100'  \ngpu_name = 'Standard_ND96asr_v4'  \nexperiment_name = 'speaker_identification_training_A100'  \nhyperparameters = [  \n    '--max_train_time', '172800'  \n]  \nscript_folder = '.\/script_folder'  \n\n# workspace  \nws = Workspace.from_config()  \nprint(ws.name, ws.location, ws.resource_group, sep='\\t')  \n\n# compute cluster  \ncompute_name = os.environ.get(&quot;AML_COMPUTE_CLUSTER_NAME&quot;, cluster_name)  \ncompute_min_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MIN_NODES&quot;, 0)  \ncompute_max_nodes = os.environ.get(&quot;AML_COMPUTE_CLUSTER_MAX_NODES&quot;, 4)  \nvm_size = os.environ.get(&quot;AML_COMPUTE_CLUSTER_SKU&quot;, gpu_name)  \n\nif compute_name in ws.compute_targets:  \n    compute_target = ws.compute_targets[compute_name]  \n    if compute_target and type(compute_target) is AmlCompute:  \n        print('found compute target. just use it. ' + compute_name)  \nelse:  \n    print('creating a new compute target...')  \n    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,  \n                                                                min_nodes=compute_min_nodes,  \n                                                                max_nodes=compute_max_nodes)  \n    compute_target = ComputeTarget.create(  \n        ws, compute_name, provisioning_config)  \n\nenv = Environment.load_from_directory(path=&quot;.\/.azureml6\/&quot;)  \nexp = Experiment(workspace=ws,name=experiment_name)  \ncommand = &quot;pwd &amp;&amp; pip install azure-storage-blob &amp;&amp; python main.py&quot;  \n# run  \nsrc = ScriptRunConfig(source_directory=script_folder,  \n command=command,  \n compute_target=compute_target,  \n environment=env  \n)  \nrun = exp.submit(config=src)  \n<\/code><\/pre>\n<p>Actually I found that in order to use A100, pytoch version should be 1.8.1+cu111. But by implementing <code>conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge<\/code>, I got the error like below<\/p>\n<blockquote>\n<p>Collecting package metadata (current_repodata.json): done  <br \/>\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.  <br \/>\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.  <br \/>\nCollecting package metadata (repodata.json): done  <br \/>\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.  <br \/>\nSolving environment: |  <br \/>\nFound conflicts! Looking for incompatible packages.  <br \/>\nThis can take several minutes. Press CTRL-C to abort.  <br \/>\nfailed<\/p>\n<p>UnsatisfiableError: The following specifications were found  <br \/>\nto be incompatible with the existing python installation in your environment:<\/p>\n<p>Specifications:<\/p>\n<ul>\n<li> pytorch==1.8.1 -&gt; python[version='2.7.<em>|3.5.<\/em>|3.6.<em>|3.6.12|3.6.12|3.7.10|3.7.10|&gt;=2.7,&lt;2.8.0a0|&gt;=3.5,&lt;3.6.0a0|&gt;=3.5|&gt;=3.7|&gt;=3.6,&lt;3.7|3.7.9|3.6.9|3.6.9|3.6.9|3.6.9|3.4.<\/em>',build='1_73_pypy|2_73_pypy|3_73_pypy|4_73_pypy|1_73_pypy|0_73_pypy|5_73_pypy|5_73_pypy|0_73_pypy']<\/li>\n<li> torchaudio==0.8.0 -&gt; python[version='2.7.<em>|3.5.<\/em>|3.6.<em>|&gt;=2.7,&lt;2.8.0a0|&gt;=3.5,&lt;3.6.0a0|3.4.<\/em>|3.9.*']<\/li>\n<\/ul>\n<p>Your python: python==3.7.9=h7579374_0<\/p>\n<p>If python is on the left-most side of the chain, that's the version you've asked for.  <br \/>\nWhen python appears to the right, that indicates that the thing on the left is somehow  <br \/>\nnot available for the python version you are constrained to. Note that conda will not  <br \/>\nchange your python version to a different minor version unless you explicitly specify  <br \/>\nthat.<\/p>\n<p>The following specifications were found to be incompatible with each other:<\/p>\n<p>Output in format: Requested package -&gt; Available versions<\/p>\n<p>Package cudnn conflicts for:  <br \/>\ntorchvision==0.9.0 -&gt; pytorch[version='&gt;=1.8.0',build=cuda*] -&gt; cudnn[version='&gt;=8.2.1.32,&lt;9.0a0']  <br \/>\ntorchvision==0.9.0 -&gt; cudnn[version='&gt;=7.6.5.32,&lt;8.0a0|&gt;=8.1.0.77,&lt;9.0a0']<\/p>\n<p>Package cudatoolkit conflicts for:  <br \/>\ntorchvision==0.9.0 -&gt; cudatoolkit[version='10.2|10.2.<em>|11.0|11.0.<\/em>|11.1|11.1.<em>|&gt;=10.1,&lt;10.2|&gt;=10.2,&lt;10.3|&gt;=11.1,&lt;11.2|11.2|11.2.<\/em>']  <br \/>\ntorchaudio==0.8.0 -&gt; pytorch==1.8.0 -&gt; cudatoolkit[version='10.2|10.2.<em>|11.0|11.0.<\/em>|11.1|11.1.<em>|11.2|11.2.<\/em>|&gt;=10.1,&lt;10.2|&gt;=11.1,&lt;11.2|&gt;=10.2,&lt;10.3']  <br \/>\ntorchvision==0.9.0 -&gt; cudnn[version='&gt;=8.1.0.77,&lt;9.0a0'] -&gt; cudatoolkit[version='10.0|10.0.<em>|10.1|10.1.<\/em>|10.2.<em>|11.<\/em>|&gt;=11.3,&lt;11.4|9.2|9.2.*']  <br \/>\npytorch==1.8.1 -&gt; cudatoolkit[version='&gt;=10.1,&lt;10.2|&gt;=11.1,&lt;11.2|&gt;=10.2,&lt;10.3']<\/p>\n<p>Package libstdcxx-ng conflicts for:  <br \/>\npython==3.7.9=h7579374_0 -&gt; libffi[version='&gt;=3.3,&lt;3.4.0a0'] -&gt; libstdcxx-ng[version='&gt;=7.3.0|&gt;=7.5.0']  <br \/>\ntorchaudio==0.8.0 -&gt; numpy[version='&gt;=1.11'] -&gt; libstdcxx-ng[version='&gt;=4.9|&gt;=7.3.0|&gt;=9.3.0|&gt;=7.5.0|&gt;=7.2.0']  <br \/>\ntorchvision==0.9.0 -&gt; libstdcxx-ng[version='&gt;=7.5.0']  <br \/>\ntorchvision==0.9.0 -&gt; cudatoolkit[version='&gt;=11.1,&lt;11.2'] -&gt; libstdcxx-ng[version='&gt;=3.4|&gt;=4.9|&gt;=7.3.0|&gt;=9.3.0|&gt;=7.2.0']  <br \/>\npytorch==1.8.1 -&gt; cudatoolkit[version='&gt;=11.1,&lt;11.2'] -&gt; libstdcxx-ng[version='&gt;=4.9|&gt;=7.3.0|&gt;=9.3.0|&gt;=7.2.0']  <br \/>\npytorch==1.8.1 -&gt; libstdcxx-ng[version='&gt;=7.5.0']  <br \/>\ncudatoolkit=11.1 -&gt; libstdcxx-ng[version='&gt;=9.3.0']<\/p>\n<p>Package libgcc-ng conflicts for:  <br \/>\npython==3.7.9=h7579374_0 -&gt; libgcc-ng[version='&gt;=7.3.0']  <br \/>\npython==3.7.9=h7579374_0 -&gt; libffi[version='&gt;=3.3,&lt;3.4.0a0'] -&gt; libgcc-ng[version='&gt;=4.9|&gt;=7.5.0|&gt;=9.4.0|&gt;=9.3.0|&gt;=7.2.0']<\/p>\n<p>Package _libgcc_mutex conflicts for:  <br \/>\npython==3.7.9=h7579374_0 -&gt; libgcc-ng[version='&gt;=7.3.0'] -&gt; _libgcc_mutex[version='<em>|0.1|0.1',build='main|main|conda_forge']  <br \/>\ncudatoolkit=11.1 -&gt; libgcc-ng[version='&gt;=9.3.0'] -&gt; _libgcc_mutex[version='<\/em>|0.1',build='main|main|conda_forge']  <br \/>\ntorchvision==0.9.0 -&gt; libgcc-ng[version='&gt;=7.5.0'] -&gt; _libgcc_mutex[version='<em>|0.1|0.1',build='main|main|conda_forge']  <br \/>\npytorch==1.8.1 -&gt; _openmp_mutex -&gt; _libgcc_mutex[version='<\/em>|0.1',build='main|main|conda_forge']<\/p>\n<p>Package pytorch conflicts for:  <br \/>\ntorchvision==0.9.0 -&gt; pytorch[version='1.8.0|&gt;=1.8.0|&gt;=1.8.0',build='cuda*|cpu*']  <br \/>\ntorchaudio==0.8.0 -&gt; pytorch==1.8.0<\/p>\n<p>Package nccl conflicts for:  <br \/>\ntorchvision==0.9.0 -&gt; pytorch==1.8.0 -&gt; nccl[version='&gt;=2.10.3.1,&lt;3.0a0|&gt;=2.7.8.1,&lt;3.0a0|&gt;=2.8.4.1,&lt;3.0a0']  <br \/>\ntorchaudio==0.8.0 -&gt; pytorch==1.8.0 -&gt; nccl[version='&gt;=2.7.8.1,&lt;3.0a0|&gt;=2.8.4.1,&lt;3.0a0']<\/p>\n<p>Package typing-extensions conflicts for:  <br \/>\npytorch==1.8.1 -&gt; typing-extensions  <br \/>\ntorchvision==0.9.0 -&gt; pytorch[version='&gt;=1.8.0',build=cpu*] -&gt; typing-extensionsThe following specifications were found to be incompatible with your system:<\/p>\n<ul>\n<li> feature:\/linux-64::__glibc==2.27=0<\/li>\n<li> feature:|@\/linux-64::__glibc==2.27=0<\/li>\n<li> cudatoolkit=11.1 -&gt; __glibc[version='&gt;=2.17,&lt;3.0.a0']<\/li>\n<li> cudatoolkit=11.1 -&gt; libgcc-ng[version='&gt;=9.3.0'] -&gt; __glibc[version='&gt;=2.17']<\/li>\n<li> pytorch==1.8.1 -&gt; cudatoolkit[version='&gt;=11.1,&lt;11.2'] -&gt; __glibc[version='&gt;=2.17|&gt;=2.17,&lt;3.0.a0']<\/li>\n<li> torchaudio==0.8.0 -&gt; pytorch==1.8.0 -&gt; __glibc[version='&gt;=2.17|&gt;=2.17,&lt;3.0.a0']<\/li>\n<li> torchvision==0.9.0 -&gt; __glibc[version='&gt;=2.17|&gt;=2.17,&lt;3.0.a0']<\/li>\n<\/ul>\n<p>Your installed version is: 2.27<\/p>\n<\/blockquote>\n<p>Can I solve this problem by adjusting the environment? or should I give up using A100?<\/p>\n<p>Thank you so much<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question: how to define custom Module in Designer",
        "Question_created_time":1594757308663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46908\/question-how-to-define-custom-module-in-designer",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>How do I define a custom Module in Azure ML Designer? In Studio (classic), I found this documentation:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/custom-r-modules\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/custom-r-modules<\/a>    <\/p>\n<p>but I have yet to find something similar for the modern version of Azure ML. The closest thing I've found is Execute Python Script, but that has several limitations:    <\/p>\n<ul>\n<li> Unnecessary overhead from casting to a pandas DataFrame and back to the internal data structure    <\/li>\n<li> No ability to add parameters    <\/li>\n<li> Difficult to reuse    <\/li>\n<li> Can't customize number of ports, module name, etc.    <\/li>\n<\/ul>\n<p>Also, is it possible to upstream any custom Modules I write? For example, there are currently no Data Transforms for handling timestamps, which I imagine are common in many datasets. I would love to contribute one upstream so that other users can use it, but I haven't yet found a GitHub repo for it.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to delete Azure ML real-time endpoints which is in transition state",
        "Question_created_time":1628858328673,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/513012\/how-to-delete-azure-ml-real-time-endpoints-which-i",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I have made deployment of the model from the AutoML experiment, due to the issue in the resources associated. Deployment has failed.  <\/p>\n<p>But the real-time endpoint has been in the transition state for few hours,  I can't delete it and the model registered along with it due to this. How can I force delete in this case. Please provide a solution.   <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":1629112596937,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thank you for the response <a href=\"\/users\/na\/?userid=bc467a93-95da-4dea-bc82-06951da4cfad\">@romungi-MSFT  <\/a>. I have left the feedback to the team.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"No Data being exported from 'Export Data' module in Azure ML",
        "Question_created_time":1629008927050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/514067\/no-data-being-exported-from-export-data-module-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am trying to export data from Azure ML to an Azure SQL Database using the 'Export Data' module but the log file contains the following messages and no data is exported to the database.  <\/p>\n<p>&quot;Not exporting to run RunHistory as the exporter is either stopped or there is no data&quot;  <\/p>\n<p>&quot;Process exiting with code: 0  <\/p>\n<p>There is definitely data flowing to the 'Export Data' module from an 'Execute R Script' module as I have checked the Result dataset.  <\/p>\n<p>Would appreciate some assistance.  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":1629106747877,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi,   <\/p>\n<p>I have resolved this issue. I had set the export table to be dbo.TestTable rather than just TestTable. As the table dbo.TestTable did not exist the 'Export module' created it in the dbo schema so the table name effectively became dbo.dbo.TestTable.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Is their limit on number of records in dataset for Azure automated ML timeserires forecasting",
        "Question_created_time":1628484429713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/505948\/is-their-limit-on-number-of-records-in-dataset-for",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi   <\/p>\n<p>I am facing issue with number of records while creating datasets automated ML timeseries forecasting, It is loading only first 10000 records rest of the records are ignored.   <\/p>\n<p>Is their any limit on number of records in the datasets for Azure automated ML timeseries forecasting.   <\/p>\n<p>If there limits in number of records , how to increase number of records   <\/p>\n<p>Thanks   <br \/>\nRamabadran <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not able to consume predict-auto-price endpoint",
        "Question_created_time":1628625065883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/508671\/not-able-to-consume-predict-auto-price-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <br \/>\nI was following <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/\">Create a Regression Model with Azure Machine Learning Designer<\/a>    <\/p>\n<p>I reached to deploy and created an endpoint for the service. But when I click consume, it keeps on loading and after sometime page become unresponsive. What can be the possible reasons for this?    <\/p>",
        "Question_closed_time":1628747611667,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=40fc3747-f845-4da1-922e-d0fc18887e34\">@Kapil Bansal  <\/a> This issue is now fixed. A hotfix was deployed to fix this. Please reload the page and check again.    <\/p>\n<p>Please feel free to accept the same as answer if it helped.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to register Managed SQL Instance as a datastore in Azure Machine Learning workspace?",
        "Question_created_time":1603811671907,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/141428\/how-to-register-managed-sql-instance-as-a-datastor",
        "Question_score_count":2,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to connect a database within the Managed SQL Instance as a datastore. Managed Instance is not among the datastore type options so I tried to select the Azure SQL database and &quot;enter manually&quot; option for account selection. When I enter the full hostname of the managed instance which is something like &quot;xxx-xxxx-xxx-xxxx-sql.45bsa4569.database.windows.net&quot; it complaints due to dot &quot;.&quot; that comes after 'sql'. Since I do not have control over that part of the hostname (Azure adds something like '.45bsa4569' on the managed instance name itself) I do not know how to fix it.   <\/p>\n<p>Questions:   <\/p>\n<ol>\n<li> Is it possible to register a managed instance as a datastore by using the method above? (Azure SQL database and 'enter manually' options).   <\/li>\n<li> If possible, how to handle the '.' in the host name so that it does not complain?   <\/li>\n<\/ol>\n<p>FYI: The managed instance is behind a vnet so I am using service principal to authenticate.   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Terminal of computer instance keeps loading and at the same time VS code cannot connect to it",
        "Question_created_time":1625832970633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/469700\/terminal-of-computer-instance-keeps-loading-and-at",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>It happens quite often, sometimes after I just started the computer instance, and sometimes after I used it for a while. Then I have to restart the computer instance.     <br \/>\nIt happens not only to one but to different computer instances.    <br \/>\nPlease see the screenshots below:    <\/p>\n<ol>\n<li> terminal keeps loading    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113336-screenshot-2021-07-09-140416.png?platform=QnA\" alt=\"113336-screenshot-2021-07-09-140416.png\" \/>    <\/li>\n<li> VS code cannot connect to the computer instance    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113337-screenshot-2021-07-09-140343.png?platform=QnA\" alt=\"113337-screenshot-2021-07-09-140343.png\" \/>    <\/li>\n<\/ol>\n<p>In the end the webpage of Notebooks shows     <br \/>\n&quot;Terminal not available    <br \/>\nCurrent terminal is encountering some issues, please switch compute or restart your current compute and retry.&quot;     <br \/>\nwith some message as below:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113237-grafik.png?platform=QnA\" alt=\"113237-grafik.png\" \/>    <\/p>\n<p>And VS codes just keep trying &quot;Installing VS Code server on &lt;computer instance&gt; Retry - &lt;some number&gt;&quot;    <\/p>\n<p>Could anyone please tell me what the problem is or solve this issue in the background? Thanks a lot!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Move R file from on Premise to Pass Services and connect APIM to R file",
        "Question_created_time":1628744989137,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/510695\/move-r-file-from-on-premise-to-pass-services-and-c",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>Hi All,   <\/p>\n<p>I am having .Net web API which is hosted to Azure IAAS sever now we have have moved API to Azure pass with API Management.  API pass the request to r server and get the details.  How we can migrate r server to pass service and connect with APIM in Azure as we don't want to use any IAAS server.  We have tried with Machine learning studio but not getting any solution.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"cant Connect API Managment request to R file",
        "Question_created_time":1628743828770,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/510811\/cant-connect-api-managment-request-to-r-file",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi team,   <\/p>\n<p>We are having .net web api which is hosted to Azure iaas sever now we have have moved that to Azure pass with apim. Api pass the request to r server and get the details.  <\/p>\n<p>How we can move r files from iaas to pass and connect with APIM in Azure as we don't want to use any iaas server.  <\/p>\n<p>We have tried with Machine learning but not getting any solution.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy azureml model service principal authentication",
        "Question_created_time":1628163912977,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/502812\/deploy-azureml-model-service-principal-authenticat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I would like to implement a way to automate model deployment from an AzureML pipeline. My issue is that I keep having to manually authenticate when deploying a model. The entire pipeline works fine using service principal authentication, except the model deployment part.   <\/p>\n<p>I'm using the following code:  <\/p>\n<pre><code>ws = Workspace(subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name, auth=svc_pr)\n\nmodel = model.deploy(overwrite=True, name=model_name, deployment_target=cpu_cluster, show_output=True, workspace=ws, models=[model], inference_config=inference_config, deployment_config=deployment_config)\n    \n<\/code><\/pre>\n<p>Is it possible to do model deployment from a pipeline without having to do the token authentication in the deployment logs?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automated ML model - endPoint goes for toss",
        "Question_created_time":1628591307843,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/507900\/automated-ml-model-endpoint-goes-for-toss",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi     <\/p>\n<p>I created &quot;Automated ML &quot; model for the given set of data. After creating the model, I deployed model as ACI , while test the model under &quot;Home &gt; endpoint&gt;modelname, I am facing below problem     <\/p>\n<ol>\n<li> Whole page hangs indefinitely , refer to attach snap shot    <\/li>\n<li> Sometime i get he page , input like to forecast time is not editable  refer to snapshot    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/121926-snap3.jpg?platform=QnA\" alt=\"121926-snap3.jpg\" \/>    <\/li>\n<\/ol>\n<p>Thanks in advance for the support      <br \/>\nRamabadran     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"My ACI endpoint in stuck in transitionning for hours, can't delete the model",
        "Question_created_time":1628023814677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/500472\/my-aci-endpoint-in-stuck-in-transitionning-for-hou",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>My endpoint is still in transitionning after hours. No logs are available...I can't delete the model either since it's attached to the endpoint..  <br \/>\nHow can I force the deletion \/ stop the deployment ?   <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML MSI deployment over ARM Templates enables purge protection on Key Vault",
        "Question_created_time":1627468001263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/492841\/azure-ml-msi-deployment-over-arm-templates-enables",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have discovered lately that when you deploy an Azure ML instance from the ARM Template, the MSI will override the purge protection settings of the Key Vault. It will enable purge protection on the Key Vault. This is not the behavior that I am looking for, because when trying to deploy it again, the template will fail saying that the Key Vault with the name already exists and you can't deleted before the retention period. This was my conclusion after doing several tests. Is my assumption correct?  <\/p>\n<p>If you deploy the Azure ML instance manually and select the Key Vault, it will keep the disable purge settings. Any ideas how can we keep purge disabled hier?  <\/p>\n<p>The Azure ML properties that we used are mentioned bellow:  <\/p>\n<pre><code>  {\n    &quot;type&quot;: &quot;Microsoft.MachineLearningServices\/workspaces&quot;,\n    &quot;apiVersion&quot;: &quot;2020-09-01-preview&quot;,\n    &quot;name&quot;: &quot;[variables('machineLearningWorkspaceName')]&quot;,\n    &quot;location&quot;: &quot;[parameters('location')]&quot;,\n    &quot;identity&quot;: {\n      &quot;type&quot;: &quot;[parameters('amlManagedIdentityOption')]&quot;\n    },\n    &quot;dependsOn&quot;: [\n      &quot;[resourceId('Microsoft.Storage\/storageAccounts', variables('storageAccountName'))]&quot;,\n      &quot;[resourceId('Microsoft.Insights\/components', variables('applicationInsightsName'))]&quot;,\n      &quot;[resourceId('Microsoft.ContainerRegistry\/registries', variables('containerRegistryName'))]&quot;\n    ],\n    &quot;tags&quot;: &quot;[parameters('resourceTags')]&quot;,\n    &quot;properties&quot;: {\n      &quot;friendlyName&quot;: &quot;[variables('machineLearningWorkspaceName')]&quot;,\n      &quot;storageAccount&quot;: &quot;[variables('storageAccount')]&quot;,\n      **&quot;keyVault&quot;: &quot;[variables('keyVault')]&quot;,**\n      &quot;applicationInsights&quot;: &quot;[variables('applicationInsights')]&quot;,\n      &quot;containerRegistry&quot;: &quot;[ variables('containerRegistry')]&quot;,\n      &quot;adbWorkspace&quot;: &quot;[variables('adbWorkSpace')]&quot;,\n      &quot;hbiWorkspace&quot;: &quot;[parameters('confidential_data')]&quot;,\n      &quot;allowPublicAccessWhenBehindVnet&quot;: &quot;[parameters('allowPublicAccessWhenBehindVnet')]&quot;\n    }\n  }\n<\/code><\/pre>\n<p>On the Key Vault created also via ARM we have:   <\/p>\n<pre><code>        &quot;properties&quot;: {\n                &quot;enabledForDeployment&quot;: &quot;[parameters('enabledForDeployment')]&quot;,\n                &quot;enabledForTemplateDeployment&quot;: &quot;[parameters('enabledForTemplateDeployment')]&quot;,\n                &quot;enabledForVolumeEncryption&quot;: &quot;[parameters('enableVaultForVolumeEncryption')]&quot;,\n                &quot;softDeleteRetentionInDays&quot;: 7,\n                &quot;tenantId&quot;: &quot;[subscription().tenantId]&quot;,\n                &quot;copy&quot;: [\n                    {\n                        &quot;name&quot;: &quot;accessPolicies&quot;,\n                        &quot;count&quot;: &quot;[length(parameters('userObjectId'))]&quot;,\n                        &quot;input&quot;: {\n                            &quot;tenantId&quot;: &quot;[subscription().tenantId]&quot;,\n                            &quot;objectId&quot;: &quot;[parameters('userObjectId')[copyIndex('accessPolicies')].Id]&quot;,\n                            &quot;permissions&quot;: &quot;[parameters('userObjectId')[copyIndex('accessPolicies')].Permissions]&quot;\n                        }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save trained model from AutoML\/Designer as pickle file to disk - Azure ML",
        "Question_created_time":1617893768667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349669\/save-trained-model-from-automl-designer-as-pickle",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I want to save trained machine learning model as <strong>pickle file(.pkl)<\/strong> to disk which is trained in AutoML\/Designer.   <\/p>\n<p>Please let me know is there any way to do that?  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning data labelling- Is it possible to assign different labelers to label same data in a single project to reach a consensus?",
        "Question_created_time":1625056620740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458004\/azure-machine-learning-data-labelling-is-it-possib",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Currently! I'm experimenting with the azure data labelling tool in the machine learning workspace for image classification, what I found was azure shows only the unlabelled data to each user i.e if a user has already labelled an image, other users won't be shown the same image again.   <br \/>\nIs there any setting that exists, which can be enabled or disabled so that we can let more than one labeller label the same data?   <\/p>",
        "Question_closed_time":1625073229547,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks for reaching to us. This capability is currently in development, and expected to release soon.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How can I access a FileDataset without filling local disk?",
        "Question_created_time":1628529752433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/506820\/how-can-i-access-a-filedataset-without-filling-loc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello!  <\/p>\n<p>I'm setting up a pipeline for machine learning. Reading the docs I understood that when I pass my FileDataset as_mount it is mounted, similar to mounting an external drive. However, three hours into my training, my pipeline crashed, out of storage. It seems that as_mount actually is downloading per file, rather than the entire Dataset, but still uses local disk space. Is this correct? If so, how can I train on a FileDataset that is too large for any of the available compute options?  <\/p>\n<p>David<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to test my ML model created with Azure Automated ML model endpoints",
        "Question_created_time":1628598159740,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/507969\/unable-to-test-my-ml-model-created-with-azure-auto",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi   <\/p>\n<p>I am unable to test the model (Microsoft azure Machine learning -&gt;endpoints-&gt;modelname -&gt;Test , even though some model i could execute on 09-Aug-2021 late evening. Please help to resolve issue   <\/p>\n<p>Thanks   <br \/>\nRamabadran <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrate Azure ML with Azure Data Factory",
        "Question_created_time":1627308102200,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/489630\/integrate-azure-ml-with-azure-data-factory",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hello,    <\/p>\n<p>I have an Azure ML Batch Endpoint that successfully submits. I have made the input dataset a parameter. Now, ideally, I'd want to do the following:    <\/p>\n<ul>\n<li> Execute the Endpoint from Azure Data Factory, while passing in a dynamic dataset that exists on Blob Storage.    <\/li>\n<li> Receive the output dataset and continue consuming the returned dataset with other activities on Azure Data Factory.    <\/li>\n<\/ul>\n<p>So far, I've had no luck or access to clear documentation that can help me achieve this functionality:    <\/p>\n<ul>\n<li> I followed <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/transform-data-machine-learning-service\">this<\/a> tutorial but it seems you can use this Activity on Azure Data Factory only to trigger an experiment on Azure ML and this doesn't mention passing in datasets from Azure Data Factory.    <\/li>\n<li> I set up my batch endpoint using <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-batch-predictions-designer\">this<\/a> tutorial and the only way this mentions the consumption of an endpoint is either manually through Azure ML or through the REST Api.     <\/li>\n<\/ul>\n<p>Overall, I'd like to know the feasibility of my desired solution. The worst case seems that I'd have to write a Python script that can create datasets on Azure ML, then trigger the batch endpoint pipeline (using the REST Api), and then re-upload the model output on a desired location in Blob Storage, and run this Python script on a Execute Batch Activity.     <\/p>\n<p>Additionally, I was wondering if it's possible to get sample code for the REST API code for consuming the batch endpoint like I did for a real-time endpoint.     <\/p>\n<p>Thanks,    <br \/>\nVarun.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to solve the \"Stopping site because it is not healthy\" when deploying ml model into an Azure Function?",
        "Question_created_time":1616116277480,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/321539\/how-to-solve-the-stopping-site-because-it-is-not-h",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p><strong>Hello there!<\/strong>     <br \/>\nWhile trying to complete following tutorial I faced following issue:     <br \/>\n&quot;Stopping site mymlfunction because it is not healthy.&quot;     <\/p>\n<p>Below the complete log lines I see:     <\/p>\n<p>&quot;     <br \/>\n2021-03-18T23:25:12.553Z INFO - Logging is not enabled for this container. Please use <a href=\"https:\/\/aka.ms\/linux-diagnostics\">https:\/\/aka.ms\/linux-diagnostics<\/a> to enable logging to see container logs here.     <br \/>\n2021-03-18T23:25:17.915Z INFO - Initiating warmup request to container mymlfunction_0_216cb03b for site mymlfunction     <br \/>\n2021-03-18T23:25:33.337Z INFO - Waiting for response to warmup request for container mymlfunction_0_216cb03b. Elapsed time = 15.4220545 sec     <br \/>\n2021-03-18T23:25:45.612Z INFO - Container mymlfunction_0_216cb03b for site mymlfunction initialized successfully and is ready to serve requests.     <br \/>\n2021-03-18T23:25:45.614Z INFO - Initiating warmup request to container mymlfunction_0_216cb03b_middleware for site mymlfunction     <br \/>\n2021-03-18T23:25:47.009Z INFO - Container mymlfunction_0_216cb03b_middleware for site mymlfunction initialized successfully and is ready to serve requests.     <br \/>\n2021-03-18T23:25:52.051Z ERROR - Container for mymlfunction_0_216cb03b site mymlfunction is unhealthy, Stopping site.     <br \/>\n2021-03-18T23:25:52.056Z INFO - Stopping site mymlfunction because it is not healthy.     <br \/>\n&quot;     <\/p>\n<p>When this happens, the system falls into a loop trying to initialize the Azure Function but fails since due to the error above just right after saying that the container was successfully deployed.     <\/p>\n<p>I was able to complete the majority of the tutorial until the last step which configures the Azure Function to use my ACR user and password but still seeing same issue, see last step of the tutorial in link below:     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-cache-for-redis\/cache-ml#deploy-image-as-a-web-app\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-cache-for-redis\/cache-ml#deploy-image-as-a-web-app<\/a>     <\/p>\n<p>The container to be deployed was build from Azure ML workspace using following python script:     <\/p>\n<p>&quot;    <br \/>\nfrom azureml.contrib.functions import package    <br \/>\nfrom azureml.contrib.functions import HTTP_TRIGGER    <br \/>\nfrom azureml.core import Workspace    <br \/>\nfrom azureml.core.model import Model    <\/p>\n<p>ws = Workspace.from_config()    <br \/>\nmodel = Model(ws, 'sklearn_mnist')    <\/p>\n<p>model_package = package(ws, [model], inference_config, functions_enabled=True, trigger=HTTP_TRIGGER)    <br \/>\nmodel_package.wait_for_creation(show_output=True)    <\/p>\n<h1 id=\"display-the-package-locationacr-path----\">Display the package location\/ACR path    <\/h1>\n<p>print(model_package.location)    <br \/>\n&quot;     <\/p>\n<p><strong>Can somebody help me resolve this issue?<\/strong> <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"All projects have been deleted",
        "Question_created_time":1628482133050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/505936\/all-projects-have-been-deleted",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I logged in after a long time All projects have been deleted.  <\/p>\n<p>Can I recover my data?  <\/p>\n<p>what can i do ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment running became extremely slow",
        "Question_created_time":1628240565393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/503939\/experiment-running-became-extremely-slow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm running some tutorials that involves using SDK to perform ML tasks. Everything was working fine till yesterday where the tasks become running very slowly and python code always ends up with Timed Out error code.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Voice\/Speech to Text Train Model",
        "Question_created_time":1627330507383,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/490113\/voice-speech-to-text-train-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi.  <\/p>\n<p>So I would like to create a model that 'listens' to audio from movies\/podcasts (with subtitles) then returns the text transcript from it. Problem is, it's in a language not supported by Azure (or most of the big cloud providers). How would I go about and, from scratch, build a model that is trained on the audio from a new language? The input audio all will have subtitles or captions.   <\/p>\n<p>I tried Azure ML studio but I couldn't create datasets with audio files. Not sure if I missed something there. Also tried Speech studio but it only supports a select number of languages. Would that be possible at all?   <\/p>\n<p>Any suggestions would be appreciated. Thanks. <\/p>",
        "Question_closed_time":1628120380253,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=d935cb60-7169-490f-b629-2b427aae1268\">@Nathan Carns  <\/a> Yes, you are correct, to develop a model for speech to text we need a deep learning model here. This is out of the scope of Azure Machine Learning Studio(classic). But I think Azure Machine Learning service should support it, please refer to this: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-deep-learning-vs-machine-learning#machine-translation\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-deep-learning-vs-machine-learning#machine-translation<\/a>    <\/p>\n<p>I have found one post which may help: <a href=\"https:\/\/towardsdatascience.com\/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706\">https:\/\/towardsdatascience.com\/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706<\/a>    <\/p>\n<p>Moreover, I have forwarded your feedback to see any plan here for Nigerian in Azure.    <\/p>\n<p>Thanks.    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure sql database Machine learning",
        "Question_created_time":1625235917747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/461404\/azure-sql-database-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>  I would like to know, do we have an option to use Machine learning with Azure SQL database or is it only available with Azure SQL managed instance  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning CI Pipeline: Submitting an experiment failed",
        "Question_created_time":1625658861767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/466362\/machine-learning-ci-pipeline-submitting-an-experim",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello everybody.<\/p>\n<p>I am currently working on a CI Pipeline for a Machine Learning Model.<\/p>\n<p>At the Task where the training should happen my code fails at submitting an experiment.<\/p>\n<p>I get following Error:<\/p>\n<pre><code>  File &quot;C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\multiprocessing\\pool.py&quot;, line 119, in worker\n    result = (True, func(*args, **kwds))\n  File &quot;C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\site-packages\\azureml\\_restclient\\snapshots_client.py&quot;, line 137, in create_snapshot\n    return self.create_snapshot(file_or_folder_path, retry_on_failure=False)\n  File &quot;C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\site-packages\\azureml\\_restclient\\snapshots_client.py&quot;, line 139, in create_snapshot\n    raise SnapshotException(get_http_exception_response_string(response))\nazureml.exceptions._azureml_exception.SnapshotException: SnapshotException:\n    Message: {\n    &quot;error_details&quot;: {\n        &quot;componentName&quot;: &quot;project&quot;,\n        &quot;correlation&quot;: {\n            &quot;operation&quot;: &quot;dsda3eb68326da4fa76b73560e39c8ac7&quot;,\n            &quot;request&quot;: &quot;23876ee7f425484f&quot;\n        },\n        &quot;environment&quot;: &quot;westeurope&quot;,\n        &quot;error&quot;: {\n            &quot;code&quot;: &quot;UserError&quot;,\n            &quot;innerError&quot;: {\n                &quot;code&quot;: &quot;NotFoundError&quot;\n            },\n            &quot;message&quot;: &quot;Unable to find storage with address: Primary = 'https:\/\/blobstorage354836.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'; Secondary = 'https:\/\/blobstorage354836-secondary.blob.core.windows.net\/snapshots\/b8f82531-be8a-44dc-b851-780e7a05486d'&quot;\n        },\n        &quot;location&quot;: &quot;northeurope&quot;,\n        &quot;time&quot;: &quot;2021-07-07T11:39:05.0508466+00:00&quot;\n    },\n    &quot;status_code&quot;: 404,\n    &quot;url&quot;: &quot;https:\/\/westeurope.experiments.azureml.net\/content\/v2.0\/subscriptions\/13f6ec8e-c4c1-4b2e-9f8b-80e2f17b0306\/resourceGroups\/ZA-GR-Prod-RPD\/providers\/Microsoft.MachineLearningServices\/workspaces\/Project_X\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d&quot;\n}\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;{\\n    \\&quot;error_details\\&quot;: {\\n        \\&quot;componentName\\&quot;: \\&quot;project\\&quot;,\\n        \\&quot;correlation\\&quot;: {\\n            \\&quot;operation\\&quot;: \\&quot;d636a3eb634da4fa76b7230e39c8ac7\\&quot;,\\n            \\&quot;request\\&quot;: \\&quot;40f26ee7f456384f\\&quot;\\n        },\\n        \\&quot;environment\\&quot;: \\&quot;northeurope\\&quot;,\\n        \\&quot;error\\&quot;: {\\n            \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n            \\&quot;innerError\\&quot;: {\\n                \\&quot;code\\&quot;: \\&quot;NotFoundError\\&quot;\\n            },\\n            \\&quot;message\\&quot;: \\&quot;Unable to find storage with address: Primary = 'https:\/\/blobstorage354836.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'; Secondary = 'https:\/\/blobstorage354836-secondary.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'\\&quot;\\n        },\\n        \\&quot;location\\&quot;: \\&quot;westeurope\\&quot;,\\n        \\&quot;time\\&quot;: \\&quot;2021-07-07T11:39:05.0508466+00:00\\&quot;\\n    },\\n    \\&quot;status_code\\&quot;: 404,\\n    \\&quot;url\\&quot;: \\&quot;https:\/\/westeurope.experiments.azureml.net\/content\/v2.0\/subscriptions\/13f6ec8e-c4c1-4b2e-9f8b-80e2f17b0306\/resourceGroups\/Ressource_cencored\/providers\/Microsoft.MachineLearningServices\/workspaces\/Projet_X\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d\\&quot;\\n}&quot;\n<\/code><\/pre>\n<p>Can anyone help me?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Execute R Script install.packages gives error: cannot open URL 'http:\/\/cran.us.r-project.org\/src\/contrib\/PACKAGES'",
        "Question_created_time":1628025270273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/500419\/execute-r-script-install-packages-gives-error-cann",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I'm trying to install the NbClust R package from an Execute R Script block in Designer:<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code>azureml_main &lt;- function(dataframe1, dataframe2){\n\n  # Install required libraries\n  print(&quot;**** START: Installing required libraries ****&quot;)\n\n  install.packages(&quot;NbClust&quot;,repos = &quot;http:\/\/cran.us.r-project.org&quot;)  \n  library(NbClust)\n\n  print(&quot;**** END: Installing required libraries ****&quot;) \n\n  print(&quot;R script run.&quot;)\n\n  print(summary(dataframe1))\n\n  # If a zip file is connected to the third input port, it is\n  # unzipped under &quot;.\/Script Bundle&quot;. This directory is added\n  # to sys.path.\n\n  # Return datasets as a Named List\n  return(list(dataset1=dataframe1, dataset2=dataframe2))\n}\n<\/code><\/pre>\n<p><strong>Error:<\/strong><\/p>\n<p>[1] &quot;R script run.&quot;  <br \/>\n[1] &quot;Import packages.&quot;  <br \/>\nLoading required package: reticulate  <br \/>\nLoading required package: jsonlite  <br \/>\nLoading required package: dplyr<\/p>\n<p>Attaching package: \u2018dplyr\u2019<\/p>\n<p>The following objects are masked from \u2018package:stats\u2019:<\/p>\n<pre><code>filter, lag\n<\/code><\/pre>\n<p>The following objects are masked from \u2018package:base\u2019:<\/p>\n<pre><code>intersect, setdiff, setequal, union\n<\/code><\/pre>\n<p>[1] &quot;R read input parquet file.&quot;  <br \/>\n[1] &quot;0 columns have been set to origin types.&quot;  <br \/>\n[1] &quot;**** START: Installing required libraries ****&quot;  <br \/>\nWarning: unable to access index for repository <a href=\"http:\/\/cran.us.r-project.org\/src\/contrib\">http:\/\/cran.us.r-project.org\/src\/contrib<\/a>:  <br \/>\ncannot open URL 'http:\/\/cran.us.r-project.org\/src\/contrib\/PACKAGES'  <br \/>\nError in library(NbClust) : there is no package called \u2018NbClust\u2019  <br \/>\nCalls: tryCatch ... tryCatchList -&gt; withCallingHandlers -&gt; azureml_main -&gt; library  <br \/>\nIn addition: Warning message:  <br \/>\npackage \u2018NbClust\u2019 is not available (for R version 3.5.1)  <br \/>\nExecution halted<\/p>\n<p>The same &quot;install.packages(&quot;NbClust&quot;,repos = &quot;http:\/\/cran.us.r-project.org&quot;)  <br \/>\nlibrary(NbClust)&quot; R code works just fine on my local computer.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to update automated machine learning model timeseries \"live\" as new events come in.",
        "Question_created_time":1628032373347,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/500499\/is-it-possible-to-update-automated-machine-learnin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have trained a simple time series ML model and deployed it.  <br \/>\nGetting predictions works well enough, but I would like to keep the model up to date as new events come along each hour.  <\/p>\n<p>For example I want to predict an event that happens in 10 minutes.   <br \/>\nAfter 10 minutes has gone by, and I learn the real value, i'd like to push that value at the end of the ML model data array without having to re-train\/deploy everything.  <br \/>\nIs that possible in Automated ML ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clear Feature with Auto ML",
        "Question_created_time":1627927876257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/498759\/clear-feature-with-auto-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I am trying to add a user Id column to my dataset but I don't want the user Id to impact the results of the ML.  <\/p>\n<p>I am using Auto ML on my dataset to generate a model and then deployed the model to an endpoint.  <\/p>\n<p>Currently I am calling the endpoint like:  <\/p>\n<pre><code>{&quot;data&quot;:[\n       {\n          &quot;TEMP&quot;:&quot;X&quot;,\n        }\n    ]\n}\n<\/code><\/pre>\n<p>and I would like to call it like:  <\/p>\n<pre><code>{&quot;data&quot;:[\n    {\n      &quot;TEMP&quot;:&quot;X&quot;,\n      &quot;userID&quot;: 5434643\n     }\n  ]}\n<\/code><\/pre>\n<p>I'm wondering if there is a way I can do this? I've seen about using Clear Feature in Edit Metadata for the Designer but I'm wondering if something similar can be done for automated ML?  <\/p>\n<p>Thanks so much!  <\/p>",
        "Question_closed_time":1627949805197,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hi, thanks for reaching out. You can customize featurization in automl to only include features relevant for prediction. Here's the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features#customize-featurization\">documentation<\/a>. Hope it helps!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error during Experiment run",
        "Question_created_time":1628072461983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/501299\/error-during-experiment-run",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am getting the following error after trying to submit my experiment in the Azure ML workspace:  <\/p>\n<p>azureml-logs\/60_control_log.txt  <\/p>\n<p>WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(143): Could not remove or rename \/anaconda\/pkgs\/zlib-1.2.11-h7b6447c_3\/lib\/libz.so.1.2.11.  Please remove this file manually (you may need to reboot to free file handles)  <\/p>\n<p>What is the cause for this problem?  <\/p>\n<p>Do I need to manually remove this files?  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how do I check if a variable is balanced in machine learning azure?",
        "Question_created_time":1627487004640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/493264\/how-do-i-check-if-a-variable-is-balanced-in-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm new to machine learning, so any recommendations is appreciated <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the point of AzureML modules?",
        "Question_created_time":1627306015463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/489671\/what-is-the-point-of-azureml-modules",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello!  <\/p>\n<p>I created an Azure ML pipeline in Python and used multiple PythonScriptSteps for each of my tasks. For example, I have three training steps running in parallel, so I create three PythonScriptSteps in a for loop with my train.py script and different data. Later, I came across the <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-how-to-use-modulestep.ipynb\">ModuleStep<\/a>, which seems to do exactly this, but with an extra layer of (seemingly pointless) abstraction. What does the ModuleStep add to a PythonScriptStep?  <\/p>\n<p>Also, I imagined the ModuleStep might make it possible to use a custom PythonScriptStep in the pipeline designer (by creating a new drag and drop module), however this doesn't seem to be the case. Is there any way of doing this?   <\/p>",
        "Question_closed_time":1628020406187,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Just to close this question, I have since discovered that the ModuleStep <strong>does<\/strong> create a custom drag-and-drop module in the designer. I don't know if I'd missed this (I imagine so) or if this is a new feature. Either way, that's the answer. <a href=\"\/users\/na\/?userid=ad870133-9538-4d77-adc8-2b5ffc5c1b45\">@YutongTie-MSFT  <\/a> can you confirm if this was recently added?    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Different tensorflow version using azure ml portal vs VS Code",
        "Question_created_time":1627517892667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/493634\/different-tensorflow-version-using-azure-ml-portal",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using azure ML to run an python code in a jupyter notebook using tensorflow. I'm using &quot;Python 3.6 - Azure ML&quot; and an instance of azure compute to run it. It's showing tensorflow version as 2.1.0 .When I run the same code using VS Code connected to azure portal remotely, it's shows tensorflow version as 2.5.0. Why this discrepency?    <\/p>\n<p>Also I need tensorflow version 2.3.0 or up but there is not way for me to upgrade that using azure ml portal. Any help will be appreciated. Thank you!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/118783-image.png?platform=QnA\" alt=\"118783-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/118822-image.png?platform=QnA\" alt=\"118822-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error Creating Inference Clusters Assing IP to Load Balancer",
        "Question_created_time":1609868045590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/219545\/error-creating-inference-clusters-assing-ip-to-loa",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>To deploy an automated ML model, I created an inference cluster in Azure.  The cluster stays in status &quot;creating&quot; for an hour then displays the following message.      <br \/>\nFailed:  K8s failed to assign an IP for Load Balancer after waiting for an hour.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/53588-2021-01-05-12-27-28.jpg?platform=QnA\" alt=\"53588-2021-01-05-12-27-28.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problems connecting to workspace using Azure Machine Learning SDK for Python",
        "Question_created_time":1606083056563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171465\/problems-connecting-to-workspace-using-azure-machi",
        "Question_score_count":0,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to connect to my Azure ML workspace using SDK for python, using Virtual Studio Code to do so. After pip installing the needed SDK packages:    <br \/>\n    pip install azureml-sdk  <br \/>\n    pip install azureml-sdk[notebooks,automl,explain]  <\/p>\n<p>I downloaded the .json configuration file for my workspace, made sure it was in the correct location for the file path and tried the following code (with my subscription id, resource group and workspace name in place of the fillers in this chunk of code):    <\/p>\n<pre><code>{  \n    &quot;subscription_id&quot;: &quot;1234567-abcde-890-fgh...&quot;,  \n    &quot;resource_group&quot;: &quot;aml-resources&quot;,  \n    &quot;workspace_name&quot;: &quot;aml-workspace&quot;  \n}  \n<\/code><\/pre>\n<p>Upon executing this in my ipy kernel in Virutal Studio Code I got a UserErrorException (see image below, I have blocked out subscription id's and other sensitive information):    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/41683-subscriptionerror.png?platform=QnA\" alt=\"41683-subscriptionerror.png\" \/>    <\/p>\n<p>I then tried this alternative way to connect to my workspace using the following code (again with my info filled in instead of the fillers in the code):    <br \/>\n    from azureml.core import Workspace  <\/p>\n<pre><code>from azureml.core import Workspace  \n  \nws = Workspace.get(name='aml-workspace',  \n                   subscription_id='1234567-abcde-890-fgh...',  \n                   resource_group='aml-resources')  \n  \nws = Workspace.from_config()  \n<\/code><\/pre>\n<p>This produced the same error upon execution. I have tried using different subscriptions with different workspace names and resource groups and it gives me the same error every time. It appears to be telling me I do not have access to the subscription that I am logged in to? I am unsure how to fix this. I am trying to do this as part of the lessons in the Microsoft Azure Data Scientist certification if anyone is familiar with that or has run into the same problem while trying to complete the modules for that certification provided through Microsoft.     <\/p>",
        "Question_closed_time":1606097262373,
        "Answer_score_count":3.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>can you try using InteractiveLoginAuthentication?  <\/p>\n<p>below code might help you  <\/p>\n<pre><code>from azureml.core.authentication import InteractiveLoginAuthentication\nia = InteractiveLoginAuthentication(tenant_id='YourTenant id')\n# You can find tenant id under azure active directory-&gt;properties\nws = Workspace.get(name='aml-workspace',\n                    subscription_id='1234567-abcde-890-fgh...',\n                    resource_group='aml-resources',auth=ia)\n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to use a registred model in a python script(in Azure) ?",
        "Question_created_time":1626012982337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/470931\/how-to-use-a-registred-model-in-a-python-script(in",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I used Azure AutoML service to test various models and after choosing the best one I registered it in my workspace.<\/p>\n<p><strong>Process done for registering:<\/strong>  <\/p>\n<ol>\n<li> I downloaded the model(a zipped folder containing 3 files) into my laptop  <\/li>\n<li> Unzipped the folder in my laptop  <\/li>\n<li> Uploaded the unzipped folder(containing the score, environment yml and pkl file ) in the Azure &quot;Models&quot; pane and registered a model under the name &quot;lgbm&quot;<\/li>\n<\/ol>\n<p><strong>What I want to achieve:<\/strong>  <br \/>\nI want to use the registered model to make some predictions on a &quot;validation&quot; Dataset I have in Azure(already registered) and check out the accuracy metrics once again.<\/p>\n<p><strong>Steps done:<\/strong>  <\/p>\n<ol>\n<li> Registered the validation dataset in Azure properly  <\/li>\n<li> Started the Azure VM and Opened a new notebook  <\/li>\n<li> Got the validation data into the script<\/li>\n<\/ol>\n<p><strong>Where I got stuck :<\/strong>  <br \/>\nUnable to get the registered model into my script and make predictions:<\/p>\n<p><strong>Code<\/strong>:<\/p>\n<p>import azureml.core  <br \/>\nfrom azureml.core import Workspace<\/p>\n<h1 id=\"load-the-workspace-from-the-saved-config-file\">Load the workspace from the saved config file<\/h1>\n<p>ws = Workspace.from_config()  <br \/>\nprint('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))<\/p>\n<p>from azureml.core import Dataset  <br \/>\nimport glob  <br \/>\ntab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'UI\/07-11-2021_055454_UTC\/test_pred.csv'))  <br \/>\ntab_data_set = tab_data_set.to_pandas_dataframe()<\/p>\n<p>model_path = Model.get_model_path('lgbm')  <br \/>\nmodel = joblib.load(model_path)<\/p>\n<p><strong>Error<\/strong>  <br \/>\nModelNotFoundException: ModelNotFoundException:  <br \/>\nMessage: Model lgbm not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/azuremlvm201\/code\/Users\/vishal_c_v. For more info, set logging level to DEBUG.  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Model lgbm not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/azuremlvm201\/code\/Users\/vishal_c_v. For more info, set logging level to DEBUG.&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy machine learning model - regression to predict auto car prices with the code from the MS docs documentation",
        "Question_created_time":1627690246390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/496628\/unable-to-deploy-machine-learning-model-regression",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>When I follow step by step as linked from the documentation to build and deploy a machine learning model with the car prices regression predictor, I get errors at the stage of adding a Python script after the score model block.    <\/p>\n<p>I am using code and documentation from <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/<\/a>    <\/p>\n<p>More precisely, I get an error when I have to input the custom run python script at <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline<\/a>    <\/p>\n<p>Has anyone had trouble executing these scripts from Microsoft? It is simply renaming a column.     <br \/>\nSee script below    <\/p>\n<pre><code>import pandas as pd  \n  \ndef azureml_main(dataframe1 = None, dataframe2 = None):  \n  \n    scored_results = dataframe1[['Scored Labels']]  \n    scored_results.rename(columns={'Scored Labels':'predicted_price'},  \n                        inplace=True)  \n    return scored_results  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Disabled drop down menu in toolbar for Create real-time inference pipeline. It is grayed out",
        "Question_created_time":1627875535160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/497610\/disabled-drop-down-menu-in-toolbar-for-create-real",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Azure ML users. I've created 1 inference pipeline in Azure Machine Learning workspace using Designer. I cannot create new one? I can only update the one I have. Do you know why?    <\/p>\n<p>Also, sometimes, I do not trust the update pipeline, as the Designer GUI seems to not really update the existing inference pipeline.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/119599-azure-realtimeinf-disabled.png?platform=QnA\" alt=\"119599-azure-realtimeinf-disabled.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"i am getting error when deploying machine learning model in aci",
        "Question_created_time":1627565559387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/494589\/i-am-getting-error-when-deploying-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p><strong>I am getting following error when trying to deploy machine learning model and when i deployed last time (1 month ago) with same score.py file it was deployed successfully, can anyone tell me why its giving error now<\/strong><\/p>\n<p><strong>Error message as below<\/strong><\/p>\n<p>service.get_logs()<\/p>\n<p>Received bad response from Model Management Service:  <br \/>\nResponse Code: 404  <br \/>\nHeaders: {'Date': 'Thu, 29 Jul 2021 12:34:55 GMT', 'Content-Type': 'application\/json',  <br \/>\n'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-  <br \/>\nclient-request-id': '70679512-c060-4340-adb7-b48ce00449f5', 'x-ms-client-session-id':  <br \/>\n'1def55d9-4542-4b5b-b499-81aaa966e48a', 'api-supported-versions': '1.0, 2018-03-01-preview,  <br \/>\n2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-  <br \/>\nContent-Type-Options': 'nosniff', 'x-request-time': '0.961', 'Content-Encoding': 'gzip'}<\/p>\n<p>Content: b'{&quot;code&quot;:&quot;NotFound&quot;,&quot;statusCode&quot;:404,&quot;message&quot;:&quot;The specified resource was not found.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;ContainerLogNotAvailable&quot;,&quot;message&quot;:&quot;Log of container \\'gpvmod24\\' in container group \\'gpvmod24-wdh0omjSOE6ebtgW6F6kJQ\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;0f3ed601-e1a9-4efb-ad42-2a6792c888c7&quot;}}'<\/p>\n<p><strong>My deployment code is below<\/strong>  <br \/>\naci_config = AciWebservice.deploy_configuration()<\/p>\n<p>service = Model.deploy(workspace=ws,  <br \/>\nname='try',  <br \/>\nmodels=[model_x],  <br \/>\ninference_config=inference_config,  <br \/>\ndeployment_config=aci_config,overwrite=True)  <br \/>\nservice.wait_for_deployment(show_output=True)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"i am getting error when deploying machine learning model in aci",
        "Question_created_time":1627583726403,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/494934\/i-am-getting-error-when-deploying-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>**I am getting following error when trying to deploy machine learning model and when i deployed last time (1 month ago) with same score.py file it was deployed successfully, can anyone tell me why its giving error now<\/p>\n<p>Error message as below**<\/p>\n<blockquote>\n<p>service.get_logs()<\/p>\n<\/blockquote>\n<p>Received bad response from Model Management Service:  <br \/>\nResponse Code: 404  <br \/>\nHeaders: {'Date': 'Thu, 29 Jul 2021 12:34:55 GMT', 'Content-Type': 'application\/json',  <br \/>\n'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-  <br \/>\nclient-request-id': '70679512-c060-4340-adb7-b48ce00449f5', 'x-ms-client-session-id':  <br \/>\n'1def55d9-4542-4b5b-b499-81aaa966e48a', 'api-supported-versions': '1.0, 2018-03-01-preview,  <br \/>\n2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-  <br \/>\nContent-Type-Options': 'nosniff', 'x-request-time': '0.961', 'Content-Encoding': 'gzip'}  <br \/>\nContent: b'{&quot;code&quot;:&quot;NotFound&quot;,&quot;statusCode&quot;:404,&quot;message&quot;:&quot;The specified resource was not found.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;ContainerLogNotAvailable&quot;,&quot;message&quot;:&quot;Log of container \\'gpvmod24\\' in container group \\'gpvmod24-wdh0omjSOE6ebtgW6F6kJQ\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;0f3ed601-e1a9-4efb-ad42-2a6792c888c7&quot;}}'<\/p>\n<p>My deployment code is below  <br \/>\naci_config = AciWebservice.deploy_configuration()<\/p>\n<p>service = Model.deploy(workspace=ws,  <br \/>\nname='try',  <br \/>\nmodels=[model_x],  <br \/>\ninference_config=inference_config,  <br \/>\ndeployment_config=aci_config,overwrite=True)  <br \/>\nservice.wait_for_deployment(show_output=True)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endpoint fails with the model generated by Automated ML",
        "Question_created_time":1626149341823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/473223\/endpoint-fails-with-the-model-generated-by-automat",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":3,
        "Question_body":"<p>I have loaded <a href=\"https:\/\/automlsamplenotebookdata.blob.core.windows.net\/automl-sample-notebook-data\/bankmarketing_train.csv\">bankmarketing_train.csv<\/a> to get a dataset and auto generated a model to predict &quot;y&quot; field value with AutoML.    <br \/>\nVoting Ensemble model was generated as the best model and tested its behavior after deployed to the endpoint.    <\/p>\n<p>Schema is generated like this for the endpoint.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113929-schema-2021-07-13-124905.png?platform=QnA\" alt=\"113929-schema-2021-07-13-124905.png\" \/>    <\/p>\n<p>Tried with the endpoint test feature in ML Studio. It worked and responded an expected output (left side in the fig below).    <br \/>\nBut my python REST call fails with 502 Bad Gateway(right side)    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114082-screenshot-2021-07-12-232443.png?platform=QnA\" alt=\"114082-screenshot-2021-07-12-232443.png\" \/>    <\/p>\n<p>Using the REST plug-in for VSCode, I have requested as below. This also failed with the same response status code.    <\/p>\n<pre><code>POST http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score  \nContent-Type: application\/json  \nAuthorization: Bearer === My correct key here ===  \n  \n{&quot;data&quot;: [{&quot;age&quot;: 87, &quot;campaign&quot;: 1, &quot;cons.conf.idx&quot;: -46.2, &quot;cons.price.idx&quot;: 92.893, &quot;contact&quot;: &quot;cellular&quot;, &quot;day_of_week&quot;: &quot;mon&quot;, &quot;default&quot;: &quot;no&quot;, &quot;duration&quot;: 471, &quot;education&quot;: &quot;university.degree&quot;, &quot;emp.var.rate&quot;: -1.8, &quot;euribor3m&quot;: 1.299, &quot;housing&quot;: &quot;yes&quot;, &quot;job&quot;: &quot;blue-collar&quot;, &quot;loan&quot;: &quot;yes&quot;, &quot;marital&quot;: &quot;married&quot;, &quot;month&quot;: &quot;may&quot;, &quot;nr.employed&quot;: 5099.1, &quot;pdays&quot;: 999, &quot;poutcome&quot;: &quot;failure&quot;, &quot;previous&quot;: 1}]}  \n<\/code><\/pre>\n<p>Investigated in the App Insight and queried the exceptions.    <br \/>\nI found this end point tries to convert 'yes' to int value. Of course it fails.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114083-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2021-07-13-003243.png?platform=QnA\" alt=\"114083-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2021-07-13-003243.png\" \/>    <\/p>\n<p>The value 'yes' is set to 'loan' and 'housing&quot;. Both are defined string value in the swagger.json for this endpoint.    <\/p>\n<p>What do you think?    <br \/>\nAm I missing something?    <br \/>\nIs this a bug with the endpoint?    <\/p>",
        "Question_closed_time":1626168091357,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Yes, I tried that. Following is the code coming from the consume, the values are set accordingly.    <\/p>\n<pre><code>import urllib.request  \nimport json  \nimport os  \nimport ssl  \n  \ndef allowSelfSignedHttps(allowed):  \n    # bypass the server certificate verification on client side  \n    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):  \n        ssl._create_default_https_context = ssl._create_unverified_context  \n  \nallowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.  \n  \n# Request data goes here  \n  \ndata = {&quot;data&quot;:  \n        [  \n          {  \n            &quot;age&quot;: &quot;17&quot;,  \n            &quot;campaign&quot;: &quot;1&quot;,  \n            &quot;cons.conf.idx&quot;: &quot;-46.2&quot;,  \n            &quot;cons.price.idx&quot;: &quot;92.893&quot;,  \n            &quot;contact&quot;: &quot;cellular&quot;,  \n            &quot;day_of_week&quot;: &quot;mon&quot;,  \n            &quot;default&quot;: &quot;no&quot;,  \n            &quot;duration&quot;: &quot;971&quot;,  \n            &quot;education&quot;: &quot;university.degree&quot;,  \n            &quot;emp.var.rate&quot;: &quot;-1.8&quot;,  \n            &quot;euribor3m&quot;: &quot;1.299&quot;,  \n            &quot;housing&quot;: &quot;yes&quot;,  \n            &quot;job&quot;: &quot;blue-collar&quot;,  \n            &quot;loan&quot;: &quot;yes&quot;,  \n            &quot;marital&quot;: &quot;married&quot;,  \n            &quot;month&quot;: &quot;may&quot;,  \n            &quot;nr.employed&quot;: &quot;5099.1&quot;,  \n            &quot;pdays&quot;: &quot;999&quot;,  \n            &quot;poutcome&quot;: &quot;failure&quot;,  \n            &quot;previous&quot;: &quot;1&quot;  \n          }  \n      ]  \n    }  \n  \n  \nbody = str.encode(json.dumps(data))  \n  \nurl = 'http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score'  \napi_key = '&lt;key&gt;' # Replace this with the API key for the web service  \nheaders = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}  \n  \nreq = urllib.request.Request(url, body, headers)  \n  \ntry:  \n    response = urllib.request.urlopen(req)  \n  \n    result = response.read()  \n    print(result)  \nexcept urllib.error.HTTPError as error:  \n    print(&quot;The request failed with status code: &quot; + str(error.code))  \n  \n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure  \n    print(error.info())  \n    print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))  \n  \n<\/code><\/pre>\n<p>The result was the same. 'yes' was tried to cast to int and failed.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114222-consume-2021-07-13-175924.png?platform=QnA\" alt=\"114222-consume-2021-07-13-175924.png\" \/>    <\/p>\n<p>In the deployment log, following exception observed. Something is happening inside the server call, which I cannot see.    <\/p>\n<pre><code>2021-07-13 08:56:49,684 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 64, in run_scoring  \n    response = invoke_user_with_timer(service_input, request_headers)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 97, in invoke_user_with_timer  \n    result = user_main.run(**params)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/wrapt\/wrappers.py&quot;, line 567, in __call__  \n    args, kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 57, in decorator_input  \n    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 285, in _deserialize_input_argument  \n    input_data = param_type.deserialize_input(input_data)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/parameter_types\/pandas_parameter_type.py&quot;, line 79, in deserialize_input  \n    data_frame = data_frame.astype(dtype=converted_types)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py&quot;, line 5865, in astype  \n    dtype=dtype[col_name], copy=copy, errors=errors, **kwargs  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py&quot;, line 5882, in astype  \n    dtype=dtype, copy=copy, errors=errors, **kwargs  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py&quot;, line 581, in astype  \n    return self.apply(&quot;astype&quot;, dtype=dtype, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py&quot;, line 438, in apply  \n    applied = getattr(b, f)(**kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py&quot;, line 559, in astype  \n    return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py&quot;, line 643, in _astype  \n    values = astype_nansafe(vals1d, dtype, copy=True, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/dtypes\/cast.py&quot;, line 707, in astype_nansafe  \n    return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)  \n  File &quot;pandas\/_libs\/lib.pyx&quot;, line 547, in pandas._libs.lib.astype_intsafe  \nValueError: invalid literal for int() with base 10: 'yes'  \n  \nDuring handling of the above exception, another exception occurred:  \n  \nTraceback (most recent call last):  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 43, in score_realtime  \n    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 77, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n<\/code><\/pre>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Custom Vision Stuck on 'Training'",
        "Question_created_time":1627340240297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/490215\/custom-vision-stuck-on-training",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I cannot train any models on Custom Vision. They stay stuck on 'Training' regardless if I choose quick or advanced training, and it stays stuck even after the maximum training time. This problem started a couple days ago, and I haven't had any problems in the past training with the same data\/ methods.   <\/p>\n<p>This is an example of the iteration details while the training job is in progress:  <\/p>\n<p>Iteration status: Training  <br \/>\nIteration Name: Iteration 1  <br \/>\nIteration training time (mins): 0  <br \/>\nIteration reserved budget time (hours): 12  <br \/>\nIteration training type: Advanced  <br \/>\nIteration classification type: None  <br \/>\nIteration error details: None  <\/p>\n<p>Yesterday I set a training job for 12 hours and it still had 0 mins for training time after 12 hours, so I had to manually delete the iteration.  <\/p>\n<p>I am used both the python SDK and azure custom vision GUI to start the training job, with the same results.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failed to query task; exceeded retry count for operation",
        "Question_created_time":1626787006267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/482901\/failed-to-query-task-exceeded-retry-count-for-oper",
        "Question_score_count":3,
        "Question_answer_count":0,
        "Question_comment_count":16,
        "Question_body":"<ul>\n<li> While attempting to train a Neural Network , the following error occurs on Hyper-parameter tuning &quot;Failed to query task; exceeded retry count for operation&quot; after one minute only.   <\/li>\n<li> The error message also occurs without an &quot;error code&quot;.<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to filter a FileDataset by name?",
        "Question_created_time":1627412512923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/491736\/how-to-filter-a-filedataset-by-name",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello!    <\/p>\n<p>I'm trying to pass a filtered dataset to a PythonScriptStep in a Pipeline. It doesn't have to be a FileDataset format, a OutputFileDatasetConfig or PipelineData would work as well. However, I don't want the step to access the entire dataset, so I want to filter it by name (<strong>without making copies of my data<\/strong>). Fortunately, FileDataset has a <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.filedataset?view=azure-ml-py#filter-expression-\">filter<\/a> function which does exactly this, allowing me to mount a &quot;folder&quot; with filtered files. Unfortunately, I can't work out how to filter by name, and the filter function only mentions filtering by Size, Extension, etc.    <\/p>\n<p>Any suggestions as to how can I achieve this?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automated machine learning model deployment issue",
        "Question_created_time":1627371604967,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/490809\/automated-machine-learning-model-deployment-issue",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>So I'm having an issue with setting up an endpoint for a machine learning model which was trained using Azure AutoML. When I try to test the deployed model, I get an error saying that the service is temporarily unavailable. After looking online, I found that this might happen because of an error in the run() function in the entry script.  <\/p>\n<p>When I try to test the entry script on a notebook in Azure ML studio, on a fresh compute instance, there are two problems:  <br \/>\nFirst I get the error: <em>AttributeError: 'MSIAuthentication' object has no attribute 'get_token'<\/em>  <br \/>\nWhich is solved by running: <em>pip install azureml-core<\/em>  <\/p>\n<p>Then I get the error: <em>ModuleNotFoundError: No module named 'azureml.automl.runtime'<\/em>  <br \/>\nWhich I try to solve using: <em>pip install azureml-automl-runtime<\/em>  <br \/>\nBut this throws a lot of incompatibility errors during the installation. When I then try to run the entry script I get an error with the message: &quot;<em>Failed while applying learned transformations.<\/em>&quot;  <\/p>\n<p>So I setup a new virtual environment on my local machine in which I only installed azure-automl-runtime. Using that setup the entry script works perfectly fine. So I created a custom environment in Azure ML studio using the conda file of that local virtual environment. Unfortunatly I still get the error &quot;service temporarily unavailable&quot; when trying to test the endpoint.  <\/p>\n<p>I have a feeling the default Azure ML containers are incompatible with azureml-automl-runtime, since installing this on a ML studio notebook also throws a lot of errors.   <\/p>\n<p>I feel like there should be an elegant way to deploy an AutoML model, am I doing something wrong here?   <\/p>\n<p><strong>Update:<\/strong> I found out I didn't change the environment for the endpoint, so that is why I was getting the same error probably. When using the custom environment I got errors from gunicorn, so I also added that package to the environment. Now I get the following error:  <\/p>\n<pre><code>      File &quot;\/var\/azureml-server\/entry.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/var\/azureml-server\/create_app.py&quot;, line 4, in &lt;module&gt;\n    from routes_common import main\n  File &quot;\/var\/azureml-server\/routes_common.py&quot;, line 39, in &lt;module&gt;\n    from azure.ml.api.exceptions.ClientSideException import ClientSideException\nModuleNotFoundError: No module named 'azure.ml'\n<\/code><\/pre>\n<p>So what do I install to fix this? Is there a list somewhere of required packages for an ML model endpoint?  <\/p>",
        "Question_closed_time":1627463996087,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I managed to fix the issue with the environment by just adding everything that would throw an error. Then I found out the return value has to be a json\/dict object, which if not done throws the exact same 'service temporarily unavailable' error.     <\/p>\n<p>But my issue with the confusing curated environments and azureml-automl-runtime in ML studio notebooks remain. Maybe this is worth looking into <a href=\"\/users\/na\/?userid=0e711f59-976b-4899-a912-2f0dd680421a\">@Ramr-msft  <\/a> .<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Model.Package fails when attempting to build image for ML model",
        "Question_created_time":1627313751780,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/489797\/model-package-fails-when-attempting-to-build-image",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Previously my code was completing while running on a machine in the cloud.  <\/p>\n<p>I am using azureml.core.Model to .package models and script which are in a \/source\/ subdirectory.  <\/p>\n<p>After connecting to the Workspace remotely I started to get the following error even when running unchanged code from the machine in the cloud.  <\/p>\n<pre><code>Message: Package creation reached non-successful terminal state.\n<\/code><\/pre>\n<p>State: Failed  <br \/>\nError:  <br \/>\nStatusCode: 400  <br \/>\nMessage: Failed to fetch details for Environment with Name: package Version: Autosave_2021-07-26T15:25:15Z_5cb0d061 Reason: Workspace connections are not supported for registry: viennaglobal.azurecr.io.  <\/p>\n<pre><code>InnerException None\nErrorResponse \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endopint not consumable after successful model deployment to azure instance container (machine learning studio - designer)",
        "Question_created_time":1627381840390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/491097\/endopint-not-consumable-after-successful-model-dep",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>hi, after i register a model and then deploy it on Azure container istance via the graphical interface of the machine learning studio - designer, although the state is &quot;heathy&quot; i cannot test the endpoint with data or consume the endpoint. These are the logs of the deploiment     <\/p>\n<p>2021-07-27 09:28:09,742 | root | INFO | 500 127.0.0.1 - - [27\/Jul\/2021:09:28:09 +0000] &quot;POST \/score?verbose=true HTTP\/1.0&quot; 500 37 &quot;-&quot; &quot;Go-http-client\/1.1&quot; Exception in worker process Traceback (most recent call last): File &quot;\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker worker.init_process() File &quot;\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 142, in init_process self.run() File &quot;\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 125, in run self.run_for_one(timeout) File &quot;\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 84, in run_for_one self.wait(timeout) File &quot;\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py&quot;, line 36, in wait ret = select.select(self.wait_fds, [], [], timeout) File &quot;\/var\/azureml-server\/routes_common.py&quot;, line 162, in alarm_handler raise TimeoutException(error_message) timeout_exception.TimeoutException Worker exiting (pid: 90) worker timeout is set to 300 Booting worker with pid: 330 SPARK_HOME not set. Skipping PySpark Initialization. Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Initializing logger 2021-07-27 09:29:12,687 | root | INFO | Starting up app insights client 2021-07-27 09:29:12,687 | root | INFO | Starting up request id generator 2021-07-27 09:29:12,687 | root | INFO | Starting up app insight hooks 2021-07-27 09:29:12,687 | root | INFO | Invoking user's init function 2021-07-27 09:29:12,882 | root | INFO | Users's init has completed successfully 2021-07-27 09:29:12,884 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled. 2021-07-27 09:29:12,884 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled. 2021-07-27 09:29:12,888 | root | INFO | Scoring timeout is found from os.environ: 60000 ms 2021-07-27 09:55:11,506 | root | INFO | Swagger file not present 2021-07-27 09:55:11,506 | root | INFO | 404 127.0.0.1 - - [27\/Jul\/2021:09:55:11 +0000] &quot;GET \/swagger.json HTTP\/1.0&quot; 404 19 &quot;-&quot; &quot;Go-http-client\/1.1&quot;    <\/p>\n<p>also if i try to consume the endpoint it ends with error 502, the specific error is this JSONDecodeError: Expecting value: line 1 column 1 (char 0)    <\/p>\n<p>i'm trying to deploy the trained model, but the same thing happen if i try to deploy the inference pipeline    <\/p>\n<p>i'm referring to this documentation    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer<\/a>    <\/p>\n<p>my dount really is &quot; it seems that i can deploy a model to an Azure Instance Container directly from the deployment tab without creating a container instance separately before, since it seems that it is created at the moment. The process should be authomatic. then the deployment state is healthy, so its ok, but somewhere during the actual deployment something fails, because i can't consume the endpoint&quot;     <\/p>\n<p>thanks for the support    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Execute R Script in ML Studio",
        "Question_created_time":1627017183467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/486775\/execute-r-script-in-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,     <\/p>\n<p>I am trying to runt the following R Script in an 'Execute R Script' module in Machine Learning Studio.    <\/p>\n<p>data.set &lt;- data.frame(installed.packages())    <br \/>\nmaml.mapOutputPort(&quot;data.set&quot;)    <\/p>\n<p>This script is taken from the 'Get started with Machine Learning Studio (classic)' in R page (<a href=\"https:\/\/learn.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries\">https:\/\/learn.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries<\/a>)    <\/p>\n<p>Whilst it works in ML (classic) I receive the following error when running it in Machine Learning Studio;    <\/p>\n<p>Error in maml.mapOutputPort(&quot;data.set&quot;): could not find function &quot;maml.mapOutputPort&quot;    <\/p>\n<p>What additional config settings are needed to enable R scripts in ML Studio?    <\/p>\n<p>Thank you.    <\/p>",
        "Question_closed_time":1627028470717,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=0c543906-17a1-488d-870d-1c2f45290746\">@Graham Benson  <\/a> For the designer version of the Azure ML studio you could follow the steps in this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/execute-r-script\">document<\/a> to install the packages and run any R scripts. Unlike the classic version you need to select or create compute for your experiment before the experiment can be submitted.     <\/p>\n<p>Example for installing a package:    <\/p>\n<pre><code>azureml_main &lt;- function(dataframe1, dataframe2){  \n  print(&quot;R script run.&quot;)  \n    \n  if(!require(zoo)) install.packages(&quot;zoo&quot;,repos = &quot;http:\/\/cran.us.r-project.org&quot;)  \n  library(zoo)  \n  # Return datasets as a Named List  \n  return(list(dataset1=dataframe1, dataset2=dataframe2))  \n}  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to use Convert-to-Indicator-Values, to convert a string category column for use in a Linear Regression model",
        "Question_created_time":1627007215790,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/486649\/how-to-use-convert-to-indicator-values-to-convert",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, Azure ML users, I'm new to modules that were not mentioned in the learning Paths. My new numerical columns are title-#NAN,title-rebuilt,title-salvage.    <\/p>\n<p>Azure seems to predict a higher price, when it sees a 1 for title-salvage, or 1 for title-rebuilt. But it needs to do the opposite. Any tips for how to use my new indicator numerical columns in a Linear Regression (online Gradient descent)?    <\/p>\n<p>screen shot attached. Thank you.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/117128-cars-4features2-confused-indicators.png?platform=QnA\" alt=\"117128-cars-4features2-confused-indicators.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model deployment stuck in \"Transitioning\" state",
        "Question_created_time":1626878916563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/484403\/model-deployment-stuck-in-transitioning-state",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have been trying to deploy a service on Azure ML workspace from a model both using an Azure DevOps pipeline and manually from the portal.  <br \/>\nIn both cases the deployment get stuck in &quot;Transitioning&quot; state for hours.  <br \/>\nWhat can I do to solve this issue?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_created_time":1626886810050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/484527\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am asking this question again, because I haven't got any update for my previous question, even though I have made new comments 20 days ago to describe my issue. The question can be found <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459776\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az.html\">here<\/a>.    <\/p>\n<p>To summarize:     <br \/>\nAfter restarting the kernel, I run the following suggested solution    <br \/>\n<code>import matplotlib<\/code>    <br \/>\n<code>matplotlib.use('Qt5Agg')<\/code>    <br \/>\n<code>import matplotlib.pyplot as plt<\/code>    <br \/>\n, and still got the same error:    <\/p>\n<pre><code>   ImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running  \n<\/code><\/pre>\n<p>Can someone please help me to solve this problem? It is really important for me to use interactive plots.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to Connect Azure ML Workspace Through VSCode",
        "Question_created_time":1627267451503,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/488719\/unable-to-connect-azure-ml-workspace-through-vscod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I changed my Azure account and closed the workspace of the previous account linked to Azure ML.     <\/p>\n<p>Then, I tried to connect my VSCode to my new Azure account and I got the following problems.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/117776-image.png?platform=QnA\" alt=\"117776-image.png\" \/>    <\/p>\n<p>Then I tried to connect Azure ML Compute Instance, it is keeping checking to see if the workspace exists.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Studio Issue",
        "Question_created_time":1627253465317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/488593\/machine-learning-studio-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey all,<\/p>\n<p>I'm working on a project for school in the machine learning studio classic and when I try to execute the following python script I get errors.<\/p>\n<p>def azureml_main(frame1):  <br \/>\nimport matplotlib  <br \/>\nmatplotlib.use('agg')<\/p>\n<pre><code>import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport statsmodels.graphics.boxplots as sm\n\nAzure = True\n<\/code><\/pre>\n<h2 id=\"create-a-series-of-bar-plots-for-the-various-levels-of-the\">Create a series of bar plots for the various levels of the<\/h2>\n<h2 id=\"string-columns-in-the-data-frame-by-readmi_class\">string columns in the data frame by readmi_class.<\/h2>\n<pre><code>names = list(frame1) \nnum_cols = frame1.shape[1]\nfor indx in range(num_cols - 1): \n        if(frame1.ix[:, indx].dtype not in [np.int64, np.int32, np.float64]):\n            temp1 = frame1.ix[frame1.readmi_class == 'YES', indx].value_counts()\n            temp0 = frame1.ix[frame1.readmi_class == 'NO', indx].value_counts()  \n            fig = plt.figure(figsize = (12,6)) \n            fig.clf()\n            ax1 = fig.add_subplot(1, 2, 1) \n            ax0 = fig.add_subplot(1, 2, 2) \n            temp1.plot(kind = 'bar', ax = ax1)\n            ax1.set_title('Values of ' + names[indx] + '\\n for readmitted patients')\n            temp0.plot(kind = 'bar', ax = ax0)\n            ax0.set_title('Values of ' + names[indx] + '\\n for patients not readmitted')\n\n            if(Azure == True): fig.savefig('bar_' + names[indx] +'.png') \n                ## Now make some box plots of the columns with numerical values. \nfor indx in range(num_cols):\n        if(frame1.ix[:, indx].dtype in [np.int64, np.int32, np.float64]): \n            temp1 = frame1.ix[frame1.readmi_class == 'YES', indx] \n            temp0 = frame1.ix[frame1.readmi_class == 'NO', indx]\n\n            fig = plt.figure(figsize = (12,6))             \n            fig.clf()\n            ax1 = fig.add_subplot(1, 2, 1)             \n            ax0 = fig.add_subplot(1, 2, 2)        \n            ax1.boxplot(temp1.as_matrix())\n            ax1.set_title('Box plot of ' + names[indx] + '\\n for readmitted patients')\n            ax0.boxplot(temp0.as_matrix())\n            ax0.set_title('Box plot of ' + names[indx] + '\\n for patients not readmitted')\n\n            if(Azure == True): fig.savefig('box_' + names[indx] +'.png')               \nreturn frame1\n<\/code><\/pre>\n<p>The error I'm getting is:  <br \/>\nError 0085: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nCaught exception while executing function: Traceback (most recent call last):  <br \/>\nFile &quot;C:\\server\\invokepy.py&quot;, line 199, in batch  <br \/>\nodfs = mod.azureml_main(*idfs)  <br \/>\nFile &quot;C:\\temp\\1f7ee68aea7d4914a540db6181eb53c8.py&quot;, line 46, in azureml_main  <br \/>\ntemp1 = frame1.ix[frame1.readmi_class == 'YES', indx]  <br \/>\nFile &quot;C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py&quot;, line 2669, in <strong>getattr<\/strong>  <br \/>\nreturn object.<strong>getattribute<\/strong>(self, name)  <br \/>\nAttributeError: 'DataFrame' object has no attribute 'readmi_class'  <br \/>\nProcess returned with non-zero exit code 1<\/p>\n<p>---------- End of error message from Python interpreter ----------  <br \/>\nStart time: UTC 07\/25\/2021 22:45:40  <br \/>\nEnd time: UTC 07\/25\/2021 22:46:03<\/p>\n<p>Has anyone encountered this or know of a fix? I appreciate any help you can provide.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error Importing URL",
        "Question_created_time":1601509681700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/113390\/error-importing-url",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":5,
        "Question_body":"<p>Hi there, I am taking an online course through EdX called Data Analytics for Managers. In this course, we have been asked to create a free MSFT Azure Machine Learning Studio account (using classic mode) and create Experiments.   <\/p>\n<p>We are then instructed to create a new Blank Experiment and import the data via url. I have followed all instructions to add the data via Web Url via HTTP and entered the following url: <a href=\"https:\/\/docs.google.com\/spreadsheets\/d\/1ub_0Y5CEj2HtKO6bgb8OIvMIG81Wca0r_q8G70OKUTc\/pub?gid=1709232748&amp;single=true&amp;output=csv\">https:\/\/docs.google.com\/spreadsheets\/d\/1ub_0Y5CEj2HtKO6bgb8OIvMIG81Wca0r_q8G70OKUTc\/pub?gid=1709232748&amp;single=true&amp;output=csv<\/a>   <\/p>\n<p><strong>I am getting the below error message<\/strong>. Please help, thanks!   <\/p>\n<p>Error 0030: Error while downloading the file: Error 0039: Error while completing operation: System.Net.WebException: An exception occurred during a WebClient request. ---&gt; Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0078: Http redirection not allowed at Microsoft.Analytics.Exceptions.ErrorMapping.Throw(ExceptionID id, Object[] arguments) at Microsoft.Analytics.Modules.Reader.Dll.HttpReader.HttpWebClient.GetWebResponse(WebRequest request) in m:\\AzureMLVS15-004_work\\117\\s\\Product\\Source\\Modules\\Reader.Dll\\HttpReader.cs:line 265 at System.Net.WebClient.DownloadBits(WebRequest request, Stream writeStream, CompletionDelegate completionDelegate, AsyncOperation asyncOp) at System.Net.WebClient.DownloadFile(Uri address, String fileName) --- End of inner exception stack trace --- at System.Net.WebClient.DownloadFile(Uri address, String fileName) at Microsoft.Analytics.Modules.Reader.Dll.HttpReader.DownloadWithRetry(Uri url) in m:\\AzureMLVS15-004_work\\117\\s\\Product\\Source\\Modules\\Reader.Dll\\HttpReader.cs:line 124.. Start time: UTC 09\/30\/2020 23:34:52 End time: UTC 09\/30\/2020 23:35:03 <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem exporting data to azure ml scored dataset to sql database from designer",
        "Question_created_time":1626948657997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/485734\/problem-exporting-data-to-azure-ml-scored-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to export scored data from azure ML pipeline to azure sql database but its running for 6 hours and still not creating any table. I am not sure how to approach to this problem.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Workspace Labelling Project Validation",
        "Question_created_time":1626623101170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/479940\/azure-ml-workspace-labelling-project-validation",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>HI, I am using Azure ML workspace Data Labelling project. I would like to know how can I trigger the Validation and Inference steps? I follow the instruction to manually labelled images, the project managed to trigger the Training steps, but there is no sign of Validation steps. I am not sure how to execute it or what is the condition to make the Validation step start. I also need to know how to trigger Inference steps as the documents I can get is limited. Any input is highly appreciated.    <\/p>\n<p>Thank you.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects<\/a>     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ml update service erro AttributeError: AttributeError: 'str' object has no attribute 'id'",
        "Question_created_time":1626917581717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/485052\/azure-ml-update-service-erro-attributeerror-attrib",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am tying to update existing webservice using new Azure ML package   <br \/>\nIts failing with error - AttributeError: 'str' object has no attribute 'id'  <\/p>\n<p>Here is the script I am using -  <\/p>\n<pre><code>ws = Workspace.get(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=cli_auth)\n\nmodel = Model.register(model_path = model_path,\n                   model_name = model_name,\n                   #tags = {&quot;key&quot;: &quot;1&quot;},\n                   description = model_description,\n                   workspace = ws)\n\nimage_config = ContainerImage.image_configuration(execution_script=&quot;score.py&quot;, \n                                              runtime=&quot;python&quot;, \n                                              conda_file=&quot;packagesenv.yml&quot;)\nimage = 'testazureml'\nservice_name = 'testazureml'\n\n# Retrieve existing service\nservice = Webservice(name = service_name, workspace = ws)\n\nprint(service)\n\nservice.update(image,'image.id')\n<\/code><\/pre>\n<p>please help  <br \/>\nI have been trying with different methods   <br \/>\nas - 'id', 'image_id'   <br \/>\nits still failing <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Import Data Error",
        "Question_created_time":1626779418893,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/482751\/import-data-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,   <br \/>\nI am a newbie and trying to practice data analysis with the Machine Learning Studio Classic &amp; I use the published data set URL as the input to run the experiment and it did not work successfully as expected (check below for the error please)  <\/p>\n<p>*Import Data Error  <br \/>\nError while downloading the file: Error 0039: Error while completing operation: System.Net.WebException: An exception occurred during a WebClient request. ---&gt; Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0078: Http redirection not allowed . ( Error 0030 )  <\/p>\n<p>Anyone can help, please? Appreciate! <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Score Recommender system - Item Recommendation failed to run",
        "Question_created_time":1626681386490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/480658\/score-recommender-system-item-recommendation-faile",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am getting an error when trying to run the Score Recommender system for Item Recommendation.  <\/p>\n<p>The status details is 'Failed to run task; exceeded retry count for operation'. Can someone help to advise on this error?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"400 schema error in AzureML regression model when using a notebook python script, but endpoint test success",
        "Question_created_time":1626321175607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/476616\/400-schema-error-in-azureml-regression-model-when",
        "Question_score_count":3,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Azure ML users! My Regression model, based on this learning Path:  <br \/>\nCreate a Regression Model with Azure Machine Learning designer --&gt; Deploy a predictive service.  <br \/>\nIt predicts a car's price. I've added Edit Meta Data in Designer to clear features of other columns selected. This displays other details about each car, like engine, manual or automatic, title status and general notes. For prediction AzureML only uses two columns, miles and year, to predict price. 6 columns ClearFeatured, 2 features and one label column for price, 9 total columns selected.  <\/p>\n<ol>\n<li> I enter data manually, CSV, click submit realtime inference and AzureML predicts a price, success.  <\/li>\n<li> I click deploy, and then click Test on the deployed endpoint, AzureML success again.  <\/li>\n<li> I click New Notebook and paste in python script to predict a price, sending 9 columns, like this, but keep getting a schema error.<\/li>\n<\/ol>\n<p>&quot;price&quot;: 5500,  <br \/>\n&quot;year&quot;: 2013,  <br \/>\n&quot;car&quot;: &quot;Mini Cooper&quot;,  <br \/>\n&quot;miles&quot;: 74000,  <br \/>\n&quot;model&quot;: &quot;Sport&quot;,  <br \/>\n&quot;engine&quot;: 1,  <br \/>\n&quot;manual&quot;: &quot;manual&quot;,  <br \/>\n&quot;title&quot;: &quot;rebuilt&quot;,  <br \/>\n&quot;notes&quot;: &quot;silver black lines to 5500 started at 6500&quot;,<\/p>\n<p>-- Here is the deploy error --  <br \/>\nThe request failed with status code: 400  <br \/>\nAccess-Control-Allow-Origin: *  <br \/>\nContent-Length: 1271  <br \/>\nContent-Type: application\/json  <br \/>\nDate: Thu, 15 Jul 2021 03:17:53 GMT  <br \/>\nServer: nginx\/1.14.0 (Ubuntu)  <br \/>\nX-Ms-Request-Id: 6d440216-81bc-441f-aeae-c5190c486028  <br \/>\nX-Ms-Run-Function-Failed: False  <br \/>\nConnection: close<\/p>\n<p>{'error': {'code': 400, 'message': 'Input Data Error. Input data are inconsistent with schema.\\nSchema: {\\'columnAttributes\\': [{\\'name\\': \\'price\\', \\'type\\': \\'Numeric\\', \\'isFeature\\': True, \\'elementType\\': {\\'typeName\\': \\'int64\\', \\'isNullable\\': False}}, {\\'name\\': \\'year\\', \\'type\\': \\'Numeric\\', \\'isFeature\\': True, \\'elementType\\': {\\'typeName\\': \\'int64\\', \\'isNullable\\': False}}, {\\'n\\nData: defaultdict(&lt;class \\'list\\'&gt;, {\\'price\\': [5500], \\'year\\': [2013], \\'car\\': [\\'Mini Cooper\\'], \\'miles\\': [74000], \\'model\\': [\\'Sport\\'], \\'engine\\': <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114777-azure-ml-deploy-has-schema-error.png?platform=QnA\">1<\/a>, \\'manual\\': [\\'manual\\'], \\'title\\': [\\'rebuilt\\'], \\'notes\\': [\\'silver black lines now down to 5800 started at 6500\\']})\\nTraceback (most recent call last):\\n File &quot;\/azureml-envs\/azureml_d04391a4e9e93a56aa2beac2c36d4d02\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/dag.py&quot;, line 167, in execute\\n input_data = create_dfd_from_dict(raw_input, schema)\\n File &quot;\/azureml-envs\/azureml_d04391a4e9e93a56aa2beac2c36d4d02\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/converter.py&quot;, line 19, in create_dfd_from_dict\\n raise ValueError(f\\'Input json_data must have the same column names as the meta data. \\'\\nValueError: Input json_data must have the same column names as the meta data. Different columns are: {\\'more1\\'}\\n', 'details': ''}}<\/p>\n<p>:: problem ::  <br \/>\nWhy is the notebook failing? but the Test of the endpoint has succcess? What am I doing wrong with the schema?<\/p>\n<p>Thank you.<\/p>\n<p>-- more details below, if you interested --  <br \/>\nmy incoming data will match the schema of the original training data, 9 columns, so I did not do this step below.<\/p>\n<p>Learning Path says:  <br \/>\n&quot;The inference pipeline assumes that new data will match the schema of the original training data, so the Automobile price data (Raw) dataset from the training pipeline is included. However, this input data includes the price label that the model predicts, which is unintuitive to include in new car data for which a price prediction has not yet been made.&quot;<\/p>\n<p>Learning Path also says:  <br \/>\n&quot;Now that you've changed the schema of the incoming data to exclude the price field, you need to remove any explicit uses of this field in the remaining modules. Select the Select Columns in Dataset module and then in the settings pane, edit the columns to remove the price field.&quot;<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114777-azure-ml-deploy-has-schema-error.png?platform=QnA\" alt=\"114777-azure-ml-deploy-has-schema-error.png\" \/><\/p>",
        "Question_closed_time":1626832365393,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>it's working now. I needed to add the more1 column. this was a null column in my dataset, the last column in CSV file.     <br \/>\nin my training pipeline this was omitted from Select Columns in Dataset. But in the Creating Inference,mistakenly put it back in, all my columns in the Enter Data Manually asset. 10 columns in Notebook now matches 10 column names for inference pipeline.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/116545-azure-fix-cars-schema1.png?platform=QnA\" alt=\"116545-azure-fix-cars-schema1.png\" \/>    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Azure ML Datastore\\Datasets",
        "Question_created_time":1626270339670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/475768\/azure-ml-datastoredatasets",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello:  <\/p>\n<p>I want to know that if it is possible automate copy file from azure storage to Azure ML folder.  <\/p>\n<p>I understand that it is duplication of data, but I want to know if yes, how I can do that.  <\/p>\n<p>Any pointer is greatly appreciated.  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1626436211017,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Depending on the frequency at which you would like to move data you can create scripts that could run on crontab to move the data between source storage account to your workspace blob store. For example, use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/common\/storage-use-azcopy-blobs-copy?toc=\/azure\/storage\/blobs\/toc.json\">azcopy<\/a> to perform this activity.    <\/p>\n<p>A very comprehensive method to move storage between storage accounts is available as a <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/copy-blobs-from-command-line-and-code\/\">Microsoft learn module<\/a> that you could take to understand the possibilities and attain this from code to automate in your application.     <\/p>\n<p> I would ideally assume that you would like to pull data when your experiment kicks off because you cannot move data to an experiments run id folder unless the experiment has started, In this case you could use the first option to place the data in your workspace blob store and then use it in your experiment without moving it to any other storage. I hope this helps.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Python script before ML endpoint",
        "Question_created_time":1626725693000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/481697\/python-script-before-ml-endpoint",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,  <\/p>\n<p>I'm wondering if there is somewhere in Azure that I can add a python script that will process my data before sending it to a Machine Learning Endpoint?(the model is already deployed)  <\/p>\n<p>Thanks so much!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Passing data from Azure Data Factory into Azure ML",
        "Question_created_time":1626444050490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/479034\/passing-data-from-azure-data-factory-into-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>In Azure ML the input data has to be defined as a Dataset (to create a pipeline). In my code I am passing datasets with the following syntax: input_data = Dataset.File.from_files(datapath)  <\/p>\n<p>I would like to change this datapath as an input parameter from Data Factory (for example via PipelineParamater), so I can apply the same Data Factory pipeline for different datasets. However, in Data Factory you can only pass string as a parameter, not a DataPath.  <\/p>\n<p>What is the solution around this?<\/p>",
        "Question_closed_time":1626693295843,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=db220306-9cc7-45e6-8626-e4713f3f5baf\">@Ilze Amanda   <\/a> ,    <\/p>\n<p>Thank you for posting your query on Microsoft Q&amp;A Portal and sharing clarifications on ask.    <\/p>\n<blockquote>\n<p>Unfortunately, we cannot create user defined types in Azure data factory at this moment.    <\/p>\n<\/blockquote>\n<p>But, I will encourage you to log your feedback using below link. Product team will actively monitor feedback there and consider them for future releases. Thank you.    <br \/>\n<a href=\"https:\/\/feedback.azure.com\/forums\/270578-data-factory\">https:\/\/feedback.azure.com\/forums\/270578-data-factory<\/a>     <\/p>\n<p>Hope this will help.    <\/p>\n<p>--------------------------------------    <\/p>\n<ul>\n<li> Please <code>accept an answer<\/code> if correct. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>.    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>.     <\/li>\n<\/ul>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Predictive Web Service disabled",
        "Question_created_time":1625852190597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/470099\/predictive-web-service-disabled",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, I'm trying to use the function &quot;Predictive Web Service&quot;    <br \/>\nBut appears disabled:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113471-image.png?platform=QnA\" alt=\"113471-image.png\" \/>    <\/p>\n<p>Why does this is happening?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to include the IP address of a specific Azure Machine Learning workspace in its storage account selected networks and get all functionality enabled?",
        "Question_created_time":1626459319327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/479209\/is-it-possible-to-include-the-ip-address-of-a-spec",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>We have secured the storage account of a Machine Learning workspace behind a vnet and have authorized a set of IPs to access the storage account. Since the workspace is not secured behind the vnet, a set of functions is disabled. Is there a way to get the IP of the workspace and include it in the list authorized networks for the storage account in order to have all workspace functionalities available? We know the official solution involves securing the workspace behind the vnet and enabling point-to-site, site-to-site or connecting through a VM, but these are not possible in our case. Thanks for the help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Find best activity for implemet ML scenario in Azure Data Factory",
        "Question_created_time":1625846969290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/470071\/find-best-activity-for-implemet-ml-scenario-in-azu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I'm new to Azure Data Factory. I want to implement the below scenario and I want to know which activity is suitable for this scenario.    <\/p>\n<ol>\n<li> My data is on the Postgres database.    <\/li>\n<li> Our data factory an activity copies data from the Postgres database.    <\/li>\n<li> In this step run preprocessing function then is a python file. Also, the Python function needs the &quot;scaler.sav&quot; file.    <\/li>\n<li> The output of step 3 use as input for step 4  and run the classification function then is a python file. Also, the Python function needs the &quot;ExtraTreesClassifier.sav&quot; file.     <\/li>\n<li> Insert the output of step 4 into the database.    <\/li>\n<\/ol>\n<p>The diagram of this scenario. I need help to know which activity should use for this scenario.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113369-image.png?platform=QnA\" alt=\"113369-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can i consume or install the universal packages  directly  in the azure ml studio?",
        "Question_created_time":1597670716377,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/68515\/how-can-i-consume-or-install-the-universal-package",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p> I have published some packages  in the artifacts feed as universal packages but i am not finding the correct resources to use those feed in the azure ml studio can anyone help me in finding the solution? I can download the published feed to local system and i can install but i want to install those directly in azure ml studio.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to stop Azure ML Compute instance",
        "Question_created_time":1626257651013,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/475562\/unable-to-stop-azure-ml-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm unable to stop my Azure ML Compute instance as it fails with the following error:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114520-image.png?platform=QnA\" alt=\"114520-image.png\" \/>    <\/p>\n<pre><code>Failed to stop compute  \nResourceNotReady: Request failed with status code 400.  \n  \nTrace ID : 698a7727-f014-4d38-9dc1-a058158a2b09  \nClient request ID : 7f491fb9-cdd3-4a82-86f3-3eebb19b8419  \nService request ID : |00-872699f1c7573e4bbb4b130d59759cab-9f1ee7b43cfb3f4c-01.ad2a11cf_  \n<\/code><\/pre>\n<p>In DevTools in the browser, I can see this additional information:    <\/p>\n<pre><code>message&quot;:&quot;There is already an active operation submitted.&quot;  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"where to find the equation for the line after making Azure ML linear regression model, 2 slopes and 1 y intercept",
        "Question_created_time":1626236136657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/474924\/where-to-find-the-equation-for-the-line-after-maki",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I've made a model and it's predicting prices of cars. hooray! I cannot find the the equation for Azure's Regression Linear model anywhere. I made this model using Designer GUI. For example, in R, the coefficients are returned by running summary(mymodel)  <br \/>\n= y-intercept + (slope * miles) + (slope * year)  <br \/>\n= 21022.96 + (-0.0249*98500) + (-6.5668*2016)  <br \/>\nsomething like this equation for a line is what I'm looking for in Azure.<\/p>\n<p>what I've tried:  <\/p>\n<ol>\n<li> If it was only 1 feature, I could solve for an equation using (y2-y1) \/ (miles2-miles1) to find slope and the solve to y intercept. But this model uses miles and year as variables.<\/li>\n<\/ol>",
        "Question_closed_time":1626277455030,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>@<a href=\"\/users\/na\/?userid=dfab4fce-bbe8-4d93-a6fe-317f22fb2756\">@MikeRichardson-3493  <\/a> Thanks, We currently do not have coefficients for regression models, but we will forward this with our data science team to check on this. We are working on an interface to surface models that compose ensembles, model weights and more. While not  as involved of an interface, some of this information is available today within the model details tags sections:.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114674-a.png?platform=QnA\" alt=\"114674-a.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML AutoML : Data transformation diagram only 1 column",
        "Question_created_time":1626184752807,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/474091\/azure-ml-automl-data-transformation-diagram-only-1",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, I am using the AutoML of Azure ML. I don't understand the diagram of Data transformation (that is still in preview). It tells me that I start with 26 columns, which is correct, but then says I'm ending up with 1 column only, after a MeanImputer. ![114216-1column.png][1] If I check the engineered features in the code, I get this table, so 26 columns with the application of MeanImputer for each of them. ![114215-allcolumns.png][2] Could you tell me why the diagram tells me that there is only 1 column at the end? [1]: \/api\/attachments\/114216-1column.png?platform=QnA [2]: \/api\/attachments\/114215-allcolumns.png?platform=QnA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Got an error when running an experiment in Azure ML studio",
        "Question_created_time":1605143753147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/159889\/got-an-error-when-running-an-experiment-in-azure-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Please take a look at the following link.    <\/p>\n<p><a href=\"https:\/\/gallery.azure.ai\/Experiment\/Retail-Forecasting-Step-1-of-6-data-preprocessing-5\">https:\/\/gallery.azure.ai\/Experiment\/Retail-Forecasting-Step-1-of-6-data-preprocessing-5<\/a>    <\/p>\n<p>When running step 5 of the experiment, I got an error. Please see screenshot<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/38870-step5retail.png?platform=QnA\" alt=\"38870-step5retail.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Regarding spot instances",
        "Question_created_time":1626182886860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/474023\/regarding-spot-instances",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have recently received a research grant which I'm planning on using to rent 8xV100 instances (or maybe 16xV100 too). My question is, how long do the spot instances last, specifically ND40rs v2 spot instances, as they are only $2.4\/hr, which is great for my use case. My second question is, can I stack 16 such instances together for $38.4\/hr? That would be very helpful if I can get such instances for say a day at a time. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot use GPU on Azure Notebooks in Azure Machine Learning Studio",
        "Question_created_time":1625492823860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/463398\/cannot-use-gpu-on-azure-notebooks-in-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey All,   <\/p>\n<p>I am new to Azure Machine Learning Studio and am currently trying to train some models on a GPU compute instance in on Azure Machine Learning Studio. The compute instance that I am using is Standard_NC6.   <\/p>\n<p>The problem I am currently facing is that even though I can successfully train my models, I realize that Tensorflow is using the CPU instead of the GPU when I run   <\/p>\n<pre><code>device_name = tensorflow.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))\nprint(&quot;Num GPUs Available: &quot;, len(tensorflow.config.list_physical_devices('GPU')))\n<\/code><\/pre>\n<p>which raises the system error. Am I doing something wrong in the setup, my code is literally the same from when I was training on Google Colab and can successfully train on a Tesla K80 there but it is somehow not working within the Azure Notebook.  <\/p>\n<p>Appreciate any help given!   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting BadRequest when creating deployment for ML online endpoint",
        "Question_created_time":1626097427733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/472314\/getting-badrequest-when-creating-deployment-for-ml",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>I'm trying to create a managed online endpoint for a ML model using the Azure Machine Learning Studio (so GUI not CLI). It succeeds on the first four steps, but when it comes to &quot;Microsoft.MachineLearningServices\/workspaces\/onlineEndpoints\/deployments&quot; it fails with a BadRequest error. The status message isn't much help either:  <br \/>\n{  <br \/>\n&quot;status&quot;: &quot;Failed&quot;,  <br \/>\n&quot;error&quot;: {}  <br \/>\n}  <br \/>\nAny suggestions?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_created_time":1623826462663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/438183\/azure-ml-tutorial-failed-to-load-entrypoint-automl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm doing following tutorial. I run successfully &quot;Create and run a Python script&quot;, but failed failed to run &quot;Create a control script&quot;.    <\/p>\n<p>What could be wrong?    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a>    <\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py   \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl =   \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0   \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages),   \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).  \nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5?   \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff-   \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49-   \n866b-   \n06c297c116cc  \nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to parse the response from the Azure ML Web Service - PowerBI, Azure Auto ML, Time Series",
        "Question_created_time":1611654540273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/245495\/unable-to-parse-the-response-from-the-azure-ml-web",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everyone,     <\/p>\n<p>I have issues while interfacing Azure ML with <strong>PowerBI<\/strong>. I deployed a model from <strong>Auto ML<\/strong>, and tried to consume it in PowerBI. I successfully completed the following tutorials <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-automated-model\">create a predictive model by using auto ML<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate?context=azure\/machine-learning\/context\/ml-context\">consume a model in PowerBI<\/a> . But when it comes to implement my proper model, I get this error : <strong>&quot;Unable to parse the response from the Azure ML Web Service&quot;<\/strong>.     <\/p>\n<p>I have to add that my model forecasts <strong>time series<\/strong>. On the contrary, the model was a regression in the Microsoft tutorials. And I didn't use R or Python script, I used exactly the same method as the second tutorial about PowerBI.    <\/p>\n<p>Thank you very much for your help ! don't hesitate to ask me if you need more information.    <\/p>\n<p>Mary    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to call azure endpoint rest api from model generated by visual studio 2019 ml builder?",
        "Question_created_time":1625718765327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/467346\/how-to-call-azure-endpoint-rest-api-from-model-gen",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I have tried visual studio 2019 model builder for object detection. I have followed a tutorial about stop sign image object detection which will use Azure for training. I then use the model generated to make inference. So far everything is working fine. I can genereate web api too which will use json input { &quot;ImageSource&quot;: &quot;path to local image&quot; } and this works too.  <\/p>\n<p>Now the problem is I am trying not to use my local cpu to do the inference. I want to use Azure to do the inference. And what I do is look for the experiment generated by model builder. Find the model and deploy the model to the endpoint.  <\/p>\n<p>Now when I go to the endpoint generated, there is a test tab there and I suppose that I need to supply the json for the inference. What is the json format needed since I try all of these and all of them not working:  <\/p>\n<ul>\n<li> just the url of the image file  <\/li>\n<li> use { &quot;url&quot; : &quot;url to the image&quot; }  <\/li>\n<li> use { &quot;imageSource&quot;: &quot;url to the image&quot; }  <\/li>\n<li> use { &quot;data&quot;: [ {&quot;url&quot; : &quot;url to the image&quot;} ] }  <\/li>\n<li> use { &quot;data&quot;: [ {&quot;imageSource&quot; : &quot;url to the image&quot;} ] }  <\/li>\n<\/ul>\n<p>And I can't find any documentation about the exact format of the json. And when I call rest api from postman\/insomnia it always says time out error.   <\/p>\n<p>Below is my deployment log when I try test.  <\/p>\n<p>Starting the inference  <br \/>\n\/azureml-envs\/azureml_a5cc75b048d996dfdd3ff5c7e66b85eb\/lib\/python3.7\/site-packages\/azureml\/contrib\/automl\/dnn\/vision\/common\/utils.py: since ignore_data_errors is True, file will be ignored.  <br \/>\nGot AutoMLVisionDataException as all images in the current batch are invalid. Skipping the batch.  <br \/>\nNumber of lines written to prediction file: 0  <br \/>\nTotal scoring time 0.0095 for 0 batches. Batch avg: 0.0000.   <br \/>\nMem stats scoring: {}.  <br \/>\nGPU stats scoring: {}{}.  <br \/>\nFinished inferencing.  <br \/>\n2021-07-08 04:15:27,849 | root | INFO | run() output is HTTP Response  <br \/>\n2021-07-08 04:15:27,849 | root | INFO | 200  <br \/>\n127.0.0.1 - - [08\/Jul\/2021:04:15:27 +0000] &quot;POST \/score?verbose=true HTTP\/1.0&quot; 200 0 &quot;-&quot; &quot;Go-http-client\/1.1&quot;  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Endpoint attempting to cast string parameter as an int",
        "Question_created_time":1625151488777,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459799\/azure-machine-learning-endpoint-attempting-to-cast",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,     <\/p>\n<p>I have created a an ML model in Azure ML using auto ML. This has been deployed as an endpoint using the UI.     <br \/>\nThis is a sample of the original dataset:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111244-image.png?platform=QnA\" alt=\"111244-image.png\" \/>    <\/p>\n<p>Its deployed as a container instance and the deployment state is healthy.     <\/p>\n<p>When I test the endpoint, it pre-populates the test form with some example values, for the various paratmeters which are strings and ints.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110980-image.png?platform=QnA\" alt=\"110980-image.png\" \/>    <\/p>\n<p>However, if I populate the blank fields with ints and leave the strings, .     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111051-image.png?platform=QnA\" alt=\"111051-image.png\" \/>    <\/p>\n<p>then test the service, I get an error that suggests it is trying to convert attribute13 to an int    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110994-image.png?platform=QnA\" alt=\"110994-image.png\" \/>    <\/p>\n<p>as you can see, it is fine with the productName parameter being a string, but tries to convert Attribute13 to an int.     <br \/>\nThe same happens with the other attributesXX.     <br \/>\nIf I set all the attributes to numerical values, the test completes and the endpoint returns a value from the model as expected.     <\/p>\n<p>IF i check the swagger file, it shows that the api is expecting a string:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111018-image.png?platform=QnA\" alt=\"111018-image.png\" \/>    <\/p>\n<p>So that all suggests the issue exists somewhere in the python code created automatically.     <br \/>\nThis is kinda where I get stuck - I see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local\">resources on debugging<\/a> the python code, I can see in my score.py file the example sample passes specifies these as 'object' dtypes:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111025-image.png?platform=QnA\" alt=\"111025-image.png\" \/>    <\/p>\n<p>And after that I dont know where to go from here - feels like it should just work 'out of the box' as I got to this point purely through the UI.     <\/p>\n<p>Any help greatly appreciated.     <\/p>\n<p>Steve    <\/p>",
        "Question_closed_time":1625655157923,
        "Answer_score_count":3.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>TL;DR: Don't have column names that are numerical.     <\/p>\n<p>I have discovered that if I send the attributes in the order the appear in they dataset - ignoring the order that they are named on the api, then they are all parsed to the correct type. Effectively the 3 columns named 341, 513, 514 belong at the end, but for some reason have been lined up with the wrong parameter names.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112439-image.png?platform=QnA\" alt=\"112439-image.png\" \/>    <br \/>\n(this returns expected values)    <\/p>\n<p>So i renamed the columns in my training data pandas dataframe so they are not numerical (e.g. System341, System513, System514) and re-ran the AutoML, and deployed the new model.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112552-image.png?platform=QnA\" alt=\"112552-image.png\" \/>    <\/p>\n<p>now the order of columns matches that of the dataset- and IT WORKS!     <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_created_time":1625144022410,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459776\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I would like to interact with the plots. But I got the error for  <br \/>\n%matplotlib qt  <br \/>\n:<\/p>\n<pre><code>ImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add ID column after feature selection processing in Azure ML studio",
        "Question_created_time":1625449418397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/462403\/add-id-column-after-feature-selection-processing-i",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,   <\/p>\n<p>In my dataset, i have one ID key with 100 features and target column. After using feature filtering function, i select top 50 feature for the prediction. the problem is, after i covert my experiment to predictive experiment, i still need to report final result as: id, scored label.   <\/p>\n<p>i found id column was missed in the predictive experiments and was not included in the SCORE MODLE - Probably due to feature filtering process.   <\/p>\n<p>How can i include ID column back to the final score model ?   <\/p>\n<p>thx. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"CROSS VALIDATION WITH HYPER PARAMETER TUNING IN AZURE ML NOTEBOOK USING PYTHON SDK",
        "Question_created_time":1624357454270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/446761\/cross-validation-with-hyper-parameter-tuning-in-az",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>is there any way to use cross validation in azure notebook using python sdk, while using hyperdrive config for hyper parameter tuning?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Facing problem in deplying pyhton application from github- unable to load tensorflow saved model in AZURE.",
        "Question_created_time":1625428420640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/462250\/facing-problem-in-deplying-pyhton-application-from",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to deploy a classification TensorFlow model on AZURE from GitHub. It is getting deployed correctly which can be seen from the below logs.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111656-image.png?platform=QnA\" alt=\"111656-image.png\" \/><\/p>\n<p>But I'm getting an OSError on log Stream saying saved model doesn't exist as shown below. The error msg is highlighted in red.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111560-image.png?platform=QnA\" alt=\"111560-image.png\" \/><\/p>\n<p>But this is working correctly on local. This model has been checked locally.  <br \/>\nThe repository for this can be checked at <a href=\"https:\/\/github.com\/Vikeshkr-DSP\/cassava-leaf-disease-prediction\">https:\/\/github.com\/Vikeshkr-DSP\/cassava-leaf-disease-prediction<\/a>.  <br \/>\nThanks in advance for your help.<\/p>",
        "Question_closed_time":1625582635013,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The above issue on <code>OSError: SavedModel file does not exist at: cassava_leaf.h5\/{saved_model.pbtxt|saved_model.pb}<\/code> was due to a bit large size of model and we did not provide an absolute path to the model location, the application could not find the same during startup.  <\/p>\n<p>The issue resolved by manually transferring the h5-model file to a location like \/home on the App Service and updated the app.py file to use an absolute path in order to refer the file.   <\/p>\n<p>Similar to: <code>model=load_model('\/home\/cassava_leaf.h5')<\/code>  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired",
        "Question_created_time":1625066182160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458139\/unknown-error-occurred-during-authentication-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI want to submit some training scripts and got this error. In the meantime I got the warning:  <\/p>\n<pre><code>{\n  &quot;error&quot;: {\n    &quot;code&quot;: &quot;UserError&quot;,\n    &quot;severity&quot;: null,\n    &quot;message&quot;: &quot;AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code&quot;,\n    &quot;messageFormat&quot;: &quot;{Message}&quot;,\n    &quot;messageParameters&quot;: {\n      &quot;Message&quot;: &quot;AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code&quot;\n    },\n    &quot;referenceCode&quot;: null,\n    &quot;detailsUri&quot;: null,\n    &quot;target&quot;: null,\n    &quot;details&quot;: [],\n    &quot;innerError&quot;: {\n      &quot;code&quot;: &quot;UserTrainingScriptFailed&quot;,\n      &quot;innerError&quot;: null\n    },\n    &quot;debugInfo&quot;: null,\n    &quot;additionalInfo&quot;: null\n  },\n  &quot;correlation&quot;: {\n    &quot;operation&quot;: &quot;4ce06386a423624f8db9086f4cde3909&quot;,\n    &quot;request&quot;: &quot;96625a89e839edc7&quot;\n  },\n  &quot;environment&quot;: &quot;westeurope&quot;,\n  &quot;location&quot;: &quot;westeurope&quot;,\n  &quot;time&quot;: &quot;2021-06-30T14:00:14.3853285+00:00&quot;,\n  &quot;componentName&quot;: &quot;execution-worker&quot;\n}\n<\/code><\/pre>\n<p>I run the same scripts in a compute instance and didn't get the error above. Only if I submit it to the computer cluster I get this error.   <br \/>\nRunning in the compute instance I got the following failure messages, though the codes can run till the end:  <\/p>\n<pre><code>Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0')).\n<\/code><\/pre>\n<p>Update: I changed to another conda environment and submit the scripts, still got the same error. Running in the terminal worked without any error and also without the failure messages.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Price Difference between Azure ML vs Azure VM",
        "Question_created_time":1625211332020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/460862\/price-difference-between-azure-ml-vs-azure-vm",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <br \/>\nour team is using AzureML for company's Machine Learning project.  <\/p>\n<p><strong>My question is this:<\/strong>  <\/p>\n<blockquote>\n<p>What's the <strong>price difference<\/strong> between <strong>AzureML<\/strong> and <strong>AzureVM<\/strong> when executing python script?  <\/p>\n<\/blockquote>\n<p>if we use AzureVM, we may use Azure Registry together, i think.    <\/p>\n<p>Because our team is newbie in Azure, we are unfamiliar with this price policy  <\/p>\n<p>thanks.  <\/p>",
        "Question_closed_time":1625239530937,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2088fd6d-27cc-47a6-9fa7-93bb2a8db8a2\">@\ubc15\uc601\ubbfc(Park Young Min)\/\ube44\uc804)DX\ud300  <\/a> Thank you for your query!!!    <\/p>\n<p>Depending upon your requirement there are different possibilities.    <\/p>\n<p>Now as per your statement you want to understand cost associated with Azure ML and Azure VM for running Python Script.    <\/p>\n<p>Now as such for Machine Learning on Azure the Machine Learning surcharges are free and you are only charged for series of VM you use.    <\/p>\n<p>It has been best described in example <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/machine-learning\/#purchase-options\">here<\/a>:    <\/p>\n<p>You will be billed daily. For billing purposes, a day commences at midnight UTC. Bills are generated monthly.    <\/p>\n<p>Training:    <br \/>\nAs a specific example, let\u2019s say you train a model for 100 hours using 10 DS14 v2 VMs on an Basic workspace in US West 2. For a billing month of 30 days, your bill will be as follows:    <\/p>\n<p>Azure VM Charge: (10 machines * $1.196 per machine) * 100 hours = $1,196    <\/p>\n<p>Azure Machine Learning Charge: (10 machines * 16 cores * $0 per core) * 100 hours = $0    <\/p>\n<p>Total: $1,196 + $0 = $1,196    <\/p>\n<p>Inferencing:    <br \/>\nAs a specific example, let\u2019s say you deploy a model for inferencing all day for a 30-day billing month using 10 DS14 v2 VMs in Basic in US West 2. For a billing month of 30 days, your bill will be as follows:    <\/p>\n<p>Azure VM Charge: (10 machines * $1.196 per machine) * (24 hours * 30 days) = $8,611.20    <\/p>\n<p>Azure Machine Learning Charge: (10 machines * 16 cores * $0 per core) * (24 hours * 30 days) = $0    <\/p>\n<p>Total: $8,611.20 + $0 = $8,611.20    <\/p>\n<p>This already includes the use of VM.    <\/p>\n<p>Now the other scenario you are talking about is around deployment of Python App where you might need to make use of containers and the cost associated with them which is a seperate topic.    <\/p>\n<p>Now let us come to your basic question where I do assume that you might want to explore the options available to you for running Python Script in Azure.    <\/p>\n<p>Both Azure Automation and Azure Functions support running Python scripts and do not require the creation of any VM's for same.    <\/p>\n<p>For Azure Function you can refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-functions\/functions-reference-python?tabs=application-level\">this<\/a>. and for cost you can refer to <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/functions\/\">this<\/a>.    <\/p>\n<p>For Azure Automation you can refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/automation\/learn\/automation-tutorial-runbook-textual-python2\">this<\/a>. For cost incurred for automation you can refer to <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/automation\/\">this<\/a> which mostly depends upon the Job you create.    <\/p>\n<p>Now if you check both the option they are not billed particularly for Python script you are running but more around resources being used for what time which you can have a rough estimation from Pricing calculator links mentioned in above links.    <\/p>\n<p>Further now if you want to deploy or run your Python App in Azure there are mainly 4 ways as mentioned <a href=\"https:\/\/azure.microsoft.com\/en-in\/get-started\/python\/\">here<\/a>:    <\/p>\n<ul>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/azure-functions\/create-first-function-vs-code-python\">Create a simple Python web app on Azure<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/azure-functions\/tutorial-vs-code-serverless-python\">Build and deploy a serverless Python app<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/notebooks\/use-machine-learning-services-jupyter-notebooks?toc=%2Fpython%2Fazure%2FTOC.json\">Try Azure Machine Learning scenarios in a preconfigured environment<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/python\/azure\/?view=azure-python\">See more ways to use Python on Azure<\/a>    <\/li>\n<\/ul>\n<p>You don't need to worry about the Python script incurring you charges but you can check the price of associated resource you are using basically any Azure resource here on <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/calculator\/\">Pricing Calculator<\/a> as well.    <\/p>\n<p>Hope it helps :) !!!    <\/p>\n<p>Please <strong>&quot;Accept as Answer&quot;<\/strong> if it helped so it can help others in community looking for help on similar topics.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"DPHistogram Component returns True has type <class 'numpy.bool_'>, but expected one of: (<class 'bool'>, <class 'numbers.Integral'>)",
        "Question_created_time":1620007339690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379955\/dphistogram-component-returns-true-has-type-(class",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi there,     <\/p>\n<p>I am running the below code from <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-differential-privacy\">here<\/a>  but getting a strange error, how can I fix the issue    <\/p>\n<pre><code>ages = list(range(0, 130, 10))  \nage = diabetes.Age  \nwith sn.Analysis() as analysis:  \n\tdata = sn.Dataset(path = data_path, column_names = cols)  \n\n\tage_histogram = sn.dp_histogram(  \n\t\tsn.cast(data['Age'], atomic_type='int', lower=0, upper=120),  \n\t\tedges = ages,  \n\t\tupper = 1000,  \n\t\tnull_value = -1,  \n\t\tprivacy_usage = {'epsilon': 0.5}  \n\t\t)  \n\t  \nanalysis.release()  \nplt.ylim([0,100])  \nwidth=4  \nagecat_left = [x + width for x in ages]  \nagecat_right = [x + 2*width for x in ages]  \nplt.bar(list(range(0,120,10)), n_age, width=width, color='blue', alpha=0.7, label='True')  \nplt.bar(agecat_left, age_histogram.value, width=width, color='orange', alpha=0.7, label='Private')  \nplt.legend()  \nplt.title('Histogram of Age')  \nplt.xlabel('Age')  \nplt.ylabel('Frequency')  \nplt.show()  \n\nprint(age_histogram.value)  \n<\/code><\/pre>\n<p>and the error    <\/p>\n<p>---------------------------------------------------------------------------    <\/p>\n<p>TypeError                                 Traceback (most recent call last)    <br \/>\n&lt;ipython-input-67-ed764f55a5fe&gt; in &lt;module&gt;    <br \/>\n     10         )  <br \/>\n     11   <br \/>\n---&gt; 12 analysis.release()    <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\base.py in release(self)    <br \/>\n    799         response_proto: api_pb2.ResponseRelease.Success = core_library.compute_release(  <br \/>\n    800             serialize_analysis(self),  <br \/>\n--&gt; 801             serialize_release(self.release_values),    <br \/>\n    802             self.stack_traces,  <br \/>\n    803             serialize_filter_level(self.filter_level))  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_release(release_values)    <br \/>\n    103 def serialize_release(release_values):  <br \/>\n    104     return base_pb2.Release(  <br \/>\n--&gt; 105         values={    <br \/>\n    106             component_id: serialize_release_node(release_node)  <br \/>\n    107             for component_id, release_node in release_values.items()  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in &lt;dictcomp&gt;(.0)    <br \/>\n    104     return base_pb2.Release(  <br \/>\n    105         values={  <br \/>\n--&gt; 106             component_id: serialize_release_node(release_node)    <br \/>\n    107             for component_id, release_node in release_values.items()  <br \/>\n    108             if release_node['value'] is not None  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_release_node(release_node)    <br \/>\n    112 def serialize_release_node(release_node):  <br \/>\n    113     return base_pb2.ReleaseNode(  <br \/>\n--&gt; 114         value=serialize_value(    <br \/>\n    115             release_node['value'],  <br \/>\n    116             release_node.get(&quot;value_format&quot;)),  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_value(value, value_format)    <br \/>\n    210         array=value_pb2.Array(  <br \/>\n    211             shape=list(array.shape),  <br \/>\n--&gt; 212             flattened=serialize_array1d(array.flatten())    <br \/>\n    213         ))  <br \/>\n    214   <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_array1d(array)    <br \/>\n    152   <br \/>\n    153     return value_pb2.Array1d(**{  <br \/>\n--&gt; 154         data_type: container_type(data=list(array))    <br \/>\n    155     })  <br \/>\n    156   <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py in init(self, **kwargs)    <br \/>\n    551             field_value = [_GetIntegerEnumValue(field.enum_type, val)  <br \/>\n    552                            for val in field_value]  <br \/>\n--&gt; 553           copy.extend(field_value)    <br \/>\n    554         self._fields[field] = copy  <br \/>\n    555       elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in extend(self, elem_seq)    <br \/>\n    283       raise  <br \/>\n    284   <br \/>\n--&gt; 285     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]    <br \/>\n    286     if new_values:  <br \/>\n    287       self._values.extend(new_values)  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in &lt;listcomp&gt;(.0)    <br \/>\n    283       raise  <br \/>\n    284   <br \/>\n--&gt; 285     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]    <br \/>\n    286     if new_values:  <br \/>\n    287       self._values.extend(new_values)  <\/p>\n<p>~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py in CheckValue(self, proposed_value)    <br \/>\n    135       message = ('%.1024r has type %s, but expected one of: %s' %  <br \/>\n    136                  (proposed_value, type(proposed_value), self._acceptable_types))  <br \/>\n--&gt; 137       raise TypeError(message)    <br \/>\n    138     # Some field types(float, double and bool) accept other types, must  <br \/>\n    139     # convert to the correct type in such cases.  <\/p>\n<p>TypeError: True has type &lt;class 'numpy.bool_'&gt;, but expected one of: (&lt;class 'bool'&gt;, &lt;class 'numbers.Integral'&gt;)    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hyperparameter search with HyperDriveConfig for ReinforcementLearningEstimator",
        "Question_created_time":1624459443980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/448819\/hyperparameter-search-with-hyperdriveconfig-for-re",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,   <\/p>\n<p>I would like to automatize Hyperparameter search for my Reinforcement Learning training jobs.  <br \/>\nIn my understanding the workflow can be written as  <\/p>\n<pre><code>training_estimator = rl.ReinforcementLearningEstimator(\n        source_directory='.\/src',\n        entry_script=entry_script,\n        script_params=script_params,\n        compute_target=compute_target,\n        rl_framework=rl.Ray(),\n        environment=env_settings)\n\n    grid_sampling = hyperdrive.GridParameterSampling(parameter_space={'lr': hyperdrive.choice([0.007, 0.005])})\n\n    hd_config = hyperdrive.HyperDriveConfig(estimator=training_estimator,\n                                            hyperparameter_sampling=grid_sampling,\n                                            policy=early_termination_policy,\n                                            primary_metric_name=&quot;episode_reward_mean&quot;,\n                                            primary_metric_goal=hyperdrive.PrimaryMetricGoal.MAXIMIZE,\n                                            max_total_runs=100,\n                                            max_concurrent_runs=4)\n\n    run = exp.submit(hd_config)\n<\/code><\/pre>\n<p>However, this gets rejected because <code>ReinforcementLearningEstimator<\/code> does not implement <code>MMLBaseEstimator<\/code>.  <\/p>\n<p>Is there any trick that I'm missing or this use case isn't supported by Azure?  <\/p>\n<p><strong>EDIT:<\/strong>  <\/p>\n<p>This code fails with the following error message  <\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;hyperdriverun.py&quot;, line 188, in &lt;module&gt;\n    run = exp.submit(hd_config)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/core\/experiment.py&quot;, line 220, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 145, in search\n    telemetry_values, activity_logger, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 38, in _create_experiment_dto\n    platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 672, in _get_platform_config\n    platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 684, in _get_platform_config_data_from_run_config\n    run_config = get_run_config_from_script_run(self.estimator._get_script_run_config())\nAttributeError: 'ReinforcementLearningEstimator' object has no attribute '_get_script_run_config'\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to save and load ML model with Azure Data Factory",
        "Question_created_time":1623657811393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/434449\/how-to-save-and-load-ml-model-with-azure-data-fact",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an Azure Data factory that receives data from a service bus and then I want to classify my data with an ML model.  <\/p>\n<p>Is there any solution to save and load the ML model on the Azure Data Factory pipeline?  <\/p>\n<p>For your information, I want to use cloud base solution. I don't use the PICKLE library. <\/p>",
        "Question_closed_time":1623860467257,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=b5c4f434-7ffe-0003-0000-000000000000\">@Mohsen Akhavan  <\/a>,    <br \/>\nThanks for the ask and using the Microsoft Q&amp;A platform  .    <\/p>\n<p>I think you can use the machine learning activity . Read and watch the video <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/transform-data-machine-learning-service\">here<\/a> .    <\/p>\n<p>The challenge in your case is the data is in EH and at this time ADF cannot read EH data . I suggest you to use a Azure stream analytics jobs and read the data from EH and write it to SQL or blob . Once the data is in any of these two sources ADF can be used to read the data .    <\/p>\n<p>Please do let me know how it goes .    <br \/>\nThanks     <br \/>\nHimanshu    <br \/>\nPlease do consider clicking on <strong>&quot;Accept Answer&quot;<\/strong> and <strong>&quot;Up-vote&quot;<\/strong> on the post that helps you, as it can be beneficial to other community members    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can i automate ML training?",
        "Question_created_time":1624953599093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/455797\/can-i-automate-ml-training",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hello,  <\/p>\n<p>Can i automate the procedure of training a machine learning model in Azure Machine Learning Studio and add a trigger to initiate all this?  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy model on AKS ModuleNotFoundError: No module named 'main'",
        "Question_created_time":1624613802117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/451760\/deploy-model-on-aks-modulenotfounderror-no-module",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>When trying to deploy a model on AKS an error occurs.  <br \/>\nThe traceback is the following:  <br \/>\nException in worker process  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker  <br \/>\nworker.init_process()  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process  <br \/>\nself.load_wsgi()  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi  <br \/>\nself.wsgi = self.app.wsgi()  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi  <br \/>\nself.callable = self.load()  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load  <br \/>\nreturn self.load_wsgiapp()  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp  <br \/>\nreturn util.import_app(self.app_uri)  <br \/>\nFile &quot;\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app  <br \/>\n<strong>import<\/strong>(module)  <br \/>\nFile &quot;\/var\/azureml-server\/entry.py&quot;, line 1, in &lt;module&gt;  <br \/>\nimport create_app  <br \/>\nFile &quot;\/var\/azureml-server\/create_app.py&quot;, line 4, in &lt;module&gt;  <br \/>\nfrom routes_common import main  <br \/>\nFile &quot;\/var\/azureml-server\/routes_common.py&quot;, line 32, in &lt;module&gt;  <br \/>\nfrom aml_blueprint import AMLBlueprint  <br \/>\nFile &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 29, in &lt;module&gt;  <br \/>\nimport main  <br \/>\nModuleNotFoundError: No module named 'main'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Timeout on AutoMLConfig is not a hard timeout",
        "Question_created_time":1624927301677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/455257\/timeout-on-automlconfig-is-not-a-hard-timeout",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>When setting the timeout on the AutoMLConfig, it is not respected. Why?     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110022-screenshot-2021-06-28-at-214112.png?platform=QnA\" alt=\"110022-screenshot-2021-06-28-at-214112.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110031-screenshot-2021-06-28-at-212944.png?platform=QnA\" alt=\"110031-screenshot-2021-06-28-at-212944.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Pipeline deployment",
        "Question_created_time":1625044229433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/457784\/azure-ml-pipeline-deployment",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there,  <\/p>\n<p>What is the method to deploy a specific Experiment Run of Azure ML Pipeline from Experiment tab?  <\/p>\n<p>Thanks,  <br \/>\nHamsini Sharma<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to read csv file(already registered in azureblobstore) as pandas DataFrame in score.py?",
        "Question_created_time":1625061831393,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458181\/how-to-read-csv-file(already-registered-in-azurebl",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am creating a ACI web service in azureml where I need to include a csv file (which I have registered in azureblobstore) in the score.py file. I have tried &quot;Dataset.get_by_name(ws,'dataset_name', version='latest')&quot; which is working fine in my local machine but getting error while deploying as web service.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Memoy Error during batch teste in Azure ML Studio",
        "Question_created_time":1624966131983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/456139\/memoy-error-during-batch-teste-in-azure-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello guys,  <\/p>\n<p>I am using Azure ML Studio to build a multiclassification model based on decision forest.  <br \/>\nNow, I am trying to predict new samples using Excel batch test, however I am getting  the error :&quot;OutOfMemoryLimit&quot;,&quot;message&quot;:&quot;The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.&quot;  <\/p>\n<p>This message is appearing even without running with new data, only with sample data generated by the Azure itself.  <\/p>\n<p>How Can I fix that? I have a standard account.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to create pyspark DataFrame from Datastore in azureml-sdk (version 1.12.0)",
        "Question_created_time":1602510230157,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123772\/unable-to-create-pyspark-dataframe-from-datastore",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to read contents from a CSV file into Spark DataFrame using azureml-sdk using following code but an exception is being thrown.  <\/p>\n<p><strong>Code throwing exception<\/strong>  <\/p>\n<pre><code>import pyspark.sql as spark\nfrom azureml.core import Dataset\ndataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\nsdf: spark.DataFrame = dataset.to_spark_dataframe()\nsdf.show()\n<\/code><\/pre>\n<p><strong>Exception<\/strong>  <\/p>\n<pre><code>---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n    100         else:\n--&gt; 101             return action()\n    102     except Exception as e:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_loggerfactory.py in wrapper(*args, **kwargs)\n    178                 try:\n--&gt; 179                     return func(*args, **kwargs)\n    180                 except Exception as e:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/dataflow.py in to_spark_dataframe(self)\n    763         self._raise_if_missing_secrets()\n--&gt; 764         return self._spark_executor.get_dataframe(steps_to_block_datas(self._steps), use_sampling=False)\n    765 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in get_dataframe(self, steps, use_sampling, overrides, use_first_record_schema)\n    136                              overrides,\n--&gt; 137                              use_first_record_schema)\n    138 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n    169                                           + lariat_version + '.')\n--&gt; 170             raise e\n    171 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n    160             if export_format == ExportScriptFormat.PYSPARKDATAFRAMELOADER:\n--&gt; 161                 return module.LoadData(secrets=secrets, schemaFromFirstRecord=use_first_record_schema)\n    162             else:\n\n\/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/loaderb9bc01c2b40c4b7aa86a95d343021e0c.py in LoadData(secrets, schemaFromFirstRecord)\n      8 def LoadData(secrets=dict(), schemaFromFirstRecord=False):\n----&gt; 9     pex = Executor(&quot;S4ddf53ee8d5f4173bd3dcf4b51d78247&quot;, &quot;dprep_2.11&quot;, &quot;0.116.0&quot;, &quot;42315&quot;, &quot;39a925e4-9ae9-4588-93c4-5433250b7f73&quot;)\n     10     jex = pex.jex\n\n\/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/Executor.py in __init__(self, scalaName, dprepMavenPackageName, dprepMavenPackageMatchingVersion, pythonHostChannelPort, pythonHostSecret)\n     54             pythonHostChannelPort,\n---&gt; 55             pythonHostSecret)\n     56 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/java_gateway.py in __call__(self, *args)\n   1568         return_value = get_return_value(\n-&gt; 1569             answer, self._gateway_client, None, self._fqn)\n   1570 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     &quot;An error occurred while calling {0}{1}{2}.\\n&quot;.\n--&gt; 328                     format(target_id, &quot;.&quot;, name), value)\n    329             else:\n\nPy4JJavaError: An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n: java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n    at com.microsoft.dprep.execution.PySparkExecutor.&lt;init&gt;(PySparkExecutor.scala:79)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:238)\n    at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n    at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\nAzureMLException                          Traceback (most recent call last)\n&lt;ipython-input-30-c546b1aded42&gt; in &lt;module&gt;\n      2 from azureml.core import Dataset\n      3 dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n----&gt; 4 sdf: spark.DataFrame = dataset.to_spark_dataframe()\n      5 sdf.show()\n      6 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n    124             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    125                 try:\n--&gt; 126                     return func(*args, **kwargs)\n    127                 except Exception as e:\n    128                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/tabular_dataset.py in to_spark_dataframe(self)\n    187         return _try_execute(dataflow.to_spark_dataframe,\n    188                             'to_spark_dataframe',\n--&gt; 189                             None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    190 \n    191     @track(_get_logger, custom_dimensions={'app_name': 'TabularDataset'}, activity_type=_PUBLIC_API)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n    102     except Exception as e:\n    103         message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n--&gt; 104         _dataprep_error_handler(e, message, is_dprep_exception)\n    105 \n    106 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _dataprep_error_handler(e, message, is_dprep_exception)\n    143         raise AzureMLException(message, inner_exception=e)\n    144     else:\n--&gt; 145         raise AzureMLException(message, inner_exception=e)\n    146 \n    147 \n\nAzureMLException: AzureMLException:\n    Message: Execution failed unexpectedly due to: Py4JJavaError\n    InnerException An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n: java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n    at com.microsoft.dprep.execution.PySparkExecutor.&lt;init&gt;(PySparkExecutor.scala:79)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:238)\n    at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n    at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Execution failed unexpectedly due to: Py4JJavaError&quot;\n    }\n}\n<\/code><\/pre>\n<p>However, I can read and print the data with the following code i.e. create as a Panda's DataFrame.  <\/p>\n<p><strong>Working code<\/strong>  <\/p>\n<pre><code>dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n#sdf: spark.DataFrame = dataset.to_spark_dataframe()\nsdf: pd.DataFrame = dataset.to_pandas_dataframe()\nprint(sdf.head(3))\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Model Profiling",
        "Question_created_time":1623937967690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/440711\/azure-ml-model-profiling",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I have a model already deployed on AzureML using AKS. Now i want to use the same model for Model Profiling so that we can set up an auto-scaler. But Model Profiling throws an error every time.  <\/p>\n<p>ERROR: UserWarning: Model Profiling operation failed with the following error: Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed.  <\/p>\n<p>It says there is some problem in the init() function. But the same model is deployed on AKS.   <\/p>\n<p>And sometimes it shows an error is in the run() function.  <\/p>\n<p>ERROR: Too many scoring request failures experienced while testing the model.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML (Designer): Endpoint deploys initially, but can't consume or test it after that.",
        "Question_created_time":1624896031587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/454914\/azure-ml-(designer)-endpoint-deploys-initially-but",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,     <\/p>\n<p>I recently deployed an Azure Machine Learning Model (Designer). I have followed <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/\">this<\/a> tutorial (but for my model). The inference pipeline looks like this:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/109810-inference-pipeline.png?platform=QnA\" alt=\"109810-inference-pipeline.png\" \/>    <\/p>\n<p>This endpoint was then deployed with the following configurations:    <\/p>\n<ul>\n<li> <strong>Compute Type<\/strong>: Azure Container Instances    <\/li>\n<li> <strong>CPU<\/strong> : 2    <\/li>\n<li> <strong>Memory<\/strong>: 2 Gb    <\/li>\n<\/ul>\n<p>From my understanding, when a model-endpoint is deployed initially, there is a test run (which tries to consume the endpoint) that is automatically run by Azure ML, and this has always worked for me (I have tried AKS too, and ACI with lower compute power). Attached, please find the logs.     <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/109955-initial-test-endpoint.txt?platform=QnA\">109955-initial-test-endpoint.txt<\/a>    <\/p>\n<p>After the test run, I can either <em>test<\/em> it from the interface itself, or I can execute some Python code (which Azure ML provides) that can <em>consume<\/em> it for me. In both cases, I get a 500-Bad Gateway error (checked through Deployment Logs):    <br \/>\n<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/109962-endpoint-test.txt?platform=QnA\">109962-endpoint-test.txt<\/a>    <\/p>\n<p>This is what the Python code outputs:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/109917-screenshot-2021-06-28-at-85746-pm.png?platform=QnA\" alt=\"109917-screenshot-2021-06-28-at-85746-pm.png\" \/>    <\/p>\n<p>I have monitored the status of the endpoint while I try to consume it, and it is always healthy.     <\/p>\n<p>I hope I have provided enough details. If not, please let me know what else is needed to understand the issue here. Any help is appreciated.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Attaching local computer to ML Studio and use it with Azure AutoML and Azure Designer",
        "Question_created_time":1624632132377,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/452250\/attaching-local-computer-to-ml-studio-and-use-it-w",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey there,  <\/p>\n<p>I was wondering, whether it is possible to connect your local computer as a compute target to the workspace and then access it as a compute target for AutoML and the Designer in the ML Studio (instead of a compute cluster)?  <br \/>\nI have read through the documentation and I feel like if this is possible, it is not very well-documented.  <\/p>\n<p>Thanks in advance!  <\/p>",
        "Question_closed_time":1624652423443,
        "Answer_score_count":0.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p>Hi, thanks for reaching out. You can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target#train\">local compute<\/a> for model training\/deployment including automl. However, you cannot attach it directly in Designer or ML Studio interface. You can only attach it from your local environment. Hope this helps!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Failure while loading azureml_run_type_providers",
        "Question_created_time":1599302705087,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/87272\/failure-while-loading-azureml-run-type-providers",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am running RStudio on azureml compute instance.  <\/p>\n<p>Running the test examples in vignettes used to work.  <\/p>\n<p>However, today I encountered this error:  <\/p>\n<pre><code>library(azuremlsdk)\n# current directory set to source code \n# config file in current folder &quot;config.js&quot;\nws &lt;- load_workspace_from_config() \n\nError:\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (portalocker 2.0.0 (\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages), Requirement.parse('portalocker~=1.0'), {'msal-extensions'}).\n<\/code><\/pre>\n<p>Herman  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrate Logic Apps with Machine Learning",
        "Question_created_time":1624612238463,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/451893\/integrate-logic-apps-with-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello everyone,  <\/p>\n<p>Is it possible to integrate Logic Apps with Machine Learning so that i can trigger the Logic App and then the Logic App starts a ML model training automatically?  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dataset for inference data is registered with wrong path when deployed on Kubernetes",
        "Question_created_time":1624590394283,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/451349\/dataset-for-inference-data-is-registered-with-wron",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>When model is deployed on Kubernetes with model data collection set to true, the dataset which gets registered in workspace has a wrong path.  <br \/>\nThe blob storage path where this data being collected has default in it but the path registered doesn't have default.  <\/p>\n<p>For example, actual path on storage:  <\/p>\n<pre><code>azuremlwsdev\/modeldata\/GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/default\/inputs\n<\/code><\/pre>\n<p>Path dataset is registered with:  <\/p>\n<pre><code>GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/inputs\/**\/inputs*.csv\n<\/code><\/pre>\n<p>Code inside our scoring service to init collector and use them:  <\/p>\n<pre><code>def init():    \n    global inputs_dc, prediction_dc\n    ...\n    inputs_dc = ModelDataCollector('model', designation=&quot;inputs&quot;, feature_names=feature_set.columns.values.tolist())\n    prediction_dc = ModelDataCollector('model', designation=&quot;predictions&quot;, feature_names=[&quot;score&quot;])\n\ndef run(raw_data):\n    inputs_dc.collect(X)\n    prediction_dc.collect(y_pred)\n<\/code><\/pre>\n<p>Below are the library versions being used:  <\/p>\n<pre><code>azureml-defaults==1.1.5\nazureml-monitoring==0.1.0a21\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Ambiguous error in Azure Machine Learning Designer 'Evaluate Model' Module",
        "Question_created_time":1622567822803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/418016\/ambiguous-error-in-azure-machine-learning-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I am getting the following error from the Evaluate Model module in Azure Machine Learning Designer:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/101409-screenshot-2021-06-01-at-100708-pm.png?platform=QnA\" alt=\"101409-screenshot-2021-06-01-at-100708-pm.png\" \/>    <\/p>\n<p>When I open the Assigned Data to Clusters module everything seems fine. I downloaded the output for Assigned Data to Clusters and played with cluster number 31 and there doesn't seem to be any issue. Additionally, I am using Azure Modules, so I am confused as to why this is failing. Please provide some clarity into this issue. This is a part of my pipeline:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/101399-screenshot-2021-06-01-at-104512-pm.png?platform=QnA\" alt=\"101399-screenshot-2021-06-01-at-104512-pm.png\" \/>    <\/p>\n<p>Additionally, it seems unless I successfully run the Evaluate Model module, I cannot create an inference pipeline. If this is untrue, please help me out here as well. There is no option for me to 'Create an Inference Pipeline' which shown in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">this tutorial; step 1.<\/a>    <\/p>\n<p>Please let me know if you need any other information.    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Question_closed_time":1623450957477,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Can you please check if the Assignment cluster 31 has NaN value? The <strong>Assign Data to Clusters<\/strong> leverages SKlearn, and from the error message, seems the Assignment column had NaN value which resulted in an error. If that's the case, let us know, so we can enable <strong>Evaluate<\/strong> Module module to deal with NaN values, and in the meantime, here's a short-term workaround:    <\/p>\n<ul>\n<li> Connect <strong>Clean Missing Data<\/strong> module to Assign Data to Cluster module, to clean the missing values.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104943-image.png?platform=QnA\" alt=\"104943-image.png\" \/>    <\/li>\n<li> Use <strong>Edit Metadata<\/strong> module to convert Assignment to Integer and categorical type, this is because if Assignment column has NaN value before and its column type was double, we need to convert it to integer.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104888-image.png?platform=QnA\" alt=\"104888-image.png\" \/>    <\/li>\n<li> Connect <strong>Edit Metadata<\/strong> to Evaluate Model module.    <\/li>\n<\/ul>\n<p>Hope this help!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Has Anyone Been Able to Successfully Parallelize Their Code on a VM?",
        "Question_created_time":1618799484800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361772\/has-anyone-been-able-to-successfully-parallelize-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I wrote a script to train a large number of time series models on my Azure VM and it uses the multiprocessing.Pool package to parallelize the code to reduce the training time period.  The code runs perfectly on my local machine, but does not parallelize across the available cores when I run the script on my Azure VM.  If anyone has run into this problem with the Pool package or has alternate suggestions as to how to parallelize training on a VM, I'd appreciate your insight.  Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"why I do not have \"Open in a new Notebook\" in my menu",
        "Question_created_time":1624421404470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/447926\/why-i-do-not-have-open-in-a-new-notebook-in-my-men",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I tried Azure machine learning workspace and I try to use 'right click' -&gt; 'CSV dataset' -&gt; There is no &quot;Open in a new Notebook&quot; in the menu, even a grey one. Could someone please guide me? Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where to Report Issues with Azure ML Command Line",
        "Question_created_time":1619791289953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/378845\/where-to-report-issues-with-azure-ml-command-line",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I am using az ml command line and finding several broken pieces of functionality. How do I report these broken  features to the team that maintains the az ml command line tools?  <\/p>\n<p>Example:  <\/p>\n<pre><code>PS C:\\projects\\Lead-Score-POC&gt; az ml dataset show --id 154c7483-bc04-43b5-a614-3d278e211111\nMissing required package &quot;azureml-dataset-runtime&quot;, which is unavailable for 32bit Python.\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The columns appears with another name",
        "Question_created_time":1624312518567,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/445579\/the-columns-appears-with-another-name",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hello I'm practicing in Microsoft Machine Learning Studio.    <\/p>\n<p>In a experiment I use de control &quot;Import data&quot;, then in the properties I use the data source: <a href=\"https:\/\/github.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/blob\/master\/modulo-2\/power-export_min.csv\">https:\/\/github.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/blob\/master\/modulo-2\/power-export_min.csv<\/a>    <\/p>\n<p>That is the file to practice in my course.    <\/p>\n<p>The resto of the fields are filled like this:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/107720-image.png?platform=QnA\" alt=\"107720-image.png\" \/>    <\/p>\n<p>But, when I use the choice visualize, appears like this:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/107744-image.png?platform=QnA\" alt=\"107744-image.png\" \/>    <\/p>\n<p>But, those are not the names of the columns.    <br \/>\nWhat I'm doing wrong?    <\/p>\n<p>Thanks a lot for your help.<\/p>",
        "Question_closed_time":1624383647527,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=12e650b3-31a2-48d9-b48f-0bd109b119b7\">@CASTANEDA RODRIGUEZ, DAMIAN  <\/a> Hello, I got you! Please click &quot;raw&quot; and use the url then to use the resource file. <a href=\"https:\/\/raw.githubusercontent.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/master\/modulo-2\/power-export_min.csv\">https:\/\/raw.githubusercontent.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/master\/modulo-2\/power-export_min.csv<\/a>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/108210-image.png?platform=QnA\" alt=\"108210-image.png\" \/>    <\/p>\n<p>Then you should be good! Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?",
        "Question_created_time":1624431973167,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/448224\/while-registering-a-dataframe-in-azureml-pipeline",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?  <\/p>\n<p>Code snippet-  <\/p>\n<p>&lt;DataFrame&gt;.register(workspace=ws, name='&lt;abc&gt;', description='&lt;abc&gt;', tags = {'format':'CSV'}, create_new_version=True)  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Not exporting to RunHistory as the exporter is either stopped or there is no data",
        "Question_created_time":1624366258553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/446927\/not-exporting-to-runhistory-as-the-exporter-is-eit",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Everyone!  <\/p>\n<p>I'm new in Azure ML and I am getting a error message that I wasn't able to solve.  <br \/>\nI got the following message &quot;Not exporting to RunHistory as the exporter is either stopped or there is no data.&quot;  <br \/>\nThe instance compute is on anb the dataset was added in the Azure ML  <\/p>\n<p>Follow the script :  <\/p>\n<blockquote>\n<p>1\/06\/22 12:21:47 Starting App Insight Logger for task:  runTaskLet  <br \/>\n2021\/06\/22 12:21:47 Version: 3.0.01622.0001 Branch: .SourceBranch Commit: 1141612  <br \/>\n2021\/06\/22 12:21:47 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info<\/a>  <br \/>\n2021\/06\/22 12:21:47 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status<\/a>  <br \/>\n[2021-06-22T12:21:47.687869] Entering context manager injector.  <br \/>\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['training\/train_aml.py', '--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani'])  <br \/>\nScript type = None  <br \/>\n[2021-06-22T12:21:48.081067] Entering Run History Context Manager.  <br \/>\n[2021-06-22T12:21:48.983332] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/wd\/azureml\/53814dea-db07-448f-820a-1f3bc510c581  <br \/>\n[2021-06-22T12:21:48.983550] Preparing to call script [training\/train_aml.py] with arguments:['--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani']  <br \/>\n[2021-06-22T12:21:48.983571] After variable expansion, calling script [training\/train_aml.py] with arguments:['--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani']  <\/p>\n<p>Running train_aml.py  <br \/>\nArgument [model_name]: prjVerzani_model.pkl  <br \/>\nArgument [step_output]: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data  <br \/>\nArgument [dataset_version]: latest  <br \/>\nArgument [data_file_path]: none  <br \/>\nArgument [caller_run_id]: none  <br \/>\nArgument [dataset_name]: verzani  <br \/>\nGetting training parameters  <br \/>\nParameters: {'n_estimators': 100, 'max_depth': 3, 'warm_start': True, 'random_state': 42}  <br \/>\n2021\/06\/22 12:21:52 Not exporting to RunHistory as the exporter is either stopped or there is no data.  <br \/>\nStopped: false  <br \/>\nOriginalData: 1  <br \/>\nFilteredData: 0.  <br \/>\nbash: line 1:   115 Killed                  \/azureml-envs\/azureml_ebb66c9c8565cab685eeed5fbcc8b544\/bin\/python $AZ_BATCHAI_JOB_TEMP\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/azureml-setup\/context_manager_injector.py &quot;-i&quot; &quot;ProjectPythonPath:context_managers.ProjectPythonPath&quot; &quot;-i&quot; &quot;RunHistory:context_managers.RunHistory&quot; &quot;-i&quot; &quot;TrackUserError:context_managers.TrackUserError&quot; &quot;training\/train_aml.py&quot; &quot;--model_name&quot; &quot;$AML_PARAMETER_model_name&quot; &quot;--step_output&quot; &quot;$AZUREML_DATAREFERENCE_pipeline_data&quot; &quot;--dataset_version&quot; &quot;$AML_PARAMETER_dataset_version&quot; &quot;--data_file_path&quot; &quot;$AML_PARAMETER_data_file_path&quot; &quot;--caller_run_id&quot; &quot;$AML_PARAMETER_caller_run_id&quot; &quot;--dataset_name&quot; &quot;verzani&quot;  <br \/>\n2021\/06\/22 12:22:11 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/ff9b58ce-7857-4d95-87be-5f16c783b667\/job-1\/53814dea-db07-448f-8_f9045680-fd73-4e1d-b941-e0b1eefbf3cb\/wd\/runTaskLetTask_error.json  <br \/>\n2021\/06\/22 12:22:11 Wrapper cmd failed with err: exit status 137  <br \/>\n2021\/06\/22 12:22:11 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status<\/a>  <br \/>\n2021\/06\/22 12:22:11 mpirun version string: {  <br \/>\nIntel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)  <br \/>\nCopyright 2003-2018 Intel Corporation.  <br \/>\n}  <br \/>\n2021\/06\/22 12:22:11 MPI publisher: intel ; version: 2018  <br \/>\n2021\/06\/22 12:22:11 Not exporting to RunHistory as the exporter is either stopped or there is no data.  <br \/>\nStopped: false  <br \/>\nOriginalData: 2  <br \/>\nFilteredData: 0.  <br \/>\n2021\/06\/22 12:22:11 Process Exiting with Code:  137  <br \/>\n2021\/06\/22 12:22:11 All App Insights Logs was send successfully  <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"StreamAccessException was caused by UnexpectedException. Too many open files in system",
        "Question_created_time":1602352746733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/122455\/streamaccessexception-was-caused-by-unexpectedexce",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have the ADLSGen2 registered as a DataStore and trying to access the excel data from one of its folders from the Notebook. Following is the code  <\/p>\n<pre><code>from azureml.data.datapath import DataPath\nfrom azureml.data.data_reference import DataReference\nfrom azureml.core import Workspace, Datastore, Dataset\n\nws = get_ws()\ndstore_name = 'ssss_aravind_store'\n\naravind_dstore = Datastore.get(ws, dstore_name)\n\nraw_input_path = DataReference(\n    datastore=aravind_dstore, \n    data_reference_name='ticket_raw_data_ref',\n    path_on_datastore='semi-structured\/ticket-incident-emails\/raw_input_data_eng.xlsx')\nprint('Raw DataReference:', raw_input_path)\n\nparent_keywords_path = DataReference(\n    datastore=aravind_dstore, \n    data_reference_name='parent_keywords_data_ref',\n    path_on_datastore='semi-structured\/ticket-incident-emails\/parent_keywords.xlsx')\nprint('Parent Keywords DataReference:', parent_keywords_path)\n\nthird_level_keywords_path = DataReference(\n    datastore=aravind_dstore, \n    data_reference_name='parent_keywords_data_ref',\n    path_on_datastore='semi-structured\/ticket-incident-emails\/third_level_keywords.xlsx')\nprint('3rd Level Keywords DataReference:', third_level_keywords_path)\n\ncleaned_data_path = DataReference(\n    datastore=aravind_dstore, \n    data_reference_name='ticket_phase1_data_ref',\n    path_on_datastore='semi-structured\/ticket-incident-emails\/phase1_op_dummy_data.xlsx')\nprint('Cleaned DataReference:', cleaned_data_path)\n\nraw_dset = Dataset.from_excel_files(raw_input_path, sheet_name= 'data', use_column_headers=True, infer_column_types=True)\nparent_kwords_dset = Dataset.from_excel_files(parent_keywords_path, sheet_name= 'New_keywords', use_column_headers=True, infer_column_types=True)\nlevel3_kwords_dset = Dataset.from_excel_files(third_level_keywords_path,  use_column_headers=True, infer_column_types=True)\ncleaned_dset = Dataset.from_excel_files(cleaned_data_path, sheet_name= 'phase1_op', use_column_headers=True, infer_column_types=True)\n<\/code><\/pre>\n<p><strong>Error<\/strong>  <\/p>\n<pre><code>---------------------------------------------------------------------------\nExecutionError                            Traceback (most recent call last)\n&lt;ipython-input-22-c4226f154137&gt; in &lt;module&gt;\n     44 # from_excel_files(path, sheet_name=None, use_column_headers=False, skip_rows=0, include_path=False, infer_column_types=True,\n     45 # partition_format=None)\n---&gt; 46 raw_dset = Dataset.from_excel_files(raw_input_path, sheet_name= 'data', use_column_headers=True, infer_column_types=True)\n     47 parent_kwords_dset = Dataset.from_excel_files(parent_keywords_path, sheet_name= 'New_keywords', use_column_headers=True, infer_column_types=True)\n     48 level3_kwords_dset = Dataset.from_excel_files(third_level_keywords_path,  use_column_headers=True, infer_column_types=True)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_deprecation.py in wrapper(*args, **kwargs)\n     20                 _warn_deprecation(target, replacement)  # only raise warning for top-level invocation\n     21                 _warning_silenced_for = target\n---&gt; 22             result = func(*args, **kwargs)\n     23             if _warning_silenced_for == target:\n     24                 _warning_silenced_for = None\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n    124             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    125                 try:\n--&gt; 126                     return func(*args, **kwargs)\n    127                 except Exception as e:\n    128                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/dataset.py in from_excel_files(path, sheet_name, use_column_headers, skip_rows, include_path, infer_column_types, partition_format)\n    661             include_path,\n    662             infer_column_types,\n--&gt; 663             partition_format)\n    664 \n    665     @staticmethod\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_client.py in from_excel_files(path, sheet_name, use_column_headers, skip_rows, include_path, infer_column_types, partition_format)\n    810             inference_arguments = dprep.InferenceArguments(day_first=True)\n    811         dataflow = dprep.read_excel(\n--&gt; 812             path, sheet_name, use_column_headers, inference_arguments, skip_rows, include_path)\n    813         dataflow._name = sheet_name\n    814         return _DatasetClient._get_dataset_from_dataflow(\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/readers.py in read_excel(path, sheet_name, use_column_headers, inference_arguments, skip_rows, include_path, infer_column_types, verify_exists)\n    186     df = df.read_excel(sheet_name, use_column_headers, skip_rows)\n    187 \n--&gt; 188     df = _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n    189 \n    190     if verify_exists:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/readers.py in _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n     32         column_types_builder = df.builders.set_column_types()\n     33         if use_inference_arguments:\n---&gt; 34             column_types_builder.learn(inference_arguments)\n     35         else:\n     36             column_types_builder.learn()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/builders.py in learn(self, inference_arguments)\n    193             if inference_arguments is not None and not isinstance(inference_arguments, InferenceArguments):\n    194                 raise ValueError('Unexpected inference arguments. Expected instance of InferenceArguments class')\n--&gt; 195             self._conversion_candidates = self._run_type_inference(self._dataflow._get_steps())\n    196             if inference_arguments is not None:\n    197                 self._resolve_date_ambiguity(inference_arguments.day_first)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/builders.py in _run_type_inference(self, steps)\n     79             inferences = self._engine_api.infer_types_with_span_context(InferTypesWithSpanContextMessageArguments(\n     80                 blocks=steps_to_block_datas(steps),\n---&gt; 81                 span_context=to_dprep_span_context(span.get_context())\n     82             ))\n     83             return {col: _inference_info_from_result(inference) for col, inference in inferences.items()}\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py in wrapper(op_code, message, cancellation_token)\n     36             if len(changed) &gt; 0:\n     37                 engine_api_func().update_environment_variable(changed)\n---&gt; 38             return send_message_func(op_code, message, cancellation_token)\n     39 \n     40         return wrapper\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py in infer_types_with_span_context(self, message_args, cancellation_token)\n    183     @update_aml_env_vars(get_engine_api)\n    184     def infer_types_with_span_context(self, message_args: typedefinitions.InferTypesWithSpanContextMessageArguments, cancellation_token: CancellationToken = None) -&gt; Dict[str, typedefinitions.FieldInference]:\n--&gt; 185         response = self._message_channel.send_message('Engine.InferTypesWithSpanContextMessage', message_args, cancellation_token)\n    186         return {k: typedefinitions.FieldInference.from_pod(v) if v is not None else None for k, v in response.items()} if response is not None else None\n    187 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py in send_message(self, op_code, message, cancellation_token)\n    180                 response = self._read_response()\n    181                 if 'error' in response:\n--&gt; 182                     raise_engine_error(response['error'])\n    183                 elif response.get('id') == message_id:\n    184                     return response['result']\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py in raise_engine_error(error_response)\n      8     error_code = error_response['errorCode']\n      9     if 'ScriptExecution' in error_code:\n---&gt; 10         raise ExecutionError(error_response)\n     11     if 'Validation' in error_code:\n     12         raise ValidationError(error_response)\n\nExecutionError: \nError Code: ScriptExecution.StreamAccess.Unexpected\nFailed Step: 0....\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by UnexpectedException.\n    Unexpected error when attempting 'GetHttpResourceStream' for 'https:\/\/stgaccount.dfs.core.windows.net\/aravind\/semi-structured\/ticket-incident-emails\/raw_input_data_eng.xlsx'.\n      Too many open files in system\n| session_id=ff6......\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML with imbalaced dataset for multiclass classification - how to creat WEIGHT COLUMN?",
        "Question_created_time":1624309313887,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/445651\/automl-with-imbalaced-dataset-for-multiclass-class",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello Guys,   <br \/>\nI am using autoML for training purposes, however my dataset is very imbalanced.   <br \/>\nIt is a multiclass task with 5 classes and I want to minimize this effect when training.   <br \/>\nI have verified the documentation and it seems autoML support the creation of a new column with weights.   <\/p>\n<p>My doubts are: What is the range I am supposed to use? At this moment I am using 30, 40, 1.5 and 4. Can I use them? Also, for new dataset this column will not exist anymore, so how can the model understand that?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to install Detectron2 Azure ML 3.8",
        "Question_created_time":1624259210607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/444357\/unable-to-install-detectron2-azure-ml-3-8",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created a NC6_SV3 compute  <br \/>\nCreated new conda environment in terminal   <br \/>\nThis command : python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'  <br \/>\nIs giving error :   <br \/>\nERROR: Command errored out with exit status 1: \/anaconda\/envs\/darthgo\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-req-build-x6bevf0j\/setup.py'&quot;'&quot;'; <strong>file<\/strong>='&quot;'&quot;'\/tmp\/pip-req-build-x6bevf0j\/setup.py'&quot;'&quot;';f = getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(<strong>file<\/strong>) if os.path.exists(<strong>file<\/strong>) else io.StringIO('&quot;'&quot;'from setuptools import setup; setup()'&quot;'&quot;');code = f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, <strong>file<\/strong>, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-4_jvac6y\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/darthgo\/include\/python3.8\/detectron2 Check the logs for full command output.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting Authenticatin error for python script step in pipeline",
        "Question_created_time":1623207954850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/427884\/getting-authenticatin-error-for-python-script-step",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to create a azure pipeline for learning purpose. I followed the steps mentioned in this notebook:    <br \/>\n<a href=\"https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/08%20-%20Create%20a%20Pipeline.ipynb\">https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/08%20-%20Create%20a%20Pipeline.ipynb<\/a>    <\/p>\n<pre><code>    #%% connect to a workspace from config  \n# use service principal authentication - https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb  \n  \nazure_svppwd = os.environ.get(&quot;AZUREML_PASSWD&quot;) # use os.environ[&quot;AZUREML_PASSWD&quot;] = ' from azure service client secret&quot;  \nauth_pwd = ServicePrincipalAuthentication(  \n    tenant_id=&quot;7da05296-d70e-4398-8a3d-f113e0dad997&quot;,  \n    service_principal_id=&quot;57bac230-cbb8-409e-be64-5c4516d40771&quot;,  \n    service_principal_password=azure_svppwd)  \nws = Workspace.from_config('config',auth=auth_pwd)      \nprint(&quot;Found workspace {} at location {}&quot;.format(ws.name, ws.location))      \n# get the data from datasets  \n  \nin_data = ws.datasets.get('testparquet') # dataset is registered through Azure UI which refers to some parquet files in another container  \n  \n#%% create environment  \nenv = Environment.from_conda_specification(name='azenv',file_path='envspec.yml')  \nenv.register(ws)  # Save the environment for future use and retreival  \n#%% create compute target - compute clusters  \ntry:  \n    comp_cluster = ComputeTarget(ws,'amltryoutcluster')  \n    print('amltryoutcluster found existing and will be used')  \nexcept 'ComputeTargetException':  \n      \n    comp_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3',min_nodes=0,max_nodes=6)  \n    # vm_size in above line indicates the type of computation powe we need  \n    comp_cluster = ComputeTarget.create(ws,'amltryoutcluster',comp_config)  \n    comp_cluster.wait_for_completion(show_output=True)  \n#%% Create pipeline data object and steps  \nprep_data = PipelineData(name=&quot;pipedata&quot;,datastore=ws.get_default_datastore())  \n#%% Create pipeline steps  \n#%% pipeline configuration  \npipe_config = RunConfiguration()  \npipe_config.target = comp_cluster  \npipe_config.environment= Environment.get(ws,&quot;azenv&quot;)  \nprep_step = PythonScriptStep(name=&quot;prep&quot;,  \n                             script_name=&quot;prep_script.py&quot;,               \n                            source_directory='.\/',                  \n                             arguments=['--ipdata',in_data.as_named_input(&quot;inparquet&quot;),  \n                                        '--oppath',prep_data],  \n                             outputs=[prep_data],  \n                             compute_target = comp_cluster,  \n                             runconfig =pipe_config,  \n                             allow_reuse=True)  \ntrain_step = PythonScriptStep(name='train',  \n                              script_name='train_script.py',  \n                              source_directory='.\/',  \n                              arguments=['--prepdata',prep_data],  \n                              inputs=[prep_data],  \n                              compute_target=comp_cluster,  \n                              runconfig=pipe_config,  \n                              allow_reuse=True)  \n# get experiment and run pipeline  \n# Construct the pipeline  \npipeline_steps = [prep_step, train_step]  \npipeline = Pipeline(workspace=ws, steps=pipeline_steps,default_datastore='parquet_ingestion')  \nexp =Experiment(ws,'amltryout')  \npipeline_run = exp.submit(pipeline, regenerate_outputs=True)  \n<\/code><\/pre>\n<p>In the prep_script.py, I have the following :    <\/p>\n<pre><code>from azureml.core import Experiment,Workspace,Datastore,Dataset  \nimport pandas as pd  \nimport argparse  \nfrom azureml.core import Run  \nfrom sklearn import preprocessing  \nimport os  \n  \nparse = argparse.ArgumentParser()  \nparse.add_argument('--ipdata')  \nparse.add_argument('--oppath')  \nargs = parse.parse_args()  \nsave_folder = args.oppath  \n  \nrun = Run.get_context()  \n  \n#https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/work-with-data-in-aml\/5-using-datasets  \npqdata = run.input_datasets['inparquet'].to_pandas_dataframe()  \n# ws = run.experiment.workspace  \n# pqdata = Dataset.get_by_id(ws, id='testparquet')  \nrun.log(&quot;count&quot;,pqdata.count())  \n  \nsel_data = pqdata[['title','country','salary']]  \nstr_enc = preprocessing.LabelEncoder()  \n  \nsel_data['title','country'] = str_enc.fit_transform(sel_data['title','country'])   \n  \n  \nos.makedirs(save_folder, exist_ok=True)  \nsave_path = os.path.join(save_folder,'data_prep.csv')  \nsel_data.to_csv(save_path)  \n  \nrun.complete()  \n<\/code><\/pre>\n<p>Also some steps in train_script , but when I submit the pipeline it fails at prep step with the following error :    <\/p>\n<p><strong>Authentication failed for Container Registry: 3495c636784040b2ae0f5c8e7ee4133a.azurecr.io.<\/strong>    <\/p>\n<p>Am I missing something here?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"dataframe.corr error on execute python script",
        "Question_created_time":1623566454357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/433653\/dataframe-corr-error-on-execute-python-script",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>\u0131 want run &quot;dataframe.corr()&quot; how can \u0131 do this?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105080-ekran-goruntusu-13.png?platform=QnA\" alt=\"105080-ekran-goruntusu-13.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105161-ekran-goruntusu-14.png?platform=QnA\" alt=\"105161-ekran-goruntusu-14.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Python code deployment using Azureml and swaggee json",
        "Question_created_time":1622869038110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/423211\/python-code-deployment-using-azureml-and-swaggee-j",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hii..I am trying to deploy a model built in python using azureml-model-management-sdk package and then writing to swagger json. The python function - the model simply takes 2 inputs and give an output.   <br \/>\nBoth the inputs are string and can contain special characters like ', &quot; \/ etc. Have added the handling of such special characters in the python code itself using re. But when the inputs contain these characters in the deployment setup it gives an error saying http 400 bad request. Is there a way to allow single and double quotes in the json directly to rectify this issue. Have searched all over the internet but haven't found a solution for the same. Please help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Transforming the Data Columns of Imported Data from Cosmos DB",
        "Question_created_time":1623844869557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/438667\/transforming-the-data-columns-of-imported-data-fro",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <br \/>\nI store edge device data to Cosmos DB and in Azure ML the Import Data shows the data as     <br \/>\nTimestamp, Name, Value and for each timestamp there are as many rows as there are parameters as shown in this snapshot <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/106157-ds.jpg?platform=QnA\" alt=\"106157-ds.jpg\" \/>    <\/p>\n<p>I suppose for downstream processing in Azure ML, I need to transform the data as 1 Row for each Timestamp and parameters as Column     <br \/>\nTimestamp parameter1 para2 para3    <br \/>\n12:23:23       3.2             3.4      2    <br \/>\n12:23:24   .......    <\/p>\n<p>is that Right ?     <br \/>\nis yes, how to transform data in Azure ML    <br \/>\nI tried Import Data -&gt; Convert to Dataset -&gt;sql transformation and wrote a sql query     <\/p>\n<p>select ts,    <br \/>\n       max(case when nm = 'parameter1' then vl end) as parameter1,  <br \/>\n       max(case when nm = 'parameter2' then vl end) as parameter2,  <br \/>\n       max(case when nm = 'parameter3' then vl end) as parameter3  <br \/>\nfrom t1    <br \/>\ngroup by ts    <\/p>\n<p>This works fine, but i cannot hard code the parameter name as they will vary for each model    <\/p>\n<p>So is my approach right ? or is there better way of doing this ?    <br \/>\nif this is approach, what should be sql query so it can handle any parameter name ?    <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"FeaturizationConfig() not working",
        "Question_created_time":1623985200440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/441498\/featurizationconfig()-not-working",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am trying to implement FeaturizationConfig() . My dataset has 30+ columns and the featurization:'auto' works fine. But I want to specify the imputer type and column purpose.     <\/p>\n<pre><code>ftrzn = FeaturizationConfig()  \nftrzn.add_column_purpose('Industry', 'CategoricalHash')  # --&gt; Doesnt work  \n# ftrzn.add_column_purpose('OpportunityName', 'CategoricalHash')   --&gt; Doesnt work  \n# ftrzn.blocked_transformers = ['CatImputer', 'Imputer']  \n# Fill missing values in the target column, Quantity, with zeros.  \nftrzn.add_transformer_params('Imputer', ['SFDC_ACV_GP'] , {&quot;strategy&quot;: &quot;constant&quot;, &quot;fill_value&quot;: 0})  \n  \nautoml_settings = {  \n    &quot;iteration_timeout_minutes&quot;: 70,  \n    &quot;enable_early_stopping&quot;: True,  \n    &quot;primary_metric&quot;: 'accuracy',  \n    &quot;featurization&quot;: ftrzn,  \n    &quot;verbosity&quot;: logging.ERROR,  \n    # &quot;n_cross_validations&quot;: 2,  \n}  \n  \n# Specify training data an d type of model  \nautoml_config = AutoMLConfig(task='classification',  \n                              debug_log='automated_ml_errors.log',  \n                              training_data=dataTrainingA,  \n                              validation_data=dataTestingA,  \n                              label_column_name='win',  \n                              **automl_settings)  \n  \n  \nThis is my code, and it gives me the following error:  \n\nErrorResponseException                    Traceback (most recent call last)  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)  \n    588             else:  \n--&gt; 589                 return self._call_api(func, *args_list, **kwargs)  \n    590         except ErrorResponseException as e:  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)  \n    244             else:  \n--&gt; 245                 return self._execute_with_base_arguments(func, *args, **kwargs)  \n    246   \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)  \n    333         return ClientBase._execute_func_internal(  \n--&gt; 334             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)  \n    335   \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)  \n    366             except Exception as error:  \n--&gt; 367                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)  \n    368   \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)  \n    425             elif error.response.status_code &lt; 500 and error.response.status_code != 408:  \n--&gt; 426                 raise error  \n    427         elif isinstance(error, ClientRequestError):  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)  \n    357                 logger.debug(&quot;ClientBase: Calling {} with url {}&quot;.format(func_name, func_url))  \n--&gt; 358                 response = func(*args, **kwargs)  \n    359                 if (isinstance(response, Response) and cls._is_retryable_status_code(response.status_code) and  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/operations\/jasmine_operations.py in create_parent_run_method(self, subscription_id, resource_group_name, workspace_name, experiment_id, create_parent_run_dto, custom_headers, raw, **operation_config)  \n    310         if response.status_code not in [200]:  \n--&gt; 311             raise models.ErrorResponseException(self._deserialize, response)  \n    312   \n  \nErrorResponseException: (UserError) Feature Engineering Customization: Feature is not available for requested compute target: Local  \n  \nDuring handling of the above exception, another exception occurred:  \n  \nServiceException                          Traceback (most recent call last)  \n&lt;ipython-input-17-650bbcc7b694&gt; in &lt;module&gt;  \n      2 experiment_name = 'test-auto-3'  \n      3 exp = Experiment(workspace=ws, name=experiment_name)  \n----&gt; 4 local_run = exp.submit(automl_config, show_output=True)  \n      5 # https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-models  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py in submit(self, config, tags, **kwargs)  \n    218         submit_func = get_experiment_submit(config)  \n    219         with self._log_context(&quot;submit config {}&quot;.format(config.__class__.__name__)):  \n--&gt; 220             run = submit_func(config, self.workspace, self.name, **kwargs)  \n    221         if tags is not None:  \n    222             run.set_tags(tags)  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _automl_static_submit(automl_config_object, workspace, experiment_name, **kwargs)  \n    105             compute_target,  \n    106             parent_run_id,  \n--&gt; 107             show_output)  \n    108   \n    109         automl_run.add_properties(global_tracking_info_registry.gather_all(settings.path))  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _start_execution(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)  \n    209                 ignored_dependencies=package_utilities._PACKAGES_TO_IGNORE_VERSIONS  \n    210             )  \n--&gt; 211         automl_run = _default_execution(experiment, settings_obj, fit_params, True, show_output, parent_run_id)  \n    212     elif is_managed:  \n    213         logger.info(&quot;Submitting local managed run.&quot;)  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _default_execution(experiment, settings_obj, fit_params, legacy_local, show_output, parent_run_id)  \n    129     experiment_state.console_writer.show_output = show_output  \n    130     driver = ExperimentDriver(experiment_state)  \n--&gt; 131     updated_params = driver.create_parent_run(**fit_params)  \n    132     start_params = _combine_start_params(updated_params, **fit_params)  \n    133     return driver.start(**start_params)  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/_experiment_drivers\/experiment_driver.py in create_parent_run(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)  \n    219             _script_run,  \n    220             parent_run_id,  \n--&gt; 221             kwargs)  \n    222         assert self.experiment_state.current_run  \n    223         self.experiment_state.parent_run_id = self.experiment_state.current_run.id  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_experiment_drivers\/local_experiment_driver.py in create_parent_run(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)  \n    176                 existing_run,  \n    177                 managed_run_id=self.experiment_state.automl_settings._local_managed_run_id,  \n--&gt; 178                 _script_run=_script_run  \n    179             )  \n    180   \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_experiment_drivers\/local_experiment_driver.py in _create_parent_run_for_local(self, parent_run_dto, existing_run, managed_run_id, _script_run)  \n    509                     logger.info(&quot;Start creating parent run&quot;)  \n    510                     self.experiment_state.parent_run_id = self.experiment_state.jasmine_client.post_parent_run(  \n--&gt; 511                         parent_run_dto  \n    512                     )  \n    513   \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/jasmine_client.py in post_parent_run(self, create_parent_run_dto)  \n     75         &quot;&quot;&quot;  \n     76         return self._execute_with_experimentid_arguments(  \n---&gt; 77             self._client.jasmine.create_parent_run_method, create_parent_run_dto)  \n     78   \n     79     def post_remote_jasmine_snapshot_run(self, parent_run_id, run_definition, snapshotId):  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/experiment_client.py in _execute_with_experimentid_arguments(self, func, *args, **kwargs)  \n    264                                             copy.deepcopy(  \n    265                                                 self._experiment_arguments_with_experiment_id),  \n--&gt; 266                                             *args, **kwargs)  \n    267   \n    268     def _combine_with_experiment_paginated_dto(self, func, count_to_download=0, *args, **kwargs):  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)  \n    589                 return self._call_api(func, *args_list, **kwargs)  \n    590         except ErrorResponseException as e:  \n--&gt; 591             raise ServiceException(e)  \n  \nServiceException: ServiceException:  \n\tCode: 401  \n\tMessage: (UserError) Feature Engineering Customization: Feature is not available for requested compute target: Local  \n\tDetails:  \n  \n\tHeaders: {  \n\t    &quot;Date&quot;: &quot;Fri, 18 Jun 2021 02:54:07 GMT&quot;,  \n\t    &quot;Content-Type&quot;: &quot;application\/json; charset=utf-8&quot;,  \n\t    &quot;Content-Length&quot;: &quot;783&quot;,  \n\t    &quot;Connection&quot;: &quot;keep-alive&quot;,  \n\t    &quot;Request-Context&quot;: &quot;appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d&quot;,  \n\t    &quot;x-ms-response-type&quot;: &quot;error&quot;,  \n\t    &quot;x-ms-client-request-id&quot;: &quot;e243c9bb-8253-4eb3-94ac-029920be77d7&quot;,  \n\t    &quot;x-ms-client-session-id&quot;: &quot;&quot;,  \n\t    &quot;Strict-Transport-Security&quot;: &quot;max-age=15724800; includeSubDomains; preload&quot;,  \n\t    &quot;X-Content-Type-Options&quot;: &quot;nosniff&quot;,  \n\t    &quot;x-request-time&quot;: &quot;0.095&quot;  \n\t}  \n\tInnerException: {  \n    &quot;additional_properties&quot;: {},  \n    &quot;error&quot;: {  \n        &quot;additional_properties&quot;: {  \n            &quot;debugInfo&quot;: null,  \n            &quot;additionalInfo&quot;: null  \n        },  \n        &quot;code&quot;: &quot;UserError&quot;,  \n        &quot;severity&quot;: null,  \n        &quot;message&quot;: &quot;Feature Engineering Customization: Feature is not available for requested compute target: Local&quot;,  \n        &quot;message_format&quot;: null,  \n        &quot;message_parameters&quot;: null,  \n        &quot;reference_code&quot;: null,  \n        &quot;details_uri&quot;: null,  \n        &quot;target&quot;: null,  \n        &quot;details&quot;: [],  \n        &quot;inner_error&quot;: {  \n            &quot;additional_properties&quot;: {},  \n            &quot;code&quot;: &quot;AuthorizationError&quot;,  \n            &quot;inner_error&quot;: {  \n                &quot;additional_properties&quot;: {},  \n                &quot;code&quot;: &quot;FeatureUnavailableError&quot;,  \n                &quot;inner_error&quot;: null  \n            }  \n        }  \n    },  \n    &quot;correlation&quot;: {  \n        &quot;operation&quot;: &quot;ba0a493b549fde42b742c2a4eef8a7c0&quot;,  \n        &quot;request&quot;: &quot;02cd58b16cf07b46&quot;  \n    },  \n    &quot;environment&quot;: &quot;eastus2&quot;,  \n    &quot;location&quot;: &quot;eastus2&quot;,  \n    &quot;time&quot;: {},  \n    &quot;component_name&quot;: &quot;jasmine&quot;  \n}  \n  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to improve particular tag accuracy in Form recognizer",
        "Question_created_time":1623650782897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/434228\/how-to-improve-particular-tag-accuracy-in-form-rec",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105244-9747f8ff-d7b8-4968-ab66-27e27e42b0c2.jpeg?platform=QnA\" alt=\"105244-9747f8ff-d7b8-4968-ab66-27e27e42b0c2.jpeg\" \/>    <\/p>\n<p>as you can see, I made a custom model(OCR) and trained it. But only some tags are well learned, and others are not well learned poorly. even if additional learning data set is added, training error occurs and learning is no longer possible.     <br \/>\nMy data format is pdf and not all parts of the file are tagged, but only some of them are tagged.     <\/p>\n<p>is there a way to increase the accuracy of particular tag?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Preparing ML object detction dataset for deep learning in PyTorch or similar",
        "Question_created_time":1607567444300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/192973\/preparing-ml-object-detction-dataset-for-deep-lear",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>The intent of what I'm trying to achieve is:  <\/p>\n<ol>\n<li> Export data labelling project as a Dataset  <\/li>\n<li> Consume the Dataset in a notebook (converting to a Pandas dataframe)  <\/li>\n<li> Perform a custom train \/ test split that maintains particular file groupings  <\/li>\n<li> Register the resulting training and testing dataframes as Datasets  <\/li>\n<li> Use these Datasets to train and test a custom object detection model  <\/li>\n<\/ol>\n<p>I need help in preparing the data for that final step. I'm familiar with different deep learning libraries, but have never implemented them in the Azure environment before. I've managed to complete 1 to 4. For step 4, I ended up writing the data to csv files and uploading these to the datastore.  <\/p>\n<pre><code># define path for training data file and create new delimited file\ntrain_path = '.\/data\/train.csv'\ntrain_dataframe.to_csv(train_path, sep = ';', index = False)\n\n# repeat for testing\ntest_path = '.\/data\/test.csv'\ntest_dataframe.to_csv(test_path, sep = ';', index = False)\n\n# get the datastore to upload prepared data\ndatastore = Datastore.get(ws, datastore_name='learningdata')\n\n# upload the local files from src_dir to the target_path in datastore\ndatastore.upload(src_dir='data', target_path='train-test', overwrite=True)\n\n# create and register training dataset from datastore files\ntraining_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/train.csv')], separator=';')\ntraining_ds = training_ds.register(workspace=ws, name = 'train', description = 'training dataset sampled from labelled data', create_new_version=True)\n\n# create and register testing dataset from datastore files\ntesting_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/test.csv')], separator=';')\ntesting_ds = testing_ds.register(workspace=ws, name = 'test', description = 'testing dataset sampled from labelled data', create_new_version=True)\n<\/code><\/pre>\n<p>The approach I was intending to use for step 5 was to use to_torchvision() to convert it into a Torchvision dataset. This doesn't work, I receive the following error:  <\/p>\n<pre><code>UserErrorException: UserErrorException:\n Message: Cannot perform torchvision conversion on dataset without labeled columns defined\n InnerException None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Cannot perform torchvision conversion on dataset without labeled columns defined&quot;\n    }\n}\n<\/code><\/pre>\n<p>I suspect that the issue has to do with DataTypes. The original Dataset (exported from the data labelling project) has the DataTypes displayed below. By comparison, all column types in the train and test Datasets are parsed as strings. From my understanding, there's no way to convert to these data types.   <\/p>\n<ul>\n<li> image_url = Stream  <\/li>\n<li> label = List  <\/li>\n<li> label_confidence = List  <\/li>\n<\/ul>\n<p>Any advice on how to prepare this dataset for use in PyTorch or recommendation for an alternative approach would be greatly appreciated.  <\/p>\n<hr \/>\n<p>Update as per comment below:  <\/p>\n<ul>\n<li> I'm currently mounting the dataframe rather than downloading it due to data size.  <\/li>\n<li> I can view images from the originally mounted Dataset, but when loading the newly registered training Dataset I can't access images as '\/tmp\/tmpog809x4v\/[...].jpg' is no longer relevant.  <\/li>\n<li> I can't perform random split because I'm using clustered sampling.  <\/li>\n<li> I'm working on creating a class object to define the dataset, but I cannot currently create the PIL Image object as required by PyTorch (<a href=\"https:\/\/pytorch.org\/tutorials\/intermediate\/torchvision_tutorial.html#defining-the-dataset\">https:\/\/pytorch.org\/tutorials\/intermediate\/torchvision_tutorial.html#defining-the-dataset<\/a>)  <\/li>\n<\/ul>",
        "Question_closed_time":1608071413793,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>I modified the methodology and was able to successfully resolve this issue as follows:  <\/p>\n<ol>\n<li> Export data labelling project as Dataset  <\/li>\n<li> Consume the Dataset in the notebook by creating both a PyTorch dataset and a Pandas dataframe  <\/li>\n<li> Use the Pandas dataframe to determine indices for the train \/ test split based on required sampling  <\/li>\n<li> Use the indices as an input to <em>torch.utils.data.Subset()<\/em> to split the PyTorch dataset into train and test<\/li>\n<\/ol>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Deploying spark-nlp model using custom docker image fails in Azure Machine Learning",
        "Question_created_time":1623911523677,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/439911\/deploying-spark-nlp-model-using-custom-docker-imag",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<h2 id=\"issue-while-deploying-spark-nlp-model-to-aml\">Issue while deploying spark-nlp model to AML<\/h2>\n<p>I am trying to deploy a SPARK-NLP trained model from <a href=\"https:\/\/johnsnowlabs.github.io\/spark-nlp-workshop\/databricks\/index.html#python\/annotation\/Spark%20NLP%20start.html\">here<\/a> to Azure Machine learning (using Python environment)<\/p>\n<p>While deploying I am using a custom docker image provided by the spark-nlp documentation <a href=\"https:\/\/nlp.johnsnowlabs.com\/docs\/en\/install#docker-support\">here<\/a>  <br \/>\nThis is because when I try to use an existing image such as  <br \/>\n<code>env = Environment.get(ws, name='AzureML-PySpark-MmlSpark-0.15')<\/code>  <br \/>\nthen we get errors when loading the model in the scoring script as spark-nlp libraries are not found in that AzureML-PySpark image.<\/p>\n<p>So now I am using custom docker file as below:<\/p>\n<p>dockerfile = r&quot;&quot;&quot;<\/p>\n<p>FROM ubuntu:18.04<\/p>\n<p>ENV NB_USER yuefeng  <br \/>\nENV NB_UID 1000  <br \/>\nENV HOME \/home\/${NB_USER}<\/p>\n<p>ENV PYSPARK_PYTHON=python3  <br \/>\nENV PYSPARK_DRIVER_PYTHON=python3<\/p>\n<p>RUN apt-get update &amp;&amp; apt-get install -y \\  <br \/>\ntar \\  <br \/>\nwget \\  <br \/>\nbash \\  <br \/>\nrsync \\  <br \/>\ngcc \\  <br \/>\nlibfreetype6-dev \\  <br \/>\nlibhdf5-serial-dev \\  <br \/>\nlibpng-dev \\  <br \/>\nlibzmq3-dev \\  <br \/>\npython3 \\  <br \/>\npython3-dev \\  <br \/>\npython3-pip \\  <br \/>\nunzip \\  <br \/>\npkg-config \\  <br \/>\nsoftware-properties-common \\  <br \/>\ngraphviz<\/p>\n<p>RUN adduser --disabled-password \\  <br \/>\n--gecos &quot;Default user&quot; \\  <br \/>\n--uid ${NB_UID} \\  <br \/>\n${NB_USER}<\/p>\n<p>RUN apt-get update &amp;&amp; \\  <br \/>\napt-get install -y openjdk-8-jdk &amp;&amp; \\  <br \/>\napt-get install -y ant &amp;&amp; \\  <br \/>\napt-get clean;<\/p>\n<p>RUN apt-get update &amp;&amp; \\  <br \/>\napt-get install ca-certificates-java &amp;&amp; \\  <br \/>\napt-get clean &amp;&amp; \\  <br \/>\nupdate-ca-certificates -f;<\/p>\n<p>ENV JAVA_HOME \/usr\/lib\/jvm\/java-8-openjdk-amd64\/  <br \/>\nRUN export JAVA_HOME<\/p>\n<p>RUN echo &quot;export JAVA_HOME=\/usr\/lib\/jvm\/java-8-openjdk-amd64\/&quot; &gt;&gt; ~\/.bashrc<\/p>\n<p>RUN apt-get clean &amp;&amp; rm -rf \/var\/lib\/apt\/lists\/* \/tmp\/* \/var\/tmp\/*<\/p>\n<p>RUN pip3 install --upgrade pip  <br \/>\nRUN pip3 install --no-cache-dir notebook==5.* numpy pyspark==2.4.4 spark-nlp==2.5.1 azureml-sdk azureml-core pandas mlflow Keras scikit-spark scikit-learn scipy matplotlib pydot tensorflow graphviz<\/p>\n<p>USER root  <br \/>\nRUN chown -R ${NB_UID} ${HOME}  <br \/>\nUSER ${NB_USER}<\/p>\n<p>WORKDIR ${HOME}<\/p>\n<p>CMD [&quot;jupyter&quot;, &quot;notebook&quot;, &quot;--ip&quot;, &quot;0.0.0.0&quot;]  <br \/>\n&quot;&quot;&quot;<\/p>\n<h1 id=\"my-environment-configuration-is-as-below\">My environment configuration is as below:<\/h1>\n<p>from azureml.core import Environment  <br \/>\nfrom azureml.core.model import InferenceConfig<\/p>\n<p>env=Environment(&quot;myenv&quot;)  <br \/>\nenv.docker.base_image=None  <br \/>\nenv.docker.base_dockerfile = dockerfile<\/p>\n<p>env.inferencing_stack_version='latest'<\/p>\n<p>inf_config = InferenceConfig(environment=env, entry_script=&quot;score.py&quot;)<\/p>\n<h1 id=\"the-entry-script-scorepy-looks-like-below\">the entry script, score.py looks like below:<\/h1>\n<p>%%writefile score.py  <br \/>\nimport json  <br \/>\nimport pyspark<\/p>\n<p>import azureml.core  <br \/>\nfrom azureml.core.model import Model  <br \/>\nfrom azureml.core import Workspace  <br \/>\nfrom pyspark.ml import PipelineModel  <br \/>\nfrom pyspark.context import SparkContext  <br \/>\nfrom pyspark.sql.session import SparkSession  <br \/>\nimport sys, glob, os<\/p>\n<p>global trainedModel  <br \/>\nglobal spark  <br \/>\ndef init():  <br \/>\nsys.path.extend(glob.glob(os.path.join(os.path.expanduser(&quot;~&quot;), &quot;.ivy2\/jars\/*.jar&quot;)))  <br \/>\nspark = SparkSession.builder.appName(&quot;Spark NLP&quot;).master(&quot;local[4]&quot;).config(&quot;spark.driver.memory&quot;,&quot;16G&quot;).config(&quot;spark.driver.maxResultSize&quot;, &quot;2G&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;).config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1,com.google.cloud.spark:spark-bigquery-with-dependencies_2.11:0.15.1-beta&quot;).getOrCreate()  <br \/>\nmodel_name = &quot;nlp_test-register&quot; #interpolated  <br \/>\nmodel_path = Model.get_model_path(model_name)  <br \/>\ntrainedModel = PipelineModel.load(model_path)<\/p>\n<p>def run(input_json):  <br \/>\nif isinstance(trainedModel, Exception):  <br \/>\nreturn json.dumps({&lt;!-- --&gt;{&quot;trainedModel&quot;:str(trainedModel)}})<\/p>\n<pre><code>try:\n    sc = spark.sparkContext\n    input_list = json.loads(input_json)\n    input_rdd = sc.parallelize(input_list)\n    input_df = spark.read.json(input_rdd)\n\n\n    prediction = trainedModel.transform(input_df)\n\n    predictions = prediction.collect()\n\n\n    preds = [str(x['ntokens']) for x in predictions.select('ntokens').collect()]\n    result = &quot;,&quot;.join(preds)\n\n    return result\nexcept Exception as e:\n    result = str(e)\n    return result\n<\/code><\/pre>\n<p>the spark-nlp trained model is registered successfully in the workspace.<\/p>\n<p>from azureml.core.model import Model  <br \/>\n--Register model  <br \/>\nresgistered_Model = Model.register(ws, model_name=&quot;nlp_test-register&quot;, model_path=&quot;.\/test.mml&quot;)<\/p>\n<p>Now, when trying to deploy the model as a local webservice:<\/p>\n<p><code>deployment_config = LocalWebservice.deploy_configuration(port=6789) service = Model.deploy(     ws,     &quot;myservice&quot;,     [model],     inf_config,     deployment_config,     overwrite=True, ) service.wait_for_deployment(show_output=True)<\/code><\/p>\n<p>I get error when trying to build the environment:<\/p>\n<p>Step 32\/45 : RUN if dpkg --compare-versions <code>conda --version | grep -oE '[^ ]+$'<\/code> lt 4.4.11; then conda install conda==4.4.11; fi  <br \/>\n---&gt; Running in 1d06aaf8f181  <br \/>\n\/bin\/sh: 1: conda: not found  <br \/>\ndpkg: error: --compare-versions takes three arguments: &lt;version&gt; &lt;relation&gt; &lt;version&gt;<\/p>\n<p>Type dpkg --help for help about installing and deinstalling packages [*];  <br \/>\nUse 'apt' or 'aptitude' for user-friendly package management;  <br \/>\nType dpkg -Dhelp for a list of dpkg debug flag values;  <br \/>\nType dpkg --force-help for a list of forcing options;  <br \/>\nType dpkg-deb --help for help about manipulating *.deb files;  <br \/>\n...  <br \/>\nStep 33\/45 : COPY azureml-environment-setup\/mutated_conda_dependencies.yml azureml-environment-setup\/mutated_conda_dependencies.yml  <br \/>\n---&gt; efe6235c07d2  <br \/>\nStep 34\/45 : RUN ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} + &amp;&amp; ldconfig  <br \/>\n---&gt; Running in 5382859f6b89  <br \/>\n\/bin\/sh: 1: conda: not found  <br \/>\nThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs &amp;&amp; conda env create -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -f azureml-environment-setup\/mutated_conda_dependencies.yml &amp;&amp; rm -rf &quot;$HOME\/.cache\/pip&quot; &amp;&amp; conda clean -aqy &amp;&amp; CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find &quot;$CONDA_ROOT_DIR&quot; -type d -name <strong>pycache<\/strong> -exec rm -rf {} + &amp;&amp; ldconfig' returned a non-zero code: 127  <br \/>\n2021\/06\/17 02:47:36 Container failed during run: acb_step_0. No retries remaining.  <br \/>\nfailed to run step ID: acb_step_0: exit status 127<\/p>\n<p>Run ID: ccx failed after 13m28s. Error: failed during run, err: exit status 1  <br \/>\nPackage creation Failed<\/p>\n<p>Does it mean conda is not available in the docker image? How to install CONDA in the docker image? What commands should be given in the docker file?  <br \/>\n&lt;img width=&quot;960&quot; alt=&quot;error&quot; src=&quot;https:\/\/user-images.githubusercontent.com\/50163025\/122332624-4d47d100-cf69-11eb-92d2-ce025500e410.PNG&quot;&gt;<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while deploying an Webservice using an ACI",
        "Question_created_time":1623853256203,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/438730\/error-while-deploying-an-webservice-using-an-aci",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,<\/p>\n<p>I am receiving the following message when I try the deploy a webservice using azure SDK.<\/p>\n<p>&quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.<\/p>\n<p>NOTE : here is my init():<\/p>\n<p>**def init():  <br \/>\ntry:  <br \/>\nglobal model_cbf  <br \/>\nglobal model_frequenceAchat  <br \/>\nglobal date_ajd  <br \/>\nglobal model_cf  <br \/>\nglobal Feature  <br \/>\nglobal Empty_Feature  <br \/>\nglobal MultiSparseInfo<\/p>\n<pre><code>    model_path_cbf = Model.get_model_path(&quot;content-based_filtering&quot;)    \n    model_cbf = joblib.load(model_path_cbf)\n\n    model_path_frequence_achat = Model.get_model_path(&quot;frequence_dachat&quot;)\n    model_frequenceAchat = joblib.load(model_path_frequence_achat)    \n    date_ajd = datetime.datetime(2014, 7, 8)\n\n    Feature = namedtuple(&quot;Feature&quot;, [&quot;name&quot;, &quot;index&quot;])\n    Empty_Feature = Feature(name=[], index=[])\n\n    MultiSparseInfo = namedtuple(&quot;MultiSparseInfo&quot;,\n                             [&quot;field_offset&quot;, &quot;field_len&quot;, &quot;feat_oov&quot;])\n\n    model_cf_data = Model.get_model_path(&quot;donnees_collaborative_filtering&quot;) \n    data_info = DataInfo.load2(model_cf_data[1])\n    model_cf = SVD(task = model_cf_data[0]['task'], data_info = data_info)\n    model_cf.load2(model_cf_data[2])\nexcept:\n    Exception as e:\n    print(str(e))**\n<\/code><\/pre>\n<p>I suspect that the presence of a class definition in the entry script might be the problem. What do you guys think?<\/p>\n<p>Thank you,<\/p>\n<p>Vincent<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ml Studio sending png to display in webpage",
        "Question_created_time":1623180478067,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/427404\/azure-ml-studio-sending-png-to-display-in-webpage",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>1) after running python script png is displayed in visualise but unable to locate its path  <br \/>\n2) how to send png file from ml studio to the azure storage container  <br \/>\n3) ML studio after python script generates png ,send png as output in web service output to web application<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why do i get :NotLabeledDataset: There is no label column in",
        "Question_created_time":1622732290603,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/421203\/why-do-i-get-notlabeleddataset-there-is-no-label-c",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hello I am trying to make a classification model using the ml designer.  <\/p>\n<p>I registert a dataset whit images. Maybe i did it wrong?   <br \/>\nI used the sample that Microsoft designer suplies densnet for image classification. I only changed the dataset whit one that i made.    <\/p>\n<p>I have 5 classes and each one is in thier own subfolder i uploaded the folder. a file type.   <\/p>\n<p>i keep getting the message <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Metrics tab.",
        "Question_created_time":1623816222417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/437991\/metrics-tab",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Next to the Normalized root mean squared error value, select View all other metrics to see values of other possible evaluation metrics for a regression model.    <\/p>\n<p>Select the Metrics tab and select the residuals and predicted_true charts if they are not already selected. Then review the charts, which show the performance of the model by comparing the predicted values against the true values, and by showing the residuals (differences between predicted and actual values) as a histogram.    <\/p>\n<p>As per the above lines, I am not able to find the Metrics tab and not able to see the predicted true charts.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/106017-screenshot-26.png?platform=QnA\" alt=\"106017-screenshot-26.png\" \/>    <\/p>",
        "Question_closed_time":1623824430657,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=470817e2-2a8d-42d2-9da4-00253723c5ca\">@A Sashank Sainath Reddy  <\/a> You will have to first click on the algorithm name from the screen shot first.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105969-image.png?platform=QnA\" alt=\"105969-image.png\" \/>    <\/p>\n<p>Then you will see the metrics tab and the charts.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/106101-image.png?platform=QnA\" alt=\"106101-image.png\" \/>    <\/p>\n<p>Please feel free to accept the answer if it helped. Thanks.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"What is the difference between online learning and offline learning",
        "Question_created_time":1623786913570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/437505\/what-is-the-difference-between-online-learning-and",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am a new learner of machine learning and computer science, I wonder the difference between these two terms. I am confused on the concept, can someone answer this question?  <\/p>",
        "Question_closed_time":1623787840780,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,  <\/p>\n<p>Thanks for reaching out to us here. They are both machine learning methods for training. online machine learning is a method of machine learning in which data becomes available in <strong>a sequential order and is used to update the best predictor<\/strong> for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the <strong>entire training data set at once.<\/strong>   <\/p>\n<p>Like, one more data coming in, the <strong>predictor moves<\/strong> once. This method is good for scenario like stock prediction, optimization...  <\/p>\n<p>Linear least square is a very good example to understand.   <br \/>\n<a href=\"https:\/\/en.wikipedia.org\/wiki\/Linear_least_squares\">https:\/\/en.wikipedia.org\/wiki\/Linear_least_squares<\/a>  <\/p>\n<p>For Machine Learning beginner, Machine Learning Designer is a very good point to start. You can try any algorithms to see the difference.  <br \/>\n<a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/designer\/\">https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/designer\/<\/a>  <\/p>\n<p>Please feel free to let us know if you have more questions.  <\/p>\n<p>Regards,  <br \/>\nYutong  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Explaining a model in AzureML Studio",
        "Question_created_time":1623017811457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/423931\/explaining-a-model-in-azureml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>There is an issue when I try to explain a Time Series model created with AzureML Studio, with the AutoML service.  <\/p>\n<p>When the proccess finishes and the best model is automatically explained, I'd like to see a chart with the information of &quot;Predicted Values vs True Values&quot; but I can\u00b4t find anything similar. Then I realized that when I click on the explanation of the model, the next message is showed:  <\/p>\n<p>&quot;Las estad\u00edsticas de rendimiento del modelo requieren que se proporcionen los resultados verdaderos adem\u00e1s de los previstos.&quot;   <\/p>\n<p>Translated: &quot;The performance statistics of the model require to provide true values in addition to the predicted ones.&quot;  <\/p>\n<p>How can I provide the model with the true values? I think it should be done automatically by the process, isn\u00b4t it? I mean, true values is part of the dataset, it is in fact the target column.   <\/p>\n<p>Furthermore, I tried to create a classification model and I don\u00b4t have that problem there.   <\/p>\n<p>Anyone could help me? Without a chart where I can compare true vs predicted values, the model doesn\u00b4t make sense.  <\/p>\n<p>Thank you very much in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use Azure Machine Learning instead of AML Studio(classic) for your new projects!",
        "Question_created_time":1623741356823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/436332\/use-azure-machine-learning-instead-of-aml-studio(c",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Azure Machine Learning is the new enterprise level machine learning platform. It provides drag-n-drop ML modules plus scalability, enterprise security and industry leading MLOps experience.  Check <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-azure-ml\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-azure-ml<\/a> to learn more.    <\/p>\n<p>We highly recommended customers evaluating machine learning platform for their new project stat with Azure Machine Learning directly. Customers using AML Studio(classic) can check <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/migrate-overview\">this article<\/a> to learn how to migrate to Azure Machine Learning.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to solve train error from running model fit in ES_RNN model?",
        "Question_created_time":1623252586213,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/428948\/how-to-solve-train-error-from-running-model-fit-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I cloned Github <strong>notebooks<\/strong>(<a href=\"https:\/\/github.com\/Azure\/DeepLearningForTimeSeriesForecasting\">https:\/\/github.com\/Azure\/DeepLearningForTimeSeriesForecasting<\/a>) provided by Microsoft and was trying to run <strong>4_ES_RNN.ipynb<\/strong>.  <\/p>\n<p>However, I am getting the following error for train model fit. Below is the code and error that I received.  <\/p>\n<p>Code:  <\/p>\n<blockquote>\n<p>model.fit(train_inputs['X'],  <br \/>\n          train_inputs['target'],  <br \/>\n          batch_size=BATCH_SIZE,  <br \/>\n          shuffle=False,  <br \/>\n          epochs=EPOCHS,  <br \/>\n          #validation_data=(valid_inputs['X'], valid_inputs['target']),  <br \/>\n          validation_split=0.1,  <br \/>\n          callbacks=[earlystop],  <br \/>\n          verbose=1)  <\/p>\n<\/blockquote>\n<p>Error:  <\/p>\n<blockquote>\n<p>InvalidArgumentError: Expected size[0] in [0, 21], but got 29  <br \/>\n[[{&lt;!-- --&gt;{node es_1\/Slice_13}} = Slice<a>Index=DT_INT32, T=DT_FLOAT, _device=&quot;\/job:localhost\/replica:0\/task:0\/device:CPU:0&quot;<\/a>]]  <\/p>\n<\/blockquote>\n<p>Any recommendation would be greatly appreciated, thanks!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can i clone an old notebook azure library?",
        "Question_created_time":1623400226543,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/432090\/how-can-i-clone-an-old-notebook-azure-library",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI'm a student and currently working on an <a href=\"https:\/\/core.ac.uk\/download\/pdf\/161875032.pdf\">article<\/a>. The writer of the article mentioned that i can found the full code and dataset on <a href=\"https:\/\/notebooks.azure.com\/william-mc\/libraries\/edge-detection\">https:\/\/notebooks.azure.com\/william-mc\/libraries\/edge-detection<\/a> link!<\/p>\n<p>When i click it, nothing happens and i faced a page that says:<\/p>\n<blockquote>\n<p>The Azure Notebooks preview has ended. You can enjoy powerful, integrated Jupyter notebooks with the following products and services from Microsoft and GitHub.<\/p>\n<\/blockquote>\n<p>i really need that codes. how can i access them? is there anyway to clone from azure notebooks please?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What algorithms are available in Azure ML for marketing puposes, especially compaign planning?",
        "Question_created_time":1623341042097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/430909\/what-algorithms-are-available-in-azure-ml-for-mark",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there,    <\/p>\n<p>I'm interested in the solution of Optimize Marketing with Machine Learning (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/solution-ideas\/articles\/optimize-marketing-with-machine-learning\">https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/solution-ideas\/articles\/optimize-marketing-with-machine-learning<\/a>). It would be very helpful if someone could give me more insides into this solution.    <\/p>\n<p>I'm wondering whether I can use this for my use-case (campaign planning) and if so, how it would look like.     <\/p>\n<p>Kind regards,    <\/p>\n<p>Jerom<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to increase the number of parameters logged in MLFlow (current max limit is 100)",
        "Question_created_time":1623455284870,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/433155\/how-to-increase-the-number-of-parameters-logged-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm using AzureML to train some networks and the recommended MLFlow to log parameters and metrics.  <br \/>\nHowever, I have reached the maximum limit of 100 parameters (mostly configuration options I pass to the trainer but also real model parameters). And I get the following error:  <\/p>\n<blockquote>\n<p>mlflow.exceptions.RestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'A field of the entity is over the size limit. <strong>FieldName=Parameters, Limit=100, Size=101<\/strong>. See <a href=\"https:\/\/aka.ms\/azure-machine-learning-limits\">https:\/\/aka.ms\/azure-machine-learning-limits<\/a> for service limits documentation.', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': 'a9544317f5dd99458be006824948b38d', 'request': '0b131227514b3b4b'}, 'Environment': 'eastus', 'Location': 'eastus', 'ComponentName': 'mlflow', 'error_code': 'BAD_REQUEST'}  <\/p>\n<\/blockquote>\n<p>Is there a way to increase this limit? If not, are there any other workarounds?  <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does Azure AutoML use (or plan to use) FLAML for the hyperparameter tuning?",
        "Question_created_time":1623298947587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/429832\/does-azure-automl-use-(or-plan-to-use)-flaml-for-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>FLAML looks like it performs better than Azure AutoML for hyperparameter tuning (based on the benchmarking in the Arxiv paper): <a href=\"https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf\">https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf<\/a>  <\/p>\n<p>Is it now being used or is there a plan to integrate it for the hyperparameter tuning in Azure Machine Learning Services? If so, when is that expected to become available?<\/p>",
        "Question_closed_time":1623391032690,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=44a7ffc5-e97c-4dec-95a0-445a9835aab3\">@Rainer Hillermann  <\/a> Thanks, We are not using the FLAML for Azure AutoML for the hyperparameter tuning, You can raise a user voice request <a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\">here<\/a> so the community can vote and provide their feedback, the product team then checks this feedback and implements the feature in future releases.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Downloading images built during ML experiment",
        "Question_created_time":1623337578827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/430883\/downloading-images-built-during-ml-experiment",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have successfully run a AML experiment . In the beginning of the experiment, I included the below command to build a conda environment with my requirements into a pre built image:  <\/p>\n<pre><code>env = azc.Environment.from_conda_specification(name='my-env', file_path='.\/envspec.yml')\nenv.docker.enabled = True\nenv.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n<\/code><\/pre>\n<p>I understand that during the preparation phase the image is built with the specified dependencies and the experiment is run.   <br \/>\nNow, where I can access this built image? I tried in the Azure container Registry inside my resource group but couldnt find anything.  <\/p>\n<p>Is there a way I can download this image and use it in a different experiment as a custom image? I assume this must save time in downloading dependencies and ensures reptroduciblity.   <\/p>\n<p>Any known way of doing this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning studio Data Labeling Dataset",
        "Question_created_time":1623134368530,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/426209\/machine-learning-studio-data-labeling-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hi ,   <\/p>\n<p>I have a have a dataset from the labelled data using the  ML Data Labeling tool , my question is how can use the dataset to train a model ? , I tried Automated ML but I cannot make ant connection with the dataset .  <\/p>\n<p>Thanks for your help.<\/p>",
        "Question_closed_time":1623240266353,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=4eb02c39-e084-433a-9d5e-4fce46999081\">@hernandoZ  <\/a> I can confirm that using labeling data in the designer is currently not supported. This is however part of the roadmap in the future releases of designer. You can consume the data with the SDK as mentioned above.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Leave-one-group-out cross-validation in Azure AutoML",
        "Question_created_time":1618488817010,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/358763\/leave-one-group-out-cross-validation-in-azure-auto",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a dataset where each row is a data sample, and there is a a column indicating a group this sample came from. So, each group has several data points, and each one is a row in the dataframe. I would like to run the cross-validation so that at each fold, the data points from one group are used as the validation set, and the data points from other groups as the training test. Is this currently somehow possible in Azure AutoML ?  <\/p>",
        "Question_closed_time":1618507805537,
        "Answer_score_count":0.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p>Yes, you can specify custom cross-validation data folds based on columns. More details are provided in the following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cross-validation-data-splits#specify-custom-cross-validation-data-folds\">document<\/a>. Hope this helps.    <\/p>\n<p><strong>Example:<\/strong>    <\/p>\n<pre><code>automl_config = AutoMLConfig(compute_target = aml_remote_compute,  \n                             task = 'classification',  \n                             primary_metric = 'AUC_weighted',  \n                             training_data = dataset,  \n                             label_column_name = 'y',  \n                             cv_split_column_names = ['cv1', 'cv2']  \n                            )  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML Designer - batch execution endpoint",
        "Question_created_time":1622424345223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/415354\/azureml-designer-batch-execution-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am migrating something from classic Azure ML to the current Azure ML and I have been using the batch execution endpoint.  .  I know there are examples how to publish a real-time endpoint through the designer, but is it possible to publish a batch execution endpoint (which is what I have been using in classic Azure ML) through the designer interface?       <\/p>\n<p>I found this documentation online: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/migrate-rebuild-web-service\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/migrate-rebuild-web-service<\/a>    <br \/>\nMy pipeline don't have a 'trained model' though it only includes a single Execute Python script module, is there a way to get around that and publish a batch inference endpoint    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Suggest solution for reading data from Azure Service Bus with Azure Data Factory",
        "Question_created_time":1623054369990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/424698\/suggest-solution-for-reading-data-from-azure-servi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I need a suggestion about the below scenario.  <br \/>\nI receive data every second on Azure Service Bus. Now, I want Azure Data Factory to fetch this data and run the ML model on data.   <br \/>\nAs I checked there isn't a link between Azure Service Bus and Azure Data Factory.  <br \/>\nWhat is the solution for this scenario?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio  pricing  and how to shutdown when not in use",
        "Question_created_time":1622033791957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/410544\/azure-ml-studio-pricing-and-how-to-shutdown-when-n",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>HI All,<\/p>\n<p>I am new to Azure. I started learning azure machine learning recently, using Azure ML Studio (classic) coz I read that it is a free service. I just tried a small experiment in it, few days back and logged in today after that , just to try some more stuff. However , after logging in , I checked the cost management section and saw that ML studio had incurred some costs for each of the past few days, even on the days when I did not login.  <br \/>\nso, couple of questions here -<\/p>\n<p>1) isn't ml studio (classic) supposed to be free. If so, can someone please explain why the cost being displayed on the cost management page?<\/p>\n<p>2) based on some other faq's , which were not specific to the classic version of ml studio, but just ml studio in general - I got to know that if the resource which is running the experiment is not shut down, it will continue to incur daily costs. so, even in the case if ml studio is not free- can someone please tell how we can shut down the compute instance associated with ml studio? I could not see any such compute instance in my resources on azure home page.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Docker container for compute instance in machine learning",
        "Question_created_time":1622313582447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/414823\/docker-container-for-compute-instance-in-machine-l",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Everyone,     <\/p>\n<p>I'm new to the cloud environment and the Microsoft Azure so incase this question doesn't belong here, my apologies in advance.    <\/p>\n<p>I was wondering if it's possible to create a docker container for a python environment within compute instance?    <\/p>\n<p>I'm working my way towards getting DP-100 certification. The other day I was trying to follow a tutorial  here <a href=\"https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/07%20-%20Work%20with%20Compute.ipynb\">https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/07%20-%20Work%20with%20Compute.ipynb<\/a>     <br \/>\nThere's a section in there 'Create a compute cluster' in which a docker configuration is specified within ScriptRunConfig. I tried running in this code on a compute instance instead of a cluster and got the following error    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/100700-image.png?platform=QnA\" alt=\"100700-image.png\" \/>    <\/p>\n<p>The code works perfectly fine if I use a compute cluster instead of a compute instance    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy Azure ML endpoint",
        "Question_created_time":1619760120333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/378131\/unable-to-deploy-azure-ml-endpoint",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>I am able to build real-time inference pipeline for Wikipedia example but get error when deployed    <\/p>\n<p>\ue946    <br \/>\nUpdate: Service status is healthy, but test call return 'GatewayTimeout'.view real-time endpoint    <\/p>\n<p>I am able to deploy car price prediction example without errors.    <\/p>\n<p>What am i doing wrong?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92768-image.png?platform=QnA\" alt=\"92768-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Request failed with status code 400 in Azure ML",
        "Question_created_time":1622118479387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/412196\/request-failed-with-status-code-400-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Created a new Azure ML account. Have set up a workspace, resource group and compute instance as required to run the experiment.   <br \/>\nHowever when i run the model in Designer i get the following error:  <br \/>\nUserError: Request failed with status code 400.  <\/p>\n<p>Trace ID : 97ee92cd-cb3c-4b76-b5e5-d2a37be0f33b  <br \/>\nClient request ID : 5e39d178-6437-4594-9cdc-21c0a160fa22  <\/p>\n<p>Can someone please advice how do i sort this issue.   <\/p>\n<p>Thanks. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"DevOps ML Studio Connection",
        "Question_created_time":1622190501230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/413565\/devops-ml-studio-connection",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to create a pipline for machine learning model to be able to logged and run through ML Studio. I created the pipeline on DevOps and created GPU Cluster on ML Studio, estabilished service connection.   <\/p>\n<p>When I run the pipeline every stage is running well and run is logged to ML Studio but I am having the following error while trying to run train.py  <\/p>\n<pre><code>Unable to fetch workspace resources\n<\/code><\/pre>\n<p>So how can i overcome this issue?  <\/p>\n<p>What I tried so far:  <\/p>\n<ol>\n<li>  Reestablish connection  <\/li>\n<li> Tried to Run pipeline from ML Studio  <\/li>\n<li> Deleted Cluster and created a new one  <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Group Categorical Values module in Microsoft Azure Machine Learning Studio (classic) giving error",
        "Question_created_time":1620279484597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/384866\/group-categorical-values-module-in-microsoft-azure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi  <br \/>\nI am using &quot;Group Categorical Values&quot; in Microsoft Azure Machine Learning Studio (classic) to group a set of Categorical values of a categorical feature in to lesser number of groups. I have sued all parameters as explained in ML Studio help page <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/group-categorical-values?redirectedfrom=MSDN\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/group-categorical-values?redirectedfrom=MSDN<\/a>  <br \/>\nBut Still I ma getting a error which says <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/94283-image.png?platform=QnA\" alt=\"![94294-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/94283-image.png?platform=QnA\">2<\/a>  <br \/>\n&quot; It seems you encountered Internal System Error: Please contact amlforum@Microsoft&quot;  <br \/>\nThanks  <br \/>\nRajashekhar  <br \/>\n<a href=\"https:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/9f5fb15755164681b389eef10324dde2#Workspaces\/Experiments\/Experiment\/9f5fb15755164681b389eef10324dde2.f-id.0cd00be569cf4dc4aa62ecd69684cfd9\/ViewExperiment\">9f5fb15755164681b389eef10324dde2<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Upload Data to Azure SQL without Data Factory and Data Transfer Step",
        "Question_created_time":1622098940050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/411746\/azure-ml-upload-data-to-azure-sql-without-data-fac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>From the documentation I could find ways to read data from Azure SQL database registered as datastore in azureML,but not ways to upload or write output data to azure SQL database from azureML. Can anyone please guide me on the same? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permission error while finishing auto ml run",
        "Question_created_time":1621886630607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>I get the following error inside the child runs in ML studio while doing an Automated ML experiment.  <\/p>\n<p>&quot;Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/artifacts\/write actions.&quot;  <\/p>\n<p>I am the owner of the resource group so I am not sure what the issue is.  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":1621971310163,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello everyone, <a href=\"\/users\/na\/?userid=1321ce4c-8332-49c7-b902-2bcd4256debc\">@Shubham Miglani  <\/a> <a href=\"\/users\/na\/?userid=8886df29-ba7f-42f0-a932-a7883bbe54ea\">@Nick Schafer  <\/a>     <\/p>\n<p>We have identified the issue and a hot fix is rolling out.  It will be fixed in all regions by end of today. Sorry for the experience.     <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Pipeline can not be built using a HyperdriveStep inside a Pipeline",
        "Question_created_time":1621515534017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/403018\/pipeline-can-not-be-built-using-a-hyperdrivestep-i",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hei, I'm trying to build a pipeline including a HyperdriveStep to tuen the hyperparameters.  <br \/>\nThe pipeline should later on run automatically and be tuned at each pipeline run.<\/p>\n<p>The pipeline consists of three steps: a preparation step resulting in a PipelineData Object, the HyperdriveStep and a final PythonRegisterStep, where the best model should be registered.<\/p>\n<p>However, when creating the pipeline object I'm getting an error I can not relate to.<\/p>\n<p>Traceback (most recent call last):<\/p>\n<pre><code>      File &quot;\/Users\/xxx\/Desktop\/azure_test\/pipeline-folder\/azure_pipeline_wrapper1.py&quot;, line 168, in &lt;module&gt;\n        pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=&quot;Pipeline for hyperparameter tuning&quot;)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/_experiment_method.py&quot;, line 104, in wrapper\n        return init_func(self, *args, **kwargs)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/pipeline.py&quot;, line 177, in __init__\n        self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1481, in build\n        graph = self.construct(name, steps)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1503, in construct\n        self.process_collection(steps)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1539, in process_collection\n        builder.process_collection(collection)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1830, in process_collection\n        self._base_builder.process_collection(item)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1533, in process_collection\n        return self.process_step(collection)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1577, in process_step\n        node = step.create_node(self._graph, self._default_datastore, self._context)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 270, in create_node\n        hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 346, in _get_hyperdrive_config\n        hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 38, in _create_experiment_dto\n        platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 672, in _get_platform_config\n        platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 686, in _get_platform_config_data_from_run_config\n        run_config = get_run_config_from_script_run(self.run_config)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/script_run_config.py&quot;, line 84, in get_run_config_from_script_run\n        run_config.arguments = deepcopy(script_run_config.arguments)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 205, in _deepcopy_list\n        append(deepcopy(a, memo))\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 270, in _reconstruct\n        state = deepcopy(state, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 230, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 270, in _reconstruct\n        state = deepcopy(state, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 230, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 264, in _reconstruct\n        y = func(*args)\n\n      File &quot;\/Users\/xxxr\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copyreg.py&quot;, line 91, in __newobj__\n        return cls.__new__(cls, *args)\n\n    TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n<\/code><\/pre>\n<p>My Code:<\/p>\n<pre><code># Connect to workspace \nws = Workspace.from_config()\nprint(ws.name, &quot;loaded&quot;)\n\n# Set compute target\ncluster_name = &quot;compcluster234&quot;\npipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n\n# Create new environment\nsklearn_env = Environment(&quot;sklearn_env&quot;)\n# Adds dependencies to PythonSection of sklaern_env\nenv_packages = CondaDependencies.create(conda_packages=['scikit-learn'])\nsklearn_env.docker.enabled = True\nsklearn_env.python.conda_dependencies = env_packages\n# Register the environment\nsklearn_env.register(workspace=ws)\n\n# =============================================================================\n# Run Configuration\n# =============================================================================\n\n# Create Run configuration \n# Pipeline_folder\npipeline_folder = path + '\/pipeline-folder'\n# Create a new runconfig object for the pipeline\npipeline_run_config = RunConfiguration()\n# Use the compute you created above. \npipeline_run_config.target = pipeline_cluster\n# Assign the environment to the run configuration\n# In comparison to the ScriptRunCnfig object, the RunConfig is more generous\npipeline_run_config.environment = sklearn_env\nprint (&quot;Run configuration created.&quot;)\n\n# =============================================================================\n# DataPath\n# =============================================================================\n\n# Get the default datastore\ndefault_ds = ws.get_default_datastore()\n# Create a DataPath object \ndatapath = DataPath(datastore = default_ds,\n                     path_on_datastore = 'cancer-data')\n# Make the datapath a PipelineParameter\ndatapath_pipeline_param = PipelineParameter(name='input-data',   \n                                            default_value=datapath)\ndatapath_input = (datapath_pipeline_param, \n                   DataPathComputeBinding(mode = 'mount'))\n\n# =============================================================================\n# PipelineData\n# =============================================================================\n\n# Create a PipelineData (temporary Data Reference) for the preppared data folder\nprepped_data_folder = PipelineData(name=&quot;prepped_data_folder&quot;,\n                                   datastore=ws.get_default_datastore())\n\n# Create PipelineData objects for the Metrics and the saved model\nmetrics_output_name = 'metrics_output'\nmetrics_data = PipelineData(name='metrics_data',\n                            datastore=default_ds,\n                            pipeline_output_name=metrics_output_name,\n                            training_output=TrainingOutput(&quot;Metrics&quot;))\n\nmodel_output_name = 'model_output'\nsaved_model = PipelineData(name='saved_model',\n                           datastore=default_ds,\n                           pipeline_output_name=model_output_name,\n                           training_output=TrainingOutput(&quot;Model&quot;,\n                                                          model_file=&quot;outputs\/model\/cancer_model.pkl&quot;))\n\n# =============================================================================\n# Pipeline Steps\n# =============================================================================\n\n# Step 1, Run the data prep script\nprep_step = PythonScriptStep(name = &quot;prepare_data&quot;,\n                                source_directory = pipeline_folder,\n                                script_name = &quot;cancer_pipeline_preprocessing.py&quot;,\n                                arguments = ['--input-data', datapath_input,\n                                             '--prepped-data', prepped_data_folder],\n                                inputs=[datapath_input],\n                                outputs=[prepped_data_folder],\n                                compute_target = pipeline_cluster,\n                                runconfig = pipeline_run_config,\n                                allow_reuse = False)\n\n# Define the search strategy and parameter space for hyperparameter tuning\nps = GridParameterSampling({ '--max_depth': choice(1,2,3)})\n# Define a early stopping criteria\nearly_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n# Define a ScriptRunConfig for the Training script\n# The ScriptRunConfig is based on the RunConfig of the Pipeline\nscript_run_config = ScriptRunConfig(script=&quot;cancer_pipeline_tuning.py&quot;,\n                                    source_directory=pipeline_folder,\n                                    # Add non-hyperparameter arguments -in this case, the training dataset\n                                    arguments = ['--training_folder', prepped_data_folder],\n                                    run_config=pipeline_run_config)\n# Define a HyperDriveConfiguration\n# The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\nhd_config = HyperDriveConfig(run_config=script_run_config, \n                             hyperparameter_sampling=ps,\n                             policy=early_termination_policy,\n                             primary_metric_name='Accuracy', \n                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                             max_total_runs=3,\n                             max_concurrent_runs=2)\n\n# Step 2b, define a HyperDriveStep\n# HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n# No arguments need to be set as they are already set inside the ScriptRunConfig\nhyperdrive_step = HyperDriveStep(name=&quot;tune_hyperparameters&quot;,\n                                 hyperdrive_config=hd_config,\n                                 inputs=[prepped_data_folder],\n                                 outputs=[metrics_data, saved_model])\n\nhyperdrive_step.run_after(prep_step)    \n\n# Step 3, Run the model registration step\nregister_step = PythonScriptStep(name=&quot;register_model&quot;,\n                                       script_name='cancer_pipeline_register1.py',\n                                       source_directory = pipeline_folder,\n                                       arguments=[&quot;--saved_model&quot;, saved_model],\n                                       inputs=[saved_model],\n                                       compute_target = pipeline_cluster,\n                                       runconfig=pipeline_run_config,\n                                       allow_reuse = False)\n\nregister_step.run_after(hyperdrive_step)    \nprint(&quot;Pipeline steps defined&quot;)\n\n\n# Construct the pipeline\npipeline_steps = [prep_step, hyperdrive_step, register_step]\npipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=&quot;Pipeline for hyperparameter tuning&quot;)\nprint(&quot;Pipeline is built.&quot;)\n<\/code><\/pre>",
        "Question_closed_time":1622098105463,
        "Answer_score_count":5.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Solved the issue!  <\/p>\n<p>Had to remove the <strong>arguments<\/strong>  argument of the ScriptRunConfig and instead set the values to the Hyperdrive Steps <strong>estimator_entry_script_arguments<\/strong> argument.  <\/p>\n<pre><code># Step 1, Run the data prep script\nprep_step = PythonScriptStep(name = &quot;prepare_data&quot;,\n                                source_directory = pipeline_folder,\n                                script_name = &quot;cancer_pipeline_preprocessing.py&quot;,\n                                arguments = ['--input-data', datapath_input,\n                                             '--prepped-data', prepped_data_folder],\n                                inputs=[datapath_input],\n                                outputs=[prepped_data_folder],\n                                compute_target = pipeline_cluster,\n                                runconfig = pipeline_run_config,\n                                allow_reuse=False)\n\n# Define the search strategy and parameter space for hyperparameter tuning\nps = GridParameterSampling({'--max_depth': choice(1,2,3),\n                            '--n_estimators': choice(100,300)})\n# Define a early stopping criteria\nearly_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n# Define a ScriptRunConfig for the Training script\n# The ScriptRunConfig is based on the RunConfig of the Pipeline\nscript_run_config = ScriptRunConfig(script=&quot;cancer_pipeline_tuning.py&quot;,\n                                    source_directory=pipeline_folder,\n                                    run_config=pipeline_run_config)\n# Define a HyperDriveConfiguration\n# The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\nhd_config = HyperDriveConfig(run_config=script_run_config, \n                             hyperparameter_sampling=ps,\n                             policy=None,\n                             primary_metric_name=&quot;Accuracy&quot;, \n                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                             max_total_runs=6,\n                             max_concurrent_runs=2)\n\n# Step 2b, define a HyperDriveStep\n# HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n# No arguments need to be set as they are already set inside the ScriptRunConfig\nhyperdrive_step = HyperDriveStep(name=&quot;tune_hyperparameters&quot;,\n                                 hyperdrive_config=hd_config,\n                                 # Add non-hyperparameter arguments -in this case, the training dataset\n                                 # IMPORTANT: Don't add them already in the ScriptRunConfig\n                                 estimator_entry_script_arguments=['--training_folder', prepped_data_folder],\n                                 inputs=[prepped_data_folder],\n                                 outputs=[metrics_data, saved_model],\n                                 allow_reuse=False)\n<\/code><\/pre>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"How do I access an input parameter in Azure Machine Learning endpoints?",
        "Question_created_time":1602485723003,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123204\/how-do-i-access-an-input-parameter-in-azure-machin",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I've created an Azure ML Endpoint Pipeline with a single 'Execute Python Script'.  From the script, I am looking for a way to access the input 'ParameterAssignments' that I POST to the endpoint to trigger the pipeline.  I expected to see them somewhere in Run.get_context(), but I haven't had any luck.  I simply need a way to POST arbitrary values that my Python scripts can access.  Thank you!<\/p>",
        "Question_closed_time":1603069686240,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>I just confirmed with our engineer that you cannot set up a pipeline parameter and use it without tying it with any of the module parameter. So the workaround is  - make the pipeline parameter as one of the inputs (i.e. dataset) to &quot;Execute Python Script&quot; module and set it as pipeline parameter. Then you can change it every time when calling the pipeline.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Auth Problems with Machine Learning Execute Pipeline Activity.",
        "Question_created_time":1621952386747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/408869\/auth-problems-with-machine-learning-execute-pipeli",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_body":"<p>Hello. Can anyone help with this error? Can not execute Azure ML activity from ADF.  <br \/>\nEverything was ok, no changes was done but suddenly(two-three days ago) I got this error.  <\/p>\n<pre><code>Request sent to Azure ML Service for operation 'submitMLPipelineRun' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{ &quot;error&quot;: { &quot;code&quot;: &quot;UserError&quot;, &quot;severity&quot;: null, &quot;message&quot;: &quot;Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/experiments\/runs\/submit\/action, Microsoft.MachineLearningServices\/workspaces\/endpoints\/pipelines\/read actions.&quot;, &quot;messageFormat&quot;: null, &quot;messageParameters&quot;: null, &quot;referenceCode&quot;: null, &quot;detailsUri&quot;: null, &quot;target&quot;: null, &quot;details&quot;: [], &quot;innerError&quot;: { &quot;code&quot;: &quot;ForbiddenError&quot;, &quot;innerError&quot;: null } '.\n<\/code><\/pre>",
        "Question_closed_time":1621971357963,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=5cdf2b77-a1ae-4f5a-a9c6-d2178ac8e6db\">@Denis Bruk  <\/a>     <\/p>\n<p>We have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Customvision run trained tensorflow model in Python: Placeholder:0 refers to a non existing tensor in image classification",
        "Question_created_time":1621939072900,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/408585\/customvision-run-trained-tensorflow-model-in-pytho",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi all,    <\/p>\n<p>I have trained an image classifier with the customvision service, which worked as charm. Now I would like to run the model inference locally with a python script on my PC. Therefore I have been following the tutorial on <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/export-model-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/export-model-python<\/a>    <\/p>\n<p>I am having troubles with sess.graph.get_tensor_by_name('Placeholder:0').shape.as_list()    <\/p>\n<p>Could you please provide some information on the system requirements and the python package versions? An openCV 4.5.1 C++ code snippet on how to consume the downloaded model would be also great if possible.    <\/p>\n<p>I am using Python 3.8.5    <\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":1622014461963,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thank you, will do.  <\/p>\n<p>I have solved the issue with using C++ openCV instead and WinML also helps with rapid prototyping.   <\/p>\n<p>This was a particularly good example I have found:  <\/p>\n<p><a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-onnx-customvision-sample\">https:\/\/github.com\/Azure-Samples\/cognitive-services-onnx-customvision-sample<\/a>  <\/p>\n<p>Would be great to have more of those.  <\/p>\n<p>Best.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Fisher Linear Discriminant Analysis Azure",
        "Question_created_time":1621855005240,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407053\/fisher-linear-discriminant-analysis-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How is the output of Fisher Linear Discriminant Analysis experiment interpreted now that the column labels in the output are replaced with Col1, Col2, Col3.......etc? How can the model be used to predict clusters of other input data as deployed web service requires even the dependent valuable(the same same ones we wish to predict)?<\/p>",
        "Question_closed_time":1621895240423,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Are you referring to the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/latent-dirichlet-allocation#lda-transformed-dataset\">categories<\/a> generated from LDA module? If so, then that's expected. LDA is an unsupervised technique, it groups words into categories\/topics and it's up to the analyst to interpret it by observing the results and transforming the output dataset accordingly. Here's are some <a href=\"https:\/\/gallery.azure.ai\/browse?s=lda\">examples<\/a> of LDA approach in Azure AI Gallery. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How can i access azure ml pipeline parameters from a python script running in designer?",
        "Question_created_time":1620522230407,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/387875\/how-can-i-access-azure-ml-pipeline-parameters-from",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I would like to perform some data transformations using the Python script module in Designer for which i would need to access some pipeline parameters. How can i get those values?  <\/p>\n<p>What would be the equivalent for an R script?<\/p>",
        "Question_closed_time":1621310816287,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=1b597528-b52c-41fc-932a-baf4d96cb15b\">@javier  <\/a>  Thanks, Currently passing a pipeline parameter to the script of Execute Python\/R Module is not supported. We have a new feature custom module which is in private preview. you can write your own module and use in Designer. If it's a common case, it might be better to use custom module.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Submitted script failed with a non-zero exit code; see the driver log file for details.",
        "Question_created_time":1621178105710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/396708\/submitted-script-failed-with-a-non-zero-exit-code",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, I'm trying to do Hyperparameter tuning a model with Azure Machine Learning with this : <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters<\/a>.    <\/p>\n<p>This time I created dataset from blob storage and used tensor-flow for model.    <\/p>\n<p>I run the code and faced the error saying :       <\/p>\n<p>AzureMLCompute job failed.    <br \/>\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.    <br \/>\n\tReason: Job failed with non-zero exit Code  <\/p>\n<p>so I looked at the driver log file and I guess the error happed around tensor-flow because of ~~ Could not load dynamic library 'libcudart.so.11.0~~    <br \/>\n  So I searched on Google but still I cannot understand. Is tensor-flow model need GPU? or what? Someone could help?     <\/p>\n<p>This is my driver log:    <\/p>\n<p>2021\/05\/16 10:51:45 Starting App Insight Logger for task:  runTaskLet    <br \/>\n2021\/05\/16 10:51:45 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info<\/a>    <br \/>\n2021\/05\/16 10:51:45 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status<\/a>    <br \/>\n[2021-05-16T10:51:45.699995] Entering context manager injector.    <br \/>\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--data-folder', 'DatasetConsumptionConfig:input__c9585223', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam'])    <br \/>\nScript type = None    <br \/>\n[2021-05-16T10:51:47.320428] Entering Run History Context Manager.    <br \/>\n[2021-05-16T10:51:48.009123] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/mounts\/workspaceblobstore\/azureml\/HD_15c1b55e-af9d-4a09-a51a-77021483d144_1    <br \/>\n[2021-05-16T10:51:48.009468] Preparing to call script [train.py] with arguments:['--data-folder', '$input__c9585223', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam']    <br \/>\n[2021-05-16T10:51:48.009538] After variable expansion, calling script [train.py] with arguments:['--data-folder', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/wd\/tmpjipv9560', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam']    <\/p>\n<p>2021-05-16 10:51:48.499303: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/intel64\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/mic\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/intel64\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/mic\/lib:\/azureml-envs\/azureml_9a5f179879cdab6df3327a8de34708df\/lib:    <br \/>\n2021-05-16 10:51:48.499444: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.    <br \/>\n2021\/05\/16 10:51:50 Not exporting to RunHistory as the exporter is either stopped or there is no data.    <br \/>\nStopped: false    <br \/>\nOriginalData: 1    <br \/>\nFilteredData: 0.    <br \/>\nData folder: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/wd\/tmpjipv9560    <\/p>\n<p>[2021-05-16T10:52:00.314862] The experiment failed. Finalizing run...    <br \/>\nCleaning up all outstanding Run operations, waiting 900.0 seconds    <br \/>\n1 items cleaning up...    <br \/>\nCleanup took 0.07348918914794922 seconds    <br \/>\nTraceback (most recent call last):    <br \/>\n  File &quot;train.py&quot;, line 66, in &lt;module&gt;    <br \/>\n    category = int((filename.split('.')[0]).split('_')[1])  <br \/>\nIndexError: list index out of range    <\/p>\n<p>[2021-05-16T10:52:00.547629] Finished context manager injector with Exception.    <br \/>\n2021\/05\/16 10:52:02 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/0e6791a9-a28d-438a-b11f-36b36ecd8da0\/job-1\/hd_15c1b55e-af9d-4a0_5be5fa54-845a-471b-8be4-e1ea80f84819\/wd\/runTaskLetTask_error.json    <br \/>\n2021\/05\/16 10:52:02 Failed to run the wrapper cmd with err: exit status 1    <br \/>\n2021\/05\/16 10:52:02 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status<\/a>    <br \/>\n2021\/05\/16 10:52:02 mpirun version string: {    <br \/>\nIntel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)    <br \/>\nCopyright 2003-2018 Intel Corporation.    <br \/>\n}    <br \/>\n2021\/05\/16 10:52:02 MPI publisher: intel ; version: 2018    <br \/>\n2021\/05\/16 10:52:02 Not exporting to RunHistory as the exporter is either stopped or there is no data.    <br \/>\nStopped: false    <br \/>\nOriginalData: 2    <br \/>\nFilteredData: 0.    <br \/>\n2021\/05\/16 10:52:02 Process Exiting with Code:  1    <br \/>\n2021\/05\/16 10:52:02 All App Insights Logs was send successfully    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wrong display of .ilearner file",
        "Question_created_time":1620835289703,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/392953\/wrong-display-of-ilearner-file",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Can anyone help me with this issue please ?    <br \/>\nI get the file (in .ilearner format) cannot be correctly displayed cuz it contains an unknown extension when I try to open it.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/96073-model.png?platform=QnA\" alt=\"96073-model.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azuremlsdk for R error Could not retrieve user token. Please run 'az login'",
        "Question_created_time":1621290302507,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398420\/azuremlsdk-for-r-error-could-not-retrieve-user-tok",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I'm trying to create a workspace in azure machine learning and receiving this error after 2 browser Windows open and I click log in.<\/p>\n<blockquote>\n<p>library(azuremlsdk)  <br \/>\nnew_ws &lt;- create_workspace(name = 'muffin',<\/p>\n<\/blockquote>\n<ul>\n<li>   subscription_id = 'XXXXXXXXXXXX',<\/li>\n<li>   resource_group = 'white',<\/li>\n<li>   location = 'eastus2',<\/li>\n<li>   create_resource_group = T)  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Error in py_call_impl(callable, dots$args, dots$keywords) :  <br \/>\n    AuthenticationException: AuthenticationException:  <br \/>\n    Message: Could not retrieve user token. Please run 'az login'  <br \/>\n    InnerException It is required that you pass in a value for the &quot;algorithms&quot; argument when calling decode().  <br \/>\n    ErrorResponse  <br \/>\n    {  <br \/>\n    &quot;error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;UserError&quot;,  <br \/>\n    &quot;inner_error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;Authentication&quot;  <br \/>\n    },  <br \/>\n    &quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;  <br \/>\n    }  <br \/>\n    }<\/li>\n<\/ul>\n<p>how do I get passed this error?<\/p>",
        "Question_closed_time":1621844855833,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>You have to use this command to make it install the correct version of miniconda reticulate::py_install(&quot;PyJWT==1.7.1&quot;). If you don't do that it seems to install the wrong version. I also had to manually delete the r-miniconda folder in \\appdata\\local\\r-miniconda which got installed previously to get it to install the correct version. It's pretty outrageous they leave that out of the tutorial when it ain't going to work otherwise.<\/p>\n<p>If you try to do the accident.R tutorial for azuremlsdk-r next make sure you add the line<\/p>\n<p>interactive_auth &lt;- interactive_login_authentication(tenant_id=&quot;&lt;tenant id&gt;&quot;)<\/p>\n<p>to your code otherwise you'll get a permissions error and it won't work.<\/p>\n<p>Then to the create_workspace or get_workspace function you have to add auth = interactive_auth after a comma.<\/p>\n<p>It should look like this<\/p>\n<p>new_ws &lt;- get_workspace(name = &quot;&lt;workspace name&gt;&quot;,  <br \/>\nsubscription_id = &quot;&lt;subscription id&gt;&quot;,  <br \/>\nresource_group = &quot;&lt;resource name&gt;&quot;,  <br \/>\nauth = interactive_auth)<\/p>\n<p>To find the tenant ID I had to download the azure CLI and run the command az login. Not sure if there is another way to find a tenant ID or not.<\/p>\n<p>To leave out critical steps from a tutorial is gross incompetence on the part of Azure. How anyone who isn't a comp sci phd uses this service is a mystery to me.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Which Microsoft tool to apply AI & ML to analyze livechat coversations?",
        "Question_created_time":1621258587277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/397779\/which-microsoft-tool-to-apply-ai-ml-to-analyze-liv",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <\/p>\n<p>I have a project where we want to analyze the content of the livechat, i.e, the livechat conversations (stored in the Azure cloud) with AI and potentially show this information in Power BI dashboards. For example, to identify the topics more discussed in the chat and so on or identify new trends in the chat data  <\/p>\n<p>Which would be the best Microsoft features for such a purpose? R and Azure Microsoft learning?  <br \/>\nAny idea\/recommendations  <\/p>\n<p>Thanks so much,  <br \/>\nJFB<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - correct input dataset however cannot open files needed due to '[Errno 2] No such file or directory'",
        "Question_created_time":1621502815900,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/402690\/azure-machine-learning-correct-input-dataset-howev",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using Microsoft Azure Machine Learning to train a CNN. This is the link to the github where the model is stored: <a href=\"https:\/\/github.com\/rodekruis\/caladrius\/tree\/handle_imbalance\/caladrius\">https:\/\/github.com\/rodekruis\/caladrius\/tree\/handle_imbalance\/caladrius<\/a>. This code already works, I'm just trying to run the model (so do both training\/testing) myself in my own Microsoft Azure Machine Learning environment now. I have the data needed for training, and by following the 'Tutorial: use your own data' (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data<\/a>) I uploaded the data in a datastore, which is of type 'Azure Blob Storage'. Then, I want to run the model such that it starts training. In order to do so, the 'run.py' file in the Github has to be run and I created the following control script to run it in the Microsoft Azure environment:<\/p>\n<pre><code>from azureml.core import Run, Workspace, Datastore, Dataset, Experiment, ScriptRunConfig, Environment  \nfrom azure.identity import DefaultAzureCredential  \nfrom azureml.data.datapath import DataPath  \nfrom azureml.data.dataset_consumption_config import DatasetConsumptionConfig  \nfrom azureml.data import OutputFileDatasetConfig  \n\nif __name__ == &quot;__main__&quot;:  \n    run = Run.get_context()  \n    credential = DefaultAzureCredential()  \n    ws = Workspace.from_config()  \n    datastore = Datastore.get(ws, 'xview')  \n    dataset_small = Dataset.File.from_files(path=(datastore, '\/test_small\/**'))  \n    #print(dataset_small.to_path())  \n    #data_path = DataPath(datastore=datastore, path_on_datastore='test_small\/')  \n\n    checkpoint = OutputFileDatasetConfig(destination=(datastore, '\/test_small\/runs\/'))  \n\n    experiment = Experiment(workspace=ws, name='thesis-sanne')  \n    config = ScriptRunConfig(source_directory='',   \n    script='run.py',   \n    compute_target='standardK80GPU',   \n    arguments = ['--data-path',dataset_small.as_named_input('input').as_mount(),   \n    '--output-type', 'classification',  \n    '--run-name', 'test1',  \n    '--checkpoint-path', checkpoint,  \n    ]  \n    )    \n\n    env= Environment.from_conda_specification(name='caladriusenv', file_path='caladriusenv.yml')  \n    config.run_config.environment = env  \n\n    run = experiment.submit(config)  \n    aml_url = run.get_portal_url()  \n    print(aml_url)  \n<\/code><\/pre>\n<p>when I submit this run, the run fails after receiving the following error:<\/p>\n<blockquote>\n<p>UserError: [Errno 2] No such file or directory: '9e3238da-8b8f-441a-a71a-2f6911f58f33\/train\/labels.txt'<\/p>\n<\/blockquote>\n<p>See also in this picture: Error message from run<\/p>\n<p>The exact error message given in the 70_driver_log.txt file is:<\/p>\n<p>[2021-05-16T08:26:21.977916] The experiment failed. Finalizing run...  <br \/>\n2021-05-16 08:26:21,978 <strong>main<\/strong> INFO Exiting context: TrackUserError  <br \/>\n[2021-05-16T08:26:21.984462] Writing error with error_code UserError and error_hierarchy UserError\/FileNotFoundError to hosttool error file located at \/mnt\/batch\/tasks\/workitems\/073df44a-2932-4bfb-a484-64e6382d81a1\/job-1\/thesis-sanne_1621153_5c453238-c8de-474e-b42c-44f791fbccea\/wd\/runTaskLetTask_error.json  <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 85  <br \/>\n2021-05-16 08:26:22,061 <strong>main<\/strong> INFO Exiting context: RunHistory  <br \/>\n2021-05-16 08:26:22,061 <strong>main<\/strong> INFO Exiting context: Dataset  <br \/>\n2021-05-16 08:26:22,062 <strong>main<\/strong> INFO Exiting context: ProjectPythonPath  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;run.py&quot;, line 59, in &lt;module&gt;  <br \/>\nmain()  <br \/>\nFile &quot;run.py&quot;, line 46, in main  <br \/>\nrun_report, datasets, args.number_of_epochs, args.selection_metric  <br \/>\nFile &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/trainer.py&quot;, line 395, in train  <br \/>\ntrain_set, train_loader = datasets.load(&quot;train&quot;)  <br \/>\nFile &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/data.py&quot;, line 144, in load  <br \/>\naugment_type=self.augment_type,  <br \/>\nFile &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/data.py&quot;, line 75, in <strong>init<\/strong>  <br \/>\nos.path.join(self.directory, self.labels_filename) #self.labels_filename) # &quot;labels.txt&quot;)  <br \/>\nFileNotFoundError: [Errno 2] No such file or directory: '9e3238da-8b8f-441a-a71a-2f6911f58f33\/train\/labels.txt'<\/p>\n<p>However, the datastore itself is found correctly and is stated as the 'Input datasets' in the picture, which includes the 'train\/labels.txt' file I'm trying to open. I checked this in the script, by printing:<\/p>\n<blockquote>\n<p>print(dataset_small.to_path())<\/p>\n<\/blockquote>\n<p>And the output of this included the file '\/train\/labels.txt'<\/p>\n<p>I think my problem is that the script does correctly call the dataset, however the data-path it needs to open the files, is incorrect. Trying to solve this problem I've already tried the following:<\/p>\n<ol>\n<li>  Instead of '--data-path', dataset_small.as_named_input('input').as_mount() I used:\n<ul>\n<li> DataPath(datastore=datastore, path_on_datastore='test_small\/'), however this doesn't work as a DataPath object is not JSON serializable<\/li>\n<li> DataReference(datastore, path_on_datastore='.\/test_small\/', mode='mount'), however this doesn't work as a DataReference object is not JSON serializable<\/li>\n<li> DatasetConsumptionConfig('dataset', dataset_small, mode='direct', path_on_compute=None), this is essentially what I do with Dataset.File.from_files() already and thus also doesn't work<\/li>\n<li> DataPathComputeBinding(mode='mount', path_on_compute=None, overwrite=False), however this doesn't work as a DataPathComputeBinding object is not JSON serializable<\/li>\n<li> datastore_paths = [(blob_datastore, 'test_small')], however this doesn't work as this object is not JSON serializable\n<ol start=\"2\">\n<li>  Instead of accessing the datastore in the Azure Machine Learning environment I tried accessing the datacontainer including the data directly from my Azure Storage account\/container. However the same problem occured.<\/li>\n<\/ol>\n<\/li>\n<\/ul>\n<\/li>\n<\/ol>\n<p>Thus the problem shortly is that my Azure Machine Learning does find the dataset I want it to use, which includes everything needed. However the model is not able to open the datafiles because it says they don't exist whereas I'm sure that they do exist and the Azure Machine Learning environment does know where to find them but does not know how to access\/open them properly I think?<\/p>\n<p>It seems to be an easy to fix problem, however I've tried every way I could think of or was proposed online and still nothing has worked yet. So hopefully someone here can help me, thank you so much in advance! If extra information is needed to clarify things, I'd be glad to provide it.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Python Kernel 3.8.1 runs conda 3.6.9",
        "Question_created_time":1621493873427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/402465\/python-kernel-3-8-1-runs-conda-3-6-9",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,   <br \/>\nI have been trying to run !python trainp.py from yolov5, but is required to have python&gt;=3.7. I tryied to run in the same path the command !python38 train.py but suddently it cant open the file. Is it an azure issue or python issue? How can i fix it.   <br \/>\nThank you.  <\/p>\n<p>I am working in an Azure ML Notebook.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cortana Intelligence Current Diagram",
        "Question_created_time":1621295370853,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398494\/cortana-intelligence-current-diagram",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello. Does anyone have a current diagram like the attached schematic on Cortana Intelligence?  This diagram seems to be outdated.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/97284-cortana-intelligence.png?platform=QnA\" alt=\"97284-cortana-intelligence.png\" \/>    <\/p>",
        "Question_closed_time":1621443861350,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>I have seen a lot of similar version but I can't find any official date for it. Could you please share where\/ which conference you found this so that we can check with related team for more information?    <\/p>\n<p><img src=\"https:\/\/msdnshared.blob.core.windows.net\/media\/2016\/09\/Session-2-Cortana-Intelligence-Suite-Overview-1024x576.png\" alt=\"Session-2-Cortana-Intelligence-Suite-Overview-1024x576.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/97928-2555cas.jpg?platform=QnA\" alt=\"97928-2555cas.jpg\" \/>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Help for Azure ML Studio experiment data translation",
        "Question_created_time":1621017033187,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/395846\/help-for-azure-ml-studio-experiment-data-translati",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am learning Azure ML (Studio) and please help me for below scenarios,  <br \/>\nI have a bank customer data having column labelled as customer age, family members (1,2,3 &amp;4), credit card (Yes \/no) Personal Loan (Yes \/no), education (1. Undergrad 2. Graduate 3. Advanced\/professional), Experience in year  (with -ve values) .  <\/p>\n<ol>\n<li> How to find % customers who are having credit card as well Personal loan?  <\/li>\n<li> How to compare education category with customers to found  possibility of more  subscribe to personal loan?  <\/li>\n<li> How to change -ve experience to 0   <\/li>\n<\/ol>\n<p>4.How to do visual analysis?  <\/p>\n<ol start=\"5\">\n<li> How to calculate correlation between 2 columns?  <\/li>\n<\/ol>\n<p>Thanks in advance for your guidance. and incase tag to wrong group please guide to appropriate group  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot create Azure ML resource",
        "Question_created_time":1621368566277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/399949\/cannot-create-azure-ml-resource",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to create a Machine Learning resource in a resource group where I am a Contributor but I get an error saying:   <\/p>\n<p> {&quot;code&quot;:&quot;AuthorizationFailed&quot;,&quot;message&quot;:&quot;The client 'XXXXXXX' with object id 'XXXXX-XXXXXX_XXXXXX' does not have authorization to perform action 'Microsoft.MachineLearningServices\/register\/action' over scope '\/subscriptions\/XXXXX-XXXX-XXXXXXX' or the scope is invalid. If access was recently granted, please refresh your credentials. (Code: AuthorizationFailed)&quot;}  <\/p>\n<p>I have had access for a while now and I can create other resources like a Azure Databricks Service or VM so I am not sure if this a permissions issue or what I need to change to be able to create a Machine Learning resource.   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Notebook - Jupyter Kernel Error - No Kernel Connecl",
        "Question_created_time":1595605454123,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/52057\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML i am following the tutorial to execute a notebook and when i open the notebook and have a valid compute (running as well as the green icon) it shows an error 'Jupyter Kernel Error'. On the far right of the screen it says 'No Kernel Connnected'. What is needed to connect the kernel?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Debugging the Execute Python Scripts model in Azure\u2013ML: Where can I find the print statements?",
        "Question_created_time":1621349529943,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/399653\/debugging-the-execute-python-scripts-model-in-azur",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am using Azure Machine Learning \u2013 Designer (drag-n-drop) \u2013\u00a0to train an ML model. While doing so, I require to execute some Python code &amp; hence decided to use the Execute Python Script module available.     <\/p>\n<p>While writing the script, I added print statements because it would allow for easier debugging. However, I have had no luck in finding a file where the print statements are stored.     <\/p>\n<p>I have tried the <a href=\"https:\/\/stackoverflow.com\/questions\/59881727\/debugging-r-scripts-in-azure-ml-where-can-stdout-and-stderr-logs-be-found-or\">following solution<\/a>. On failure of the script, this method (opening 70_driver_log.txt and searching for messages) only shows me the error returned by the Python Interpreter, but it doesn't show me any print statements at all. For example:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/97526-screenshot-2021-05-18-at-64950-pm.png?platform=QnA\" alt=\"97526-screenshot-2021-05-18-at-64950-pm.png\" \/>    <\/p>\n<p>Similarly, on success, no print statements are displayed.     <\/p>\n<p>Additionally, <em>logs &gt; azureml &gt; stdoutlogs .txt<\/em> is completely empty.     <\/p>\n<p>What clue am I missing? Any help is appreciated!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"is there any way I can serialize the R model which trained using caret or some other libraries instead of RevoScaleR?",
        "Question_created_time":1621302852490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398544\/is-there-any-way-i-can-serialize-the-r-model-which",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I am using SQL Server Machine Learning services to Run a R model. I am able to serialize it using RevoScaleR and rxSerializeModel but I want to use caret instead of RevoScaleR here is my code which is giving an error when asks to serialiaze the trained model    <\/p>\n<p>Step1 train model using SP    <\/p>\n<p>   DROP PROCEDURE IF EXISTS generate_PCL_R_native_model;    <br \/>\ngo    <br \/>\nCREATE PROCEDURE generate_PCL_R_native_model (<a href=\"\/users\/na\/?userid=0f55de7e-bffd-0003-0000-000000000000\">@\u9ed8  <\/a>_type varchar(30), @trained_model varbinary(max) OUTPUT)    <br \/>\nAS    <br \/>\nBEGIN    <\/p>\n<pre><code>EXECUTE sp_execute_external_script  \n  @language = N'R'                                  -- Spesify langauge and R code   \n\n, @script = N'                                        \n<\/code><\/pre>\n<p>require(&quot;RevoScaleR&quot;)    <br \/>\nrequire(&quot;caret&quot;)    <br \/>\nrequire(&quot;ranger&quot;)    <br \/>\nlibrary(caret)    <br \/>\nlibrary(ranger)    <\/p>\n<p>fitControl &lt;- trainControl(method = &quot;cv&quot;,     <br \/>\n                           number = 5,  <\/p>\n<pre><code>                       savePredictions = TRUE  \n                      ,  \n                         \n                       classProbs = T,   \n                      verboseIter = F  \n                       )  \n\n                       rf_grid &lt;- expand.grid(mtry = 2,  \n                   splitrule = c(&quot;gini&quot;, &quot;extratrees&quot;),  \n                   min.node.size = c(1, 3, 5));  \n<\/code><\/pre>\n<p>if(model_type == &quot;dtree&quot;) {    <br \/>\nmodel_linmod &lt;-     <br \/>\ntrain(pclitemspct10r_new ~       <\/p>\n<pre><code>+ d1  \n+ d2  \n+ d3  \n+ d4  \n+ d5  \n+ d6  \n+ d7  \n+ e1  \n+ e2  \n+ e3  \n+ e4  \n+ e5  \n+ e6  \n+ marriedd1  \n+ marriedd2  \n\n  \n  \n  \n, data = PCL_train_data,   \n            method = &quot;ranger&quot;,  \n            trControl = fitControl,  \n            #tuneGrid = rf_grid  \n            )  \n  \n\n\n#serialize the model  \n  \ntrained_model &lt;- as.raw(serialize((model_linmod, NULL));  \n}  \n<\/code><\/pre>\n<p>'    <\/p>\n<pre><code>, @input_data_1 = N'select  * from [dbo].[training_IOP_data_new]'  \n, @input_data_1_name = N'PCL_train_data';   \n<\/code><\/pre>\n<p>STEP 2 - Setup model table for storing the model    <\/p>\n<p>DROP TABLE IF EXISTS  PCL_models;    <br \/>\nGO    <br \/>\nCREATE TABLE PCL_models (    <br \/>\n                model_name VARCHAR(30) NOT NULL DEFAULT('default model'),  <br \/>\n                lang VARCHAR(30),  <br \/>\n                model VARBINARY(MAX),  <br \/>\n                native_model VARBINARY(MAX),  <br \/>\n                PRIMARY KEY (model_name, lang)  <\/p>\n<p>);    <br \/>\nGO     <br \/>\nStep 3 Save the model in table format    <\/p>\n<p>DECLARE @model2 VARBINARY(MAX);    <br \/>\nEXEC generate_PCL_R_native_model &quot;dtree&quot;, @model2 OUTPUT;    <br \/>\nINSERT INTO PCL_models (model_name, native_model, lang) VALUES('dtree_model', @model2, 'R');    <\/p>\n<p>is there any way I can serialize the R model which trained using caret or some other libraries instead of RevoScaleR.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Variable Importance in AutoML Experiment",
        "Question_created_time":1620845444243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/393120\/variable-importance-in-automl-experiment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We have create a classification experiment using AutoML.  We can not find any output related to variable importance, propensity scores, or coefficients.  Please tell us how to get this or find it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer: Automatically Update AKS Webservice After Training",
        "Question_created_time":1620652503773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/389170\/azure-ml-designer-automatically-update-aks-webserv",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>As part of our MLOps flow, we need to retrain a machine learning model using the AML designer, and then update the AKS webservice with the new machine learning model (+ a couple of other supplementary training artifacts), also from the designer.  <\/p>\n<p>We have built an inference pipeline to do this, and are able to run it manually. However, the solution requirements require this process to be automated. We have previously successfully automated this through the python SDK and the akswebservice.update method, but this solution has a hard requirement to use the designer only (custom python code blocks would be allowed, however).  <\/p>\n<p>Is there a way, using any Azure services (eg Azure Data Factory, Azure DevOps), that we can kick off a designer real time inference update pipeline immediately after its associated training pipeline finishes executing, in order to get the latest model version into the webservice, without any manual intervention? To be clear though, manual intervention is acceptable to build the initial inference pipeline for version 1, but not on the retraining cycle.<\/p>",
        "Question_closed_time":1620691417853,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, thanks for reaching out. Currently, you can only use the Azure Machine Learning SDK to automatically <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update the web service<\/a>. I'm inquiring from the product team whether there are plans to support this scenario (will share updates accordingly). Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure AutoML via User Interface",
        "Question_created_time":1621023165310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/396020\/azure-automl-via-user-interface",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When we use Azure AutoML via User Interface, what data do they use to calculate the metrics?  <br \/>\nDo they train test split? If so, the metrics return from the test data?  <br \/>\nOr they use the whole data to validate the models. Thus, the metrics are from cross-validation.   <br \/>\nIf they use the whole data set to train, I should do the train-test split and only upload a train data set (I should clean data first). Then deploy the models with the test data to see how accurate the model is.  <br \/>\nIf it is that case, this function is such a useless function.   <br \/>\nI can use Python SDK directly.  <br \/>\nPlease help me to clarify if it is that case. The metrics are only from cross-validation.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In Azure Machine Learning Attach Compute - what is the format of private key?",
        "Question_created_time":1621000694820,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/395761\/in-azure-machine-learning-attach-compute-what-is-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am trying to attach an Azure Data Science Virtual Machine in my workspace.    <br \/>\nI have created the Azure VM previously and had the wizard generate public\/private key for me. During creation I was prompted to download the private key and I have that on my machine. I am also able to SSH into the machine successfully by passing the path to the private key on my machine.    <\/p>\n<p>However, during the wizard to attach this machine to my machine workspace I am not sure what 'value' I actually need to put into the private key box.    <\/p>\n<p>Furthermore, during the creation of the VM - I was never asked to input a passphrase.     <\/p>\n<p>Should I create a new key once I SSH into the VM?    <br \/>\nEven with that - what is the value one pastes into this box?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/96696-2021-05-13-22-09-09-compute-microsoft-azure-machin.png?platform=QnA\" alt=\"96696-2021-05-13-22-09-09-compute-microsoft-azure-machin.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",",
        "Question_created_time":1619621454417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/375577\/submitted-script-failed-with-a-non-zero-exit-code",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi All,    <br \/>\nI am trying to creating batch inference of my pretrained churn classification model. I  was following this  github of  iris  batch inference   <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92040-screenshot-1.png?platform=QnA\">1<\/a>: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb<\/a> .    <br \/>\nBut I am getting error , please help me how can I  fix this error.    <\/p>\n<p>Here my code:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92040-screenshot-1.png?platform=QnA\" alt=\"92040-screenshot-1.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92147-screenshot-2.png?platform=QnA\" alt=\"92147-screenshot-2.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92165-screenshot-3.png?platform=QnA\" alt=\"92165-screenshot-3.png\" \/>    <\/p>\n<p>Here my errors:    <\/p>\n<pre><code>========================================================================================================================  \n2  \n. Please ignore this if the GPUs don't utilize NVIDIA\u00ae NVLink\u00ae switches.  \n2021-04-28T12:53:39Z Starting output-watcher...  \n2021-04-28T12:53:39Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption  \n2021-04-28T12:53:39Z Executing 'Copy ACR Details file' on 10.0.0.4  \n2021-04-28T12:53:39Z Copy ACR Details file succeeded on 10.0.0.4. Output:   \n&gt;&gt;&gt;     \n&gt;&gt;&gt;     \nLogin Succeeded  \nUsing default tag: latest  \nlatest: Pulling from azureml\/azureml_af590fdfaae8ba3ead1eba5ea12b0fb3  \n4007a89234b4: Pulling fs layer  \n5dfa26c6b9c9: Pulling fs layer  \n0ba7bf18aa40: Pulling fs layer  \n4c6ec688ebe3: Pulling fs layer  \n574f361512d6: Pulling fs layer  \ndb4d1e2d7079: Pulling fs layer  \ne544ee0f522d: Pulling fs layer  \nc655136086be: Pulling fs layer  \n2ec37f44090c: Pulling fs layer  \n5fba3bd4a2c4: Pulling fs layer  \n7e0ea9d0a1ab: Pulling fs layer  \nda005f826951: Pulling fs layer  \n6e842608b724: Pulling fs layer  \n6b1a4187f1d0: Pulling fs layer  \ndb4d1e2d7079: Waiting  \nc763bae43813: Pulling fs layer  \n490d7c37a7d7: Pulling fs layer  \n791bb1082f38: Pulling fs layer  \ne544ee0f522d: Waiting  \ne863af755720: Pulling fs layer  \nc655136086be: Waiting  \n4c6ec688ebe3: Waiting  \n0cb6e30b3f1c: Pulling fs layer  \n88468e3f4c2c: Pulling fs layer  \n77d6ac8c0bf7: Pulling fs layer  \n574f361512d6: Waiting  \n2ec37f44090c: Waiting  \nda005f826951: Waiting  \n5fba3bd4a2c4: Waiting  \n6e842608b724: Waiting  \n6b1a4187f1d0: Waiting  \nc763bae43813: Waiting  \n490d7c37a7d7: Waiting  \n791bb1082f38: Waiting  \ne863af755720: Waiting  \n0cb6e30b3f1c: Waiting  \n88468e3f4c2c: Waiting  \n77d6ac8c0bf7: Waiting  \n7e0ea9d0a1ab: Waiting  \n0ba7bf18aa40: Verifying Checksum  \n0ba7bf18aa40: Download complete  \n5dfa26c6b9c9: Verifying Checksum  \n5dfa26c6b9c9: Download complete  \n4c6ec688ebe3: Verifying Checksum  \n4c6ec688ebe3: Download complete  \n4007a89234b4: Download complete  \ndb4d1e2d7079: Verifying Checksum  \ndb4d1e2d7079: Download complete  \ne544ee0f522d: Verifying Checksum  \ne544ee0f522d: Download complete  \n574f361512d6: Verifying Checksum  \n574f361512d6: Download complete  \n4007a89234b4: Pull complete  \n5dfa26c6b9c9: Pull complete  \n0ba7bf18aa40: Pull complete  \n4c6ec688ebe3: Pull complete  \n5fba3bd4a2c4: Download complete  \nc655136086be: Verifying Checksum  \nc655136086be: Download complete  \n7e0ea9d0a1ab: Verifying Checksum  \n7e0ea9d0a1ab: Download complete  \nda005f826951: Verifying Checksum  \nda005f826951: Download complete  \n6e842608b724: Download complete  \n6b1a4187f1d0: Download complete  \nc763bae43813: Verifying Checksum  \nc763bae43813: Download complete  \n2ec37f44090c: Verifying Checksum  \n2ec37f44090c: Download complete  \n490d7c37a7d7: Verifying Checksum  \n490d7c37a7d7: Download complete  \n0cb6e30b3f1c: Verifying Checksum  \n0cb6e30b3f1c: Download complete  \ne863af755720: Verifying Checksum  \ne863af755720: Download complete  \n77d6ac8c0bf7: Verifying Checksum  \n77d6ac8c0bf7: Download complete  \n88468e3f4c2c: Verifying Checksum  \n88468e3f4c2c: Download complete  \n574f361512d6: Pull complete  \ndb4d1e2d7079: Pull complete  \ne544ee0f522d: Pull complete  \n791bb1082f38: Verifying Checksum  \n791bb1082f38: Download complete  \nc655136086be: Pull complete  \n2ec37f44090c: Pull complete  \n5fba3bd4a2c4: Pull complete  \n7e0ea9d0a1ab: Pull complete  \nda005f826951: Pull complete  \n6e842608b724: Pull complete  \n6b1a4187f1d0: Pull complete  \nc763bae43813: Pull complete  \n490d7c37a7d7: Pull complete  \n  \nStreaming azureml-logs\/65_job_prep-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt  \n===============================================================================================================  \n[2021-04-28T12:54:05.020376] Entering job preparation.  \n[2021-04-28T12:54:08.337333] Starting job preparation.  \n[2021-04-28T12:54:08.337375] Extracting the control code.  \n[2021-04-28T12:54:08.365360] fetching and extracting the control code on master node.  \n[2021-04-28T12:54:08.365417] Starting extract_project.  \n[2021-04-28T12:54:08.365467] Starting to extract zip file.  \n[2021-04-28T12:54:09.302078] Finished extracting zip file.  \n[2021-04-28T12:54:09.804262] Using urllib.request Python 3.0 or later  \n[2021-04-28T12:54:09.804327] Start fetching snapshots.  \n[2021-04-28T12:54:09.804373] Start fetching snapshot.  \n[2021-04-28T12:54:09.804391] Retrieving project from snapshot: f4a38de4-3230-4038-ac4b-cde33bdd63e5  \nStarting the daemon thread to refresh tokens in background for process with pid = 51  \n[2021-04-28T12:54:10.714200] Finished fetching snapshot.  \n[2021-04-28T12:54:10.714233] Start fetching snapshot.  \n[2021-04-28T12:54:10.714251] Retrieving project from snapshot: b71de588-0f3c-44ae-b144-ea24a905546e  \n[2021-04-28T12:54:24.343681] Finished fetching snapshot.  \n[2021-04-28T12:54:24.343714] Finished fetching snapshots.  \n[2021-04-28T12:54:24.343728] Finished extract_project.  \n[2021-04-28T12:54:24.360941] Finished fetching and extracting the control code.  \n[2021-04-28T12:54:24.364330] downloadDataStore - Download from datastores if requested.  \n[2021-04-28T12:54:24.365371] Start run_history_prep.  \n[2021-04-28T12:54:24.436823] Entering context manager injector.  \nAcquired lockfile \/tmp\/a1c4fded-7336-4024-8c9e-fed19f5d1b37-datastore.lock to downloading input data references  \n[2021-04-28T12:54:24.903804] downloadDataStore completed  \n[2021-04-28T12:54:24.906597] Job preparation is complete.  \n  \nStreaming azureml-logs\/70_driver_log.txt  \n========================================  \n2021\/04\/28 12:54:26 Starting App Insight Logger for task:  runTaskLet  \n2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/info  \n2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status  \n[2021-04-28T12:54:27.564276] Entering context manager injector.  \n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', '  \n2021\/04\/28 12:54:31 Not exporting to RunHistory as the exporter is either stopped or there is no data.  \nStopped: false  \nOriginalData: 1  \nFilteredData: 0.  \n  \nStreaming azureml-logs\/75_job_post-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt  \n===============================================================================================================  \n[2021-04-28T13:02:20.275818] Entering job release  \n[2021-04-28T13:02:21.348190] Starting job release  \n[2021-04-28T13:02:21.348739] Logging experiment finalizing status in history service.  \nStarting the daemon thread to refresh tokens in background for process with pid = 1369  \n[2021-04-28T13:02:21.349418] job release stage : upload_datastore starting...  \n[2021-04-28T13:02:21.349812] job release stage : start importing azureml.history._tracking in run_history_release.  \n[2021-04-28T13:02:21.352029] job release stage : copy_batchai_cached_logs starting...  \n[2021-04-28T13:02:21.352142] job release stage : execute_job_release starting...  \n[2021-04-28T13:02:21.357651] job release stage : copy_batchai_cached_logs completed...  \n[2021-04-28T13:02:21.358513] Entering context manager injector.  \n[2021-04-28T13:02:21.372410] job release stage : upload_datastore completed...  \n[2021-04-28T13:02:21.595288] job release stage : execute_job_release completed...  \n[2021-04-28T13:02:21.628735] job release stage : send_run_telemetry starting...  \n[2021-04-28T13:02:21.849387] get vm size and vm region successfully.  \n[2021-04-28T13:02:22.175695] get compute meta data successfully.  \n[2021-04-28T13:02:22.444070] post artifact meta request successfully.  \n[2021-04-28T13:02:22.471466] upload compute record artifact successfully.  \n[2021-04-28T13:02:22.471531] job release stage : send_run_telemetry completed...  \n[2021-04-28T13:02:22.471747] Job release is complete  \n  \nStepRun(batch-score) Execution Summary  \n=======================================  \nStepRun( batch-score ) Status: Failed  \n---------------------------------------------------------------------------  \nActivityFailedException                   Traceback (most recent call last)  \n&lt;ipython-input-30-49d7d34a142d&gt; in &lt;module&gt;  \n      3 # Run the pipeline as an experiment  \n      4 pipeline_run = Experiment(ws, 'batc-prediction_pipeline').submit(pipeline)  \n----&gt; 5 pipeline_run.wait_for_completion(show_output=True)  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)  \n    293                             try:  \n    294                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,  \n--&gt; 295                                                              raise_on_error=raise_on_error)  \n    296                             except TypeError as e:  \n    297                                 # If there are package conflicts in the user's environment, the run rehydration  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)  \n    735             try:  \n    736                 return self._stream_run_output(timeout_seconds=timeout_seconds,  \n--&gt; 737                                                raise_on_error=raise_on_error)  \n    738             except KeyboardInterrupt:  \n    739                 error_message = &quot;The output streaming for the run interrupted.\\n&quot; \\  \n  \n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in _stream_run_output(self, timeout_seconds, raise_on_error)  \n    823             print(json.dumps(error, indent=4))  \n    824         if error and raise_on_error:  \n--&gt; 825             raise ActivityFailedException(error_details=json.dumps(error, indent=4))  \n    826   \n    827         print(final_details)  \n  \nActivityFailedException: ActivityFailedException:  \n Message: Activity Failed:  \n{  \n    &quot;error&quot;: {  \n        &quot;code&quot;: &quot;UserError&quot;,  \n        &quot;message&quot;: &quot;AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code&quot;,  \n        &quot;messageFormat&quot;: &quot;{Message}&quot;,  \n        &quot;messageParameters&quot;: {  \n            &quot;Message&quot;: &quot;AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code&quot;  \n        },  \n        &quot;details&quot;: [],  \n        &quot;innerError&quot;: {  \n            &quot;code&quot;: &quot;UserTrainingScriptFailed&quot;  \n        }  \n    },  \n    &quot;correlation&quot;: {  \n        &quot;operation&quot;: null,  \n        &quot;request&quot;: &quot;6833f86b6a0c0af1&quot;  \n    },  \n    &quot;environment&quot;: &quot;eastus&quot;,  \n    &quot;location&quot;: &quot;eastus&quot;,  \n    &quot;time&quot;: &quot;2021-04-28T13:02:41.490064Z&quot;,  \n    &quot;componentName&quot;: &quot;execution-worker&quot;  \n}  \n InnerException None  \n ErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;message&quot;: &quot;Activity Failed:\\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n        \\&quot;message\\&quot;: \\&quot;AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\&quot;,\\n        \\&quot;messageFormat\\&quot;: \\&quot;{Message}\\&quot;,\\n        \\&quot;messageParameters\\&quot;: {\\n            \\&quot;Message\\&quot;: \\&quot;AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\&quot;\\n        },\\n        \\&quot;details\\&quot;: [],\\n        \\&quot;innerError\\&quot;: {\\n            \\&quot;code\\&quot;: \\&quot;UserTrainingScriptFailed\\&quot;\\n        }\\n    },\\n    \\&quot;correlation\\&quot;: {\\n        \\&quot;operation\\&quot;: null,\\n        \\&quot;request\\&quot;: \\&quot;6833f86b6a0c0af1\\&quot;\\n    },\\n    \\&quot;environment\\&quot;: \\&quot;eastus\\&quot;,\\n    \\&quot;location\\&quot;: \\&quot;eastus\\&quot;,\\n    \\&quot;time\\&quot;: \\&quot;2021-04-28T13:02:41.490064Z\\&quot;,\\n    \\&quot;componentName\\&quot;: \\&quot;execution-worker\\&quot;\\n}&quot;  \n    }  \n}  \n  \n\u200b  \n  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer - Replace existing real-time inference endpoint error",
        "Question_created_time":1613636477313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/278158\/azure-ml-designer-replace-existing-real-time-infer",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>Hi,  <\/p>\n<p>When replacing an existing, healthy Azure ML End-point through the Azure ML Designer, I get the following error:  <\/p>\n<pre><code>Failed on Preparing to deploy. Details: AzureML service API error. Error calling ServicePatch: {&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;EmptyOrInvalidParameter&quot;,&quot;message&quot;:&quot;Cannot set both number of replicas and auto scale settings in the same request&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;14982e6e-dc63-4732-964b-55027243dac3&quot;}}\n<\/code><\/pre>\n<p>The current endpoint I'm trying to replace was created a few days ago. It has:   <\/p>\n<ul>\n<li> Autoscale enabled == true  <\/li>\n<li> Min\/Max replicas == 1\/10  <\/li>\n<\/ul>\n<p>The deploy menu does not contain an option to change or set these values. Therefore, I do not understand why the request fails.  <\/p>\n<p>Could you help me fix this issue?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Help for Azure ML Studio experiment mapping",
        "Question_created_time":1620716372030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/390316\/help-for-azure-ml-studio-experiment-mapping",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am learning Azure ML (Studio) and please help me for below scenarios,   <br \/>\nI have a bank customer data having column labelled as customer age, family members (1,2,3 &amp;4), credit card (Yes \/no) Personal Loan (Yes \/no), education (1. Undergrad 2. Graduate 3. Advanced\/professional).   <\/p>\n<ol>\n<li> How to filter age column and find number of customers less than 45 years in % of total number of customers?   <\/li>\n<li> Also need % customers who are having credit card as well Personal loan?  <\/li>\n<li> which education category of customers are more prone to subscribe to personal loan?  <\/li>\n<li> How to do visual analysis?  <\/li>\n<li> How to calculate correlation between 2 columns?  <\/li>\n<\/ol>\n<p>Thanks in advance for your guidance. and incase tag to wrong group please guide to appropriate group  <\/p>",
        "Question_closed_time":1620774454347,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi, thanks for reaching out. I am assuming you are using Azure ML Studio Designer to work on this scenario. Please review response below:    <\/p>\n<ol>\n<li> How to filter age column and find number of customers less than 45 years in % of total number of customers? <strong>As part of your <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/module-reference#data-preparation-modules\">data preparations step<\/a>, you can use available data transformation modules such as <code>apply sql transformation<\/code> and <code>apply math operation<\/code> to perform data transformations.<\/strong>    <\/li>\n<li> Also need % customers who are having credit card as well Personal loan? <em><strong>Similar to 1 above.<\/strong><\/em>    <\/li>\n<li> Which education category of customers are more prone to subscribe to personal loan? <em><strong>This seems to be a <code>multi-classification problem<\/code> where you'd want to predict several categories. AML Studio has the following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/module-reference#machine-learning-algorithms\">modules and algorithms<\/a> for predicting classes. For future reference, this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-cheat-sheet\">document<\/a> helps you identify which algorithm to select based on the ML scenario.<\/strong><\/em>    <\/li>\n<li> How to do visual analysis? <strong>With Azure ML Designer, you can <code>Right Click on a module<\/code> and <code>select Visualize<\/code> to visualize dataset output or results.<\/strong>    <\/li>\n<li> How to calculate correlation between 2 columns? <strong>You can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/filter-based-feature-selection\">Filter Based Feature Selection<\/a> to identify the columns in your input dataset that have the greatest predictive power. The module includes correlation methods such as <code>Pearson correlation<\/code> and <code>Chi-Squared<\/code>.<\/strong>    <\/li>\n<\/ol>\n<p>Also, here are some useful resources to help get you started:    <\/p>\n<ul>\n<li> Azure Machine Learning <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/\">Documentation<\/a>.    <\/li>\n<li> Sample <strong>tutorials<\/strong> are available in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\">Designer<\/a> (<strong>newer drag and drop interface<\/strong>. <code>Click Designer<\/code>, select <code>More Samples<\/code>) and Classic (<strong>older drag and drop interface<\/strong>, via <a href=\"https:\/\/gallery.azure.ai\/browse\">Azure AI Gallery<\/a>, although some modules may not be available in designer, but a great starting point as well).    <\/li>\n<\/ul>\n<p>Hope this helps!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Pre-existing Compute Resource necessary for running a scheduled ML pipeline?",
        "Question_created_time":1620803656847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/392165\/pre-existing-compute-resource-necessary-for-runnin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi fellows,  <br \/>\nI have been exploring Azure ML Pipeline. I am referring to <a href=\"https:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/06A%20-%20Creating%20a%20Pipeline.ipynb\">this notebook<\/a> for the below code:<\/p>\n<p>Here is a small snippet from a MS Repo:  <br \/>\ntrain_step = PythonScriptStep(name = &quot;Prepare Data&quot;,  <br \/>\nsource_directory = experiment_folder,  <br \/>\nscript_name = &quot;prep_diabetes.py&quot;,  <br \/>\narguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),  <br \/>\n'--prepped-data', prepped_data_folder],  <br \/>\noutputs=[prepped_data_folder],  <br \/>\ncompute_target = pipeline_cluster,  <br \/>\nrunconfig = pipeline_run_config,  <br \/>\nallow_reuse = True)<\/p>\n<p>This suggests that while defining a pipeline, we must provide it a compute resource. This obviously makes sense, since specific compute might be required for a specific step.<\/p>\n<p>But do we need to have this compute resource up and running always, so that whenever a pipeline is triggered, it can find the compute resource?<\/p>\n<p>Also, i figured we can probably keep a cluster with Zero minimum nodes, in which cases cluster is resized whenever pipeline is triggered. But i think there is a minimal cost incurrent in probably container registry regularly in such a setup. Is this the recommended way to deploy ML pipelines or some more efficient approach is possible?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Images are not shown in AML notebooks output cell",
        "Question_created_time":1620103839040,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/381476\/images-are-not-shown-in-aml-notebooks-output-cell",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>The matplotlib \/ raster libraries show method doesn't show the images plotted in notebook cell output. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment on Azure Machine Learning services is not starting.",
        "Question_created_time":1620678944347,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/389811\/experiment-on-azure-machine-learning-services-is-n",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I run an experiment in the azure ml service using an associated VM, but the experiment status is as follows:    <\/p>\n<p><strong>Job  runstatus is NotStarted<\/strong>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/95403-image.png?platform=QnA\" alt=\"95403-image.png\" \/>    <\/p>\n<p>ID execution 75ff42c9-2fbd-48c2-beec-b72aa38f1d00    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ml pipeline fails at sql transform task",
        "Question_created_time":1620697549357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/390003\/azure-ml-pipeline-fails-at-sql-transform-task",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I'm using Azure ML Designer to run a pipeline. The pipeline performs a few steps and then it cancels the work throwing an error message with no further details.  <\/p>\n<p>If I re-submit the pipeline it completes the previously failed step but fails on the next step. If I re-submit the same thing happens (completes previously failed step to then fail the next step)... until it gets stuck in a specific sql transform step (see log below)  <\/p>\n<p>Here is a sequence of  run ids related with the issue:  <br \/>\nd33d23a2-2e60-4198-a6b6-f47e6e27ef4e  <br \/>\n57e04c1e-73e8-4ddf-91a8-c407cd1ad5ef  <br \/>\nad7dc826-6549-4eb3-9536-9a801d8e8c0b  <br \/>\ne6623f6f-b7b9-4f19-9501-c8c28f53ab23  <\/p>\n<p>It may be due to the way my pipeline is built but seems like JOIN, SQL Transform and SELECT Column operations tend to fail the most.  <\/p>\n<p>Would much appreciate any help on this.  <\/p>\n<pre><code>2021\/05\/11 01:57:24 Starting App Insight Logger for task:  runTaskLet\n2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/info\n2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/status\n[2021-05-11T01:57:24.912444] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', 'DatasetOutputConfig:Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22'])\nScript type = None\n[2021-05-11T01:57:26.142183] Entering Run History Context Manager.\n[2021-05-11T01:57:26.734197] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/mounts\/workspaceblobstore\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\n[2021-05-11T01:57:26.734493] Preparing to call script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '$Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n[2021-05-11T01:57:26.734551] After variable expansion, calling script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n\nSession_id = 4b5b4c29-cfda-4ab6-a715-47fee287c468\nInvoking module by urldecode_invoker 0.0.8.\n\nModule type: custom module.\n\nUsing runpy to invoke module 'azureml.designer.modules.datatransform.invoker'.\n\n\/azureml-envs\/azureml_7c975cabc8bb1dc19c3de94457d707fd\/lib\/python3.6\/site-packages\/azureml\/designer\/modules\/datatransform\/tools\/dataframe_utils.py:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n  from pandas.util.testing import assert_frame_equal\n2021-05-11 01:57:27,324 [             invoker] [    INFO] .[main] Start custom modules\n2021-05-11 01:57:27,337 [             invoker] [    INFO] .[main] Module version: 0.0.74\n2021-05-11 01:57:27,344 [             invoker] [    INFO] .[main] args: azureml.designer.modules.datatransform.invoker, ApplySqlTransModule, --dataset, \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu, --t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr, --t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy, --t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji, --sqlquery=select b.*,c.*\nfrom (\n    select a.customer_id, a.sku_id\n    from (\n        select * from t1 cross join t2\n    ) a\n    where exists (\n        select t3.top_skus\n        from t3\n        where t3.sku_id = a.sku_id\n    )\n) b\ninner join (\n    select distinct sku_id, top_skus\n    from t3\n) c\non c.sku_id = b.sku_id\n2021-05-11 01:57:27,352 [             invoker] [    INFO] .[main] &quot;transform_module_class_name&quot;: ApplySqlTransModule\n2021-05-11 01:57:27,444 [         module_base] [    INFO] ...[get_arg_parser] Construct arg parser\n2021-05-11 01:57:27,460 [         module_base] [    INFO] ...[get_arg_parser] arg: t1\n2021-05-11 01:57:27,468 [         module_base] [    INFO] ...[get_arg_parser] arg: t2\n2021-05-11 01:57:27,476 [         module_base] [    INFO] ...[get_arg_parser] arg: t3\n2021-05-11 01:57:27,484 [         module_base] [    INFO] ...[get_arg_parser] arg: dataset\n2021-05-11 01:57:27,492 [         module_base] [    INFO] ...[get_arg_parser] arg: sqlquery\n2021-05-11 01:57:27,500 [         module_base] [    INFO] ..[parse_and_insert_args] invoker args:\n module_classname = ApplySqlTransModule\n t1 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n t2 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n t3 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n dataset = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu\n sqlquery = select b.*,c.*\nfrom (\n    select a.customer_id, a.sku_id\n    from (\n        select * from t1 cross join t2\n    ) a\n    where exists (\n        select t3.top_skus\n        from t3\n        where t3.sku_id = a.sku_id\n    )\n) b\ninner join (\n    select distinct sku_id, top_skus\n    from t3\n) c\non c.sku_id = b.sku_id\n\n2021-05-11 01:57:27,508 [             invoker] [    INFO] .[main] start to run custom module: ApplySqlTransModule\n2021-05-11 01:57:27,516 [apply_sql_trans_module] [    INFO] ...[run] Construct SQLite Server\n2021-05-11 01:57:27,530 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n2021-05-11 01:57:29,215 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1 with only column names\n2021-05-11 01:57:29,227 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n2021\/05\/11 01:57:29 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-05-11 01:57:30,093 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2 with only column names\n2021-05-11 01:57:30,106 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n2021-05-11 01:57:30,876 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3 with only column names\n2021-05-11 01:57:30,888 [apply_sql_trans_module] [    INFO] ...[run] Read SQL script query\n2021-05-11 01:57:30,895 [apply_sql_trans_module] [    INFO] ...[run] Validate SQL script query\n2021-05-11 01:57:30,912 [apply_sql_trans_module] [    INFO] ...[run] Insert data to SQLite Server\n2021-05-11 01:57:30,919 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1\n2021-05-11 01:57:30,930 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2\n2021-05-11 01:57:30,970 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3\n2021-05-11 01:57:31,053 [apply_sql_trans_module] [    INFO] ...[run] Generate SQL query result from SQLite Server\n<\/code><\/pre>",
        "Question_closed_time":1620739797130,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Found the problem.   <\/p>\n<p>There was a task failing but due to the size of the canvas I wasn't able to spot it at first (working late hours didn't help also).   <\/p>\n<p>However it certainly didn't help the fact that the error message didn't provide any info regarding which task failed, so maybe the AML team would like to add more descriptive messages in cases like this one.  <\/p>\n<p>thanks<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Receive error GraphDatasetNotFound: Request failed with status code 400 when submitting pipeline",
        "Question_created_time":1619957038450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379678\/receive-error-graphdatasetnotfound-request-failed",
        "Question_score_count":4,
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_body":"<p>I am running through the tutorial at ..https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/explore-data    <\/p>\n<p>When I submit my pipeline I am seeing the error ...    <\/p>\n<p>An error occurred while submitting pipeline run    <br \/>\nGraphDatasetNotFound: Request failed with status code 400    <\/p>\n<p>This is an incredibly unhelpful message. I believe I have followed the steps as per the tutorial.     <\/p>\n<p>Any idea what is the cause of this error?    <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":1620057090880,
        "Answer_score_count":14.0,
        "Answer_comment_count":9.0,
        "Answer_body":"<p>In dataset Version change from &quot;Always use latest&quot; to 1 or anyother version, worked for me<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Read data from CDM folder",
        "Question_created_time":1620478169427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/387697\/read-data-from-cdm-folder",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a CDM folder with data coming from Dynamics 365 Business Central.  <br \/>\nI need to do some data cleaning\/preprocessing and then apply my models on that data, but I didn't find a proper way to read CDM folders.  <br \/>\nI found some code on the Microsoft github repository, but is marked as obsolete.  <\/p>\n<p><a href=\"https:\/\/github.com\/Azure-Samples\/cdm-azure-data-services-integration\">Azure-Samples\/cdm-azure-data-services-integration<\/a>  <\/p>\n<p>I'm searching for something like the <strong>Apache Spark CDM connector<\/strong> but to use within Azure Machine Learning service.  <\/p>\n<p>ps: I know that is possible to copy\/transform files with <em>Azure Data Factory<\/em> and that is supports CDM folders too, but is not what I want. I want to read CDM folder from python, do my stuff (data cleaning, preprocessing, applying models, ecc) then save the results.  <\/p>\n<p>Is there any way?   <br \/>\nAny advice is welcome.  <\/p>\n<p>Thanks.  <\/p>",
        "Question_closed_time":1620687553120,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for reaching out. The data source you specified isn't a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types\">supported storage type<\/a> in AML. If you're using unsupported storage, we recommend that you <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/quickstart-create-data-factory-copy-data-tool\">move<\/a> your data to supported Azure storage solutions. Currently, we don't have a python connector for connecting to CRMs. A workaround would be to load your data to a database and connect to the database using python. Hope this helps, sorry for any inconvenience.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"When using Azure Machine Learning Designer why are two way visualizations not available in the Series version, while they are with the older Studio (Classic) version?",
        "Question_created_time":1620661630457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/389481\/when-using-azure-machine-learning-designer-why-are",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am a Data Scientist that is new to Azure ML.  I have been experimenting with Designer using both the Azure Machine Learning and the older Classic version.  As far as I can see the older version has more useful functionality.  When looking at the raw data it is easy to compare the dependent and independent variables using the visualization option on the Classic version. In the new version the visualization only looks at each variable separately and cannot compare one against another.  Also once the scores have been created, they can be quickly be compared to the actual values to see how they are correlated.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML designer: force pipeline to execute with only an underlying data change",
        "Question_created_time":1620410422613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/387140\/azure-ml-designer-force-pipeline-to-execute-with-o",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We are deploying an ML model through the Azure ML designer. Over time the underlying data changes and so the model needs to be regularly retrained. The actual designer pipeline and the dataset definition (a query on a SQL database) are not changed, only the underlying data in the Azure SQL database.  <\/p>\n<p>Right now, the pipeline API can be triggered, but it does not execute (as expected). This is equivalent to the default allow_reuse = True in the Azure ML SDK. Is there a way to disable this setting (or set in to False) in the designer so that when the API is triggered we can force it to re-execute the pipeline every time we want to do a retraining (eg once a week) as new data comes in, so that a new model version is generated every time.  <\/p>\n<p>To be clear, the training takes around 20 minutes, and the compute cluster it runs on has a 120 second scale-down time, so cost considerations etc (ie the reason for this feature being enabled by default) are not a concern.  <\/p>\n<p>Thanks in advance for any help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure services without CC",
        "Question_created_time":1620486974020,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/387725\/azure-services-without-cc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am currently enrolled in the Cloud Skill Challenge where I get the opportunity to get to know all the services Microsoft provide and get certified. As a student, I do not have a credit card but a debit credit card I use in all online purchases. In order to continue with my challenge, I need access to Azure Machine Learning, but my card is not accepted. Why is it so difficult to be able to use the trial without a &quot;credit card&quot;? In 2021, I have to say there is a huge amount of paying methods and credit cards are definitely not common in Europe...<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't find the run button",
        "Question_created_time":1617852662423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/348777\/cant-find-the-run-button",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>****Do I need to add the .ipynb extension manually to my notebook file ?**  <br \/>\n**I can't find the run button.****<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85574-capture2.png?platform=QnA\" alt=\"85574-capture2.png\" \/><\/p>",
        "Question_closed_time":1617872811417,
        "Answer_score_count":2.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=441c29e9-5f3d-4595-9f6c-dec6fcde5e85\">@paul gureghian  <\/a> You can re-name your file with .ipynb extension which should help to display the cells and the available options like run button for cell. Usually while creating new files in your workspace the UI prompts to select the extension of the file. If you can create a new file with .ipynb extension and copy these cells individually that should also work. Thanks.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"What are the differences between LightGBM and FastTree algorithms used by ML.Net's modelbuilder?",
        "Question_created_time":1620299148307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/385365\/what-are-the-differences-between-lightgbm-and-fast",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>For my master thesis, I am using ML.Net library with the model builder to build machine learning models for regression \/ to predict values. My field of study is in constructional mechanics, so I'm rather new to machine learning.    <\/p>\n<p>For most of my models, tree-based regression algorithms seem to be the best performing, and of these LightGBM and FastTree are the best performing algorithms.    <\/p>\n<p>I've tried to read up on LightGBM here: <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/lightgbm-a-highly-efficient-gradient-boosting-decision-tree\/\">https:\/\/www.microsoft.com\/en-us\/research\/publication\/lightgbm-a-highly-efficient-gradient-boosting-decision-tree\/<\/a> And FastTree here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet\">https:\/\/learn.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet<\/a>    <\/p>\n<p>However, I struggle to distinguish what the difference between these algorithms is. Could someone explain what the difference between LightGBM and FastTree is?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.",
        "Question_created_time":1620234016640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/384152\/userprocesskilledbysystemsignal-job-failed-since-t",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am getting this error when scoring a model.   <\/p>\n<p>Seems like it is an out-of-memory issue or a segfault issue (no idea what that means).  <\/p>\n<p>I'm using Designer while my compute is Standard Dv2 Family vCPUs. Have made no changes to my storage account key.   <\/p>\n<p>Any advice on how to debug this one? Many thanks in advance  <\/p>\n<blockquote>\n<p>AzureMLCompute job failed.  <br \/>\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.  <br \/>\n Reason: Process Killed with either 6:aborted or 9:killed  or 11:segment fault. exit code here is from wrapping bash hence 128 + n  <br \/>\n Cause: killed  <br \/>\n TaskIndex:   <br \/>\n NodeIp: 10.0.0.5  <br \/>\n NodeId: tvmps_ee452edcf7395836bdf60c0e0cd5f3a6308fafbb41c860c50a47be1367393df6_d  <br \/>\n Reason: Job failed with non-zero exit Code  <\/p>\n<\/blockquote>",
        "Question_closed_time":1620235517220,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Seems like it was an out-of-memory problem. If I reduce the trainning set, I get no error.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Group Categorical Data module missing in Designer, how to reduce number of levels?",
        "Question_created_time":1620183260377,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/383026\/group-categorical-data-module-missing-in-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi there,  <\/p>\n<p>I'm working through a tutorial on reducing the number of levels of a categorical variable before using the &quot;Convert to Indicator Values&quot; module. In the tutorial, the presenter is using the classic studio which has a module called &quot;Group Categorical Data&quot;. Unfortunately, I'm using ML Designer and it doesn't have that module.  <\/p>\n<p>Is there an easy workaround to reduce the number of categorical levels in Designer before using the Convert to Indicator Values module?  <\/p>\n<p>Thanks kindly,<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to configure the runs combine pipeline and hyperdrive",
        "Question_created_time":1619990039720,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379819\/how-to-configure-the-runs-combine-pipeline-and-hyp",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there,<\/p>\n<p>I have a pipeline that is composed of &quot;data prep&quot; and &quot;training&quot; steps and I need to test different hyperparameters on the training step. I cannot figure out how I should use hyperdrive config within the pipeline.<\/p>\n<p>from azureml.core import Environment  <br \/>\nfrom azureml.core.conda_dependencies import CondaDependencies  <br \/>\nfrom azureml.core.runconfig import RunConfiguration<\/p>\n<h1 id=\"create-a-python-environment-for-the-experiment\">Create a Python environment for the experiment<\/h1>\n<p>diabetes_env = Environment(&quot;diabetes-pipeline-env&quot;)  <br \/>\ndiabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies  <br \/>\ndiabetes_env.docker.enabled = True # Use a docker container<\/p>\n<h1 id=\"create-a-set-of-package-dependencies\">Create a set of package dependencies<\/h1>\n<p>diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],  <br \/>\npip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])<\/p>\n<h1 id=\"add-the-dependencies-to-the-environment\">Add the dependencies to the environment<\/h1>\n<p>diabetes_env.python.conda_dependencies = diabetes_packages<\/p>\n<h1 id=\"register-the-environment\">Register the environment<\/h1>\n<p>diabetes_env.register(workspace=ws)  <br \/>\nregistered_env = Environment.get(ws, 'diabetes-pipeline-env')<\/p>\n<h1 id=\"create-a-new-runconfig-object-for-the-pipeline\">Create a new runconfig object for the pipeline<\/h1>\n<p>run_config = RunConfiguration()<\/p>\n<h1 id=\"use-the-compute-you-created-above\">Use the compute you created above.<\/h1>\n<p>run_config.target = ComputerTarget_Crea<\/p>\n<h1 id=\"assign-the-environment-to-the-run-configuration\">Assign the environment to the run configuration<\/h1>\n<p>run_config.environment = registered_env<\/p>\n<p>print (&quot;Run configuration created.&quot;)<\/p>\n<h1 id=\"get-the-training-dataset\">Get the training dataset<\/h1>\n<p>diabetes_ds = ws.datasets.get(&quot;diabetes dataset&quot;)<\/p>\n<h1 id=\"create-a-pipelinedata-temporary-data-reference-for-the-model-folder\">Create a PipelineData (temporary Data Reference) for the model folder<\/h1>\n<p>prepped_data_folder = PipelineData(&quot;prepped_data_folder&quot;, datastore=ws.get_default_datastore())<\/p>\n<h1 id=\"create-a-script-config\">Create a script config<\/h1>\n<p>script_config = ScriptRunConfig(source_directory=experiment_folder,  <br \/>\nscript='diabetes_training.py',  <br \/>\n# Add non-hyperparameter arguments -in this case, the training dataset  <br \/>\narguments = ['--input-data', diabetes_ds.as_named_input('training_data')],  <br \/>\nenvironment=registered_env,  <br \/>\ncompute_target = ComputerTarget_Crea)<\/p>\n<h1 id=\"sample-a-range-of-parameter-values\">Sample a range of parameter values<\/h1>\n<p>params = GridParameterSampling(  <br \/>\n{  <br \/>\n# Hyperdrive will try 6 combinations, adding these as script arguments  <br \/>\n'--learning_rate': choice(0.01, 0.1, 1.0),  <br \/>\n'--n_estimators' : choice(10, 100)  <br \/>\n}  <br \/>\n)<\/p>\n<p>hyperdrive = HyperDriveConfig(run_config=script_config,  <br \/>\nhyperparameter_sampling=params,  <br \/>\npolicy=None, # No early stopping policy  <br \/>\nprimary_metric_name='AUC', # Find the highest AUC metric  <br \/>\nprimary_metric_goal=PrimaryMetricGoal.MAXIMIZE,  <br \/>\nmax_total_runs=6, # Restict the experiment to 6 iterations  <br \/>\nmax_concurrent_runs=2) # Run up to 2 iterations in parallel<\/p>\n<h1 id=\"step-1-run-the-data-prep-script\">Step 1, Run the data prep script<\/h1>\n<p>prep_step = PythonScriptStep(name = &quot;Prepare Data&quot;,  <br \/>\nsource_directory = experiment_folder,  <br \/>\nscript_name = &quot;prep_diabetes.py&quot;,  <br \/>\narguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),  <br \/>\n'--prepped-data', prepped_data_folder],  <br \/>\noutputs=[prepped_data_folder],  <br \/>\ncompute_target = ComputerTarget_Crea,  <br \/>\nrunconfig = run_config,  <br \/>\nallow_reuse = True)<\/p>\n<h1 id=\"step-2-run-the-training-script\">Step 2, run the training script<\/h1>\n<p>train_step = PythonScriptStep(name = &quot;Train and Register Model&quot;,  <br \/>\nsource_directory = experiment_folder,  <br \/>\nscript_name = &quot;train_diabetes.py&quot;,  <br \/>\narguments = ['--training-folder', prepped_data_folder],  <br \/>\ninputs=[prepped_data_folder],  <br \/>\ncompute_target = ComputerTarget_Crea,  <br \/>\nrunconfig = hyperdrive,  <br \/>\nallow_reuse = True)<\/p>\n<h1 id=\"error-i-get\">Error I get<\/h1>\n<p>Expected a StepRun object but received &lt;class 'azureml.core.run.Run'&gt; instead.  <br \/>\nThis usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.  <br \/>\nPlease check for package conflicts in your python environment<\/p>\n<p>TypeError Traceback (most recent call last)  <br \/>\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\pipeline\\core\\run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)  <br \/>\n293 try:  <br \/>\n--&gt; 294 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,  <br \/>\n295 raise_on_error=raise_on_error)<\/p>\n<p>TypeError: wait_for_completion() got an unexpected keyword argument 'timeout_seconds'<\/p>\n<p>During handling of the above exception, another exception occurred:<\/p>\n<p>ActivityFailedException Traceback (most recent call last)  <br \/>\n&lt;ipython-input-29-e1c5033d6731&gt; in &lt;module&gt;  <br \/>\n13 print(&quot;Pipeline submitted for execution.&quot;)  <br \/>\n14 RunDetails(pipeline_run).show()  <br \/>\n---&gt; 15 pipeline_run.wait_for_completion(show_output=True)<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\pipeline\\core\\run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)  <br \/>\n307 'azureml-core or azureml-pipeline-core.\\n' +  <br \/>\n308 'Please check for package conflicts in your python environment')  <br \/>\n--&gt; 309 step_run.wait_for_completion(raise_on_error=raise_on_error)  <br \/>\n310 else:  <br \/>\n311 # Different error than the run rehydration issue<\/p>\n<p>~\\anaconda3\\lib\\site-packages\\azureml\\core\\run.py in wait_for_completion(self, show_output, wait_post_processing, raise_on_error)  <br \/>\n819  <br \/>\n820 if raise_on_error:  <br \/>\n--&gt; 821 raise ActivityFailedException(error_details=json.dumps(error, indent=4))  <br \/>\n822  <br \/>\n823 return final_details<\/p>\n<p>ActivityFailedException: ActivityFailedException:  <br \/>\nMessage: Activity Failed:  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Unexpected character encountered while parsing value: &lt;. Path '', line 0, position 0.&quot;,  <br \/>\n&quot;messageParameters&quot;: {},  <br \/>\n&quot;details&quot;: []  <br \/>\n},  <br \/>\n&quot;time&quot;: &quot;0001-01-01T00:00:00.000Z&quot;  <br \/>\n}  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Activity Failed:\\n{\\n \\&quot;error\\&quot;: {\\n \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n \\&quot;message\\&quot;: \\&quot;Unexpected character encountered while parsing value: &lt;. Path '', line 0, position 0.\\&quot;,\\n \\&quot;messageParameters\\&quot;: {},\\n \\&quot;details\\&quot;: []\\n },\\n \\&quot;time\\&quot;: \\&quot;0001-01-01T00:00:00.000Z\\&quot;\\n}&quot;  <br \/>\n}  <br \/>\n}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AttributeError: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGBoosterUnserializeFromBuffer",
        "Question_created_time":1620076989343,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/381203\/attributeerror-anaconda-envs-azureml-py36-lib-libx",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/93350-capture2.png?platform=QnA\" alt=\"93350-capture2.png\" \/>    <\/p>\n<p>I am following automated ML guideline.:    <\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression\/auto-ml-regression.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression\/auto-ml-regression.ipynb<\/a>    <\/p>\n<p>I created development environment according to the documentation. As recommended, I am using version 1.27.0 of the Azure ML SDK.    <\/p>\n<p>After remote_run completed, I got the error for the following command &quot;best_run, fitted_model = remote_run.get_output()&quot;    <\/p>\n<p>I would appreciate if you could help me.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot authenticate to Azure Machine Learning from RServer",
        "Question_created_time":1619076064070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/367167\/cannot-authenticate-to-azure-machine-learning-from",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>Hi everyone,    <\/p>\n<p>I cannot authenticate from Rserver (the one on compute instance azureml)     <\/p>\n<p>I got prompted to open the devicelogin site and enter the code, did that and still got prompted again and then errors. It kept happening no matter what I tried.     <\/p>\n<p>I can't find any documentation or discussion online that can help with this. Please help!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90273-screenshot.png?platform=QnA\" alt=\"90273-screenshot.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accessing Data from azure container from a notebook",
        "Question_created_time":1617804754800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/348022\/accessing-data-from-azure-container-from-a-noteboo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hey there,  <\/p>\n<p>i have a question concerning the navigation in the file system of the azure cloud.  <\/p>\n<p>How can i access data (like images) from my container through a azure notebook?  <br \/>\nCan i navigate in the cloud like in the file system of my local machine?  <\/p>\n<p>Best regards and thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"unable to install AzureStor in R script in Azure ML Studio",
        "Question_created_time":1619361821370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370607\/unable-to-install-azurestor-in-r-script-in-azure-m",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I got this error when trying to install older version  <\/p>\n<p>0063: The following error occurred during evaluation of R script:  <br \/>\n---------- Start of error message from R ----------  <br \/>\n'AzureStor' is not a valid installed package  <\/p>\n<p>when tried to install newer version of zip downloaded from cran. then it was giving error can not read version 3 <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML model deployment issue",
        "Question_created_time":1619524308143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/373687\/ml-model-deployment-issue",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to deploy an ML classification model on Azure using GUI.    <\/p>\n<p>After registering\/uploading the model inside the portal, I am deploying the model in the Azure container instance, with custom entry_script and the conda dependencies.    <\/p>\n<p><strong>Entry Script<\/strong>    <\/p>\n<pre><code># Importing Pacakges  \nimport pandas as pd  \nimport pickle  \nimport regex, json  \nimport numpy as np  \nimport sklearn  \nimport os  \n  \nfrom inference_schema.schema_decorators import input_schema, output_schema  \nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType  \n  \ndef init():  \n    global model  \n    global classes  \n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'randomForest50.pkl')  \n    model = pickle.load(open(model_path, &quot;rb&quot;))  \n    classes = lambda x : [&quot;F&quot;, &quot;M&quot;][x]  \n  \ninput_sample = np.array([['Thomas', 'Anna']])  \noutput_sample = np.array(['m', 'F'])  \n  \n  \n@input_schema('data', NumpyParameterType(input_sample))  \n@output_schema(NumpyParameterType(output_sample))  \ndef run(data):  \n    try:  \n        namesList = json.loads(data)[&quot;data&quot;][&quot;names&quot;]  \n        pred = list(map(classes, model.predict(preprocessing(namesList))))  \n        return str(pred[0])  \n    except Exception as e:  \n        error = str(e)  \n        return error  \n<\/code><\/pre>\n<p>Conda.yaml    <\/p>\n<pre><code>name: prediction  \ndependencies:  \n- python=3.7  \n- numpy  \n- scikit-learn  \n- pip:  \n    - azureml-defaults  \n    - pandas  \n    - pickle4  \n    - regex  \n    - inference-schema[numpy-support]     \n<\/code><\/pre>\n<p>After deployment, the endpoint deployment state goes to unhealthy. and the logs show that program is stuck in a loop. Check logs below:    <\/p>\n<pre><code>2021-04-26T08:14:55,433967500+00:00 - rsyslog\/run   \n2021-04-26T08:14:55,421414500+00:00 - iot-server\/run   \n2021-04-26T08:14:55,540534600+00:00 - gunicorn\/run   \n2021-04-26T08:14:55,646209100+00:00 - nginx\/run   \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...  \n2021-04-26T08:14:58,234212800+00:00 - iot-server\/finish 1 0  \n2021-04-26T08:14:58,324505300+00:00 - Exit code 1 is normal. Not restarting iot-server.  \nStarting gunicorn 19.9.0  \nListening at: http:\/\/127.0.0.1:31311 (62)  \nUsing worker: sync  \nworker timeout is set to 300  \nBooting worker with pid: 89  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2021-04-26 08:15:11,623 | root | INFO | Starting up app insights client  \n2021-04-26 08:15:11,624 | root | INFO | Starting up request id generator  \n2021-04-26 08:15:11,631 | root | INFO | Starting up app insight hooks  \n2021-04-26 08:15:11,632 | root | INFO | Invoking user's init function  \nworker timeout is set to 300  \nBooting worker with pid: 91  \nSPARK_HOME not set. Skipping PySpark Initialization.  \nInitializing logger  \n2021-04-26 08:15:29,014 | root | INFO | Starting up app insights client  \n2021-04-26 08:15:29,014 | root | INFO | Starting up request id generator  \n2021-04-26 08:15:29,014 | root | INFO | Starting up app insight hooks  \n2021-04-26 08:15:29,014 | root | INFO | Invoking user's init function  \nworker timeout is set to 300  \nBooting worker with pid: 98  \nSPARK_HOME not set. Skipping PySpark Initialization.  \n...  \n...  \n...  \n<\/code><\/pre>\n<p>I tried to deploy the model using python also. But it also failed with message:    <\/p>\n<pre><code>WebserviceException: WebserviceException:  \n Message: Service deployment polling reached non-successful terminal state, current service state: Failed  \nOperation ID: 98e464d4-5b15-4606-936f-a2625f7bd1fd  \nMore information can be found using '.get_logs()'  \nError:  \n{  \n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n  &quot;statusCode&quot;: 400,  \n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;,  \n  &quot;details&quot;: [  \n    {  \n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.&quot;  \n    },  \n    {  \n      &quot;code&quot;: &quot;AciDeploymentFailed&quot;,  \n      &quot;message&quot;: &quot;Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\&quot;RestartCount\\&quot;: 3\\n\\&quot;CurrentState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Waiting\\&quot;,\\&quot;startTime\\&quot;:null,\\&quot;exitCode\\&quot;:null,\\&quot;finishTime\\&quot;:null,\\&quot;detailStatus\\&quot;:\\&quot;CrashLoopBackOff: Back-off restarting failed\\&quot;}\\n\\&quot;PreviousState\\&quot;: {\\&quot;state\\&quot;:\\&quot;Terminated\\&quot;,\\&quot;startTime\\&quot;:\\&quot;2021-04-27T10:46:03.903Z\\&quot;,\\&quot;exitCode\\&quot;:111,\\&quot;finishTime\\&quot;:\\&quot;2021-04-27T10:46:07.524Z\\&quot;,\\&quot;detailStatus\\&quot;:\\&quot;Error\\&quot;}\\n\\&quot;Events\\&quot;:\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2021-04-27T10:42:37Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2021-04-27T10:42:37Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulling\\&quot;,\\&quot;message\\&quot;:\\&quot;pulling image \\\\\\&quot;20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:1,\\&quot;firstTimestamp\\&quot;:\\&quot;2021-04-27T10:44:15Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2021-04-27T10:44:15Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Pulled\\&quot;,\\&quot;message\\&quot;:\\&quot;Successfully pulled image \\\\\\&quot;20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\&quot;\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:4,\\&quot;firstTimestamp\\&quot;:\\&quot;2021-04-27T10:44:40Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2021-04-27T10:46:03Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Started\\&quot;,\\&quot;message\\&quot;:\\&quot;Started container\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n{\\&quot;count\\&quot;:4,\\&quot;firstTimestamp\\&quot;:\\&quot;2021-04-27T10:44:43Z\\&quot;,\\&quot;lastTimestamp\\&quot;:\\&quot;2021-04-27T10:46:07Z\\&quot;,\\&quot;name\\&quot;:\\&quot;Killing\\&quot;,\\&quot;message\\&quot;:\\&quot;Killing container with id 5c5ddb266c4b38b1c306367712d9bec0687e5f6979e34afea7f6b943edf7db75.\\&quot;,\\&quot;type\\&quot;:\\&quot;Normal\\&quot;}\\n&quot;  \n    }  \n  ]  \n}  \n InnerException None  \n ErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 98e464d4-5b15-4606-936f-a2625f7bd1fd\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n  \\&quot;statusCode\\&quot;: 400,\\n  \\&quot;message\\&quot;: \\&quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\n\\\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\\\n\\\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;,\\n  \\&quot;details\\&quot;: [\\n    {\\n      \\&quot;code\\&quot;: \\&quot;CrashLoopBackOff\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\n\\\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\\\n\\\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\&quot;\\n    },\\n    {\\n      \\&quot;code\\&quot;: \\&quot;AciDeploymentFailed\\&quot;,\\n      \\&quot;message\\&quot;: \\&quot;Your container application crashed. Please follow the steps to debug:\\\\n\\\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\\\n\\\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\\\n\\\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\\\n\\\\\\&quot;RestartCount\\\\\\&quot;: 3\\\\n\\\\\\&quot;CurrentState\\\\\\&quot;: {\\\\\\&quot;state\\\\\\&quot;:\\\\\\&quot;Waiting\\\\\\&quot;,\\\\\\&quot;startTime\\\\\\&quot;:null,\\\\\\&quot;exitCode\\\\\\&quot;:null,\\\\\\&quot;finishTime\\\\\\&quot;:null,\\\\\\&quot;detailStatus\\\\\\&quot;:\\\\\\&quot;CrashLoopBackOff: Back-off restarting failed\\\\\\&quot;}\\\\n\\\\\\&quot;PreviousState\\\\\\&quot;: {\\\\\\&quot;state\\\\\\&quot;:\\\\\\&quot;Terminated\\\\\\&quot;,\\\\\\&quot;startTime\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:46:03.903Z\\\\\\&quot;,\\\\\\&quot;exitCode\\\\\\&quot;:111,\\\\\\&quot;finishTime\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:46:07.524Z\\\\\\&quot;,\\\\\\&quot;detailStatus\\\\\\&quot;:\\\\\\&quot;Error\\\\\\&quot;}\\\\n\\\\\\&quot;Events\\\\\\&quot;:\\\\n{\\\\\\&quot;count\\\\\\&quot;:1,\\\\\\&quot;firstTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:42:37Z\\\\\\&quot;,\\\\\\&quot;lastTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:42:37Z\\\\\\&quot;,\\\\\\&quot;name\\\\\\&quot;:\\\\\\&quot;Pulling\\\\\\&quot;,\\\\\\&quot;message\\\\\\&quot;:\\\\\\&quot;pulling image \\\\\\\\\\\\\\&quot;20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\\\\\\\\&quot;\\\\\\&quot;,\\\\\\&quot;type\\\\\\&quot;:\\\\\\&quot;Normal\\\\\\&quot;}\\\\n{\\\\\\&quot;count\\\\\\&quot;:1,\\\\\\&quot;firstTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:44:15Z\\\\\\&quot;,\\\\\\&quot;lastTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:44:15Z\\\\\\&quot;,\\\\\\&quot;name\\\\\\&quot;:\\\\\\&quot;Pulled\\\\\\&quot;,\\\\\\&quot;message\\\\\\&quot;:\\\\\\&quot;Successfully pulled image \\\\\\\\\\\\\\&quot;20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\\\\\\\\&quot;\\\\\\&quot;,\\\\\\&quot;type\\\\\\&quot;:\\\\\\&quot;Normal\\\\\\&quot;}\\\\n{\\\\\\&quot;count\\\\\\&quot;:4,\\\\\\&quot;firstTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:44:40Z\\\\\\&quot;,\\\\\\&quot;lastTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:46:03Z\\\\\\&quot;,\\\\\\&quot;name\\\\\\&quot;:\\\\\\&quot;Started\\\\\\&quot;,\\\\\\&quot;message\\\\\\&quot;:\\\\\\&quot;Started container\\\\\\&quot;,\\\\\\&quot;type\\\\\\&quot;:\\\\\\&quot;Normal\\\\\\&quot;}\\\\n{\\\\\\&quot;count\\\\\\&quot;:4,\\\\\\&quot;firstTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:44:43Z\\\\\\&quot;,\\\\\\&quot;lastTimestamp\\\\\\&quot;:\\\\\\&quot;2021-04-27T10:46:07Z\\\\\\&quot;,\\\\\\&quot;name\\\\\\&quot;:\\\\\\&quot;Killing\\\\\\&quot;,\\\\\\&quot;message\\\\\\&quot;:\\\\\\&quot;Killing container with id 5c5ddb266c4b38b1c306367712d9bec0687e5f6979e34afea7f6b943edf7db75.\\\\\\&quot;,\\\\\\&quot;type\\\\\\&quot;:\\\\\\&quot;Normal\\\\\\&quot;}\\\\n\\&quot;\\n    }\\n  ]\\n}&quot;  \n    }  \n}  \n<\/code><\/pre>\n<p><strong>I have deployed the same model with the same entryScript.py and the same conda.yaml previously, and it worked fine.<\/strong>    <\/p>\n<p>I cannot figure out what can be the issue here. Can anybody please suggest to me something for solving this?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning ExperimentExecutionException while submitting a distributed training run !",
        "Question_created_time":1619892981027,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379458\/azure-machine-learning-experimentexecutionexceptio",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, here is the details of my issue.  <br \/>\nI want to execute a distributed training run with the Tensorflow framework and Horovod.  <br \/>\nTo do this, I've configured a environment called &quot;tf_env&quot; as follow :<\/p>\n<pre><code># Create the environment : the dependencies are in the .yml file\ntf_env = Environment.from_conda_specification(name=&quot;tensorflow_environment&quot;, file_path=&quot;experiments\/package-list.yml&quot;)\n\n# Register the environment\ntf_env.register(workspace=ws)\n\n# Specify a GPU base image\ntf_env.docker.enabled = True\ntf_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n<\/code><\/pre>\n<p>Where my &quot;package-list.yml&quot; contains all the dependencies my &quot;train_script.py&quot; requires.  <br \/>\nI've defined my ScriptConfigRun as follow :<\/p>\n<pre><code>arguments = [\n    (... other arguments ...)\n    &quot;--ds&quot;,  images_ds.as_mount()\n]\n\nsrc = ScriptRunConfig(\n    source_directory=&quot;experiments&quot;,\n    script='train_script.py',\n    arguments=arguments,\n    compute_target=compute_target,\n    environment=tf_env,\n    distributed_job_config=MpiConfiguration(node_count=2)\n)\n<\/code><\/pre>\n<p>Then, when I want to submit the run :<\/p>\n<pre><code>run = best_model_experiment.submit(config=src)\n<\/code><\/pre>\n<p>... it raises this error I don't understand :<\/p>\n<pre><code>ExperimentExecutionException: ExperimentExecutionException:\n    Message: {\n    &quot;error_details&quot;: {\n        &quot;componentName&quot;: &quot;execution&quot;,\n        &quot;correlation&quot;: {\n            &quot;operation&quot;: &quot;***&quot;,\n            &quot;request&quot;: &quot;***&quot;\n        },\n        &quot;environment&quot;: &quot;westeurope&quot;,\n        &quot;error&quot;: {\n            &quot;code&quot;: &quot;UserError&quot;,\n            &quot;message&quot;: &quot;Error when parsing request; unable to deserialize request body&quot;\n        },\n        &quot;location&quot;: &quot;westeurope&quot;,\n        &quot;time&quot;: &quot;***&quot;\n    },\n    &quot;status_code&quot;: 400,\n    &quot;url&quot;: &quot;https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment***&quot;\n}\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;{\\n    \\&quot;error_details\\&quot;: {\\n        \\&quot;componentName\\&quot;: \\&quot;execution\\&quot;,\\n        \\&quot;correlation\\&quot;: {\\n            \\&quot;operation\\&quot;: \\&quot;***\\&quot;,\\n            \\&quot;request\\&quot;: \\&quot;***\\&quot;\\n        },\\n        \\&quot;environment\\&quot;: \\&quot;westeurope\\&quot;,\\n        \\&quot;error\\&quot;: {\\n            \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n            \\&quot;message\\&quot;: \\&quot;Error when parsing request; unable to deserialize request body\\&quot;\\n        },\\n        \\&quot;location\\&quot;: \\&quot;westeurope\\&quot;,\\n        \\&quot;time\\&quot;: \\&quot;***\\&quot;\\n    },\\n    \\&quot;status_code\\&quot;: 400,\\n    \\&quot;url\\&quot;: \\&quot;https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment_***\\&quot;\\n}&quot;\n    }\n}\n<\/code><\/pre>\n<p>Could you please help me decrypt this error ?  <br \/>\nThank you.<\/p>",
        "Question_closed_time":1620024521707,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Issue solved ! I've given a list in arguments to argparse so it could'nt deserialized the object.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Error while submitting pipeline using Azure ML Designer",
        "Question_created_time":1619901578667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379556\/error-while-submitting-pipeline-using-azure-ml-des",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, I am pretty new to AzureML and facing the following issue while submitting the pipeline.    <br \/>\nI have attached the screenshot for your reference.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/93109-capture.png?platform=QnA\" alt=\"93109-capture.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data gateway issue server cannot be reached",
        "Question_created_time":1619709093280,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/377424\/data-gateway-issue-server-cannot-be-reached",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,     <\/p>\n<p>I am following the instruction here to install my data gateway for Azure Machine Learning Studio    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/use-data-from-an-on-premises-sql-server\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/classic\/use-data-from-an-on-premises-sql-server<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92587-image.png?platform=QnA\" alt=\"92587-image.png\" \/>    <\/p>\n<p>I install on my personal and another one on the server    <br \/>\nmy personal one works well.    <br \/>\nBut on the data gateway from the server always show below message:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92588-image.png?platform=QnA\" alt=\"92588-image.png\" \/>    <\/p>",
        "Question_closed_time":1620043441103,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=e35fd686-d5ff-42db-9a7e-95deb29fb95e\">@Austin Kuo  <\/a> Thanks, Please follow the guidance given here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/import-from-on-premises-sql-server-database#manually-set-properties-in-the-import-data-module\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/import-from-on-premises-sql-server-database#manually-set-properties-in-the-import-data-module<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/v1\/data-factory-troubleshoot-gateway-issues#problem\">https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/v1\/data-factory-troubleshoot-gateway-issues#problem<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AutoML: problem with univariate time series forecasting",
        "Question_created_time":1617739313070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/346598\/automl-problem-with-univariate-time-series-forecas",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm having troubles generating univariate time series forecasts with Azure Automated Machine Learning (I know...).    <\/p>\n<p><strong>What I'm doing<\/strong>    <\/p>\n<p>So I have about 5 years worth of monthly observations in a dataframe that looks like this:    <\/p>\n<table>\n<thead>\n<tr>\n<th>date<\/th>\n<th>target_value<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2015-02-01<\/td>\n<td>123<\/td>\n<\/tr>\n<tr>\n<td>2015-03-01<\/td>\n<td>456<\/td>\n<\/tr>\n<tr>\n<td>2015-04-01<\/td>\n<td>789<\/td>\n<\/tr>\n<tr>\n<td>...<\/td>\n<td>...<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<p>I want to forecast <code>target_value<\/code> <em>based on past values of<\/em> <code>target_value<\/code>, i.e. univariate forecasting like ARIMA for instance.      <br \/>\nSo I am setting up the AutoML forecast like this:    <\/p>\n<pre><code># that's the dataframe as shown above  \ntrain_data = Dataset.Tabular.from_delimited_files(path=datastore.path(my_remote_filename))  \n  \n# ...other code...  \n  \nforecasting_parameters = ForecastingParameters(  \n    time_column_name='date',  \n    forecast_horizon=2,  \n    target_lags='auto',  \n    freq='MS'  \n)  \n  \nautoml_config = AutoMLConfig(task='forecasting',  \n                             debug_log='automl_forecasting_function.log',  \n                             primary_metric='normalized_root_mean_squared_error',  \n                             enable_dnn=True,  \n                             experiment_timeout_hours=8.0,  \n                             enable_early_stopping=True,  \n                             training_data=train_data,  \n                             compute_target='my-cluster',  \n                             n_cross_validations=3,  \n                             verbosity=logging.INFO,  \n                             max_concurrent_iterations=4,  \n                             max_cores_per_iteration=-1,  \n                             label_column_name='target_value',  \n                             forecasting_parameters=forecasting_parameters)  \n<\/code><\/pre>\n<p><strong>What the problem is<\/strong>    <\/p>\n<p>But AutoML does not seem to generate the forecast for <code>target_value<\/code> based on past values of <code>target_value<\/code>. <strong>It seems to use the <code>date<\/code> column as the independent variable!<\/strong>    <br \/>\nThe feature importance chart also shows <code>date<\/code> as <em>the<\/em> input feature:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/84928-5ajgr.png?platform=QnA\" alt=\"84928-5ajgr.png\" \/>    <\/p>\n<p><em>As a side note: running multivariate forecasts works fine.       <br \/>\nWhen I use a dataset like this, <code>feature_1<\/code> and <code>feature_2<\/code> are used (i.e. as the X) to forecast <code>target_value<\/code> (i.e. the y)<\/em>    <\/p>\n<table>\n<thead>\n<tr>\n<th>date<\/th>\n<th>feature_1<\/th>\n<th>feature_2<\/th>\n<th>target_value<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2015-02-01<\/td>\n<td>10<\/td>\n<td>7<\/td>\n<td>123<\/td>\n<\/tr>\n<tr>\n<td>2015-03-01<\/td>\n<td>30<\/td>\n<td>2<\/td>\n<td>456<\/td>\n<\/tr>\n<tr>\n<td>2015-04-01<\/td>\n<td>20<\/td>\n<td>5<\/td>\n<td>789<\/td>\n<\/tr>\n<tr>\n<td>...<\/td>\n<td>...<\/td>\n<td>...<\/td>\n<td>...<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<p><strong>My questions therefore<\/strong>       <br \/>\nHow do I need to set up a univariate AutoML forecast to forecast <code>target_value<\/code> based on past observations <code>target_value<\/code>?       <br \/>\nI assumed generating lagged values for <code>target_value<\/code> etc. is exactly what AutoML is supposed to do.    <\/p>\n<p>Thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ml designer: how to call a pipeline from another pipeline",
        "Question_created_time":1619288778083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370433\/azure-ml-designer-how-to-call-a-pipeline-from-anot",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using ML Designer and i have created a sub-pipeline that i want to use it in other pipelines. how do i call that sub-pipeline from the designer?  <\/p>\n<p>The purpose of the subpipeline is to transform data, so the output is a dataset.  <\/p>",
        "Question_closed_time":1619449185637,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>@javier-8889Thanks for the question. Can you please add more details about the pipeline steps. You can implement an <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-batch-scoring-classification#create-the-pipeline-step\">AML pipeline<\/a> with Python code, but also with the new AML designer which under the covers is creating an AML Pipeline defining that \u201cvisual workflow\u201d. Basically you can register a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer\">trained model in Designer<\/a> bring it out with SDK\/CLI to deploy it. Currently only Data Drift Monitor (Data Drift-&gt;EventGrid-&gt;LogicApp-&gt;Trigger Pipeline) allows to trigger a pipeline when dataset drift has been detected.    <\/p>\n<p>When designing a pipeline in Azure ML Designer, each step or module creates intermediate datasets that can be seen using the UI using Visualize option. Those datasets are persisted in the blob storage.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how to update azure ml model from adf?",
        "Question_created_time":1619624088887,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/375702\/how-to-update-azure-ml-model-from-adf",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I manage to run a azure ml trainning pipeline in adf. Then I can see that I can create\/update a batch inference pipeline from the Designer. But can I update the batch inference pipeline from adf?  <\/p>\n<p>thanks<\/p>",
        "Question_closed_time":1619629995207,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=1b597528-b52c-41fc-932a-baf4d96cb15b\">@javier  <\/a>,    <\/p>\n<p>Thanks for using Microsoft Q&amp;A !!    <\/p>\n<p>Unfortunately this is not supported using Azure Data Factory and you can only update the scoring web service using <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/update-machine-learning-models\">Azure Machine Learning Studio (classic) update resource activity<\/a> Can you please provide your scenario\/use case in details so that I can check internally.  I also suggest you to please post this as a feedback at <a href=\"https:\/\/feedback.azure.com\/forums\/270578-data-factory\">ADDF UserVoice<\/a>. This will allow the community to upvote and for the product team to include into their plans    <\/p>\n<p>----------    <\/p>\n<p><em>Please do not forget to &quot;Accept the answer&quot; wherever the information provided helps you to help others in the community.<\/em>    <\/p>\n<p>Thanks    <br \/>\nSaurabh    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"DSVM can support SQL Server Developer Edition for Ubuntu",
        "Question_created_time":1618980125337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/365284\/dsvm-can-support-sql-server-developer-edition-for",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>According to this     <\/p>\n<ul>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/tools-included#store-retrieve-and-manipulate-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/tools-included#store-retrieve-and-manipulate-data<\/a>,     <br \/>\nit appears that the SQL Server Developer Edition (Ubuntu) is being supported in DSVM but I couldn\u2019t find the name in the supported list here <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-tools-data-platforms#sql-server-developer-edition\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-tools-data-platforms#sql-server-developer-edition<\/a>,     <br \/>\nfurthermore there is no guide line for Linux Guide line but only windows guideline is there.     <br \/>\nI\u2019d like make sure the followings :     <\/li>\n<li> Can DSVM support SQL Server Developer Edition for Ubuntu?    <\/li>\n<li> If yes, where is the guideline for this?    <\/li>\n<li> If no, the documentation is wrong? And any particular supporting plan for SQL Server Developer Edition for Ubuntu?     <\/li>\n<\/ul>\n<p>Thanks <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to Delete Data Backing a Dataset",
        "Question_created_time":1619800286227,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379022\/how-to-delete-data-backing-a-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How do I delete the data backing a dataset?    <\/p>\n<p>I've got a ton of datasets our data scientist created. Some of these are good, but most are no longer relevant. These are growing and I want to delete these since they cost money to store.    <\/p>\n<p>I think these files located in &quot;blobstore-&lt;UUID&gt;\/UI&quot; may be backing files. There are *.csv files.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92927-image.png?platform=QnA\" alt=\"92927-image.png\" \/>    <\/p>\n<p>What are these files located in &quot;blobstore-&lt;UUID&gt;\/azureml?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92991-image.png?platform=QnA\" alt=\"92991-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Devops for Data Science Project",
        "Question_created_time":1620038832133,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/380561\/devops-for-data-science-project",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <br \/>\nI have a use case wherein some machine learning models will be developed by a team. My team will be developing an application to consume that model. Also we have to do the CI  Cd for that models , in such a way that every time the other team uploads a model in a blob storage , pipeline should be triggered and entire application should work the same way if new model performs better than previous one.    <br \/>\nThere is a documentation from microsoft but it is for VSTS.     <\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/DevOps-For-AI-Apps\/blob\/jainr-refactor\/Tutorial.md\">https:\/\/github.com\/Azure\/DevOps-For-AI-Apps\/blob\/jainr-refactor\/Tutorial.md<\/a>    <\/p>\n<p>The steps mentioned here is exactly what I would like to do but I need the same tutorial for Azure Devops.Since I see many changes in VSTS and Devops portal.    <\/p>\n<p><a href=\"\/users\/na\/?userid=4d073137-9058-4091-b406-3ce13c4eb1c4\">@Chris Patterson  <\/a> <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Notebook Python kernel never loads",
        "Question_created_time":1618279137097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/354727\/azure-ml-notebook-python-kernel-never-loads",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Hello,     <\/p>\n<p>I'm working through mslearn examples. I created a Workspace and a Compute instance based on provided specs [Standard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)]    <\/p>\n<p>The compute instance deploys and runs fine. I tried to open a terminal to clone the dp100 examples, but the terminal always fails, even with the compute instance selected. I tried restarting the compute instance and the terminal never loaded.    <\/p>\n<p>Parallel to that, when I create an ML Studio notebook, the compute instance says its running, but the Python 3.6 kernel never loads so I can't run cells from the Notebook. However, if I open the contents of the Notebook in the Jupyter editor it runs fine.    <\/p>\n<p>I was able to run the git clone code using the above, but I'd like to understand why the notebooks and terminal aren't working as they should be.    <\/p>\n<p>I was following these instructions: <a href=\"https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/01-create-a-workspace.html\">https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/01-create-a-workspace.html<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/87116-notebooks-microsoft-azure-machine-learning.png?platform=QnA\" alt=\"87116-notebooks-microsoft-azure-machine-learning.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/87205-dp100-compute-instance-microsoft-azure-machine-lea.png?platform=QnA\" alt=\"87205-dp100-compute-instance-microsoft-azure-machine-lea.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ml designer: how to use parameters with sql transformation?",
        "Question_created_time":1619281429040,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370365\/azure-ml-designer-how-to-use-parameters-with-sql-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I would like to apply an SQL Query Transformation to my data in Azure ML Designer but the transformation needs to take two parameters as inputs. How do I reference them  <\/p>\n<p>The idea is to have something like this:  <\/p>\n<pre><code>select * from customers where account = [param1] and cuType = [param2] \n<\/code><\/pre>\n<p>I have defined param1 and param2 as pipeline parameters but not sure how to reference them in the sql script<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failure in Sidecar: Failed to read file line by line.",
        "Question_created_time":1619675273623,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/376584\/failure-in-sidecar-failed-to-read-file-line-by-lin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I was running 100 identical jobs on a compute cluster via Azure Machine Learning of which 97 failed and 3 succeeded without issues. The failed jobs failed half-way through with the following error message<\/p>\n<pre><code>AzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n    Reason: Job failed with non-zero exit Code\n    Reason: runSpecialJobTask failed with with non zero exit code\n    stderr: runSpecialJobTask: postprocessing: Failure in Sidecar:\nFailed to read file line by line.\n    Reason: Job release task failed with non-zero exit Code\n<\/code><\/pre>\n<p>There is no error message in the driver log or any other log file to indicate what went wrong. It seems like the failed jobs stopped half-way for no reason. The wording of the error message &quot;Failed to read file line by line.&quot; does not seem to be a standard python error message. Is there a way I can find out what happened in the sidecar and trace this error?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"URL not functioning in Azure Machine Learning Studio",
        "Question_created_time":1619685812787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/376972\/url-not-functioning-in-azure-machine-learning-stud",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Can someone please help me with the following link. I receive all the time Error 0030 when I run the project in Azure Machine Learning Studio. But the file is still relevant. Don't understand where is a problem.    <\/p>\n<p><a href=\"https:\/\/docs.google.com\/spreadsheets\/d\/1ub_0Y5CEj2HtKO6bgb8OIvMIG81Wca0r_q8G70OKUTc\/pub?gid=1709232748&amp;single=true&amp;output=csv\">https:\/\/docs.google.com\/spreadsheets\/d\/1ub_0Y5CEj2HtKO6bgb8OIvMIG81Wca0r_q8G70OKUTc\/pub?gid=1709232748&amp;single=true&amp;output=csv<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Send new data to Deployed model",
        "Question_created_time":1619546083177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/374180\/send-new-data-to-deployed-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>We are sending data from a smartwatch -&gt; IoT Central -&gt; Event Hubs -&gt; Data Explorer -&gt; Blob Storage.  <\/p>\n<p>We are then using the blob storage as a datastore in Machine Learning, which we make a dataset of.  <\/p>\n<p>We deployed a model we trained locally to Azure Machine Learning.  <\/p>\n<p>We now want to send new data from the watch to the model to make predictions on.  <\/p>\n<p>We are wondering how we can do this?  <\/p>\n<p>Do we just update the dataset the same way we are currently sending the data? and if so, how can we then auto send it to the model?  <\/p>\n<p>Or is there another way to send this new data? Can we still send through blob storage? Or should we send the data directly from the watch to the webservice made by the model?  <\/p>\n<p>Thanks so much!<\/p>",
        "Question_closed_time":1619561766013,
        "Answer_score_count":1.0,
        "Answer_comment_count":7.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a706cc9a-ba35-4065-a95e-7fd5a2c7ba9d\">@yjay  <\/a> ,    <\/p>\n<p>so you get new data from devices and you want to predict using that data?    <\/p>\n<p>Check out <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf?WT.mc_id=IoT-MVP-5002324\">Azure Stream Analytics<\/a> which can ingest messages from the Event Hub.    <\/p>\n<p>Then, you can Azure ML as a function on make decisions based on the incoming data using ML.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91901-image.png?platform=QnA\" alt=\"91901-image.png\" \/>     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error while accessing the dataset from a datastore",
        "Question_created_time":1619698599813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/377203\/error-while-accessing-the-dataset-from-a-datastore",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have tried to read the dataset from datastore. Also tried to create the dataset also.<\/p>\n<p>The code for reading the dataset is below<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = Datastore.get(ws, 'qdataset')\n<\/code><\/pre>\n<p>It works fine still now.<\/p>\n<pre><code>from azureml.core.dataset import Dataset\nsix_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n<\/code><\/pre>\n<p>Also i have tried from <code>azureml.core import Dataset<\/code><\/p>\n<p>It shows the following error:<\/p>\n<p>2021-04-29 11:56:47.284077 | ActivityCompleted: Activity=_dataflow, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'activity_name': '_dataflow', 'activity_type': 'InternalCall', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.27.0', 'dataprepVersion': '2.14.2', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Failure', 'durationMs': 962.01}, Exception=AttributeError; module 'azureml.dataprep' has no attribute 'api'<\/p>\n<hr \/>\n<p>AttributeError Traceback (most recent call last)  <br \/>\n&lt;ipython-input-34-ac7a8d35da4d&gt; in &lt;module&gt;  <br \/>\n1 from azureml.core.dataset import Dataset  <br \/>\n----&gt; 2 six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in get_by_name(workspace, name, version)  <br \/>\n87 :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]  <br \/>\n88 &quot;&quot;&quot;  <br \/>\n---&gt; 89 dataset = AbstractDataset._get_by_name(workspace, name, version)  <br \/>\n90 AbstractDataset._track_lineage([dataset])  <br \/>\n91 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _get_by_name(workspace, name, version)  <br \/>\n652 if not success:  <br \/>\n653 raise result  <br \/>\n--&gt; 654 dataset = _dto_to_dataset(workspace, result)  <br \/>\n655 warn_deprecated_blocks(dataset)  <br \/>\n656 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_dataset_rest_helper.py in _dto_to_dataset(workspace, dto)  <br \/>\n93 registration=registration)  <br \/>\n94 if dto.dataset_type == _DATASET_TYPE_FILE:  <br \/>\n---&gt; 95 return FileDataset._create(  <br \/>\n96 definition=dataflow_json,  <br \/>\n97 properties=dto.latest.properties,<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _create(cls, definition, properties, registration, telemetry_info)  <br \/>\n555 from azureml.data._partition_format import parse_partition_format  <br \/>\n556  <br \/>\n--&gt; 557 steps = dataset._dataflow._get_steps()  <br \/>\n558 partition_keys = []  <br \/>\n559 for step in steps:<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _dataflow(self)  <br \/>\n215 raise UserErrorException('Dataset definition is missing. Please check how the dataset is created.')  <br \/>\n216 if self._registration and self._registration.workspace:  <br \/>\n--&gt; 217 dataprep().api._datastore_helper._set_auth_type(self._registration.workspace)  <br \/>\n218 if not isinstance(self._definition, dataprep().Dataflow):  <br \/>\n219 try:<\/p>\n<p>AttributeError: module 'azureml.dataprep' has no attribute 'api'<\/p>\n<p>Please give a solution to solve this<\/p>",
        "Question_closed_time":1619702571567,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>It now worked..   <br \/>\nWe need to install azure-ml-api-sdk using this command  <\/p>\n<p>pip install azure-ml-api-sdk  <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Deploy AML Model to ACI with SSL Enabled",
        "Question_created_time":1619607996060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/375249\/deploy-aml-model-to-aci-with-ssl-enabled",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am trying to deploy a model to ACI with SSL enabled in AML Studio that keeps hanging.  I am able to successfully deploy the model without SSL but struggling to do so with SSL enabled. I am following the article:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service<\/a>    <\/p>\n<p>We have purchased a domain and certificate (pem encoded) from a CA and updated our DNS as per the article.  The certificate and key files have been uploaded to Azure Machine Learning Studio under the same folder as the register and deploy python script.    <\/p>\n<p>The following code in the register and deploy python script should set up the ACI Webservice. deployment configuration:    <\/p>\n<p>from azureml.core.webservice import AciWebservice    <\/p>\n<p><em>aciconfig = AciWebservice.deploy_configuration(cpu_cores=2,     <br \/>\n                                               memory_gb=10,  <br \/>\n                                               tags={&quot;x&quot;: &quot;xx&quot;,  &quot;xxx&quot;},   <br \/>\n                                               description=&lt;some text&gt;,  <br \/>\n                                               auth_enabled=True,  <br \/>\n                                               ssl_enabled=True,   <br \/>\n                                               ssl_cert_pem_file=&quot;&lt;name of cert file&gt;&quot;,   <br \/>\n                                               ssl_key_pem_file=&quot;&lt;name of key file&quot;,   <br \/>\n                                               ssl_cname=&quot;&lt;domain&gt;&quot;)<\/em>  <\/p>\n<p>All looks fine but then when running the following code to deploy the model, execution starts but the Jupyter kernel is just hanging, without providing much logging information:    <\/p>\n<p>%%time    <br \/>\nfrom azureml.core.webservice import Webservice    <\/p>\n<p>service = Model.deploy(workspace=ws,     <br \/>\n                       name='&lt;name&gt;',   <br \/>\n                       models=[model],   <br \/>\n                       inference_config=inference_config,   <br \/>\n                       deployment_config=aciconfig,  <br \/>\n                       overwrite = True)  <\/p>\n<p>service.wait_for_deployment(show_output=True)    <\/p>\n<p>After a while of execution I eventually interrupt the kernel which suggests execution has stopped. However, when trying to deploy again it suggests that something is still running, forcing me to stop and restart the compute cluster. So something is still hanging in the background as a result of my deployment attempt.     <\/p>\n<p>The logs don't give much with the last line stating the following:    <br \/>\n2021-04-28 10:12:56,189 | root | INFO | Scoring timeout is found from os.environ: 60000 ms    <\/p>\n<p>Any help would be much appreciated - thanks!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure On-Demand ML cluster from a search in the data catalog",
        "Question_created_time":1619209726297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/369952\/azure-on-demand-ml-cluster-from-a-search-in-the-da",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I'm trying to implement a self-service solution in Azure so users can run a Jupyter or PySpark notebook on-Demand\/automatically with the dataset they found a search in the Azure Data Catalog.  I visualize, once the user finds the data in a search, there will be a link that will take him\/her to a Notebook and the dataset can be used for analysis.  Any suggestion would be very much appreciated!<\/p>",
        "Question_closed_time":1619432530247,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=072ff3f6-8045-41ef-849b-87cd092ffd6e\">@Jairo Melo  <\/a> Thanks for the question.Azure Purview can find, understand, and consume data sources. Please follow the Azure Purview documentation: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/purview\/\">https:\/\/learn.microsoft.com\/en-us\/azure\/purview\/<\/a>    <\/p>\n<p>and We have  Azure Open Datasets where you can download a Notebook for AML, Databricks or Synapse that explores the data: <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/open-datasets\/catalog\/\">Azure Open Datasets Catalog<\/a> | Microsoft Azure. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/open-datasets\/overview-what-are-open-datasets\">What are open datasets? Curated public datasets - Azure Open Datasets | Microsoft Learn.<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to deploy ML Designer pipeline as real-time inference pipeline using N-Gram",
        "Question_created_time":1606307286153,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/175242\/how-to-deploy-ml-designer-pipeline-as-real-time-in",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <br \/>\ni deployed a real-time inference pipeline using ML Designer. Training and deploying works fine. But when I'm consuming\/testing my API it doesn't work. Postman gives me Errorcode 500 and &quot;Internal Server Error. Run: Server internal error is from Module Extract N-Gram Features from Text&quot;.    <\/p>\n<p>This is my training pipeline:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42733-image.png?platform=QnA\" alt=\"42733-image.png\" \/>    <\/p>\n<p>I read this: <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/algorithm-module-reference\/extract-n-gram-features-from-text.md#score-or-publish-a-model-that-uses-n-grams\">https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/algorithm-module-reference\/extract-n-gram-features-from-text.md#score-or-publish-a-model-that-uses-n-grams<\/a>    <\/p>\n<p>But I don't know how to achieve this.    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Question_closed_time":1606367173387,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Once you create a real-time inference pipeline, please make the further modifications below:    <\/p>\n<ol>\n<li> Find the output <strong>Result_vocabulary<\/strong> dataset from <strong>Extract N-Gram Features from Text<\/strong> module.    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42884-findmoduleoutputdataset.png?platform=QnA\" alt=\"42884-findmoduleoutputdataset.png\" \/>    <\/li>\n<li> Register the dataset as with a name    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42905-registerdataset.png?platform=QnA\" alt=\"42905-registerdataset.png\" \/>    <\/li>\n<li> Update real-time inference pipeline like below:    <br \/>\n <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42865-inferencepipeline.png?platform=QnA\" alt=\"42865-inferencepipeline.png\" \/>    <\/li>\n<\/ol>\n<p>We will improve the documentation accordingly. Thanks for reporting the issue!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"how can i retrain the model after a period of time",
        "Question_created_time":1619232734657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370080\/how-can-i-retrain-the-model-after-a-period-of-time",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello everyone, i'm using lambda architecture to build a fraud detection project , i build my model using machine learning in databricks , after saving the model , i load the model in the speed layer to predict the incoming data, i want to know how can i retrain this model using new incoming data from eventhub ??  <br \/>\ndoes the retrain should be in the batch layer ?  <br \/>\nthanks for helping <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export trained model in Azure automated ML (Interface)",
        "Question_created_time":1617885405287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349497\/export-trained-model-in-azure-automated-ml-(interf",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <br \/>\nWe are able to export the trained model by automl module in  Azure ML jupyter notebook. We have set enable_onnx_compatible_models=True in AutoMLConfig. As shown in image below it create  model.onnx and model.pkl  file both for each algorithm and iteration it used.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85755-with-onnx.png?platform=QnA\" alt=\"85755-with-onnx.png\" \/>    <\/p>\n<p>Now we are trying to export the model in automated ML (interface). We can see in image below it only create the model.pkl file not model.onnx file.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85745-without-onnx.png?platform=QnA\" alt=\"85745-without-onnx.png\" \/>    <\/p>\n<p>Is there any configuration change is required to export the trained model in automated ML (Interface), like enable_onnx_compatible_models in Azure ML notebook.    <\/p>\n<p>Best Regards,    <br \/>\nRatan Kumar<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Beginner question - Cannot locate column selector for CSV data to filter out columns",
        "Question_created_time":1619428512443,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/371634\/beginner-question-cannot-locate-column-selector-fo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm in classic Azure ML mode. I am working on my first ever experiment, so please be patient..    <\/p>\n<p>I cannot locate column selector for CSV data to filter out columns. I found this:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/select-columns-in-dataset\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/select-columns-in-dataset<\/a>    <\/p>\n<p>And I'm following a tutorial (behind pay wall, from 2017) that shows it in the right hand side properties pane. It says in his example to add the &quot;Select columns in dataset&quot; and it shows the option of &quot;launch column selector&quot;.    <\/p>\n<p>I have browsed through every single choice in the left menu, but cannot locate it... I have no idea what I am missing.    <\/p>\n<p>I need to exclude columns from the data set. Then later I need to make some of the fields &quot;categorical&quot;. Input on that would be appreciated too, unless it becomes obvious from other information provided.    <\/p>\n<p>Please help me :) Thanks in advance for patience and\/or assistance.<\/p>",
        "Question_closed_time":1619488667407,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>First you need to navigate to Data Transformation  - &gt; Manipulation -&gt; Select columns in dataset, drag that into your process.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91523-image.png?platform=QnA\" alt=\"91523-image.png\" \/>    <\/p>\n<p>Then, left click on the module and click launch column selector.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91497-image.png?platform=QnA\" alt=\"91497-image.png\" \/>    <\/p>\n<p>And you can do you want now.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91524-image.png?platform=QnA\" alt=\"91524-image.png\" \/>    <\/p>\n<p>Please accept the answer if you feel helpful, thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML Studio and Git\/AzureDevOps",
        "Question_created_time":1618340223767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/355882\/azure-ml-studio-and-git-azuredevops",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>We have created an Azure ML Studio based proof of concept.  I would like to get the &quot;source code&quot; into a source code repository. We use Git on AzureDevOps.     <\/p>\n<p>I'm at a loss where to begin since the designer has no source files with which to interact. All of the project is point-and-click via the Designer.  This is a ML project built following this tutorial:  <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a>    <\/p>\n<p>We've created our own models, data, etc and have a solution.     <\/p>\n<p>What artifacts from an Azure ML Studio project should be included in a version control system?   Where are these files located?    <\/p>\n<p>Thanks for any insight.    <\/p>\n<p>-jeremiah<\/p>",
        "Question_closed_time":1618395018257,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=db6d5d1b-2e52-4bd2-9a58-09e9966cf4db\">@Jeremiah Adams  <\/a> Thanks for the question.  Can you share a snippet of how you are uploading to azure Devops?. Please follow this document: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer<\/a>. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it. Just run az ml model download - that will get all of the <a href=\"https:\/\/github.com\/microsoft\/MLOps\/tree\/master\/model-deployment\">files<\/a>.    <\/p>\n<p>Also look at the <a href=\"https:\/\/youtu.be\/bmFr0LYo_6o\">MLOPs demo<\/a>.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"getting error 151",
        "Question_created_time":1619442149707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/371888\/getting-error-151",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Error writing to cloud storage: The remote server returned an error: (400) Bad Request.. Please check the url. . ( Error 0151 )   <br \/>\nwhen trying to export data frame from output port to blob storage as csv file from azure ML studio<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleExceptionMessage:ModuleOutOfMemory: Memory has been exhausted, unable to complete running of module.",
        "Question_created_time":1619357291613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370636\/moduleexceptionmessage-moduleoutofmemory-memory-ha",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am getting the error from the subject line when i try to inner join a dataset of 850K rows and 3 columns (parquet data file of around 4mb) with another with 300K rows and 10 columns (parquet data file is about 1mb). I'm using Azure ML Studio Designer  <\/p>\n<p>My compute is Standard Dv2 Family vCPUs (20% of utilization).  <\/p>\n<p>I was surprised by this hitting a limit. Any idea on how i should proceed?<\/p>",
        "Question_closed_time":1619444233763,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>i manage to do this by trainning the model in a subset of records (using the Sample model).    <\/p>\n<p>Also noted that the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/apply-sql-transformation\">documentation<\/a> implies that an out of memory error is dependant on the RAM of the client \/ Designer user machine not the compute selected (or at least that is my understanding of the note at the beginning of the doc)    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Test data after deploying model",
        "Question_created_time":1619200443810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/369813\/test-data-after-deploying-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>We are deploying our model built locally to Azure Machine Learning resource. The model was successfully registered and deployed.<\/p>\n<p>We are now trying to test the model but keeping getting different errors such as:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;MLMain.py&quot;, line 248, in &lt;module&gt;\n    test = bytes(test, encoding='utf8')\n<\/code><\/pre>\n<p>and<\/p>\n<pre><code>TypeError: encoding without a string argument\nInference result = float() argument must be a string or a number, not 'dict'\n<\/code><\/pre>\n<p>Our MLMain.py looks like:<\/p>\n<pre><code>........\n\nprint('************ REGISTER MODEL ******\\n')\n    model = run.register_model(model_name='TempModel',\n                       tags={'Temp': 'SelfTrainingClassifier'},\n                       model_path='outputs\/TempModel.pkl')\n    print(model.name, model.id, model.version, sep='\\t')\n\n    print('************ DEPLOY MODEL ******\\n')\n    service_name = 'test123'\n    #aks_target = AksCompute(workspace,&quot;testCompute&quot;)\n    deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                                           memory_gb = 1)\n\n    #env.python.conda_dependencies.add_pip_package(&quot;inference-schema[numpy-support]&quot;)\n    #env.python.conda_dependencies.save_to_file(&quot;.&quot;, &quot;myenv.yml&quot;)\n    inference_config = InferenceConfig(entry_script=&quot;.\/TempModel\/score.py&quot;,\n                                   environment=env)\n\n    service = Model.deploy(workspace, service_name, [model], inference_config, deployment_config)\n    service.wait_for_deployment(show_output = True)\n    print(service.state)\n    print(service.scoring_uri)\n\n\n    print('*********** TEST MODEL *****\\n')\n    test = {\n    &quot;data&quot;:   [[177,44]]\n    }\n\n    test = bytes(test, encoding='utf8')\n    y_hat = service.run(input_data=test)\n<\/code><\/pre>\n<p>The score.py looks like:<\/p>\n<pre><code>def run(data):\n    try:\n        data = np.array(json.loads(data))\n        result = model.predict(data)\n        # You can return any data type, as long as it is JSON serializable.\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>When we run the model locally we are able to predict on:<\/p>\n<pre><code>loaded_model = pickle.load(open('self_training_model5.pkl', 'rb'))\n\nresult = loaded_model.predict([[177,89]])\n<\/code><\/pre>\n<p>Any ideas would be great.  <br \/>\nThanks so much!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to do machine learning in Azure IoT Central?",
        "Question_created_time":1618360709993,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/356183\/is-it-possible-to-do-machine-learning-in-azure-iot",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was wondering if it is possible to do machine learning on Azure IoT central. I read in some places that it is possible to do so in Azure IoT Edge. I saw a template for Video Analytics but cannot seem to find a way to implement my own models. If Edge is the only way to perform machine learning in Azure IoT, is there some way  to use IoT Edge with IoT Central? Or, is it possible to train your own Tensorflow Lite Models with Raspberry Pi and just host the Pi in IoT Hub? If both are possible, which of the two would be the easiest? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create batch inference Pipline for forecasting model using AutoML",
        "Question_created_time":1618831327213,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/362632\/how-to-create-batch-inference-pipline-for-forecast",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi  everyone,  <\/p>\n<p>I   am beginner for Azure auto ML. So I deployed the Forecasting Model Using Auto ML notebooks,  Now  I am trying to creating the Batch Inference Pipeline using ML my best Forecasting Model. please help me how can  I create  the Batch Inference Pipeline for forecasting model . please refer me Any doc to me.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"Explanation_dataTransform: e.every is not a function\"  Error AutoML Explanation Preview",
        "Question_created_time":1619105132597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/367955\/explanation-datatransform-e-every-is-not-a-functio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90406-capture.png?platform=QnA\" alt=\"90406-capture.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90260-image.png?platform=QnA\" alt=\"90260-image.png\" \/>    <\/p>\n<p>Although child run of the explanation is completed successfully, we are not able to see the explanation preview. We would appreciate if you could help us.    <\/p>\n<p>Best regards,    <\/p>\n<p>Cagatay Topcu    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why does my pipeline take so long to run?",
        "Question_created_time":1618607050577,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/360906\/why-does-my-pipeline-take-so-long-to-run",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi  <\/p>\n<p>I am trying out the free subscription of MS Azure. I am running a Machine learning pipeline and it seems to take a very long time to run. My input datasource is an excell spreadsheet of only 50 rows and just the 'select columns in dataset' component takes 3 or 4 minutes to complete. The same thing (as in the step that converts the spreadsheet to a pandas dataframe and selects the columns for the dependent and independent variables) takes a matter of seconds when I run it in Google Colab. Why does MS Azure take so much longer to run?  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Separate data in data explorer and use as datastore",
        "Question_created_time":1619036349177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/366532\/separate-data-in-data-explorer-and-use-as-datastor",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>We are sending data from IoT Central to Event Hubs and then to Data Explorer, with the hopes of then sending the data to Azure Machine Learning.    <\/p>\n<p>In order to send data from Event Hubs to Data Explorer it needs a data ingestion into a table on data explorer.    <\/p>\n<p>For this data ingestion, it needs a json mapping.    <\/p>\n<p>We could ingest the data, but the message from the iot central data goes to event hubs that goes to data explorer carries the telemetry data as a dynamic type (a json inside a json).     <\/p>\n<pre><code>(&quot;telemetry&quot;:{&quot;Temp:&quot;37&quot;,&quot;Vol&quot;:&quot;97&quot;})  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90018-data.jpg?platform=QnA\" alt=\"90018-data.jpg\" \/>    <br \/>\nWe want to separate the telemetry data in different columns.    <\/p>\n<p>So Temp will have one column and Vol another.    <\/p>\n<p>I am wondering how that can be done?    <\/p>\n<p>And additionally, since we would like to send the data to ML, can data explorer be used as a datastore in ML?    <\/p>\n<p>Thanks!!    <\/p>",
        "Question_closed_time":1619080604290,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a706cc9a-ba35-4065-a95e-7fd5a2c7ba9d\">@yjay  <\/a>,    <\/p>\n<p>You can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-explorer\/kusto\/query\/parseoperator\">parse operator<\/a> - Evaluates a string expression and parses its value into one or more calculated columns. The calculated columns will have nulls, for unsuccessfully parsed strings.     <\/p>\n<p>For more details, refer <a href=\"https:\/\/stackoverflow.com\/questions\/63779632\/split-column-string-with-delimiters-into-separate-columns-in-azure-kusto\">SO<\/a> thread addressing similar issue.     <\/p>\n<blockquote>\n<p>Unfortuantely, Azure Data Explorer is not a supported storage solution with Azure Machine Learning.     <\/p>\n<\/blockquote>\n<p>Datastores currently support storing connection information to the storage services listed in the following matrix.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90159-image.png?platform=QnA\" alt=\"90159-image.png\" \/>    <\/p>\n<p>For unsupported storage solutions, and to save data egress cost during ML experiments, move your data to a supported Azure storage solution.    <\/p>\n<p><strong>Reference:<\/strong> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\">Connect to storage services on Azure - Azure Machine Learning<\/a>.     <\/p>\n<p>Hope this helps. Do let us know if you any further queries.    <\/p>\n<p>------------    <\/p>\n<p>Please don\u2019t forget to <code>Accept Answer<\/code> and <code>Up-Vote<\/code> wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Install Library",
        "Question_created_time":1618974903553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/365159\/install-library",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is there a way to install the spacy library<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to add r2 and adj r2 metric in linear regression model - AzureML Studio?",
        "Question_created_time":1618843927707,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/362850\/how-to-add-r2-and-adj-r2-metric-in-linear-regressi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have trained a linear regression model in AzureML studio which was created in designer as pipeline.    <\/p>\n<p>I could not able to see R square and adj-R square metric in Evaluate Model step.     <\/p>\n<p>Could any throw thoughts how can I add these 2 metrics to my trained model     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/89088-image.png?platform=QnA\" alt=\"89088-image.png\" \/>    <\/p>\n<p>Thanks    <br \/>\nBhaskar<\/p>",
        "Question_closed_time":1618877959740,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>Sorry  for the confusing. Actually, Coefficient of determination, often referred to as R2, represents the predictive power of the model as a value between 0 and 1. Zero means the model is random (explains nothing); 1 means there is a perfect fit. However, caution should be used in interpreting R2 values, as low values can be entirely normal and high values can be suspect in Azure Machine Learning Designer.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/evaluate-model#metrics-for-regression-models\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/evaluate-model#metrics-for-regression-models<\/a>    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"slowness of azure ml cloud compute",
        "Question_created_time":1618714586367,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361307\/slowness-of-azure-ml-cloud-compute",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am doing a speed comparison test between my machine and azure ml cloud compute. My PC is 8 cores with 64 GB RAM. The compute instance I created on azure is &quot;Standard_D14_v2 (16 cores, 112 GB RAM, 800 GB disk)&quot;. One test I did was to run a XGBoost model and it took about 1h15m locally. On the cloud, it took 1h45m. I thought I would have a better performance with the instance created on azure. Could someone explain to me why I saw the opposite? Thank you so much!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"can not install opendp.smartnoise in Azure ML",
        "Question_created_time":1618600497387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/360860\/can-not-install-opendp-smartnoise-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am using Azure ML via jupyter notebook Python 3.8 - AzureML and Standard_D2s_v3  as computing power  <br \/>\nI want to apply differential privacy via opendp according to official tutorials. Hovewer When I try to install it I have an error  <\/p>\n<blockquote>\n<p>!pip install opendp-smartnoise  <\/p>\n<p>from opendp.smartnoise.metadata import CollectionMetadata  <br \/>\nfrom opendp.smartnoise.sql import PandasReader, PrivateReader  <br \/>\nimport opendp.smartnoise.core as sn  <\/p>\n<hr \/>\n<p>ModuleNotFoundError                       Traceback (most recent call last)  <br \/>\n&lt;ipython-input-15-29fe0b8b627f&gt; in &lt;module&gt;  <br \/>\n      1 get_ipython().system('pip install opendp-smartnoise')  <br \/>\n      2   <br \/>\n----&gt; 3 from opendp.smartnoise.metadata import CollectionMetadata  <br \/>\n      4 from opendp.smartnoise.sql import PandasReader, PrivateReader  <br \/>\n      5 import opendp.smartnoise.core as sn  <\/p>\n<p>ModuleNotFoundError: No module named 'opendp'  <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Train Split clarification in Automated ML",
        "Question_created_time":1618754770423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361456\/train-split-clarification-in-automated-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure automated ML experiment: <em>30,000<\/em> rows:  <br \/>\nIn <em>Additional configurations<\/em> -&gt; <em>Validation<\/em> -&gt; <em>Validation Type<\/em>  <\/p>\n<ol>\n<li> When selecting <em>Auto<\/em>, which 10% of the dataset is taken for validation?  <br \/>\n <em>a. The first 10% of the dataset?  <br \/>\n b. The last 10% of the dataset?  <br \/>\n c. Random 10% of the dataset?<\/em>  <\/li>\n<li> When selecting <em>Train-validation split<\/em>, which X% of the dataset is taken for validation?  <br \/>\n <em>a. The first X% of the dataset?  <br \/>\n b. The last X% of the dataset?  <br \/>\n c. Random X% of the dataset?<\/em>  <\/li>\n<\/ol>\n<p>If none of the answers is b, how can I run an automated ML experiment with a specified Train dataset and another totally separate validation dataset that was prepared beforehand?  <\/p>\n<p>Thanks!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"VM Environment Fails Because It Cannot Find ipkernal Module",
        "Question_created_time":1618545455163,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/359692\/vm-environment-fails-because-it-cannot-find-ipkern",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have created a python script using Azure SDK to train a machine learning model and save an output .csv file. I created a python environment with all of the conda and pip dependencies needed to run the script and registered that environment to the workspace. However, when I go to run my script using the registered environment my experiments keep failing. The error message in the log that I cannot figure out states that the script fails because it cannot find the 'ipykernal' module when trying to import matplotlib. Here is the full text of error message:<\/p>\n<p>[2021-04-15T22:52:41.716160] The experiment failed. Finalizing run...  <br \/>\n[2021-04-15T22:52:41.716178] Start FinalizingInRunHistory  <br \/>\n[2021-04-15T22:52:41.717507] Logging experiment finalizing status in history service.  <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 22305  <br \/>\nCleaning up all outstanding Run operations, waiting 300.0 seconds  <br \/>\n1 items cleaning up...  <br \/>\nCleanup took 0.07227706909179688 seconds  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;prod_model.py&quot;, line 5, in &lt;module&gt;  <br \/>\nimport matplotlib.pyplot as plt  <br \/>\nFile &quot;\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/site-packages\/matplotlib\/pyplot.py&quot;, line 2356, in &lt;module&gt;  <br \/>\nswitch_backend(rcParams[&quot;backend&quot;])  <br \/>\nFile &quot;\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/site-packages\/matplotlib\/pyplot.py&quot;, line 221, in switch_backend  <br \/>\nbackend_mod = importlib.import_module(backend_name)  <br \/>\nFile &quot;\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/importlib\/<strong>init<\/strong>.py&quot;, line 127, in import_module  <br \/>\nreturn _bootstrap._gcd_import(name[level:], package, level)  <br \/>\nModuleNotFoundError: No module named 'ipykernel'<\/p>\n<p>[2021-04-15T22:52:42.232402] Finished context manager injector with Exception.<\/p>\n<p>I have tried to import ipykernal as both a conda and pip package when creating the environment, but neither method is able to find the ipykernal package when I try to run the environment creation code. I have even tried to include the exact same version of every package that I have downloaded on my local machine (where the code runs without errors).<\/p>\n<p>If anyone has any thoughts as to how to resolve this issue, I'd love to hear them. Thanks in advance for any help you can provide.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model Explanation Run Error: Object of type 'Timestamp' is not JSON serializable",
        "Question_created_time":1618588503547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/360712\/model-explanation-run-error-object-of-type-timesta",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>All my model explanation run have following error. (For different data, algorithm, model,...)<\/p>\n<p>Encountered an internal AutoML error. Error Message\/Code: ClientException. Additional Info: ClientException:  <br \/>\nMessage: Object of type 'Timestamp' is not JSON serializable  <br \/>\nInnerException: None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Object of type 'Timestamp' is not JSON serializable&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>I would appreciate if you could help me to solve<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML.NET support CUDA 11",
        "Question_created_time":1618583468453,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/360545\/ml-net-support-cuda-11",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Loading model from: F:\\V2Sorter\\DataSet\\03.01.2021\\imageClassifier_2.zip  <br \/>\n2021-04-16 16:06:33.457209: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1720] Found device 0 with properties:   <br \/>\npciBusID: 0000:03:00.0 name: GeForce RTX 3080 computeCapability: 8.6  <br \/>\ncoreClock: 1.905GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB\/s  <br \/>\n2021-04-16 16:06:33.458465: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll  <br \/>\n2021-04-16 16:06:33.459114: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll  <br \/>\n2021-04-16 16:06:33.459639: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll  <br \/>\n2021-04-16 16:06:33.460164: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll  <br \/>\n2021-04-16 16:06:33.460705: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll  <br \/>\n2021-04-16 16:06:33.461270: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll  <br \/>\n2021-04-16 16:06:33.461946: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll  <br \/>\n2021-04-16 16:06:33.462589: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll  <br \/>\n2021-04-16 16:06:33.463409: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1862] Adding visible gpu devices: 0  <br \/>\n2021-04-16 16:06:33.464111: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:  <br \/>\n2021-04-16 16:06:33.464830: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1267]      0   <br \/>\n2021-04-16 16:06:33.465221: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1280] 0:   N   <br \/>\n2021-04-16 16:06:33.465788: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1406] Created TensorFlow device (\/job:localhost\/replica:0\/task:0\/device:GPU:0 with 7745 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:03:00.0, compute capability: 8.6)  <br \/>\nException thrown: 'System.EntryPointNotFoundException' in Microsoft.ML.Vision.dll  <br \/>\ndevice is disconnected  <br \/>\nException thrown: 'System.IO.FileNotFoundException' in mscorlib.dll  <br \/>\nException thrown: 'System.IO.FileNotFoundException' in mscorlib.dll  <br \/>\nThe thread 0x2f80 has exited with code 0 (0x0).  <\/p>\n<p>I'm using &quot;SciSharp.TensorFlow.Redist-Windows-GPU&quot; with CUDA 2.4.0 support but get the exception &quot;Exception thrown: 'System.EntryPointNotFoundException' in Microsoft.ML.Vision.dll&quot;  <br \/>\nwhat could be the problem?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Manually deploy azureml docker image to app service",
        "Question_created_time":1614951059587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/300934\/manually-deploy-azureml-docker-image-to-app-servic",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to deploy an Azure ML webservice endpoint to an app service. I prefer to use an app service instead of ACI or AKS endpoints, because an app service has the benefit of scaling and deploying SSL certificates, withouth having to maintain and setup a fully secured AKS cluster. ACI is not advised to use in a production environment.  <\/p>\n<p>The docker image I am trying to deploy is the same docker image produced with ACI or AKS deployment. To do so I ran 'az model deploy' command for an ACI endpoint, which builds and packages all resources needed for the endpoint into an Docker image stored in ACR. I set up an app service which pulls this docker image from an ACR. Copying the startup command <code>runsvdir \/var\/runit<\/code> and azureml environment variables from a working ACI example should give an working webservice endpoint as app service. Unfortunately, I am struggling with an error that the azureml-app directory could not be found, which contains the model, model code and model execution scripts.   <\/p>\n<pre><code>2021-03-05T08:38:53.803756130Z 2021-03-05T08:38:53,786438768+00:00 - gunicorn\/run \n2021-03-05T08:38:53.806168222Z .\/run: line 13: cd: \/var\/azureml-app: No such file or directory\n<\/code><\/pre>\n<p>Pulling the docker image from the ACR and inspecting manually indeed confirmed there is no \/var\/azureml-app directory. But connecting to the ACI and inspecting the running container has a directory \/var\/azureml-app.  For me it's not clear when this folder and data is pulled into the image\/container. I would expect during 'az ml deploy' command which builds tjhe docker image, but clearly this is not the case. This is the only thing preventing me from having a working app service, does anyone have an idea how to solve this?  <\/p>\n<p>More info about the docker image build by AzureML <a href=\"http:\/\/Manually+deploy+azureml+webservice+endpoint+to+app+service\">Docker Image AzureML<\/a>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to load jupyternote book files in Machine learning Workspace",
        "Question_created_time":1612883421600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265623\/unable-to-load-jupyternote-book-files-in-machine-l",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>None of the jupyter notebook files are loading in Machine Learning workspace studio. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Filter blob storage data and send to Machine Learning",
        "Question_created_time":1617134052800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/338053\/filter-blob-storage-data-and-send-to-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>As a kind of continuation of my previous question: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/321315\/send-data-from-iot-central-to-azure-machine-learni.html\">Send data from IoT central to Azure Machine Learning Resource<\/a>     <br \/>\nI am wondering how I can filter my data to send to Machine Learning. I have multiple devices that are exporting data from IoT Central to Azure Blob Storage, I am wondering how I can filter the data for each device so I can send to a Machine Learning model?    <\/p>\n<p>Additionally, do I need to create multiple ML models for each device or can I send all filtered data to the same model? (For ex. If I have 5 devices collecting temperature data and I want to predict if the device user has a cold, I want to use the same model that predicts colds but I want to predict separately for each user based on their data)    <\/p>\n<p>Thanks so much!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ServicePrincipalAuthentication no longer working in Databricks",
        "Question_created_time":1618246743070,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/354148\/serviceprincipalauthentication-no-longer-working-i",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi all.<\/p>\n<p>I've had this problem for MONTHS now and, not having the option to give up, I'm getting desperate.<\/p>\n<p>I have a databricks set up where an azure file-share is mounted, and this is used to extract data and read it into a database. Up until Monday it was been working fine.<\/p>\n<p>Recently, although nothing has changed about the way the drive is mounted (via Azure ML libraries):<\/p>\n<p>sp = ServicePrincipalAuthentication(tenant_id=&quot;x&quot;, # tenantID service_principal_id=&quot;y&quot;, clientId service_principal_password=&quot;z&quot;)<\/p>\n<p>clientSecret ws = Workspace.get(name=&quot;wsname&quot;, auth=sp, subscription_id=&quot;a&quot;)<\/p>\n<p>Listing the contents of a directory suddenly takes an enormous amount of time to finish (50 minutes), before no longer being able to find the folder. Essentially, it repeatedly tries to switch back to interactive authentication before failing altogether, saying [Errno22]: Invalid Argument.<\/p>\n<p>import os<\/p>\n<p>folder = &quot;\/mnt\/tmp\/xx\/a\/b\/c&quot;<\/p>\n<p>patient_names = os.listdir(&quot;\/mnt\/tmp\/xx\/a\/b\/c&quot;) print(patient_names)<\/p>\n<p>I'm lost, is there anywhere I should be looking to try and find out what's wrong?<\/p>\n<p>It works fine using Interactive authentication and WAS working with SPA, but suddenly does not.  <br \/>\nI've tried:<\/p>\n<ul>\n<li>   Recreating the datastore and dataset in ML<\/li>\n<li>   Creating new databricks clusters on which to run the code.<\/li>\n<li>   Creating another service principal<\/li>\n<li>   Running the code on my windows work machine with Pycharm and Python 3.7<\/li>\n<li>   Creating an Ubuntu environment with Pycharm and Python 3.7<\/li>\n<li>   Creating a new machine learning environment<\/li>\n<li>   Running the code with the python logging module to see if anything useful has come back.<\/li>\n<li>   Trying several different versions of azureml-sdk[databricks]<\/li>\n<li>   Trying yet another service principal.    Nothing has worked. I don't understand how\/why service principals are suddenly being ignored, why there are no error messages or useful information of any kind, or how nobody else has come across this problem?<\/li>\n<\/ul>\n<p>Please can someone help?<\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while trying to run  data",
        "Question_created_time":1604177052600,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/147105\/error-while-trying-to-run-data",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>i am new on Azure ML and trying to get familiar.i imported my data from the Web URL via HTTP. i tried running but it cant be completed as it keeps giving me Error 0030 , error while downloading the file , error 0039, error while completing operations.  <br \/>\nkindly help ou as i cant proceed<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where are the variables quotients after doing a regression run in ML?",
        "Question_created_time":1617200123477,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/339422\/where-are-the-variables-quotients-after-doing-a-re",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Having done my first Azure ML Studio session, the presented output metrics are global (Spearman, Explained variance, etc) are somewhat secondary to my requirement of knowing how each of my hundreds of variables have contributed to these. But I cannot find them. I would appreciate some guidance to where such numbers are - I know they have to be somewhere, as they (in total) provide the shown metrics.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine learning and attached compute instance",
        "Question_created_time":1617888515360,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349518\/azure-machine-learning-and-attached-compute-instan",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <br \/>\nMy initial one-month free credits have expired and I registered my credit card. In the first year there are several free resources which can be used free of charge for a limited capacity.    <br \/>\nI have created a Standard B2s (2 vcpus, 4 GiB memory) VM and a Machine Learning resource in the same resource group.    <br \/>\nI have successfully attached this VM to the ML computing resources as you can see on the photo:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85778-ml-attach.png?platform=QnA\" alt=\"85778-ml-attach.png\" \/>    <\/p>\n<p>However whether in the notebook part if I create a new notebook or in the pipeline part if I create a new pipeline I can't select this attached compute resource to be the compute target.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85804-target.png?platform=QnA\" alt=\"85804-target.png\" \/>    <\/p>\n<p>Can you please help how to manage this situation?    <br \/>\nI am in the learning phase of Azure ML and I would like to use the free resource until I have enough experience to create the production pipeline.    <br \/>\nThanks in advance    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AssertError:read can not have position excceed buffer length",
        "Question_created_time":1618316417143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/355512\/asserterror-read-can-not-have-position-excceed-buf",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi i am getting following error when trying to predict using externally generated R xgboost model in azure ML studio  <\/p>\n<p>Error 0063: The following error occurred during evaluation of R script:  <br \/>\n---------- Start of error message from R ----------  <br \/>\nAssertError:read can not have position excceed buffer length  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NOTEBOOK TERMINAL AZURE",
        "Question_created_time":1618331988847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/355752\/notebook-terminal-azure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>I COPIED AND PASTED, pip install -r requirements.txt --user --upgrade UNDER MY NOTEBOOK TERMINAL IN AZURE. IT STARTED LAUNCHING BUT LAPTOP SHUTDOWN. I RESTARTED IT, TRIED COPYING AND PASTING THE ABOVE LINK, BUT NOW IT GIVES THE MESSAGE BELOW. HELP PLEASE.  <\/p>\n<p>Requirement already satisfied, skipping upgrade: oauthlib&gt;=3.0.0 in \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-&gt;-r requirements.txt (line 32)) (3.1.0)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studios Deploy Model - Obtain logs",
        "Question_created_time":1618204695277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/353046\/azure-machine-learning-studios-deploy-model-obtain",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am attempting to deploy a model to an Endpoint in MS Azure Machine Learning studio but I get some errror.<\/p>\n<p>2 Questions  <\/p>\n<ol>\n<li> How can we get the logs for a deployed model (See my attempts below)  <\/li>\n<li> How do models get loaded into the docker images as I suspect for some reason it didn't get copied into the docker image.<\/li>\n<\/ol>\n<p>Step 1) Upload the model: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model<\/a>  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/86639-image.png?platform=QnA\" alt=\"86639-image.png\" \/><\/p>\n<p>Which is successful. I can see and download that my model is correct.<\/p>\n<p>Step 2) Deploy to Azure Container Instances: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance<\/a><\/p>\n<p>I use this code snippet to deploy my code<\/p>\n<pre><code>from azureml.core.model import InferenceConfig  \nfrom azureml.core.webservice import AciWebservice  \nfrom azureml.core.webservice import Webservice  \nfrom azureml.core.model import Model  \nfrom azureml.core.environment import Environment  \n\nscript_file_name = 'inference\/score.py'  \n\ninference_config = InferenceConfig(entry_script=script_file_name, environment=tf_env)  \n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,   \n                                               memory_gb = 1,   \n                                               tags = {'iris': &quot;rh1832&quot;, 'type': &quot;sklearn&quot;},   \n                                               description = 'sample service for iris')  \n\naci_service_name = 'rh1832-iris-demo'  \nprint(aci_service_name)  \naci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)  \naci_service.wait_for_deployment(True)  \nprint(aci_service.state)  \n<\/code><\/pre>\n<p>And my score.py inference script looks like<\/p>\n<pre><code># ---------------------------------------------------------  \n# Copyright (c) Microsoft Corporation. All rights reserved.  \n# ---------------------------------------------------------  \nimport json  \nimport logging  \nimport os  \nimport pickle  \nimport numpy as np  \nimport pandas as pd  \nimport joblib  \n\ntry:  \n    logger = logging.getLogger('azureml.automl.core.scoring_script')  \nexcept:  \n    pass  \n\n\ndef init():  \n    global model  \n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_model')  \n    path = os.path.normpath(model_path)  \n    path_split = path.split(os.sep)  \n    logger.info(&quot;Loading model from path.&quot;)  \n    model = joblib.load(model_path)  \n    logger.info(&quot;Loading successful.&quot;)  \n\n\ndef run(data):  \n    try:  \n        target_names = ['database', 'network', 'resource']  \n        result = model.predict([data])  \n        return json.dumps(target_names[result[0]])  \n    except Exception as e:  \n        print(&quot;error: &quot; + str(e))  \n        result = str(e)  \n        return json.dumps({&quot;error&quot;: result})  \n<\/code><\/pre>\n<p>After submitting the webservice to be deployed i get an error that just says its in crashloopbackoff state with no details for which part of the script failed.  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/86703-image.png?platform=QnA\" alt=\"86703-image.png\" \/><\/p>\n<p>Step 3) I attempted to debug the logs by follow this guide: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#dockerlog\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#dockerlog<\/a><\/p>\n<p>1) Running script locally which I was able to successfully run score.py  <br \/>\n2) Running docker image locally I didn't see the model in the folder azureml-environment-setup in the docker container:<\/p>\n<p>root@09e7230839e3:\/azureml-environment-setup# ls  <br \/>\nenvironment_context.json log4j.properties mutated_conda_dependencies.yml send_conda_dependencies.py spark_cache.py<\/p>\n<p>and also i didn't see the entrypoint for running the docker container. Is there any guide for running the docker image locally?<\/p>\n<p>3) Finally I attempted to get the logs using Azure CLI and it only return an Null list it appeared  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/86713-image.png?platform=QnA\" alt=\"86713-image.png\" \/><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't disable a scheduled pipeline endpoint",
        "Question_created_time":1618002234640,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/351921\/cant-disable-a-scheduled-pipeline-endpoint",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <br \/>\nI scheduled my pipeline to run weekly. Now I want to disable it. However, when I disable on Azure ML Studio, an error shows as below:  <\/p>\n<p>An error occurred while disabling pipeline  <br \/>\nBadRequest: Cannot deprecate a pipeline with active schedules.  <\/p>\n<p>Trace ID : cded492c-84a5-47aa-afc4-0a678e611e5b  <br \/>\nClient request ID : 4e904a8b-90f5-4572-815d-c23a0249c43b  <\/p>\n<p>Could you look into this? and instruct me how to stop that scheduled pipeline.  <br \/>\nThanks,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Module: Error in running inference pipeline",
        "Question_created_time":1618193761160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/352952\/azure-machine-learning-module-error-in-running-inf",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline<\/a>.    <\/p>\n<p>I'm following the instructions on the module page above, however the following error occurs repeatley when I attempted to run the pipeline.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/86615-image.png?platform=QnA\" alt=\"86615-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Convert to tabular from file dataset",
        "Question_created_time":1617956083027,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/350780\/convert-to-tabular-from-file-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Yesterday I ran the \u2018consume\u2019 code to pull the data onto the cluster and it seemed to work but I still can\u2019t use it from ML designer as it\u2019s a file dataset rather than a tabular dataset. I\u2019ve tried a couple of ways of converting it without success, my next avenue of exploration is to use the SDK rather than trying to do it through the console <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Paste into a .ipynb notebook",
        "Question_created_time":1617916645243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349979\/paste-into-a-ipynb-notebook",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><strong>I have a created .ipynb file but I can't seem to be a able to paste copied code into the cells.<\/strong>   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Files in gitignore are not excluded in snapshot created by ML pipeline",
        "Question_created_time":1617897599523,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349783\/files-in-gitignore-are-not-excluded-in-snapshot-cr",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I'm trying to run a pipeline (built via Python SDK), and I want the repo to be snapshotted, because the different modules are called inside the pipeline scripts. The source folder I pass to the pipeline has the following structure:  <\/p>\n<p>repo  <\/p>\n<ul>\n<li> src  <\/li>\n<li> data  <\/li>\n<li> <code>script_step1.py<\/code>  <\/li>\n<li> <code>script_step2.py<\/code>  <\/li>\n<li> <code>script_step3.py<\/code>  <\/li>\n<li> <code>.gitignore<\/code>  <\/li>\n<\/ul>\n<p>I want the data folder to be ignored in the snapshot, so in my gitignore file I have al line with written *\/data\/**, but when I try to run the pipeline I get an error that tells me that the snapshot is too big (I checked the size of the other stuff except for data folder and it is very little)  <br \/>\nI'm not understanding why that happens.  <br \/>\nThanks a lot in advance  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Hyperdrive",
        "Question_created_time":1617723280093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/346257\/azure-ml-hyperdrive",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When running the hyperdrive step, I would like to get the hyper parameters that were selected for the best model and export them to use in a subsequent model. How would I got about doing that? I saw a method get_hyperparameters but from what I can tell that just gets all child runs. I am essentially wanting to use the same model but change alpha levels. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployment Failed: Microsoft.MachineLearningServices Internal service error",
        "Question_created_time":1617654155327,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/344946\/deployment-failed-microsoft-machinelearningservice",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to deploy an Azure ML workspace with the Azure portal, no matter what settings I choose I get an Internal service error on creation of the workspace, all the other resources deploy without issues. Is there a way to debug this with a better error message?  <\/p>\n<pre><code>{\n    &quot;status&quot;: &quot;Failed&quot;,\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;InternalServerError&quot;,\n        &quot;message&quot;: &quot;InternalServerError&quot;\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning designer - edit columns stuck on loading",
        "Question_created_time":1617486098190,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/343332\/azure-machine-learning-designer-edit-columns-stuck",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":12,
        "Question_body":"<p>Azure machine learning designer :  <\/p>\n<p>I have a dataset on the designer connected to a Normalize data module but it keeps loading when i try to Edit columns on Normalize data module with no result or errors.  <br \/>\nThe same thing happens with Select columns in dataset module.  <\/p>\n<p>I have tried to recreate and restart and even deleted the whole resource group but no luck.  <br \/>\nI tried on both mac and windows with different browsers but still getting stuck on the same place.  <\/p>\n<p>any idea on how to solve this issue?   <\/p>\n<p>Thanks!  <\/p>\n<p>Screenshot:  <br \/>\n<a href=\"https:\/\/i.imgur.com\/P0oWrGR.png\">https:\/\/i.imgur.com\/P0oWrGR.png<\/a>  <\/p>",
        "Question_closed_time":1617711247023,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7246d026-6219-48cf-ab02-a9826f9174a5\">@Ayush Bhardwaj  <\/a> <a href=\"\/users\/na\/?userid=1f1ee936-54c7-4809-839f-2bd5ff84ec7b\">@yazeen jasim  <\/a> <a href=\"\/users\/na\/?userid=491da3e9-5349-4967-9851-b193f28abcac\">@Anshul Sharma  <\/a> This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Pytorch cannot detect GPU when using an AML Compute Cluster with a GPU",
        "Question_created_time":1617721297227,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/346224\/pytorch-cannot-detect-gpu-when-using-an-aml-comput",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I've been trying to train a pytorch model on the Azure ML compute clusters (STANDARD_NV6) but I cannot get the code to detect and use the GPU device, torch.cuda.is_available() always returns False.<\/p>\n<p>I'm using a custom environment and have tried using a few different dockerfiles as base images from the Microsoft container repository. For example, I've tried the &quot;mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04&quot; base image.<\/p>\n<p>In the build log, I can see that the correct dependencies are installed each time but the code still doesn't detect a GPU. I tried forcing docker to use the GPU with docker_arguments = [&quot;--gpus&quot;, &quot;all&quot;] but this causes the build to fail with this error:<\/p>\n<pre><code>AzureMLCompute job failed.\nFailedStartingContainer: Unable to start docker container\n    FailedContainerStart: Unable to start docker container\n    err: warning: your kernel does not support swap limit capabilities or the cgroup is not mounted. memory limited without swap.\ndocker: error response from daemon: oci runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: running hook #1:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: \/mnt\/docker\/overlay2\/66b78fe178db5d08ca4db26528f1a6de00aba65b528a6568649b1abcbea22348\/merged\/run\/nvidia-persistenced\/socket: no such device or address: unknown.\n\n    Reason: warning: your kernel does not support swap limit capabilities or the cgroup is not mounted. memory limited without swap.\ndocker: error response from daemon: oci runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: running hook #1:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: \/mnt\/docker\/overlay2\/66b78fe178db5d08ca4db26528f1a6de00aba65b528a6568649b1abcbea22348\/merged\/run\/nvidia-persistenced\/socket: no such device or address: unknown.\n\n    Info: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>It feels like I've missed some obvious step somewhere...<\/p>\n<p>Thanks for any help!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get transformation function inside entry script",
        "Question_created_time":1617723042437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/346270\/get-transformation-function-inside-entry-script",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>Hello everyone,    <\/p>\n<p>i am currently getting into Azure Machine Learning. I am trying out the learning path for Data Scientists. In that learning path, the Designer is introduced, where Pipelines are being published to be consumed as a real time inference pipeline.    <\/p>\n<p>Since I dont want to use the Designer all the time I want to do the same in python and convert the tutorial inference pipeline (here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline<\/a>) to a python script for deployment. For that I am refering to the learning path on how to deploy a model (here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/register-and-deploy-model-with-amls\/2-deploy-model\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/register-and-deploy-model-with-amls\/2-deploy-model<\/a>).     <\/p>\n<p>My current issue is that in the designer inference pipeline the transformation steps seem to get a transformation function to transform new incoming data based on the transformation that was done during training. The ressources in the azure documentation do not explain anywhere on how to retrieve this function from a training pipeline to do the same transformation in an entry script using python.     <\/p>\n<p>I would be happy if you could help me with this issue since I am eager to learn and use Azure Machine Learning in the future.    <br \/>\nBest regards and Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why can't a label the rest of my set?",
        "Question_created_time":1616799706400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/333975\/why-cant-a-label-the-rest-of-my-set",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>Can anyone suggest why I can't label the rest of my pending images??    <\/p>\n<p>See screenshot for example..    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/82041-image.png?platform=QnA\" alt=\"82041-image.png\" \/>    <\/p>\n<p>Regards,    <br \/>\nChris<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"After selecting the \"Edit column\" button of the \"Select Columns in Dataset\" module in Designer, it will be stuck in the \"loading\" state.",
        "Question_created_time":1617523186537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/343427\/after-selecting-the-edit-column-button-of-the-sele",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_body":"<p>Hello everyone!    <\/p>\n<p>I am taking the <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data\">Create a Regression Model with Azure Machine Learning designer<\/a> course in Microsoft Learn. When I perform the steps in the Explore Data section, after selecting the &quot;Edit column&quot; button of the &quot;Select Columns in Dataset&quot; module in Designer, it will be stuck in the &quot;loading&quot; state. Therefore, I cannot proceed to the next step.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/84160-1.png?platform=QnA\" alt=\"84160-1.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/84253-2.png?platform=QnA\" alt=\"84253-2.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/84294-3.png?platform=QnA\" alt=\"84294-3.png\" \/>    <\/p>\n<p>Thank you very much!    <\/p>\n<p>Best regards,    <br \/>\nLing    <\/p>",
        "Question_closed_time":1617711172380,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2f4c69cd-f08d-480e-af96-29ddb1d93452\">@\u9ad8\u6977\u4fee  <\/a> This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine. <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Import Data Error - DocumentDb library exception: DocumentDB client threw an exception . ( Error 1000 ) Using Machine learning studio (classic)",
        "Question_created_time":1616594926800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/329881\/import-data-error-documentdb-library-exception-doc",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using Machine learning studio classic to connect the Import Data module to Cosmos. But, on run, it throws Error 1000. I tried using select * from c, select &lt;attribute&gt; from &lt;database&gt;, select &lt;attribute&gt; from &lt;collection&gt;, but it still returns the error message. In the official Cosmos documentation, using c works with the C# SDK. Is there a special syntax here for the query?    <br \/>\nThe other option is the Execute Python Script module, but the packet azure.cosmos is not installed. Is there a way to install it, importing it doesn't work because it requires dependencies, and adding those dependencies like azure.core, they have import commands with relative paths in them, which result in another &quot;module not found&quot; error regarding those dependencies further down the path?    <\/p>\n<p>I downloaded the Wheel file type .whl of &quot;azure.cosmos&quot;, extracted it along with &quot;azure.core&quot; to a new folder, added the folder to a .zip file, and uploaded it as a dataset. Then, connecting that dataset to a Python Script module and importing with:    <\/p>\n<p>from azure.cosmos import exceptions, CosmosClient, PartitionKey    <\/p>\n<p>returns another error, about a missing &quot;azure.core&quot; module. That is because the cosmos module depends on the &quot;azure.core&quot; module and the .py files in the core module reference other files with relative paths.    <\/p>\n<p>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    <\/p>\n<p>More about the Import Data module error:    <\/p>\n<p>Error 1000    <br \/>\nInternal library exception.    <\/p>\n<p>This error is provided to capture otherwise unhandled internal engine errors. Therefore, the cause for this error might be different depending on the module that generated the error.    <\/p>\n<p>To get more help, we recommend that you post the detailed message that accompanies the error to the Azure Machine Learning forum, together with a description of the scenario, including the data used as inputs. This feedback will help us to prioritize errors and identify the most important issues for further work.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/errors\/machine-learning-module-error-codes?redirectedfrom=MSDN#error-1000\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/errors\/machine-learning-module-error-codes?redirectedfrom=MSDN#error-1000<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Group Categorical Values in Azure ML Designer",
        "Question_created_time":1615818855177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/315002\/group-categorical-values-in-azure-ml-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <br \/>\nis there any possibility to do the same in Azure ML Studio designer as it is able in Azure ML Studio? I need to group categorical values, but in Azure ML Studio designer there option for Group Data into Bins. When I am trying to do it by chosing custom edges, it does not seem to work with data column which is categorical.   <\/p>\n<p><strong>EDIT<\/strong>  <br \/>\nI have rating 1-5, and I would like to make it in from 1-2-3-4-5 to 1-5. When creating bins I only can get categorized as 1 and 2.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Train model fail \/ error",
        "Question_created_time":1615749764870,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/313505\/train-model-fail-error",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, when I create a model and try to train it, it always fails. The same model on different two compute targets are these:   <\/p>\n<ol>\n<li> <em>AzureMLCompute job failed. UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault. Reason: Process Killed with either 6:aborted or 9:killed or 11:segment fault. exit code here is from wrapping bash hence 128 + n Cause: killed TaskIndex: NodeIp: 10.0.0.4 NodeId: tvmps_2b4c1352eab879faa7df6dd68985461ea7ef172338311bc4bd278f1c7c66b3ad_d Reason: Job failed with non-zero exit Code<\/em>  <\/li>\n<li> <em>AmlExceptionMessage:AzureMLCompute job failed. JobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details. Reason: Job failed with non-zero exit Code ModuleExceptionMessage:InvalidTrainingDataset: Dataset contains invalid data for training. Learner type: Binary classifier. Reason: The number of label classes should equal to 2, got 5 classes.<\/em>  <\/li>\n<li> <em>AzureMLCompute job failed. JobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details. Reason: Job failed with non-zero exit Code<\/em>  <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I save my machine learning prediciton model which is built in Azure ML Studio?",
        "Question_created_time":1615464810373,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/309888\/how-can-i-save-my-machine-learning-prediciton-mode",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to extract or save the model which I worked and built in Azure ML Studio as .pkl file or some other format. Can anyone please share the steps on how to do it?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML AKS - Failed to Pull Image",
        "Question_created_time":1617400984927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/342829\/aml-aks-failed-to-pull-image",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>We are using a preview future from AKS to stop our cluster with our real-time inference cluster.   <\/p>\n<p>From time to time when we start the Cluster we wait to all of the services get ready but some of the pods stay without starting. Today researching about this issue in the logs we saw this error:  <\/p>\n<p>  Failed to pull image  <br \/>\n  &quot;viennaglobal.azurecr.io\/azureml\/azureml_d401b6211d79af733a3b055ae6394****  <\/p>\n<p>Some of our models that are deployed to this AKS are created and deployed with AML Designer and endpoint publisher  <\/p>\n<p>If i'm not wrong this image is an AML &quot;base&quot; image and it is not ours. I saw all of our suscription container registry and i cannot see a registry with this endpoint or even an image with this ID.  <\/p>\n<p>Is this a &quot;public&quot; AML repository? Is this container registry repository available or it has some problem on it?  <\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Production Web API pricing",
        "Question_created_time":1617359262120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/342374\/production-web-api-pricing",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello everyone,  <\/p>\n<ol>\n<li> I'd like to try AutoML and deploy a machine learning model and consume it as a web service in an application.  <\/li>\n<li> Can please someone explains more about Production Web API pricing just the Dev\/Test version.  <\/li>\n<\/ol>\n<p>I would be most grateful if you could provide a documentation link that can guide me through the above.  <\/p>\n<p>Your help will be highly appreciated.  <\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I get started predictive Maintanance using Machine Learning?",
        "Question_created_time":1617360731433,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/342399\/how-do-i-get-started-predictive-maintanance-using",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Give me a brief description of the <a href=\"https:\/\/www.intuceo.com\/blog\/how-to-get-started-with-predictive-maintenance-using-machine-learning\/\">predictive maintenance<\/a> using machine learning.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What syntax references Pipeline parameters in the where clause of a SQL query of 'Import Data' modules in Microsoft Azure Machine Learning designer?",
        "Question_created_time":1616787456817,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/333816\/what-syntax-references-pipeline-parameters-in-the",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have created a pipeline in Microsoft Azure Machine Learning designer. I have added a Pipeline parameter myNumber in the pipeline settings, with a valid default value, to accept the unique ID of the asset in our DB so that the pipeline can return only the asset-specific data for use as our model input. Specifically I want to reference that pipeline parameter in the where clause of the SQL query in the 'Import Data' module that connects to our Azure SQL server.  <\/p>\n<p>I cannot find a reference in the documentation on how to do this. I have tried the methods specified for accomplishing this task in Azure Data Factory, using  where RowId = @pipeline().parameters.myNumber or where RowId = @{variables('myNumber')} but the experiment fails with SqlException error code '137', variable not defined.  <\/p>\n<p>Can you please tell me the necessary syntax to reference Pipeline parameters in the where clause of a SQL query of 'Import Data' modules of Microsoft Azure Machine Learning designer?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using \"cv_splits_indices\" in AutoMLConfig",
        "Question_created_time":1614846003803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/298513\/using-cv-splits-indices-in-automlconfig",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When training an regression model with AutoMLConfig with n_cross_validations being a normal int, I'm facing no problems.  <\/p>\n<p>Now I want to use TimeSeriesSplit as the cross validation method for training a model with AutoMLConfig. For this there is a &quot;cv_splits_indices&quot; argument where I put in a list of lists of indicis like the following when n_splits=5 in TimeSeriesSplit :  <\/p>\n<pre><code>array([[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n        array([11, 12, 13, 14])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n        array([15, 16, 17, 18])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18]),\n        array([19, 20, 21, 22])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22]),\n        array([23, 24, 25, 26])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26]),\n        array([27, 28, 29, 30])]], dtype=object)\n<\/code><\/pre>\n<p>Unfortunately when running the following cell:  <\/p>\n<pre><code>automl_settings = {\n    &quot;iteration_timeout_minutes&quot;: 15,\n    &quot;experiment_timeout_hours&quot;: 0.3,\n    &quot;max_cores_per_iteration&quot; : -1,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;primary_metric&quot;: 'normalized_root_mean_squared_error',\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;cv_splits_indices&quot;: idxs\n}\n\nautoml_config = AutoMLConfig(task='regression',\n                             debug_log=f'automated_ml_errors_.log',\n                             training_data=train,\n                             validation_data=train,\n                             label_column_name=y_var,\n                             **automl_settings)\n<\/code><\/pre>\n<p>I receive the following error:  <\/p>\n<pre><code>ConfigException: ConfigException:\n Message: cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\n InnerException: None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;cv_splits_indices&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;\n            }\n        },\n        &quot;reference_code&quot;: &quot;XXXXXXREDACTEDXXXX&quot;\n    }\n}\n<\/code><\/pre>\n<p>What is going wrong here? My input looks correct?  <\/p>\n<p>Thank you  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model training \"canceled\" on Microsoft Azure",
        "Question_created_time":1616758467970,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/333336\/model-training-canceled-on-microsoft-azure",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Frequently while training Machine Learning models on Azure, the loss and accuracy output freezes half way through training. A &quot;canceled&quot; message in red is appearing the notebook cell. However, the kernel is still displaying a &quot;busy&quot; message.   <\/p>\n<p>I am paying for a GPU and this is making the service unusable for me as I don't know if the model is training correctly.   <\/p>\n<p>It appears that I have to pay for technical support to register a ticket. What a joke!!!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML deployment error from designer \"There is no label column in \"Scored dataset\"",
        "Question_created_time":1616709014857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/332169\/azure-ml-deployment-error-from-designer-there-is-n",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>Hello All,<\/p>\n<p>We have developed below model. Model built and trained successfully. But while deploying as realtime inference it is throwing the error.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/81722-azure-ml-error.png?platform=QnA\" alt=\"81722-azure-ml-error.png\" \/><\/p>\n<p>Below is the deployment log<\/p>\n<p>2021\/03\/25 14:48:21 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/info\">http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/info<\/a>  <br \/>\n2021\/03\/25 14:48:21 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status<\/a>  <br \/>\n[2021-03-25T14:48:23.131202] Entering context manager injector.  <br \/>\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module', '--evaluation-results', 'DatasetOutputConfig:Evaluation_results', '--scored-dataset=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g'])  <br \/>\nScript type = None  <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 79  <br \/>\n[2021-03-25T14:48:25.777114] Entering Run History Context Manager.  <br \/>\n[2021-03-25T14:48:26.588216] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/mounts\/workspaceblobstore\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b  <br \/>\n[2021-03-25T14:48:26.588401] Preparing to call script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module', '--evaluation-results', '$Evaluation_results', '--scored-dataset=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g']  <br \/>\n[2021-03-25T14:48:26.588510] After variable expansion, calling script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module', '--evaluation-results', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpbh275yuo', '--scored-dataset=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g']<\/p>\n<p>2021\/03\/25 14:48:26 Not exporting to RunHistory as the exporter is either stopped or there is no data.  <br \/>\nStopped: false  <br \/>\nOriginalData: 1  <br \/>\nFilteredData: 0.  <br \/>\nSession_id = 77d2289a-878a-4d00-99c0-9d4112bd03b4  <br \/>\nInvoking module by urldecode_invoker 0.0.8.<\/p>\n<p>Module type: official module.<\/p>\n<p>Using runpy to invoke module 'azureml.studio.modulehost.module_invoker'.<\/p>\n<p>2021-03-25 14:48:27,284 studio.modulehost INFO Reset logging level to DEBUG  <br \/>\n2021-03-25 14:48:27,284 studio.modulehost INFO Load pyarrow.parquet explicitly: &lt;module 'pyarrow.parquet' from '\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'&gt;  <br \/>\n2021-03-25 14:48:27,284 studio.core INFO execute_with_cli - Start:  <br \/>\n2021-03-25 14:48:27,284 studio.modulehost INFO | ALGHOST 0.0.150  <br \/>\n2021-03-25 14:48:28,130 studio.modulehost INFO | CLI arguments parsed: {'module_name': 'azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module', 'OutputPortsInternal': {'Evaluation results': '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpbh275yuo'}, 'InputPortsInternal': {'Scored dataset': '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g'}}  <br \/>\n2021-03-25 14:48:28,139 studio.modulehost INFO | Invoking ModuleEntry(azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module; EvaluateModelModule; run)  <br \/>\n2021-03-25 14:48:28,139 studio.core DEBUG | Input Ports:  <br \/>\n2021-03-25 14:48:28,139 studio.core DEBUG | | Scored dataset = &lt;azureml.studio.modulehost.cli_parser.CliInputValue object at 0x7fe5ceeae5c0&gt;  <br \/>\n2021-03-25 14:48:28,139 studio.core DEBUG | Output Ports:  <br \/>\n2021-03-25 14:48:28,139 studio.core DEBUG | | Evaluation results = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpbh275yuo  <br \/>\n2021-03-25 14:48:28,140 studio.core DEBUG | Parameters:  <br \/>\n2021-03-25 14:48:28,140 studio.core DEBUG | | (empty)  <br \/>\n2021-03-25 14:48:28,140 studio.core DEBUG | Environment Variables:  <br \/>\n2021-03-25 14:48:28,140 studio.core DEBUG | | AZUREML_DATAREFERENCE_Scored_dataset = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g  <br \/>\n2021-03-25 14:48:28,140 studio.core INFO | Reflect input ports and parameters - Start:  <br \/>\n2021-03-25 14:48:28,141 studio.core INFO | | Handle input port &quot;Scored dataset&quot; - Start:  <br \/>\n2021-03-25 14:48:28,141 studio.core INFO | | | Mount\/Download dataset to '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g' - Start:  <br \/>\n2021-03-25 14:48:28,141 studio.modulehost DEBUG | | | | Content of directory \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g:  <br \/>\n2021-03-25 14:48:28,482 studio.modulehost DEBUG | | | | | _meta.yaml  <br \/>\n2021-03-25 14:48:28,482 studio.modulehost DEBUG | | | | | _samples.json  <br \/>\n2021-03-25 14:48:28,482 studio.modulehost DEBUG | | | | | data.dataset  <br \/>\n2021-03-25 14:48:28,483 studio.modulehost DEBUG | | | | | data.dataset.parquet  <br \/>\n2021-03-25 14:48:28,483 studio.modulehost DEBUG | | | | | data.metadata  <br \/>\n2021-03-25 14:48:28,483 studio.modulehost DEBUG | | | | | data.schema  <br \/>\n2021-03-25 14:48:28,483 studio.modulehost DEBUG | | | | | data.visualization  <br \/>\n2021-03-25 14:48:28,483 studio.modulehost DEBUG | | | | | data_type.json  <br \/>\n2021-03-25 14:48:28,891 studio.modulehost DEBUG | | | | | schema\/_schema.json  <br \/>\n2021-03-25 14:48:28,891 studio.core INFO | | | Mount\/Download dataset to '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g' - End with 0.7505s elapsed.  <br \/>\n2021-03-25 14:48:28,892 studio.core INFO | | | Try to read from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g via meta - Start:  <br \/>\n2021-03-25 14:48:29,215 studio.common INFO | | | | Load DataTableMeta successfully, path=data.dataset  <br \/>\n2021-03-25 14:48:29,220 studio.common INFO | | | | Load meta data from directory successfully, data=DataFrameDirectory(meta={'type': 'DataFrameDirectory', 'visualization': [{'type': 'Visualization', 'path': 'data.visualization'}], 'extension': {'DataTableMeta': 'data.dataset'}, 'format': 'Parquet', 'data': 'data.dataset.parquet', 'samples': '_samples.json', 'schema': 'schema\/_schema.json'}), type=&lt;class 'azureml.studio.common.datatable.data_table_directory.DataTableDirectory'&gt;  <br \/>\n2021-03-25 14:48:29,224 studio.core INFO | | | Try to read from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azuremldemo\/azureml\/7230c4b5-94a5-4af9-b5ff-5cd06433f19b\/wd\/tmpj67_av4g via meta - End with 0.3316s elapsed.  <br \/>\n2021-03-25 14:48:29,224 studio.core INFO | | Handle input port &quot;Scored dataset&quot; - End with 1.0836s elapsed.  <br \/>\n2021-03-25 14:48:29,225 studio.core INFO | | Handle input port &quot;Scored dataset to compare&quot; - Start:  <br \/>\n2021-03-25 14:48:29,225 studio.modulehost WARNING | | | File 'None' does not exist.  <br \/>\n2021-03-25 14:48:29,225 studio.core INFO | | Handle input port &quot;Scored dataset to compare&quot; - End with 0.0001s elapsed.  <br \/>\n2021-03-25 14:48:29,225 studio.core INFO | Reflect input ports and parameters - End with 1.0843s elapsed.  <br \/>\n2021-03-25 14:48:29,225 studio.core INFO | EvaluateModelModule.run - Start:  <br \/>\n2021-03-25 14:48:29,225 studio.core DEBUG | | kwargs:  <br \/>\n2021-03-25 14:48:29,225 studio.core DEBUG | | | scored_data = &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;  <br \/>\n2021-03-25 14:48:29,225 studio.core DEBUG | | | scored_data_to_compare = None  <br \/>\n2021-03-25 14:48:29,226 studio.core DEBUG | | validated_args:  <br \/>\n2021-03-25 14:48:29,226 studio.core DEBUG | | | scored_data = &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;  <br \/>\n2021-03-25 14:48:29,226 studio.core DEBUG | | | scored_data_to_compare = None  <br \/>\n2021-03-25 14:48:29,226 studio.module INFO | | Validate input data (Scored Data).  <br \/>\n2021-03-25 14:48:29,227 studio.core INFO | EvaluateModelModule.run - End with 0.0014s elapsed.  <br \/>\n2021-03-25 14:48:29,227 studio.modulehost INFO | Set error info in module statistics  <br \/>\n2021-03-25 14:48:29,227 studio.core INFO | Logging exception information of module execution - Start:  <br \/>\n2021-03-25 14:48:29,227 studio.modulehost INFO | | Session_id = 77d2289a-878a-4d00-99c0-9d4112bd03b4  <br \/>\n2021-03-25 14:48:29,227 studio.core INFO | | ModuleStatistics.log_stack_trace_telemetry - Start:  <br \/>\n2021-03-25 14:48:29,769 studio.core INFO | | ModuleStatistics.log_stack_trace_telemetry - End with 0.5417s elapsed.  <br \/>\n2021-03-25 14:48:29,769 studio.modulehost ERROR | | Get ModuleError when invoking ModuleEntry(azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module; EvaluateModelModule; run)  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 379, in exec  <br \/>\noutput_tuple = self._entry.func(**reflected_input_ports, **reflected_parameters)<\/p>\n<blockquote>\n<p>reflected_input_ports = {'scored_data': &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;, 'scored_data_to_compare': None}<\/p>\n<\/blockquote>\n<pre><code>  &gt; reflected_parameters = {}  \n\n  &gt; self = &lt;azureml.studio.modulehost.module_reflector.ModuleReflector object at 0x7fe5ceeae358&gt;  \n<\/code><\/pre>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 76, in wrapper  <br \/>\nret = func(*args, **validated_args)<\/p>\n<blockquote>\n<p>func = &lt;function EvaluateModelModule.run at 0x7fe5cee95f28&gt;<\/p>\n<\/blockquote>\n<pre><code>  &gt; args = ()  \n\n  &gt; validated_args = {'scored_data': &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;, 'scored_data_to_compare': None}  \n<\/code><\/pre>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 57, in run  <br \/>\noutput_values = EvaluateModelModule.evaluate_generic(**input_values)<\/p>\n<blockquote>\n<p>input_values = {'scored_data_to_compare': None, 'scored_data': &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;, 'input_values': {...}}<\/p>\n<\/blockquote>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 168, in evaluate_generic  <br \/>\ncls._validate_input(scored_data=scored_data, scored_data_to_compare=scored_data_to_compare)<\/p>\n<blockquote>\n<p>cls = &lt;class 'azureml.studio.modules.ml.evaluate.evaluate_generic_module.evaluate_generic_module.EvaluateModelModule'&gt;<\/p>\n<\/blockquote>\n<pre><code>  &gt; scored_data = &lt;azureml.studio.common.datatable.data_table.DataTable object at 0x7fe5cee5a668&gt;  \n\n  &gt; scored_data_to_compare = None  \n<\/code><\/pre>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 146, in _validate_input  <br \/>\ndataset_name=cls._args.scored_data.friendly_name)<\/p>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 133, in _validate_data_table  <br \/>\nerror_setting.ErrorMapping.throw(error_setting.NotLabeledDatasetError(dataset_name=dataset_name))<\/p>\n<blockquote>\n<p>dataset_name = 'Scored dataset'<\/p>\n<\/blockquote>\n<p>File &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py&quot;, line 821, in throw  <br \/>\nraise err<\/p>\n<blockquote>\n<p>err = NotLabeledDatasetError('There is no label column in &quot;Scored dataset&quot;.',)<\/p>\n<\/blockquote>\n<p>NotLabeledDatasetError: There is no label column in &quot;Scored dataset&quot;.  <br \/>\n2021-03-25 14:48:29,771 studio.core INFO | Logging exception information of module execution - End with 0.5435s elapsed.  <br \/>\n2021-03-25 14:48:29,771 studio.core INFO | ModuleStatistics.save_to_azureml - Start:  <br \/>\n2021-03-25 14:48:30,030 studio.core INFO | ModuleStatistics.save_to_azureml - End with 0.2591s elapsed.  <br \/>\n2021-03-25 14:48:30,030 studio.core INFO execute_with_cli - End with 2.7457s elapsed.  <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 79<\/p>\n<p>[2021-03-25T14:48:30.046295] The experiment failed. Finalizing run...  <br \/>\nCleaning up all outstanding Run operations, waiting 900.0 seconds  <br \/>\n3 items cleaning up...  <br \/>\nCleanup took 0.22303390502929688 seconds  <br \/>\nStarting the daemon thread to refresh tokens in background for process with pid = 79  <br \/>\nTraceback (most recent call last):  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_invoker.py&quot;, line 7, in &lt;module&gt;  <br \/>\nexecute(sys.argv)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_host_executor.py&quot;, line 41, in execute  <br \/>\nreturn execute_with_cli(original_args)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/core\/logger.py&quot;, line 209, in wrapper  <br \/>\nret = func(*args, **kwargs)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_host_executor.py&quot;, line 52, in execute_with_cli  <br \/>\ndo_execute_with_env(parser, FolderRuntimeEnv())  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_host_executor.py&quot;, line 68, in do_execute_with_env  <br \/>\nmodule_statistics_folder=parser.module_statistics_folder  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 397, in exec  <br \/>\nself._handle_exception(bex)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 471, in _handle_exception  <br \/>\nraise exception  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 379, in exec  <br \/>\noutput_tuple = self._entry.func(**reflected_input_ports, **reflected_parameters)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py&quot;, line 76, in wrapper  <br \/>\nret = func(*args, **validated_args)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 57, in run  <br \/>\noutput_values = EvaluateModelModule.evaluate_generic(**input_values)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 168, in evaluate_generic  <br \/>\ncls._validate_input(scored_data=scored_data, scored_data_to_compare=scored_data_to_compare)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 146, in _validate_input  <br \/>\ndataset_name=cls._args.scored_data.friendly_name)  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/evaluate\/evaluate_generic_module\/evaluate_generic_module.py&quot;, line 133, in _validate_data_table  <br \/>\nerror_setting.ErrorMapping.throw(error_setting.NotLabeledDatasetError(dataset_name=dataset_name))  <br \/>\nFile &quot;\/azureml-envs\/azureml_27ff1befbcbf963c2543a3994cfbad97\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py&quot;, line 821, in throw  <br \/>\nraise err  <br \/>\nazureml.studio.common.error.NotLabeledDatasetError: There is no label column in &quot;Scored dataset&quot;.<\/p>\n<p>[2021-03-25T14:48:31.272570] Finished context manager injector with Exception.  <br \/>\n2021\/03\/25 14:48:32 Could not parse control script error at path: \/mnt\/batch\/tasks\/workitems\/335323a5-4a6b-472a-8676-f079f4b45127\/job-1\/7230c4b5-94a5-4af9-b_d7e8588d-bb39-4e7e-b730-1d9bc350919b\/wd\/runTaskLetTask_error.json because: File \/mnt\/batch\/tasks\/workitems\/335323a5-4a6b-472a-8676-f079f4b45127\/job-1\/7230c4b5-94a5-4af9-b_d7e8588d-bb39-4e7e-b730-1d9bc350919b\/wd\/runTaskLetTask_error.json doesn't exist, continuing without  <br \/>\n2021\/03\/25 14:48:32 Failed to run the wrapper cmd with err: exit status 1  <br \/>\n2021\/03\/25 14:48:32 Attempt 1 of http call to <a href=\"http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status\">http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status<\/a>  <br \/>\n2021\/03\/25 14:48:32 mpirun version string: {  <br \/>\nIntel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)  <br \/>\nCopyright 2003-2018 Intel Corporation.  <br \/>\n}  <br \/>\n2021\/03\/25 14:48:32 MPI publisher: intel ; version: 2018  <br \/>\n2021\/03\/25 14:48:32 Not exporting to RunHistory as the exporter is either stopped or there is no data.  <br \/>\nStopped: false  <br \/>\nOriginalData: 2  <br \/>\nFilteredData: 0.  <br \/>\n2021\/03\/25 14:48:32 Process Exiting with Code: 1<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Data Labelling - Zoom broken on prelabelled tasks??",
        "Question_created_time":1616185580847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/323305\/azure-machine-learning-data-labelling-zoom-broken",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My dataset now has enough samples to start pre-labeling a set of labels (bounding boxes for image identification).  <\/p>\n<p>However, rather worryingly this seems fundamentally broken?   <br \/>\nWe appear to have lost the ability to zoom the image (zoom just appears to zoom the bounding boxes, and not the underlying image) which basically makes this entire functionality useless.  <\/p>\n<p>Am I missing something or is this feature completely broken?  <br \/>\nI hope the former, as the pre-labeling was a significant factor in choosing this platform.  <\/p>\n<p>We have tried multiple browsers in case this was a browser issue but to no success, they all present the same issue.  <\/p>\n<p>Is anyone able to advise??  <\/p>",
        "Question_closed_time":1616398055640,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=06d543d4-352b-4f24-bd0a-512b74834f7c\">@ChrisH  <\/a> Thanks for the question. Can you please share image and snapshot for the same. We are able to zoom the underlying image using the <a href=\"http:\/\/ml.azure.com\">data labeling<\/a>.     <br \/>\n<img src=\"\/answers\/storage\/temp\/80116-image.png\" alt=\"80116-image.png\" \/>    <br \/>\nPlease follow the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-label-images#tag-images-and-specify-bounding-boxes-for-object-detection\">doc<\/a> to Tag images and specify bounding boxes for object detection.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Conda environment locked by another AzureML job",
        "Question_created_time":1611713493223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/246501\/conda-environment-locked-by-another-azureml-job",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I tried to run an experiments. There was an error in my first submit and the run did not go through. However, a lock has been created which is preventing me from submitting further runs. I am getting the following error.  <\/p>\n<p>&quot;The conda environment is currently locked by another AzureML job. Further job submission will wait until the other process finishes. If there are no other jobs running, please delete \/home\/azureuser\/.azureml\/locks\/azureml_conda_lock&quot;  <\/p>\n<p>I tried to use:  <br \/>\naz ml run cancel -r exp_id  <\/p>\n<p>in CLI. However, this gives me an error:  <br \/>\nError, default experiment not set and experiment name parameter not provided.\\nPlease provide a value for the experiment name parameter.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does ML Studio\/Designer\/AutoML support Natural Language Processing?",
        "Question_created_time":1615905694633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/316809\/does-ml-studio-designer-automl-support-natural-lan",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_body":"<p>Hey everyone,  <br \/>\nI think Microsoft doesn't explicitly state this anywhere so I was wondering if I can create models (via AutoML or via the manual designer) using datasets containing text in natural language (such as a couple sentences, paragraphs etc.). AutoML doesn't really indicate that it can process paragraphs using NLP anywhere.  <br \/>\nThere are Text Analytics features in the designer and I heard about Azure AutoML's BERT support so I suppose it should be possible but I just wanted to make sure.  <br \/>\nRight now I can upload such dataset and create a classification model based on it but I don't know if it treats these cells containing paragraphs just as one long string and doesn't do anything or if it actually processes the individual words etc.  <br \/>\nCould anyone let me know, please? And if it does support NLP, what can I do besides classification? Can it do sentiment analysis, entity extraction etc.?  <\/p>\n<p>Thanks a lot!  <\/p>\n<p>(I don't see a tag for AutoML or the designer, that's why I tagged the classic Studio.)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Services - AutoMl - Error running experiment.submit: \"\/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\"",
        "Question_created_time":1616170731780,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/322886\/azure-machine-learning-services-automl-error-runni",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,<\/p>\n<p>I created a notebook in the workspace and when I sent the experiment for training I received error message <strong>undefined symbol: XGDMatrixSetDenseInfo<\/strong> for algorithm <strong>Xgboost<\/strong>. Do you know how to fix the problem?<\/p>\n<p><strong>Azure ML Version:<\/strong> 1.22.0  <br \/>\n<strong>Compute Instance:<\/strong> Standard_DS3_v2<\/p>\n<ul>\n<li> Code:  import logging  <br \/>\n  from azureml.train.automl import AutoMLConfig  <br \/>\n  from azureml.core.experiment import Experiment  automl_settings = {  <br \/>\n  &quot;iteration_timeout_minutes&quot;: 10,  <br \/>\n  &quot;experiment_timeout_hours&quot;: 0.3,  <br \/>\n  &quot;enable_early_stopping&quot;: True,  <br \/>\n  &quot;primary_metric&quot;: 'normalized_root_mean_squared_error',  <br \/>\n  &quot;featurization&quot;: 'auto',  <br \/>\n  &quot;verbosity&quot;: logging.INFO,  <br \/>\n  &quot;n_cross_validations&quot;: 5  <br \/>\n  }  automl_config = AutoMLConfig(task='regression',  <br \/>\n  debug_log='automated_ml_errors.log',  <br \/>\n  training_data=x_train,  <br \/>\n  label_column_name=&quot;production_time&quot;,  <br \/>\n  **automl_settings)  experiment = Experiment(ws, &quot;train-model&quot;)  <br \/>\n  local_run = experiment.submit(automl_config, show_output=True)<\/li>\n<li> Full Error Message:  ERROR: FitException:  <br \/>\n  Message: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo  <br \/>\n  InnerException: AttributeError: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo  <br \/>\n  ErrorResponse  <br \/>\n  {  <br \/>\n  &quot;error&quot;: {  <br \/>\n  &quot;code&quot;: &quot;SystemError&quot;,  <br \/>\n  &quot;message&quot;: &quot;Encountered an internal AutoML error. Error Message\/Code: FitException. Additional Info: FitException:\\n\\tMessage: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n \\&quot;error\\&quot;: {\\n \\&quot;message\\&quot;: \\&quot;\/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\\&quot;,\\n \\&quot;target\\&quot;: \\&quot;Xgboost\\&quot;,\\n \\&quot;reference_code\\&quot;: \\&quot;Xgboost\\&quot;\\n }\\n}&quot;,  <br \/>\n  &quot;details_uri&quot;: &quot;https:\/\/learn.microsoft.com\/azure\/machine-learning\/resource-known-issues#automated-machine-learning&quot;,  <br \/>\n  &quot;target&quot;: &quot;Xgboost&quot;,  <br \/>\n  &quot;inner_error&quot;: {  <br \/>\n  &quot;code&quot;: &quot;ClientError&quot;,  <br \/>\n  &quot;inner_error&quot;: {  <br \/>\n  &quot;code&quot;: &quot;AutoMLInternal&quot;  <br \/>\n  }  <br \/>\n  },  <br \/>\n  &quot;reference_code&quot;: &quot;Xgboost&quot;  <br \/>\n  }  <br \/>\n  }<\/li>\n<\/ul>\n<p>Best regards,  <br \/>\nCristina<\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/79658-packages.txt?platform=QnA\">79658-packages.txt<\/a><\/p>",
        "Question_closed_time":1616196599997,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hi, can you try uninstalling and reinstalling Xgboost (try versions &lt;= 0.90 if you continue to get errors).<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AZURE ML - Web Service",
        "Question_created_time":1616267169727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/323764\/azure-ml-web-service",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<ul>\n<li> How to configure the input fields with drop down values from the experiment. Eg: if car make is a field, the input field for the car make should start showing options when you start entering.    <\/li>\n<li> List item    <\/li>\n<\/ul>\n<p>In the below example, fuel field should show drop down values like, diesel, petrol etc. ![79842-image.png][1] [1]: \/api\/attachments\/79842-image.png?platform=QnA     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"web app model deployment",
        "Question_created_time":1616240230297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/323724\/web-app-model-deployment",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am deploying my prediction model as web app for first time in Azure through github actions step.    <br \/>\nI can see the deployment process is successful in github actions window. When I browse my app from azure window, it is not connecting to my web app. There is some issue. but the app is up &amp; running.    <\/p>\n<p>my subscription id - 06facb88-7723-4e1e-82cd-774f082c46d5    <\/p>\n<p>Attached is the sample images.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Secure Azure Machine Learning REST Endpoints (deployed in ACI) with TLS",
        "Question_created_time":1615991231360,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/318807\/secure-azure-machine-learning-rest-endpoints-(depl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>We have developed and deployed machine learning models in AML Studio. The models were deployed using ACI and we have REST endpoints that we can make calls to successfully. Next thing that I need to do is to secure the endpoints using TLS. I am going through the following article:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable<\/a>    <\/p>\n<p>The article suggests that I need to get a domain and then update our DNS point to the IP address of scoring endpoint. I have a subdomain  ready to use but as for the IP address, I can't work out where I would get the IP address of the scoring endpoint and how I would even be able to map this to the endpoint as the current endpoint do not contain and IP address and look nothing like the example in the article.    <\/p>\n<p>URIs currently look like the following:    <br \/>\n<a href=\"http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score\">http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score<\/a>    <\/p>\n<p>Anyone able to help with this one please as it's a little confusing and I can't find any guidance online anywhere?<\/p>",
        "Question_closed_time":1616038303613,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Hello,<\/p>\n<p>You can do it according to DNS.<\/p>\n<p>A \u201cURL\u201d is a full specification to a page. For example:<\/p>\n<p><a href=\"http:\/\/example.com\/this_is_example.html\">http:\/\/example.com\/this_is_example.html<\/a> is a URL. It has three parts:<\/p>\n<p>The protocol specifier: http:<\/p>\n<p>The domain name: example.com<\/p>\n<p>The page location: \/this_is_example.html<\/p>\n<p>The protocol specifies the port that will be used. http, for example, is  <br \/>\nport 80. ftp uses ports 20 and 21. SMTP, the mail sending protocol, is usually  <br \/>\non port 25. You can actually find the full list of \u201cofficial\u201d ports here.<\/p>\n<p>It\u2019s only the domain name that has an IP address associated with it. So that\u2019s what you would be looking up.<\/p>\n<p>My approach is to use the \u201cping\u201d command in a Windows command prompt. For  <br \/>\nexample:<\/p>\n<p>C:\\&gt;ping example.com<\/p>\n<p>Then you can get it.<\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Data Import error for Azure table storage to Azure ML studio ?",
        "Question_created_time":1616070530733,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/320696\/data-import-error-for-azure-table-storage-to-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>I tried connecting to Azure table storage in Azure ML Studio. It shows connection successful after updating all credentials but after hitting run, import is landing to internal system error.  <br \/>\nBelow is the message :  <br \/>\n[Critical]     Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.  <\/p>\n<p>Requesting you to please assist in this case.  <\/p>\n<p>Regards,  <br \/>\nSachin<\/p>",
        "Question_closed_time":1616395982957,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>There is a known issue that Azure ML Studio only supports \u201chttp\u201d protocol when connecting with Azure Storage Account. You might hit this issue when using the Import Data module.    <\/p>\n<p>Here is a quick work around:    <br \/>\nPlease check the \u201cConfiguration\u201d of your Storage Account, and make sure the \u201cSecure transfer required\u201d is disabled (see the figure below).    <\/p>\n<p>If still encountering error after taking these steps, please double check and make sure the account key is correct.    <\/p>\n<p><a href=\"\/users\/na\/?userid=520e72bc-f33a-4fa2-84f8-4795fd5f44af\">@Sachin Gaikwad  <\/a> Please accept the answer if you feel the work around works. Thank you!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/80028-image.png?platform=QnA\" alt=\"80028-image.png\" \/>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to creata a compute instance",
        "Question_created_time":1616247083753,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/323742\/unable-to-creata-a-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to follow the steps given here - <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data<\/a>    <\/p>\n<p>I've tried regions east us2 and east us for creating the instance but it fails after taking more than half an hour. I tried virtual machine sizes - Standard_DS11_v2 &amp; Standard_DS3_v2.    <\/p>\n<p>Any help would be appreciated.     <\/p>\n<p>Edit - I don't have any other instances running in my subscription, so it should not be a quota issue. The error message says &quot;An internal server error occurred.&quot;.<\/p>",
        "Question_closed_time":1616282059877,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Good day <a href=\"\/users\/na\/?userid=79ab735d-44c2-44c3-954b-5a6233041e68\">@Aatish Suman  <\/a>      <\/p>\n<p>Did you read the comment in the compute page?    <\/p>\n<p>Please confirm that you are using an account which fit the limitations    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/79891-image.png?platform=QnA\" alt=\"79891-image.png\" \/>    <\/p>\n<p>For more information please check this post:    <\/p>\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/\">https:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/<\/a>    <\/p>\n<p>Note: I followed the tutorial which you provided the link to and it is working well for me. Therefore, I assume the issue is related to the above comment.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AML Tutorials on Docs.Microsoft",
        "Question_created_time":1616289490963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/324003\/aml-tutorials-on-docs-microsoft",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>These tutorial files are out of sync on the docs vs. the notebooks? Is this intentional? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't create a VM in compute - Creation failed",
        "Question_created_time":1615983139490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/318685\/cant-create-a-vm-in-compute-creation-failed",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi    <br \/>\nI am unable to create a VM in Compute. Status is at Creating for an hour and then it fails.     <br \/>\nI tried several times without luck.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/78763-image.png?platform=QnA\" alt=\"78763-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/78781-image.png?platform=QnA\" alt=\"78781-image.png\" \/>    <\/p>\n<p>Does anyone know how to solve this?<\/p>",
        "Question_closed_time":1616052673920,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I was able to delete all the failed VMs and create one today.  <br \/>\nThe solution in this case was to wait it out.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"The request failed with status code: 502 error while consuming the model deployed",
        "Question_created_time":1615982217267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/318618\/the-request-failed-with-status-code-502-error-whil",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have deployed an ML model trained with combining CSVs through dataset. When I try to consume the model REST endpoint through python. I get 502 error. In score.py, I predicted by using the dataset in the workspace as I need to use Count vectorizer. Below is my score.py code for your reference.  <\/p>\n<pre><code>def init():\n    global model\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), &quot;prediction-model.pickle&quot;)\n    model = joblib.load(model_path)\n\n\ndef run(data):\n    try:\n        data = json.loads(data)['data']\n        print(data)\n        workspace = Workspace.get(name=&quot;xxx&quot;, subscription_id='xxx',\n                                  resource_group='xxx')\n        dataset_name = 'prediction_ds'\n        prediction_ds = Dataset.get_by_name(workspace=workspace, name=dataset_name)\n        df = prediction_ds.to_pandas_dataframe()\n        df = df[pd.notnull(df['DESCRIPTION'])]\n        df = df[pd.notnull(df['CUSTOMERCODE'])]\n        col = ['CUSTOMERCODE', 'DESCRIPTION']\n        df = df[col]\n        df.columns = ['CUSTOMERCODE', 'DESCRIPTION']\n        df['category_id'] = df['DESCRIPTION'].factorize()[0]\n        df = df.applymap(str)\n        X_train, X_test, y_train, y_test = train_test_split(df['CUSTOMERCODE'], df['DESCRIPTION'], random_state=0)\n        count_vect = CountVectorizer()\n        count_vect.fit_transform(X_train)\n        predicted_result = model.predict(count_vect.transform(data))\n        return predicted_result.tolist()\n    except Exception as e:\n        print(&quot;exception occured&quot;)\n        error = str(e)\n        print(error)\n        logging.info(error)\n        return error\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retrieve Notebooks Azure Files",
        "Question_created_time":1615959743450,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/317875\/retrieve-notebooks-azure-files",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to retrieve notebooks that were hosted on notebooks.azure.com? If so, how? The service is now discontinued but I would like to retrieve files that were hosted on the service.<\/p>",
        "Question_closed_time":1615975649020,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=e2b81f66-f91b-46e3-964b-29275f3216c7\">@Sean  <\/a> I am afraid that the option to retrieve this data is not possible. Please refer this <a href=\"https:\/\/github.com\/microsoft\/AzureNotebooks\/issues\/838\">thread<\/a> for information and the options that were available before the last day to migrate them. Thanks!!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Compute Instances List is not displaying any of my previously create instance",
        "Question_created_time":1615936137423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/317533\/compute-instances-list-is-not-displaying-any-of-my",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Compute Instances List is not displaying any of my previously create instance  <\/p>\n<p>when i log in and go to the machine learning studio and click on the link it display an error.  <\/p>\n<p>Its like the list is timing out  <\/p>\n<p>I have tried this on multiple machines   <\/p>\n<p>error  <\/p>\n<p> 'Failed to load computes Your request for data wasn\u2019t sent. Here are some things to try: Check your network and internet connection, make sure a proxy server is not blocking your connection, follow our guidelines if you\u2019re using a private link, and check if you have AdBlock turned on. Trace ID : 6c0087da-5c17-4aea-814b-59d8292caa5b Client request ID : fa33bb7f-d4dd-4975-a538-cb119b7a2d64 ' <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MS Azure Machine Learning: MemoryError: Unable to allocate 5.43 GiB for an array with shape (23847, 30582) and data type int64",
        "Question_created_time":1615935222203,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/317531\/ms-azure-machine-learning-memoryerror-unable-to-al",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to extract pixel values from a raster image using xarray module.  I tried to &quot;stack&quot; the coordinates to get a third dimension but I end up getting the error above.  I create a compute instance of 56GB RAM so I was wondering why the 5.43 GiB, I would have expected going beyond 56GB but the values seems off.  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"R script error on Azure machine learning (Error 1000)",
        "Question_created_time":1615375884937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/307755\/r-script-error-on-azure-machine-learning-(error-10",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_body":"<p>When I try to connect my data source to the &quot;Execute R script&quot; then I run the experiment, the experiment does not run and I get this error message &quot;Execute R Script Error  <br \/>\nRPackage library exception: Attempting to obtain R output before invoking execution process . ( Error 1000 )&quot;  <\/p>\n<p>Please advice me how to solve this error and In general how to connect my datasets on Azure machine learning for D365 demand forecasting.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Model data output",
        "Question_created_time":1615488109277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/310400\/ml-model-data-output",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,<\/p>\n<p>I was running several time series model using Azure automated machine learning, I didn't write any code. After the running was completed, there are some datasets stored in Azure Blob Storage. But I don't know if these files include the prediction results or not because I can't find a right software to open it . I don't need to deploy the model. I just need a plain spreadsheet which contains the result. Why it is so hard? The attachment is the screenshot of the fiels stored in Blob of the model I ran? What do those files mean?  <br \/>\nAnd I just check the running outcome, it shows there is no output dataset. I was so confused! Do I need to change something when I set the model running?  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/76887-image.png?platform=QnA\" alt=\"![76837-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/76887-image.png?platform=QnA\">1<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Program on VM automatically crash after long idle",
        "Question_created_time":1615873089030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/315909\/program-on-vm-automatically-crash-after-long-idle",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <\/p>\n<p>I am training machine learning model on Azure VM with NC6 promo GPU. Everything was fine at the beginning, but after a while I went back to check and realized my training program was stopped. Also, I got this message &quot;client_loop: send disconnect: Broken pipe&quot;. Is there any solution for this problem since it cost me a lot of time and money.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can we append data to an existing csv file stored in Azure blob storage?",
        "Question_created_time":1615437989000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/308980\/can-we-append-data-to-an-existing-csv-file-stored",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a machine learning model deployed in azure designer studio. I need to retrain it everyday with new data through python code. I need to keep the existing csv data in the blob storage and also add some more data to the existing csv and retrain it. If I retrain the model with only the new data, the old data is lost so I need to retrain the model by appending new data to existing data. Is there any way to do it through python coding?  <\/p>\n<p>I have also researched about append blob but they add only in the end of the blob. In the documentation, they have mentioned we cannot update or add to an existing blob.   <\/p>\n<p>Any help is appreciated. Thanks a lot.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automate machine learning model on Azure portal failed",
        "Question_created_time":1614327752400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/290347\/automate-machine-learning-model-on-azure-portal-fa",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>User is not authorized to query provided resources due to s2s call not providing any active baggage to verify role-based access.  <\/p>",
        "Question_closed_time":1614577233697,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>No update yet.  <\/p>\n<p>I have been receiving emails from Microsoft that they will disable my account for going against their policy.   <\/p>\n<p>Reason was because I am frequently using the Azure platform.  <\/p>\n<p>I decided to take a break from the platform to avoid them deleting my account.  <\/p>\n<p>Don't know what to do \ud83d\ude2d next<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Can an Azure ML model be updated via Power BI ?",
        "Question_created_time":1615461194467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/309851\/can-an-azure-ml-model-be-updated-via-power-bi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi everyone,     <\/p>\n<p>I developed a model in Azure ML Studio and consume it in Power BI. To do so, I followed <a href=\"https:\/\/learn.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate\">this<\/a> tutorial.     <br \/>\nAnd now, I would like to empower my final user to update by herself the model by giving it additional data through Power BI. I can consider other solutions than Power BI, given that it is user friendly. My train set is a csv file, I do not use data base for this project.     <\/p>\n<p>Thank you for your help, and your ideas!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"help me fix error 0085",
        "Question_created_time":1615644585240,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/312960\/help-me-fix-error-0085",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Error 0085: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nCaught exception while executing function: Traceback (most recent call last):  <br \/>\nFile &quot;C:\\server\\invokepy.py&quot;, line 199, in batch  <br \/>\nodfs = mod.azureml_main(*idfs)  <br \/>\nFile &quot;C:\\temp\\dcc32c6db61a425eb482bb3deadd6e41.py&quot;, line 25, in azureml_main  <br \/>\ndataset.columns = ['sentiment', 'tweets']  <br \/>\nFile &quot;C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py&quot;, line 2682, in <strong>setattr<\/strong>  <br \/>\nreturn object.<strong>setattr<\/strong>(self, name, value)  <br \/>\nFile &quot;pandas\\src\\properties.pyx&quot;, line 65, in pandas.lib.AxisProperty.<strong>set<\/strong> (pandas\\lib.c:45018)  <br \/>\nFile &quot;C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py&quot;, line 425, in _set_axis  <br \/>\nself._data.set_axis(axis, labels)  <br \/>\nFile &quot;C:\\pyhome\\lib\\site-packages\\pandas\\core\\internals.py&quot;, line 2578, in set_axis  <br \/>\n(old_len, new_len))  <br \/>\nValueError: Length mismatch: Expected axis has 3 elements, new values have 2 elements  <br \/>\nProcess returned with non-zero exit code 1<\/p>\n<p>---------- End of error message from Python interpreter ----------  <br \/>\nStart time: UTC 03\/13\/2021 14:06:38  <br \/>\nEnd time: UTC 03\/13\/2021 14:07:11<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"update real interference pipeline",
        "Question_created_time":1615298736310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/305899\/update-real-interference-pipeline",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I deployed my Training pipeline and my Real-time inference pipeline.  <br \/>\nWith the REST-Api of my training pipeline I'm able to retrain my ML model. Is it possible to use that retrained model automated in my real inference pipeline?  <br \/>\nWhen i trigger the pipeline in ML studio I have to update my real inference pipeline manually. Since I want to trigger my retraining external that is not possible.  <br \/>\nThanks in advance.<\/p>",
        "Question_closed_time":1615579149187,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, here's a reference on which <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines#which-azure-pipeline-technology-should-i-use\">technology<\/a> to use based on a given scenario. For your scenario, you should be able to create an Azure Machine Learning pipeline using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline\">SDK to trigger a pipeline<\/a> based on a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#create-a-schedule\">time\/change based schedule<\/a> and then <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update the web service<\/a> accordingly. Depending on the complexity of your triggers or data prep needs, you can leverage other technologies such as <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#use-azure-logic-apps-for-complex-triggers\">Logic Apps<\/a> or <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#call-machine-learning-pipelines-from-azure-data-factory-pipelines\">Azure Data Factory<\/a> to trigger your Azure Machine Learning pipeline. Currently, you can only use the Azure Machine Learning SDK to automatically update the web service. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to use a model trained by Azure AutoML",
        "Question_created_time":1614822360083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/297882\/how-to-use-a-model-trained-by-azure-automl",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <br \/>\nI've trained a classification model using Azure AutoML. In the &quot;Output&quot; folder of the best model page I can see these files:  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74033-image.png?platform=QnA\" alt=\"![![74035-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74033-image.png?platform=QnA\">1<\/a>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74033-image.png?platform=QnA\">1<\/a><\/p>\n<p><strong>1<\/strong>- How should I use this model to predict new observations. I want to do this on Azure Machine Learning Studio, so no need to deploy it as a web service or take it to a local computer as a pickle file.<\/p>\n<p><strong>2<\/strong>- I saw a few examples where people downloading their model as a PKL file and loading and running it to get predictions. I tried it by using the following code:<\/p>\n<pre><code>import pickle  \nPkl_Filename = &quot;testPickle.pkl&quot;  \nwith open(Pkl_Filename, 'rb') as file:    \n    Pickled_LR_Model = pickle.load(file)  \nPickled_LR_Model  \n<\/code><\/pre>\n<p><strong>and got the below error:<\/strong><\/p>\n<p>ModuleNotFoundError Traceback (most recent call last)  <br \/>\n&lt;ipython-input-14-1e47995f2929&gt; in &lt;module&gt;  <br \/>\n2 Pkl_Filename = &quot;testPickle.pkl&quot;  <br \/>\n3 with open(Pkl_Filename, 'rb') as file:  <br \/>\n----&gt; 4 Pickled_LR_Model = pickle.load(file)  <br \/>\n5  <br \/>\n6 Pickled_LR_Model<\/p>\n<p>ModuleNotFoundError: No module named 'azureml.automl.runtime._ml_engine.featurizer_suggestion'<\/p>\n<p>Also used the <em>joblib<\/em> library to load the model and got the same error. Please help me with detailed step-by-step instructions (including scripts) if it is possible. I'm new to Azure Machine Learning Studio.<\/p>",
        "Question_closed_time":1615407389617,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I fixed this problem by creating a new compute instance and using it to load the pickle file. Sounds strange but it seems this error happens due to a mismatch between the azureml sdk on the jupyter instance and on the compute instance.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Using a plain text to create a data dictionary in Machine Learning Studio",
        "Question_created_time":1614531976997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/292155\/using-a-plain-text-to-create-a-data-dictionary-in",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I am new for Machine Learning Studio, and have a small project. I have one txt file, see the attach, and I would like to create a data dictionary by using the Machine Learning Studio. The data dictionary template check the image. ![72703-data-dictionary-templete.png][1] [72704-est17-pa.txt][2] Where am I going to start? Thanks. [1]: \/api\/attachments\/72703-data-dictionary-templete.png?platform=QnA [2]: \/api\/attachments\/72704-est17-pa.txt?platform=QnA <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Lost access to machine learning studio webservices. Cannot access already existing ones, nor depoy new ones.",
        "Question_created_time":1615306897887,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/306150\/lost-access-to-machine-learning-studio-webservices",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I've been working with machine learning studio webservices for over a year now, and have never had any trouble with the webservices. Suddenly me and a few colleagues have lost access to them. We can still create experiments, but when we try to deploy them we get the following error:  <\/p>\n<p>&quot;Web Service deployment failed. This account does not have sufficient access to the Azure subscription that contains the Workspace. In order to deploy a Web Service to Azure, the same account must be invited to the Workspace and be given access to the Azure subscription that contains the Workspace.&quot;  <\/p>\n<p>When trying to access an already existing one, we get this:  <\/p>\n<p>&quot;The Azure Subscription could not be accessed. This issue is most likely due the user account not having sufficient access claims to the Azure Subscription.&quot;  <\/p>\n<p>In regards to my access to the workspace\/subscription, I have a contributor role, and as far as I'm aware thats always been my role.  <\/p>\n<p>What possible other access shall I need to keep on working the the webservices?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine learning job stuck on queued and then cancelled",
        "Question_created_time":1614676942043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/294828\/machine-learning-job-stuck-on-queued-and-then-canc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a job which I set to run last night, only to find out it was queued for over 2 hours and eventually cancelled (not by me).  <\/p>\n<p>This morning, my machine learning run is again, stuck on queued.  <\/p>\n<p>Is there any way to fix this? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.",
        "Question_created_time":1615209277803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/303859\/image-build-failed-for-more-details-check-log-file",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <\/p>\n<p>When we wanted to get an explanation of a model, we received following error. &quot;Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.&quot;    <\/p>\n<p>You can find the log file attached.    <\/p>\n<p>I would appreciate if you could help us to resolve the issue. The model is very successful. It is important for us. Thus, we would like to understand it better with the explanation.    <\/p>\n<p>Thank you very much in advance for your interest and support!    <\/p>\n<p>Best regards,    <\/p>\n<p>Cagatay Topcu<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/75409-20-image-build-log.pdf?platform=QnA\">75409-20-image-build-log.pdf<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cross Validation",
        "Question_created_time":1612476102827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/259529\/cross-validation",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello, I am getting an error when training a model with Cross validation.   <\/p>\n<p>requestId = 511f53ca6e0d4bdd991ece1e5c34a62b errorComponent=Module. taskStatusCode=500. {&quot;Exception&quot;:{&quot;ErrorId&quot;:&quot;InternalError&quot;,&quot;ErrorCode&quot;:&quot;0000&quot;,&quot;ExceptionType&quot;:&quot;ModuleException&quot;,&quot;Message&quot;:&quot;Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.&quot;,&quot;Exception&quot;:{&quot;ExceptionType&quot;:&quot;Exception&quot;,&quot;Message&quot;:&quot;Exception has been thrown by the target of an invocation.&quot;,&quot;Exception&quot;:{&quot;ExceptionType&quot;:&quot;Exception&quot;,&quot;Message&quot;:&quot;Right hand side shape must match region being assigned to&quot;}}}}Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you. Process exited with error code -2  <\/p>\n<p>Url adress:  <\/p>\n<p><a href=\"https:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/9a8580b8f8e2410bba1214d24539753c?#Workspaces\/Experiments\/Experiment\/9a8580b8f8e2410bba1214d24539753c.f-id.f8dc50a742e04a0fa02c13cd730ef124\/ViewExperiment\">https:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/9a8580b8f8e2410bba1214d24539753c?#Workspaces\/Experiments\/Experiment\/9a8580b8f8e2410bba1214d24539753c.f-id.f8dc50a742e04a0fa02c13cd730ef124\/ViewExperiment<\/a>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure automated ml Error: Run timed out.",
        "Question_created_time":1614109931990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/285527\/azure-automated-ml-error-run-timed-out",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>I got the below error while trying to run an experiment that uses automated machine learning to train a regression model. ![71149-azure-ml-errorcapture.png][1]    <\/p>\n<p>I followed the MS Learn setting here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/use-auto-ml\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/use-auto-ml<\/a>.     <\/p>\n<p>I tried increasing the Training job time from 0.25 to 0.5 and it still failed. Thanks for any direction. [1]: \/api\/attachments\/71149-azure-ml-errorcapture.png?platform=QnA <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"export trained model in MS Azure designer",
        "Question_created_time":1613562176760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/276752\/export-trained-model-in-ms-azure-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>how to export trained model in MS Azure designer in onnx format?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Notebooks: how to access data from an experiment",
        "Question_created_time":1614762558803,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/296661\/azureml-notebooks-how-to-access-data-from-an-exper",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am new to Azure ML, and I have been trying to replicate the same structure presented in the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-train-models-with-aml\">MNIST tutorial<\/a>, but I don't understand how to adapt it to my case.     <\/p>\n<p>I am running a python file from the experiment, but I don't understand how I can access data that is currently in a folder in the cloud file system from the script running in the experiment.     <br \/>\nI have found many examples about accessing one single .csv file, but my data is made of many images.    <\/p>\n<p>From my understanding I should first load the folder to a datastore, then use Dataset.File.upload_directory to create a dataset containing my folder, and here is how I tried to do it:     <\/p>\n<pre><code># Create dataset from data directory  \ndatastore = Datastore.get(ws, 'workspaceblobstore')  \ndataset = Dataset.File.upload_directory(path_data, target, pattern=None, overwrite=False, show_progress=True)  \n  \nfile_dataset = dataset.register(workspace=ws, name='reduced_classification_dataset',  \n                                                 description='reduced_classification_dataset',  \n                                                 create_new_version=True)  \n<\/code><\/pre>\n<p>But then I don't understand if and how I can access this data like a normal file system from my python script, or I need further steps to be able to do that.     <\/p>",
        "Question_closed_time":1614833313090,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=bf39b622-b8af-42d8-809c-296225cdbb39\">@Matzof  <\/a> Thanks for the question. Please follow the below code for writing.    <\/p>\n<pre><code>   datastore = ## get your defined in Workspace as Datastore   \ndatastore.upload(src_dir='.\/files\/to\/copy\/...',  \n                 target_path='target\/directory',  \n                 overwrite=True)  \n<\/code><\/pre>\n<p>Datastore.upload only support blob and fileshare. For adlsgen2 upload, you can try our new dataset upload API:    <\/p>\n<pre><code>from azureml.core import Dataset, Datastore  \ndatastore = Datastore.get(workspace, 'mayadlsgen2')  \nDataset.File.upload_directory(src_dir='.\/data', target=(datastore,'data'))  \n<\/code><\/pre>\n<p>Pandas is integrated with fsspec which provides Pythonic implementation for filesystems including s3, gcs, and Azure. You can check the source for Azure here: <a href=\"https:\/\/github.com\/dask\/adlfs\">dask\/adlfs: fsspec-compatible Azure Datake and Azure Blob Storage access (github.com)<\/a>. With this you can use normal filesystem operations like ls, glob, info, etc.     <\/p>\n<p>You can find an example (for reading data) here: <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/tutorials\/using-dask\/1.intro-to-dask.ipynb\">azureml-examples\/1.intro-to-dask.ipynb at main \u00b7 Azure\/azureml-examples (github.com)<\/a>     <\/p>\n<p>Writing is essentially the same as reading, you need to switch the protocol to abfs (or az), slightly modify how you're accessing the data, and provide credentials unless your blob has public write access.     <\/p>\n<p>You can use the Azure ML Datastore to retrieve credentials like this (taken from example):     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74112-2.png?platform=QnA\" alt=\"74112-2.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Excel en Microsoft Azure",
        "Question_created_time":1614968855700,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/301247\/excel-en-microsoft-azure",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hola a todos, perdon quiza sea muy basica mi pregunta, no se como importar un excel como Dataset. Solo puedo importar CSV, etc. Muchas gracias<\/p>",
        "Question_closed_time":1614974319960,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, thanks for reaching out. Excel is not a <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py\">supported format<\/a> for Azure ML Tabular datasets. I recommend that you convert your excel file to .csv file (save as .csv) before importing to Azure ML. Hope this helps!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Missing principal component analysis module in Azure ML Designer",
        "Question_created_time":1614943157500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/300776\/missing-principal-component-analysis-module-in-azu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I cannot find the Principal Component module in Azure ml designer. For the classic ML studio version it used to be under the data transformation group of transformations but seems to be no longer there. Am I missing something? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"predict() missing 1 required positional argument: 'X' while consuming a deployed web service through python in azure",
        "Question_created_time":1614169733667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/286859\/predict()-missing-1-required-positional-argument-x",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>I'm trying to consume a web service that I deployed and I get  predict() missing 1 required positional argument: 'X' error. Here is a link for reference about m previous question: <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/282967\/error-while-consuming-the-deployed-web-service-thr.html\">error-while-consuming-the-deployed-web-service-thr.html<\/a>    <\/p>\n<p>Here is my train.py file    <\/p>\n<blockquote>\n<p>df = pd.read_csv('prediction_data01.csv')    <br \/>\ndf = df[pd.notnull(df['DESCRIPTION'])]    <br \/>\ndf = df[pd.notnull(df['CUSTOMERCODE'])]    <br \/>\ncol = ['CUSTOMERCODE', 'DESCRIPTION']    <br \/>\ndf = df[col]    <br \/>\ndf.columns = ['CUSTOMERCODE', 'DESCRIPTION']    <br \/>\ndf['category_id'] = df['DESCRIPTION'].factorize()[0]    <\/p>\n<p>tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 4), stop_words='english')    <br \/>\nfeatures = tfidf.fit_transform(df.DESCRIPTION).toarray()    <br \/>\nlabels = df.category_id    <\/p>\n<p>df = df.applymap(str)    <br \/>\nX_train, X_test, y_train, y_test = train_test_split(df['CUSTOMERCODE'], df['DESCRIPTION'], random_state=0)    <br \/>\ncount_vect = CountVectorizer()    <br \/>\nX_train_counts = count_vect.fit_transform(X_train)    <br \/>\ntfidf_transformer = TfidfTransformer()    <br \/>\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)    <\/p>\n<p>clf = MultinomialNB().fit(X_train_tfidf, y_train)    <br \/>\nos.makedirs(&quot;.\/outputs&quot;, exist_ok=True)    <br \/>\njoblib.dump(clf, 'prediction-model.pickle')    <\/p>\n<\/blockquote>\n<p>Here is my score.py file:    <\/p>\n<blockquote>\n<p>def init():    <br \/>\n    global model    <br \/>\n    # AZUREML_MODEL_DIR is an environment variable created during deployment.    <br \/>\n    # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)    <br \/>\n    # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)    <br \/>\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), &quot;prediction-model.pickle&quot;)    <br \/>\n    model = joblib.load(model_path)    <\/p>\n<p>def run(raw_data):    <br \/>\n    data = np.array(json.loads(raw_data)['data'])    <br \/>\n    # make prediction    <br \/>\n    y_hat = model.predict(data)    <br \/>\n    # you can return any data type as long as it is JSON-serializable    <br \/>\n    return y_hat.tolist()    <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Errors",
        "Question_created_time":1614300692297,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/289691\/azure-machine-learning-errors",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, I am trying to run some of the sample notebooks from Microsoft Learn for Azure Machine Learning. I am running into the following error and cannot find a workaround though this appears to be a common error that others have also encountered with no workaround. cannot import name 'AzureMLAggregatedException' from 'azureml.exceptions'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to open successfully a terminal in jupyter notebook",
        "Question_created_time":1614840049767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/298197\/how-to-open-successfully-a-terminal-in-jupyter-not",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,     <\/p>\n<p>Opening a terminal from jupyter notebook created in the compute resource is failing with the following error:     <\/p>\n<p>failed: Error during WebSocket handshake: Unexpected response code: 426 make_terminal @ terminado.js:4 index.js:5     <br \/>\nUncaught TypeError: Cannot read property 'parentElement' of undefined at proposeGeometry (index.js:5) at fit (index.js:30) at Terminal.terminalConstructor.fit (index.js:44) at window.onresize (main.js:54)     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74147-azure-error-1-terminal.png?platform=QnA\" alt=\"74147-azure-error-1-terminal.png\" \/>    <\/p>\n<p> I have deleted and created again the compute instance with the following characteristics:     <br \/>\n<strong>Attributes<\/strong>     <br \/>\nCompute name: veracruz     <br \/>\nCompute type: Compute instance     <br \/>\nSubscription ID: 7aa3fe31-0364-453e-bd8f-ff5c11be8727     <br \/>\nResource group: machine-learning-cgi     <br \/>\nWorkspace: ml-practice-2021 Region: eastus2     <br \/>\nCreated by: Reyes Lopez, Arturo     <\/p>\n<p>Steps to reproduce: The compute instance is running:     <\/p>\n<p>When clicking on Jupyter and selecting New-&gt; Terminal getting the mentioned error above in Google Chrome and Microsoft Edge browsers:     <\/p>\n<p>What can be the issue when opening the terminal from jupyter notebook? The issue is when following this steps after the creation of compute resource: <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data#clone-the-ml-basics-repository\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data#clone-the-ml-basics-repository<\/a>     <\/p>\n<p>Thanks     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Anaconda commercial use on Azure Data Science Virtual Machine",
        "Question_created_time":1614757334137,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/296502\/anaconda-commercial-use-on-azure-data-science-virt",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I would like to know if there is any problem in terms of license if enterprise companies use Anaconda that is preinstalled in Azure Data Science Virtual Machine. In another inquiry, I saw an answer that Anaconda included in Azure Machine Learning service has no problem in terms of the license but I would like to confirm whether DSVM also has a problem or not. <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html<\/a><\/p>",
        "Question_closed_time":1614766234917,
        "Answer_score_count":0.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=6672f5df-879d-4960-a974-87ca328f8861\">@Kenta  <\/a> The thread referenced by a user was in a different context who wanted to check if they had to subscribe to commercial license to use Azure ML. In the case of DSVM where anaconda packages are installed they are still configured to use open source packages irrespective of the subscription that spins them up. So, you can definitely use the DSVM for your purposes and configure any license's that were acquired to enhance your usage experience with the tools that have been pre-installed. Thanks!!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Importing Data in Azure ML Studio Experiment",
        "Question_created_time":1614362680897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/291213\/importing-data-in-azure-ml-studio-experiment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I\u2019m having an issue importing the data into my Machine Learning Studio. It shows me a Red Cross with the error 0030 - which means that there\u2019s an issue in downloading the data. For background, I\u2019m importing data from the Web URL via HTTP option. I looked up the issue on the troubleshooting page, followed the advice, which shows I\u2019ve done everything correctly. My data link works perfectly fine in my browser. When I enter the http link into my browser, it immediately downloads the csv file. However, my studio is not downloading the data. Importing the data is the first step in my experiment, and I can\u2019t move forward without it. Immediate help would be greatly appreciated! I\u2019ve attached pictures for reference. [1]: \/api\/attachments\/72499-0ebb78a4-4805-46e8-a7f1-fbf99682af5f.png?platform=QnA <\/p>",
        "Question_closed_time":1614759574360,
        "Answer_score_count":0.0,
        "Answer_comment_count":7.0,
        "Answer_body":"<p>Hello,  <\/p>\n<p>This exception in Azure Machine Learning occurs when it is not possible to download a file. You will receive this exception when an attempted read from an HTTP source has failed after three (3) retry attempts.  <\/p>\n<p>Resolution: Verify that the URI to the HTTP source is correct and that the site is currently accessible via the Internet.  <\/p>\n<p>Is this file on any place need authentication?   <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Framing API for Azure Workspace Experiments Runs",
        "Question_created_time":1612790580067,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/263728\/framing-api-for-azure-workspace-experiments-runs",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi there,    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest<\/a>    <\/p>\n<p>As explained in the doc here, could you help me to frame the API URL to fetch all the runs of an experiment of a workspace.     <\/p>\n<p>Thanks,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Jupyter Notebook not running as fast as expected?",
        "Question_created_time":1614288658810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/289526\/jupyter-notebook-not-running-as-fast-as-expected",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,<\/p>\n<p>I have recently started using Azure because I need to run a very demanding piece of code on Jupyter Notebook. I am attempting to run the notebooks by creating a workspace via Azure Machine Learning<\/p>\n<p>I have obtained quotas for High Performance Computing but still, the time required to run my code is the same as it is with my laptop. My laptop isn't the greatest so I suspect there's either something wrong with my connectivity or the way I set up the notebook. Is it enough to just connect to a compute instance or do I need to set up an environment at the very top?<\/p>\n<p>EDIT: The device I am using is a Standard_HB60rs with 60 cores, 223.52GB RAM and 700GB Storage which costs $2.28\/hour. I am importing a package that is used for simulations of quantum mechanical systems called qutip.<\/p>\n<h1 id=\"installing-qutip\">Installing Qutip<\/h1>\n<p>conda install numpy scipy cython matplotlib nose jupyter notebook spyder<\/p>\n<p>conda config --append channels conda-forge<\/p>\n<p>conda install qutip<\/p>\n<h1 id=\"the-installation-seems-to-be-working-as-i-have-been-able-to-run-the-next-cells-which-use-the-package\">The installation seems to be working as I have been able to run the next cells which use the package.<\/h1>\n<h1 id=\"cell-1-where-i-import-all-necessary-packages\">Cell 1 where I import all necessary packages<\/h1>\n<p>%matplotlib notebook<\/p>\n<p>import copy  <br \/>\nimport numpy as np  <br \/>\nimport math  <br \/>\nimport matplotlib.pyplot as plt  <br \/>\nfrom qutip.qip.noise import RandomNoise<\/p>\n<p>pi = np.pi<\/p>\n<p>from qutip.qip.device import Processor  <br \/>\nfrom qutip.operators import sigmaz, sigmay, sigmax, destroy  <br \/>\nfrom qutip.states import basis  <br \/>\nfrom qutip.metrics import fidelity  <br \/>\nfrom qutip.qip.operations import rx, ry, rz, hadamard_transform<\/p>\n<p>hbar = 1.0545718 * (10**-34) #in Js  <br \/>\nh = hbar * 2 * np.pi #in Js  <br \/>\neV = 1.60217662 * (10**-19)  <br \/>\nh_eV = 6.58 * (10**-22)*(10**6) #h in eVs<\/p>\n<h1 id=\"cell-2\">Cell 2<\/h1>\n<p>processor = Processor(N=1) #this command builds a 2-level quantum mechanical system<\/p>\n<h1 id=\"parameters-for-some-of-the-functions-that-will-be-used\">parameters for some of the functions that will be used<\/h1>\n<p>Delta = (2*(10<strong>9)) * (h) #in Joules  <br \/>\nDelta_2 = ((Delta\/(h)) * 2 * pi)\/(10<\/strong>13) #in Hz units<\/p>\n<p>processor.add_control((0.5*Delta_2*sigmax()), targets=0, label=&quot;sigmaz&quot;) #Hamiltonian of the system<\/p>\n<h1 id=\"cell-3-here-i-drive-my-system-from-its-ground-state-to-a-superposed-state\">Cell 3. Here, I drive my system from its ground state to a superposed state.<\/h1>\n<p>w_min = (pi\/2\/Delta_2)*(10**-2)  <br \/>\nw_max = (pi\/2\/Delta_2)  <br \/>\nstep = 0.01<\/p>\n<p>tpoints = np.linspace(w_min,w_max,123)<\/p>\n<p>basis0 = basis(2,0)<\/p>\n<p>final_states = []<\/p>\n<p>for t in tpoints:  <br \/>\ntlist = np.linspace(0,t,1000)  <br \/>\nprocessor.pulses[0].coeff = np.array([1 for t in tlist])  <br \/>\nprocessor.pulses[0].tlist = tlist  <br \/>\nresult = processor.run_state(init_state=basis0)  <br \/>\nfinal_states.append(result.states[-1])<\/p>\n<p>The Physics of the matter isn't the matter here. I know the code does what it is supposed to do; the remaining of the code includes various loops which do similar computations. The code in #cell 3 would usually take between 10-20 seconds to run on my laptop. I was surprised to see that it would take the same time on Azure.<\/p>\n<p>Hope this is a bit more clear<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while consuming the deployed web service through python",
        "Question_created_time":1613996362460,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/282967\/error-while-consuming-the-deployed-web-service-thr",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have tried consuming the web service with python with the link <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python\">how-to-consume-web-service<\/a>. I'm getting an error<\/p>\n<blockquote>\n<p>predict() missing 1 required positional argument: 'X'<\/p>\n<\/blockquote>\n<p>I have trained the model to predict only one field &quot; DESCRIPTION&quot; and two input fields &quot;CUSTOMERCODE&quot;, &quot;DESCRIPTION&quot;<\/p>\n<p>when I try to predict with input data with the code below:<\/p>\n<blockquote>\n<p>import requests  <br \/>\nimport json<\/p>\n<h1 id=\"url-for-the-web-service\">URL for the web service<\/h1>\n<p>scoring_uri = 'xxx'<\/p>\n<h1 id=\"if-the-service-is-authenticated-set-the-key-or-token\">If the service is authenticated, set the key or token<\/h1>\n<p>key = 'xxx'<\/p>\n<h1 id=\"two-sets-of-data-to-score-so-we-get-two-results-back\">Two sets of data to score, so we get two results back<\/h1>\n<p>data = {&quot;data&quot;:  <br \/>\n[  <br \/>\n[  <br \/>\n&quot;10000&quot;,  <br \/>\n&quot;CAPPUCINO&quot;  <br \/>\n],  <br \/>\n[  <br \/>\n&quot;12345&quot;,  <br \/>\n&quot;CAFFINE&quot;  <br \/>\n]  <br \/>\n]  <br \/>\n}  <br \/>\ninput_data = json.dumps(data)  <br \/>\nheaders = {'Content-Type': 'application\/json'}  <br \/>\nheaders['Authorization'] = f'Bearer {key}'  <br \/>\nresp = requests.post(scoring_uri, input_data, headers=headers)  <br \/>\nprint(resp.text)<\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I open the automated ML explanation in Jupyter notebooks?",
        "Question_created_time":1614091964233,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/285089\/how-can-i-open-the-automated-ml-explanation-in-jup",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>What-If and Individual Conditional Expectation (ICE) plots are not supported in Azure Machine Learning studio under the Explanations tab since the uploaded explanation needs an active compute to recalculate predictions and probabilities of perturbed features. It is currently supported in Jupyter notebooks when run as a widget using the SDK. How can I open the automated ML explanation in Jupyter notebooks?<\/p>",
        "Question_closed_time":1614614318550,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello Cagatay,<\/p>\n<p>In jupyter notebook for AutoML models, you can download the trained model, then compute explanations locally and visualize the explanation results using ExplanationDashboard from interpret-community. Sample code below:-<\/p>\n<pre><code>best_run, fitted_model = remote_run.get_output()\n\nfrom azureml.train.automl.runtime.automl_explain_utilities import AutoMLExplainerSetupClass, automl_setup_model_explanations\nautoml_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train,\n                                                                                                                         X_test=X_test, y=y_train,\n                                                                                                                         task='regression')\n\nfrom interpret.ext.glassbox import LGBMExplainableModel\nfrom azureml.interpret.mimic_wrapper import MimicWrapper\nexplainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel,\n                         init_dataset=automl_explainer_setup_obj.X_transform, run=best_run,\n                         features=automl_explainer_setup_obj.engineered_feature_names,\n                         feature_maps=[automl_explainer_setup_obj.feature_map],\n                         classes=automl_explainer_setup_obj.classes)\n\npip install interpret-community[visualization]\n\nengineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\nprint(engineered_explanations.get_feature_importance_dict()),\nfrom interpret_community.widget import ExplanationDashboard\nExplanationDashboard(engineered_explanations, automl_explainer_setup_obj.automl_estimator, datasetX=automl_explainer_setup_obj.X_test_transform)\n\nraw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n                                     raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n                                     eval_dataset=automl_explainer_setup_obj.X_test_transform)\nprint(raw_explanations.get_feature_importance_dict()),\nfrom interpret_community.widget import ExplanationDashboard\nExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, datasetX=automl_explainer_setup_obj.X_test_raw)\n<\/code><\/pre>\n<p>The code sample repo please refer to: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/scoring-time\/train-explain-model-locally-and-deploy.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/scoring-time\/train-explain-model-locally-and-deploy.ipynb<\/a><\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"When Analyzing using Explanations is it possible to unselect the first value?",
        "Question_created_time":1614091600373,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/285095\/when-analyzing-using-explanations-is-it-possible-t",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>When working with Azure Machine Learning AutoML I am unable to unselect the first value in the list when trying to create a new cohort using Explanations. For example in the below I am unable to unselect Female if I wish to only see how a factor affected the Male demographic. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/71212-capture.png?platform=QnA\" alt=\"71212-capture.png\" \/>    <\/p>\n<p>Is there a way to unselect this value?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - Deployed to Inference Cluster throws 500 Server Error - MissingFeaturesError",
        "Question_created_time":1614113525043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/285607\/azure-ml-deployed-to-inference-cluster-throws-500",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>We have an Azure ML model we are ready to deploy to an http endpoint for consumption and testing.    <\/p>\n<p>We are using this tutorial (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy<\/a>) as the jumping off point for deploying our ml model. We have created an inference cluster, converted the training model to a real-time inference model and deployed. Deployment looks successful. However, when testing (both via the Test tab in the Azure ML Workspace and via http POST) the server throws a 500. The MissingFeaturesError follows:    <\/p>\n<blockquote>\n<p>File &quot;\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/common\/base_learner.py&quot;, line 289, in _validate_no_missing_feature    <br \/>\n    ErrorMapping.throw(MissingFeaturesError(required_feature_name=';'.join(missing_feature_list)))    <br \/>\n      &gt; missing_feature_list = ['Miles', 'Age', 'Gender', 'MarriagetPlans']    <\/p>\n<p>  File &quot;\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py&quot;, line 814, in throw    <br \/>\n    raise err    <br \/>\n      &gt; err = MissingFeaturesError('Features for Miles;Age;Gender;MarriagetPlans required but not provided.',)    <\/p>\n<p>  MissingFeaturesError: Features for Miles;Age;Gender;MarriagetPlans required but not provided.    <\/p>\n<\/blockquote>\n<p>In both test cases (via Test tab in Azure and http POST to the endpoint) all the required data is indeed provided. The request body definitely includes Miles, Age, Gender, MarriagetPlans.    <\/p>\n<p>What is going on here?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use private Python packages with Azure Machine Learning - PAT Auth",
        "Question_created_time":1614263822737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/288955\/use-private-python-packages-with-azure-machine-lea",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am trying to deploy a model on an AKS cluster in Azure Machine Learning that uses a Python package that is present as a package in a feed on Azure DevOps.     <br \/>\nI found the following article that explains how to do this:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-private-python-packages\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-private-python-packages<\/a>    <\/p>\n<p>In the example it shows that in the Worspace.set_connection method, it passes a string as &quot;value&quot;.     <br \/>\nIf I try to do the same in my code the following error appears:    <\/p>\n<p>azureml._base_sdk_common.workspace.models.machine_learning_service_error.MachineLearningServiceErrorException: (ValidationError) JSON format is expected for Properties.Value    <\/p>\n<p>Looking at the documentation  (<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#set-connection-name--category--target--authtype--value-\">azureml.core.workspace.workspace<\/a>) it actually says that it expects a JSON:     <br \/>\nvalue: the json format serialization string of the connection details)    <\/p>\n<p>What format and what information should this JSON contain?    <\/p>\n<p>Thanks,    <br \/>\nG.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning: Update Realtime endpoint",
        "Question_created_time":1611847882743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/249335\/azure-machine-learning-update-realtime-endpoint",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,<\/p>\n<p>I've deployed an endpoint in Azure ML with the command &quot;az ml model deploy&quot; and it has created an realtime endpoint (in my case based on AKS cluster type).<\/p>\n<p>Now I want to update this endpoint, because for example I want to change some configuration or code in the score.py. If I try to relaunch the same command above with the option --overwrite, it prints an error regarding the unavailabilty of CPU and memory, even though their configuration is the same as the previous deployment.<\/p>\n<p>{'Azure-cli-ml Version': '1.20.0', 'Error': WebserviceException:  <br \/>\nMessage: Deployment request failed due to insufficient compute resource. For the specified compute target, 1 replica cannot be created per specified CPU\/Memory configuration(3 CPU Cores, 20GB Memory). You can address this problem by adjusting number of replicas, using a different CPU\/memory configuration, or using a different compute target.  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Deployment request failed due to insufficient compute resource. For the specified compute target, 1 replica cannot be created per specified CPU\/Memory configuration(3 CPU Cores, 20GB Memory). You can address this problem by adjusting number of replicas, using a different CPU\/memory configuration, or using a different compute target.&quot;  <br \/>\n}  <br \/>\n}}<\/p>\n<p>I therefore think that it is not overwriting the endpoint, but creating a parallel environment.<\/p>\n<p>I also tried to create a new version of the endpoint with the commands &quot;az ml endpoint realtime create-version&quot; and &quot;az ml endpoint realtime update-version&quot;, but in this case it always tells me that it doesn't find the endpoint I'm trying to update (despite with the command &quot;list&quot; it finds me exactly my endpoint).<\/p>\n<p>Error Message:<\/p>\n<p>{  <br \/>\n&quot;Azure-cli-ml Version&quot;: &quot;1.20.0&quot;,  <br \/>\n&quot;Error&quot;: {  <br \/>\n&quot;Error&quot;: &quot;Error, no service\/endpoint with name &lt;endpoint-name&gt; found in workspace &lt;workspace-name&gt; in resource group &lt;resource-group-name&gt; of type aksendpoint.&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>So, how can I overwrite my endpoint? I hope there is a better solution than manually deleting the endpoint each time and recreating it.<\/p>\n<p>Thank you very much,<\/p>\n<p>G.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to train TensorFlow pretrained Object Detection model in AzureML?",
        "Question_created_time":1612228828727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/254691\/how-to-train-tensorflow-pretrained-object-detectio",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have a problem to do custom TensorFlow2 Object Detection in AzureML (see <a href=\"https:\/\/www.tensorflow.org\/hub\/tutorials\/tf2_object_detection\">https:\/\/www.tensorflow.org\/hub\/tutorials\/tf2_object_detection<\/a>). I failed to install the API with error message as follow:  <br \/>\nobject_detection\/protos\/calibration.proto:41:3: Expected &quot;required&quot;, &quot;optional&quot;, or &quot;repeated&quot;.  <br \/>\nobject_detection\/protos\/calibration.proto:41:6: Expected field name.  <br \/>\nobject_detection\/protos\/calibration.proto:53:3: Expected &quot;required&quot;, &quot;optional&quot;, or &quot;repeated&quot;.  <br \/>\nobject_detection\/protos\/calibration.proto:53:6: Expected field name.  <br \/>\nERROR: Could not install packages due to an EnvironmentError: [('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/gpu-notebook\/code\/Users\/mengoon.lee\/models\/research\/a3c_blogpost\/a3c_cartpole.py',  <br \/>\nPlease help me. Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"'str' object has no attribute 'items'",
        "Question_created_time":1613362872313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/272689\/str-object-has-no-attribute-items",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I'm trying to consume a model that I deployed from Azure Machine Learning as a web service but I keep getting an error: <code>'str' object has no attribute 'items'     Help: https:\/\/go.microsoft.com\/fwlink\/?linkid=2146748<\/code>.    <\/p>\n<p>I am following the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal\">Consume an Azure Machine Learning model deployed as a web service tutorial<\/a> for calling the service using python.    <\/p>\n<p>I followed the formatting <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal#call-the-service-python\">as shown in the documentation<\/a> but I still keep getting this error.    <\/p>\n<pre><code>import requests  \nimport json  \n  \n# URL for the web service  \nscoring_uri = 'http:\/\/00.00.00.00:00\/api\/v1\/service\/test\/score'  \n# If the service is authenticated, set the key or token  \n  \n  \n# Two sets of data to score, so we get two results back  \ndata = {&quot;data&quot;:  \n        [  \n            {'volume': 0.23,   \n             'temp': 0.66, }  \n        ]  \n        }  \n# Convert to JSON string  \ninput_data = json.dumps(data)  \nprint(input_data)  \n  \n# Set the content type  \nheaders = {'Content-Type': 'application\/json'}  \n  \n  \n# Make the request and display the response  \nresp = requests.post(scoring_uri, input_data, headers=headers)  \nprint(resp.text)  \n<\/code><\/pre>\n<p>Any ideas would be great, thanks!    <\/p>\n<p>UPDATE:    <br \/>\nScoring script:    <\/p>\n<pre><code>import os  \nimport json  \n  \nfrom azureml.studio.core.io.model_directory import ModelDirectory  \nfrom pathlib import Path  \nfrom azureml.studio.modules.ml.score.score_generic_module.score_generic_module import ScoreModelModule  \nfrom azureml.designer.serving.dagengine.converter import create_dfd_from_dict  \nfrom collections import defaultdict  \nfrom azureml.designer.serving.dagengine.utils import decode_nan  \nfrom azureml.studio.common.datatable.data_table import DataTable  \n  \n  \nmodel_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'trained_model_outputs')  \nschema_file_path = Path(model_path) \/ '_schema.json'  \nwith open(schema_file_path) as fp:  \n    schema_data = json.load(fp)  \n  \n  \ndef init():  \n    global model  \n    model = ModelDirectory.load(model_path).model  \n  \n  \ndef run(data):  \n    data = json.loads(data)  \n    input_entry = defaultdict(list)  \n    for row in data:  \n        for key, val in row.items():  \n            input_entry[key].append(decode_nan(val))  \n  \n    data_frame_directory = create_dfd_from_dict(input_entry, schema_data)  \n    score_module = ScoreModelModule()  \n    result, = score_module.run(  \n        learner=model,  \n        test_data=DataTable.from_dfd(data_frame_directory),  \n        append_or_result_only=True)  \n    return json.dumps({&quot;result&quot;: result.data_frame.values.tolist()})  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is There a Way to Visualize the Decision Tree AML Used?",
        "Question_created_time":1612898717163,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265984\/is-there-a-way-to-visualize-the-decision-tree-aml",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have used a Two-Class Boosted Decision Tree in Azure ML to make some predictions on data that I am analyzing. Once the model has completed training is there a way for me to visualize the structure of the decision tree that was ultimately used by Azure?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Auto ML forecasting - dependent variables",
        "Question_created_time":1613448096113,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/274229\/azure-auto-ml-forecasting-dependent-variables",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I am trying to use Azure auto ML for forecasting. The dataset has a date_time column, a target variable and other columns that affect the target variable. I have deployed the model as a web service. But I am finding it hard to use the service\/model for forecasting future frames. Let's say I need to forecast for the next 4 hours (data frequency is 5 minutes), but the model is asking for other column inputs as well.  Can you please help me to resolve this?   <br \/>\nTIA,  <br \/>\nRajesh<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error - WebApp Implementation with Principal Component Analysis(PCA)",
        "Question_created_time":1613865635337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/281600\/error-webapp-implementation-with-principal-compone",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>After applying Principal Component Analysis PCA to my data set in order to achieve better model accuracy. The 13 features dimensions, I am reducing it to 10 features using PCA. Everything is fine till here.    <\/p>\n<p>After implementing the model in WebApp, it is building &amp; seems fine in the studio.    <\/p>\n<p>In the testing phase of model prediction, Instead of displaying 10 features as an input, the UI system is showing the original features which is 13 &amp; the output is showing 10 featu<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/70351-01.pdf?platform=QnA\">70351-01.pdf<\/a>res which does not have any feature names for the newly generated features which are 10. And also prediction is not working at all after executing it.\\    <\/p>\n<p>Attached are the screenshots, Please refer.    <\/p>",
        "Question_closed_time":1613976829527,
        "Answer_score_count":0.0,
        "Answer_comment_count":7.0,
        "Answer_body":"<p>@RakshitSidd-7739 After updating and running the training experiment did you try to update the prediction experiment.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/70512-image.png?platform=QnA\" alt=\"70512-image.png\" \/>    <\/p>\n<p>After the prediction experiment is updated you can update the web service and check if it shows up correctly.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Fastai error running experiment on Azure ML",
        "Question_created_time":1613753712050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/280802\/fastai-error-running-experiment-on-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hello everybody,  <br \/>\nI\u2019m working with Fastai (V. 2.1.7) on Azure Machine Learning (Azure ML) and I\u2019m having an issue.  <\/p>\n<p>If I train a model directly in the notebook, everything looks ok.  <br \/>\nWhen I try to run exactly the same python code into an experiment I get the following error.  <\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;train.py&quot;, line 75, in &lt;module&gt;\n    learn.fit_one_cycle(8, 3e-3)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/callback\/schedule.py&quot;, line 112, in fit_one_cycle\n    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 205, in fit\n    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 154, in _with_events\n    try:       self(f'before_{event_type}')       ;f()\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 196, in _do_fit\n    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 154, in _with_events\n    try:       self(f'before_{event_type}')       ;f()\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 190, in _do_epoch\n    self._do_epoch_train()\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 182, in _do_epoch_train\n    self._with_events(self.all_batches, 'train', CancelTrainException)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 154, in _with_events\n    try:       self(f'before_{event_type}')       ;f()\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py&quot;, line 160, in all_batches\n    for o in enumerate(self.dl): self.one_batch(*o)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/data\/load.py&quot;, line 103, in __iter__\n    yield self.after_batch(b)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastcore\/transform.py&quot;, line 198, in __call__\n    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastcore\/transform.py&quot;, line 150, in compose_tfms\n    x = f(x, **kwargs)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py&quot;, line 34, in __call__\n    self.before_call(b, split_idx=split_idx)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py&quot;, line 377, in before_call\n    self.do,self.mat = True,self._get_affine_mat(b)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py&quot;, line 388, in _get_affine_mat\n    aff_m = _init_mat(x)\n  File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py&quot;, line 286, in _init_mat\n    mat = torch.eye(3, device=x.device).float()\nAttributeError: 'list' object has no attribute 'device'\n<\/code><\/pre>\n<p>Have you ever experienced the same issue?  <br \/>\nDo you have any idea about it?  <br \/>\nThanks a lot  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute instance showing cross against starting",
        "Question_created_time":1613826664207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/281408\/compute-instance-showing-cross-against-starting",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to start a compute instance on ML studio and the starting process has been running for a while now. Previously while running it showed a green status symbol while starting now it is showing red cross and it does not seem to be starting.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/70263-image.png?platform=QnA\" alt=\"70263-image.png\" \/>    <\/p>\n<p>When I am trying to create a new compute I get the below error    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/70283-image.png?platform=QnA\" alt=\"70283-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Python visual in Power BI for calling ML Azure rest API works in desktop version but not when published",
        "Question_created_time":1613593697693,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/277404\/using-python-visual-in-power-bi-for-calling-ml-azu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I created a dashboard in Power BI desktop. I have a trained model from ML Azure which I already deployed and has it's rest API. I need to call this rest API from the dashboard itself using measures I created (not from the query editor). I did it using the Python visual to send the input data and get back the output from the rest API and plotting the result (a number). This works perfectly in the desktop version. I need to publish this dashboard to share with other members of my organization but in the web version the script gives a runtime error. ![69200-capture.png][1] How to make it work? [1]: \/api\/attachments\/69200-capture.png?platform=QnA<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to implment the Azure ML model in the .NET Core web service",
        "Question_created_time":1613442662890,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/274165\/how-to-implment-the-azure-ml-model-in-the-net-core",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/68337-image.png?platform=QnA\" alt=\"![68337-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/68337-image.png?platform=QnA\">1<\/a><\/p>\n<p>I want to run this model on the website. The website is running now but I do not know how can I put models on.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MLOps For Python with R code",
        "Question_created_time":1613119407860,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/270615\/mlops-for-python-with-r-code",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hello Azure MLOps Team,    <\/p>\n<p>I am looking at the reference architecture <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python<\/a>.    <\/p>\n<p>Most of our data science models are made in R. I am wondering, which part of the MLOps process (Azure Pipelines or Azure ML Compute\/Azure ML Pipelines) can be configured in Python for R code to run?    <\/p>\n<p>Our preference is to leverage as much Python as possible for the code R code. I see there is an Azure ML SDK for python and R. Can we use Azure ML SDK in Python with R codebase?    <\/p>\n<p>Kind regards,    <br \/>\nSlava Keshkov    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error in score.py file while deploying a machine learning model through python",
        "Question_created_time":1613655483977,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/278693\/error-in-score-py-file-while-deploying-a-machine-l",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have trained a machine learning model through python locally and I'm trying to deploy it to Azure with inference cluster. I'm able to train, upload data, register model but I'm unable to deploy the model. It's throwing path error but I have tried all the possible paths for my model. What is the correct path to the model? I have attached the error and code below for your reference. Any help is appreciated. Thanks a lot.  <\/p>\n<blockquote>\n<p>Error:   <br \/>\n&quot;code&quot;: &quot;KubernetesDeploymentFailed&quot;,  <br \/>\n&quot;statusCode&quot;: 400,  <br \/>\n&quot;message&quot;: &quot;Kubernetes Deployment failed&quot;,  <br \/>\ndetails&quot;:   <br \/>\n&quot;code&quot;: &quot;CrashLoopBackOff&quot;,  <br \/>\n&quot;message&quot;: &quot;Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models\/amlstudio-mlpredictionep01\/1\/sklearn_ml_exp', please run print(service.get_logs()) to get details.&quot;  <\/p>\n<\/blockquote>\n<p>Here is my score.py file:  <\/p>\n<blockquote>\n<p>def init():  <br \/>\n    global model  <br \/>\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_ml_exp')  <br \/>\n    model = joblib.load(model_path)  <\/p>\n<p>def run(raw_data):  <br \/>\n    data = np.array(json.loads(raw_data)['data'])  <br \/>\n    y_hat = model.predict(data)  <br \/>\n    return y_hat.tolist()  <\/p>\n<\/blockquote>\n<p>I registered the model with:  <\/p>\n<blockquote>\n<p>model = Model.register(workspace=ws,  <br \/>\n                       model_name='sklearn_ml_exp',  <br \/>\n                       model_path='outputs\/prediction-model.pickle', # local path  <br \/>\n                       description='Prediction model',  <br \/>\n                       tags={'data-format': 'CSV'},  <br \/>\n                       model_framework=Model.Framework.SCIKITLEARN,  <br \/>\n                       model_framework_version='0.20.3')  <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML error: Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.'",
        "Question_created_time":1613661513130,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/278775\/automl-error-microsoft-dprep-sharedlibrary-errorha",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm implementing a pipeline where a step involves creating and submitting an AutoML run. The issue I'm seeing occurs when the run starts &quot;ActivityStarted: StreamingFit&quot;. I've gone ahead and pasted the error trace below.     <\/p>\n<p>My best guess would be something to do with authentication to our ADLS gen 2 which houses the files for our Dataset. I've tried remaking the same Dataset under the workspace default storage and it works fine. Both the cluster and the service principal associated with the AutoML run have full blob storage access.    <\/p>\n<p>Appreciate any help on this.    <\/p>\n<p>Edit: for clarity. I have a PythonScriptStep that sets up and submits an AutoMLRun.     <\/p>\n<pre><code>2021-02-18 14:52:12.367 - INFO - ActivityStarted: StreamingFit  \nError: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' StackTrace: Elapsed time: 00:00:06.7332685  \n2021-02-18 14:52:19.361 - CRITICAL - Type: AutoMLInternal  \nClass: FitException  \nMessage: FitException:  \n Message: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.'   \n InnerException: BridgeRuntimeError: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.'   \n ErrorResponse   \n{  \n    &quot;error&quot;: {  \n        &quot;code&quot;: &quot;SystemError&quot;,  \n        &quot;message&quot;: &quot;Encountered an internal AutoML error. Error Message\/Code: FitException. Additional Info: FitException:\\n\\tMessage: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;message\\&quot;: \\&quot;Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \\&quot;,\\n        \\&quot;target\\&quot;: \\&quot;NimbusML\\&quot;,\\n        \\&quot;reference_code\\&quot;: \\&quot;NimbusML\\&quot;\\n    }\\n}&quot;,  \n        &quot;details_uri&quot;: &quot;https:\/\/learn.microsoft.com\/azure\/machine-learning\/resource-known-issues#automated-machine-learning&quot;,  \n        &quot;target&quot;: &quot;NimbusML&quot;,  \n        &quot;inner_error&quot;: {  \n            &quot;code&quot;: &quot;ClientError&quot;,  \n            &quot;inner_error&quot;: {  \n                &quot;code&quot;: &quot;AutoMLInternal&quot;  \n            }  \n        },  \n        &quot;reference_code&quot;: &quot;NimbusML&quot;  \n    }  \n}  \nTraceback:  \n  File &quot;telemetry_activity_logger.py&quot;, line 57, in _log_activity  \n    yield  \n  File &quot;streaming_featurizer.py&quot;, line 165, in learn_transformations  \n    estimator.fit(self._training_data)  \n  File &quot;streaming_estimator.py&quot;, line 70, in fit  \n    &quot;nimbus ml failed to fit during featurization at {0}&quot;.format(bre.callstack))  \n  File &quot;streaming_estimator.py&quot;, line 66, in fit  \n    self._pipeline.fit(datastream_X)  \n  File &quot;utils.py&quot;, line 220, in wrapper  \n    params = func(*args, **kwargs)  \n  File &quot;pipeline.py&quot;, line 1086, in fit  \n    raise e  \n  File &quot;pipeline.py&quot;, line 1073, in fit  \n    **params)  \n  File &quot;entrypoints.py&quot;, line 460, in run  \n    output_predictor_modelfilename)  \n  File &quot;entrypoints.py&quot;, line 315, in _try_call_bridge  \n    model=output_modelfilename)  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to change MS Learn Display Name in Microsoft Cloud Skills Challenge?",
        "Question_created_time":1610604860147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/230124\/how-to-change-ms-learn-display-name-in-microsoft-c",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Yesterday I enrolled Microsoft Cloud Skills Challenge for study.  <\/p>\n<p>But when I enroll the challenge, I did not write proper name at MS Learn Display Name blank.  <\/p>\n<p>So I want to change the MS Learn Display Name.  <\/p>\n<p>How can I do this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Personal ML workspace",
        "Question_created_time":1613672886057,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/279065\/personal-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I have an MS Azure account as part of Capita. I am interested in doing the Create Machine Learning Model course offered via MS Azure. To do this I am required to create an ML Workspace. Is it safe for me to do this? i.e. will this just be private to my user or will it be public? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azureml when deployment fails from local source directory",
        "Question_created_time":1613640050113,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/278324\/azureml-when-deployment-fails-from-local-source-di",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Running on an Azure ML Studio compute with following SDK version  <\/p>\n<p>azure 1.0.1b6.post1  <br \/>\n core 1.19.0  <br \/>\ntrain 1.19.0  <\/p>\n<p>When I attempt to deploy I get the error that '.\/models\/model1.pkl1' is not found. However when I launch python kernel from <code>\/source\/<\/code> and execute the following everything is fine:  <\/p>\n<pre><code>from score import *\ninit()\n<\/code><\/pre>\n<p>My directory looks like so:  <\/p>\n<ul>\n<li> source  \n<ul>\n<li> models\n<ul>\n<li> model1.pkl<\/li>\n<li> model2.pkl<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<\/li>\n<li> score.py  <\/li>\n<li> exceptions.csv  <\/li>\n<\/ul>\n<p>I define an InferenceConfig and deploy model as such:  <\/p>\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=2, \n                                               tags={&quot;data&quot;: &quot;qtc&quot;,  &quot;method&quot; : &quot;automl&quot;}, \n                                               description='Estimate order completion time')\n\nenv = Environment.get(ws, &quot;AzureML-AutoML&quot;).clone('qtc_automl_env')\n\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;,\n                                   environment=env, source_directory=&quot;source&quot;)\n\nservice = Model.deploy(workspace=ws, \n                       name='qtc-watchtower4-20210106', \n                       models=[], \n                       inference_config=inference_config, \n                       deployment_config=aciconfig,\n                       overwrite=True)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>What is missing from your code or documentation, or is there a new sdk that I need to update?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Autoscaling on Azure Machine Learning with R",
        "Question_created_time":1612696726743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/262211\/autoscaling-on-azure-machine-learning-with-r",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, I have a two part question.    <\/p>\n<p>I'm using Azure Machine Learning to train my model using Compute clusters.  I'm using F64s v2 VM (64 vCPU and 128 GB of RAM). To be ablo to use all the 64 cores I used the doFuture package in R adding this code before tuning:    <\/p>\n<pre><code>registerDoFuture()  \nn_cores &lt;- parallel::detectCores()  \nplan(  \n    strategy = cluster,  \n    workers = parallel::makeCluster(n_cores)  \n)  \n<\/code><\/pre>\n<p>This works on my Windows 10 machine so I though this would also work on the VM, is this correct?    <\/p>\n<p>My other question is related to the autoscaling of the Compute cluster. The cluster can scale up to three nodes, so I guess it could be 192 cores and 384 of RAM. When monitoring the cluster I was only using one node instead of all three, i.e. there was only one Busy nodes and two Unprovisioned nodes.    <br \/>\nIn the end the code failed with this error message:    <br \/>\n<strong>Error in unserialize(node$con) : **    <br \/>\n**  Failed to retrieve the value of ClusterFuture (doFuture-1) from cluster SOCKnode #1 (on \u2018localhost\u2019). The reason reported was \u2018error reading from connection\u2019<\/strong>    <\/p>\n<p>which I think means I'm out of memory, is this correct? If so, why didn't the cluster scale up to three nodes?    <\/p>\n<p>See attached screenshot where only one node is busy but two unprovisioned.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/64938-image.png?platform=QnA\" alt=\"64938-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retrain a model programmatically with python",
        "Question_created_time":1613484358493,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/275122\/retrain-a-model-programmatically-with-python",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p> I have created a Scikit-learn model with python and I have ran the experiment. Now , I need to retrain the model with new data through python but its mentioned in the documentation that we need to create a batch interference pipeline to retrain a model. If I create a batch interference pipeline, will I be able to deploy it? Any help will be appreciated. Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Stacking ML Algorithms",
        "Question_created_time":1612271654627,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/255671\/stacking-ml-algorithms",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hello, I am new to ML and stacking and I still learning. I want to design an experiment in Azure ML Studio (classic) where I use stacking to combine PCA-based anomaly detection, one-class SVM, and two-class neural network. Can I stack these three methods where I use only the Tune Model Hyperparameter instead of combining Tune Model Parameter and Train Anomaly Detection for PCA-based and one-class SVM-based anomaly detection and Train Model for the two-class neural network? Also, to train the PCA-based anomaly detection as a meta model, can I use the Train Model Hyperparameter in conjunction with the Train Anomaly detection method?  For the base models can I hyper tune parameters and then use the appropriate train model? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Update real-time webservice with the retrained endpoint or published pipeline",
        "Question_created_time":1613014495637,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/268354\/update-real-time-webservice-with-the-retrained-end",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have already tried with the documentation <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">how-to-deploy-update-web-service<\/a>. I need a detailed explanation on how to update a web service with the experiment run or pipeline endpoint. There is no clear explanation in the link. I trained the model in the designer from scratch. I need to automate the whole flow of retraining the model and updating the web service. Any help is appreciated.    <\/p>\n<p>Please answer the following questions:    <\/p>\n<ol>\n<li> How do I give the model path for a trained model from the retrained experiment or published pipeline?    <\/li>\n<li> What is the tags field that I need to mention ?    <\/li>\n<li> what is the deploy environment I need to specify?    <\/li>\n<li> What to specify in the place of score.py?    <\/li>\n<\/ol>\n<blockquote>\n<p>ws = Workspace.get(name=&quot;xxx&quot;, subscription_id='xxx, resource_group='xxx')    <br \/>\nnew_model = Model.register(model_path=&quot;azureml\\ce6116ec-cd48-4115-a567-e0eeed49f5b5\\Trained_model&quot;,    <br \/>\n                           model_name=&quot;Trained_model&quot;,    <br \/>\n                           tags=tags)    <br \/>\ndeploy_env = Environment.get(workspace=ws, name=&quot;AzureML-PyTorch-1.4-GPU&quot;, version=&quot;3&quot;)    <br \/>\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;,    <br \/>\n                                   environment=deploy_env)    <\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I deploy the run after retraining a published endpoint and consume it?",
        "Question_created_time":1612959835657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/267341\/how-do-i-deploy-the-run-after-retraining-a-publish",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created an ML model and created a real time endpoint with the model and also published the pipeline. I retrained it with a different parameter and ran the experiment. Also I have published the endpoint. Now how do I deploy it or replace it with the already created endpoint? <\/p>",
        "Question_closed_time":1612984587887,
        "Answer_score_count":0.0,
        "Answer_comment_count":5.0,
        "Answer_body":"<p>Hi, this document provides information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update a web service<\/a> that was deployed with Azure Machine Learning. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why the storage account assosiated to azure machine learning has differenent region compared ML workspace?",
        "Question_created_time":1613120096110,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/270693\/why-the-storage-account-assosiated-to-azure-machin",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created a machine learning workspace in West Europe region. But the storage account, key vault and application insights got created in East US region. All these got created by default with creation on ML workspace.  <br \/>\nSo I want to know the reason for different region and also want to move the storage account to West Europe region.<\/p>",
        "Question_closed_time":1613167744633,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, this is unusual. There's no way to move your default AML storage account to a different region. I recommend creating a new workspace or contacting <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-portal\/supportability\/how-to-create-azure-support-request\">Azure Support<\/a> to investigate further.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Missing PIL from AzureML TF 2.3 curated environment",
        "Question_created_time":1613413000850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/273860\/missing-pil-from-azureml-tf-2-3-curated-environmen",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I've been attempting to run my machine learning experiments (computer vision) on the curated environment AzureML provides, that has TensorFlow 2.3 (whose dependency should be PIL), but I keep getting an error stating that PIL is not present. Specifically, it crashed at it saying that PIL.Image cannot be imported.  <\/p>\n<p>I have run my script on my local computer without issue using the same dependencies (as saved from the curated environment). The error only seems to happen on the remote during a run.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Read\/Write from\/to Blob Storage in AzureML",
        "Question_created_time":1613410517227,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/273787\/read-write-from-to-blob-storage-in-azureml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using AzureML and I have a blob storage container, where I want read data from it and write data to it. Can I achieve that with the path that is being passed to the experiment as follows (from <a href=\"https:\/\/azure.github.io\/azureml-examples\/docs\/cheatsheet\/data\/\">here<\/a>):  <\/p>\n<pre><code>from azureml.core import Workspace\nws: Workspace = Workspace.from_config()\ncompute_target: ComputeTarget = ws.compute_targets['&lt;compute-target-name&gt;']\nds: Datastore = ws.get_default_datastore()\n\ndata_ref = ds.path('&lt;path\/on\/datastore&gt;').as_mount()\n\nconfig = ScriptRunConfig(\n    source_directory='.',\n    script='script.py',\n    arguments=[str(data_ref)],               # returns environment variable $AZUREML_DATAREFERENCE_example_data\n    compute_target=compute_target,\n)\n\nconfig.run_config.data_references[data_ref.data_reference_name] = data_ref.to_config()\n<\/code><\/pre>\n<p>If so, what is the purpose of OutputFileDatasetConfig class in the API? Is it just a convenient shortcut to the path in the container?  <\/p>\n<pre><code>from azureml.data import OutputFileDatasetConfig\n\noutput = OutputFileDatasetConfig(folder, destination=(datastore_obj, path_to_folder))\n\narguments = [output]\n<\/code><\/pre>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"R device Loading variable to data frame not complete",
        "Question_created_time":1611736150143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/246934\/r-device-loading-variable-to-data-frame-not-comple",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>This is my code  <br \/>\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,  <br \/>\nprobs=c(0, .25,.5, 0.75, 1) ) ) )<\/p>\n<h1 id=\"select-dataframe-to-be-sent-to-the-output-dataset-port\">Select data.frame to be sent to the output Dataset port<\/h1>\n<p>maml.mapOutputPort(&quot;dataset1&quot;);<\/p>\n<p>R device port (Loading variable ) show &quot;Loading variable port1...&quot;  <br \/>\n0% 25% 50% 75% 100%  <br \/>\n6319\/A16.ZDE1DWW70500009 0.270 0.5050 0.740 0.9000 1.06  <br \/>\n6319\/A17.ZDE1DWW70500009 0.300 0.3825 0.445 0.5825 0.89  <br \/>\n6319\/A18.ZDE1DWW70500009 0.470 0.4700 0.470 0.4700 0.47  <br \/>\n6320\/A01.ZDE1DWW70500009 0.330 0.3725 0.475 1.2675 1.99<\/p>\n<p>How to import this in table format for analysis<\/p>\n<p>I try to use  <br \/>\ndata.set &lt;- data.frame (  <br \/>\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,  <br \/>\nprobs=c(0, .25,.5, 0.75, 1) ) ) )  <br \/>\n)<\/p>\n<p>I get this that has not first column ( ex. 6319\/A16.ZDE1DWW70500009)  <br \/>\n0. X25. X50. X75. X100.<\/p>\n<p>0.27 0.505 0.74 0.9 1.06  <br \/>\n0.3 0.3825 0.445 0.5825 0.89  <br \/>\n0.47 0.47 0.47 0.47 0.47  <br \/>\n0.33 0.3725 0.475 1.2675 1.99  <br \/>\n0.2 0.2675 0.33 0.3925 0.52<\/p>\n<p>Please suggest me,  <br \/>\nI sorry for my english is not good.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Remote run model unable to be saved",
        "Question_created_time":1613083790957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/270011\/remote-run-model-unable-to-be-saved",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I've built models using the AutoML function and I'm trying to call the best model to deploy into production. The AutoML function ran correctly and produced the ~35 models. My goal is to pull the best model. Here is the code:  <\/p>\n<p>best_run, fitted_model = remote_run.get_output()  <br \/>\nfitted_model  <\/p>\n<p>When runnning the code, I get the following error:   <\/p>\n<p>AttributeError: 'DataTransformer' object has no attribute 'enable_dnn'  <\/p>\n<p>Any help would be much appreciated.   <\/p>",
        "Question_closed_time":1613128985603,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=f0b99777-9086-42ac-b2e2-2b069641e943\">@Bernardo Jaccoud  <\/a> Did your run configure enable_dnn i.e bert <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features#bert-integration-in-automated-ml\">settings<\/a> of automated ML? I am curious to understand what the status of your run is directly on the portal ml.azure.com?    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"unable to call Workspace class and save to variable ws, MSLearning Path module 08",
        "Question_created_time":1611691140170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/246099\/unable-to-call-workspace-class-and-save-to-variabl",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I keep getting error, running commands in Jupyter notebook.    <\/p>\n<p>import azureml.core    <br \/>\nfrom azureml.core import Workspace    <br \/>\nws = Workspace.from_config()    <br \/>\nprint('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))    <\/p>\n<p>return RED text line number = 4 # Load the workspace from the saved config file    <br \/>\n----&gt; 5 ws = Workspace.from_config()    <br \/>\nanother line in RED = --&gt; 292             resource_group=resource_group)    <\/p>\n<p>I seem to be <strong>unable to call the Workspace Class<\/strong>    <\/p>\n<p>I have tried these    <\/p>\n<ul>\n<li> print(Workspace.get('worksp_mike1')) fails with TypeError, _get_ambient_new() takes 1 positional argument but 2 were given    <\/li>\n<li> Workspace.get_details() ... return = TypeError: get_details() missing 1 required positional argument: 'self'     <\/li>\n<li> I have run this successfully = !pip install --upgrade azureml-sdk azureml-widgets    <\/li>\n<li> this also runs OK, print(&quot;SDK version:&quot;, azureml.core.VERSION) = SDK version: 1.21.0    <\/li>\n<li> I get the same ws error in previous modules....    <\/li>\n<\/ul>\n<p>this is where I am, module 08 in Jupyter, &quot;<strong>Create a Pipeline<\/strong>&quot;    <br \/>\n<a href=\"https:\/\/microsoftlearning.github.io\/mslearn-dp100\/\">https:\/\/microsoftlearning.github.io\/mslearn-dp100\/<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60644-azure-workspace-error1.jpg?platform=QnA\" alt=\"60644-azure-workspace-error1.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"standard NC6 is very slow",
        "Question_created_time":1613141409857,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/271125\/standard-nc6-is-very-slow",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I run a code on a machine with a GPU (standard NC6) (a simple Keras model)  <\/p>\n<p>I also run the same python code on google Colab for free  <\/p>\n<p>the Azure ML is extremely slow in performance compared to the Colab  <\/p>\n<p>what is the problem with my machine?  <\/p>\n<p>I'm thinking of deleting my azure account.  <br \/>\nhow can I delete it and remove my credit card?   <\/p>\n<p>(You can see how frustrated I am)  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Training Auto ML models from a Python script via Azure Functions is failing with MemoryError",
        "Question_created_time":1612783690643,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/263618\/training-auto-ml-models-from-a-python-script-via-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm trying to do the following:  <\/p>\n<ul>\n<li> I want to run an Auto ML training script in Azure Functions via a Python script.  <\/li>\n<li> I have configured a remote compute and a dataset in Azure ML that I'm using. The dataset is a 22 KB csv file.  <\/li>\n<li> When I start the experiment the script fails with a memory error complaining about the system running out of memory (see below)  <\/li>\n<li> I get the error regardless of what app service plan tier I'm using; the script isn't <strong>actually<\/strong> running out of memory based on the metrics    2021-02-08T11:11:09.395 [Error] Executed 'Functions.AutomatedAutoMLTrainerWorker' (Failed, Id=1857c033-8199-444f-8deb-b2de73d44741, Duration=73313ms)\n    Result: FailureException: MemoryError: Engine process terminated. This is most likely due to system running out of memory. Please retry with increased memory. |session_id=c2ed81b1-66b1-4dda-82b6-056b335eaec0\n    Stack:   <br \/>\n    File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 357, in _handle__invocation_requestself.__run_sync_func, invocation_id, fi.func, args)\n    File &quot;\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in runresult = self.fn(*self.args, **self.kwargs)File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 542, in __run_sync_funcreturn func(**params)\n    File &quot;\/home\/site\/wwwroot\/AutomatedAutoMLTrainerWorker\/<strong>init<\/strong>.py&quot;, line 64, in mainrun = experiment.submit(automl_config, show_output=True)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/core\/experiment.py&quot;, line 220, in submitrun = submit_func(config, self.workspace, self.name, **kwargs)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 102, in _automl_static_submitshow_output)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 214, in _start_executionautoml_run = _default_execution(experiment, settings_obj, fit_params, False, show_output)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 127, in _default_executionreturn automl_estimator.fit(**fit_params)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/_azureautomlclient.py&quot;, line 218, in fittest_data\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py&quot;, line 90, in convert_inputs_datasetreturn tuple([_convert_to_trackable_definition(dataset) for dataset in datasets])\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py&quot;, line 90, in &lt;listcomp&gt;return tuple([_convert_to_trackable_definition(dataset) for dataset in datasets])\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py&quot;, line 162, in _convert_to_trackable_definitiondefinition, trackable = _reference_dataset(dataset)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py&quot;, line 178, in _reference_datasetreturn dataset._dataflow, False\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py&quot;, line 129, in wrapperreturn func(*args, **kwargs)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/abstract_dataset.py&quot;, line 208, in _dataflowdataprep().api._datastore_helper._set_auth_type(self._registration.workspace)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 143, in _set_auth_typeget_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.DERIVED, json.dumps(auth)))\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 19, in get_engine_api_engine_api = EngineAPI()\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 69, in __init__connect_to_requests_channel()\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 56, in connect_to_requests_channelself._engine_server_secret = self.sync_host_secret(self.requests_channel.host_secret)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py&quot;, line 38, in wrapperreturn send_message_func(op_code, message, cancellation_token)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 260, in sync_host_secretresponse = self._message_channel.send_message('Engine.SyncHostSecret', message_args, cancellation_token)\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 275, in send_messageraise message['error']\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 223, in process_responsesresponse = self._read_response(caller='MultiThreadMessageChannel.process_responses')\n    File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 148, in _read_responseraise error<\/li>\n<\/ul>\n<p>My requirements.txt for the function app looks like this:<\/p>\n<pre><code>azure-functions==1.6.0\nazureml-core==1.21.0\nazureml-train-automl-client==1.21.0\nazureml-contrib-functions==1.21.0\nazure-storage-queue==12.1.5\nruamel.yaml&gt;=0.16.5\nPyJWT==1.7.1\n<\/code><\/pre>\n<p>My training script looks like this:<\/p>\n<pre><code>import logging\n\nimport azure.functions as func\nimport os\nimport tempfile\n\nimport azureml.core\nfrom azureml.core import Experiment, Workspace\nfrom azureml.core.environment import Environment\nfrom azureml.core.dataset import Dataset\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.authentication import MsiAuthentication\nfrom azureml.train.automl import AutoMLConfig\n\n\ndef main(msg: func.QueueMessage) -&gt; None:\n    tenant_id = os.getenv(&quot;TenantId&quot;)\n    resource_group = os.getenv(&quot;AzureMLResourceGroup&quot;)\n    workspace_name = os.getenv(&quot;AzureMLWorkspace&quot;)\n    compute_name = os.getenv(&quot;AzureMLComputeName&quot;)\n    dataset_name = os.getenv(&quot;AzureMLDataSetName&quot;)\n    dataset_label_column = os.getenv(&quot;AzureMLDataSetLabelColumn&quot;)\n    experiment_name = os.getenv(&quot;AzureMLExperimentName&quot;)\n\n    msi_auth = MsiAuthentication()\n    ws = Workspace(subscription_id=tenant_id,\n               resource_group=resource_group,\n               workspace_name=workspace_name,\n               auth=msi_auth)\n\n    compute_target = ws.compute_targets[compute_name]\n\n    dataset = Dataset.get_by_name(workspace=ws, name=dataset_name)\n\n    tempFilePath = tempfile.gettempdir() + '\/debug.log'\n    automl_config = AutoMLConfig(task='regression',\n                                   experiment_timeout_minutes=60,\n                                   primary_metric='normalized_root_mean_squared_error',\n                                   training_data=dataset,\n                                   compute_target=compute_target,\n                                   label_column_name=dataset_label_column,\n                                   debug_log=tempFilePath)\n\n    experiment = Experiment(ws, experiment_name)\n\n    run = experiment.submit(automl_config, show_output=True)\n    run.wait_for_completion()\n<\/code><\/pre>\n<p>Does anyone have a clue what might be going wrong? :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I have created an ML model and retrained it manually in the designer. While updating the web service, its asking for a score.py file. How do I prepare the score.py file for a model that I have created through designer?",
        "Question_created_time":1613025843247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/268585\/i-have-created-an-ml-model-and-retrained-it-manual",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have trained a model , deployed and retrained completely through azure designer pipeline. Now , I need to update the existing web service with the new one after retraining. Its asking for a score.py file in the inference_config (python sdk). How do I prepare a score.py file for an existing model? Any help is appreciated. Thanks a lot :)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning (and cognitive services) is not supported in Region \"Germany\"?",
        "Question_created_time":1612860215177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265151\/azure-machine-learning-(and-cognitive-services)-is",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm working for a campany located in Germany. We want to use Azure Machine Learning (and other stuff like that).   <br \/>\nWe are only allowed to use Azure in the Region &quot;Germany&quot;, because the data of our customers cannot left germany.  <\/p>\n<p>Now I saw, that a lot of stuff in Azure Machine Learning is not available in Germany?  <\/p>\n<p>Questions:  <\/p>\n<ol>\n<li> Is that true?  <\/li>\n<li> Does some one now, at what time Microsoft plans to make the stuff available in Germany?  <\/li>\n<\/ol>\n<p>Thank you for a answer!  <\/p>\n<p>Patrick  <\/p>",
        "Question_closed_time":1612862196647,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=1d5d0740-76fa-4574-b01a-5fcee1ddf5b1\">@Patrick Huber  <\/a>     <br \/>\nYes, Azure Machine Learning is not available in Germany region.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/65687-image.png?platform=QnA\" alt=\"65687-image.png\" \/>    <\/p>\n<p><a href=\"https:\/\/feedback.azure.com\/forums\/34192--general-feedback\">Please check in Azure feedback<\/a>    <\/p>\n<p>If the Answer is helpful, please click <code>Accept Answer<\/code> and <strong>up-vote<\/strong>, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml'",
        "Question_created_time":1609112074090,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/211503\/modulenotfounderror-no-module-named-azureml",
        "Question_score_count":4,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am doing the Challenge. <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/intro-to-azure-machine-learning-service\/\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/intro-to-azure-machine-learning-service\/<\/a>    <\/p>\n<p>Please see what I have installed:    <\/p>\n<blockquote>\n<p>pip install azureml-sdk    <\/p>\n<\/blockquote>\n<p>I am getting the following messages at the end:    <\/p>\n<blockquote>\n<p>ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.    <\/p>\n<p>We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.    <\/p>\n<p>jupyterlab 2.2.9 requires jupyterlab-server&lt;2.0,&gt;=1.1.5, which is not installed.    <br \/>\nSuccessfully installed applicationinsights-0.11.9 azure-identity-1.4.1 azureml-automl-core-1.19.0 azureml-dataprep-2.6.3 azureml-dataprep-native-26.0.0 azureml-dataprep-rslex-1.4.0 azureml-dataset-runtime-1.19.0.post1 azureml-pipeline-1.19.0 azureml-pipeline-core-1.19.0 azureml-pipeline-steps-1.19.0 azureml-sdk-1.19.0 azureml-telemetry-1.19.0 azureml-train-1.19.0 azureml-train-automl-client-1.19.0 azureml-train-core-1.19.0 azureml-train-restclients-hyperdrive-1.19.0 distro-1.5.0 dotnetcore2-2.1.20 fusepy-3.0.1 msal-1.8.0 msal-extensions-0.2.2 numpy-1.19.3 portalocker-1.7.1 pyarrow-1.0.1 pywin32-227    <\/p>\n<\/blockquote>\n<p>Now I am trying to start up and type the following in .py file in Visual Studio Code    <\/p>\n<blockquote>\n<p>from azureml.core import Workspace    <\/p>\n<\/blockquote>\n<p>This is the error message I am getting:    <\/p>\n<blockquote>\n<p> File &quot;c:\/Users\/User\/OneDrive\/Desktop\/New folder\/Build AI Solution\/automl_python.py&quot;, line 1, in &lt;module&gt;    <br \/>\n    from azureml.core import Workspace    <br \/>\nModuleNotFoundError: No module named 'azureml'    <\/p>\n<\/blockquote>\n<p>Please could you help me?    <\/p>\n<p>thanks,    <\/p>\n<p>Naveen<\/p>",
        "Question_closed_time":1610753174427,
        "Answer_score_count":29.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>This is now solved. Thanks!<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"What is a working way to set up a custom Environment in AzureML using the Python SDK",
        "Question_created_time":1612894252760,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265924\/what-is-a-working-way-to-set-up-a-custom-environme",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Below are my <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66042-conda.txt?platform=QnA\">conda yml<\/a>, <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66033-dockerfile.txt?platform=QnA\">Dockerfile<\/a> and <a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66005-register.txt?platform=QnA\">register.py<\/a>(python SDK script) to create and register a custom environment in my AzureML Workspace. The AzureML documentation recommends this, if a custom system package should be installed. For me this is Graphviz. The conda environment and the docker file run successfully locally. However with my register.py script it fails:     <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66005-register.txt?platform=QnA\">66005-register.txt<\/a>    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66042-conda.txt?platform=QnA\">66042-conda.txt<\/a>    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/66033-dockerfile.txt?platform=QnA\">66033-dockerfile.txt<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to access user activity logs of azure machine learning workspace for audit purpose?",
        "Question_created_time":1612341541173,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/256833\/how-to-access-user-activity-logs-of-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>We are looking for API or Azure services from which will be able to access the activity of users in the Azure ML workspace. And also access the user activity logs related  Compute instances associated with ML workspace.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Classic Workspace New Webservices : New-AzMlWebService Powershell module",
        "Question_created_time":1606389917980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/176959\/azureml-classic-workspace-new-webservices-new-azml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>All,    <br \/>\nDoes anyone know how to use this powershell module to deploy a new webservice in the azure ml classic studio? I am able to deploy an existing experiment to a new webservice from the portal. I am trying to achieve the same using powershell.    <br \/>\nTried <a href=\"https:\/\/learn.microsoft.com\/en-us\/powershell\/module\/az.machinelearning\/new-azmlwebservice?view=azps-5.1.0\">this<\/a> cmdlet but couldnt succeed.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42969-image.png?platform=QnA\" alt=\"42969-image.png\" \/>    <\/p>\n<p>All I want is to deploy an experiment to a &quot;new&quot; webservice and choose a webservice plan using powershell.(like the following image action in the portal.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42995-image.png?platform=QnA\" alt=\"42995-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dataset + Preprocessed Text : Parameter \"Stopwords columns\" value should be less than or equal to parameter \"1\" value. . ( Error 0007 )",
        "Question_created_time":1612874807950,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265397\/dataset-preprocessed-text-parameter-stopwords-colu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I encounter the following error :  <\/p>\n<p>Parameter &quot;Stopwords columns&quot; value should be less than or equal to parameter &quot;1&quot; value. . ( Error 0007 )  <br \/>\nwhen building a simple pipeline :  <\/p>\n<p>with a .csv Dataset followed by a &quot;Preprocessed Text&quot;.  <\/p>\n<p>No parameter 'Stopwords columns' is available in the &quot;Preprocessed Text&quot; properties !!!<\/p>",
        "Question_closed_time":1612878128547,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Solved.  <\/p>\n<p>There must be only one connection (left: Dataset) and not 2 connections (left : Dataset + right : Stopwords) from the &quot;Dataset&quot; to the &quot;Preprocessed Text&quot;<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"UNZIP large zip file in azure machine learning",
        "Question_created_time":1612431352160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/258610\/unzip-large-zip-file-in-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I have a big zip file, I need to unzip it in order to use the files in my notebook  <\/p>\n<p>I used this script in my notebook  :  <\/p>\n<p>import os  <br \/>\nimport zipfile  <br \/>\nlocal_zip = 'Caltech101.zip'  <br \/>\nzip_ref = zipfile.ZipFile(local_zip, 'r')  <br \/>\nzip_ref.extractall('Caltech101')  <br \/>\nzip_ref.close()  <\/p>\n<p>it succeeded (green v in the notebook), but only the first two folders were unzipped.  <br \/>\nthis file is only 130 MB  <br \/>\nI also need to unzip 3 GB zip file<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrate Azure ML Model with Power BI by using Python",
        "Question_created_time":1612444605970,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/258899\/integrate-azure-ml-model-with-power-bi-by-using-py",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Dear Sir\/ Madam,  <br \/>\nWhile  I was trying to integrate Azure ML Model(classic) with Power BI I searched for Python script but was not able to find any code or video regarding the integration through Python.  <\/p>\n<p>If there is any way to integrate them please share.  <\/p>\n<p>Regards,  <br \/>\nNikhil.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Studio (Classic) stuck on uploading datset",
        "Question_created_time":1612782398937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/263661\/ml-studio-(classic)-stuck-on-uploading-datset",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>ML Studio classic - dataset stuck on uploaded, unable to delete.  <\/p>\n<p>Whole system is frozen and upload to run experiment, please help!  <\/p>\n<p>Required for a university assignment due this week.  <\/p>\n<p>Thank you in advance.  <\/p>\n<p>Andreia<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Package \u2018AzureML\u2019 is not available In R",
        "Question_created_time":1612444037050,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/258928\/package-azureml-is-not-available-in-r",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Dear Sir\/ Madam,    <br \/>\nI was trying to Integrate Azure ML Model(classic) with Power BI using R script and I was running following code.    <br \/>\n[    <br \/>\nwsid = &quot;&quot;    <br \/>\nauth = &quot;&quot;    <br \/>\nserviceName = &quot;Name of Exp&quot;    <\/p>\n<h1 id=\"was-trying-to-install-azureml-but-it-shows-the-error-attached-in-the-picture----\">was trying to install AzureML but it shows the error attached in the picture.    <\/h1>\n<p>library(&quot;AzureML&quot;)    <\/p>\n<p>ws &lt;- workspace(wsid, auth)    <br \/>\nds &lt;- consume(services(ws, name = serviceName),dataset)    <br \/>\nds &lt;- data.frame(ds,dataset)    <br \/>\n]    <\/p>\n<p>I tried different version of R but it is giving me the same error, Please Help.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/63939-screenshot-38.png?platform=QnA\" alt=\"63939-screenshot-38.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Module not found when custom python package installed via shell script",
        "Question_created_time":1612719050957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/262423\/module-not-found-when-custom-python-package-instal",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi All,<\/p>\n<p>I am using Azure ML designer to run zipped python scripts. But the code is complaining about the 'No module Found' error.  <br \/>\nFrom the main python script where azureml_main() is present I am calling a bash script using following call:<\/p>\n<pre><code>proc = call([&quot;bash&quot;, &quot;Script Bundle\/setup.sh&quot;])\n\n# \/bin\/bash\necho &quot;Hello World !!!&quot;\npip install -r 'Script Bundle\/requirement.txt'\npython account_test.py\n\n\n\n#account_test.py\nimport os\nimport json\nimport xmltodict\n\nfrom bankaccount import BankAccount\n\nmy_account = BankAccount(50)\nmy_account.withdraw(5)\nprint (my_account.balance, my_account.overdrawn())\n\nwith open('Script Bundle\/person.json') as f:\n   data = json.load(f)\n   print(data)\n\nwith open('Script Bundle\/sample.xml') as fd:\n    doc = xmltodict.parse(fd.read())\n    print(doc)\n<\/code><\/pre>\n<p>Inside the bash script I am installing the custom module using pip and immediately calling an entry python script(python account_test.py) to call a chain of scripts. But the code is unable to find the module(xmltodict) and is failing eventually.<\/p>\n<p>My assumption is the module is getting installed in a separate process and main process do not have access to that. But I tried with calling the python file from same shell script, still it is not working.<\/p>\n<p>Looking for your help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Error: HTTPSConnectionPool(host='westus2.api.azureml.ms', port=443):",
        "Question_created_time":1612285884163,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/255760\/azure-error-httpsconnectionpool(host-westus2-api-a",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <br \/>\nwe have a process that we have been running for over a year and suddenly have started failing and the error is not very descriptive. In this process, we run a train evaluation and a registration process from Azure DevOps.  <\/p>\n<p>The script that we are running is:  <\/p>\n<pre><code>def main():\n    # Get Azure machine learning workspace\n    login_azure = ServicePrincipalAuthentication(tenant_id, app_id, app_secret)\n    aml_workspace = Workspace.get(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=login_azure,\n    )\n\n    myenv = Environment(name=&quot;myenv&quot;)\n    CONDA_YAML = &quot;src\/train\/conda_dependencies.yml&quot;\n    load_requirements_into_conda_yml(conda_yml=CONDA_YAML)\n    conda_dep = CondaDependencies(conda_dependencies_file_path=CONDA_YAML)\n\n    # We need this pip version\n    conda_dep.add_conda_package(&quot;pip==20.2.4&quot;)\n    files_whl = []\n    os.chdir(&quot;.\/ml_service\/pipelines&quot;)\n    for file_whl in glob.glob(&quot;*.whl&quot;):\n        files_whl.append(file_whl)\n\n    for file_whl in files_whl:\n        try:\n            whl_url = Environment.add_private_pip_wheel(\n                workspace=aml_workspace, file_path=file_whl, exist_ok=True\n            )\n            conda_dep.add_pip_package(whl_url)\n        except Exception:\n            print(f&quot;Not able to add the wheel {file_whl}&quot;)\n\n    os.chdir(&quot;..\/..\/&quot;)\n\n    myenv.docker.base_image_registry.address = REGISTRY_CONTAINER_IMAGE\n    myenv.docker.base_image_registry.username = REGISTRY_CONTAINER_USERNAME\n    myenv.docker.base_image_registry.password = REGISTRY_CONTAINER_PASSWORD\n\n    # Environment Configuration\n    myenv.docker.enabled = True\n    myenv.python.user_managed_dependencies = False\n    myenv.docker.base_image = REGISTRY_BASE_IMAGE\n    myenv.python.conda_dependencies = conda_dep\n\n    run_config = RunConfiguration()\n    run_config.target = &quot;template-trainc&quot;\n\n    # Image configuration\n\n    model_name = PipelineParameter(name=&quot;model_name&quot;, default_value=model_name)\n    release_id = PipelineParameter(name=&quot;release_id&quot;, default_value=&quot;0&quot;)\n    run_config.environment = myenv\n\n    train_step = PythonScriptStep(\n        name=&quot;Train Model&quot;,\n        script_name=train_script_path,\n        compute_target=run_config.target,\n        source_directory=sources_directory_train,\n        arguments=[&quot;--release_id&quot;, release_id, &quot;--model_name&quot;, model_name],\n        runconfig=run_config,\n        allow_reuse=False,\n    )\n    print(&quot;Step Train created&quot;)\n\n    evaluate_step = PythonScriptStep(\n        name=&quot;Evaluate Model &quot;,\n        script_name=evaluate_script_path,\n        compute_target=run_config.target,\n        source_directory=sources_directory_train,\n        arguments=[&quot;--release_id&quot;, release_id, &quot;--model_name&quot;, model_name],\n        runconfig=run_config,\n        allow_reuse=False,\n    )\n    print(&quot;Step Evaluate created&quot;)\n\n    evaluate_step.run_after(train_step)\n    steps = [evaluate_step]\n\n    train_pipeline = Pipeline(workspace=aml_workspace, steps=steps)\n    train_pipeline.validate()\n    published_pipeline = train_pipeline.publish(\n        name=pipeline_name, description=&quot;Model training\/retraining pipeline&quot;, version=build_id\n    )\n    print(f&quot;Published pipeline: {published_pipeline.name}&quot;)\n    print(f&quot;for build {published_pipeline.version}&quot;)\n<\/code><\/pre>\n<p>the error is produced by this line:  <\/p>\n<pre><code>published_pipeline = train_pipeline.publish(\n        name=pipeline_name, description=&quot;Model training\/retraining pipeline&quot;, version=build_id\n    )\n<\/code><\/pre>\n<p>We are running the process in a container, that we have saved in azure acr, the container image that we are using is <a href=\"https:\/\/github.com\/microsoft\/MLOpsPython\">https:\/\/github.com\/microsoft\/MLOpsPython<\/a>, with the requirements:  <\/p>\n<pre><code>adal==1.2.2\nantlr4-python3-runtime==4.7.2\napplicationinsights==0.11.9\nargcomplete==1.10.0\nasn1crypto==0.24.0\natomicwrites==1.3.0\nattrs==19.1.0\nazure-batch==7.0.0\nazure-cli==2.0.71\nazure-cli-command-modules-nspkg==2.0.3\nazure-cli-core==2.0.71\nazure-cli-nspkg==3.0.4\nazure-cli-telemetry==1.0.3\nazure-common==1.1.23\nazure-cosmos==3.1.1\nazure-datalake-store==0.0.47\nazure-functions-devops-build==0.0.22\nazure-graphrbac==0.60.0\nazure-keyvault==1.1.0\nazure-mgmt-advisor==2.0.1\nazure-mgmt-appconfiguration==0.1.0\nazure-mgmt-applicationinsights==0.1.1\nazure-mgmt-authorization==0.52.0\nazure-mgmt-batch==6.0.0\nazure-mgmt-batchai==2.0.0\nazure-mgmt-billing==0.2.0\nazure-mgmt-botservice==0.2.0\nazure-mgmt-cdn==3.1.0\nazure-mgmt-cognitiveservices==5.0.0\nazure-mgmt-compute==6.0.0\nazure-mgmt-consumption==2.0.0\nazure-mgmt-containerinstance==1.5.0\nazure-mgmt-containerregistry==3.0.0rc5\nazure-mgmt-containerservice==5.3.0\nazure-mgmt-cosmosdb==0.7.0\nazure-mgmt-datalake-analytics==0.2.1\nazure-mgmt-datalake-nspkg==3.0.1\nazure-mgmt-datalake-store==0.5.0\nazure-mgmt-datamigration==0.1.0\nazure-mgmt-deploymentmanager==0.1.0\nazure-mgmt-devtestlabs==2.2.0\nazure-mgmt-dns==2.1.0\nazure-mgmt-eventgrid==2.2.0\nazure-mgmt-eventhub==2.6.0\nazure-mgmt-hdinsight==1.1.0\nazure-mgmt-imagebuilder==0.2.1\nazure-mgmt-iotcentral==1.0.0\nazure-mgmt-iothub==0.8.2\nazure-mgmt-iothubprovisioningservices==0.2.0\nazure-mgmt-keyvault==1.1.0\nazure-mgmt-kusto==0.3.0\nazure-mgmt-loganalytics==0.2.0\nazure-mgmt-managedservices==1.0.0\nazure-mgmt-managementgroups==0.2.0\nazure-mgmt-maps==0.1.0\nazure-mgmt-marketplaceordering==0.2.1\nazure-mgmt-media==1.1.1\nazure-mgmt-monitor==0.5.2\nazure-mgmt-msi==0.2.0\nazure-mgmt-netapp==0.5.0\nazure-mgmt-network==3.0.0\nazure-mgmt-nspkg==3.0.2\nazure-mgmt-policyinsights==0.3.1\nazure-mgmt-privatedns==0.1.0\nazure-mgmt-rdbms==1.9.0\nazure-mgmt-recoveryservices==0.4.0\nazure-mgmt-recoveryservicesbackup==0.4.0\nazure-mgmt-redis==6.0.0\nazure-mgmt-relay==0.1.0\nazure-mgmt-reservations==0.3.1\nazure-mgmt-resource==2.2.0\nazure-mgmt-search==2.1.0\nazure-mgmt-security==0.1.0\nazure-mgmt-servicebus==0.6.0\nazure-mgmt-servicefabric==0.2.0\nazure-mgmt-signalr==0.1.1\nazure-mgmt-sql==0.13.0\nazure-mgmt-sqlvirtualmachine==0.4.0\nazure-mgmt-storage==4.0.0\nazure-mgmt-trafficmanager==0.51.0\nazure-mgmt-web==0.42.0\nazure-multiapi-storage==0.2.4\nazure-nspkg==3.0.2\nazure-storage-blob==1.5.0\nazure-storage-common==1.4.2\nazureml==0.2.7\nazureml-core==1.0.62\nazureml-dataprep==1.1.17\nazureml-dataprep-native==13.0.3\nazureml-pipeline==1.0.62\nazureml-pipeline-core==1.0.62\nazureml-pipeline-steps==1.0.62\nazureml-sdk==1.0.62\nazureml-telemetry==1.0.62\nazureml-train==1.0.62\nazureml-train-core==1.0.62\nazureml-train-restclients-hyperdrive==1.0.62\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==3.1.7\ncertifi==2019.3.9\ncffi==1.11.5\nchardet==3.0.4\ncloudpickle==1.2.2\ncolorama==0.4.1\nconda==4.3.16\ncontextlib2==0.5.5\ncryptography==2.4.2\ndistro==1.4.0\ndocker==4.0.2\ndotnetcore2==2.1.8.1\nentrypoints==0.3\nfabric==2.5.0\nflake8==3.7.8\nflake8-formatter-junit-xml==0.0.6\nfusepy==3.0.1\nhumanfriendly==4.18\nidna==2.8\nimportlib-metadata==0.23\ninvoke==1.3.0\nisodate==0.6.0\njavaproperties==0.5.1\njeepney==0.4.1\nJinja2==2.10.1\njmespath==0.9.4\njsondiff==1.2.0\njsonpickle==1.2\njunit-xml==1.8\nknack==0.6.3\nMarkupSafe==1.1.1\nmccabe==0.6.1\nmock==2.0.0\nmore-itertools==7.2.0\nmsrest==0.6.10\nmsrestazure==0.6.2\nndg-httpsclient==0.5.1\nnumpy==1.19.4\noauthlib==3.1.0\npandas==1.1.4\nparamiko==2.6.0\npathspec==0.5.9\npbr==5.4.3\npip==18.1\npluggy==0.13.0\nportalocker==1.5.1\npsutil==5.6.3\npy==1.8.0\npyasn1==0.4.7\npycodestyle==2.5.0\npycosat==0.6.3\npycparser==2.19\npydocumentdb==2.3.3\npyflakes==2.1.1\nPygments==2.4.2\nPyJWT==1.7.1\nPyNaCl==1.3.0\npyOpenSSL==18.0.0\nPySocks==1.6.8\npytest==4.3.0\npython-dateutil==2.8.0\npython-dotenv==0.10.3\npytz==2019.1\nPyYAML==5.1.2\nrequests==2.22.0\nrequests-oauthlib==1.2.0\nruamel.yaml==0.16.12\nruamel.yaml.clib==0.2.2\nscp==0.13.2\nSecretStorage==3.1.1\nsetuptools==40.6.3\nsix==1.12.0\nsshtunnel==0.1.5\ntabulate==0.8.3\nurllib3==1.24.1\nvsts==0.1.25\nvsts-cd-manager==1.0.2\nwebsocket-client==0.56.0\nwheel==0.30.0\nxmltodict==0.12.0\nzipp==0.6.0\n<\/code><\/pre>\n<p>Error:  <\/p>\n<pre><code>File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 100, in __init__\n    self.datatype_provider.ensure_default_datatypes()\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 1512, in ensure_default_datatypes\n    ids = [datatype.id for datatype in self.get_all_datatypes()]\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py&quot;, line 1448, in get_all_datatypes\n    entities = self._service_caller.get_all_datatypes_async()\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_restclients\/aeva\/service_caller.py&quot;, line 499, in get_all_datatypes_async\n    workspace_name=self._workspace_name, custom_headers=self._get_custom_headers())\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_restclients\/aeva\/aml_pipelines_api10.py&quot;, line 813, in api_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_data_types_get\n    response = self._client.send(request, header_parameters, stream=False, **operation_config)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/service_client.py&quot;, line 336, in send\n    pipeline_response = self.config.pipeline.run(request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py&quot;, line 197, in run\n    return first_node.send(pipeline_request, **kwargs)  # type: ignore\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py&quot;, line 150, in send\n    response = self.next.send(request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/requests.py&quot;, line 137, in send\n    return self.next.send(request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py&quot;, line 150, in send\n    response = self.next.send(request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/requests.py&quot;, line 193, in send\n    self.driver.send(request.http_request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py&quot;, line 333, in send\n    return super(RequestsHTTPSender, self).send(request, **requests_kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py&quot;, line 145, in send\n    raise_with_traceback(ClientRequestError, msg, err)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/exceptions.py&quot;, line 51, in raise_with_traceback\n    raise error.with_traceback(exc_traceback)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py&quot;, line 142, in send\n    **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py&quot;, line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py&quot;, line 643, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/requests\/adapters.py&quot;, line 507, in send\n    raise RetryError(e, request=request)\nmsrest.exceptions.ClientRequestError: Error occurred in request., RetryError: HTTPSConnectionPool(host='westus2.api.azureml.ms', port=443): Max retries exceeded with url: \/api\/v1.0\/subscriptions\/01c989d5-4dec-4881-a9df-193efdcc5582\/resourceGroups\/trpacml01-AML-RG\/providers\/Microsoft.MachineLearningServices\/workspaces\/trpacml01-AML-WS\/DataTypes (Caused by ResponseError('too many 530 error responses'))\n##[error]Bash exited with code '1'.\n<\/code><\/pre>\n<p>Is there is any new kind of requirement? proxy? or the service is unavailable?  <\/p>\n<p>Thank you so much!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Update a deployed web service with published endpoint after retraining with new pipeline parameter.",
        "Question_created_time":1612770312390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/263253\/update-a-deployed-web-service-with-published-endpo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created a model in the new Azure designer portal with some data and I have deployed it as a real-time interference pipeline. After that, I retrained the pipeline with the new pipeline parameter as mentioned in the link below.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-retrain-designer\">how-to-retrain-designer<\/a>    <\/p>\n<p>Once the model is retrained , I published it as a new endpoint and I got the RESTAPI to consume. But I don't know how to consume the updated endpoint with the REST API. Please let me know any links that helps to consume them.    <\/p>\n<p>Also there is no clear documentation on how to update the existing web service of the model with the old data to the new data.     <br \/>\nAlso I need to know how to do all these programmatically. Any help is appreciated. Many thanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"VBA  And Azure Machine Learning Excel Add In",
        "Question_created_time":1610149745593,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224491\/vba-and-azure-machine-learning-excel-add-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi! I wanted to see if VBA and Azure Machine Learning Excel Add In can be connected to each other. Are there any way to code VBA (use VBA) for controlling or altering Azure Machine Learning Excel Add In? I have used Azure Machine Learning to rate candidate feedback as negative or positive, but it has like a 75 -80% success rate - there are still a good chunk of comments that are rated wrong. However, it is still an amazing tool that I want to use v- I was just wondering if I can increase the accuracy of it somehow by creating a VBA code that connects it to Azure Machine Learning where I can add words related to negative responses or vice versa for positive response to increase the accuracy. <\/p>",
        "Question_closed_time":1610161769647,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, we currently don't support VBA and Azure ML Excel add-in integration. You'll need to apply <a href=\"https:\/\/stackoverflow.com\/questions\/41447104\/how-to-improve-classification-accuracy-for-machine-learning\">ML techniques for improving your model<\/a> and re-deploy your model.  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Stopping ML Server Engine",
        "Question_created_time":1612666795983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/262003\/stopping-ml-server-engine",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm running the Microsoft Machine Learning Server on my computer. Right now, there are no tasks\/nodes running, and task manager is showing multiple instances of the &quot;Microsoft ML Server Engine&quot; that are using nearly all my computer resources. I've gone into the administration utility, but can't seem to find a way of stopping this, short of brute &quot;End Task&quot; within TM. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I fix this Snapshot Exception?",
        "Question_created_time":1612425944867,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/258581\/how-do-i-fix-this-snapshot-exception",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I'm doing a pipeline in Azure ML SDK. After I had run the pipeline for some amount of times it reported I had reached the Snapshot limit of 300MB. I followed some of the fixes that was proposed:<\/p>\n<ul>\n<li>   Each step script is moved to a separate subfolder<\/li>\n<li>   I added a datastore to the pipeline<\/li>\n<li>   This line was added: <code>azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 1000<\/code><\/li>\n<\/ul>\n<p>But then a new Snapshot error occurred after I submitted my pipeline:<\/p>\n<pre><code>pipeline1 = Pipeline(default_source_directory=&quot;.&quot;, default_datastore=def_blob_store, workspace=ws, steps=[prep_step, hd_step, register_model_step])\n<\/code><\/pre>\n<p>THE ERROR MESSAGE:<\/p>\n<pre><code>WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n---------------------------------------------------------------------------\nSnapshotException                         Traceback (most recent call last)\n&lt;ipython-input-14-05c5aa4991aa&gt; in &lt;module&gt;\n----&gt; 1 pipeline1 = Pipeline(default_source_directory=&quot;.&quot;, default_datastore=def_blob_store, workspace=ws, steps=[prep_step, hd_step, register_model_step])\n      2 pipeline1.validate()\n      3 pipeline_run = Experiment(ws, 'health_insuarance').submit(pipeline1, regenerate_outputs=False)\n      4 RunDetails(pipeline_run).show()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/_experiment_method.py in wrapper(self, *args, **kwargs)\n     95             &quot;&quot;&quot;\n     96             ExperimentSubmitRegistrar.register_submit_function(self.__class__, submit_function)\n---&gt; 97             return init_func(self, *args, **kwargs)\n     98         return wrapper\n     99     return real_decorator\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/pipeline.py in __init__(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\n    175                 raise ValueError('parameter %s is not recognized for Pipeline ' % key)\n    176         self._enable_email_notification = enable_email_notification\n--&gt; 177         self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n    178 \n    179     def _set_experiment_name(self, name):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in build(self, name, steps, finalize, regenerate_outputs)\n   1479                 pass\n   1480 \n-&gt; 1481         graph = self.construct(name, steps)\n   1482         if finalize:\n   1483             graph.finalize(regenerate_outputs=regenerate_outputs)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in construct(self, name, steps)\n   1501         self._graph = Graph(name, self._context)\n   1502         self._nodeStack.append([])\n-&gt; 1503         self.process_collection(steps)\n   1504         for builder in self._builderStack[::-1]:\n   1505             builder.apply_rules()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n   1537         self._nodeStack.append([])\n   1538         self._builderStack.append(builder)\n-&gt; 1539         builder.process_collection(collection)\n   1540         added_nodes = self._nodeStack.pop()\n   1541         self._nodeStack[-1].extend(added_nodes)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n   1828         &quot;&quot;&quot;\n   1829         for item in collection:\n-&gt; 1830             self._base_builder.process_collection(item)\n   1831 \n   1832     def apply_rules(self):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n   1531         # just a step?\n   1532         if isinstance(collection, PipelineStep):\n-&gt; 1533             return self.process_step(collection)\n   1534 \n   1535         # delegate to correct builder\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_step(self, step)\n   1575             return self._step2node[step]\n   1576 \n-&gt; 1577         node = step.create_node(self._graph, self._default_datastore, self._context)\n   1578         self.assert_node_valid(step, self._graph, node)\n   1579 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py in create_node(self, graph, default_datastore, context)\n    247         &quot;&quot;&quot;\n    248         hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n--&gt; 249                                                                                context._experiment_name)\n    250         self._params[HyperDriveStep._run_config_param_name] = json.dumps(hyperdrive_config)\n    251         self._params[HyperDriveStep._run_reuse_hashable_config] = json.dumps(reuse_hashable_config)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py in _get_hyperdrive_config(self, workspace, experiment_name)\n    323 \n    324         hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n--&gt; 325                                                         experiment_name, telemetry_values)\n    326 \n    327         hyperdrive_config = hyperdrive_dto.as_dict()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/_search.py in _create_experiment_dto(hyperdrive_config, workspace, experiment_name, telemetry_values, activity_logger, **kwargs)\n     41     if hyperdrive_config.source_directory is not None:\n     42         snapshot_client = SnapshotsClient(workspace.service_context)\n---&gt; 43         snapshot_id = snapshot_client.create_snapshot(hyperdrive_config.source_directory)\n     44 \n     45         if activity_logger is not None:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/snapshots_client.py in create_snapshot(self, file_or_folder_path, retry_on_failure, raise_on_validation_failure)\n     83         exclude_function = ignore_file.is_file_excluded\n     84 \n---&gt; 85         self._validate_snapshot_size(file_or_folder_path, exclude_function, raise_on_validation_failure)\n     86 \n     87         # Get the previous snapshot for this project\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/snapshots_client.py in _validate_snapshot_size(self, file_or_folder_path, exclude_function, raise_on_validation_failure)\n     61                             &quot;\\n&quot;.format(file_or_folder_path, SNAPSHOT_MAX_SIZE_BYTES \/ ONE_MB)\n     62             if raise_on_validation_failure:\n---&gt; 63                 raise SnapshotException(error_message)\n     64             else:\n     65                 self._logger.warning(error_message)\n\nSnapshotException: SnapshotException:\n    Message: ====================================================================\n\nWhile attempting to take snapshot of .\/train\/\nYour total snapshot size exceeds the limit of 0.00095367431640625 MB.\nPlease see http:\/\/aka.ms\/aml-largefiles on how to work with large files.\n\n====================================================================\n\n\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;====================================================================\\n\\nWhile attempting to take snapshot of .\/train\/\\nYour total snapshot size exceeds the limit of 0.00095367431640625 MB.\\nPlease see http:\/\/aka.ms\/aml-largefiles on how to work with large files.\\n\\n====================================================================\\n\\n&quot;\n    }\n}\n\u200b\n<\/code><\/pre>\n<p>Any idea how I fix this?<\/p>",
        "Question_closed_time":1612529086250,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Alright, so I found the fix.  <\/p>\n<p>I changed this line by adding a number equvilant to 1GB: <code>azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 1000000000<\/code>  <\/p>\n<p>For some reason, you have to define the size in BYTES and not megabytes even though the default is 300 MB. Not especially intuitive.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"How to specify HTTP response status code in AML R Web Service",
        "Question_created_time":1612354860267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/257156\/how-to-specify-http-response-status-code-in-aml-r",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Is there any way to return a custom HTTP status code from R Web Service in Azure ML?  <\/p>\n<p>All the examples of entry scripts in documentation return the response body from the scoring function. In Python Web Service, it is possible to return a HTTP response object with a custom status code. However, R's httr library does not seem to have any function to create response objects directly (only via HTTP method objects such as POST, which call a given URL).  <\/p>\n<p>I would like to implement a custom exception handling scheme in R Web Service. Is there any way to return a custom HTTP code from the entry script?  <\/p>\n<p>EDIT: Found this idea on the feedback forum, which suggests that the option is not available in Python Web Service either:  <br \/>\n<a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor\">https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor<\/a>  <\/p>",
        "Question_closed_time":1612394092687,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello Lauri,  <\/p>\n<p>Thanks for the feedback. Yes, we have this product idea in our backlog. I will help to bump up this idea to product group again. ^^  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Import Reader module or pass Azure storage queried values in Batch Execution (BES) with python for retraining",
        "Question_created_time":1612247831417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/255061\/import-reader-module-or-pass-azure-storage-queried",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Currently I have a machine learning model and I'm retraining it with Python BES code. I need to pass the input directly to the input parameters. It's accepting only CSV file (Or may be other files). I don't want to use any file. I have fetched the rows from database from python.  <\/p>\n<p> Is it possible to directly pass the queried values as input parameters?  <\/p>\n<p>I have read about the reader module but I cannot fine anything to use it with python BES code.  <\/p>\n<p>Any help is appreciated. Thanks   <\/p>\n<p>I have deployed the model through Azure machine learning studio (Classic) and Here is the code where the input payload is passed. I need to pass a python variable or the data returned from the storage table to this and not as CSV. Is it possible to achieve this?  <\/p>\n<pre><code>    payload = {\n        &quot;Inputs&quot;: {\n                &quot;input1&quot;:\n                {\n                    &quot;ConnectionString&quot;: connection_string,\n                    &quot;RelativeLocation&quot;: &quot;\/&quot; + storage_container_name + &quot;\/filename.csv&quot; # Replace this with the location you would like to use for your input file, and valid file extension (usually .csv)\n                },\n        },\n\n        &quot;Outputs&quot;: {\n                &quot;output2&quot;:\n                {\n                    &quot;ConnectionString&quot;: connection_string,\n                    &quot;RelativeLocation&quot;: &quot;\/&quot; + storage_container_name + &quot;\/filename.ilearner&quot; # Replace this with the location you would like to use for your output file, and valid file extension (usually .csv for scoring results, or .ilearner for trained models)\n                },\n                &quot;output1&quot;:\n                {\n                    &quot;ConnectionString&quot;: connection_string,\n                    &quot;RelativeLocation&quot;: &quot;\/&quot; + storage_container_name + &quot;\/filename.csv&quot; # Replace this with the location you would like to use for your output file, and valid file extension (usually .csv for scoring results, or .ilearner for trained models)\n                },\n        },\n\n    &quot;GlobalParameters&quot;: {\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to Consume a trained model saved as web service",
        "Question_created_time":1612313789263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/256246\/how-to-consume-a-trained-model-saved-as-web-servic",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello all,   <\/p>\n<p>I trained a model which uses cross-validation. So I can not save it locally as trained model as far as I know. For this case, I tried to to deploy it as web service.  <\/p>\n<p>For example, I trained a model called X. Then, I created a new experiment called Y to consume this trained model X. I tried to drag and drop load trained model to use model X via web service. it does not work. Could you please guide me how I can consume my trained model that saved as web-services. Or Can you please let me know how I can save my model that using cross-validation locally?   <\/p>\n<p>-Best<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Estimator or SciptRunConfig for Pipeline with Hyperdrive and XGBoost?",
        "Question_created_time":1611821264403,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/248696\/using-estimator-or-sciptrunconfig-for-pipeline-wit",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm learning Azure ML and I'm trying to make a pipeline with HyperDrive and an Xgboost estimator. But I cannot figure out how I add the custom XGBoost environment to my HyperDriveConfig.  <\/p>\n<p>Estimator is apparently deprecated and telling me to use ScriptRunConfig instead.  <\/p>\n<p>So I have created an Enviroment pointing to a yaml file with dependencies and a  ScriptRunConfig pointing to the environment. But how should I use the  ScriptRunConfig in HyperDriveConfig?  <br \/>\nThis is the code I'm trying atm:  <\/p>\n<pre><code>env = Environment.from_conda_specification(&quot;xgboost&quot;, &quot;environment.yml&quot;)\n\nsrc = ScriptRunConfig(\n                    source_directory='.',\n                    script='train.py',\n                    compute_target=compute_target,\n                    environment=env,\n)\n\nhyperdrive_run_config = HyperDriveConfig(\n                                         hyperparameter_sampling=ps, \n                                         primary_metric_name='Accuracy',\n                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                         max_total_runs=100,\n                                         max_concurrent_runs=4,\n                                        #run_config = aml_run_config,\n                                        policy=None,\n                                        estimator=src\n                                        )\n<\/code><\/pre>\n<p>When I submit the pipeline  get the following error:  <\/p>\n<p>AttributeError: 'ScriptRunConfig' object has no attribute '_get_script_run_config'<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"can we run a jupyter notebook using scriptrunconfig on target compute cluster ?",
        "Question_created_time":1612203390137,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/254301\/can-we-run-a-jupyter-notebook-using-scriptrunconfi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I understood that we can run a python script using scriptrunconfig.  <\/p>\n<p>My question is whether we can run jupyter notebook ?  <br \/>\nWhat other type of scripts can we run ?  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"machine learning server",
        "Question_created_time":1610574178773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/229665\/machine-learning-server",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am not able to use my Jupyterlab and Jupyter Notebook. It cannot connect to a Kernel.  <\/p>\n<p>Will this problem be solved when I uninstall Anaconda and install Microsoft Machine Learning Server.  <\/p>\n<p>Thanks,  <\/p>\n<p>Naveen<\/p>",
        "Question_closed_time":1610581957883,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, I'm assuming you're using your own development environment. I found some <a href=\"https:\/\/jupyter-notebook.readthedocs.io\/en\/stable\/troubleshooting.html\">troubleshooting steps<\/a> that may be helpful. Furthermore, <a href=\"https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/what-is-machine-learning-server\">Azure Machine Learning Server<\/a> is an enterprise software that provides the tools for performing data science tasks. You can review Azure ML Server and other <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment#local\">options<\/a> to determine which option best suits your data science scenario. Hope this helps.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Internal server error while connecting to jupyter lab instance",
        "Question_created_time":1610979567287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/234805\/internal-server-error-while-connecting-to-jupyter",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_body":"<p>I have created an ML-compute instance from scratch, nothing particularly installed.  <br \/>\nBut when I try to connect to Jupiter Lab directly through the URL provided by the user interface I get the following error :<\/p>\n<p>{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;ServiceError&quot;,  <br \/>\n&quot;severity&quot;: null,  <br \/>\n&quot;message&quot;: &quot;InternalServerError&quot;,  <br \/>\n&quot;messageFormat&quot;: null,  <br \/>\n&quot;messageParameters&quot;: null,  <br \/>\n&quot;referenceCode&quot;: null,  <br \/>\n&quot;detailsUri&quot;: null,  <br \/>\n&quot;target&quot;: null,  <br \/>\n&quot;details&quot;: [],  <br \/>\n&quot;innerError&quot;: null,  <br \/>\n&quot;debugInfo&quot;: null  <br \/>\n},  <br \/>\n&quot;correlation&quot;: {  <br \/>\n&quot;operation&quot;: &quot;716efa38ccc70341b4b5b93bc16e441b&quot;,  <br \/>\n&quot;request&quot;: &quot;170d9ccac55c9d42&quot;  <br \/>\n},  <br \/>\n&quot;environment&quot;: &quot;westeurope&quot;,  <br \/>\n&quot;location&quot;: &quot;westeurope&quot;,  <br \/>\n&quot;time&quot;: &quot;2021-01-18T14:00:19.9517739+00:00&quot;,  <br \/>\n&quot;componentName&quot;: &quot;notebook-instance-proxy&quot;  <br \/>\n}<\/p>\n<p>I also tried to connect through SSH to this compute instance, I notice that there is a conflict about the version of the pillow package.  <br \/>\nThen I've fixed the version conflict but the error still persists even after rebooting the machine.  <br \/>\nAfter that, I've connected to the machine through SSH tunnelling and I could start the Jupiter lab instance (even though the error still persist when connecting through the Azure ML Interface).<\/p>\n<p>Could you please investigate the connection issue through the user interface please?  <br \/>\nThanks in advance<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"New Azure ML Service - Designer missing",
        "Question_created_time":1611932220923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/251151\/new-azure-ml-service-designer-missing",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,    <br \/>\nThe Designer is suddenly missing in the new Azure ML Workspace. I was using it a few weeks back, any clue why this is happening? The service is in west europe.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/61895-image.png?platform=QnA\" alt=\"61895-image.png\" \/>    <br \/>\nThanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get image id from deployed azureml Model?",
        "Question_created_time":1611789072743,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/247987\/get-image-id-from-deployed-azureml-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>About a year ago when testing <code>azure.train.automl<\/code> models' deployments with <code>AciContainer<\/code> and <code>AciWebServices<\/code> the endpoint details also displayed an <code>Image ID<\/code> which our web services team could pull and deploy.  <\/p>\n<p>Now with <code>azure.core==1.19.0<\/code> the <code>Image ID<\/code> is not automatically produced.  <\/p>\n<p>How do I generate the <code>Image ID<\/code> for them to pull the image?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data entry webservice Azure consume: Transform values of data entered",
        "Question_created_time":1611930985517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/251134\/data-entry-webservice-azure-consume-transform-valu",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have built a predictive model within Azure that works fine. I am trying to improve this by grouping values for some columns.  <br \/>\nI have 2 columns: format1, format2. I need to roundup them (ceil function). I did it in the Azure model but I need now to round these values when the user enters imput via the webservice.   <br \/>\nExample :   <br \/>\nformat1 =&gt; 21 =&gt; should be 25  <br \/>\nformat2 =&gt; 31 =&gt; should be 35  <br \/>\nThen these values (25,35) will be used in the Azure model.   <br \/>\nI tried to add a &quot;apply math operation&quot; in the predictive experiment but it seems not adapted for this....  <\/p>\n<p>Thank you for your help.  <\/p>\n<p>Regards,  <\/p>\n<p>Mohamed.<\/p>",
        "Question_closed_time":1611932433297,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,  <\/p>\n<p>I got it, it works fine. Adding the module &quot;apply math operation in the predictive experiment and just after the data entry module is efficient.  <\/p>\n<p>Thx :)  <\/p>\n<p>Mohamed.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"AzureMLCompute job failed: container registry failed unexpectedly: container setup task failed",
        "Question_created_time":1610999729247,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/235234\/azuremlcompute-job-failed-container-registry-faile",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,  <\/p>\n<p>Could you please help me with running python script in azureml environment? I created the workspace and azure container registry and pushed docker image to the container.  This is the example of dockerfile:  <\/p>\n<pre><code>FROM python:3.7\n\nRUN pip install --upgrade pip\n\nRUN pip install virtualenv\n\nENV VIRTUAL_ENV=\/venv\n\nRUN virtualenv venv -p python3\n\nENV PATH=&quot;VIRTUAL_ENV\/bin:$PATH&quot;\n\nWORKDIR \/app\n\nADD . \/app\n\nENV PYTHON_PACKAGES=&quot;\\\n     numpy \\\n pandas \\\n seaborn \\\n matplotlib \\\n sklearn \\\n scipy \\\n imbalanced-learn \\\n xgboost \\\n joblib \\\n&quot; \n\nRUN pip install --no-cache-dir $PYTHON_PACKAGES\n\nENTRYPOINT [&quot;python3&quot;,&quot;train.py&quot;]\n<\/code><\/pre>\n<p>When I run the experiment I get this error:  <\/p>\n<blockquote>\n<p>&quot;Message&quot;: &quot;AzureMLCompute job failed.\\nJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\tJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\terr: container setup task failed: exit status 1\\n\\tReason: container setup task failed: exit status 1\\n\\tInfo: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.&quot;  <\/p>\n<\/blockquote>\n<p>I do not understand what this error mean.  <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Registered AzureML Model from a NotebookVM can not be found",
        "Question_created_time":1611611453007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/244841\/registered-azureml-model-from-a-notebookvm-can-not",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>First here is code for my version:  <\/p>\n<p><code>&gt;&gt;&gt;from azureml.__version__ import __version__ as _azml_version_<\/code>  <br \/>\n<code>&gt;&gt;&gt;from azureml.core import __version__ as _azmlcore_version_<\/code>  <br \/>\n<code>&gt;&gt;&gt;from azureml.train.automl import __version__ as _azmltrain_version_<\/code>  <\/p>\n<p><code>&gt;&gt;&gt;print('azure', _azml_version_)<\/code>  <br \/>\n<code>&gt;&gt;&gt;print(' core', _azmlcore_version_)<\/code>  <br \/>\n<code>&gt;&gt;&gt;print('train', _azmltrain_version_)<\/code>  <br \/>\n<code>azure 1.0.1b6.post1<\/code>  <br \/>\n<code> core 1.18.0<\/code>  <br \/>\n<code>train 1.18.0<\/code>  <\/p>\n<p>The following cell fails when trying to execute the <code>Model.get_model_path(<\/code> method and ultimately raises a <code>ModelNotFoundException<\/code> .  <br \/>\nWhich is very weird because I can view the model info in the &quot;Microsoft Azure Machine Learning&quot; portal.  <\/p>\n<p><code>&gt;&gt;&gt; model_name = 'total_ridge_20210106'<\/code>  <br \/>\n<code>&gt;&gt;&gt; model_path = f'ridge_src\/{model_name}.pkl'<\/code>  <br \/>\n<code>&gt;&gt;&gt; <\/code>  <br \/>\n<code>&gt;&gt;&gt; model = joblib.load(model_path)<\/code>  <br \/>\n<code>&gt;&gt;&gt; <\/code>  <br \/>\n<code>&gt;&gt;&gt; azmodel = Model.register(model_path=model_path,<\/code>  <br \/>\n<code>&gt;&gt;&gt;                          model_name=model_name,<\/code>  <br \/>\n<code>&gt;&gt;&gt;                          tags={'area': &quot;qtc&quot;, 'type': &quot;regression&quot;},<\/code>  <br \/>\n<code>&gt;&gt;&gt;                          description=f&quot;monolithic ridge model&quot;,<\/code>  <br \/>\n<code>&gt;&gt;&gt;                          workspace=ws)<\/code>  <br \/>\n<code>&gt;&gt;&gt; <\/code>  <br \/>\n<code>&gt;&gt;&gt; retrieved_path = Model.get_model_path(model_name)<\/code>  <\/p>\n<p><code>ModelNotFoundException: ModelNotFoundException:<\/code>  <br \/>\n<code>\tMessage: Model not found in cache or in root at .\/total_ridge_20210106. For more info,set logging level to DEBUG.<\/code>  <br \/>\n<code>\tInnerException None<\/code>  <br \/>\n<code>\tErrorResponse <\/code>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to disable Azure ML snapshots (for compute clusters)",
        "Question_created_time":1611558384720,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/243585\/how-to-disable-azure-ml-snapshots-(for-compute-clu",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am using the Azure ML Python SDK to spawn jobs using a prebuilt Docker image compute cluster. The Docker image has all of the dependencies installed and the source code I am running.    <\/p>\n<p>According to the logs, Azure ML's &quot;snapshot&quot; operations (that I assume upload and then download the source directory to Azure ML jobs) increase the startup time from 2 minutes to 8-20 minutes (i.e., the time it takes for an Azure ML run to begin running my code). By comparison, when I run the exact same code on a compute <strong>instance<\/strong> instead of a compute cluster, startup time is 60-80 seconds. Notably, the startup logs for the compute <strong>instance<\/strong> make no mention of &quot;snapshots&quot;.    <\/p>\n<p>I already <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.runconfig.historyconfiguration?view=azure-ml-py\">disabled saving snapshots for historical record<\/a>, but that made little difference and the startup logs (for a cluster) still show operations for snapshots. I also significantly expanded our <code>.amlignore<\/code> file, which reduced the startup time by 10+ minutes, but 5-10 minutes are still spent on the &quot;fetching snapshots&quot; step (which we do not even use).     <\/p>\n<p><strong>Questions:<\/strong>    <\/p>\n<ol>\n<li> What is this &quot;fetching snapshot&quot; operation if it is not the saving of snapshots for historical record (which I already disabled and confirmed)?    <\/li>\n<li> Why does this operation only occur for compute clusters but not compute instances?    <\/li>\n<li> Why is this operation so slow? I.e., 5-10 minutes to &quot;fetch&quot; less than 10 MB of python files.    <\/li>\n<li> Can I disable everything having to do with snapshots altogether? I assume this is possible because this occurs when using compute instances in Azure ML.    <\/li>\n<\/ol>\n<p>Thank you very much. Please let me know if there is anything more I can provide to help debug.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine learning Workspace not loading. Shows a Request cannot be served error",
        "Question_created_time":1611837281277,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/249069\/machine-learning-workspace-not-loading-shows-a-req",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My ML workspace does not load. It shows like this.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/61417-screenshot-233.png?platform=QnA\" alt=\"61417-screenshot-233.png\" \/>    <\/p>\n<p>Need a answer quickly. Thanks in advance    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"R device result",
        "Question_created_time":1611814116917,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/248487\/r-device-result",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>R device Loading variable to data frame not complete  <br \/>\nThis is my code  <br \/>\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,  <br \/>\nprobs=c(0, .25,.5, 0.75, 1) ) ) )  <\/p>\n<p>Select data.frame to be sent to the output Dataset port  <br \/>\nmaml.mapOutputPort(&quot;dataset1&quot;);  <\/p>\n<p>R device port (Loading variable ) show &quot;Loading variable port1...&quot;  <br \/>\n0% 25% 50% 75% 100%  <br \/>\n6319\/A16.ZDE1DWW70500009 0.270 0.5050 0.740 0.9000 1.06  <br \/>\n6319\/A17.ZDE1DWW70500009 0.300 0.3825 0.445 0.5825 0.89  <br \/>\n6319\/A18.ZDE1DWW70500009 0.470 0.4700 0.470 0.4700 0.47  <br \/>\n6320\/A01.ZDE1DWW70500009 0.330 0.3725 0.475 1.2675 1.99  <\/p>\n<p>How to import this in table format for analysis  <\/p>\n<p>I try to use  <br \/>\ndata.set &lt;- data.frame (  <br \/>\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,  <br \/>\nprobs=c(0, .25,.5, 0.75, 1) ) ) )  <br \/>\n)  <\/p>\n<p>I get this table that has not first column ( ex. 6319\/A16.ZDE1DWW70500009)  <br \/>\n0. X25. X50. X75. X100.  <\/p>\n<p>0.27 0.505 0.74 0.9 1.06  <br \/>\n0.3 0.3825 0.445 0.5825 0.89  <br \/>\n0.47 0.47 0.47 0.47 0.47  <br \/>\n0.33 0.3725 0.475 1.2675 1.99  <br \/>\n0.2 0.2675 0.33 0.3925 0.52  <\/p>\n<p>Please suggest me,  <br \/>\nI sorry for my english is not good.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Time Series Forecasting \/ Regression - How to download the actual predictions?",
        "Question_created_time":1608891234540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/210527\/time-series-forecasting-regression-how-to-download",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have trained an auto regressive model and I can see its performance metrics.   <br \/>\nHow do I see  the predictions or download as a cvs?   <\/p>\n<p>Is there a start-to-end example explaining how to do regression \/ time series forecasting using machine learning?  <br \/>\nAll examples from microsoft I could find explain things up to <code>creating a model<\/code>, I can not find information on how to use the model for prediction.  <br \/>\nDetailed explanations on how data is expected as input would be much appreciated (example: should the dates go from most recent to least recent or the other way around? Should I use linux timesamps instead? Should the prediction values be marked as currency or integer or float or just normal?)  <\/p>\n<p>Thanks, Efe<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Forecasting and AutoMLConfig do not propagate to UI",
        "Question_created_time":1611539077903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/243175\/forecasting-and-automlconfig-do-not-propagate-to-u",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi! Using the SDK version 19 and setting the blocked_models as none or a given model do not propagate in the triggered run to only block that model, instead it blocks a bunch. Also the forecastingParameters do not propagate as well. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60031-screenshot-2021-01-24-at-220420.png?platform=QnA\" alt=\"60031-screenshot-2021-01-24-at-220420.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60032-screenshot-2021-01-24-at-220426.png?platform=QnA\" alt=\"60032-screenshot-2021-01-24-at-220426.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/59974-screenshot-2021-01-24-at-220637.png?platform=QnA\" alt=\"59974-screenshot-2021-01-24-at-220637.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/59994-screenshot-2021-01-24-at-220642.png?platform=QnA\" alt=\"59994-screenshot-2021-01-24-at-220642.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to get started about analysing time series with Azure?",
        "Question_created_time":1611334374593,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/241953\/how-to-get-started-about-analysing-time-series-wit",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We have a large amount of time series that get updated each month or week and would like to use some Azure based machine learning to QC this.  <\/p>\n<p>Having no practical experience of machine learning or azure, could you point me where\/how I could get started, please?  <\/p>\n<p>Our data itself is located on the cloud in a Snowflake database.  <\/p>\n<p>Many Thanks   <\/p>\n<p>Eric  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to use notebook in Azure ML",
        "Question_created_time":1611215759177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/239535\/unable-to-use-notebook-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have been following several ML tutorials and this is the second time that I cannot work in the notebook directly in Azure ML. I can open and edit it in Jupyter notebook, but it will never open in ML.    <\/p>\n<p>Also it states &quot;no kernel selected&quot; but its greyed out. I tried login in and out with no change.    <\/p>\n<p>Tutorial i followed:    <br \/>\nlearn.microsoft.comhttps:\/\/learn.microsoft.com\/da-dk\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/deploy-service    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/59033-image.png?platform=QnA\" alt=\"59033-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I run ML on my own hardware or ARC connected cluster",
        "Question_created_time":1611291212300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/240991\/can-i-run-ml-on-my-own-hardware-or-arc-connected-c",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am just trying to find a simple YES\/NO answer to this question  <\/p>\n<p>Can I run Azure ML on my own hardware\/cluster? All the functions to register a new VM\/system via IP address have been deprecated and now requires a resource ID.  <\/p>\n<p>I have created 2 resources in Azure ARC  - A cluster and a server and I cant use either resource id to link to Azure ML via python or AZ command - both advise its not virtual machine.  <\/p>\n<p>So if someone could please put my out of my misery, can you run Azure ML on your own hardware.  <\/p>\n<p>Thanks!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I can't delete Azure ML workspace",
        "Question_created_time":1611219605467,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/239609\/i-cant-delete-azure-ml-workspace",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I created azure ml workspace - region east us, after I tried to create compute instances in this workspace I found that those resources could't be allocated from that region and compute instances were in the unknown state. I decided to delete this workspace but the deletion is taking more than 8 hours, I want to delete this workspace as it decreases the available quotas for me for compute resources.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Images Segmentation using Azure",
        "Question_created_time":1610951620483,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/234232\/images-segmentation-using-azure",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <br \/>\nI have been using object detection from Custom Vision to train images. Classification do not suit my goal so I'm looking at alternative methods to training images. Can I get some suggestions with using Azure for images segmentation?<\/p>",
        "Question_closed_time":1610955618900,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=d94e82d7-8d83-4f86-8055-f9af74b9130d\">@Nam Ly  <\/a>    <\/p>\n<p>Suggestions and refer below url for Azure for images segmentation.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/samples\/browse\/?products=azure&amp;term=vision&amp;terms=%22Custom%20Vision%22\">Custom Vision integration sample skill for cognitive search<\/a>    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/classify-images-custom-vision\/\">Classify images with the Custom Vision service<\/a>    <\/p>\n<p>Please don\u2019t forget to <code>Accept the answer<\/code> and <code>up-vote<\/code> wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML doesn't let me use notebooks",
        "Question_created_time":1610372674263,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/226106\/azure-ml-doesnt-let-me-use-notebooks",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am going into my notebooks portal on one of my expiriments, and it says,&quot;The current subscription state does not allow this operation.&quot; It worked yesterday, but why not today?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deepspeed gpt-2 megatron-LM problems",
        "Question_created_time":1610037769210,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/222550\/deepspeed-gpt-2-megatron-lm-problems",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to make a GPT-2 model with deepspeed on an azure VM. I found ~2 bugs which I was able to patch, but I have stumbled upon a really tough one. You see, it says I need pytorch. No surprise. I install pytorch. It still says I don't have it. I used both pip and pip3 many times. I install pytorch from github and run setup.py. It says I need python 3. When I get python 3 it says the same. When I try google colab it gives me the following error:  <br \/>\n<code>Traceback (most recent call last):   <\/code>  File &quot;pretrain_gpt2.py&quot;, line 709, in &lt;module&gt;  <br \/>\n<code>   main()  <\/code>  File &quot;pretrain_gpt2.py&quot;, line 654, in main  <br \/>\n<code>   args.eod_token = get_train_val_test_data(args)  <\/code>  File &quot;pretrain_gpt2.py&quot;, line 600, in get_train_val_test_data  <br \/>\n<code>   args)  <\/code>  File &quot;\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py&quot;, line 34, in apply  <br \/>\n<code>   return make_loaders(args)  <\/code>  File &quot;\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py&quot;, line 170, in make_loaders  <br \/>\n<code>   train, tokenizer = data_utils.make_dataset(**data_set_args)  <\/code>  File &quot;\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/<strong>init<\/strong>.py&quot;, line 109, in make_dataset  <br \/>\n<code>   ds = split_ds(ds, split)  <\/code>  File &quot;\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py&quot;, line 194, in split_ds  <br \/>\n<code>   rtn_ds[i] = SplitDataset(ds, split_inds)   <\/code> File &quot;\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py&quot;, line 134, in <strong>init<\/strong>  <br \/>\n <code>  self.lens = itemgetter(*self.split_inds)(list(self.wrapped_data.lens))  <\/code>TypeError: itemgetter expected 1 arguments, got 0  <\/p>\n<p>How do I fix both the google colab and the azure VM errors?<\/p>",
        "Question_closed_time":1610409087243,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b4907c12-a726-468e-8576-0c4a9c876196\">@sammyboy123  <\/a>     <br \/>\nI would start by installing PyTorch via pip. Instructions can be found <a href=\"https:\/\/pytorch.org\/get-started\/locally\/\">here<\/a>. There is also a verification section which will test if you have PyTorch installed correctly. You also might find the DeepSpeed <a href=\"https:\/\/www.deepspeed.ai\/getting-started\/\">Getting Started page<\/a> helpful. There are specific tutorials for Azure and also a docker image available.    <\/p>\n<p>Let me know if this doesn't work for you or you are still facing issues.    <\/p>\n<p>-------------------------------    <\/p>\n<p>Please don\u2019t forget to <strong>&quot;Accept the answer&quot;<\/strong> and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"WebserviceException",
        "Question_created_time":1610753682927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/232883\/webserviceexception",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,  <\/p>\n<p>I am trying to do &quot;create a Real-time Inferencing Service&quot; and in the Notebook at some point, this is the code:  <\/p>\n<pre><code>from azureml.core.webservice import AciWebservice\nfrom azureml.core.model import InferenceConfig\n\n# Configure the scoring environment\ninference_config = InferenceConfig(runtime= &quot;python&quot;,\n                                   entry_script=script_file,\n                                   conda_file=env_file)\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n\nservice_name = &quot;diabetes-service&quot;\n\nservice = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)\n<\/code><\/pre>\n<p>This is the error message I am getting:  <\/p>\n<pre><code>&quot;WebserviceException: WebserviceException: Message: Service deployment polling reached non-successful terminal state, current service state: Failed Operation ID: &quot;\n<\/code><\/pre>\n<p>Please can you help me with this?  <\/p>\n<p>Thanks,  <\/p>\n<p>Naveen  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning studio - Images which have filename containing square brackets is not shown in outputs folder.",
        "Question_created_time":1610588261997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/229808\/azure-machine-learning-studio-images-which-have-fi",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I am using Azure Machine Learning studio.  <\/p>\n<p>I trained my deep learning model on computing cluster, and then outputs images onto 'outputs' directory.  <br \/>\nHowever, in Experiment &gt; Run &gt; outputs + logs tab, directories was displayed instead of my images.  <\/p>\n<p>Is it possible to get my images from 'outputs' directory?  <\/p>\n<p>After investigation, I recognized that images which have filename containing square brackets is not shown in the tab.  <br \/>\nFor instance, if I created 'outputs\/test[0].jpg', then 'outputs\/test' directory was shown in the tab.  <\/p>\n<p>[Sample code]  <\/p>\n<pre><code>import cv2\nimport numpy as np\nfrom pathlib import Path\n\n# Check whether output directory exists or not\noutput_dir = Path('.\/outputs\/')\nif not output_dir.exists():\n    output_dir.mkdir()\n\n# Generate test image\nIMAGE_SIZE = (28, 28)\n\ntest_image = np.zeros(IMAGE_SIZE)\n\n# Save image with filename which contained \/ not contained square brackets\n# 'test.jpg' and 'test' directory will be shown in the 'outputs' directory, however 'test[].jpg' and 'test[0].jpg' are disappeared.\ncv2.imwrite(str(output_dir \/ 'test.jpg'), test_image)\ncv2.imwrite(str(output_dir \/ 'test[].jpg'), test_image)\ncv2.imwrite(str(output_dir \/ 'test[0].jpg'), test_image)\n<\/code><\/pre>",
        "Question_closed_time":1610646282360,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi, it probably recognizes the square bracket as wildcard. Try using a double-backticks to escape the brackets, otherwise, I recommend you rename without the brackets and train again.  <\/p>\n<pre><code>cv2.imwrite(str(output_dir \/ 'test``[``].jpg'), test_image)\n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"WebserviceException: How to delete an existing service",
        "Question_created_time":1610661593007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/231106\/webserviceexception-how-to-delete-an-existing-serv",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am getting the following error message:  <br \/>\n&quot;WebserviceException: WebserviceException: Message: Service diabetes-service with the same name already exists, please use a different service name or delete the existing service. InnerException None ErrorResponse { &quot;error&quot;: { &quot;message&quot;: &quot;Service diabetes-service with the same name.&quot;  <\/p>\n<p>Please can you help with deleting the service in question?  <\/p>\n<p>Thanks,  <\/p>\n<p>Naveen  <\/p>",
        "Question_closed_time":1610680137287,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello, Naveen. This error message means that in your current AML workspace, there already exists a real-time endpoint(or service) whose name is &quot;diabetes-service&quot;, so you can't deploy a new service with this same name because it will cause duplication.   <\/p>\n<p>You can check your workspace in our portal <a href=\"https:\/\/ml.azure.com\/selectWorkspace\">https:\/\/ml.azure.com\/selectWorkspace<\/a> , in the sidebar you can find a &quot;Endpoints&quot; button, you can find all your &quot;real-time endpoint&quot; there. Then please delete the dup service, after deletion you can deploy your new service with the name &quot;diabetes-service&quot;.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to take a ML Azure Container Instance from the registry and deploy it elsewhere?",
        "Question_created_time":1610554902053,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/229405\/is-it-possible-to-take-a-ml-azure-container-instan",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>I was wondering if it was possible to take a ML Model deployed to a container instance and then take that and deploy that in docker elsewhere.  I have managed to sync a repo with the Azure registry and download the container which was created in Azure ML.  When i started the container though it didn't do anything; i logged into the container and nothing was running; i could start NGINX but wasn't sure if this was a supported?   <\/p>\n<p>I was that you can do this with the Azure Sentiment Analysis Containers but wondering if you could do with ML Azure Container Instances?  <\/p>\n<p>Any pointers would be good.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating Inference CLuster Fails",
        "Question_created_time":1610727778147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/232390\/creating-inference-cluster-fails",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_body":"<p>I am using the portal to create an inference cluster.  All attempts have failed.  I am using the UI, not any template. The error makes no sense to me since I am not using any template.  <\/p>\n<p>FailedFailed  <br \/>\nFailed to get ACR with ID '\/subscriptions\/9de54990-2158-4f98-a0ae-48801ecd5e04\/resourcegroups\/kp-lead-score\/providers\/microsoft.containerregistry\/registries\/kppreprodregistry'.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"check workspace details \/ settings",
        "Question_created_time":1610192562230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224633\/check-workspace-details-settings",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi all,  <\/p>\n<p>I am doing the following exercise: <a href=\"https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/02-automated-ml.html\">https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/02-automated-ml.html<\/a>  <br \/>\nIn step3 this is what I had to do:  <br \/>\n\u2022\tRegion: The same region as your workspace  <br \/>\n\u2022\tVirtual Machine priority: Dedicated  <br \/>\n\u2022\tVirtual Machine type: CPU  <br \/>\n\u2022\tVirtual Machine size: Standard_DS11_v2  <br \/>\n\u2022\tCompute name: enter a unique name  <br \/>\n\u2022\tMinimum number of nodes: 0  <br \/>\n\u2022\tMaximum number of nodes: 2  <br \/>\n\u2022\tIdle seconds before scale down: 120  <br \/>\n\u2022\tEnable SSH access: Unselected  <\/p>\n<p>I think I went a bit too fast and did not check the following:  <br \/>\n\u2022\tMinimum number of nodes: 0  <br \/>\n\u2022\tMaximum number of nodes: 2  <br \/>\n\u2022\tIdle seconds before scale down: 120  <br \/>\n\u2022\tEnable SSH access: Unselected  <\/p>\n<p>How can I check if I selected the correct nodes, idle second and SSH access. Also, if these are not set correctly, how can I change these? I do not want to start again and create a new workspace.  <\/p>\n<p>Thanks,  <\/p>\n<p>Naveen   <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Docker container fails to run due to invalid --GPU switch",
        "Question_created_time":1610298719520,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/225027\/docker-container-fails-to-run-due-to-invalid-gpu-s",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>I have been testing Azure ML experiments running locally on my machine with docker. So far I have run into the same issue using several curated environments as well as using a conda dependencies file.  <\/p>\n<ul>\n<li> The run job is submitted successfully  <\/li>\n<li> Docker container builds successfully   <\/li>\n<li> The docker run command fails due to the --gpu all switch  <\/li>\n<\/ul>\n<p>This switch gets added to every docker container I try to launch locally (doesn't matter the container type).   <\/p>\n<p>I have tested this a few different ways   <\/p>\n<ul>\n<li> Using VScode and VScode insiders  <\/li>\n<li> Running the experiment from code  <\/li>\n<li> Running Experiment the Azure ML Extension in VScode  <\/li>\n<\/ul>\n<p>All attempts end with the docker container failing to run.   <\/p>\n<p>Any thought on how to fix this would be appreciated.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Round columns in Azure ML",
        "Question_created_time":1610454807547,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/227626\/round-columns-in-azure-ml",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have made an experiment in Azure ML with a coefficient of detemination reaching 86% (regression). I would like to improve it using the rounding of several features (columns). I would like to round some columns to &quot;xx-ten&quot; example: 1854 =&gt; 1850 (up and down if possible)  <br \/>\nI have used ceil functions before  to avoid decimal numbers but here this is another case. I cannot see how to do this.  <\/p>\n<p>Can anyone help in this please?  <\/p>\n<p>Kind Regards,  <\/p>\n<p>Mohamed.<\/p>",
        "Question_closed_time":1610574523547,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello Dear,  <\/p>\n<p>Thank you for your advice. I have found in the rounding area the &quot;tomultiple&quot; function where I can decide to round a number to tens, hundreds... (example: tomultiple(2583,10) =&gt; 2580).  <\/p>\n<p>Thank you :)  <\/p>\n<p>Mohamed.  <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Speech to Text, Text to Speech, Speech Translation, PHP AP\u0130 document ?",
        "Question_created_time":1610464220930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/227739\/speech-to-text-text-to-speech-speech-translation-p",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Speech to Text, Text to Speech, Speech Translation We will use the services. I need a php document ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to use a Windows Account for configuring Machine Learning Server 9.4.7?",
        "Question_created_time":1610029811687,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/222486\/is-it-possible-to-use-a-windows-account-for-config",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>After configuring Machine Learning Server with a password, one connects to the server through the user name &quot;admin&quot; and the designated password. Is it possible configure Machine Learning Server to use a Windows Account instead of the default &quot;admin&quot;?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create a Compute Instance",
        "Question_created_time":1609999991360,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/221759\/how-to-create-a-compute-instance",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello Folks,    <\/p>\n<p>I'm currently using a free trial version of Azure.    <\/p>\n<p>When creating a compute instance in machine learning studio, I cannot select a virtual machine.    <br \/>\nAll virtual machine names in the selection field are inactive.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/54196-image.png?platform=QnA\" alt=\"54196-image.png\" \/>    <\/p>\n<p>How are these virtual machines activated?    <\/p>\n<p>I am creating a virtual machine &quot;Standard_D2s_v3&quot;.    <br \/>\nAnd I interpret this capture as showing that there are two available quarters for &quot;Standard DSv3 Family vCPUs&quot;.If so, why is the virtual machine &quot;Standard_D2s_v3&quot; inactive?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/54244-image2.png?platform=QnA\" alt=\"54244-image2.png\" \/>    <\/p>\n<p>I'm sorry for my poor English.    <br \/>\nI very appreciate any help or direction. Thank you.    <\/p>\n<p>Regards,    <br \/>\nKoki    <\/p>",
        "Question_closed_time":1610008313753,
        "Answer_score_count":0.0,
        "Answer_comment_count":6.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=e43e0c55-0c1c-4fc1-a434-caf239469077\">@Koki  <\/a> I think there could be two reasons here for this behaviour.     <\/p>\n<ol>\n<li> The second screen shot could be showing the availability in a different region than your Azure ML workspace region. Please verify if this is the case.    <\/li>\n<li> The Azure ML resource under the free tier has a special exception with regards to the compute that can be used. This is limited based on the available cores and the subscription offering. This is documented <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-compute\">here<\/a> with more details. If this is the case you can raise a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#request-quota-increases\">quota increase<\/a> and our team will evaluate the feasibility based on your subscription offering.     <\/li>\n<\/ol>\n<p>If the above two cases do not resolve you can convert to a pay as you go subscription and use the required compute size with your Azure ML experiments. Thanks!!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"RStudio Server stack limit error",
        "Question_created_time":1609858201667,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/219363\/rstudio-server-stack-limit-error",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm using a free account with a default configuration. I'm trying to get through this tutorial <a href=\"https:\/\/learn.microsoft.com\/pl-pl\/azure\/machine-learning\/tutorial-1st-r-experiment\">https:\/\/learn.microsoft.com\/pl-pl\/azure\/machine-learning\/tutorial-1st-r-experiment<\/a>.    <\/p>\n<p>I encounter the error: C stack usage  &lt;big number&gt; is too close to the limit.    <\/p>\n<p>Because of this, I cannot complete the tutorial. I'm wondering how to solve this issue. Is it about free account limitations like memory and\/or CPU?    <\/p>\n<p>Can anyone help?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to update azure ml webservice",
        "Question_created_time":1601290286423,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/109836\/how-to-update-azure-ml-webservice",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to update azure ml webservice which already deployed with new scoring file . Can you please help me in this , i follow your instruction from <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service<\/a> but i am getting error as AttributeError: 'NoneType' object has no attribute 'lower' (<a href=\"https:\/\/stackoverflow.com\/questions\/63763564\/how-to-update-scoring-py-file-in-deployed-azure-ml-web-services-without-changing\/64095971#64095971\">https:\/\/stackoverflow.com\/questions\/63763564\/how-to-update-scoring-py-file-in-deployed-azure-ml-web-services-without-changing\/64095971#64095971<\/a> ) and i am not able to solve it , can you please help me .?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I orchestrate ML model retraining periodically?",
        "Question_created_time":1610148728983,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224481\/how-do-i-orchestrate-ml-model-retraining-periodica",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have to retrain every month or so a PyTorch Model trained on data obtained from processing tables sitting in Azure Data Lake Storage gen 1.    <\/p>\n<p>So far, I have the following building blocks:    <\/p>\n<ol>\n<li> A Databricks notebook that does the ETL job of transforming the ADLS gen 1 tables into train\/validation files that are written in blob storage    <\/li>\n<li> Python scripts that I can execute locally to run in an AzureML workspace an experiment so to train the PyTorch model using a ScriptRunConfig + training script as in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-pytorch\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-pytorch<\/a> mounting blob to get the training data.     <\/li>\n<\/ol>\n<p>How can I schedule steps 1. and 2. to be run in sequence in a pipeline? Azure Data Factory seems a possible way to go, but what should I use as activities in ADF?    <\/p>\n<p>I see a few alternatives:    <\/p>\n<ol>\n<li> Stays surely a Databricks notebook    <br \/>\n 2a. Databricks python script calling the azureml-sdk classes (?)     <\/li>\n<\/ol>\n<p>Alternative for step 2a could be    <\/p>\n<p>2b. a Batch Service custom activity calling the azureml-sdk classes - seems overkill to me    <br \/>\n2c. use a AzureML execute pipeline as ADF activity <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines<\/a> (not sure how...)    <br \/>\n2d. use a Python script Databricks activity train a PyTorch model with Databricks <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/tracking-ex-pytorch\">https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/tracking-ex-pytorch<\/a> instead of calling the azureml-sdk classes     <\/p>\n<p>Can someone point me to the current best practice for this?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ml for data series in 3 states (stages)",
        "Question_created_time":1610145100317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224370\/azure-ml-for-data-series-in-3-states-(stages)",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello! I am new to using azure ml and I am trying to recreate in azure ml a process that is composed of 3 different states. State 1 influences state 2, state 1 and 2 influence state 3. Indeed I need azure ml to predict what will happen in stage 2, after analyzing stage 1 data, then what will happen in stage 3 after analyzing stage 1 data and 2. I can't find any way to put the data in azure ml in this configuration.If anyone has a suggestion ... it would help me. Thanks in advance for any help.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML time series model inference error during data input (python)",
        "Question_created_time":1609993978043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/221774\/azure-ml-time-series-model-inference-error-during",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I prepared a model for time series forecasting. The data have some rare gaps in all data sets. I am using the following code to call for a deployed Azure AutoML model as a web service:<\/p>\n<pre><code>import requests\nimport json\nimport pandas as pd\n\n# URL for the web service\nscoring_uri = 'http:\/\/xxxxxx-xxxxxx-xxxxx-xxxx.xxxxx.azurecontainer.io\/score'\n\n# Two sets of data to score, so we get two results back\nnew_data = pd.DataFrame([\n            ['2020-10-04 19:30:00',1.29281,1.29334,1.29334,1.29334,1],\n            ['2020-10-04 19:45:00',1.29334,1.29294,1.29294,1.29294,1],\n            ['2020-10-04 21:00:00',1.29294,1.29217,1.29334,1.29163,34],\n            ['2020-10-04 21:15:00',1.29217,1.29257,1.29301,1.29115,195]],\n            columns=['1','2','3','4','5','6']        \n)\n# Convert to JSON string\ninput_data = json.dumps({'data': new_data.to_dict(orient='records')})\n\n# Set the content type\nheaders = {'Content-Type': 'application\/json'}\n\n# Make the request and display the response\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>I am getting an error:<\/p>\n<pre><code>{\\&quot;error\\&quot;: \\&quot;DataException:\\\\n\\\\tMessage: No y values were provided. We expected non-null target values as prediction context because there is a gap between train and test and the forecaster depends on previous values of target. If it is expected, please run forecast() with ignore_data_errors=True. In this case the values in the gap will be imputed.\\\\n\\\\tInnerException: None\\\\n\\\\tErrorResponse \\\\n{\\\\n\n<\/code><\/pre>\n<p>I tried to add &quot;ignore_data_errors=True&quot; to different parts of the code without a success, hence, getting another error:<\/p>\n<pre><code>TypeError: __init__() got an unexpected keyword argument 'ignore_data_errors'\n<\/code><\/pre>\n<p>I would very much appreciate any help as I am stuck at this.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AutoML automatic data preprocessing?",
        "Question_created_time":1610102782470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/223781\/automl-automatic-data-preprocessing",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I used a dataset that contains missing values, and Auto ML reached over 90% accuracy. I am curious how Auto ML dealt with missing values and if there is a way to retrieve the preprocessed dataset that Auto ML created? Or does it ignore rows with missing data?  <\/p>\n<p>Additionally, I selected &quot;enable deep learning&quot; when creating my Auto ML instance, but when I look at the models tried after the process completes, I do not see deep learning models have been tried. Why is that? I see random forest, LightGBM, XG boost, but no deep neural nets.  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there any way to print auto ml rank value?",
        "Question_created_time":1610014966120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/222271\/is-there-any-way-to-print-auto-ml-rank-value",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>\uc624\ud1a0ml \uc0ac\uc6a9\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.   <br \/>\n\uacb0\uacfc\uac12\uc744 \ub192\uc740 \ud655\ub960\uc21c\uc73c\ub85c  <br \/>\n1\uc21c\uc704 \uacb0\uacfc\uac12, 2\uc21c\uc704 \uacb0\uacfc\uac12, 3\uc21c\uc704 \uacb0\uacfc\uac12\uc73c\ub85c \ucd9c\ub825\ud558\uace0 \uc2f6\uc740\ub370  <br \/>\n\uc624\ud1a0ml\ub85c\ub294 1\uc21c\uc704 \uacb0\uacfc\uac12\ub9cc \ucd9c\ub825\uc774 \ub429\ub2c8\ub2e4.  <br \/>\n\uc5ec\ub7ec \uc21c\uc704\ub97c \ucd9c\ub825\ud558\ub294 \ubc29\ubc95\uc740 \uc5c6\uc744\uae4c\uc694??  <\/p>\n<hr \/>\n<p><strong>Translated from Korean to English:<\/strong>  <\/p>\n<p>I am using auto ml.  <br \/>\nResults in order of high probability  <br \/>\nI want to print the first result value, the second order result value, and the third order result value.  <br \/>\nWith auto ml, only the first priority result is output.  <br \/>\nIs there any way to print multiple ranks??  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does the \"Estimated monthly costs\" for Azure Machine Learning in the Price Calculator include all other non-compute \"additional resources\" created in the workspace",
        "Question_created_time":1609267518950,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/213635\/does-the-estimated-monthly-costs-for-azure-machine",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>When trying to use the Azure Pricing estimate in the Azure Pricing Calculator, the &quot;Estimated monthly costs&quot; seems to include but also far exceeds the compute cost.  Does this Estimated Monthly cost include the other resources that get created?     <br \/>\neg. Azure Container Registry Basic account, Azure Block Blob Storage (general purpose v1), Key Vault    <\/p>\n<p>Thank you    <br \/>\nPeter    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/52085-image.png?platform=QnA\" alt=\"52085-image.png\" \/>    <\/p>",
        "Question_closed_time":1609285909057,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi Peter.    <\/p>\n<p>Thanks for reaching out. I tried your selections but I don't have the same service as you. Have you selected other services in you calculator?     <\/p>\n<p>For your question, the estimated price is only for Azure Machine Learning Service. You need to select all services you need in the calculator like below:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/51998-image.png?platform=QnA\" alt=\"51998-image.png\" \/>    <\/p>\n<p>Please note I only use random number for the example.     <\/p>\n<p><strong>From the number I guess you have selected 2 Machine Learning Services and also other services since they added to your basket when you clicked them,<\/strong> you can click the button to see what you have all as below.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/51969-image.png?platform=QnA\" alt=\"51969-image.png\" \/>    <\/p>\n<p>Also you are selecting Reservation service, detail: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/reservations\/save-compute-costs-reservations\">https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/reservations\/save-compute-costs-reservations<\/a>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Data Labeling not accesible after Transfer billing ownership",
        "Question_created_time":1609967334840,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/221503\/data-labeling-not-accesible-after-transfer-billing",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I transferred the billing ownership of my azure directory, and now I have not access to the ML data labeling project.    <\/p>\n<p>Everything works fine in the destination account, but the data labeling project that was in progress.     <\/p>\n<p>If I create a new data labeling project using the same Datastore, It will work; I can label images as usual. But the original project will not work, I can even open the project but in the moment I try to &quot;Label Data&quot;, it says I don't have permissions.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/54097-image.png?platform=QnA\" alt=\"54097-image.png\" \/>    <br \/>\nThis error pops up even using the owner user.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Data input format (call the service) for Azure ML time series forecast model deployed as a web service (Python)",
        "Question_created_time":1609733310997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-(call-the-service)-for-azure-ml",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Sorry in advance for the lengthy question as I wanted to explain it as detailed as possible. I used the Azure AutoML to train a model and deployed it as a web service. Now I can access (call) it over the REST endpoint.    <\/p>\n<p>I have the following data types for attributes: date (timestamp), number, number, number, number, integer. I trained the model with the following parametres:    <\/p>\n<p>Timestaps interval: 15 min    <br \/>\nForecast Horizon: 4 (I need the forecast every hour for the next hour)    <br \/>\nTarget rolling window size: 96 (the forecast must ba based on the last 24 hours of data)    <\/p>\n<p>I have two questions.    <\/p>\n<ol>\n<li> As I understand, based on the above, I have to provide last 4 entries to the model for a correct prediction. Otherwise, it will consider a time gap. Am I right? In this case, how I could input 4 instances at a time for a single prediction? The following example is wrong as it asks for 4 predictions for each instance:        import requests  <br \/>\n    import json  <h1 id=\"url-for-the-web-service--\">URL for the web service  <\/h1>\n    scoring_uri = 'http:\/\/xxxxx-xxxxxxx-xxxxxx-xxxxxxx.xxxxx.azurecontainer.io\/score'      data = {&quot;data&quot;:  <br \/>\n            [  <br \/>\n                [  <br \/>\n                    2020-10-04 19:30:00,1.29281,1.29334,1.29334,1.29334,1  <br \/>\n                ],  <br \/>\n                [  <br \/>\n                    2020-10-04 19:45:00,1.29334,1.29294,1.29294,1.29294,1  <br \/>\n                ],  <br \/>\n                [  <br \/>\n                    2020-10-04 21:00:00,1.29294,1.29217,1.29334,1.29163,34  <br \/>\n                ],  <br \/>\n                [  <br \/>\n                    2020-10-04 21:15:00,1.29217,1.29257,1.29301,1.29115,195]  <br \/>\n            ]  <br \/>\n            }  <h1 id=\"convert-to-json-string--\">Convert to JSON string  <\/h1>\n    input_data = json.dumps(data)  <h1 id=\"set-the-content-type--\">Set the content type  <\/h1>\n    headers = {'Content-Type': 'application\/json'}  <h1 id=\"make-the-request-and-display-the-response--\">Make the request and display the response  <\/h1>\n    resp = requests.post(scoring_uri, input_data, headers=headers)  <br \/>\n    print(resp.text)  <\/li>\n<\/ol>\n<p>The above code is based on the provided Microsoft example <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python<\/a>.    <\/p>\n<ol start=\"2\">\n<li> I am unable to replicate the provided example with my data. I have an error &quot;SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers&quot; pointing to the date. I assume, I need to specify the data type but could not find how.    <br \/>\nI tried to load a line from a csv file but I have an error (SyntaxError: invalid syntax) pointing to &quot;with&quot; with the following:        data = {&quot;data&quot;:  <br \/>\n            [with open('<em>file<\/em>', &quot;r&quot;) as f:  <br \/>\n                for line in f: pass  <br \/>\n                print(line)]  <br \/>\n            }  <\/li>\n<\/ol>\n<p>I tested getting the last line from a csv file intependetly and it works but not inside the full script.    <\/p>\n<p>I very appreciate any help or direction. Thank you.    <\/p>",
        "Question_closed_time":1609796508693,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=bb489438-223a-4580-a123-7535213f9c71\">@Alexey Pisakov  <\/a>     <br \/>\nPlease try the solution mentioned below.    <\/p>\n<p>The service takes data in form of deserialized pandas data frame. In the example below, it will look like:    <br \/>\nimport json    <\/p>\n<p>X_test = pd.DataFrame([    <\/p>\n<pre><code>['2020-10-04 19:30:00', 1.29281, 1.29334, 1.29334, 1.29334, 1],  \n\n['2020-10-04 19:45:00', 1.29334, 1.29294, 1.29294, 1.29294, 1],  \n\n['2020-10-04 21:00:00', 1.29294, 1.29217, 1.29334, 1.29163, 34],  \n\n['2020-10-04 21:15:00', 1.29217, 1.29257, 1.29301, 1.29115, 195]],  \n\ncolumns=['date', 'number_1', 'number_2', 'number_3', 'number_4', 'integer']  \n<\/code><\/pre>\n<p>)    <\/p>\n<p>test_sample = json.dumps({'data': X_test.to_dict(orient='records')})    <\/p>\n<p>test_sample    <\/p>\n<p>Which will result in JSON string as:    <\/p>\n<p>{&quot;data&quot;: [{&quot;date&quot;: &quot;2020-10-04 19:30:00&quot;, &quot;number_1&quot;: 1.29281, &quot;number_2&quot;: 1.29334, &quot;number_3&quot;: 1.29334, &quot;number_4&quot;: 1.29334, &quot;integer&quot;: 1}, {&quot;date&quot;: &quot;2020-10-04 19:45:00&quot;, &quot;number_1&quot;: 1.29334, &quot;number_2&quot;: 1.29294, &quot;number_3&quot;: 1.29294, &quot;number_4&quot;: 1.29294, &quot;integer&quot;: 1}, {&quot;date&quot;: &quot;2020-10-04 21:00:00&quot;, &quot;number_1&quot;: 1.29294, &quot;number_2&quot;: 1.29217, &quot;number_3&quot;: 1.29334, &quot;number_4&quot;: 1.29163, &quot;integer&quot;: 34}, {&quot;date&quot;: &quot;2020-10-04 21:15:00&quot;, &quot;number_1&quot;: 1.29217, &quot;number_2&quot;: 1.29257, &quot;number_3&quot;: 1.29301, &quot;number_4&quot;: 1.29115, &quot;integer&quot;: 195}]}    <\/p>\n<p><strong>Please rename the columns to the corresponding columns from the training data set.<\/strong>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to deploy a keras or tensorflow model on iot edge and inference using onnx runtime?",
        "Question_created_time":1608665108717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/207778\/how-to-deploy-a-keras-or-tensorflow-model-on-iot-e",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have developed a classification model in keras. I wish to deploy this model onto iot edge device.How can I inference this model using onnx runtime..How to write the scoring script.Is there any good source to refer the same?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Choice of Azure technology for a backend system - Azure newcomer",
        "Question_created_time":1608401528893,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/204380\/choice-of-azure-technology-for-a-backend-system-az",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I would like to use Azure to:  <\/p>\n<ol>\n<li> Run a server\/service (in a broad sense) issuing HTTP\/REST API requests to an online resource (think: Twitter) - probably not event-based, but rather periodically (e.g. every 5 minutes)  <\/li>\n<li> Have the retrieved data in 1. being processed for some custom analytics (think: some statistics\/ML written in Python and ran on tweets). I'm not sure yet whether the unprocessed data should be stored, or if I will decide to process\/analyze them on the fly, and drop the &quot;raw&quot; input immediately afterwards  <\/li>\n<li> Store the &quot;analytics&quot; result in some (probably relational) database for further use  <\/li>\n<\/ol>\n<p>where all of the above should be &quot;in the cloud&quot;. Given the abundance of options\/solutions in Azure, to which I'm new, what would be the names\/keywords\/technologies that I should read upon or google to get things started with my architecture?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is onnx the best way to deal with azure iot edge Machine Learning models?",
        "Question_created_time":1609255835060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/213450\/is-onnx-the-best-way-to-deal-with-azure-iot-edge-m",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I am working on Azure IOT Edge. I have three models.  <br \/>\na)yolov3 object detection model in .weights format  <br \/>\nb)Resnet classfication model   <br \/>\nc)VGG16 classification model in .h5 format.  <\/p>\n<p>I converted them to onnx and using onnx runtime inferenced them and wrote the necessary scoring scripts.  <\/p>\n<p>I wanted to know how do I use these models in original format without converting them to onnx or is onnx the best way for iot edge modules?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I have been searching the documentation and cannot find this answer. Is every module in the Azure ML designer available in the Python SDK that lists the pipelines created and trigger with script",
        "Question_created_time":1609736281147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/217362\/i-have-been-searching-the-documentation-and-cannot",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an Azure ML pipeline created with designer utilities from the portal. I want to schedule the retraining by changing the input folder from the python script and try to automate it.  <\/p>\n<p>I have searched the documentation and unable to find the answer.plz help<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MLOps using Azure Databricks & Azure ML - question on data prep for model inference and retraining.",
        "Question_created_time":1607958581913,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/197618\/mlops-using-azure-databricks-azure-ml-question-on",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I am using this blog (<a href=\"https:\/\/databricks.com\/blog\/2020\/10\/13\/using-mlops-with-mlflow-and-azure.html\">https:\/\/databricks.com\/blog\/2020\/10\/13\/using-mlops-with-mlflow-and-azure.html<\/a>) to set-up MLOps using Azure Databricks &amp; Azure ML. As mentioned in the blog, we deploy MLflow model into an Azure ML environment using the built in MLflow deployment capabilities, which is used for inference. A couple of questions -   <\/p>\n<ol>\n<li> How and where does the data prep come into picture before inference and how I can integrate that piece.   <\/li>\n<li> How to create a re-training workflow for the model?  <\/li>\n<\/ol>\n<p>Thanks.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Split Datasets on Auto ML",
        "Question_created_time":1609436368370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/215623\/split-datasets-on-auto-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi! On Azure AutoML with the UI there is no way to split our dataset automatically between train\/test sets. This is crucial and the docs don't reference it. How can we do it? Can we fix the docs?  <\/p>\n<p>Also, there is no clear way to use the Explainability runs with forecast models with the No-Code solution, which is crucial too! And how to evaluate our models in a final set to check overfitting.  <\/p>\n<p>Finally, being able to check the learning curves would be useful too!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Question_created_time":1607093437353,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/186789\/does-automl-support-optimizing-convolutional-neura",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?<\/p>",
        "Question_closed_time":1607117314597,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>AutoML doesn't currently support CNNs publicly, it's on our roadmap and it will come with optimizations across different parameters, so stay tuned. Hope this helps.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why my testing always failed in Custom Speech?",
        "Question_created_time":1608793221783,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/209520\/why-my-testing-always-failed-in-custom-speech",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/50990-%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20201224145449.jpg?platform=QnA\" alt=\"50990-%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20201224145449.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model path for a model folder that has json file and weights.",
        "Question_created_time":1608489600887,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/204868\/model-path-for-a-model-folder-that-has-json-file-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to create a score.py file for model deployment. In the folder where the model is present, there are two files present. One is the JSON model file another is a .h5 file which has weights of the model. how do I configure the file in this case in the init function of the score.py file?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating a New linked service (Azure Machine Learning)",
        "Question_created_time":1608828206490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/210152\/creating-a-new-linked-service-(azure-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am getting this below error  <\/p>\n<p>Request sent to Azure ML Service for operation 'validateWorkspace' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{&quot;error&quot;:{&quot;code&quot;:&quot;AuthorizationFailed&quot;,&quot;message&quot;:&quot;The client 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' with object id 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' does not have authorization to perform action 'Microsoft.MachineLearningServices\/workspaces\/read' over scope '\/subscriptions\/f9f0926a-ab30-492e-8951-e0b88e6da187\/resourceGroups\/machinelearning_rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ml_workspace' or the scope is invalid. If access was recently granted, please refresh your credentials.&quot;}}'. Activity ID: 81e99656-f46a-4375-a7de-6b4fe925c5d5.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Types of Regression Algorithm",
        "Question_created_time":1608719172483,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/208685\/types-of-regression-algorithm",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>What are the types of Regression algorithm? Are there any kinds of regression called &quot;non-linear regression&quot;?<\/p>",
        "Question_closed_time":1608817848270,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=4bd5b942-e3cc-4aa2-8ef5-03d77bfd1721\">@Sanniddha Chakrabarti  <\/a> Please follow the below document for Regression.    <br \/>\n<a href=\"https:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/comprehensive-guide-regression\/#:%7E:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables\">https:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/comprehensive-guide-regression\/#:~:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables<\/a>.    <\/p>\n<p>Types of Regressions:    <br \/>\nLinear Regression    <br \/>\nLogistic Regression    <br \/>\nPolynomial Regression    <br \/>\nStepwise Regression    <br \/>\nRidge Regression    <br \/>\nLasso Regression    <br \/>\nElasticNet Regression    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"different results in clustering",
        "Question_created_time":1608744570720,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/209102\/different-results-in-clustering",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>One of the disadvantage of clustering is the result can be different, because it randomly selects the initial mean point. It should impact on the time to take complete the clustering, but how it effects on the result?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"advantage of neural network",
        "Question_created_time":1608746288657,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/208999\/advantage-of-neural-network",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>One advantage of neural network is it can take thousands of attributes. But we can take thousands of attributes in any algorithm. So, why it  is the advantage of neural network only, why not for other algorithms?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"regression model",
        "Question_created_time":1608745621877,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/209043\/regression-model",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Why we can't draw line (like jig jag line) which connect all the data points, in case of regression. Why we draw straight line?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Advantage of clustering algorithm",
        "Question_created_time":1608719822847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/208687\/advantage-of-clustering-algorithm",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We don't need the name of attributes in clustering, so, if I do not know my attribute names how can I understand that which data should I enter and also if I do not know the name of the attributes how can I give the axis name of the plotted graph? If it is the advantage of clustering algorithm, then why it is not the advantage of other algorithms, because if we do not know the name of the attributes  we can create our models because if we have attribute values that is enough, but why we need attribute names too in other algorithms? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Advantage of decession tree",
        "Question_created_time":1608720679863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/208727\/advantage-of-decession-tree",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>One of the advantage of the decision trees is that it ignore outliers. But how outliers come in the sense in case of decision trees. Because decision trees  use a set of data like humidity, month, etc. It not uses the data like temperature, population, distance, etc. In this example how outliers can happen ?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/50750-screenshot-2020-12-23-162024.jpg?platform=QnA\" alt=\"50750-screenshot-2020-12-23-162024.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment creates local compute target, but shouldn't.",
        "Question_created_time":1608483356530,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/204932\/experiment-creates-local-compute-target-but-should",
        "Question_score_count":2,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I'm new to Azure and following a course on Udacity. In one of the assignments I need to create a grid search using Hyperdrive, and that part works fine. It runs and I get the results. Every time it attaches my compute target as it should but it also creates a local compute target which keeps running after all the runs have finished. The code is run in Jupyter and the local compute target gets created when I run my first block of code:    <\/p>\n<pre><code>from azureml.core import Workspace, Experiment  \n  \nws = Workspace.get(name=&quot;Michaels_test1&quot;)  \nexp = Experiment(workspace=ws, name=&quot;udacity-pipeline&quot;)  \n  \nprint('Workspace name: ' + ws.name,   \n      'Azure region: ' + ws.location,   \n      'Subscription id: ' + ws.subscription_id,   \n      'Resource group: ' + ws.resource_group, sep = '\\n')  \n  \nrun = exp.start_logging()  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/49734-local-2020-12-15-141139.png?platform=QnA\" alt=\"49734-local-2020-12-15-141139.png\" \/>    <\/p>\n<p>As far as I know it shouldn't create a local compute target and it also prevents me from running the rest of my jupytercode because I waits for the experiment to finish, which it never does because the local compute target keeps running.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get Azure Machine Learning Service Workspace details based on Logged in User",
        "Question_created_time":1608547741557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/205737\/how-to-get-azure-machine-learning-service-workspac",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi there,    <\/p>\n<p>This document page <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/workspaces\">https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/workspaces<\/a> page describes how we can retrieve (Get function) Workspace details based on the subscription.    <\/p>\n<p>I am interested to get similar Workspace details based on the logged user. Please let me know how I can achieve it.    <\/p>\n<p>Thanks,    <br \/>\nHamsini Sharma<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Importing Libraries in Azure ML Designer",
        "Question_created_time":1608525858523,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/205209\/importing-libraries-in-azure-ml-designer",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Is it possible to Install and import libraries in Azure ML designer? Because i dont see kernal available in designer like the notebook.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to add multiple csv's as .zip file new Azure Machine Learning Designer (Non-Classic)",
        "Question_created_time":1608479520287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/204887\/how-to-add-multiple-csvs-as-zip-file-new-azure-mac",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In classic mode there was option of adding multiple csv files zipped into a folder and uploaded into the Azure ML studio (classic). I want to achieve the same in the new Azure Machine Learning designer (non-classic) but I don't see the option of upload .zip file.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/49733-image.png?platform=QnA\" alt=\"49733-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compute Clusters in Azure ML Notebook",
        "Question_created_time":1608276696563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/203139\/compute-clusters-in-azure-ml-notebook",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I created a compute cluster in Azure ML and  I am able to see it in designer but not in the notebook. Can someone let me know the reason for this?<\/p>",
        "Question_closed_time":1608293911593,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c0af539e-5b19-433b-85a1-2ca81772cd40\">@Srinivasan G  <\/a> This is an expected behavior while using notebooks on Azure ML portal. Compute clusters are used to train models and run experiments using the designer or pipelines. These cannot be used with notebooks.     <br \/>\nNotebooks are integrated to run on an <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#notebookvm\">compute instance<\/a> which was previously termed as notebook VM. You can start\/stop the compute instance while using your notebook from Azure ML portal.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Error: Incremental refresh of labeling project",
        "Question_created_time":1607952473720,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/197548\/error-incremental-refresh-of-labeling-project",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects#--configure-incremental-refresh\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects#--configure-incremental-refresh<\/a>    <\/p>\n<p>States incremental refresh picks up new data every 24h.     <br \/>\nTested this on a cat\/dog dataset.    <\/p>\n<p>First added 3 pictures of dogs in a dataset. Created classification labeling project, with incremental refresh enabled. Labeled 2 images. Updated dataset with 3 images of cats. confirmed updated dataset version ID is used on labeling project. <strong>However, images of cats are not included in the labeling project.<\/strong>    <\/p>\n<p>Any help?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to run a basic pipeline that summarizes the dataset.",
        "Question_created_time":1608270119370,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/203047\/unable-to-run-a-basic-pipeline-that-summarizes-the",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to run some basic pipeline in Azure ML Workspace using the Trial account.  <\/p>\n<p>Just use an example data and summarize the data.  <\/p>\n<p>But, when I run the pipeline, it stays forever in &quot;Not Started&quot; status despite of assigning descent Compute resources and making sure that Compute resources are running.  <br \/>\nAfter a while the run eventually fails with following error...  <\/p>\n<p>UserError: Number of retries is exceeded the max count: 10, last error: Failure in GetDataStoreDto while calling service DataStoreClient; HttpMethod: GET; Response StatusCode: NotFound; Exception type: Microsoft.RelInfra.Extensions.HttpRequestDetailException  <\/p>\n<p>What does it mean?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to edit skipped images?",
        "Question_created_time":1608134707420,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/200882\/is-there-a-way-to-edit-skipped-images",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>My team is using the Azure data labeling tool and in our current workflow, we sometimes skip an annotation because there is nothing to annotate.  <br \/>\n(We are missing global tags btw!)  <\/p>\n<p>Is there a way to unskip an image? I've been looking at the storage account of the ML instance, but found nothing.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Migrate models from Azure Machine Learning Studio (classic) v1 to Azure Machine Learning Studio v2",
        "Question_created_time":1601619807160,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/114944\/migrate-models-from-azure-machine-learning-studio",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Is it possible to migrate models created in Azure ML studio (classic) to Azure ML studio v2?  <\/p>\n<p>Can I move my models from v1 to v2 in an easy way?  <\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":1602438917847,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello Helena,  <\/p>\n<p>Thanks for your waiting. There is not a tool for auto-migration from V1 to V2 for now and future since the architecture of studio(classic) and machine learning studio is totally different. So I don't think it's easy to migrate. But we will have plan for migration in next few month, there should be a way to migrate from studio(classic) to machine learning studio with effort.   <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Can't run a basic model in Azure ML",
        "Question_created_time":1607553548183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/192735\/cant-run-a-basic-model-in-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm new to Azure Machine Learning, so I'm trying some tutorials on a free trial account.    <\/p>\n<p>None of the tutorials I've followed is running on my account, not even the most basic ones.    <\/p>\n<p>For example, the &quot;Flight Delay Prediction&quot; is running for several hours and then frustratingly it fails....    <\/p>\n<p>This is how the designer looks like:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/46744-image.png?platform=QnA\" alt=\"46744-image.png\" \/>    <\/p>\n<p>Does this make sense?     <br \/>\nCan anyone help?    <\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Register a dataset as model in azure",
        "Question_created_time":1607946981470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/197584\/register-a-dataset-as-model-in-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How is it possible to register a dataset or blob container directly as a model?   <\/p>\n<p>At the moment I have built a pipeline that outputs my trained models and registers them as datasets. I want to perform inference by deploying the models to for example AKS.   <\/p>\n<p>At the moment it appears the only way to register a model is by first downloading the dataset. Note I cannot register the model based on the runID because my model output is saved directly to blob storage through OutputFileDatasetConfig.  <\/p>\n<p>The motivation here is to avoid having to download and then upload large models. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML studio (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly)",
        "Question_created_time":1607923602410,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/197005\/azure-ml-studio-(error-0009-exception-occurs-when",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>I have tried to connect Azure blob and Azure ML studio but am facing following error (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly).  <\/p>\n<p>Tried out some solution as suggested by Microsoft . However we were facing the same issue again.   <\/p>\n<p>Could you please help me on this.  <\/p>\n<p>Thanks,  <br \/>\nCharles  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem when launching a child run on AzureML",
        "Question_created_time":1602870917083,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/129324\/problem-when-launching-a-child-run-on-azureml",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Got a error when trying to launch child runs from a pipeline step.<\/p>\n<p>In pipeline step I have this:<\/p>\n<pre><code>import argparse\nfrom azureml.core import Run, ScriptRunConfig\nfrom azureml.core.model import Model\nfrom azureml.core.environment import Environment\n\nrun = Run.get_context()\ncompute_target = run.experiment.workspace.compute_targets[run.get_details()['target']]\n\nparser = argparse.ArgumentParser(&quot;args&quot;)\nparser.add_argument(&quot;--train_path&quot;, type=str, help=&quot;train_path&quot;)\nparser.add_argument(&quot;--test_path&quot;, type=str, help=&quot;test_path&quot;)\nargs = parser.parse_args()\n\nchild_config_xgboost = ScriptRunConfig(\n    source_directory=&quot;.&quot;,\n    script='xgboost_model.py',\n    arguments=['--train_path', args.train_path, &quot;--test_path&quot;, args.test_path],\n    compute_target=compute_target,\n    environment=run.get_environment()\n)\n\nchild_xgboost=run.submit_child(child_config_xgboost)\nchild_xgboost.wait_for_completion()\n<\/code><\/pre>\n<p>I receive this error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;train.py&quot;, line 7, in &lt;module&gt;\n    compute_target = run.experiment.workspace.compute_targets[run.get_details()['target']]\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/workspace.py&quot;, line 1009, in compute_targets\n    compute_target.name: compute_target for compute_target in ComputeTarget.list(self)}\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/compute.py&quot;, line 535, in list\n    env_obj = child.deserialize(workspace, env)\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py&quot;, line 638, in deserialize\n    target._initialize(workspace, object_dict)\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py&quot;, line 130, in _initialize\n    status.created_by_user_org)\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py&quot;, line 947, in _get_user_display_name\n    headers = {&quot;Authorization&quot;: &quot;Bearer &quot; + workspace._auth._get_graph_token()}\n  File &quot;\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/authentication.py&quot;, line 1455, in _get_graph_token\n    raise AuthenticationException(&quot;AzureMLTokenAuthentication._get_graph_token &quot;\nUserScriptException: UserScriptException:\n Message: AzureMLTokenAuthentication._get_graph_token not yet supported.\n InnerException AuthenticationException:\n Message: AzureMLTokenAuthentication._get_graph_token not yet supported.\n InnerException None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Authentication&quot;\n        },\n        &quot;message&quot;: &quot;AzureMLTokenAuthentication._get_graph_token not yet supported.&quot;\n    }\n}\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;AzureMLTokenAuthentication._get_graph_token not yet supported.&quot;\n    }\n}\n<\/code><\/pre>\n<p>How can I launch a child run using a ScriptRunConfig with the same environment and compute target as the parent run?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Data Factory : How to pass DataPath as a parameter to Azure ML Pipeline activity?",
        "Question_created_time":1599771191990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/91785\/azure-data-factory-how-to-pass-datapath-as-a-param",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hello All,  <\/p>\n<p>How to pass a Datapath as a parameter in Azure ML Pipeline activity?   <\/p>\n<p>More details here : Have opened an issue here : <a href=\"https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216\">https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216<\/a>  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":1601023399257,
        "Answer_score_count":1.0,
        "Answer_comment_count":8.0,
        "Answer_body":"<p>Thanks <a href=\"\/users\/na\/?userid=1e1dfdb6-a824-42dc-8b1c-8e2c3f669d59\">@Sriram Narayanan  <\/a> for your patience!    <\/p>\n<p>I discussed with the Product team and they confirmed that there is no datatype supported for &quot;DataPath&quot; parameter today in Azure Data Factory(ADF). However, there is a feature already raised for the same and work is in progress for it.     <\/p>\n<p>I would recommend you also to submit an idea in <a href=\"https:\/\/feedback.azure.com\/forums\/270578-data-factory\">feedback forum<\/a>. The ideas in this forum are closely monitored by data factory product team and will prioritize implementing them in future releases.    <\/p>\n<p>Sorry for the inconvenience!     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why does Azure AutoML TargetLag featurization use so much memory? Is this a bug?",
        "Question_created_time":1607045489347,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/185758\/why-does-azure-automl-targetlag-featurization-use",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to train a time series forecast model using Azure AutoML. My data set has three series each with two years of hourly data. The whole csv file of training data is less than 2MB. My compute cluster is using D2V2 machines with 7GB of ram. If I configure the training with three target lags, the training run fails to get under way. It seems like there may be a bug. Can someone take a look at the stack trace below and confirm?<\/p>\n<p>This is the error in the log:<\/p>\n<pre><code>2020-12-04 00:06:04,486|azureml.WorkerPool|ERROR|&lt;class '__main__.UserScriptException'&gt;: UserScriptException:\n    Message: There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.\n    InnerException ResourceException:\n    Message: There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.\n    InnerException: MemoryError: cannot allocate memory for array\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/azurevmsizes&quot;,\n        &quot;target&quot;: &quot;Skipping setup\/featurization run split. Beginning full featurization logic.&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;ResourceExhausted&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;Memory&quot;\n            }\n        },\n        &quot;reference_code&quot;: &quot;791a2bd3-4812-407f-91f7-1f8a5a0b0f5a&quot;\n    }\n}\n<\/code><\/pre>\n<p>I found the error stack trace in another log:<\/p>\n<pre><code>raceback:\n  File &quot;telemetry_activity_logger.py&quot;, line 57, in _log_activity\n    yield\n  File &quot;utilities.py&quot;, line 177, in _transform_and_validate_input_data\n    feature_sweeping_config=feature_sweeping_config,\n  File &quot;contextlib.py&quot;, line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File &quot;telemetry_activity_logger.py&quot;, line 81, in _log_activity\n    raise e.with_traceback(e.__traceback__)\n  File &quot;telemetry_activity_logger.py&quot;, line 57, in _log_activity\n    yield\n  File &quot;utilities.py&quot;, line 177, in _transform_and_validate_input_data\n    feature_sweeping_config=feature_sweeping_config,\n  File &quot;data_transformation.py&quot;, line 529, in complete_featurization\n    fault_verifier=verifier\n  File &quot;data_transformation.py&quot;, line 1048, in _get_ts_transformer_x\n    x_transform = tst.fit_transform(x, y)\n  File &quot;logging_utilities.py&quot;, line 300, in debug_log_wrapped\n    r = f(self, *args, **kwargs)\n  File &quot;timeseries_transformer.py&quot;, line 1475, in fit_transform\n    transformed = self.transform(X, y)\n  File &quot;logging_utilities.py&quot;, line 300, in debug_log_wrapped\n    r = f(self, *args, **kwargs)\n  File &quot;timeseries_transformer.py&quot;, line 1374, in transform\n    transformed_data = self._fit_columns_order()\n  File &quot;timeseries_transformer.py&quot;, line 1260, in _fit_columns_order\n    self._known_train_part, self._known_train_part.ts_value.values)\n  File &quot;forecasting_pipeline.py&quot;, line 390, in fit_transform\n    X, y, **fit_params)\n  File &quot;forecasting_pipeline.py&quot;, line 284, in execute_pipeline_op\n    Xt, fit_params = self.__execute_pipeline__preprocess_fit(X, y, **fit_params)\n  File &quot;forecasting_pipeline.py&quot;, line 320, in __execute_pipeline__preprocess_fit\n    return self._pipeline._fit(X, y, **fit_params)\n  File &quot;pipeline.py&quot;, line 315, in _fit\n    **fit_params_steps[name])\n  File &quot;memory.py&quot;, line 355, in __call__\n    return self.func(*args, **kwargs)\n  File &quot;pipeline.py&quot;, line 728, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File &quot;logging_utilities.py&quot;, line 300, in debug_log_wrapped\n    r = f(self, *args, **kwargs)\n  File &quot;lag_lead_operator.py&quot;, line 904, in fit_transform\n    rv = super(LagLeadOperator, self).fit_transform(X, y, **fit_params)  # type: TimeSeriesDataFrame\n  File &quot;base.py&quot;, line 574, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File &quot;logging_utilities.py&quot;, line 300, in debug_log_wrapped\n    r = f(self, *args, **kwargs)\n  File &quot;lag_lead_operator.py&quot;, line 882, in transform\n    left_index=True, right_index=True)\n  File &quot;time_series_data_frame.py&quot;, line 2389, in merge\n    copy=copy, indicator=indicator)\n  File &quot;frame.py&quot;, line 7349, in merge\n    validate=validate,\n  File &quot;merge.py&quot;, line 83, in merge\n    return op.get_result()\n  File &quot;merge.py&quot;, line 642, in get_result\n    join_index, left_indexer, right_indexer = self._get_join_info()\n  File &quot;merge.py&quot;, line 859, in _get_join_info\n    (left_indexer, right_indexer) = self._get_join_indexers()\n  File &quot;merge.py&quot;, line 838, in _get_join_indexers\n    self.left_join_keys, self.right_join_keys, sort=self.sort, how=self.how\n  File &quot;merge.py&quot;, line 1312, in _get_join_indexers\n    lkey, rkey, count = fkeys(lkey, rkey)\n  File &quot;merge.py&quot;, line 1902, in _factorize_keys\n    llab = rizer.factorize(lk)\n  File &quot;hashtable.pyx&quot;, line 122, in pandas._libs.hashtable.Int64Factorizer.factorize\n  File &quot;hashtable_class_helper.pxi&quot;, line 1222, in pandas._libs.hashtable.Int64HashTable.get_labels\n  File &quot;hashtable_class_helper.pxi&quot;, line 1148, in pandas._libs.hashtable.Int64HashTable._unique\n  File &quot;hashtable_class_helper.pxi&quot;, line 201, in pandas._libs.hashtable.Int64Vector.resize\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to fail an Azure ML run?",
        "Question_created_time":1607609097120,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/193802\/how-to-fail-an-azure-ml-run",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>We are using Azure ML for large tests to facilitate testing our code on CUDA in an automated manner. Things work mostly well, but one thing we cannot figure out is how to fail a job such that the job failure     <\/p>\n<ol>\n<li> shows in the UI as Failed (see snapshot),     <\/li>\n<li> gets propagated back to the submitting client (our testing code) such that we can fail the test when the Run has reached failed state.    <\/li>\n<\/ol>\n<p>Here's what we tried:    <\/p>\n<ul>\n<li> Exit the run process with a non-zero status.     <\/li>\n<li> Use the Run instance to send the non-zero exit code and a reason from the VM.    <\/li>\n<li> Try to detect Failed state or reason    <\/li>\n<\/ul>\n<p>When we call the following method:    <br \/>\ndef report_error(returncode: int):    <br \/>\n    from azureml.core.run import Run  <br \/>\n    run = Run.get_context(allow_offline=False)  <br \/>\n    print(f&quot;Failing the run with return code={returncode}&quot;)  <br \/>\n    run.fail(f&quot;A process returned a non-zero status code {returncode}&quot;, error_code=returncode)  <br \/>\n    exit(returncode)  <\/p>\n<p>We can see the exit code in the UI at the top of a failed run, but the run is still marked as Completed.    <br \/>\nAs a result, we are unable to determine that the job failed from the submitting client.     <br \/>\nAfter:    <br \/>\nrun.wait_for_completion(show_output=True,    <br \/>\n                                raise_on_error=True)  <br \/>\nWe tried:    <br \/>\n     if result['status'] != 'Completed' or (result['details'] is not None and  <br \/>\n                                           'A process returned a non-zero status code' in result['details']):  <br \/>\n        run.fail(error_details=result['details'], error_code=1)  <br \/>\n        exit(1)  <br \/>\nYet, the return value of this process, communicated to the test client is zero.    <\/p>\n<p>Is this a timing issue in obtaining the result details?     <\/p>\n<p>What could we do to make sure such jobs actually show as Failed in the UI?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/46960-run-27-microsoft-azure-machine-learning.png?platform=QnA\" alt=\"46960-run-27-microsoft-azure-machine-learning.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use AzureMLDataset",
        "Question_created_time":1607676200880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I have used the data labeling system within Azure Machine Learning studio to label a dataset of images.  <br \/>\nThen the output of the labeling system is a new dataset that can be found in the &quot;Dataset&quot; section of the designer in ML studio.  <\/p>\n<p>The problem is that this new dataset module, that can be dragged and dropped in the pipeline, has datatype &quot;AzureMLDataset&quot; (or datasoruce type &quot;amldataset&quot;), which then I cannot connect to any other module in the pipeline because there is no module which accepts as input something with datatype &quot;AzureMLDataset&quot; (or with datasource type &quot;amldataset&quot;).  <\/p>\n<p>I have seen that it is possible to consume the dataset using python, but I would like to use Azure ML studio because it is more convenient to the system I am working in.  <\/p>\n<p>How can I use the AzureMLDataset output module inside ML studio?  <\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot disable Azure Machine Learning Schedule because of 'Provisioning' state",
        "Question_created_time":1607510860937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/191829\/cannot-disable-azure-machine-learning-schedule-bec",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>There is one Schedule that we are not able to disable on our Azure Machine Learning workspace:  <\/p>\n<pre><code>az ml pipeline disable-schedule --schedule-id SCHEDULE_ID \\\n                                --resource-group RG \\\n                                --workspace-name WN\n<\/code><\/pre>\n<p>It's been returning:  <\/p>\n<p><em>(BadRequest) Cannot update an entity while it's in Provisioning state.<\/em>  <\/p>\n<p>The status of the schedule is 'Active'.   <br \/>\nWe were able to disable other schedules on the workspace without any issues. Has anyone faced a similar issue?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to use private docker registry with latest Azure ML release",
        "Question_created_time":1604958506767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/157021\/unable-to-use-private-docker-registry-with-latest",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Since the latest Azure ML release, we have been unable to submit any job using a private docker registry. Same jobs were working before the new release.  <br \/>\nWe configure the job as follows (all of this is automated and the code has not changed):<\/p>\n<p>base_image_name = 'REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_1601582281'<\/p>\n<pre><code># Set the container registry information  \n\nmyenv = Environment(name=&amp;#34;lb&amp;#34;)  \n\nmyenv.docker.enabled = True  \nmyenv.docker.base_image = base_image_name  \nmyenv.docker.base_image_registry.address = &amp;#39;REDACTED.azurecr.io\/lb\/&amp;#39;  \nmyenv.docker.base_image_registry.username, myenv.docker.base_image_registry.password = get_docker_secrets()  \nmyenv.python.user_managed_dependencies = True  \n\nmyenv.python.interpreter_path = &amp;#34;\/opt\/miniconda\/bin\/python&amp;#34;  \n<\/code><\/pre>\n<p>Instead of successful job submission, we are instead getting:  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;message&quot;: &quot;Activity Failed:\\n{\\n \\&quot;error\\&quot;: {\\n \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n \\&quot;message\\&quot;: \\&quot;Unable to get image details : Specified base docker image REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_16\\&quot;,\\n \\&quot;details\\&quot;: []\\n },\\n \\&quot;correlation\\&quot;: {\\n \\&quot;operation\\&quot;: null,\\n \\&quot;request\\&quot;: \\&quot;c41448d429f9c80b\\&quot;\\n },\\n \\&quot;environment\\&quot;: \\&quot;eastus\\&quot;,\\n \\&quot;location\\&quot;: \\&quot;eastus\\&quot;,\\n \\&quot;time\\&quot;: \\&quot;2020-11-09T21:40:39.699533Z\\&quot;,\\n \\&quot;componentName\\&quot;: \\&quot;execution-worker\\&quot;\\n}&quot;  <br \/>\n}  <br \/>\n}  <br \/>\nThe image has not changed (we tried a few different ones from prior successful jobs) and the use of the SDK has not changed.  <br \/>\nHas anybody else encountered a similar problem since the Nov 5 upgrade (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes<\/a>)?  <br \/>\nThis is a major block as we cannot proceed with any project that depend on Azure ML at this time.<\/p>",
        "Question_closed_time":1605016029613,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=d02d6aeb-d51f-460e-9be5-e8da649952cc\">@Fabien Campagne  <\/a>  Thanks for the details, with fully qualified base image name you do not need to specify container registry address. container registry address itself should be just a host name.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Workspaces REST API operations",
        "Question_created_time":1602589232617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/124740\/azure-machine-learning-workspaces-rest-api-operati",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi there,    <\/p>\n<p>As per Azure documentation, Azure Machine Learning Workspaces REST API operations can be listed through below call. Refer documentation: <a href=\"https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/operations\/list\">https:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/operations\/list<\/a>     <\/p>\n<p>GET <a href=\"https:\/\/management.azure.com\/providers\/Microsoft.MachineLearningServices\/operations?api-version=2019-05-01\">https:\/\/management.azure.com\/providers\/Microsoft.MachineLearningServices\/operations?api-version=2019-05-01<\/a>    <\/p>\n<p>When I try this call, it gives the REST API operations that one can do on a workspace like    <br \/>\n{    <br \/>\n      <strong>&quot;name&quot;: &quot;Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read&quot;,<\/strong>  <br \/>\n      &quot;display&quot;: {  <br \/>\n        &quot;provider&quot;: &quot;Machine Learning Services Resource Provider&quot;,  <br \/>\n        &quot;resource&quot;: &quot;Machine Learning Services Workspace&quot;,  <br \/>\n        &quot;operation&quot;: &quot;Gets the Notebook VMs for a particular workspace&quot;,  <br \/>\n        <strong>&quot;description&quot;: &quot;Gets the Notebook VMs for a particular workspace&quot;<\/strong>  <br \/>\n      },  <br \/>\n      &quot;origin&quot;: &quot;user,system&quot;,  <br \/>\n      &quot;properties&quot;: null,  <br \/>\n      &quot;isDataAction&quot;: false  <br \/>\n    },  <\/p>\n<p>As per the highlighted text I understand that &quot;Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read&quot; can be used when we want to get the notebook VMs a workspace.    <\/p>\n<p>I am unable to identify the complete REST API URL for this &quot;Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read&quot;, so that I can use in my program.    <\/p>\n<p>Please suggest.    <\/p>\n<p>Thanks,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Model Deployment- POST Body Type",
        "Question_created_time":1602526641177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123960\/azure-ml-model-deployment-post-body-type",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I had registered a CNN model on Azure ML and would like to have and endpoint API that returns the predictions based on the image it receives and I also would like to send some metadata along the image itself. So, I prefer to POST the data in form-data format. However,The official tutorials mention application-json or binary data only.   <br \/>\nHow can I POST data in form-data format to an API in Azure ML ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Detect and treat local outliers",
        "Question_created_time":1607084778140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/186619\/detect-and-treat-local-outliers",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have built a solution within Azure ML predicting the weight(&quot;Poids&quot; below) of our materials production. It happens that some rows have a cost value that is not normal considering the similarity of the values from the other features. This row should be then exluded (replaced with a mean) according to me. How can I do this ?  <\/p>\n<p>** As this is not a real outlier in the all dataset but an outlier regarding values of the other fields.  <\/p>\n<p>** My predictive model gives the result of 19.000 where visually I would have expected 50.000 which is the correct value....  <\/p>\n<p>FT1Fini 20.00 20.00 20.00 20.00  <\/p>\n<p>FT2Fini 28.30 28.30 28.30 28.30  <\/p>\n<p>PagesTot 592 592 592 600  <\/p>\n<p>QteFact 27.120 29.045 29.045 27.973  <\/p>\n<p>PoidsKG 48.823 <em><strong>2.260<\/strong><\/em> 53.500 52.029  <\/p>\n<p>Thank you for your hep.  <\/p>\n<p>Regards,  <\/p>\n<p>Meddi.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning - SQL Server",
        "Question_created_time":1607409750170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/190067\/azure-machine-learning-sql-server",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I have a created a VM and installed SQL Sever in it and I want to use that data in Azure Machine learning. Is there a way to bring data from SQL server installed on VM to the Azure Machine learning? Please note VM is in a different Vnet (VPN gateway)<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML datetime format issue in output",
        "Question_created_time":1606058533223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171333\/azure-ml-datetime-format-issue-in-output",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>HI ,    <\/p>\n<p>Am trying to do some prediction for time series. When I get the output it is converting to MM\/DD\/YYYY format which is an issue.    <\/p>\n<p>When I give input in YYYY-MM-DD format why is it not returning me in the same format. Please see the screenshot of input vs output    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/41637-image.png?platform=QnA\" alt=\"41637-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Object detection is not working with my model. Why?",
        "Question_created_time":1604239932967,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/147305\/ml-object-detection-is-not-working-with-my-model-w",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello  <br \/>\nI am using the Object Detection project sample in Visual Studio 2019 Preview. The only change I did is created my own ONNX model fromTorch.onnx. The error message now is as following:  <\/p>\n<p>fromTorch.onnx failed:This is an invalid model. Error in Node:Resize_43 : Node (Resize_43) has input size 4 not in range [min=2, max=2]  <\/p>\n<p>I created that model in Google Colub, obtained the h5-file and convert it to onnx-file after.  <br \/>\nWhat would cause the error?  <br \/>\nThanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"D365 Demand Forecasting - Can we connect to new Azure ML Service instead of a classic studio service?",
        "Question_created_time":1606959642257,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/183990\/d365-demand-forecasting-can-we-connect-to-new-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>There is a D365 forecasting option that allows to connect to a azure ml classic studio service. Can we connect from D365 to the new Azure ML Service? I couldnt find any documentation about this, any pointers please.Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Moving resources across the regions",
        "Question_created_time":1606983526427,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/184565\/moving-resources-across-the-regions",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <br \/>\nWe have resource group(RG1) created in Germany region. Resource created are   <\/p>\n<ol>\n<li> Vnet  <\/li>\n<li> VPN gateway  <\/li>\n<li> Disks - HDD  <\/li>\n<li> VM (database installed)  <\/li>\n<\/ol>\n<p>We wanted to use  Azure machine learning service to read data from database(present in resource group RG1 in German region). We later found that azure machine learning service is not available in Germany region and in order to create end points for Azure ML service both the networks(vnets of the DB and Azure ML ) should be in the same region.   <\/p>\n<p>So we tried migrating the resource and resource group (RG1) from German region to west Europe by using wizard on the portal. But we got prompted that disk , vnet and vpn gateway cannot be moved to different region ) .   <\/p>\n<p>Is there anyway we could move them ? or any alternate solutions ? .Else, we would end up recreating every thing in westeurope which i would like to avoid.   <\/p>\n<p>Regards,   <br \/>\nSuman <\/p>",
        "Question_closed_time":1606984258243,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Maybe this is helpful:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/site-recovery\/azure-to-azure-tutorial-migrate\">https:\/\/learn.microsoft.com\/en-us\/azure\/site-recovery\/azure-to-azure-tutorial-migrate<\/a>    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Custom Vision for Canada region",
        "Question_created_time":1606512423207,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/178721\/custom-vision-for-canada-region",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I used Custom Vision to create a small proof of concept project, and it works super nice; however, now that we are ready for the next steps to see if it is doable to use it, I have got some questions that might be roadblocks if I were to go ahead and work on the business implementation:  <\/p>\n<ul>\n<li> The service cannot be deployed in Canada regions. Is this something that will be considered in the future? This is a huge block because the items classified may contain data that should not leave the Canadian space  <\/li>\n<li> What's the privacy terms of using custom vision or where can I find them to read? As the previous item describes, the items classified could contain compromised data, so it would be unfeasible to use the custom vision service if the data is going to be &quot;shared&quot; or &quot;used&quot; by Microsoft or other parties for other purposes.  <\/li>\n<\/ul>\n<p>As a side question, is this service capable of classifying PDF documents as images? And if not, is there a known Azure\/Microsoft service that does so?  <\/p>\n<p>Thanks a bunch! :)  <\/p>\n<p>Kenny Perroni  <\/p>",
        "Question_closed_time":1606709384577,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7684b110-6198-4851-8089-51cea27ce3b0\">@Kenny Perroni  <\/a> Thanks for the feedback. We have forwarded this feedback to our product team, You can also raise a user voice request <a href=\"https:\/\/feedback.azure.com\/forums\/932041-azure-cognitive-services?category_id=395743\">here<\/a> so the community can vote and provide their feedback, the product team then checks this feedback and implements the same for Canada region. For Region availability please check the following <a href=\"https:\/\/azure.microsoft.com\/en-us\/global-infrastructure\/services\/?products=cognitive-services\">link<\/a>    <\/p>\n<p>For custom vision service you control over the storage and deletion of any customer data that store as part of the service. Please follow the below for privacy and compliance. As with all of the Cognitive Services, developers using the Custom Vision service should be aware of Microsoft's policies on customer data. See the below Cognitive Services page on the Microsoft Trust Center to learn more.    <br \/>\n<a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/legal\/cognitive-services-compliance-and-privacy\/\">https:\/\/azure.microsoft.com\/en-us\/support\/legal\/cognitive-services-compliance-and-privacy\/<\/a>    <\/p>\n<p>The Computer vision <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/computer-vision\/concept-recognizing-text#input-requirements\">Read<\/a> service support PDF document as images. Here is the <a href=\"https:\/\/github.com\/microsoft\/computervision-recipes\/blob\/master\/README.md\">link<\/a> for vision best practice and samples. Also the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/form-recognizer\/?branch=release-build-cogserv-forms-recognizer\">Form Recognizer<\/a> supports OCR and PDF documents with <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/form-recognizer\/tutorial-ai-builder\">AI builder.<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Training Personalizer",
        "Question_created_time":1606863751290,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/182318\/training-personalizer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am considering using Personalizer for project and have found limited third party metrics for this service. This one article indicates needing TENS of thousands of hits to get good results.  <\/p>\n<p><a href=\"https:\/\/medium.com\/@EnefitIT\/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e\">https:\/\/medium.com\/@EnefitIT\/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e<\/a>  <\/p>\n<p>Can any one provide any other data?   <\/p>\n<p>Obviously, over time it will get better, but does it have to get to 10K+ to get good?<\/p>",
        "Question_closed_time":1606893531207,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=bac6bba0-0ba2-419e-b1dd-254f191be319\">@Gregorio Rojas  <\/a> The minimum requirements to have an effective recommendation is to have a minimum of ~1k\/day content-related events. Higher rate of events do help you to provide faster and better recommendations. All the requirements are documented in the official documentation <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/cognitive-services\/personalizer\/what-is-personalizer#content-requirements\">page<\/a> of the service. The samples <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-personalizer-samples\">repo<\/a> provides some data along with the quickstart's from the documentation to get started. The service now provides an E0 tier or apprentice mode that helps you test the service and gain confidence to move to a higher tier with production level recommendations.     <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to configute WebServiceOutput?",
        "Question_created_time":1606819526077,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/181635\/how-to-configute-webserviceoutput",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, I trained and deployed a ML model via Auto ML. The result looks like this:  <br \/>\n&quot;\\&quot;{\\\\&quot;result\\\\&quot;: [\\\\&quot;Test\\\\&quot;]}\\&quot;&quot;<\/p>\n<p>Once I did the same with an endpoint created with the Azure ML Designer my result looks like this:  <br \/>\n&quot;{\\&quot;Results\\&quot;: {\\&quot;WebServiceOutput0\\&quot;: [{\\&quot;Scored Labels\\&quot;: \\&quot;Test\\&quot;}]}}&quot;<\/p>\n<p>Is there a way to configure the response that it looks similar to the AutoML response?<\/p>\n<p>Thanks :)<\/p>",
        "Question_closed_time":1606912260000,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=fe5bc84e-425f-4db0-a234-78d2a8fbbae1\">@ID_27051995  <\/a> Unfortunately, AutoML and AML Designer currently generates 2 different swagger format automatically, and there is no way to configure the output format. We are working on to address this inconsistency, and the Designer swagger format will be the converged format. Cheers!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Machine Learning on Prem onebox configuration",
        "Question_created_time":1606877642097,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/182686\/machine-learning-on-prem-onebox-configuration",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am trying to setup Machine Learning 9.4.7 onebox configuration on windows 2016. When I am trying to configure onebox Admin cli utility got hang up. I tried to open up another window and run az mlserver admin node list. It says webnode is running but not compute node. So I set up compute node and tried to log in az mlserver login.     <br \/>\nIt fails with following error:    <\/p>\n<p><strong>Assert that [--mls-endpoint http:\/\/localhost:12800] is correct.    <br \/>\n('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))<\/strong>    <\/p>\n<p>C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin&gt;az mlserver login    <br \/>\nUsername: admin    <br \/>\nPassword:    <br \/>\nAssert that [--mls-endpoint http:\/\/localhost:12800] is correct.    <br \/>\n('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))    <\/p>\n<p>C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin&gt;az mlserver admin node list    <br \/>\n[    <br \/>\n  {    <br \/>\n    &quot;node&quot;: &quot;web&quot;,  <br \/>\n    &quot;pid&quot;: &quot;4608&quot;,  <br \/>\n    &quot;state&quot;: &quot;running&quot;  <br \/>\n  },    <br \/>\n  {    <br \/>\n    &quot;node&quot;: &quot;compute&quot;,  <br \/>\n    &quot;pid&quot;: &quot;6764&quot;,  <br \/>\n    &quot;state&quot;: &quot;running&quot;  <br \/>\n  }    <br \/>\n]    <\/p>\n<p>C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin&gt;    <\/p>\n<p>I have also attached stderr log file for web node.<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/44167-stderr.txt?platform=QnA\">44167-stderr.txt<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I wish to store a variable in R in ML studio to use it for consecutive executions (Web service calls). But since the R script is run from the start, the variable's value resets to default value, that I set. Is there a way to achieve this?",
        "Question_created_time":1606214692780,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/173691\/i-wish-to-store-a-variable-in-r-in-ml-studio-to-us",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My Machine learning flow looks something like this:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42095-image.png?platform=QnA\" alt=\"42095-image.png\" \/>    <\/p>\n<p>And my R script looks something like this:     <\/p>\n<pre><code>if(useAxe){  \n   if (condition1) {  \n      useAxe &lt;- true  \n   }else{  \n      useAxe&lt;- false  \n}  \n<\/code><\/pre>\n<p>I want the value of <strong>useAxe<\/strong> from the previous execution and update it according to the criteria.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is Azure ML instance cost calculated?",
        "Question_created_time":1606732706930,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/180023\/how-is-azure-ml-instance-cost-calculated",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I've created an endpoint for scoring using a modified version of this tutorial: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model<\/a>. I used this command for specifying resources: <code>AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=12)<\/code> and my resource group is &quot;West EU&quot;. I'd like to know how the cost is calculated. I assume that the requested resources are converted to an instance (is that right?). I have found this useful website <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\">calculator<\/a> but I cannot find which instance I am using.     <\/p>\n<p>How can I retrieve the information? Can I also do it programatically?    <\/p>\n<p>Many thanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automated machine learning (AutoML)",
        "Question_created_time":1606236131380,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/174091\/automated-machine-learning-(automl)",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi everyone,  <\/p>\n<p>I want to find the right model for my code, that's why I would like to use Azure AutoML.  <br \/>\nI'm at the point where I split the data:  <br \/>\nX_train, X_test, y_train, y_test (...)  <\/p>\n<p>A vector matrix is created from X_train with TF\/IDF:  <br \/>\ntfidf_vectorizer_matrix = tfidf_vectorizer.fit_transform (X_train).toarray ()  <\/p>\n<p>Normally I would now run through my models one by one, which also works.  <\/p>\n<p>My problem is how must automl_config = AutoMLConfig (...) be filled so that I can use TF\/IDF ?  <\/p>\n<p>A little sample code would be very helpful.  <br \/>\nPlease need help on this topic.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML real time endpoints stuck in 'Transitioning' state",
        "Question_created_time":1606672254767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/179215\/azure-ml-real-time-endpoints-stuck-in-transitionin",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I am trying to deploy Azure ML models as webservice endpoints using an AKS cluster. I have deployed the real time inference pipeline using the Azure ML Studio interface.   <br \/>\nThe endpoints deploy successfully and quickly reach a &quot;Healthy&quot; state, however occasionally the deployments are stuck in the &quot;Transitioning&quot; state for indefinite time. This disables the testing for the endpoints on the portal and we are unable to consume the webservice for that period of time.  <br \/>\nAny idea why this might be happening, or what I can do to fix this?  <br \/>\nIs there a limit to the number of endpoints available on an inference cluster ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_created_time":1605264849177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/162055\/register-azure-ml-model-from-databricksstep",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>Hi,<\/p>\n<p>I'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.<\/p>\n<p>But as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:<\/p>\n<p>UserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:<\/p>\n<ol>\n<li> You are not authorized to access this resource, or directory listing denied.<\/li>\n<li> you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.<\/li>\n<li> You have multiple objects\/login session opened, please close all session and try again.\n<pre><code>InnerException None\nErrorResponse\n\n{\n&quot;error&quot;: {\n&quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;\\\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\\\n1. You are not authorized to access this resource, or directory listing denied.\\\\n2. you may not login your azure service, or use other subscription, you can check your\\\\ndefault account by running azure cli commend:\\\\n'az account list -o table'.\\\\n3. You have multiple objects\/login session opened, please close all session and try again.\\\\n &quot;\n}\n}\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>with the following call stack<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70 return self.\\\n71 _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---&gt; 72 custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74 @error_with_model_id_handling<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, *args, **kwargs)\n65\n66 def _execute_with_workspace_arguments(self, func, *args, **kwargs):\n---&gt; 67 return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), *args, **kwargs)\n68\n69 def get_or_create_experiment(self, experiment_name, is_async=False):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n536 return self._call_paginated_api(func, *args_list, **kwargs)\n537 else:\n--&gt; 538 return self._call_api(func, *args_list, **kwargs)\n539 except ErrorResponseException as e:\n540 raise ServiceException(e)<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n234 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235 else:\n--&gt; 236 return self._execute_with_base_arguments(func, *args, **kwargs)\n237\n238 def _call_paginated_api(self, func, *args, **kwargs):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n323 total_retry = 0 if self.retries &lt; 0 else self.retries\n324 return ClientBase._execute_func_internal(\n--&gt; 325 back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n326\n327 @classmethod<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n343 return func(*args, **kwargs)\n344 except Exception as error:\n--&gt; 345 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347 reset_func(*args, **kwargs) # reset_func is expected to undo any side effects from a failed func call.<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385 &quot;&quot;&quot;\n--&gt; 386 raise_from(UserErrorException(error_msg), error)\n387\n388 elif error.response.status_code == 429:<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)<\/p>\n<p>Did anybody experience the same error and knows what is its cause and how to solve it?<\/p>\n<p>Best,\nJonas<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Studio endpoint problem after Aks\/VM Restart",
        "Question_created_time":1605582083440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165092\/ml-studio-endpoint-problem-after-aks-vm-restart",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_body":"<p>After restarting VM's associated to AKS created with to ML Studio deployed the ws endpoint gets unreachable.  <\/p>\n<p>Try several time to restart but it doesn't work.  <\/p>\n<p>Any idea? Any workaround besides re-create the cluster?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AML Studio - cannot create dataset from datastore file",
        "Question_created_time":1605192099620,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/160773\/aml-studio-cannot-create-dataset-from-datastore-fi",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I am using Jupyter notebooks to work in AML. I was able to upload a file to a datastore (the default workspaceblobstore), but am receiving an error when I try to create a dataset using this file. The relevant code is below:<\/p>\n<pre><code>#This part works\n\ndatastore = ws.get_default_datastore()\n\ndatastore.upload_files(files = ['data\/german_credit_dataset.csv'], overwrite = True, show_progress = True)\n\n# This part doesn't\n\ndataset = Dataset.Tabular.from_delimited_files(path = [(datastore ,'german_credit_dataset.csv')])\n<\/code><\/pre>\n<p>I know the file was uploaded correctly as I am able to locate it in the datastore, and manually create a dataset. The error I receive is:<\/p>\n<p>code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by DatastoreResolutionException.\\r\\n DatastoreResolutionException was caused by UnexpectedException.\\r\\n  <br \/>\nCould it be a permissions issue? I used the json file to connect to my compute instance and it seems to work since I was able to upload the file.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML local Deployment: TypeError: 'NoneType' object is not subscriptable",
        "Question_created_time":1606476453447,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/178262\/azure-ml-local-deployment-typeerror-nonetype-objec",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_body":"<p>I made a script to automatically deploy Azure Models using the python SDK. I want the Data Scientists in my team to easily have their models tested locally and deploy in the cloud afterwards. I use Model.deploy with a custom configuration which looks like this:   <\/p>\n<p><code>inference_config = InferenceConfig(source_directory=params[&amp;#39;source_directory&amp;#39;], entry_script=&amp;#39;score.py&amp;#39;, environment=environment)<\/code>  <\/p>\n<p>When I run the script in the cloud it is working perfectly, but when I run the script locally I get the following error:   <\/p>\n<p><code>Traceback (most recent call last):     File &amp;#34;\/deploy_script.py&amp;#34;, line 14, in &amp;lt;module&amp;gt;       test_deploy.test_service(service, folder, params[&amp;#39;service_name&amp;#39;], delete_service_after_test=False)   File &amp;#34;\\testing_deployment.py&amp;#34;, line 20, in test_service       result = service.run(input_json)   File &amp;#34;\\azureml\\core\\webservice\\local.py&amp;#34;, line 72, in decorated       return func(self, *args, **kwargs)   File &amp;#34;\\azureml\\core\\webservice\\local.py&amp;#34;, line 429, in run       cleanup_on_failure=False, score_url=self.scoring_uri)   File &amp;#34;\\azureml\\core\\webservice\\local.py&amp;#34;, line 442, in scoring_uri       overrideScorePath = self._container_override_config[&amp;#34;scorePath&amp;#34;] TypeError: &amp;#39;NoneType&amp;#39; object is not subscriptable<\/code>  <\/p>\n<p>It seems like there is a failure when _container_override_config is accessed because it is None.   <\/p>\n<p>Does anyone have an idea why it is not working for this local configuration, but it is working for the cloud-based solution?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Designer error: Dataset initialization failed",
        "Question_created_time":1606556238047,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/178715\/azure-ml-designer-error-dataset-initialization-fai",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Getting following error when submiting Azure ML designer pipeline, following azure tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data\">explore-data<\/a>    <\/p>\n<p>Error msg:    <br \/>\nDataset initialization failed: Waiting for mount point to be ready has timed out. Check if fuse device is available on your system.    <br \/>\nIf mounting on remote targets, see <a href=\"https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-train-with-datasets#mount-files-to-remote-compute-targets\">https:\/\/learn.microsoft.com\/azure\/machine-learning\/how-to-train-with-datasets#mount-files-to-remote-compute-targets<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/43378-azure.png?platform=QnA\" alt=\"43378-azure.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML workspace- compute prices",
        "Question_created_time":1606098165613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171550\/azure-ml-workspace-compute-prices",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I was trying to create a compute instance on Azure ml workspace and found that few of the virtual machine sizes show blank in thee price column. Wondering if they are free to use or its a bug.  I sorted by prices. So, you can see first few rows showing blanks under price column    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/41713-azureml-compute.jpg?platform=QnA\" alt=\"41713-azureml-compute.jpg\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there any kinect version that helps in speech therapy?",
        "Question_created_time":1606122417867,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171998\/is-there-any-kinect-version-that-helps-in-speech-t",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI am an educator\/researcher who is working on a project or a thesis for my degree.   <br \/>\nI am thinking of using Kinect to recognize the lips\/ mouth movements to train speech delay kids. My idea is to show students audio-visual 3d mouth, tongue, and throat movements on the Kinect to train them to speak a letter or word by interacting with the camera and evaluating their sounds and movements by the Kinect. At the same time, the Kinect camera will configure if the student's sound and mouth movement are correct.  <\/p>\n<p>I am perplexed about which tag I should use for my question to be best answered.   <\/p>\n<p>I really appreciated it if there are studies or experiments on this issue to let me know.  <\/p>\n<p>Regards<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"html5lib on Azure ML Studio not Running in Python",
        "Question_created_time":1606170996307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/172922\/html5lib-on-azure-ml-studio-not-running-in-python",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I am trying to run a python script inside Azure ML Studio.  <br \/>\nThe script loads an external zipped pip html5lib<\/p>\n<p>I can get it to run but when I try to import reference this sub-method it fails.  <br \/>\nfrom html5lib.serializer import SerializeError<\/p>\n<p>I have tried the following:<\/p>\n<ol>\n<li>  I have confirmed the python script exists in the html5lib zip file<\/li>\n<li>  I have confirmed the root script loads with using 'import html5lib'<\/li>\n<\/ol>\n<p>Does anyone know what I can try?<\/p>\n<p>Thanks.<\/p>\n<p>Full script below:<\/p>\n<hr \/>\n<p>Error is:<\/p>\n<p>Error 0085: The following error occurred during script evaluation, please view the output log for more information:  <br \/>\n---------- Start of error message from Python interpreter ----------  <br \/>\nCaught exception while executing function: Traceback (most recent call last):  <br \/>\nFile &quot;C:\\server\\invokepy.py&quot;, line 199, in batch  <br \/>\nodfs = mod.azureml_main(*idfs)  <br \/>\nFile &quot;C:\\temp\\14a349841e5843a59b28ef365e67397a.py&quot;, line 195, in azureml_main  <br \/>\ndataframe1['sentences']= HTMLSentenceTokenizer().feed(dataframe1['FullEmailContent'])  <br \/>\nFile &quot;C:\\temp\\14a349841e5843a59b28ef365e67397a.py&quot;, line 69, in <strong>init<\/strong>  <br \/>\nself.parser = html5lib.HTMLParser()  <br \/>\nAttributeError: module 'html5lib' has no attribute 'HTMLParser'  <br \/>\nProcess returned with non-zero exit code 1<\/p>\n<p>---------- End of error message from Python interpreter ----------  <br \/>\nStart time: UTC 11\/23\/2020 22:35:12  <br \/>\nEnd time: UTC 11\/23\/2020 22:35:24<\/p>\n<hr \/>\n<h1 id=\"the-script-must-contain-a-function-named-azureml_main\">The script MUST contain a function named azureml_main<\/h1>\n<h1 id=\"which-is-the-entry-point-for-this-module\">which is the entry point for this module.<\/h1>\n<p>import pandas as pd  <br \/>\nimport nltk  <br \/>\nimport html5lib  <br \/>\nfrom html5lib.serializer import SerializeError<\/p>\n<h1 id=\"setup\">setup<\/h1>\n<p>INLINE_ELEMENTS = {'a', 'abbr', 'acronym', 'b', 'bdi', 'bdo', 'big', 'cite', 'code', 'dfn', 'em', 'i', 'kbd',  <br \/>\n'label', 'mark', 'nav', 'output', 'progress', 'q', 's', 'slot', 'small', 'span', 'strong',  <br \/>\n'sub', 'sup', 'time', 'tt', 'var', 'wbr'}<\/p>\n<h1 id=\"does-not-include-pre-or-textarea-which-are-accounted-for-in-preserve_whitespace_elements\">does not include pre or textarea (which are accounted for in PRESERVE_WHITESPACE_ELEMENTS<\/h1>\n<p>BLOCK_LEVEL_ELEMENTS = {'address', 'article', 'blockquote', 'caption', 'details', 'dialog', 'div', 'dl',  <br \/>\n'dt', 'figcaption', 'footer', 'form', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'header', 'hgroup',  <br \/>\n'li', 'main', 'ol', 'p', 'ul', 'section', 'table', 'tbody', 'td', 'th', 'thead', 'tr'}<\/p>\n<p>HEADER_ELEMENTS = {'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'header', 'hgroup'}<\/p>\n<p>SKIPPED_ELEMENTS = [&quot;br&quot;, &quot;hr&quot;]<\/p>\n<h1 id=\"elements-which-cannot-contain-children-and-denote-the-end-of-a-sentence\">elements which cannot contain children and denote the end of a sentence<\/h1>\n<p>EMPTY_ELEMENTS = {'area', 'base', 'br', 'embed', 'hr', 'img'}<\/p>\n<h1 id=\"elements-which-can-have-children-which-never-qualify-as-a-sentence\">elements which can have children which never qualify as a sentence<\/h1>\n<p>SENTENCE_VOID_ELEMENTS = {'button', 'caption', 'col', 'colgroup', 'pre', 'table', 'textarea', 'td', 'tfoot',  <br \/>\n'th', 'thead', 'tr'}<\/p>\n<p>class InvalidTagError(Exception):  <br \/>\ndef <strong>init<\/strong>(self, tag_name):  <br \/>\nsuper(InvalidTagError, self).<strong>init<\/strong>(&quot;Parsing an empty tag which is not of the accepted element types. It is &quot;  <br \/>\n&quot;of type {}&quot;.format(tag_name))<\/p>\n<p>class HTMLSentenceTokenizer:<\/p>\n<pre><code>def __init__(self, ignore_headers=True, raise_invalid_tags=False):\n    &quot;&quot;&quot;\n    :param ignore_headers: If true, ignores text inside of the tags included in HEADER_ELEMENTS. This defaults to\n    true because the text inside of these &quot;header elements&quot; is typically not a sentence.\n    :param raise_invalid_tags: If true, raises an InvalidTagError when parsing a tag not in INLINE_ELEMENTS,\n    BLOCK_LEVEL_ELEMENTS (which includes the elements of HEADER_ELEMENTS), SKIPPED_ELEMENTS, EMPTY_ELEMENTS, or\n    SENTENCE_VOID_ELEMENTS. If false, ignores this tag and all of its children. (Sentences descending from it will\n    not be included in the value returned from feed)\n    &quot;&quot;&quot;\n    # self.parser is an etree parser by default.\n    self.parser = html5lib.HTMLParser()\n    self.walker = html5lib.getTreeWalker(&quot;etree&quot;)\n    self.sentences = []\n    self.ignore_header_text = ignore_headers\n    self.raise_invalid_tags = raise_invalid_tags\n    self.reset()\n\ndef feed(self, markup):\n    &quot;&quot;&quot;\n    Given an HTML document which contains tags on only INLINE_ELEMENTS, BLOCK_LEVEL_ELEMENTS, or\n    PRESERVE_WHITESPACE_ELEMENTS, parses the HTML document into a BeautifulSoup-like tree represented by Node\n    and TextNode objects. Stores these objects in the database. At the end, also resets this SentenceParser object\n    by calling the reset() method.\n    :return: The root node of the parsed tree.\n    &quot;&quot;&quot;\n    etree_document = self.parser.parse(markup)\n    stream = self.walker(etree_document)\n\n    # todo: find a more efficient way to only iterate over tags that are a descendant of body\n    passed_body = False\n\n    for i in stream:\n        if passed_body:\n            if i['type'] == 'StartTag':\n                self.handle_starttag(i['name'])\n            elif i['type'] == 'EndTag':\n                if i['name'] == 'body':\n                    break\n                self.handle_endtag(i['name'])\n            elif i['type'] == 'EmptyTag':\n                self.handle_empty_tag(i['name'])\n            elif i['type'] == 'Characters' or (i['type'] == 'SpaceCharacters' and self.ignored_parent_count &gt; 0):\n                self.handle_text(i['data'])\n            elif i['type'] == 'SpaceCharacters':\n                self.handle_text(' ')\n            elif i['type'] == 'SerializeError':\n                raise SerializeError(i['data'])\n            # else, is a comment, doctype, entity, or unknown.\n            else:\n                pass\n        elif i['type'] == 'StartTag' and i['name'] == 'body':\n            passed_body = True\n\n    sentences_copy = self.sentences\n    self.reset()\n    return sentences_copy\n\ndef reset(self):\n    self.sentences = []\n    self.ignored_parent_count = 0\n    self.current_string = ''\n\ndef handle_text(self, text):\n    if self.ignored_parent_count &gt; 0:\n        return\n\n    self.current_string += text\n\ndef handle_starttag(self, tag_name):\n    # if this tag is the child of an SVE or it is a header element and user would like to ignore headers\n    if self.ignored_parent_count &gt; 0:\n        if tag_name in SENTENCE_VOID_ELEMENTS or (self.ignore_header_text and tag_name in HEADER_ELEMENTS):\n            self.ignored_parent_count += 1\n        return\n\n    if tag_name in SENTENCE_VOID_ELEMENTS:\n        self.handle_end_of_string()\n        self.ignored_parent_count += 1\n        return\n\n    if tag_name in BLOCK_LEVEL_ELEMENTS:\n        self.handle_end_of_string()\n        return\n\n    if tag_name in INLINE_ELEMENTS:\n        return\n\n    if self.raise_invalid_tags:\n        raise ValueError(&quot;Parsing a tag which is not in the accepted element types. It is of type &quot;\n                         &quot;{}&quot;.format(tag_name))\n    else:\n        self.ignored_parent_count += 1\n\ndef handle_endtag(self, tag_name):\n    if tag_name in SENTENCE_VOID_ELEMENTS or (self.ignore_header_text and tag_name in HEADER_ELEMENTS):\n        self.ignored_parent_count -= 1\n        self.current_string = ''\n        return\n\n    # if in an SVE (and this tag is not an SVE).\n    if self.ignored_parent_count &gt; 0:\n        return\n\n    if tag_name in BLOCK_LEVEL_ELEMENTS:\n        self.handle_end_of_string()\n        return\n\n    # if tag_name in INLINE_ELEMENTS, nothing is done.\n\ndef handle_empty_tag(self, tag_name):\n    if tag_name in EMPTY_ELEMENTS:\n        self.handle_end_of_string()\n    else:\n        raise ValueError(\n            &quot;Parsing an empty tag which is not of the accepted element types. It is of type {}&quot;.format(tag_name))\n\ndef handle_end_of_string(self):\n    self.current_string = self.current_string.strip()\n\n    if len(self.current_string) == 0:\n        return\n\n    current_sentences = sent_tokenize(self.current_string)\n    for i in current_sentences:\n        i = i.strip()\n        self.sentences.append(i)\n\n    self.current_string = ''\n<\/code><\/pre>\n<h1 id=\"the-entry-point-function-can-contain-up-to-two-input-arguments\">The entry point function can contain up to two input arguments:<\/h1>\n<h1 id=\"paramdataframe1-a-pandasdataframe\">Param&lt;dataframe1&gt;: a pandas.DataFrame<\/h1>\n<h1 id=\"paramdataframe2-a-pandasdataframe\">Param&lt;dataframe2&gt;: a pandas.DataFrame<\/h1>\n<p>def azureml_main(dataframe1 = None, dataframe2 = None):<\/p>\n<pre><code># Execution logic goes here\nprint('Input pandas.DataFrame #1:\\r\\n\\r\\n{0}'.format(dataframe1))\ndataframe1['sentences']= HTMLSentenceTokenizer().feed(dataframe1['FullEmailContent'])\n# If a zip file is connected to the third input port is connected,\n# it is unzipped under &quot;.\\Script Bundle&quot;. This directory is added\n# to sys.path. Therefore, if your zip file contains a Python file\n# mymodule.py you can import it using:\n# import mymodule\n\n# Return value must be of a sequence of pandas.DataFrame\nreturn dataframe1\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Split Data with randomized_split unchecked",
        "Question_created_time":1605537495223,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/164274\/split-data-with-randomized-split-unchecked",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Please what happen when we split data on the mode <strong>SPLIT ROWS<\/strong> with randomized_split <strong>unchecked<\/strong> ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML experiment run 70- driver log not printing after a few epoches",
        "Question_created_time":1604880529150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/155350\/azure-ml-experiment-run-70-driver-log-not-printing",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am training a deep learning artificial neural network model, usually the run submitted to the Experiment will show all the model running logs in 70-driver-log of 'outputs + logs' tab, but starting yesterday, the logs show only a few lines of logs and stop printing. I can still see the model is running since the 'metrics' tab is showing the loss and accuracy results.  <\/p>\n<p>And another weird thing is that after model training finished, the model is not saved.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What could I be doing wrong to get this result from Azure AutoML timeseries forecasting?",
        "Question_created_time":1606359622230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/176361\/what-could-i-be-doing-wrong-to-get-this-result-fro",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm experimenting with Azure AutoML for timeseries forecasting. I have a simple two column training dataset with two years of data at hourly intervals. Column 1 is Date\/Time Column 2 is the variable I want to predict. I've done several runs of Azure AutoML and it seems to complete successfully. However, when I do a forecast and graph it something is obviously wrong. It looks like the forecast is being quantised somehow. The graph below is for the 7 days after the training set. Blue is actual and red is the forecast. This is obviously not right.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/42777-badautoml.png?platform=QnA\" alt=\"42777-badautoml.png\" \/>    <\/p>\n<p>Here is my configuration for the training (python):    <\/p>\n<pre><code>lags = [1,24,168]  \nforecast_horizon = 7 * 24 # 7 days of hourly data  \nforecasting_parameters = ForecastingParameters(  \n    time_column_name=&quot;DateTime&quot;,  \n    forecast_horizon=forecast_horizon,  \n    target_lags=lags,  \n    country_or_region_for_holidays='NZ',  \n    freq='H',  \n    use_stl='season',  \n    seasonality='auto'  \n)  \nautoml_config = AutoMLConfig(task='forecasting',  \n                             debug_log='automl_forecasting_function.log',  \n                             primary_metric='normalized_root_mean_squared_error',  \n                             experiment_timeout_hours=1,  \n                             experiment_exit_score=0.05,   \n                             enable_early_stopping=True,  \n                             training_data=train_df,  \n                             compute_target=compute,  \n                             n_cross_validations=10,  \n                             verbosity = logging.INFO,  \n                             max_concurrent_iterations=19,  \n                             max_cores_per_iteration=19,  \n                             label_column_name=&quot;Output&quot;,  \n                             forecasting_parameters=forecasting_parameters,  \n                             featurization=&quot;auto&quot;,  \n                             enable_dnn=False)  \n<\/code><\/pre>\n<p>The best model from the run is a VotingEnsemble:    <\/p>\n<pre><code>ForecastingPipelineWrapper(pipeline=Pipeline(  \n  memory=None,  \n  steps=[('timeseriestransformer',  \n  TimeSeriesTransformer(  \n    featurization_config=None,  \n    pipeline_type=&lt;TimeSeriesPipelineType.FULL: 1&gt;)),  \n  ('prefittedsoftvotingregressor',  \n  PreFittedSoftVotingRegressor(estimators=[('7',  \n  Pipeline(memory=None,  \n  steps=[('minmaxscaler',  \n  MinMaxScaler(copy=True,  \n  feature_range=(0,  \n  1))...  \n  DecisionTreeRegressor(ccp_alpha=0.0,  \n  criterion='mse',  \n  max_depth=None,  \n  max_features=0.5,  \n  max_leaf_nodes=None,  \n  min_impurity_decrease=0.0,  \n  min_impurity_split=None,  \n  min_samples_leaf=0.00218714609400816,  \n  min_samples_split=0.00630957344480193,  \n  min_weight_fraction_leaf=0.0,  \n  presort='deprecated',  \n  random_state=None,  \n  splitter='best'))],  \n  verbose=False))],  \n  weights=[0.5,  \n  0.5]))],  \n  verbose=False),  \n  stddev=None)  \n<\/code><\/pre>",
        "Question_closed_time":1606423079827,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I tried again after turning off early stopping and letting it run for the two hours....  and got this<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/43171-goodautoml.png?platform=QnA\" alt=\"43171-goodautoml.png\" \/>    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"How does AzureML choose the node to launch a run?",
        "Question_created_time":1605888033847,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/170198\/how-does-azureml-choose-the-node-to-launch-a-run",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I have a question related with runs, compute clusters and vcpu\/memory boundaries for specific run.    <\/p>\n<p>I have this mindset that a run executes over an environment (a docker image) in a specific compute target. My idea is, if there are resources (vcpu and memory) available on a node, so the run executes in that node. But I always see that a node only executes one run each time, independently the node sku of compute cluster. It seams, AzureML chooses always a idle node to launch a run.    <\/p>\n<p>Does a node always execute one, and not more than one, run in the same time?    <br \/>\nWhat are resources boundaries for run? Or the run might spread over all node resources?    <br \/>\nIf there is boundaries, the default boundaries is static or configurable through <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.dockersection?view=azure-ml-py#variables\">environment property <code>arguments<\/code> for docker run<\/a>?    <\/p>\n<p>What the following section in run raw json means?    <\/p>\n<pre><code>&quot;containerInstance&quot;: {  \n  &quot;region&quot;: null,  \n  &quot;cpuCores&quot;: 2,  \n  &quot;memoryGb&quot;: 3.5  \n},  \n<\/code><\/pre>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML time series model returns strange forecast",
        "Question_created_time":1604413410307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/149896\/azure-automl-time-series-model-returns-strange-for",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>I used Azure AutoML to train a time series forecasting model and selected the forecasting horizon to be 6. Each of our data row is one month, so we want to see the forecast for the following 6 months.  <\/p>\n<p>However, when feeding 2 rows of data to the model, it returns 2 figures, and when feeding 8 rows of data, it returns 8 figures. We expect that as we select the forecasting horizon to be 6, regardless of how many rows of data being fed into the model, it should returns 6 figures.  <\/p>\n<p>Could somebody explain why this happens and how to correct it? Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML endpoint not accessible after stopping\/restarting ACI",
        "Question_created_time":1604412389243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/149864\/ml-endpoint-not-accessible-after-stopping-restarti",
        "Question_score_count":2,
        "Question_answer_count":2,
        "Question_comment_count":5,
        "Question_body":"<p>I have been developing a ML model using Azure ML workspace and the azure-ml SDK. The development of the model and deployment of the model works using the SDK. I have confirmed multiple times that after the endpoint is created I can call it with the correct payload and the webservice will return the correct results.  <\/p>\n<p>However, once I deploy a model to ACI and stop-start or restart the container instance resource in Azure. The endpoint stops working and I get a timeout error when calling the webservice.  <\/p>\n<p>Have any of you run into the same issues when deploying an Azure ML model to ACI?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Blocked Algorithms still run for AutoML Experiment",
        "Question_created_time":1605815289883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/168932\/blocked-algorithms-still-run-for-automl-experiment",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I have been trying to run an AutoML Forecasting Experiment with only allowing one algorithm (FBProphet) to run and no other supported algorithms. The issue I run into is that even though I specify the blocked algorithms, they still run in the experiment taking up unnecessary runtime. For eg, my experiment should run only for 1-2 hours but it ends up running for 24-30 hours because it still runs the undesired algorithms. Is there any way I can stop making the blocked algorithms from running in my experiment so I can save up on significant runtime? I have attached a screenshot and my AutoML config code to help understand this issue better.   <\/p>\n<h3 id=\"code--\">Code:  <\/h3>\n<pre><code>n_test_periods = 60\nblocked_algos = ['ExtremeRandomTrees','DecisionTree','ElasticNet','LassoLars']\ntime_series_settings = {\n    'time_column_name': time_column_name,\n    'grain_column_names': grain_column_names ,\n    'forecast_horizon': n_test_periods\n}\n\nautoml_config = AutoMLConfig(task='forecasting',\n                             debug_log='Logs\/prophet_forecasting_errors.log',\n                             primary_metric='normalized_mean_absolute_error',\n                             training_data=train_data,\n                             label_column_name=target_column_name,\n                             compute_target=compute_target,\n                             featurization= 'off',\n                             blocked_model = blocked_algos,\n                             allowed_models = ['Prophet'],\n                             n_cross_validations= 3,\n                             verbosity=logging.INFO,\n                             max_cores_per_iteration=6,\n                             **time_series_settings)\n\nremote_run = experiment.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<h3 id=\"screenshot-of-the-experiment-this-took-32h-when-it-should-ideally-take-56-mins--\">Screenshot of the Experiment: (This took 32h when it should ideally take 56 mins)  <\/h3>\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/6346065\/99596393-0847c600-29ab-11eb-859a-c4e125be8dfc.PNG\" alt=\"github1\" \/>  <\/p>",
        "Question_closed_time":1606310431887,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=b7b34487-4b0d-4ccb-bf3e-c3772a4a5432\">@Megha Lokanadham  <\/a> it's always good to have the latest version if possible, latest version is <a href=\"https:\/\/pypi.org\/project\/azureml-sdk\/\">1.18.0<\/a> as of today.    <\/p>\n<p>Can you please try the following 1. Correct the name of the parameter( blocked_model) to &quot;<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py\">blocked_models<\/a>&quot; and keep both &quot;blocked_models&quot; and &quot;allowed_models&quot;.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ML dataset: label column of dataset is None",
        "Question_created_time":1605709509727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/167244\/azure-ml-dataset-label-column-of-dataset-is-none",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>For a project we need to load some data and its labels from an azure ML dataset. However when using the following sample code in python:  <\/p>\n<pre><code>    from azureml.core import Workspace, Dataset\n    subscription_id = 'sub-id...'\n    resource_group = 'res-grp...'\n    workspace_name = 'ws-name...'\n    ds_name = 'name-of-ds'\n\n    workspace = Workspace(subscription_id, resource_group, workspace_name)\n    dataset = Dataset.get_by_name(workspace, name=ds_name).to_pandas_dataframe()\n<\/code><\/pre>\n<p>the labels are None. The dataset was exported from a &quot;Image Classification Multi-label&quot; project. For a dataset exported from a &quot;Image Classification Multi-class&quot; the code works fine. Currently I work on a local PC in Pycharm with Python 3.5 (due to easier debugging). Can you maybe help me with that?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to retrain Automated ML generated Model with new Data",
        "Question_created_time":1606117190360,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171971\/how-to-retrain-automated-ml-generated-model-with-n",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <br \/>\ni generated a machine learning model with Automated ML in Azure Machine Learning. Time to time i get new data, and i wanna feed the generated model with it.   <br \/>\nIs there a way to automatically retrain that model and updating the belonging endpoint.   <\/p>\n<p>I have seen some intructions to this using Data Factory and Pipelines. Since I'm using Automated ML I'm not able to do it this way.  <\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployment of ML model stuck in transitioning state",
        "Question_created_time":1606113753810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171789\/deployment-of-ml-model-stuck-in-transitioning-stat",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to deploy a simple LSTM model in ACI. The deployment is stuck in transitioning state for about a day now. Any help will be much appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Isn't Interactive login, default for Workspace.from_config()?",
        "Question_created_time":1606097614390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171577\/isnt-interactive-login-default-for-workspace-from",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>According to <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\">this<\/a> notebook  <\/p>\n<blockquote>\n<p>Interactive Authentication  <br \/>\nInteractive authentication is the default mode when using Azure ML SDK.  <\/p>\n<p>When you connect to your workspace using workspace.from_config, you will get an interactive login dialog.  <\/p>\n<\/blockquote>\n<p>So, i ran <code>ws=Workspace.from_config()<\/code>  <br \/>\n and got the following error  <\/p>\n<pre><code>--------------------------------------------------------------------------\nUserErrorException                        Traceback (most recent call last)\n&lt;ipython-input-13-e469111f639c&gt; in &lt;module&gt;\n----&gt; 1 ws = Workspace.from_config()\n\n~\\Documents\\Softwares\\Anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py in from_config(path, auth, _logger, _file_name)\n    276\n    277             if not found_path:\n--&gt; 278                 raise UserErrorException(\n    279                     'We could not find config.json in: {} or in its parent directories. '\n    280                     'Please provide the full path to the config file or ensure that '\n\nUserErrorException: UserErrorException:\n        Message: We could not find config.json in: C:\\Users\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n        InnerException None\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;We could not find config.json in: C:\\\\Users\\\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":1606116372007,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2c0f2a38-b74b-451f-85f1-6cc6fb702227\">@kalyan reddy  <\/a> A configuration file(JSON) is created when you run the configuration.ipynb file or notebook which can then be used to get the configuration using     <br \/>\n    ws = Workspace.from_config()  <\/p>\n<p>You can run this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/setup-environment\/configuration.ipynb\">notebook<\/a> and create a new workspace if not available or use the existing workspace. For example, Set the workspace details as environment varibles.    <\/p>\n<pre><code>import os  \n  \nsubscription_id = os.getenv(&quot;SUBSCRIPTION_ID&quot;, default=&quot;&lt;my-subscription-id&gt;&quot;)  \nresource_group = os.getenv(&quot;RESOURCE_GROUP&quot;, default=&quot;&lt;my-resource-group&gt;&quot;)  \nworkspace_name = os.getenv(&quot;WORKSPACE_NAME&quot;, default=&quot;&lt;my-workspace-name&gt;&quot;)  \nworkspace_region = os.getenv(&quot;WORKSPACE_REGION&quot;, default=&quot;eastus2&quot;)  \n<\/code><\/pre>\n<p>Write then to config.json file    <\/p>\n<pre><code>from azureml.core import Workspace  \n  \ntry:  \n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)  \n    # write the details of the workspace to a configuration file to the notebook library  \n    ws.write_config()  \n    print(&quot;Workspace configuration succeeded. Skip the workspace creation steps below&quot;)  \nexcept:  \n    print(&quot;Workspace not accessible. Change your parameters or create a new workspace below&quot;)  \n<\/code><\/pre>\n<p>You can now access this config from other notebooks and need not specify the subscription or workspace details in every notebook file.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Unable to start azure ml notebooks",
        "Question_created_time":1600874019267,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/104765\/unable-to-start-azure-ml-notebooks",
        "Question_score_count":1,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_body":"<p>I have been trying to experiment with Azure ML. So, i created a workspace. When i create a notebook, i keep getting same error from past two days. Please help.   <\/p>\n<p><img src=\"https:\/\/pbs.twimg.com\/media\/Eim7kUeVgAEag-6?format=jpg&amp;name=medium\" alt=\"Eim7kUeVgAEag-6\" \/>  <\/p>\n<p>Also, you can see errors in console.  <br \/>\n<img src=\"https:\/\/pbs.twimg.com\/media\/Eim9UTEVgAAKzHc?format=png&amp;name=small\" alt=\"Eim9UTEVgAAKzHc\" \/>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML: ID column for joining data returns \"No. Of unique values ... is greater than allowed\"",
        "Question_created_time":1604936001023,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/156534\/azure-ml-id-column-for-joining-data-returns-no-of",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_body":"<p>Hi.  <\/p>\n<p>I am working on an ML model in Designer.  <\/p>\n<p>I have a dataset of c. 55,000 rows.   <\/p>\n<p>When I add an &quot;ID&quot; column (unique per row - so 55,000 IDs) to my dataset for training \/ scoring, I receive the error message:  <\/p>\n<blockquote>\n<p>ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: &quot;ID&quot; is greater than allowed.  <\/p>\n<\/blockquote>\n<p><strong>Question:<\/strong> is this error based on a physical cap on number of rows - or capacity based on e.g. Compute power associated with the instance?  <\/p>\n<p>I can run 20k rows through the model <em>without<\/em> the ID column - so it seems the unique rows is the challenge.  <\/p>\n<p>But then - how do I keep an identifying column in the scored dataset, if there is a cap on unique values?   <\/p>\n<p>Because I need the ID column to join with other data that is not able to be used in modelling as features etc.   <\/p>\n<p>Any guidance welcome! <\/p>",
        "Question_closed_time":1605654456913,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>User can use Edit Metadata module to mark the ID column as &quot;ClearFeature&quot;, and thus this will not be used in Train Model. This should prevent the error. Please have a try and let me know if there is any questions. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/edit-metadata\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/edit-metadata<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/40390-microsoftteams-image-7.png?platform=QnA\" alt=\"40390-microsoftteams-image-7.png\" \/>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Investigating AML workspace images crashes due to already deleted model",
        "Question_created_time":1605805617850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/168781\/investigating-aml-workspace-images-crashes-due-to",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am currently working with Azure Machine Learning. Doing this I encountered a problem when trying to access the images associated with the AML workspace I am working on. It seems, that the method is trying to get access to a model that was already deleted from the model registration by me some time ago. I deleted the model in the GUI of AML on the &quot;models&quot; tab.   <\/p>\n<p>Calling:  <\/p>\n<pre><code>ws.images\n<\/code><\/pre>\n<p>Produces:  <\/p>\n<pre><code>Received bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Thu, 19 Nov 2020 16:56:10 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '5b1ae4fc52324429b241197be3f455a3', 'x-ms-client-session-id': '', 'api-deprecated-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '2.912', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\nContent: b'{&quot;code&quot;:&quot;NotFound&quot;,&quot;statusCode&quot;:404,&quot;message&quot;:&quot;The specified resource was not found.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;NoSuchModelRegistered&quot;,&quot;message&quot;:&quot;One or more models are not registered in Account Subscription: da80dbc4-7dd6-4833-b66e-f6dbbbe42ece, ResourceGroup: dat-q-rg, Workspace: dat-q-aml-01. Unregistered modelIds sklearn_regression_model.pkl:13&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;5b1ae4fc52324429b241197be3f455a3&quot;}}'\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\d91755\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azureml\\core\\image\\image.py&quot;, line 577, in list\n    resp.raise_for_status()\n  File &quot;C:\\Users\\d91755\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py&quot;, line 943, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https:\/\/westeurope.modelmanagement.azureml.net\/modelmanagement\/v1.0\/subscriptions\/da80dbc4-7dd6-4833-b66e-f6dbbbe42ece\/resourceGroups\/dat-q-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dat-q-aml-01\/images?expand=true\n<\/code><\/pre>\n<p>The model  <em>sklearn_regression_model.pkl:13<\/em> existed and was registered in AML but was deleted manually by me in AML. How come calling the <em>images<\/em> method has still knowledge of this model?  <br \/>\nHow can I fix this to be able to call the images method again?  <\/p>\n<p>In case this is a bug, where would I report it?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to find the example URL and other details after publishing the LUIS app",
        "Question_created_time":1605612037043,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165568\/unable-to-find-the-example-url-and-other-details-a",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hii,  <br \/>\nI have created and a published a LUIS app, but in the manage section I am not able to see and example URL and other details such as keys and other Information after publishing it. Can some help me out with the mentioned issue?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"frame = ds.to_dataframe() doesn't work for me",
        "Question_created_time":1605353730307,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/162914\/frame-ds-to-dataframe()-doesnt-work-for-me",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39817-capture.png?platform=QnA\" alt=\"39817-capture.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39760-capture1.png?platform=QnA\" alt=\"39760-capture1.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39805-capture2.png?platform=QnA\" alt=\"39805-capture2.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endpoint deployment stuck on \u201cTransitioning\u201d in Azure Machine Learning",
        "Question_created_time":1605092257033,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/159147\/endpoint-deployment-stuck-on-transitioning-in-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I am trying to deploy an endpoint from the machine learning studio, but all endpoints get stuck in the transitioning state.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39082-chrome-2020-11-10-14-02-13.png?platform=QnA\" alt=\"39082-chrome-2020-11-10-14-02-13.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/38868-image.png?platform=QnA\" alt=\"38868-image.png\" \/>    <\/p>\n<p>When looking at the container's activity log, I can see the following operations took place:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/38990-image.png?platform=QnA\" alt=\"38990-image.png\" \/>    <\/p>\n<p>And if I select the top level failed action, I can see this error message:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/39073-image.png?platform=QnA\" alt=\"39073-image.png\" \/>    <\/p>\n<p>However, I should have the usual permissions for the group I'm deploying in, as I've created other resources in this group before.    <\/p>\n<p>Am I missing a different permission which would not be needed for other resources?    <\/p>\n<p>Resource group: intrglmpdev00002    <\/p>\n<p>Subscription Id: 931c1c11-140f-4489-a457-6f4b22023b26    <\/p>\n<p>Workspace: LimburgsMooisteML1    <\/p>\n<p>While searching for a solution earlier I found this thread; <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39341\/azure-ml-endpoint-stuck-in-transitioning-state.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39341\/azure-ml-endpoint-stuck-in-transitioning-state.html<\/a> I have also sent an email to microsoft as specified there.    <\/p>\n<p>EDIT: I also just noticed that the description that I entered for testdeployment3 does not show up in the endpoint specifications.     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to export experiment parameters and logged metrics in Azure ML to CSV?",
        "Question_created_time":1605641332880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/166057\/is-there-a-way-to-export-experiment-parameters-and",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am running a bunch of ML experiments using AzureML, sometimes changing training parameters and sometimes aspects of the data preprocessing. In general, for a given experiment I will be able to get a table (aka &quot;view&quot;) like this:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/40466-image.png?platform=QnA\" alt=\"40466-image.png\" \/>    <\/p>\n<p>While the UI allows some minimum level of customization, sorting runs by e.g. desired columns (say the accuracy to identify the best runs) seems really problematic.     <\/p>\n<p>The only workaround I am aware of is to save the page to HTML (!) and extract the values from there.     <br \/>\nThe data in the cells can't by copied with a cursor either...    <\/p>\n<p>Is there an easy way to export the data collected during several runs, via the UI or programmatically, without the need to scrape the blob storage of the Azure ML workspace (I am asking the community here as <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-view-training-logs\">docs<\/a> don't seem particularly helpful)?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Anaconda commercial use on Azure Machine Learning",
        "Question_created_time":1605597154997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Anaconda announced that commercial users should purchase the licenses on APR, 20, 2020.  <br \/>\nHowever, Azure Machine Learning heavily depends on this anaconda packages; developing models on computing instance and deploy container environment.  <\/p>\n<p>Do commercial developers have to pay to anaconda to continue usage of Azure Machine Learning with anaconda?  <\/p>",
        "Question_closed_time":1605602646227,
        "Answer_score_count":0.0,
        "Answer_comment_count":4.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=55ef7a9f-c4d6-4e64-b536-02ebed405538\">@Eisuke Yonezawa  <\/a> If you are have the commercial version of Anaconda you can configure the same for your experiments to deploy packages that are available under license but in most cases you can simply use conda to install available python packages without paying for the commercial license. There is no restriction to have a commercial license to continue using Azure Machine Learning with anaconda. I hope this helps!!<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"TabularDataset \"topandasdataframe()\" - does not support pandas errorbadlines?",
        "Question_created_time":1605588169590,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165143\/tabulardataset-topandasdataframe()-does-not-suppor",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,    <\/p>\n<p>I am trying to skip lines that produces more columns than intended while loading to a pandas dataframe.    <\/p>\n<p>Like this Pandas Option: When error_bad_lines = False, pandas will skip these lines.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/40293-pictravel.jpg?platform=QnA\" alt=\"40293-pictravel.jpg\" \/>    <\/p>\n<p>How can I achieve this with to-pandas-dataframe? Thanks.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deep learning training on Azure steps and tutorial",
        "Question_created_time":1605040090287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/158168\/deep-learning-training-on-azure-steps-and-tutorial",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi MSFT Community,     <\/p>\n<p>I followed this guide to set up a GPU: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-ubuntu-intro\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-ubuntu-intro<\/a>    <\/p>\n<p>VM: Standard NC12_Promo, 12 vCPUs, 112 Gib RAM    <br \/>\nOperating System: Linux    <br \/>\nOffer: Ubuntu-1804    <\/p>\n<p>I am ready to start deep learning training but I am confused about what to do next. I am doing a medical image classification project. I have 1 millions images store in Azure blob now. Do I need to download them to my VM in order to train? Or is it a better way to access image efficiently?    <\/p>\n<p>What are some good tutorials to set up the experiments? I've read a lot of documentation but still confused.     <\/p>\n<p>Thank you very much!    <br \/>\nBest Regards,    <br \/>\nClaire<\/p>",
        "Question_closed_time":1605057040680,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=d324c18d-0c6a-4b3e-878e-30b46421559e\">@gecheng  <\/a>     <br \/>\ncheck on the below AI training modules.    <br \/>\n<a href=\"https:\/\/aischool.microsoft.com\/en-us\/services\/learning-paths\">https:\/\/aischool.microsoft.com\/en-us\/services\/learning-paths<\/a>    <\/p>\n<p>AI Lab    <br \/>\n<a href=\"https:\/\/www.microsoft.com\/en-us\/ai\/ai-lab-projects\">https:\/\/www.microsoft.com\/en-us\/ai\/ai-lab-projects<\/a>    <\/p>\n<p>AI module gallery    <br \/>\n<a href=\"https:\/\/gallery.azure.ai\/browse\">https:\/\/gallery.azure.ai\/browse<\/a>    <\/p>\n<p>----------    <\/p>\n<p>Please don\u2019t forget to &quot;Accept the answer&quot; and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Deploying Machine Learning Modules to IoT Edge running on Windows",
        "Question_created_time":1604258300613,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/147408\/deploying-machine-learning-modules-to-iot-edge-run",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm building an IoT device that needs to run on Windows. I'm aggregating data for analytics and would like to build a Machine Learning model. I've seen that IoT Edge with Windows Containers doesn't support Azure Machine Learning and won't be able to run modules written in Python.  What options do you recommend for developing machine learning modules for Windows containers? Is there a timeline for IoT Edge supporting python in Windows containers? Or supporting Azure Machine Learning? I saw a forum post back in early 2019 from a Project Manager that said both were planned features and I don't want to spend time\/money developing a C# module if a Python update is around the corner and I just have to wait for deployment<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Endpoint stuck in 'transitioning' state",
        "Question_created_time":1604939373570,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/156439\/endpoint-stuck-in-transitioning-state",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>I'm trying to use Azure ML to host an image classification model trained in lobe.ai (externally trained model).     <\/p>\n<p>I've used the 'no code' model deployment approach described <a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/how-to-deploy-no-code-deployment\">here<\/a>     <\/p>\n<p>I've been able to authenticate my workspace and register my TensorFlow model, but the endpoint is stuck on transitioning for over 2 hours.     <\/p>\n<p>Any ideas?    <\/p>\n<pre><code>from azureml.core import Model  \n  \nmodel = Model.register(workspace=ws,  \n                       model_name='cxr',                            # Name of the registered model in your workspace.  \n                       model_path='cxr_test',                       # Local Tensorflow SavedModel folder to upload and register as a model.  \n                       model_framework=Model.Framework.TENSORFLOW,  # Framework used to create the model.  \n                       model_framework_version='1.15.3',            # Version of Tensorflow used to create the model.  \n                       description='Pneumonia-prediction model')  \n  \nservice_name = 'tensorflow-cxr-service'  \nservice = Model.deploy(ws, service_name, [model])  \n<\/code><\/pre>",
        "Question_closed_time":1605125180897,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>We have created a support ticket for this issue and we will update the solution later. Thanks.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"GPT-3 access",
        "Question_created_time":1605179070400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/160489\/gpt-3-access",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'd like to use GPT-3 for my application.  I understand MS has licensed GPT-3 from OpenAI, and that there is pricing too.  So how do I get to use GPT-3?  <\/p>\n<p>Chris Powell<\/p>",
        "Question_closed_time":1605182707940,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=912f72cd-88e9-416f-bbe1-5a7356385053\">@Crispy  <\/a> Thanks for the question, Innovations from our GPT-3 workstreams will be incorporated in later versions of Azure. In the meantime, If you are interested in participation in the OpenAI GPT-3 and Azure Service partnership please fill out this <a href=\"https:\/\/forms.office.com\/Pages\/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRyj5DlT4gqZKgEsfbkRQK5xUQVlSVlJITkxDQkRaOVdESjJGN0dONkQzNy4u\">form<\/a> to submit a request.    <\/p>\n<p>Ignite blog announcement: <a href=\"https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/\">https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"i am not able to select jupyter notebook in azure ML",
        "Question_created_time":1604559071717,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/152224\/i-am-not-able-to-select-jupyter-notebook-in-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/37606-screenshot-92.png?platform=QnA\" alt=\"37606-screenshot-92.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How much will it cost me to learn Azure Machine Learning?",
        "Question_created_time":1589500691030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/27214\/how-much-will-it-cost-me-to-learn-azure-machine-le",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to do the Azure Data Scientist Associate certification. I'm on the first portion of learning exercises and it has me create a Machine Learning Workspace and then its had me create a VM which according to the Azure pricing calculator will cost me $367 a month. If I forget to shut down this VM could I get a bill for this much? Is there a way to have these VM's automatically shut down? Since I'm only interacting with this VM via a web interface I'm really worried that I'm going to get stuck with some hefty bills after this training. Should I be concerned? The Azure Portal has a cost estimate section but it does not include any of my Machine Learning resources or workspaces so I'm not sure how I can get a realistic estimate for how much this will cost me to complete this training. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I utilize multiple cores on Azure ML Studio VM's?",
        "Question_created_time":1603703811737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/139002\/how-can-i-utilize-multiple-cores-on-azure-ml-studi",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hi. I have a python script which can be run either sequentially or in parallel (using concurrent.futures). On my local machine using the parallel option results in a considerably faster execution (nearly linear speed up). Running the same script inside an Experiment on Azure ML Studio I was not able to observe any speedup from the parallel version. At first I thought adding the following line conda_env.docker.arguments = [&quot;--cpuset-cpus=4&quot;] would help, but still the same. Therfore my question is, how can I enable the docker container to leverage multiple cores of the vm-instance? Kind Regard Kai <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can machine learning rewrite\/recognize text to one truth",
        "Question_created_time":1604082069767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/146531\/can-machine-learning-rewrite-recognize-text-to-one",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi there,  <\/p>\n<p>My dataset has a lot of productnames, all the product of the shops are not written by the same.  <br \/>\nSo i want azure can recognize if it's the same:  <\/p>\n<p>So if the productgroup is X and productname looks like\/contains tomato. The product is tomato.  <br \/>\nExample: Tomatoes, tomato, bunch of tomatoes, a bag of tomatoes, small tomatoes = new colom tomato.  <\/p>\n<p>Hopefully someone can help me with this?  <\/p>\n<p>Thanks a lot.  <\/p>",
        "Question_closed_time":1604310668223,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=a025e8b8-4c28-486c-808d-f6251370f906\">@Borget  <\/a>  Thanks for the details. With a variety of data inputs, Can you try <a href=\"https:\/\/learn.microsoft.com\/en-us\/powerquery-m\/table-fuzzygroup\">fuzzy<\/a> matching\/regex\u2019s or Azure Search would be a complete Information Retrieval engine. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/search\/search-indexer-overview\">Azure Search<\/a> works well for this.    <br \/>\nbut using full Lucene syntax you can do fuzzy and proximity search.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/search\/search-query-lucene-examples\">https:\/\/learn.microsoft.com\/en-us\/azure\/search\/search-query-lucene-examples<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"R model deployment with custom Docker image: \"ModuleNotFoundError: No module named 'azureml.api'\"",
        "Question_created_time":1602855221470,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/129038\/r-model-deployment-with-custom-docker-image-module",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to deploy an R inference script to Azure ML Service Endpoint as an Azure Container Instance. I have made the following steps:<\/p>\n<ul>\n<li>   created a custom Docker image from scratch and pushed it to the Azure Container Registry (associated with AML Workspace)<\/li>\n<li>   registered a custom environment in AML Workspace, based on the image in ACR<\/li>\n<li>   deployed R entry script (just a simple hello world script with init() and run() functions defined)\n<ul>\n<li>   the inference configuration uses the custom AML environment<\/li>\n<li>   deployment is made with Azure ML R SDK<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>The container instance is created, but the endpoint startup runs into error. Here is the output from the container instance:<\/p>\n<pre><code>2020-10-16T12:56:21,639812796+00:00 - gunicorn\/run \n2020-10-16T12:56:21,639290594+00:00 - iot-server\/run \n2020-10-16T12:56:21,640405198+00:00 - rsyslog\/run \n2020-10-16T12:56:21,735291424+00:00 - nginx\/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-10-16T12:56:23,736657191+00:00 - iot-server\/finish 1 0\n2020-10-16T12:56:23,834747728+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 20.0.4\nListening at: http:\/\/127.0.0.1:31311 (11)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 38\n\/bin\/bash: \/root\/miniconda3\/lib\/libtinfo.so.6: no version information available (required by \/bin\/bash)\nSPARK_HOME not set. Skipping PySpark Initialization.\nException in worker process\nTraceback (most recent call last):\n  File &quot;\/var\/azureml-server\/app.py&quot;, line 43, in &lt;module&gt;\n    from azureml.api.exceptions.ClientSideException import ClientSideException\nModuleNotFoundError: No module named 'azureml.api'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py&quot;, line 119, in init_process\n    self.load_wsgi()\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py&quot;, line 144, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 49, in load\n    return self.load_wsgiapp()\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 39, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/usr\/lib\/python3\/dist-packages\/gunicorn\/util.py&quot;, line 383, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/usr\/lib\/python3.8\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1014, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 671, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 783, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n    from app import main\n  File &quot;\/var\/azureml-server\/app.py&quot;, line 45, in &lt;module&gt;\n    from azure.ml.api.exceptions.ClientSideException import ClientSideException\nModuleNotFoundError: No module named 'azure.ml'\nWorker exiting (pid: 38)\nShutting down: Master\nReason: Worker failed to boot.\n2020-10-16T12:56:39,434787859+00:00 - gunicorn\/finish 3 0\n2020-10-16T12:56:39,435715063+00:00 - Exit code 3 is not normal. Killing image.\n<\/code><\/pre>\n<p>How do I install the azureml.api dependency, which can not be found? It doesn't seem to be part of the Azure ML SDK. I have installed the following dependencies in my Dockerfile:<\/p>\n<pre><code>RUN apt-get -y install python3-flask python3-rpy2 python3-azure python3-applicationinsights\nRUN pip install azureml-core\n<\/code><\/pre>\n<p>I also have Miniconda installed. Pip refers to Miniconda's pip.<\/p>\n<p>Or, is this dependency available to install at all? Should I use some pre-defined AML environment as the base Docker image? (Note: I am currently using bare FROM: ubuntu). Suggestions how to find and use the base images are also welcome, since this is not documented very well.<\/p>",
        "Question_closed_time":1603104240927,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=c02d5983-5261-45cb-9bb0-3e5f19b42ae9\">@Lauri Lehman  <\/a> Thanks for the question. Here is the <a href=\"https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fmedium.com%2Fmicrosoftazure%2Fhow-to-create-custom-docker-base-images-for-azure-machine-learning-environments-86aa4c7bc7b9&amp;data=02%7C01%7CRamprasad.Mula%40microsoft.com%7C49414af813754671ec7908d83863d1b5%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637321350687268940&amp;sdata=f5ebitkOUNxY8v7cOS2vFy12mBfuP%2BJVVzLbhAKVyXE%3D&amp;reserved=0\">document<\/a>  to Create Custom Docker Base Images for Azure Machine Learning Environments for R people.    <br \/>\nWe have used the AzureML <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.r_script_step.rscriptstep?view=azure-ml-py\">RScriptStep<\/a>  pipeline feature which allows you to point to CRAN or Github or custom URLS, but this requires authoring the pipeline in python or YAML.. In R You can also  these arguments in the Azuremlsdk R estimator function:  <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/reference\/estimator.html\">https:\/\/azure.github.io\/azureml-sdk-for-r\/reference\/estimator.html<\/a>    <br \/>\nAnother option that are not available through conda install as part of the R script with install.packages(\u201cpath\/*.tar.gz\u201d, repos=NULL))    <\/p>\n<p>One of the challenges is that the build at runtime can take a while to prepare the environment.  R likes to compile packages on Linux environments and a large package could have lots of dependencies which would take a while.  This is an R on Linux\/PaaS thing, rather than specific to AzureML    <\/p>\n<p>To make start up fast we created a custom docker image where you can tightly control the image ahead of runtime.  If you want to go in this direction you can find an example Dockerfile to get you started here..    <br \/>\n<a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\/blob\/master\/.azure-pipelines\/docker\/Dockerfile\">https:\/\/github.com\/Azure\/azureml-sdk-for-r\/blob\/master\/.azure-pipelines\/docker\/Dockerfile<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"AzureML and PowerBI compatible endpoint error - \"list index out of range\"",
        "Question_created_time":1602771468233,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/127842\/azureml-and-powerbi-compatible-endpoint-error-list",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I have produced a model that is deployed as an ACI, which I can send data to via the REST API in python using the code described here (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python<\/a>).    <\/p>\n<p>However I have ran into a problem producing a PowerBI compatible endpoint which requires an inference schema described here (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#power-bi-compatible-endpoint\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#power-bi-compatible-endpoint<\/a>).    <\/p>\n<p>I have adapted the input samples as required and the deployment goes ahead fine and is displayed as healthy. Checking the JSON, all seems fine with the schema. However when I try to send some data using the first script using the REST API, all that is returned is &quot;list index out of range&quot;. All that has changed is the addition of the inference schema entry script.    <\/p>\n<p>Any idea what might be causing this error? I have tried to change a variety of things to do with the data being sent and the entry script but it always ends with the same error.    <\/p>\n<p>Thanks    <\/p>\n<p>EDIT:    <\/p>\n<p>I should also clarify that the model returns a probability output of each class using a wrapper for .predict() which works fine before adding this PowerBI compatibility.     <\/p>\n<pre><code>class SklearnModelWrapper(mlflow.pyfunc.PythonModel):  \n        def __init__(self, model):  \n            self.model = model  \n        def predict(self, model_input):  \n            return self.model.predict_proba(model_input)  \n<\/code><\/pre>\n<p>This is a binary problem so the output for two rows of data is the format [[0.3, 0.7], [0.64, 0.36]] representing the probability for each class. I have tried this for the sample output in the schema and still no change, the same error is produced regardless of deploying a wrapped model that returns the probability per each class or a normal model that returns the class. Both work fine without the inference schema.    <\/p>\n<p>Entry script:    <\/p>\n<pre><code>import numpy as np  \nimport pandas as pd  \nimport joblib  \nfrom azureml.core.model import Model  \n  \nfrom inference_schema.schema_decorators import input_schema, output_schema  \nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType  \nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType  \nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType  \n  \ndef init():  \n    global model  \n    #Model name is the name of the model registered under the workspace  \n    model_path = Model.get_model_path(model_name = 'databricksmodelpowerbi2')  \n    model = joblib.load(model_path)  \n  \n#Provide 3 sample inputs for schema generation for 2 rows of data  \nnumpy_sample_input = NumpyParameterType(np.array([[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]], dtype = 'float64'))  \npandas_sample_input = PandasParameterType(pd.DataFrame({'value': [2400.0, 368.55], 'delayed_percent': [78.26086956521739, 96.88311688311687], 'total_value_delayed': [11100.0, 709681.1600000012], 'num_invoices_per30_dealing_days': [3.612565445026178, 73.88059701492537], 'delayed_streak': [3.0, 44.0], 'prompt_streak': [0.0, 0.0]}))  \nstandard_sample_input = StandardPythonParameterType(0.0)  \n  \n# This is a nested input sample, any item wrapped by `ParameterType` will be described by schema  \nsample_input = StandardPythonParameterType({'input1': numpy_sample_input,   \n                                            'input2': pandas_sample_input,   \n                                            'input3': standard_sample_input})  \n  \nsample_global_parameters = StandardPythonParameterType(1.0) #this is optional  \nsample_output = StandardPythonParameterType([1.0, 1.0])  \n  \n@input_schema('inputs', sample_input)  \n@input_schema('global_parameters', sample_global_parameters) #this is optional  \n@output_schema(sample_output)  \n  \ndef run(inputs, global_parameters):  \n    try:  \n        data = inputs['input1']  \n        # data will be convert to target format  \n        assert isinstance(data, np.ndarray)  \n        result = model.predict(data)  \n        return result.tolist()  \n    except Exception as e:  \n        error = str(e)  \n        return error  \n<\/code><\/pre>\n<p>Prediction script:    <\/p>\n<pre><code>import requests  \nimport json  \nfrom ast import literal_eval  \n  \n# URL for the web service  \nscoring_uri = ''  \n## If the service is authenticated, set the key or token  \n#key = '&lt;your key or token&gt;'  \n  \n# Two sets of data to score, so we get two results back  \ndata = {&quot;data&quot;: [[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]]}  \n# Convert to JSON string  \ninput_data = json.dumps(data)  \n  \n# Set the content type  \nheaders = {'Content-Type': 'application\/json'}  \n## If authentication is enabled, set the authorization header  \n#headers['Authorization'] = f'Bearer {key}'  \n  \n# Make the request and display the response  \nresp = requests.post(scoring_uri, input_data, headers=headers)  \nprint(resp.text)  \n  \nresult = literal_eval(resp.text)  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parameters Tuning for Randomforest",
        "Question_created_time":1603934642440,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/143528\/parameters-tuning-for-randomforest",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I followed the samples from DP-100 lab 8A.<\/p>\n<p><a href=\"https:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/08A%20-%20Tuning%20Hyperparameters.ipynb\">https:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/08A%20-%20Tuning%20Hyperparameters.ipynb<\/a><\/p>\n<p>I tried to parameter tunning for randomforest regressor on Boston Data.<\/p>\n<p>However, the code is running. I am not able to get metric and the output of the result.<\/p>\n<p>What is the problem.<\/p>\n<hr \/>\n<pre><code>%%writefile $experiment_folder\/diabetes_training.py\n# Import libraries\nimport argparse\nimport joblib\nimport os\nfrom azureml.core import Run\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\n# Set regularization parameter\nparser = argparse.ArgumentParser()\nparser.add_argument(&amp;#39;--regularization&amp;#39;, type=float, dest=&amp;#39;reg_rate&amp;#39;, default=0.01, help=&amp;#39;regularization rate&amp;#39;)\nargs = parser.parse_args()\nreg = args.reg_rate\n\n# Get the experiment run context\nrun = Run.get_context()\n\n# load the diabetes dataset\nprint(&amp;#34;Loading Data...&amp;#34;)\ndiabetes = run.input_datasets[&amp;#39;diabetes&amp;#39;].to_pandas_dataframe() # Get the training data from the estimator input\n\n# Separate features and labels\nX, y = diabetes[[&amp;#39;Pregnancies&amp;#39;,&amp;#39;PlasmaGlucose&amp;#39;,&amp;#39;DiastolicBloodPressure&amp;#39;,&amp;#39;TricepsThickness&amp;#39;,&amp;#39;SerumInsulin&amp;#39;,&amp;#39;BMI&amp;#39;,&amp;#39;DiabetesPedigree&amp;#39;,&amp;#39;Age&amp;#39;]].values, diabetes[&amp;#39;Diabetic&amp;#39;].values\n\n# Split data into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\n# Train a logistic regression model\nprint(&amp;#39;Training a logistic regression model with regularization rate of&amp;#39;, reg)\nrun.log(&amp;#39;Regularization Rate&amp;#39;,  np.float(reg))\nmodel = LogisticRegression(C=1\/reg, solver=&amp;#34;liblinear&amp;#34;).fit(X_train, y_train)\n\n# calculate accuracy\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nprint(&amp;#39;Accuracy:&amp;#39;, acc)\nrun.log(&amp;#39;Accuracy&amp;#39;, np.float(acc))\n\n# calculate AUC\ny_scores = model.predict_proba(X_test)\nauc = roc_auc_score(y_test,y_scores[:,1])\nprint(&amp;#39;AUC: &amp;#39; + str(auc))\nrun.log(&amp;#39;AUC&amp;#39;, np.float(auc))\n\nos.makedirs(&amp;#39;outputs&amp;#39;, exist_ok=True)\n# note file saved in the outputs folder is automatically uploaded into experiment record\njoblib.dump(value=model, filename=&amp;#39;outputs\/diabetes_model.pkl&amp;#39;)\n\nrun.complete()\n\n\nfrom azureml.core import Experiment\nfrom azureml.train.sklearn import SKLearn\nfrom azureml.train.hyperdrive import GridParameterSampling, MedianStoppingPolicy, HyperDriveConfig, PrimaryMetricGoal, choice, normal\nfrom azureml.widgets import RunDetails\n\n\n# Sample a range of parameter values\nparams = GridParameterSampling(\n    {\n        # Tuning the Parameters\n\n        &amp;#39;--max_depth&amp;#39;:choice(70,100,130,160)\n    }\n)\n\n\n# Get the training dataset\nboston_ds = ws.datasets.get(&amp;#34;boston dataset&amp;#34;)\n\n# Create an estimator that uses the remote compute\nhyper_estimator = SKLearn(source_directory=experiment_folder,\n                          inputs=[boston_ds.as_named_input(&amp;#39;boston&amp;#39;)], # Pass the dataset as an input...\n                          pip_packages=[&amp;#39;azureml-sdk&amp;#39;], # ...so we need azureml-dataprep (it&amp;#39;s in the SDK!)\n                          entry_script=&amp;#39;train_boston.py&amp;#39;,\n                          compute_target = training_cluster,)\n\n\n#early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)\n\n\n# Configure hyperdrive settings\nhyperdrive = HyperDriveConfig(estimator=hyper_estimator, \n                          hyperparameter_sampling=params, \n                          policy=None, \n                          primary_metric_name=&amp;#39;MAE&amp;#39;, \n                          primary_metric_goal= PrimaryMetricGoal.MINIMIZE, \n                          max_total_runs=6,\n                          max_concurrent_runs=4)\n\n# Run the experiment\nexperiment = Experiment(workspace = ws, name = &amp;#39;boston_training_hyperdrive&amp;#39;)\nrun = experiment.submit(config=hyperdrive)\n\n# Show the status in the notebook as the experiment runs\nRunDetails(run).show()\nrun.wait_for_completion()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"LineTooLong('got more than 65536 bytes when reading the header line\" error while running a python code on MSML 9.3 using az ml admin diagnostic code option",
        "Question_created_time":1604054581813,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/145900\/linetoolong(got-more-than-65536-bytes-when-reading",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>&quot;LineTooLong('got more than 65536 bytes when reading the header line&quot; error while running a python code on MSML 9.3 using <strong>az ml admin diagnostic code<\/strong> option.  <\/p>\n<p>could anyone help to figure out the issue here ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Consume Azure ML Web Service with Postman: how to pass arguments?",
        "Question_created_time":1603965300457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/144230\/consume-azure-ml-web-service-with-postman-how-to-p",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to pass parameters to an Azure ML Web Service with Postman? I created an R web service endpoint that runs in an Azure Container Instance. My run function has one argument (&quot;data&quot;). I can call the web service using Azure ML R SDK (using invoke_webservice()) and the input parameter is read successfully from the request content. The input is constructed like:  <\/p>\n<pre><code>toJSON(data.frame(data=&quot;This is my test string&quot;))\n<\/code><\/pre>\n<p>Result:  <\/p>\n<pre><code>[{&quot;data&quot;: &quot;This is my test string&quot;}]\n<\/code><\/pre>\n<p>If I create a Postman request and copy the input to the request body, the input parameter is not passed to the web service. The web service can return a static output to Postman but the variable data is always empty. Is this a property of the ML Web Service? If not, how can I set up the request body so that the argument is read successfully? I have tried many variations, but none have worked.  <\/p>\n<p>I have set content-type header to application\/json. I don't have authentication in the web service, since it is just a test instance.  <\/p>\n<p>Ultimately, we need to call the web service with C# from Azure Function. I know that we can use the C# template from documentation and it can probably pass the parameter to the web service, but it would be nice to be able to test the web service with Postman.<\/p>",
        "Question_closed_time":1603976126077,
        "Answer_score_count":1.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Try this in postman.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/35960-postman.png?platform=QnA\" alt=\"35960-postman.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"(Beginner\/New to Azure ML)Unable to execute Jupyter Notebook code in Azure ML",
        "Question_created_time":1603639845287,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/138151\/(beginner-new-to-azure-ml)unable-to-execute-jupyte",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hello all,    <br \/>\nWhile trying to follow official guide for MOC as described here:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-in\/learn\/modules\/classify-images-custom-vision\/3-create-image-classifier\">https:\/\/learn.microsoft.com\/en-in\/learn\/modules\/classify-images-custom-vision\/3-create-image-classifier<\/a>    <\/p>\n<p>I am stuck at step 3 under 'Download the exercise files':    <\/p>\n<p>When the new notebook has been created, ensure that the compute instance you created previously is selected in the Compute box, and that it has a status of Running. Then, in the rectangular cell that has been created in the notebook, paste the following code:    <\/p>\n<p>!git clone <a href=\"https:\/\/github.com\/MicrosoftDocs\/ai-fundamentals\">https:\/\/github.com\/MicrosoftDocs\/ai-fundamentals<\/a>    <\/p>\n<p>And same issue running jupyter notebook here (step 11 running the code to test deployment):    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-in\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/deploy-service\">https:\/\/learn.microsoft.com\/en-in\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/deploy-service<\/a>    <\/p>\n<p>What could be missing,why am I unable to see the output of the execution, it was working fine 2 days back with old Compute Instance(even tried creating new instance but unable to see any output or import of github folder).    <\/p>\n<p>Regards.    <br \/>\nAditya Garg    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to deploy a autoML as a webservice without using C#, Go, Java, or Python (just a browser)",
        "Question_created_time":1603290567957,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/134024\/unable-to-deploy-a-automl-as-a-webservice-without",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am running this tutorial: <a href=\"https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml\">https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml<\/a>    <\/p>\n<p>and struggle under &quot;next steps&quot; to deploy this model to a browser user interface of some kind (where I can manually type in the input values and press &quot;predict&quot; to get the output value).     <\/p>\n<p>Background: I would like to present this for a seminar &quot;AI without any code&quot; and hence I will not call this REST-API in any other place but try to stay in the (Azure) web ecosystem. Any chance to get such a webinterface (functionality)?<\/p>",
        "Question_closed_time":1603319937640,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks for reaching out. Currently, Azure AutoML does not support consuming deployed web services via UI. You can create a client for the service, or use python to consume the web service via Azure ML Notebooks. Sorry for the inconvenience.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Variable importance in Linear regression",
        "Question_created_time":1603453945917,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/136931\/variable-importance-in-linear-regression",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>Am running a Linear regression model in Azure ML studio having multiple features(both numeric and categorical).  <\/p>\n<p>Is there a way to get the important features among all the given input features?  <\/p>\n<p> From the train model I see weights assigned to each of the variable. Does Azure ML regression normalize the variables before running the model. If so can we assume this weight for the important features ?  <\/p>\n<p>Can we export this weights to csv file ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"If on Azure any reason not to use the Azure ML platform vs a dedicated VM and azure functions",
        "Question_created_time":1603468321273,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/137047\/if-on-azure-any-reason-not-to-use-the-azure-ml-pla",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I come from a full stack dev background and I don't know that much about ML, just evaluating a proposal. We have Azure web apps, Azure SQL and Azure BI for our SaaS. Seems it would make more sense to use the Azure ML platform and have it create the private endpoints and manage deployment, less setup...  <br \/>\nThis is more for text parsing, good and bad messages and suggestion like spam detection.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't create dataset from csv file - error: 'Delimiter' is not specified or invalid.",
        "Question_created_time":1603103147810,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/131015\/cant-create-dataset-from-csv-file-error-delimiter",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have got a problem. I can't add my csv files to datasets. Every time I have got error:  <\/p>\n<p>&quot;message&quot;: &quot;'Delimiter' is not specified or invalid.&quot;  <\/p>\n<p>Is there anyway to specified this while uploading csv file?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Registered Dataset is not logged as reference in Azure Machine Service Experiment",
        "Question_created_time":1601553618217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/114019\/registered-dataset-is-not-logged-as-reference-in-a",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_body":"<p>Hi there,  <\/p>\n<p>I have tried executing the notebook &quot;tutorial-1st-experiment-sdk-train.ipynb&quot; given by Azure as part of the tutorial in Azure Machine Learning service itself.   <\/p>\n<p>The only  change I made was, rather taking the input directly from package, I registered the dataset first and referred that in this notebook. My intention was to see how input dataset can be tracked in the experiment.   <\/p>\n<p>But, no luck. I was able to successfully execute the notebook, but in experiment, &quot;Input datasets&quot; was blank, not referenced, though I used a registered latest version of dataset from Azure as my input.  <\/p>\n<p>How do we tag the input dataset to an experiment when executing from Azure Machine Learning Notebook?  <\/p>\n<p>Thanks,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error: Scoring FE IP address not updated yet, when enabling the use of internal load balancer",
        "Question_created_time":1602573604000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/124588\/error-scoring-fe-ip-address-not-updated-yet-when-e",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hello, currently, I'm having issues to enable private load balancer after attaching an existing AKS Cluster to AML Workspace. The error message &quot;Scoring FE IP address not updated yet&quot; is displayed when trying to enable private load balancer by following the instructions at <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=azure-cli#internal-aks-load-balancer\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=azure-cli#internal-aks-load-balancer<\/a>. The AKS Cluster is in a separate VNet than the AML Workspace. The two VNet have peered. Also, I've tried using Azure CLI but receiving the same error message. Can you provide some help on resolving this?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error when Visualizing Dataset in Microsoft Azure Machine Learning Studio",
        "Question_created_time":1602791972497,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/127980\/error-when-visualizing-dataset-in-microsoft-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>In Azure Machine learning Studio, I have imported a dataset from a locally stored spreadsheet. In the designer, I drag the dataset into the workspace, right click, and select 'Visualize. I get the following error:   <\/p>\n<p>&quot;Unable to visualize this dataset. This might be because your data is stored behind a virtual network or your data does not support profile&quot;. I've searched for hours for a remedy, but find nothing.   <\/p>\n<p>What do I do to fix this error?<\/p>",
        "Question_closed_time":1603128837010,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=ab00ff52-eb99-4909-97c6-13620f09e957\">@Dana Shields  <\/a> I have tried this scenario with my workspace and i was able to replicate the message you have seen. It looks like you are using the Dataset type as File while creating the dataset which is causing the issue. Please register the dataset as Tabular type and then use the dataset in designer. This should show you the preview of the data. Here is a screen shot from my workspace of the designer.    <\/p>\n<p><img src=\"\/answers\/storage\/temp\/33346-image.png\" alt=\"33346-image.png\" \/>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Batch scoring pipeline NodeStartError \/ StorageErrorException",
        "Question_created_time":1599466176397,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/88085\/batch-scoring-pipeline-nodestarterror-storageerror",
        "Question_score_count":0,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I'm trying to build a batch scoring pipeline in Azure ML using this Microsoft MLOpsPython repository. (<a href=\"https:\/\/github.com\/microsoft\/MLOpsPython\">https:\/\/github.com\/microsoft\/MLOpsPython<\/a>)  <\/p>\n<p>However, when I run the pipeline it fails at the batch scoring step and it says:  <\/p>\n<pre><code>User program failed with NodeStartError: Failed to start node after 10 tries. Please check logs for error. You can check logs\/readme.txt for the layout of logs.\n<\/code><\/pre>\n<p>I went to the logs in the blob storage &gt; azureml &gt; [run id] &gt; logs &gt; sys &gt; node &gt; [ip] &gt; _boot.txt and found these errors:  <\/p>\n<pre><code>azure.storage.blob._generated.models._models_py3.StorageErrorException: Operation returned an invalid status 'Specified feature is not yet supported for hierarchical namespace accounts.'\n\nazure.core.exceptions.HttpResponseError: Specified feature is not yet supported for hierarchical namespace accounts.\n\nTypeError: Object of type AioHttpTransportResponse is not JSON serializable\n<\/code><\/pre>\n<p>I tried to Google these errors but I couldn't find any info.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure machine learning data export module failure",
        "Question_created_time":1602687603067,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/126502\/azure-machine-learning-data-export-module-failure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I want to export the data from my batch flow with the use of the data export module. Tried multiple file shares but get the following error.    <\/p>\n<p>User program failed with UserError: ScriptExecutionException was caused by WriteStreamsException.    <br \/>\n  WriteStreamsException was caused by UnexpectedException.    <br \/>\n    Unexpected exception while writing files with writer 'delimited'.  <br \/>\n      StreamAccessException was caused by NotFoundException.  <br \/>\n        File Share '[REDACTED]' does not exist at '[REDACTED]'.  <br \/>\n| session_id=e1ee8699-3a94-4ea6-ab5d-f5bb945d56f3    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/32402-image.png?platform=QnA\" alt=\"32402-image.png\" \/>    <\/p>\n<p>The file share name is the Azure named file share name or is this something else. Cannot find an eample.    <\/p>\n<p>The export works to local ML workspace, but this doesn't accept folders creation.    <\/p>",
        "Question_closed_time":1602726430747,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hello,    <\/p>\n<p>Thanks for reaching out to us. The file share name is the name of FILE_SHARE_CONTAINER     <\/p>\n<p>Please refer to below document for more details:    <\/p>\n<p>Export data module: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data<\/a>    <\/p>\n<p>Data storage - Azure File Share: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-file-share\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-file-share<\/a>    <\/p>\n<p>Please let me know if you have more questions.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Navigating to azure ml studio",
        "Question_created_time":1602782362910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/127890\/navigating-to-azure-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I already set up a free account by didn't know how to navigate to azure machine learning studio to conduct my analysis. Can you show me how? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"i cant access machine learning workspace",
        "Question_created_time":1602927883520,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/129615\/i-cant-access-machine-learning-workspace",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>good day    <\/p>\n<p>im trying to learn data science vi aMicrosoft Learn learn and i cant access the machine learning workspace,it keeps saying oops cannot create market place item.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML classic webservices deploy - Error When Doing Test Request-Response",
        "Question_created_time":1602523062553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123854\/azure-ml-classic-webservices-deploy-error-when-doi",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>So, I created an experiment, based on one of many examples and picked a dataset that required some transformations, columns choosing and categorical features. The model creation worked just fine, with only smaller hiccups. However as I deployed the webservice, the API is requesting the new column data set (created after the feature transformation) and not the original data set. This does not serve my purpose, as my aim for creating a service that would adhere to the original dataset features.  <\/p>\n<p>What am I doing wrong? Or shall I be required to implement the data transformation. Also, the feature I am trying to predict is also showing up as a input feature, and that does not make sense.  <\/p>\n<p>Any pointers?  <\/p>",
        "Question_closed_time":1602859603930,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>After further investigation, it has been determined that by design, studio (classic) will echo this error when using convert to indicator values transformation, hence, we suggest not using convert to indicator values block in the inference pipeline. However, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/convert-to-indicator-values\">designer<\/a>, indicator values transformation is saved so that this module can be used in the inference pipeline. Sorry for the inconvenience, but hope this helps!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Is it possible to migrate Machine learning from Classic Portal to ARM Portal?",
        "Question_created_time":1601646927710,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/115313\/is-it-possible-to-migrate-machine-learning-from-cl",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi there, do we know if it's possible to migrate Machine learning from Classic Portal to ARM Portal without having to do it manully?  <\/p>\n<p>This would include trained models etc.  <\/p>\n<p>Thanks  <br \/>\nGregor<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I deploy R code & models as a web service on a ML Ubuntu server deployed on Azure cloud, accessible from the Internet?",
        "Question_created_time":1602754539597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/127379\/how-do-i-deploy-r-code-models-as-a-web-service-on",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,     <\/p>\n<p>I would like to build a simple model in R and deploy it on a Machine Learning Server instance (Linux Ubuntu 16.04) that I created in Azure.    <br \/>\nThis web service should be accessible from the Internet, through REST API calls.    <\/p>\n<p>I tried to use the approach described here: <a href=\"https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service\">https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service<\/a>    <\/p>\n<p>The problem is that I cannot login from R into the ML Server instance, namely, the following command fails:    <\/p>\n<pre><code>remoteLogin(&amp;#34;http:\/\/myhost.switzerlandnorth.cloudapp.azure.com:12800&amp;#34;, username = &amp;#34;myusername&amp;#34;, password = &amp;#34;mypassword&amp;#34;)  \n<\/code><\/pre>\n<p>On the other hand, I can log into the ML Server instance from the command line, through ssh: the following command    <\/p>\n<pre><code>ssh  myusername:12800@myhost.switzerlandnorth.cloudapp.azure.com  \n<\/code><\/pre>\n<p>opens a terminal on the ML Server machine (the terminal greeting is &quot;Welcome to the Linux Data Science Virtual Machine on Azure!&quot;).    <\/p>\n<p>What I am trying to achieve is explained in this figure:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/configure-machine-learning-server-one-box\">https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/configure-machine-learning-server-one-box<\/a>    <\/p>\n<p>In that picture, I would want the &quot;one-box configuration&quot; to run entirely on the Microsoft Cloud (not on my laptop, or on other servers).    <br \/>\nAnd I would like to access the R models from a front-end app (deployed elsewhere) through authenticated REST API calls to the &quot;one-box&quot;.    <br \/>\nThis is how I provisioned my Linux Data Science VM on Azure:    <\/p>\n<p><a href=\"https:\/\/azuremarketplace.microsoft.com\/en-us\/marketplace\/apps\/deploy-r.operationalization?tab=overview\">https:\/\/azuremarketplace.microsoft.com\/en-us\/marketplace\/apps\/deploy-r.operationalization?tab=overview<\/a>    <\/p>\n<p>This is the kind of R script that I'd like to use to deploy my R models on that DSVM:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service\">https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service<\/a>    <\/p>\n<p>This is what I'm trying to do:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/r-reference\/mrsdeploy\/mrsdeploy-package\">https:\/\/learn.microsoft.com\/en-us\/machine-learning-server\/r-reference\/mrsdeploy\/mrsdeploy-package<\/a>    <\/p>\n<p>But all examples I could find for the <code>remoteLogin()<\/code> function use a localhost server, not a remote server on the Microsoft Azure Cloud, see e.g.    <\/p>\n<pre><code>remoteLogin(&amp;#34;https:\/\/localhost:1280&amp;#34;, session=TRUE, diff=TRUE, commandline=TRUE)  \n<\/code><\/pre>\n<p>See e.g. <a href=\"https:\/\/blog.revolutionanalytics.com\/2017\/03\/running-your-r-code-azure.html\">https:\/\/blog.revolutionanalytics.com\/2017\/03\/running-your-r-code-azure.html<\/a>    <\/p>\n<p>I searched the Q&amp;A forum, but could only find threads that are vaguely related to my issue, such as:    <\/p>\n<p><a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b5cc5cff-ad46-4772-8d01-793dd067e4a6\/pass-web-service-input-to-r-script?forum=MachineLearning\">https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b5cc5cff-ad46-4772-8d01-793dd067e4a6\/pass-web-service-input-to-r-script?forum=MachineLearning<\/a>    <br \/>\n<a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b47b0dcf-d92d-4bdf-9a19-f8ba0f5a29cc\/r-web-service-input?forum=MachineLearning\">https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b47b0dcf-d92d-4bdf-9a19-f8ba0f5a29cc\/r-web-service-input?forum=MachineLearning<\/a>    <br \/>\n<a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/598b0e20-5f12-47a2-8d8a-81dbff83ef6d\/how-to-consume-machine-learning-webservice-using-r?forum=MachineLearning\">https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/598b0e20-5f12-47a2-8d8a-81dbff83ef6d\/how-to-consume-machine-learning-webservice-using-r?forum=MachineLearning<\/a>    <\/p>\n<p>Also see here for related threads:    <br \/>\n<a href=\"https:\/\/medium.com\/@RonakTalreja\/deploying-apis-the-microsoft-way-ffde1fdd027a\">https:\/\/medium.com\/@RonakTalreja\/deploying-apis-the-microsoft-way-ffde1fdd027a<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/previous-versions\/machine-learning-server\/install\/operationalize-r-server-one-box-config\">https:\/\/learn.microsoft.com\/en-us\/previous-versions\/machine-learning-server\/install\/operationalize-r-server-one-box-config<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Databrick workspace linking to Azure Machine Learning workspace error unable to get Workspace.from_config()",
        "Question_created_time":1594145605387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/43845\/azure-databrick-workspace-linking-to-azure-machine",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>We are in a POC of Azure Databricks and Azure Machine Learning integration so that we can advance our MLOps practice.<\/p>\n<p>We have been dealing the with workspace linking issue for the past few weeks and have hit a wall. We worked with Databricks and search the internet for solution but were not successful. As AML is still in Preview, documentation may not be all there.<\/p>\n<p>I think this example below is the most recent and calls out how the linking should work. Is the statement highlighted below correct and if so, is there detail configuration that we are missing besides clicking the &quot;Link Azure ML Workspace&quot; button?<\/p>\n<p>[https:\/\/tsmatz.github.io\/azure-databricks-exercise\/exercise10-mlflow.html][1]<\/p>\n<p>Note : Here (in this hands-on) we connect to an Azure Machine Learning workspace by running Python code, however, you can now use the following &quot;<strong>Link Azure ML Workspace<\/strong>&quot; button (simplified integrated experience) in Azure Databricks launcher page to connect a new or existing workspace. <strong>Once you have linked with this experience, you don't need to run the following ws.write_config(), Workspace.from_config(), and mlflow.set_tracking_uri(<\/strong>).<\/p>\n<p>We have done the following.  <\/p>\n<ol>\n<li> Linked the workspace via &quot;Link Azure ML Workspace&quot; button  <\/li>\n<li> Run the attached MLFLow + AML \u2013 Combined.dbc  <\/li>\n<li> Failure in Cmd 15  <br \/>\nws = Workspace.from_config()<\/li>\n<\/ol>\n<h2 id=\"usererrorexception-usererrorexception\">UserErrorException: UserErrorException:<\/h2>\n<p>UserErrorException Traceback (most recent call last)  <br \/>\n&lt;command-4338604541924184&gt; in &lt;module&gt;  <br \/>\n3  <br \/>\n4  <br \/>\n----&gt; 5 ws = Workspace.from_config()  <br \/>\n6 exp = &quot;\/adb\/XXXXXXXXXXXXXXX\/XXXXXXXXXXXX\/Users\/######@#######.com\/MLFlow + AML - Combined&quot;  <br \/>\n7 runs = list(exp.get_runs())<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/core\/workspace.py in from_config(path, auth, _logger, _file_name)  <br \/>\n272 'We could not find config.json in: {} or in its parent directories. '  <br \/>\n273 'Please provide the full path to the config file or ensure that '  <br \/>\n--&gt; 274 'config.json exists in the parent directories.'.format(normalized_path))  <br \/>\n275  <br \/>\n276 subscription_id, resource_group, workspace_name = project_info.get_workspace_info(<\/p>\n<p>UserErrorException: UserErrorException:  <br \/>\nMessage: We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;  <br \/>\n}  <br \/>\n}  <br \/>\n4. Config.json manually place into directory path specified in error message<\/p>\n<ol start=\"5\">\n<li>  Perform workspace write_config(). But, forces interactive authentication which is blocked by our organization policy.<\/li>\n<\/ol>\n<p>Besides performing the &quot;Link Azure ML Workspace&quot; via the button from Databricks, we have not performed any other configuration. Based on the documentation, it should just work. Appreciate any assistance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error When Doing Test Request-Response",
        "Question_created_time":1602017369767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/118546\/error-when-doing-test-request-response",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_body":"<p>I'm doing a Test Request-Response in Azure Machine Learning Studio (Classic), and am getting the following error below. The model trained and tested fine. Why would this error now be throwing when deployed as a web service?   <\/p>\n<p>Error Message: Score Model (AFx Library) : table: The data set being scored must contain all features used during training, missing feature(s): 'Rating_HashingFeature_485', 'Rating_HashingFeature_148', 'Rating_HashingFeature_536', 'Rating_HashingFeature_437', 'Preprocessed Review_HashingFeature_414', 'Preprocessed Review_HashingFeature_666', 'Preprocessed Review_HashingFeature_413', 'Preprocessed Review_HashingFeature_522', 'Preprocessed Review_HashingFeature_602', 'Preprocessed Review_HashingFeature_746'.  <br \/>\nSite Path: \/workspaces\/a5be8959d5e047d3af0d350190323087\/webservices\/ba9b6b4066df42e5bb5edd9c0ad9062e\/endpoints\/default\/test\/rrs  <br \/>\nActivity ID: 82e53138-b3b9-4a94-8695-0b8152c505ac  <br \/>\nRequest ID: 3f55ed33-f261-4103-ba76-9a36e3a3b03c  <br \/>\nWorkspace ID: a5be8959d5e047d3af0d350190323087  <br \/>\nWorkspace Type: Free  <br \/>\nUser Role: Owner  <br \/>\nTenant ID: 6cacd170-f897-4b19-ac58-46a23307b80a<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delimeter error while adding new dataset in ml service",
        "Question_created_time":1602240911150,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/121529\/delimeter-error-while-adding-new-dataset-in-ml-ser",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hello,     <br \/>\nI have problem with adding new dataset in ml service. After upload i'm getting below error (screen)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/31188-error.jpg?platform=QnA\" alt=\"31188-error.jpg\" \/>    <\/p>\n<p>I think is a new issue, because few days ago everything was good.    <br \/>\nIn my csv file is semicolon delimeter.    <\/p>\n<p>Thank you in advance!    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Pickle file size Azure Machine Learning Service",
        "Question_created_time":1599612419390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/89630\/ml-pickle-file-size-azure-machine-learning-service",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Is there any restriction on registering an ML pickle model into Azure Machine Learning Service in terms of the size of the pickle file?  <\/p>\n<p>Does it cause latency in realtime data processing and getting the prediction results from the pickle file if we have a  model that let's say it 5MB and the other one is 500MB (The bigger file has better performance in terms of accuracy)?  <br \/>\nThanks,  <\/p>\n<p>John<\/p>",
        "Question_closed_time":1599800075417,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=ccc37df1-9b57-4e84-920a-f92d8316aa7c\">@JJA  <\/a> Thanks, For ACI we recommend not using a model over 1GB in size.    <br \/>\nFor AKS you are limited by the memory resources that you request for your service, minus about 500mb for the running python process in the pod.    <\/p>\n<p>There will be no difference in prediction speed once the model is successfully deployed.    <br \/>\nRegistering will take longer as we have to upload the model, and deploying will take longer as the service must download the model.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Parquet file registered in a Tabular format is loaded with worng values",
        "Question_created_time":1602081582550,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/119459\/parquet-file-registered-in-a-tabular-format-is-loa",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I'm facing an issue that pandas DataFrames loaded from the following two datasets are not identical although the same parquet file is used to register.  <\/p>\n<ul>\n<li> DataFrame loaded with &quot;to_pandas_dataframe()&quot; from a dataset registered in a <strong>Tabular<\/strong> format  <\/li>\n<li> DataFrame loaded with &quot;pandas.read_parquet()&quot; from a dataset registered in a <strong>File<\/strong> format  <\/li>\n<\/ul>\n<p>Specifically, DataFrame from the Tabular format has wrong values in some fields. Let's say, a DataFrame has 5 rows, and a field &quot;col1&quot; should has values [&quot;A&quot;, <strong>&quot;A&quot;<\/strong>, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;] from the top, but it has [&quot;A&quot;, <strong>&quot;B&quot;<\/strong>, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;]. The second element should have &quot;A&quot;, but somehow it has &quot;B&quot;. Wrong values are not completely unknown or broken values, but other values used in the same field seem to be set.  <\/p>\n<p>I'd like to know there is a known issue to see how the situation (fix plan, etc.) is going. I cannot give reproducible environment here because this issue happened with internal dataset, and I tried but couldn't reproduce it with toy dataset that I can share in public.  <\/p>\n<p>Environment that I created the parquet file  <\/p>\n<ul>\n<li> OS: Windows 10  <\/li>\n<li> Python: 3.7.4  <\/li>\n<li> pandas: 0.25.1  <br \/>\nThe parquet file was created with &quot;df.to_parquet(output_path, index=False)&quot; without any other args.  <\/li>\n<\/ul>\n<p>Environment that I loaded dataset registered on AzureML  <\/p>\n<ul>\n<li> Notebook in AzureML workspace with default environment.  <\/li>\n<\/ul>\n<p>Pseudo script used to load dataset  <br \/>\nFor Tabular dataset   <\/p>\n<pre><code>from azureml.core import Dataset, Workspace\n\nws = Workspace.from_config()\ndf = Dataset.get_by_name(workspace=ws, name='dataset_name1').to_pandas_dataframe()\n<\/code><\/pre>\n<p>For File dataset   <\/p>\n<pre><code>from pathlib import Path\n\nfrom azureml.core import Dataset, Workspace\nimport pandas as pd\n\nws = Workspace.from_config()\nds = Dataset.get_by_name(workspace=ws, name='dataset_name2')\nwith ds.mount() as m:\n    path = str(Path(m.mount_point) \/ 'filename.parquet')\n    df = pd.read_parquet(path)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What does \"local\" mean in compute target?",
        "Question_created_time":1600495202147,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/99901\/what-does-local-mean-in-compute-target",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi guys, I'm new to Azure ML. Following the URL below, I tried to run my python script on local machine. By local, I meant exactly Windows on my local physical machine in my house.  But it seems python script 'transform_titanic.py' was executed on Azure.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#local-compute-target\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#local-compute-target<\/a>    <\/p>\n<p>I executed the script below on my local computer, and expected it runs 'transform_titanic.py' on my local computer.    <\/p>\n<pre><code>   from azureml.core import Environment, Experiment, ScriptRunConfig, Workspace  \n   from dotenv import load_dotenv  \n     \n   load_dotenv()  \n     \n   ws = Workspace(  \n       os.environ['SUBSCRIPTION_ID']  \n       os.environ['RESOURCE_GROUP']  \n       os.environ['WORKSPACE_NAME']  \n   )  \n     \n   exp = Experiment(workspace=ws, name='experiment')  \n     \n   env = Environment('user-managed-env')  \n   env.python.user_managed_dependencies = True  \n     \n   script_run_config = ScriptRunConfig(  \n       source_directory='src\/transform',  \n       script='transform_titanic.py',  \n       arguments=['--input_dataset_name1', 'titanic'],  \n   )  \n     \n   script_run_config.run_config.target = 'local'  \n   script_run_config.run_config.environment = env  \n     \n   run = exp.submit(config=script_run_config)  \n   print(run.get_portal_url())  \n   run.wait_for_completion()  \n<\/code><\/pre>",
        "Question_closed_time":1600495830720,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Sorry, I found it was run on my local computer. Some artifact created in the script was in C:\\Users{username}\\AppData\\Local\\Temp\\azureml_runs\\local_experiment_XXXXXXXXXX  <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Azure ML Endpoint Wont deploy on AKS with Azure ML Studio",
        "Question_created_time":1600005134313,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/93418\/azure-ml-endpoint-wont-deploy-on-aks-with-azure-ml",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Got problem while deploying Azure ML real-time Endpoint on AKS with Azure ML Studio. It remains in Transitioning state indefinitely. Looked in AKS event logs and found that error is  <\/p>\n<blockquote>\n<p>Failed to pull image  <br \/>\n  &quot;viennaglobal.azurecr.io\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849&quot;:  <br \/>\n  [rpc error: code = Unknown desc = Error response from daemon: Get  <br \/>\n  https:\/\/viennaglobal.azurecr.io\/v2\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849\/manifests\/latest:  <br \/>\n  unauthorized: Application not registered with AAD., rpc error: code = Unknown  <br \/>\n  desc = Error response from daemon: Get  <br \/>\n  https:\/\/viennaglobal.azurecr.io\/v2\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849\/manifests\/latest:  <br \/>\n  unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization  <br \/>\n  for more information.]  <\/p>\n<\/blockquote>\n<p>It repeat this action with no success. This Inference cluster created with Azure ML Dashboard, and it worked week ago without any unauthorized problems. Tried to create new inference clusters, endpoints but with no success  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"timestamp is in POSIXlt vector format in Azure Auto ML",
        "Question_created_time":1601961656490,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/117596\/timestamp-is-in-posixlt-vector-format-in-azure-aut",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>What if timestamp is in POSIXlt vector format in Azure Auto ML? I am putting data in timestamp column in azure ML studio and it's not detecting<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best Practices for Routing Requests within Inference Clusters",
        "Question_created_time":1601043259400,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/107990\/best-practices-for-routing-requests-within-inferen",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Hi,    <\/p>\n<p>I have a Kubernetes Service attached as an inference cluster to an azure machine learning workspace. I have deployed multiple models to that the AKS service, each with their own endpoints. I plan to configure this such that I just need to send the request to one main endpoint, which after applying some conditions, will redirect the request to one of the endpoints (e.g. redirect the request to the appropriate model). Are there any best practices to approach this problem?    <\/p>\n<p>There seems to be an <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python#azure-ml-router\">Azure ML router using azureml-fe<\/a> that does something similar, but I cannot find any documentation about it.     <\/p>\n<p>Thanks,    <br \/>\nLawrence    <\/p>",
        "Question_closed_time":1601934562660,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=888ae66b-34ae-4a26-b896-abb53c4a8a32\">@Lawrence Wong  <\/a> ,    <br \/>\nWe do have a solution for this in private preview (called Many Models solution accelerator).    <br \/>\nPlease send your email id to AzCommunity[at]microsoft[dot]com). Include title and link to this thread in the email (and reply here once you do for faster response) and we can take the conversation from there.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How can I mark an Azure Dataset as a time series dataset reading from a parquet folder with date partitions?",
        "Question_created_time":1601474555217,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/112885\/how-can-i-mark-an-azure-dataset-as-a-time-series-d",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I would like to create a Tabular\/Time series dataset from a folder that contains parquet files this way:  <\/p>\n<ul>\n<li> timestamp=2018-01-06  <\/li>\n<li> timestamp=2018-01-07  <\/li>\n<\/ul>\n<p>How can I make Azure Dataset, through the GUI, recognises the timestamp partition as a date and mark my dataset as a time series dataset?  <\/p>\n<p>Does anyone know?  <\/p>\n<p>Thank you!  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - AKS Service deployment unable to handle concurrent requests despite auto scaling",
        "Question_created_time":1601545725850,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/113919\/azure-ml-aks-service-deployment-unable-to-handle-c",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I have deployed around 23 models (amounting to 1.57 GB) in a Azure ML workspace using Azure Kubernetes Service. For the AKS cluster, I have used 3 D8sv3 nodes, and enabled cluster auto scaling for the cluster up to 6 nodes.     <br \/>\nThe AksWebService is configured with 4.4 cores, 16 GB memory. I have enabled pod auto scaling for the Web service, having set autoscale_max_replicas at 40:    <\/p>\n<pre><code>aks_config = AksWebservice.deploy_configuration(cpu_cores = 4.4, memory_gb = 16, autoscale_enabled = True,  \n                                                description = 'TEST - Configuration for Kubernetes Compute Target',  \n                                                enable_app_insights = True, max_request_wait_time = 25000,  \n                                                autoscale_target_utilization = 0.6, autoscale_max_replicas = 40)  \n<\/code><\/pre>\n<p>I tried running load tests with 10 concurrent users (using JMeter). And I monitored the cluster application insights:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/29661-oct1-test1-cpu-mem.png?platform=QnA\" alt=\"29661-oct1-test1-cpu-mem.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/29663-oct1-test1-node-pod.png?platform=QnA\" alt=\"29663-oct1-test1-node-pod.png\" \/>    <\/p>\n<p>I can see the nodes and pods scaling. However, there is no spike in CPU\/memory utilization. For 10 concurrent requests, only 5 to 6 requests pass, the rest fail. When I send an individual request to the deployed endpoint, the response is generated in 7 to 9 seconds. However, in the load test logs, there are plenty requests taking more than 15 seconds to generate a response. And the requests taking more than 25 seconds, fail with status code 503. I increased the max_request_wait_time due to this reason, however, I don't understand why it would take so much time despite such amount of compute, and the dashboard shows that memory isn't even 30% utilized. Should I be changing the <code>replica_max_concurrent_requests<\/code> param? Or should I be increasing the <code>autoscale_max_replicas<\/code> even more? Concurrent requests load may sometimes reach 100 in production, is there any solution to this?    <\/p>\n<p>Will be grateful for any advice. Thanks.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When I try to create a workshop for ml, why I get this error each time?",
        "Question_created_time":1601774826563,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/116011\/when-i-try-to-create-a-workshop-for-ml-why-i-get-t",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>{&quot;code&quot;:&quot;InvalidTemplate&quot;,&quot;message&quot;:&quot;Deployment template validation failed: 'The template resource 'storageAccountResourceGroupName' at line '101' and column '44' is not valid: The template function 'RESOURCEGROUP' is not expected at this location. Please see <a href=\"https:\/\/aka.ms\/arm-template-expressions\">https:\/\/aka.ms\/arm-template-expressions<\/a> for usage details.. Please see <a href=\"https:\/\/aka.ms\/arm-template-expressions\">https:\/\/aka.ms\/arm-template-expressions<\/a> for usage details.'.&quot;,&quot;additionalInfo&quot;:[{&quot;type&quot;:&quot;TemplateViolation&quot;,&quot;info&quot;:{&quot;lineNumber&quot;:101,&quot;linePosition&quot;:44,&quot;path&quot;:&quot;properties.template.parameters.storageAccountResourceGroupName&quot;}}]}<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a tool for my scenario?",
        "Question_created_time":1601450792517,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/112364\/is-there-a-tool-for-my-scenario",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a scenario where we need to compare the content of two pages. Page2 will have the same text as page1 + some minor changes (extra image, extra space, etc). The changes are repetitive and very easy to catch with human eye. We need compare the 2 pages and confirm that indeed Page2 corresponds to Page1 and the changes have been applied correctly.  <br \/>\nWe have currently 10 000 of such page pairs, and expect half a million. We have people doing this manually.  <\/p>\n<p>I would like them to stop.   <\/p>\n<p>Is there an AI tool we could leverage for this scenario? I could feed it 1000 pairs and expect it to learn the pattern. I could provide either images of those pages or html. We have quite a big error margin (5% totally wrong, 15% partially wrong). I am totally green in the area, so any suggestions are welcome.  <\/p>",
        "Question_closed_time":1601488203637,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=f05e3e75-e760-47d0-8032-cdb0df6ca75b\">@Ana  <\/a> I think your use case is a perfect scenario for the Azure computer vision <a href=\"https:\/\/westcentralus.dev.cognitive.microsoft.com\/docs\/services\/computer-vision-v3-ga\/operations\/5d986960601faab4bf452005\">READ API<\/a>. This API can read printed and handwritten text and provide the output of the document\/image as a JSON response which can be compared or processed by your application to determine if the content is similar with in the margin of error specified. This service can currently process PDF documents for upto the first two pages for free, this will help you to evaluate the API without any cost. If the results are satisfactory you can switch to paid tier to process multiple documents without the limits of the free tier. You can try this API with any of the language that is suitable with this <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/cognitive-services\/computer-vision\/quickstarts-sdk\/client-library?pivots=programming-language-csharp\">quickstart<\/a>.    <\/p>\n<p>We hope this helps you to get started. If this response is helpful, please accept the same as answer. Thanks!!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How can I create a dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_created_time":1601468116080,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/112778\/how-can-i-create-a-dataset-in-azure-ml-studio-(thr",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.  <\/p>\n<p>In my folder, Spark creates files such as &quot;_SUCCESS&quot; or &quot;_committed_8998000&quot;.   <\/p>\n<p>Azure ML Studio is not able to read them or ignore them and tells me:  <\/p>\n<pre><code>The provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  &quot;message&quot;: &quot; &quot;\n}\n<\/code><\/pre>\n<p>I selected &quot;Ignore unmatched files path&quot; and yet, it still does not work.  <\/p>\n<p>If I remove the &quot;_SUCCESS&quot; and other Spark files, it works.   <\/p>\n<p>Does anyone have an idea about a workaround?  <\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":1601535069840,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>I used &quot;path\/<em>\/<\/em>.parquet&quot; in the &quot;Path&quot; field and now it works.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"From AMLS Deploying  models in ACI in a vnet",
        "Question_created_time":1601173833227,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/108659\/from-amls-deploying-models-in-aci-in-a-vnet",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am facing error when I deploy in ACI. Is there a way to deploy the models when AMLS and  vnet are in different resource groups?<\/p>",
        "Question_closed_time":1601265795363,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=abfc7f57-eb48-411e-acbd-c71bd241842b\">@AI866  <\/a> Thanks, If you are using AMLS SDK, Unfortunately this is a limitation today that we plan to address this in the near future.    <br \/>\nYou can create a pipeline, DevOps or manual process to deploy to any ACI in any VNET\/different subscription    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet\">https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet<\/a>    <\/p>\n<p>Please follow the below for common troubleshooting issues.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting\">https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure machine learning - Trying to use an analytical function from SQLite results in error",
        "Question_created_time":1600977576630,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/106670\/azure-machine-learning-trying-to-use-an-analytical",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>When trying to use the LAG function from SQLite on an Apply SQL Transformation module from Azure Machine Learning designer results in a error, saying the sintax near &quot;(&quot; was wrong.    <\/p>\n<p>The SQL code:    <\/p>\n<blockquote>\n<p>select t1.id, t1.veiculo, lag(t1.id) over (partition by t1.veiculo order by t1.id) id_ant    <br \/>\nfrom t1    <\/p>\n<\/blockquote>\n<p>Looking at the link below, there is no clue on why I can't use a analytical function from SQLite on the module.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/apply-sql-transformation\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/apply-sql-transformation<\/a>    <\/p>\n<p>Any tips?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is the field \"compute target\" for data drift monitoring in ML studio still blank whereas I have a compute instance?",
        "Question_created_time":1601275746390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/109397\/why-is-the-field-compute-target-for-data-drift-mon",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have created a compute instance:    <\/p>\n<p><strong>Virtual machine size<\/strong>    <br \/>\nSTANDARD_DS3_V2 (4 Cores, 14 GB RAM, 28 GB Disk)    <\/p>\n<p><strong>Processing Unit<\/strong>    <br \/>\nCPU - General purpose    <\/p>\n<p>But, I'm not able to access it when trying to set it for data drift monitoring.    <br \/>\nThe dropdown list is empty. I can't understand why. Can you help me please?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/28475-datadrift.png?platform=QnA\" alt=\"28475-datadrift.png\" \/>    <\/p>",
        "Question_closed_time":1601279018463,
        "Answer_score_count":1.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>I found the answer. You must give a <strong>cluster<\/strong> compute instance to do data drift in Azure Machine Learning Studio.  <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"\u00a1Ayuda, por favor!. Ocurri\u00f3 el siguiente error al intentar guardar las propiedades del usuario administrador. Acceso denegado.",
        "Question_created_time":1601265997497,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/109254\/ayuda-por-favor-ocurri-el-siguiente-error-al-inten",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hola!. Desde hace algunos dias, he intentado habilitar la cuenta de administrador de mi laptop, porque no me deja hacer pr\u00e1cticamente nada, solo me deja ejecutar programas que ya tengo instalados, si quiero descargar e instalar otra cosa me pide permisos de administrador. M\u00e1s espec\u00edficamente aparece un cartel que dice: &quot;para continuar escriba el nombre y contrase\u00f1a de un administrador&quot; y solo me da una opci\u00f3n que dice no. Entonces, ese es un problema, el cu\u00e1l me lleva al otro. Me met\u00ed en administrador de dispositivos , usuarios, me met\u00ed en la cuenta administradora y desmarqu\u00e9 la opci\u00f3n que dice: &quot;deshabilitar esta cuenta&quot; y al darle aplicar me dice el siguiente mensaje:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/28621-image.png?platform=QnA\" alt=\"28621-image.png\" \/>    <\/p>\n<p>Entonces, no se como hacer, es un problema realmente grave y no se que hacer, por favor, agradecer\u00eda que me ayudaran lo m\u00e1s r\u00e1pido posible!.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Upgrading Azure Machine Learning Compute Instance (virtual machine)",
        "Question_created_time":1591430074777,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32793\/upgrading-azure-machine-learning-compute-instance",
        "Question_score_count":1,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,  <\/p>\n<p>How can I safely upgrade the default OS and softwares of a compute instance (Azure Machine Learning)?  <\/p>\n<p>The default compute instance comes with pre-default versions for OS and packages.  <\/p>\n<p>For example, the following are a few which I\u2019ve inspected after spinning on a compute instance:  <\/p>\n<ol>\n<li>\tOS is currently an Ubuntu LTS 16.04 (release date February 28, 2019)  <\/li>\n<li>\tPython version 3.6.9 (release date July 2, 2019)  <\/li>\n<li>\tR version 3.6.3 (release date February 29, 2020)  <\/li>\n<\/ol>\n<p>The latest stable versions of the above (as of today June 4,2020) are:  <\/p>\n<ol>\n<li> Ubuntu 20.04 LTS (release date April 23,2020)  <\/li>\n<li> Python version 3.7.7 (release date March 10,2020)  <\/li>\n<li> R version 4.0 (release date April 24,2020)  <\/li>\n<\/ol>\n<p>I actually tried upgrading the OS through the command line but it doesn't seem to be stable after the upgrade to Ubuntu LTS 18.04.  <br \/>\nUpgrading RStudio server also fails.  <\/p>\n<p>So I'm not entirely confident whether the usual commands to upgrade work.   <br \/>\nIs there anything I need to do with the repository list to ensure smooth upgrades and updates?  <\/p>\n<p>Thanks  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML authentication with Service Principal certificate",
        "Question_created_time":1601045466093,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/108060\/azure-ml-authentication-with-service-principal-cer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I am responsible for deploying Azure ML resources like workspace, compute target and datastore using Python from Azure CI\/CD Devops Pipeline. I have Service principal certificate for authentication. I am confused about which authentication method of Python I will follow.  <\/p>\n<p>Shall I used MSAL authentication? or  <\/p>\n<p>please suggest a secure authentication method of python that supports Service Principal certificate to authenticate Azure ML workspace. Please share a sample as reference if any.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML web endpoint unreachable after successful deployment",
        "Question_created_time":1600890127103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/105346\/azure-ml-web-endpoint-unreachable-after-successful",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>The deployment state of the service is marked as being unhealthy.     <\/p>\n<p>Compute target is AKS.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/27654-capture.png?platform=QnA\" alt=\"27654-capture.png\" \/>    <\/p>\n<p>The pod is running and the logs says that the init() completed successfully.     <\/p>\n<p>Also, when deploying it as a local web service it works.     <\/p>\n<p>Model size is small, execution time is &lt; 2 min and we are requesting 0.7 cpu and 0.5 Gb mem. Increasing these requests does not solve it, so guess that it's not related to request limit.     <\/p>\n<p>However, when trying to consume the scoring service, an 504 error is returned saying that:    <\/p>\n<p>RROR - Received bad response from Model Management Service:    <br \/>\nResponse Code: 504    <br \/>\nHeaders: {'Date': 'Wed, 23 Sep 2020 18:44:31 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'x-request-time': '180.032', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}    <br \/>\nContent: b'&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;504 Gateway Time-out&lt;\/title&gt;&lt;\/head&gt;\\r\\n&lt;body&gt;\\r\\n&lt;center&gt;&lt;h1&gt;504 Gateway Time-out&lt;\/h1&gt;&lt;\/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;\/center&gt;\\r\\n&lt;\/body&gt;\\r\\n&lt;\/html&gt;\\r\\n'    <\/p>\n<p>Guess this should be fixed on AKS. But what should be done? Any help much appreciated.     <\/p>\n<p>Container logs:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/27761-capture2.png?platform=QnA\" alt=\"27761-capture2.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Prediction of Cancer",
        "Question_created_time":1600172964937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/95802\/prediction-of-cancer",
        "Question_score_count":2,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have made a prediction algorithm in which I have predicted whether a patient has cancer or not based on the past data. I have also run the model successfully and have received the parameters. Now my question is, which parameter should I give the <strong>most importance<\/strong> for this case of prediction? Is it the precision, recall, accuracy or the threshold?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Quality of a Classifier Model",
        "Question_created_time":1600172751413,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/95756\/quality-of-a-classifier-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have been trying out a classifier model in ML studio, and I have got some results in the Visualize option. I can see the values for Precision, Recall, Accuracy, threshold and also the Confusion Matrix. Now my question is, which of the above mentioned parameters <strong>describes the quality of the model<\/strong>?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I add OpenAPI specification to a webservice deployed with AzureML in AKS?",
        "Question_created_time":1600897231890,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/105437\/can-i-add-openapi-specification-to-a-webservice-de",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'd like to deploy a machine learning service using AzureML on AKS. I also need to add some OpenAPI specification for it.    <\/p>\n<p>Features in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python<\/a> are neat, but that of having API docs\/swagger for the webservice seems missing.    <\/p>\n<p>Having some documentation is useful especially if the model takes in input several features of different type.    <\/p>\n<p>To overcome this, I currently get models trained in AzureML and include them in Docker containers that use the python FastAPI library to build the API and OpenAPI\/Swagger specs, and those are deployed on some host.     <\/p>\n<p>Can I do something equivalent to this with AKS in AzureML instead? If so, how?<\/p>",
        "Question_closed_time":1600930445547,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=9ced4628-b03a-4169-99b4-e42b0955c045\">@Davide Fiocco  <\/a> The deployments of Azure ML provide a swagger specification URI that can be used directly. The documentation of this is available <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.akswebservice?view=azure-ml-py\">here<\/a>. You can print your <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service\">swagger_uri<\/a> of the web service and check if it confirms with the specifications you are creating currently.     <\/p>\n<p>If the above response helps, please accept the response as answer. Thanks!!    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to create a machine learning workspace in Microsoft Azure?",
        "Question_created_time":1600870263283,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/104585\/how-to-create-a-machine-learning-workspace-in-micr",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I want to create a machine learning workspace in Microsoft Azure but I am not able to do it. Please provide me demo of it or provide me steps with detailed description.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deloyment stuck on transitioning status",
        "Question_created_time":1600239147820,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/96645\/azure-ml-real-time-inference-endpoint-deloyment-st",
        "Question_score_count":0,
        "Question_answer_count":11,
        "Question_comment_count":0,
        "Question_body":"<p>I can't use ml real-time inference endpoint becouse it's stuck on transitioning status (more than 20 hours). Could you help me with that?<\/p>",
        "Question_closed_time":1600780351533,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I've chacked in on some different algorithms and the issue appears when i'm using n-grams block for getting features. When i'm using feature hashing for example it looks like working well.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Different results with same input in request\/response if input by one row or several rows in Azure Machine Learning Studio",
        "Question_created_time":1599811674310,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/92464\/different-results-with-same-input-in-request-respo",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/24067-image-4.png?platform=QnA\" alt=\"24067-image-4.png\" \/>    <\/p>\n<p>Hi all,    <br \/>\nI created a classifier by trained SVM and PCA as well as normalization transformation. And use Request\/Response Excel to test.    <br \/>\nAnd if I only input for one row, all the PCA would be &quot;0&quot;     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/24111-classificationresultwith1row.png?platform=QnA\" alt=\"24111-classificationresultwith1row.png\" \/>    <br \/>\nbut if I put more than one row together then the result would change and both behavior doesn't make sense.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/24085-classificationresultwith2rows.png?platform=QnA\" alt=\"24085-classificationresultwith2rows.png\" \/>     <br \/>\nI read some other questions below and I wonder if something wrong in &quot;Normalization&quot; calculating that it didn't count by referring &quot;Applying transformation&quot; but simply normalizing by data input.    <br \/>\n<a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/bb800d7e-2fbf-4874-a525-aae9ace5df4f\/azure-ml-webservice-same-sample-file-but-different-predictions?forum=MachineLearning\">https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/bb800d7e-2fbf-4874-a525-aae9ace5df4f\/azure-ml-webservice-same-sample-file-but-different-predictions?forum=MachineLearning<\/a>    <br \/>\n<a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/21938a5a-ae9c-4559-82f0-95889b359206\/normalization-and-predictive-web-service?forum=MachineLearning\">https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/21938a5a-ae9c-4559-82f0-95889b359206\/normalization-and-predictive-web-service?forum=MachineLearning<\/a>     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No option to select Local machine for compute in Azure ML",
        "Question_created_time":1600253902967,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/96915\/no-option-to-select-local-machine-for-compute-in-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/25233-capture2.png?platform=QnA\" alt=\"25233-capture2.png\" \/>Hi,    <\/p>\n<p>I have created ML space for experimenting ML on azure. However to execute my ML work I need to select compute target and as per Azure docs I can select local machine or remote compute but I don't see option to select local machine. I only have options to create compute instance, compute clusters.    <\/p>\n<p>Can someone please help me why I don't have the option.    <\/p>\n<p>reference on doc: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-azure-machine-learning-architecture#computes\">concept-azure-machine-learning-architecture<\/a>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clean Missing Data",
        "Question_created_time":1600173335010,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/95746\/clean-missing-data",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>While doing a machine learning algorithm in Azure ML Studio, I used a dataset which contained some missing data. So I used the <strong>Clean Missing Data<\/strong> module for this purpose. Inn the fields section, there are fields named as <strong>Minimum Missing Value Ratio<\/strong> and <strong>Maximum Missing Value Ratio<\/strong>. I referred to the documentation mentioned <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/clean-missing-data#bkmk_SettingThreshold\">here<\/a>. But I couldn't understand whether giving these fields are necessary or not. Is it necessary to provide these two fields?     <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"creating conda environment on azure hdinsight spark cluster taking hours",
        "Question_created_time":1599747249100,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/91524\/creating-conda-environment-on-azure-hdinsight-spar",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>trying to follow the code in this tutorial , <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-in-spark\/train-in-spark.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-in-spark\/train-in-spark.ipynb<\/a>    <\/p>\n<p>when i send the run to run to azure ml, the run essentially stalls on the step creating the conda environment in the hdinsight cluster I am looking to run the pyspark code on.      <\/p>\n<p>I am wondering if anyone has run into the same problem where creating a conda environment on a hdinsight cluster for the first time is taking hours, already been 2 hours for me.     <\/p>\n<p>Thanks    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/23854-image.png?platform=QnA\" alt=\"23854-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model for Predicting Earthquakes",
        "Question_created_time":1600174009770,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/95792\/model-for-predicting-earthquakes",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am planning to create an Azure Machine Learning model to Predict the number of Earthquakes based on past historical data. I am asked to use one of the Regression techniques. Which regression model should I be using? Can I use Logistic Regression, or Poisson Regression, or Fast Forest Quantile Regression?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model for Amount spent in a Supermarket",
        "Question_created_time":1600176252270,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/95768\/model-for-amount-spent-in-a-supermarket",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I was asked to create a model to predict the average amount of money spent by a user at a Supermarket. But I am unable to identify which algorithm would be most appropriate. Which algorithm can I use? Can I use Regression, or Clustering, or Classification?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use \"Web serivie iput\"module on MicroSoft Azure Machien lerning designer reak-time inferance",
        "Question_created_time":1599810536260,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/92414\/how-to-use-web-serivie-iputmodule-on-microsoft-azu",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I deplyed  image classificatin reak-time inferanceon on Azure Machine Lerning designer.  <br \/>\nSo Id like to test this model by using REST API.  <br \/>\nbut REST API Need  prameter og Image by Data Ftame directory Type parametar.  <br \/>\nCan I use REST API by using direct image(Direct PUT iamge  or via Storage URI) like Azure Custom Vision'sREST API not ?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In Automated ML how modules are linked together?",
        "Question_created_time":1599749780997,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/91527\/in-automated-ml-how-modules-are-linked-together",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>In Automated ML how modules are linked together?. Since we build many modules inside the Automated ML, how these modules are inter-linked and how they interact?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Server - Where are the web services published stored?",
        "Question_created_time":1599623268007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/89720\/machine-learning-server-where-are-the-web-services",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>For machine learning server, we are able to publish model as a web service to Machine Learning Server using the publishService() function from the mrsdeploy package.  <\/p>\n<p>For the published web services, where can they be found?  <\/p>\n<p>First, are the published web services in the web node or compute node?  <\/p>\n<p>Second, which directory are they stored in?  <\/p>\n<p>Third, are they stored in each of the web nodes or compute nodes if multiple nodes were setup?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"LGPL license restriction in azureml-core phyton library",
        "Question_created_time":1599557373747,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/89083\/lgpl-license-restriction-in-azureml-core-phyton-li",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello all,  <\/p>\n<p>We are using  azureml-core phyton library to interact with Azure Machine Learning Workspace.   The library is hosted on  <a href=\"https:\/\/pypi.org\/project\/azureml-core--%3E\">https:\/\/pypi.org\/project\/azureml-core--&gt;<\/a>   <a href=\"https:\/\/pypi.org\/project\/azureml-core\/\">https:\/\/pypi.org\/project\/azureml-core\/<\/a>  It is authored by Microsoft and maintained by pypi community members.  <\/p>\n<p>One of the dependencies of azureml-core is  &quot;chardet&quot;  phyton library and it has  LGPL license restriction. <a href=\"https:\/\/pypi.org\/project\/chardet\/\">https:\/\/pypi.org\/project\/chardet\/<\/a>  --&gt;  <a href=\"https:\/\/pypi.org\/project\/chardet\/\">chardet<\/a>  <\/p>\n<p>Our compliance team would  like us to avoid the use of LGPL licensed open source libraries to avoid future license implications.  I am wondering if there is an alternative to azureml-core  phyton library?  I noticed that there are two GitHub initiatives to replace chardet .  Please refer to below links:  <\/p>\n<p><a href=\"https:\/\/github.com\/psf\/requests\/issues\/4848\">https:\/\/github.com\/psf\/requests\/issues\/4848<\/a>  <\/p>\n<p><a href=\"https:\/\/github.com\/encode\/httpx\/issues\/1018\">https:\/\/github.com\/encode\/httpx\/issues\/1018<\/a>  <\/p>\n<p>I am wondering whether Microsoft is planning to taken an action on the replacement of chardet library and avoid  LGPL licensing issues.  <\/p>\n<p>Thanks in advance  <\/p>\n<p>Mehmet Baserdem  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\" Object of type 'int64' is not JSON serializable\" when running automl time series",
        "Question_created_time":1599571606537,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/89272\/object-of-type-int64-is-not-json-serializable-when",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am trying to use the Online ML studio and running an &quot;Automated ML&quot;. I upload my dataset (see simple example below) which passes fine and then I start a automl experiment selecting &quot;time series forecasting&quot;. I select all the revelant fields and everything starts without any issues.<\/p>\n<p>Shortly after the process fails and the error given is:<\/p>\n<p>&quot;User error: User program failed with TypeError: Object of type 'int64' is not JSON serializable&quot;<\/p>\n<p>Digging into the logs the only log with any useful information appears to be the driver_log which has these lines with no more detail about the error unless the INFO about streaming is actually an error not information:<\/p>\n<p>2020-09-08 11:17:01.734 - INFO - Successfully retrieved data using dataprep.  <br \/>\n2020-09-08 11:17:01.734 - INFO - Streaming is not conducive due to incompatible settings. Reason[s]: [Forecasting is not supported, 'n_cross_validations' was non-empty]  <br \/>\n2020-09-08 11:17:01.734 - INFO - Service responded with streaming disabled  <br \/>\n2020-09-08 11:17:01.734 - INFO - Inferring type for feature columns.  <br \/>\n2020-09-08 11:17:12.669 - INFO - Error in setup_wrapper.  <br \/>\n2020-09-08 11:17:12.670 - ERROR - Marking Run AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup as Failed.<\/p>\n<p>Can anyone suggest an answer or recommend some ways to debug this?<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/23190-image.png?platform=QnA\" alt=\"![23236-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/23190-image.png?platform=QnA\">1<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Consume private packages from DevOps Artifacts in AzureML",
        "Question_created_time":1598473641800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/78083\/consume-private-packages-from-devops-artifacts-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have published a private Python package to Azure DevOps Artifact.  <br \/>\nWhen trying to follow <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-private-python-packages#consume-a-repository-of-packages-from-azure-devops-feed\">this tutorial<\/a> I encounter following problem, to which there is no help online whatsoever.<\/p>\n<p>{  <br \/>\n&quot;code&quot;: &quot;AciDeploymentFailed&quot;,  <br \/>\n&quot;statusCode&quot;: 400,  <br \/>\n&quot;message&quot;: &quot;Failed to submit build for Environment with Name: deploymentenv Version: Autosave_2020-08-26T19:42:40Z_b11e8d13 Reason: {\\n \\&quot;error\\&quot;: {\\n \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n \\&quot;severity\\&quot;: null,\\n \\&quot;message\\&quot;: \\&quot;Unable to set authorization on python feed. Multiple connections available for the specified host company.pkgs.visualstudio.com\\&quot;,\\n \\&quot;messageFormat\\&quot;: null,\\n \\&quot;messageParameters\\&quot;: null,\\n \\&quot;referenceCode\\&quot;: null,\\n \\&quot;detailsUri\\&quot;: null,\\n \\&quot;target\\&quot;: null,\\n \\&quot;details\\&quot;: [],\\n \\&quot;innerError\\&quot;: null,\\n \\&quot;debugInfo\\&quot;: null\\n },\\n \\&quot;correlation\\&quot;: {\\n \\&quot;operation\\&quot;: \\&quot;fcd33b3aaf97a04982c36841fd2176d5\\&quot;,\\n \\&quot;request\\&quot;: \\&quot;4ddc0bff3cd6ec47\\&quot;\\n },\\n \\&quot;environment\\&quot;: \\&quot;westeurope\\&quot;,\\n \\&quot;location\\&quot;: \\&quot;westeurope\\&quot;,\\n \\&quot;time\\&quot;: \\&quot;2020-08-26T20:15:48.9795242+00:00\\&quot;,\\n \\&quot;componentName\\&quot;: \\&quot;environment-management\\&quot;\\n}.&quot;,  <br \/>\n&quot;details&quot;: []  <br \/>\n}  <br \/>\nI replaced the actual company name with &quot;company&quot;.<\/p>\n<p>What does the error <code>Unable to set authorization on python feed. Multiple connections available for the specified host<\/code> mean?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No module named 'xgboost'",
        "Question_created_time":1597377002880,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66628\/no-module-named-xgboost",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello there,  <\/p>\n<p>I'm seeing an error - No module named 'xgboost' when attempting to deploy a model using python SDK. Here is my conda yaml file. What am I missing?  <br \/>\nUnable to get the end point to generate an output.  <\/p>\n<p>name: project_environment  <br \/>\ndependencies:  <\/p>\n<h1 id=\"the-python-interpreter-version--\">The python interpreter version.  <\/h1>\n<h1 id=\"currently-azure-ml-only-supports-352-and-later--\">Currently Azure ML only supports 3.5.2 and later.  <\/h1>\n<ul>\n<li> python=3.6.2  <\/li>\n<li> pip:    \n<ul>\n<li> inference-schema  <\/li>\n<li> azureml-defaults  <\/li>\n<li> azureml-explain-model  <\/li>\n<li> numpy&gt;=1.16.0,&lt;1.17.0  <\/li>\n<li> pandas&gt;=0.21.0,&lt;=0.23.4  <\/li>\n<li> scikit-learn&gt;=0.19.0,&lt;=0.20.3  <\/li>\n<li> py-xgboost  <\/li>\n<li> fbprophet==0.5  <\/li>\n<li> holidays==0.9.11  <\/li>\n<li> psutil&gt;=5.2.2,&lt;6.0.0  <\/li>\n<li> xgboost  <\/li>\n<li> azureml-sdk[notebooks,automl]  <br \/>\nchannels:  <\/li>\n<\/ul>\n<\/li>\n<li> anaconda  <\/li>\n<li> conda-forge<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning and jupyterlab git extension not working",
        "Question_created_time":1594716551237,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46614\/azure-machine-learning-and-jupyterlab-git-extensio",
        "Question_score_count":1,
        "Question_answer_count":4,
        "Question_comment_count":5,
        "Question_body":"<p>Hi,<\/p>\n<p>I need some help trying to understand why I can't see any GIT options (left panel and top selection drop down menu) in my Azure machine learning JupyterLab.<\/p>\n<p>I did the following steps:<\/p>\n<pre><code> jupyter labextension install @jupyterlab\/git\n pip install --upgrade jupyterlab-git\n jupyter serverextension enable --py jupyterlab_git\n jupyter lab build\n<\/code><\/pre>\n<p>I've restarted my jupyterLab a couple of times, if I check the command:<\/p>\n<pre><code> jupyter labextension list\n<\/code><\/pre>\n<p>I get that @jupyterlab\/git v0,20,0 is enabled and ok.  <br \/>\nWhat am I doing wrong?<\/p>\n<p>Thank you in advance,  <br \/>\nCarla<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/12015-issue1.png?platform=QnA\" alt=\"12015-issue1.png\" \/><\/p>",
        "Question_closed_time":1594762360103,
        "Answer_score_count":1.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>Hi <a>@ramr-msft<\/a> ,<\/p>\n<p>I did the steps mention in the link you gave me (<a href=\"https:\/\/github.com\/jupyterlab\/jupyterlab-git\">https:\/\/github.com\/jupyterlab\/jupyterlab-git<\/a>) but still I can't open the Git extension from the Git tab on the left panel because it still doesn't exists.<\/p>\n<p>You mentioned we can still manage git repositories using the command line. Do you have any useful documentation on this approach?<\/p>\n<p>Once again, thank you in advance.  <br \/>\nCarla<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Update out of date packages on Azure Machine Learning Compute instance",
        "Question_created_time":1598608952077,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/80212\/update-out-of-date-packages-on-azure-machine-learn",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Started up a STANDARD_D11_V2 cluster to run some notebooks on.<\/p>\n<p>Wanted to use json_normalize from pandas: <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.json_normalize.html\">https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.json_normalize.html<\/a> and I get the below error:<\/p>\n<pre><code>AttributeError: module 'pandas' has no attribute 'json_normalize'\n<\/code><\/pre>\n<p>Pandas seems to be out of date. Checked the installed version of pandas:<\/p>\n<pre><code>$ python\nPython 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) [GCC 7.3.0] on linux\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.\n&gt;&gt;&gt; import pandas\n\n&gt;&gt;&gt; pandas.__version__\n\n'0.23.4\n<\/code><\/pre>\n<p>Pandas is indeed out of date, the latest version is v1.1.1. Fired up a terminal to run:<\/p>\n<pre><code>conda update --all\n<\/code><\/pre>\n<p>On the azureml_py36 environment which I had selected to run the notebook on. It hangs on:<\/p>\n<pre><code>Solving environment: \/\n<\/code><\/pre>\n<p>Went to update conda to see if that would help:<\/p>\n<pre><code>conda update conda\n<\/code><\/pre>\n<p>But I get this error:<\/p>\n<pre><code>PackageNotInstalledError: Package is not installed in prefix.\n  prefix: \/anaconda\/envs\/azureml_py36\n  package name: conda\n<\/code><\/pre>\n<p>Which leads me to think this is not a typical installation of conda.<\/p>\n<p>Would like to run the most up to date packages on Azure Machine Learning to replicate the local environment I have setup. Does anyone know how to do this?<\/p>",
        "Question_closed_time":1598622188187,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>@philmariusnew-9791 I have tried the above steps and the installation completed successfully for conda. But when we upgrade pandas azureml package has a dependency  so it cannot use version v1.1.1     <\/p>\n<p>I have went ahead and upgrade the pandas version but there is a warning as seen below:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/21216-image.png?platform=QnA\" alt=\"21216-image.png\" \/>    <\/p>\n<p>We would recommend to use the package that is compatible with azureml so your environment setup works as expected.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Jupyterlab page is blank",
        "Question_created_time":1598559753367,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/79393\/jupyterlab-page-is-blank",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>In my Workspace, after creating a compute, when I click on Jupyterlab , I get a blank page. When I click on Jupyter, the notebook work fine.  <\/p>\n<p>Whats the issue<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accessing the my ML Model from azure ml",
        "Question_created_time":1598739182170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/80879\/accessing-the-my-ml-model-from-azure-ml",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am accessing my ML  modal that i have deployed on azure ml and using that model to predict but is there any way i can pass the data other than json format ?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Studio Notebooks folder structure",
        "Question_created_time":1598909886827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/82485\/azure-ml-studio-notebooks-folder-structure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to create non-user folders for <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks\">Notebooks in Azure ML Studio<\/a>? I would look to organize my notebooks into folders, but outside of my persona user folder structure (similar to how Azure Databricks allows you to create folders within the workspace)  \u2013 doesn\u2019t look like that is possible, but wanted to double check.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is AML's average GpuUtilization metric computed?",
        "Question_created_time":1598450649953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/77678\/how-is-amls-average-gpuutilization-metric-computed",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>How is the &quot;GpuUtilization&quot; metric computed for an AML workspace? What are the inputs and what is the equation used to compute GpuUtilization?     <\/p>\n<p>The &quot;metrics&quot; tab in the AML web portal shows a chart of the GpuUtilization over a specified time period, along with the average GpuUtilization for that time period. However, I have found that average GpuUtilization does not appear to accurately reflect the data shown in the chart for some of my organization's AML workspaces.    <\/p>\n<p>For example, the following screenshot shows the GpuUtilization for July 1-31, with the average GpuUtilization reported as 54.06. This is clearly much higher than what is shown in the chart. When I download the data from the chart (Share -&gt; Download to Excel), I compute the average GpuUtilization to be ~11% in Excel. Why is there such a discrepancy?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/20553-aml-metric-qna.png?platform=QnA\" alt=\"20553-aml-metric-qna.png\" \/>    <\/p>\n<p>I have found similar discrepancies for other AML workspaces as well. However, the average GpuUtilization appears to be more accurate for the August 1-25 time period than it is for July 1-31. I wish to better understand how AML computes the average GpuUtilization over a time period so we can accurately account for my organization's AML GPU usage on a per-workspace basis.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Git integration with ML Azure Jupyterhub is very slow",
        "Question_created_time":1598513619823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/78634\/git-integration-with-ml-azure-jupyterhub-is-very-s",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>JupyterLab (in ML Azure) default mounts a shared file system for all users in my workspace. The <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-train-model-git-integration#clone-git-repositories-into-your-workspace-file-system\">documentation<\/a> recommends to &quot;clone git repositories into our own user directory&quot;. It works, but it is <strong>extremely<\/strong> slow. A simple 'git status' can take up to 3 seconds to run. Committing, pushing, pulling, stashing, each can take long time to execute (matter of seconds). In a my local machine it takes the order of <em>milliseconds<\/em>. This can be very annoying, specially if one does so very frequently.    <\/p>\n<p>So here is my question: is there a way to fix it or is it inherently bounded to the slow mounted file system? If it can't  be solved, how can I change Jupyter's mounting point (so I can point it out to a local file system)?    <\/p>\n<p>Thanks,    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access Azure Machine Learning logs from another Azure Project",
        "Question_created_time":1598601355923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/79984\/access-azure-machine-learning-logs-from-another-az",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am running two Azure instances. The main instance can be considered the parent instance and will house all insights across all the children instances. The children instances are aligned to specific lines of business performing machine learning. The children instances will use the Azure Machine Learning service. Models will be trained here and the model metrics are stored here as logs. Following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-view-training-logs\">this<\/a>.       <\/p>\n<p>I need to monitor the children instances from my main instance. By this, I need to get all the logs from Azure Machine Learning in the child instance to the parent instance. Assume storage is a blob container. Does Azure Machine Learning have an API to get logs from an external Azure instance?    <\/p>\n<p>I know you can use the Azure ML SDK to access logging, but how would the permissions need to be set up to access from an external Azure instance?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: ds is greater than allowed.",
        "Question_created_time":1597254135800,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/65476\/moduleexceptionmessage-columnuniquevaluesexceeded",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>We are trying to train a model using the Boosted Tree Regression model and running into the &quot;ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: &quot;ds&quot; is greater than allowed.&quot; error.  <\/p>\n<p>This is a time series data and it is going to have unique values in the timestamp - how are we supposed to get around the issue.  <\/p>\n<p>PS: When using the exact same dataset in the classic studio it runs fine and does not throw this error.  <\/p>\n<p>The big picture:  We are happy with studio based results on the prediction however, there isn't a way to fully end to end automate, meaning retrain the model with latest data and use the API to download the results in classic version. We are looking to use the new Azure ML pipelines and endpoints etc but quite frankly all of this is turning out be quite complex than needed for some reason. And the documentation to retrain the models shows a mixture of classic and new azure ml steps which is quite frustrating.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to deploy Azure automated machine learning model to production to generate forecast",
        "Question_created_time":1597314320727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66173\/how-to-deploy-azure-automated-machine-learning-mod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I managed to use Azure automated machine learning to train a time series forecasting model in Azure machine learning studio.  <\/p>\n<p>We get new data only once a month, therefore we do not think that web service is necessary for our needs.  <\/p>\n<p>We want to deploy the model on the cloud or locally to start generating forecasting data. But We are not quite sure how to do so. We do not have knowledge about Python and machine learning deployment.  <\/p>\n<p>Could you recommend some instructions on how to deploy Azure automated machine learning model on the cloud and locally? Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to deploy Azure automated machine learning model to generate forecast",
        "Question_created_time":1597314111690,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66092\/how-to-deploy-azure-automated-machine-learning-mod",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I managed to use Azure automated machine learning to train a time series forecasting model in Azure machine learning studio.  <\/p>\n<p>We get new data only once a month, therefore we do not think that web service is necessary for our needs.  <\/p>\n<p>We want to deploy the model on the cloud or locally to start generating forecasting data. But We are not quite sure how to do so. We do not have knowledge about Python and machine learning deployment.  <\/p>\n<p>Could you recommend some instructions on how to deploy Azure automated machine learning model on the cloud and locally? Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azureml-sdk and azure-identity==1.4.0",
        "Question_created_time":1598460449627,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/77924\/azureml-sdk-and-azure-identity-1-4-0",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>In our project we already use azure-identity==1.4.0 (to use az cli authentication in development - DefaultAzureCredential). Now we would like to use azureml-sdk however it seems that it only works with azure-identity&lt;1.3.0.   <br \/>\nIs there any workaround to make it work? Any idea when azureml-sdk will catch up and how to make a pressure on them?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deploy ML model to Kubernetes + overwrite previous endpoint",
        "Question_created_time":1598425965377,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/77362\/deploy-ml-model-to-kubernetes-overwrite-previous-e",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm building a CI\/CD pipeline in Azure DevOps for the deployment of my Machine Learning model to Azure Kubernetes Service. I have the following task in my YAML pipeline file (replaced some of the values with '...'):<\/p>\n<pre><code>- task: AzureCLI@1\n  displayName: &quot;Deploy to AKS&quot;\n  inputs:\n    azureSubscription: '...'\n    scriptLocation: inlineScript\n    workingDirectory: $(Build.SourcesDirectory)\/score\n    inlineScript: |\n      set -e # fail on error\n\n      az ml model deploy --name 'aks-deploy-test' --model '$(MODEL_NAME):$(get_model.MODEL_VERSION)' \\\n      --compute-target $(AKS_COMPUTE_NAME) \\\n      --ic inference_config.yml \\\n      --dc deployment_config_aks.yml \\\n      -g ... --workspace-name ... \\\n      --overwrite -v\n<\/code><\/pre>\n<p>When I run the pipeline the first time, it successfully deployed the ML model and I can see the Endpoint in the Azure ML workspace. However, when I try to run the pipeline a second time (to deploy a newer version of the model), I get the error:<\/p>\n<pre><code>Error:\n{\n  &quot;code&quot;: &quot;KubernetesError&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Kubernetes Deployment Error&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;Unschedulable&quot;,\n      &quot;message&quot;: &quot;0\/6 nodes are available: 4 Insufficient cpu, 6 Insufficient memory.&quot;\n    },\n    {\n      &quot;code&quot;: &quot;DeploymentFailed&quot;,\n      &quot;message&quot;: &quot;Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https:\/\/aka.ms\/debugimage#container-cannot-be-scheduled for more information.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>Isn't the --overwrite option in the az ml model deploy command supposed to completely overwrite the current deployment of the model? If so, why am I still getting this error, or is there a better way to deploy a newer version of the ML model to the same AKS cluster?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MLS version (9.4.7) is supported up to Cloudera 6.1",
        "Question_created_time":1597330930617,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66337\/mls-version-(9-4-7)-is-supported-up-to-cloudera-6",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>The current latest MLS version (9.4.7) is supported up to Cloudera 6.1 only, so wanted to check if there are any plans and a timeline to certify\/support Cloudera 6.3.2 versions.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Microsoft Machine Learning getting sample sizes and other information",
        "Question_created_time":1598192106863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/74341\/microsoft-machine-learning-getting-sample-sizes-an",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>We are using the Microsoft Machine Learning library (Microsoft.ML). We have the following script working:  <\/p>\n<pre><code>           var trainingData = mlContext.Data.LoadFromTextFile&lt;CSOData&gt;(\n                path: @&quot;C:\\Users\\Administrator\\source\\repos\\WindowsFormsApp1\\WindowsFormsApp1\\level-data - reduced.txt&quot;,\n                hasHeader: false,\n                separatorChar: ',');\n\n            \/\/ set up a learning pipeline\n            \/\/ step 1: concatenate input features into a single column\n            var pipeline = mlContext.Transforms.Concatenate(\n                &quot;Features&quot;,\n                &quot;Level&quot;)\n\n                \/\/ step 2: use the k-means clustering algorithm\n                \/\/ assume there are 3 clusters\n                .Append(mlContext.Clustering.Trainers.KMeans(\n                    &quot;Features&quot;,\n                    numberOfClusters: 3));\n\n            \/\/ train the model on the data file\n            Debug.WriteLine(&quot;Start training model....&quot;);\n            TransformerChain&lt;ClusteringPredictionTransformer&lt;KMeansModelParameters&gt;&gt; model = pipeline.Fit(trainingData);\n            Debug.WriteLine(&quot;Model training complete!&quot;);\n\n            \/\/ Transform data\n            IDataView transformedData = model.Transform(trainingData);\n\n            VBuffer&lt;float&gt;[] centroids = null;\n            var last = model.LastTransformer;\n            KMeansModelParameters kparams = (KMeansModelParameters)last.GetType().GetProperty(&quot;Model&quot;).GetValue(last);\n            kparams.GetClusterCentroids(ref centroids, out int k);\n            float cluster1 = centroids[0].GetValues().ToArray().FirstOrDefault();\n            float cluster2 = centroids[1].GetValues().ToArray().FirstOrDefault();\n            float cluster3 = centroids[2].GetValues().ToArray().FirstOrDefault();\n\n            Debug.WriteLine(cluster1);\n            Debug.WriteLine(cluster2);\n            Debug.WriteLine(cluster3);\n<\/code><\/pre>\n<p>So we are able to get the centroids of each cluster. What we need is the number of samples in each cluster and the withinss value for each cluster but we just cannot work out how to do this.  <\/p>\n<p>Does anyone know how to access these values?    <\/p>\n<p>Regards  <\/p>\n<p>Ian Hannah  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_created_time":1597248641713,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/65511\/is-there-a-way-to-access-compute-quotas-with-the-a",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#workspace-level-quota\">link<\/a>), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment added into collection becomes a deleted item",
        "Question_created_time":1596676751863,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/60252\/experiment-added-into-collection-becomes-a-deleted",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>I cannot add these experiments into my collections. Whenever I add them, and then refresh my page to see if they are in the collections, they become deleted items. Is this some sort of bug?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/15905-screen-shot-2020-08-05-at-81447-pm.png?platform=QnA\" alt=\"15905-screen-shot-2020-08-05-at-81447-pm.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/15947-screen-shot-2020-08-05-at-81541-pm.png?platform=QnA\" alt=\"15947-screen-shot-2020-08-05-at-81541-pm.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deleted Azure ML Key Vault",
        "Question_created_time":1597243360113,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/65422\/deleted-azure-ml-key-vault",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Does anyone have an idea if there's a way to associate an existing ML resource with a different key vault, storage account, etc? The names generated for these resources when you create a ML resource do not match our naming convention, plus, our key vault associated with the ML resource was accidentally deleted.   <\/p>\n<p>EDIT: hoping someone has a good solution, but for now, the only thing i can think of is Terraform. I'll pursue that and update the thread<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AI Build Flow Getting Failed Due to Error &#34;Action &#39;Predict&#39; failed&#34;",
        "Question_created_time":1597387903250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/66913\/ai-build-flow-getting-failed-due-to-error-34-actio",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Dear Team,  <\/p>\n<p>Trying to build a AI Build solution flow to capture the PDF information, but getting below error details  <br \/>\nStart time: Aug 14, 09:23 AM (2 h ago)  <br \/>\nDuration: 00:00:41  <br \/>\nStatus: Failed  <br \/>\nError: Action 'Predict' failed  <br \/>\nError Details:  <br \/>\n{&quot;operationStatus&quot;:&quot;Error&quot;,&quot;error&quot;:{&quot;type&quot;:&quot;Error&quot;,&quot;code&quot;:&quot;DependencyTimeout&quot;,&quot;message&quot;:&quot;The request timed out or was cancelled by the client for method POST&quot;,&quot;properties&quot;:{&quot;BackendErrorCode&quot;:&quot;DependencyTimeout&quot;,&quot;DependencyHttpStatusCode&quot;:&quot;504&quot;}}}  <\/p>\n<p>Can anyone help me, why this error being returned.  <\/p>\n<p>Thanks  <br \/>\nManoj<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to assign a value to a text in Mashin Learning?",
        "Question_created_time":1597065951903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/63598\/how-to-assign-a-value-to-a-text-in-mashin-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hello Everyone,  <br \/>\nI'm a new user of Microsoft Azure Mashin Learning studio so sorry if my Question is not challenging enough.  <br \/>\nso i'm trying to train a model and my data looks like this<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16842-image.png?platform=QnA\" alt=\"![![16814-image.png\" \/>]<a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16842-image.png?platform=QnA\">1<\/a><\/p>\n<p>the First row is ID ,the second is the Description (this is the part that should get analysed) and the 3. one is basically what should get predicted with azure mashin learning studio.<\/p>\n<p>i know that i should use Classification but which one and how is the part that i'm having difficulty with.<\/p>\n<p>Best Regards<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops ?",
        "Question_created_time":1592185292417,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35810\/how-to-retrain-model-and-deploy-(if-new-model-is-b",
        "Question_score_count":0,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hi  <\/p>\n<p>i am beginner of azure.  <\/p>\n<p>i am trying to use mlops.  <\/p>\n<p>it is not easy to not programmer...  <\/p>\n<p>but i want to practice mlops.  <\/p>\n<p>i want to retrain model by  scheduling.   <\/p>\n<p>please let me know <em><strong>how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops<\/strong><\/em>  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Zoom or increase size of a cell in azure notebooks",
        "Question_created_time":1597097734127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/63846\/zoom-or-increase-size-of-a-cell-in-azure-notebooks",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I have a plot but the cell is quite small to correctly display the plot, I didn\u00b4t find how to zoom or increase cell size for better display, any alternative?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16868-image.png?platform=QnA\" alt=\"16868-image.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Migration from azure notebooks",
        "Question_created_time":1596029416727,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/54459\/migration-from-azure-notebooks",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I have receive many warnings saying that Azure notebooks will be shutdown end of September.  <br \/>\nI wanted to migrate to azure machine learning studio but the notebooks' icon that it is supossed to appear is not there.  <br \/>\nCan you tell me where to find updated instructions in order to create a new space to work with my notebooks?  <br \/>\nSincerely  <br \/>\nHermes<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pipe %&gt;% for R is not working in azure notebooks",
        "Question_created_time":1597095266457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/63863\/pipe-gt-for-r-is-not-working-in-azure-notebooks",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,    <\/p>\n<p>I tried to use the pipe operation %&gt;% of R in an azure notebook without success ...    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16866-image.png?platform=QnA\" alt=\"16866-image.png\" \/>    <\/p>\n<p>is possible to use it or it is a limitation in azure notebooks ?<\/p>",
        "Question_closed_time":1597097474163,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi,  <\/p>\n<p>Fixed.  <\/p>\n<p>Azure Notebook release the session after some time of inactivity, therefore the dplyr package wasn\u00b4t loaded in the session<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Simple filter is not working in Azure notebook for R",
        "Question_created_time":1597096204317,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/63901\/simple-filter-is-not-working-in-azure-notebook-for",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have imported packages:    <\/p>\n<p>library(dplyr)    <\/p>\n<p>Uploaded my dataset:    <\/p>\n<p>bike &lt;- readRDS(&quot;bike.rds&quot;)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16798-image.png?platform=QnA\" alt=\"16798-image.png\" \/>    <\/p>\n<p>But when I try simple &quot;filter&quot; it is not working:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16867-image.png?platform=QnA\" alt=\"16867-image.png\" \/>    <\/p>",
        "Question_closed_time":1597097170387,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Fixed.  <\/p>\n<p>It looks azure notebook clean the session after some period of inactivity, there the package dplyr was not loaded after some time<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Added Experiment to Collection becomes Deleted item",
        "Question_created_time":1596654530823,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/60092\/added-experiment-to-collection-becomes-deleted-ite",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hi, I\u2019ve been having trouble adding an experiment into my collection to show employers. Everytime I add an experiment into my collection it becomes a deleted file. Does anyone else encounter this?<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/15921-7b402028-e6fd-4cd7-99b1-b924c8680428.png?platform=QnA\" alt=\"15921-7b402028-e6fd-4cd7-99b1-b924c8680428.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Reinforcement Learning - Windows server administration",
        "Question_created_time":1596612095990,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/59522\/reinforcement-learning-windows-server-administrati",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi Team,  <br \/>\nGreetings!!!  <\/p>\n<p>I have been looking for use cases that can be addressed using Reinforcement Learning(RL) agent by Machine learning. Would you please share some business use cases?  <br \/>\nOne of the example is clearing\/archiving log files, when it expands. Agent will reward(1) or punish(0) based on the action taken by the system. Over a period of time, system will learn by itself and apply the solution based on reward points.  <\/p>\n<p>Thanks  <br \/>\nDinesh<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot create compute instance with 2 nodes",
        "Question_created_time":1595860934587,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/52800\/cannot-create-compute-instance-with-2-nodes",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am not able to create computer cluster with 2 nodes, every time I try to do it, it gives the error - You only have enough quota to scale upto to 1 node. I am studying for azure exam DP-100. I am following the given learning paths, it was working fine for first 2-3 modules but after that I am not able to create cluster with 2 nodes and not able to proceed with my learning. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Non-interactive login to registered dataset",
        "Question_created_time":1595346764937,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/50386\/non-interactive-login-to-registered-dataset",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I'm trying to tune hyperparameters similar to the following guide: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters<\/a>    <\/p>\n<p>My PyTorch Dataset in train.py contains:    <\/p>\n<pre><code>ws = Workspace.from_config()  \nds = Dataset.get_by_name(ws, 'train')  \ndf = ds.to_pandas_dataframe()  \n<\/code><\/pre>\n<p>This code works fine when run from the command-line, but when I submit a hyperparam tuning job to each node of a training cluster, I get the following error:    <\/p>\n<blockquote>\n<p>We could not find config.json in: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/adamml\/azureml\/hd_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3\/mounts\/workspaceblobstore\/azureml\/HD_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3 or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.    <\/p>\n<\/blockquote>\n<p>If I manually pass my subscription id, resource group, and workspace id, I don't get this error, but now every single hyperparam tuning experiment requires me to log in through the web portal. Is there a way to do a non-interactive login?<\/p>",
        "Question_closed_time":1595534742240,
        "Answer_score_count":2.0,
        "Answer_comment_count":3.0,
        "Answer_body":"<p>If I read the post correctly, you were trying to get an registered dataset within a submitted run. There, Workspace.from_config() won't work since there is no config.json file as the error suggested.    <\/p>\n<p>And when you created an auth object which is InteractiveLoginAuth, it is expected to perform interactive login.    <\/p>\n<p>Within a run the recommended way to connect to current workspace it via:    <\/p>\n<pre><code>   from azureml.core import Run  \n   run = Run.get_context().experiment.workspace  \n<\/code><\/pre>\n<p>Meanwhile, there is way to pass in an dataset object to a run without involving register and workspace signin. If that fit your scenario better, please refer to the example in this document <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#access-and-explore-input-datasets\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#access-and-explore-input-datasets<\/a>    <\/p>\n<pre><code>   from azureml.core import Dataset, Run  \n     \n   run = Run.get_context()  \n   # get the input dataset by name  \n   dataset = run.input_datasets['titanic']  \n     \n   # load the TabularDataset to pandas DataFrame  \n   df = dataset.to_pandas_dataframe()  \n<\/code><\/pre>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Not able to deploy a classification Model using autoML",
        "Question_created_time":1596056740773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/54834\/not-able-to-deploy-a-classification-model-using-au",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>While deploying a classification model to use it as a web service from azure Ml studio, the deployment Pane stays put and no deployment status is shown and not completed even after 20-30 minutes.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Endpoint stuck in \"Transitioning\" state",
        "Question_created_time":1592942479500,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39341\/azure-ml-endpoint-stuck-in-transitioning-state",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_body":"<p>Hello,  <\/p>\n<p>I am trying to deploy several Azure ML models as webservice endpoints using an AKS cluster. I have scripted the deployment process and created a new inference cluster using the Azure ML Studio interface. The first 2-3 endpoints deploy successfully and quickly reach a &quot;Healthy&quot; state (in under a minute), but any subsequent deployments are stuck in the &quot;Transitioning&quot; state endlessly (several hours before just deleting the endpoint).   <\/p>\n<p>Any idea why this might be happening, or what I can do to fix this?  <br \/>\nIs there a limit to the number of endpoints available on an inference cluster?  <\/p>\n<p>I noticed another question with a similar problem about 12 days ago, but that seems to have been resolved by deploying a fix to infrastructure.  <\/p>\n<p>Thank you in advance. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In Azure ML Pipeline, unable to train the model with large dataset",
        "Question_created_time":1595970998073,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/53724\/in-azure-ml-pipeline-unable-to-train-the-model-wit",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I want to train the model with binary logistic regression model,with a dataset of 3000 data points. while creating the pipeline , it fails at the training model step.   <\/p>\n<p>Please help me  to train the model with large datasets or retrain the model continously.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML Sending and parsing datarequests to update AZURE Blob Storage.",
        "Question_created_time":1595285072103,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/49944\/azureml-sending-and-parsing-datarequests-to-update",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hello dear,  <\/p>\n<ol>\n<li> I need to be able to send data (HTTP request)s from different systems (SAP, for example) to update data in Azure Blob Storage.   <\/li>\n<li> And correspondingly, I need to be able to accept coming requests with data from Azure Blob Storage, so that I can train ML models based on that.   <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Invalid graph - invalid dataset",
        "Question_created_time":1595587512910,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/51962\/invalid-graph-invalid-dataset",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Invalid graph - Invalid dataset    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/13654-image.png?platform=QnA\" alt=\"13654-image.png\" \/>    <\/p>",
        "Question_closed_time":1595663838377,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>Thanks <a href=\"\/users\/na\/?userid=1e7f9c83-620c-44be-ba18-5a53cbfac917\">@Showndarya Madhavan  <\/a> for your quick response.    <\/p>\n<p>I found that I had to press Generate Profile as in the picture below and then it worked    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/13722-image.png?platform=QnA\" alt=\"13722-image.png\" \/>    <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Machine Learning",
        "Question_created_time":1595618344213,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/52106\/machine-learning",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>My company provides analytics and machine learning services to enterprises. Now that we are moving over to Azure (from AWS and on-prem), I would like to understand how our workflow might change. The main aspects I am uncertain about is how we ingest data from our customers and how we deploy models for real-time and batch inference with minimal technical overheads.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Service started return InternalError 500 for batch requests. Code:14.",
        "Question_created_time":1595609615540,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/52082\/ml-service-started-return-internalerror-500-for-ba",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>ML Service started return InternalError for batch requests with Code:14.   <br \/>\nI enabled logs, logs are good, even results in storage are good.     <\/p>\n<p>Single request works without any issues.   <\/p>\n<p>{&quot;error&quot;:{&quot;code&quot;:&quot;InternalError&quot;,&quot;message&quot;:&quot;Execution encountered an internal error.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;14&quot;}]}}  <\/p>\n<p>Batch Request Log shows request as &quot;Finished&quot; and provides link to blob.   <\/p>\n<p>Anybody knows what is a Code:14? <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"azure ML no kernel connected jupyter notebook",
        "Question_created_time":1593201636980,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40474\/azure-ml-no-kernel-connected-jupyter-notebook",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I Setup a new ML Resource, cloned a tutorial notebook from azure ml and when i try to get &quot;Jupyter Kernel Failure&quot;. I do see at the top right no kernel is connected. i have set a compute. How am i able to start or restart the jupyter kernel?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML How to retrain published ML WebSerice (end point) using Jupyter Notebooks",
        "Question_created_time":1595284669333,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/49994\/azure-ml-how-to-retrain-published-ml-webserice-(en",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Azure ML    <\/p>\n<p>We are using Azure Notebooks to train ML models. We are able to publish Web services then.(<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-deploy-models-with-aml\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-deploy-models-with-aml<\/a>)    <\/p>\n<p>Out data is stored in Azure Blob Storage. My qustions are:    <\/p>\n<p>1- How can i remotely (as from a web point) update the data at Blob Storage?    <\/p>\n<p>2- How Can I retrain model on that new data that is already publiched? Here I need some kind separate rest end point to be able to lunch retraining remotely.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Relational Database for Automated Machine Learning",
        "Question_created_time":1594992643703,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/48810\/relational-database-for-automated-machine-learning",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I'm trying to build a time-series Machine Learning experiment in Azure Machine Learning. However, I'm using outputs from previous functions which analyzes multiple factors using the same timestamp. For example, extracting all key phrases from customer surveys, and using it to forecast future sales. This creates a new row for each key phrase found, with all of the other survey data points and the same timestamp. This causes an error due to duplicate timestamps across multiple rows forecasting the same target value. I need to either make each timestamp\/survey on row, convert the columns to a list\/array, and have it iterate through each key phrase in that column, or use a relational database where the key phrases column is the foreign key to my table of keyphrases. Any recommendations on how to solve this? Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to run CuDNNLSTM on JupyterLab within Azure Machine Learning?",
        "Question_created_time":1595404543680,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/50813\/how-to-run-cudnnlstm-on-jupyterlab-within-azure-ma",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Good day Everyone  <\/p>\n<p>I am trying to train an LSTM based recurrent neural network using Azure Machine Learning JupyterLab. I have setup the VM instance to use a 6 core GPU. However, when i try to train my recurrent network using the efficient GPU based CuDNNLSTM network i get a &quot;ModuleNotFoundError: no module named tensorflow.contrib&quot;. How can i rectify this so that i can be able to run CuDNNLSTM based code on my GPU?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Specify your own equation in ML.NET",
        "Question_created_time":1594911016883,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/48563\/specify-your-own-equation-in-ml-net",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Is there a way to specify your own equation when using ML.NET in Visual Studio?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio - Stucked in Queue",
        "Question_created_time":1595305659507,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/50103\/azure-machine-learning-studio-stucked-in-queue",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,   <\/p>\n<p>I tried to run my experiment in Azure Learning Studio but it just get stuck at &quot;Queue&quot;.  I cancelled and ensured I just ran 1 experiment but I still get the same issue.   <\/p>\n<p>Please help.  <\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Random forests on Azure GPU VM using the SDK",
        "Question_created_time":1595050125193,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/49008\/random-forests-on-azure-gpu-vm-using-the-sdk",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Can you please share any code examples for training random forests with GPU on Azure using libraries.  <br \/>\nI want to run on the multiple nodes.<\/p>",
        "Question_closed_time":1595231268033,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a>@vautoml-0887<\/a> Thanks for the question. You can run LightGBM with boosting=random_forest, Please follow the below documentation:  <br \/>\n<a href=\"https:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst#boosting\">https:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst#boosting<\/a><\/p>\n<p>Here is a general tutorial on how to run LightGBM on GPU, You can run it on any Azure GPU VM:  <br \/>\n<a href=\"https:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/GPU-Tutorial.rst\">https:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/GPU-Tutorial.rst<\/a><\/p>\n<p>If you need to run it on multiple nodes, there is also a distributed spark implementation available at <a href=\"https:\/\/github.com\/Azure\/mmlspark\">https:\/\/github.com\/Azure\/mmlspark<\/a>.<\/p>\n<p>Random Forests for the GPU using PyCUDA: <a href=\"https:\/\/pypi.org\/project\/cudatree\/\">https:\/\/pypi.org\/project\/cudatree\/<\/a>  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Stream Analytics: ML Service function call in cloud job results in no output events",
        "Question_created_time":1594918621430,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/48592\/azure-stream-analytics-ml-service-function-call-in",
        "Question_score_count":1,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_body":"<p>Hey,    <br \/>\nI've got a problem with an Azure Stream Analytics (ASA) job that should call an Azure ML Service function to score the provided input data.    <br \/>\nThe query was developed und tested in Visual Studio (VS) 2019 with the &quot;Azure Data Lake and Stream Analytics Tools&quot; Extension.    <br \/>\nAs input the job uses an Azure IoT-Hub and as output the VS local output for testing purposes (and later even with Blobstorage).    <br \/>\nWithin this environment everything works fine, the call to the ML Service function is successfull and it returns the desired response.    <br \/>\nUsing the same query, user-defined functions and aggregates like in VS in the cloud job, no output events are generated (with neither Blobstorage nor Power BI as output).    <br \/>\nIn the ML Webservice it can be seen, that ASA successfully calls the function, but somehow does not return any response data.    <br \/>\nDeleting the ML function call from the query results in a successfull run of the job with output events.    <\/p>\n<p>For the deployment of the ML Webservice I tried the following (working for VS, no output in cloud):    <\/p>\n<ul>\n<li> ACI (1 CPU, 1 GB RAM)    <\/li>\n<li> AKS dev\/test (Standard_B2s VM)    <\/li>\n<li> AKS production (Standard_D3_v2 VM)    <\/li>\n<\/ul>\n<p>The inference script function schema:    <\/p>\n<ul>\n<li> input: array    <\/li>\n<li> output: record    <\/li>\n<\/ul>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/12734-image.png?platform=QnA\" alt=\"12734-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/12648-image.png?platform=QnA\" alt=\"12648-image.png\" \/>    <\/p>\n<p>The ASA job subquery with ML function call:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/12735-image.png?platform=QnA\" alt=\"12735-image.png\" \/>    <br \/>\n&quot;Sequence&quot; is a subquery that aggregates the data into sequences (arrays) with an user-defined aggragate.    <\/p>\n<p>I hope the provided information is sufficient and you can help me.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Enpoint deployment failed EAST US region",
        "Question_created_time":1594945530060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/48609\/azure-ml-enpoint-deployment-failed-east-us-region",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have an Azure ML Real-time inference endpoint deployed ran for a month till yesterday. Today it is in the state of &quot;Failed&quot;.  <\/p>\n<p>I did create a new compute and did a new deployment in the same region EAST US and it failed again.  <\/p>\n<p>What's going? Is this just a problem for me or a general issue?  <\/p>\n<p>Thanks  <br \/>\n-Dali<\/p>",
        "Question_closed_time":1594953029753,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi, thanks for reaching out. I successfully deployed in the east us region. Please review the following <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-pipelines\">troubleshooting guidelines<\/a>. Also check for any <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/service-health\/service-health-overview\">service\/resource health issues<\/a> that could be impacting your service. Let me know if you're still experiencing issues afterwards and please share the logs so we can investigate further. Thanks.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Feature request: module for selecting rows in a dataset",
        "Question_created_time":1594758444380,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/47022\/feature-request-module-for-selecting-rows-in-a-dat",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm looking for a module similar to Select Columns in Dataset but for rows. For example, one of the columns in my dataset is a string containing the quality control level. If the QC level equals some value, I would like to keep that row and discard the rest of the rows. Similarly, my dataset contains -999 values to represent NaNs, but I have no way of removing these values without writing a custom Python script to do so.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question: how to define custom Model in Designer",
        "Question_created_time":1594757599337,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46909\/question-how-to-define-custom-model-in-designer",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML Designer, I can't figure out how to define a custom Model. The builtin NN Regression module has many bugs (will open a separate issue for those), so I need to make my own custom model. The closest thing I've found so far is Create Python Model, but this has the following limitation:  <\/p>\n<ul>\n<li> Can't parametrize model, so doesn't work with Tune Model Hyperparameters module  <\/li>\n<\/ul>\n<p>Is there any way to design my own model, and is it possible to contribute this upstream for others to use?  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question: what framework\/language does Designer use behind the scenes?",
        "Question_created_time":1594757836773,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46976\/question-what-framework-language-does-designer-use",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using Azure ML Designer, but it isn't clear what framework\/language is being used behind the scenes. For example, deep learning is incredibly computation-heavy, so I would like to run any matrix multiplications on a GPU instead of on a CPU. For the builtin modules, does the framework support GPU operations, or only CPU? If I have a complex pipeline, are all steps in the pipeline (that don't depend on each other) run in parallel? Or does that require the use of a Compute Cluster instead of a Compute Instance? How are NaNs handled in the dataset? So far I've only encountered seg faults with the builtin models, so I'm assuming they aren't handled. Also, why does the pipeline take so long to run? If I code things in pure pandas, the pipeline should finish in under a second on my laptop, but takes several minutes to run in Azure ML Designer, regardless of which hardware I choose.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Real-time endpoint response is empty",
        "Question_created_time":1592313268633,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/36610\/real-time-endpoint-response-is-empty",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_body":"<p>Hi, I've created and deployed NLP pipeline as a real-time endpoint, but the response that I get is an empty result ( {&quot;Results&quot;:{}} ) with Status 200 OK.    <\/p>\n<p>I have the Owner role, so i think that the permission is not a problem. I've also tried to deploy the preset experiment &quot;Sample 1: Regression - Automobile Price Prediction (Basic)&quot; using the same resources and it returned the results without a problem.    <\/p>\n<p>In the training pipeline, I've used the train and validation datasets.  After creating the real-time inference pipeline, it automatically created two Web Service inputs the one linked to the train dataset input is irrelevant in the real-time inference pipeline as it's used only to create the Vocabulary for the Extract N-Gram Features from Text module linked to the validation dataset.    <br \/>\nAfter that, I've deleted the Web Service input connected to the training dataset and tried to deploy the real-time endpoint.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/10195-a.jpg?platform=QnA\" alt=\"10195-a.jpg\" \/>    <\/p>\n<p>After submitting the training pipeline, I've saved the Result Vocabulary from the Extract N-Gram Features from Text module that is connected to the training dataset and used it as an input vocabulary for the N-Gram module (ReadOnly vocabulary mode) in the real-time inference pipeline and deployed that as a real-time endpoint.    <\/p>\n<p>In both cases above, I didn't get any errors, scoring and evaluation of a model are correct but the response from the endpoint is empty.    <br \/>\nIt's worth mentioning, that if I leave the real-time pipeline as is (with two inputs) it doesn't work because of the parameter settings in the Extract N-Gram Features from Text module where training dataset is connected.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"User program failed with ValueError: ZIP does not support timestamps before 1980",
        "Question_created_time":1594652762620,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46217\/user-program-failed-with-valueerror-zip-does-not-s",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi i'm running into an issue in Azure ML-  <\/p>\n<p>I'm getting the error &quot;User program failed with ValueError: ZIP does not support timestamps before 1980&quot;  <br \/>\nwhen it calls the  <\/p>\n<p>when i run the following part of the code as a part of a pipeline  <\/p>\n<p>from azureml.train.estimator import Estimator  <\/p>\n<p>script_folder = os.getcwd()  <br \/>\nprint(&quot;script folder : &quot;,script_folder)  <br \/>\nest = Estimator(source_directory=script_folder,  <br \/>\ncompute_target=compute_target,  <br \/>\nenvironment_definition=env,  <br \/>\nentry_script='train.py')  <\/p>\n<p>run = exp.submit(config=est)  <br \/>\nprint(run)  <\/p>\n<p>Not sure what is causing this but when i run the file independently of the pipeline it runs fine<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Time out after Succeded",
        "Question_created_time":1594192651827,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/44044\/time-out-after-succeded",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>Hi, I was trying to deploy my model as a web service after I run this command (Webservice.deploy_from_model), it said it was succeded. After that, I run this command (service.wait_for_deployment). this process told me the &quot;Time out&quot; condition. My region is southeast Asia. can you help me what's wrong with my development?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Automated ML(interface) Does k-fold cross validation in autoML use just random sampling?",
        "Question_created_time":1593759166663,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/42551\/azure-automated-ml(interface)-does-k-fold-cross-va",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is k-fold cross validation in automated ML(interface) stratified sampling or random sampling by default?     <br \/>\nI have ran several automated ML experiments using a training set with five data points for the least common class(say class A), and started to wonder if each CV set is guaranteed to have at least one element from the class A when I set k as 4 or 5.    <br \/>\nI read the 'Train and validation data' part in the link below    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>    <br \/>\nand want to make sure if it's okay to use 4-fold cv or 5-fold cv.    <br \/>\nThanks.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question: distinction between Modules and Models in Designer",
        "Question_created_time":1594756919963,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46991\/question-distinction-between-modules-and-models-in",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML, under designer, there are 3 categories:  <\/p>\n<ul>\n<li> Datasets  <\/li>\n<li> Modules  <\/li>\n<li> Models  <\/li>\n<\/ul>\n<p>Datasets are pretty straightforward, but I don't understand the distinction between Modules and Models. As an ML researcher, when I think of a &quot;model&quot;, I think of something like linear regression or SVM. However, those are listed under Modules -&gt; Machine Learning Algorithms. So what exactly qualifies as a Model?  <\/p>",
        "Question_closed_time":1594759184477,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Hi,  <\/p>\n<p>Thanks for reaching out.  <\/p>\n<p>Model is a concept of Machine Learning itself. A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about those data. For example, let's say you want to build an application that can recognize a user's emotions based on their facial expressions. You can train a model by providing it with images of faces that are each tagged with a certain emotion, and then you can use that model in an application that can recognize any user's emotion.   <\/p>\n<p>Modules is one of the concept of Azure Machine Learning Designer. Each module represents a set of code that can run independently and perform a machine learning task, given the required inputs. A module might contain a particular algorithm, or perform a task that is important in machine learning, such as missing value replacement, or statistical analysis.  <\/p>\n<p>Let me know if you have any question.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Bug report: can't parametrize # hidden node or momentum in NN regression model",
        "Question_created_time":1594758142250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/47011\/bug-report-cant-parametrize-hidden-node-or-momentu",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I'm using the NN regression model in Azure ML Designer, but it appears to have a bug. If I switch trainer mode to ParameterRange, it allows me to use a semicolon-separated list of hyperparameters for learning rate and epochs. However, I'm unable to use a semicolon-separated list of hyperparameters for number of hidden nodes or momentum. Since the number of hidden nodes is the most commonly tuned hyperparameter for a MLP, this module doesn't seem particularly useful if I want to use it to tune hyperparameters.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature request: more customizability in builtin models",
        "Question_created_time":1594758735000,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46982\/feature-request-more-customizability-in-builtin-mo",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML Designer, I would like to customize and parametrize other aspects of the models. For example, in the NN Regression model, I would like to try various optimizers (Adam, Adagrad, SGD) and activation functions (ReLU, Sigmoid, Tanh).<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature request: module for handling timestamps",
        "Question_created_time":1594758338030,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/47021\/feature-request-module-for-handling-timestamps",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML Designer, there are dozens of builtin Modules for data transformation, but none of them can handle timestamps. What I'm looking for is a module in which the user:  <\/p>\n<ol>\n<li> Selects which column of the input dataset contains a timestamp  <\/li>\n<li> Selects which output columns they would like to compute, such as: year, month, day, hour, min, sec, DOY, DOW, etc.  <\/li>\n<li> Selects how they want to perform the operation: inplace, append, etc.  <\/li>\n<\/ol>\n<p>If you can show me how to write a custom Module and contribute it upstream, I would be more than happy to do this myself.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature request: models only support single prediction column",
        "Question_created_time":1594758597390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46949\/feature-request-models-only-support-single-predict",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Many machine learning tasks involve input data in the form of scalars, vectors, matrices, and higher-order tensors. Similarly, the output predictions are often in the same format. The builtin NN regression model in Azure ML Designer only supports scalar predictions (single column of ground truth labels), but many tasks involve multiple columns. For example, you might be trying to predict mean and std dev, or a bounding box.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Bug report: Apply Math Operation doesn't cache and reuse results from previous run",
        "Question_created_time":1594757991143,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/47002\/bug-report-apply-math-operation-doesnt-cache-and-r",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>In Azure ML Designer, I have a complex data preprocessing pipeline. One of the main features of Designer pipelines is that they are supposed to cache the results of each run, so that they don't need to be re-executed every time if nothing that they depend on has changed. This feature works correctly for all of the nodes in my graph except for the Apply Math Operation nodes. This results in the second half of my pipeline needing to be re-run every time I add a new node.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning",
        "Question_created_time":1594208627597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/44135\/machine-learning",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>i have problem with detecting the objects using the ML.NET and draw a boundary boxes   <br \/>\nand i cannot find an example or module that i can learn.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Automated ML(interface) how do models created from an Automated ML experiment handle Imbalanced Data?",
        "Question_created_time":1593407718737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40727\/azure-automated-ml(interface)-how-do-models-create",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>I have run automated ML experiments with imbalanced data (10:1, 20:1, sometimes 30:1) and deployed the best models which all showed fantastic results.    <\/p>\n<p>When I looked up the link    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data<\/a>    <br \/>\n, it says Azure automated ML can properly handle imbalance of up to 20:1.     <br \/>\nI started to wonder where the ratio 20:1 came from.     <\/p>\n<p>As far as I understand, Azure automated ML doesn't use upsampling, downsampling or resampling, and is more focused on a column of weights to make a class more or less important, and a performance metric dealing better with imbalanced data.    <\/p>\n<ul>\n<li> Does this 20:1 come from some theory? or from tons of experiments already conducted?    <\/li>\n<\/ul>\n<p>Azure automated ML shows the result with warning when I use 30:1(or more) imbalanced data, but I still wonder why it is 20:1.<\/p>",
        "Question_closed_time":1594030959317,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>In AutoML we use 5% minority class as threshold to classify imbalance\/non-imbalance. This is a heuristic, and is one guideline produced in the Guardrails to the question \u201cAt x% threshold level is the dataset balanced?\u201d. Since it is not possible to absolutely classify imbalance in all cases (depending on the dataset and its size and distribution, 5% or 10% or even higher may mean imbalance, whereas for very large datasets the minority class may have sufficient training samples for model to learn and get a reasonable imbalance-appropriate metric such as weighted AUC or balanced accuracy),  current Guardrails serve the goal of surfacing \u201csubstantial\u201d imbalance to user so the user can take any of the following measures:  <\/p>\n<p>\u2022\tWhen the user knows (either from their knowledge of their own data or from guardrails) that there is imbalance, Automated ML provides an option in the Automated ML config to provide sample weights \u2013 a user-specified weight array where user can specify to weight each sample with a weight. That way they can weigh the minority class more when submitting the data into Automated ML config. We will soon provide weighting option for imbalance classes from within AutoML that will be activated automatically when imbalance is detected.  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Why does Azure Machine Learning Studio (classic) take additonal time to execute python scripts?",
        "Question_created_time":1593687947923,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/42134\/why-does-azure-machine-learning-studio-(classic)-t",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,  <\/p>\n<p>I have been working with ML Studio (classic) and facing a problem with &quot;Execute Python&quot; scripts. I have noticed that it takes time to perform some internal tasks after which it starts executing the actual Python code in ML Studio. This delay has caused an increased time of 40-60 seconds per module which is aggregating and causing a delay of 400-500 seconds per execution when consumed through Batch Execution System or on running the experiments manually. (I've multiple Modules of &quot;Execute Python&quot; scripts)  <\/p>\n<p>Can you please help understand the reason behind this or any optimization that can be done?  <\/p>\n<p>Regards,  <br \/>\nAnant<\/p>",
        "Question_closed_time":1594049839263,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I completely understand, sorry for the inconvenience, however, this is a known limitation as optimizing performance in Azure ML Studio (Classic) isn't supported. We recommend that customers use Designer for advanced capabilities and active updates\/improvements for the service. Thanks.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Machine Learning Model Deployment",
        "Question_created_time":1593620777527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/41755\/machine-learning-model-deployment",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am new to ML model and am researching using Azure Databricks and MLFlow to train a model. My question is once the model is created, is there a way to host the model that can be downloaded and inferenced remotely ? I am looking for options other than deploying it as a REST endpoint. <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does Azure Ml support training deep learning models like yolov3, faster R-CNN, Deeplabv3+, Mask R-CNN",
        "Question_created_time":1594372489527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/45193\/does-azure-ml-support-training-deep-learning-model",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Does the azure ml supports training and inference task for deep learning models for object detection, semantic segmentation models.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Jupyter Lab Git options",
        "Question_created_time":1594373340610,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/45187\/azure-machine-learning-jupyter-lab-git-options",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <br \/>\nI'm trying to setup an integration between a GITHub repository and my Jupyter Lab but I'm struggling to find the GIT options in my Jupyter Lab application.  <\/p>\n<p>I was expecting to see a Git clone button, a Git option on the toolbar and also the same option on the left pane but there is nothing GIT related.  <\/p>\n<p>I've already installed successfully the following:  <\/p>\n<p>pip install jupyterlab-git  <br \/>\npip install --upgrade python-gitlab  <\/p>\n<p>But nothing happens.  <br \/>\nWhen I try to clone a GIT repository, I get the folders\/files but then I can't interact with it. It's just copying it into my space but then I can't push\/pull anything.  <\/p>\n<p>Can you help me on this?  <\/p>\n<p>Thank you,  <br \/>\nCarla  <\/p>",
        "Question_closed_time":1594378601087,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I found the answer to my question by following the steps here:  <\/p>\n<p><a href=\"https:\/\/www.oreilly.com\/library\/view\/jupyterlab-quick-start\/9781789805543\/94288841-0158-4a98-8151-4a90ea9bf2da.xhtml\">https:\/\/www.oreilly.com\/library\/view\/jupyterlab-quick-start\/9781789805543\/94288841-0158-4a98-8151-4a90ea9bf2da.xhtml<\/a> <\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"model status unhealthy unable to debug",
        "Question_created_time":1592232758653,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/36115\/model-status-unhealthy-unable-to-debug",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>Hi team,  <\/p>\n<p>I am new to azure and trying to deploy model with multiple files on azure. after deployment process it was showing unhealthy status.how can i debug?  <\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way not to record the source directory files snapshot or delete it after an AML pipeline run?",
        "Question_created_time":1592380547767,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37071\/is-there-a-way-not-to-record-the-source-directory",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am running experiments with AML pipeline and I do not want to store the source directory files of my script steps in the experiment panel after the run is completed (when I enter a run from the experiments panel, there is a snapshot containing those files). I know experiment runs can't be deleted, only archived, but this is not what I'm looking for.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Code",
        "Question_created_time":1593978457140,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/43081\/machine-learning-code",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_body":"<p>Hey,  <\/p>\n<p>I followed your Tutorial: Categorize iris flowers using k-means clustering with ML.NET to develop a porgram on drivers: whether a driver is good or bad.  <br \/>\nI would like that on the console it shows me the 2 groups that it has to form with their properties (for example prenon and last name). all the bad drivers then all the good. How can I do that?   <\/p>\n<p>I look forward to your response   <br \/>\nThank you very much<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning Code",
        "Question_created_time":1593980194230,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/43091\/machine-learning-code",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hey,   <\/p>\n<p>I am developing an ASP.Net application and I would like to integrate machine learning into my app. But let the result appear in a window of my app and not on the console. Can you tell me how to do it please?  <\/p>\n<p>Thank you in advance  <br \/>\nI look forward to your response  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resource Groups are EMPTY for all the AI lessons in MSLearn",
        "Question_created_time":1593355107607,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40537\/resource-groups-are-empty-for-all-the-ai-lessons-i",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I have been attempting to complete the AI learning challenge.  Starting with the Create Bot lesson and then Cognitive Vision services lesson, I can't create resources as the Resource groups lists are empty.  I type in the names in the lessons and that doesn't work.    <\/p>\n<p>I click the link to the Azure portal and I go to the one I created ... and it exists.  But it can't find anything (like mslearn-faceapi) to complete the lessons.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio Designer (preview) - Selective module execution",
        "Question_created_time":1593464903017,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/41135\/azure-machine-learning-studio-designer-(preview)-s",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I find that I am often inserting or modifying one module in a flow, and needing to edit several later items in the DAG,  <\/p>\n<p>But since the prior module is now invalidated, It asks me to SUBMIT and run the full experiment, so that I can do things like select columns.  <\/p>\n<p>Is there not a way to disable modules? or selectively execute just a subset of modules?  <\/p>\n<p>I am using the preview versions of the ML  studio.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Something Wrong?",
        "Question_created_time":1593090172523,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40031\/something-wrong",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<pre><code>    Isn&amp;#39;t me only or...?[welcome-to-azure][1]![10701-%E6%89%B9%E6%B3%A8-2020-06-25-205624.png][2]  \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureMLCompute Job Failed",
        "Question_created_time":1592828367680,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38604\/azuremlcompute-job-failed",
        "Question_score_count":1,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>I am having this error when I was following the notebook here:     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/<\/a>     <\/p>\n<p>AzureMLCompute job failed. BFSMountError: unable to mount blob fuse file system Info: Could not mount Azure Blob Container azureml-blobstore-29.......xx12 at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid. Info: Job environment preparation failed on 10.0.0.4.    <\/p>\n<p>{    <br \/>\n  &quot;message&quot;: &quot;AzureMLCompute job failed.\\nBFSMountError: unable to mount blob fuse file system\\n\\tInfo: Could not mount Azure Blob Container azureml-blobstore-29.......xx12  at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.\\n\\tInfo: Job environment preparation failed on 10.0.0.4.&quot;    <br \/>\n}    <\/p>\n<p>It says 'cannot access the storage account' however I am able to run a Jupiter notebook within this compute and access the storage account without any problem. I guess 'account key' is referring to the storage account key. If so, how can I provide it during deployment?     <\/p>\n<p>Note:     <\/p>\n<ol>\n<li> I am having a similar error when I try to deploy a model to ACI.     <\/li>\n<li> The AML workspace and so the storages are created in a VNET    <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Ranking calculation of probability programming with draw",
        "Question_created_time":1593445781820,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40959\/ranking-calculation-of-probability-programming-wit",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<pre><code>  On the web page\u201c https:\/\/learn.microsoft.com\/zh-cn\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dAccording to the winning and losing relationship of each player and the result of the game, the players are ranked by using probabilistic programming. The source code is as follows  \n<\/code><\/pre>\n<p> static void Main(string[] args)    <br \/>\n        {  <br \/>\n        \u202f\u202f\u202f \/\/ The winner and loser in each of 6 samples games  <br \/>\n        \u202f\u202f\u202f var winnerData = new[] { 0, 0, 0, 1, 3, 4 };  <br \/>\n        \u202f\u202f\u202f var loserData = new[] { 1, 3, 4, 2, 1, 2 };  <\/p>\n<hr \/>\n<p>Here only win or lose, such as the game is a draw, how to add a draw data, how to calculate the ranking    <\/p>\n<hr \/>\n<pre><code>    \u202f\u202f\u202f \/\/ Define the statistical model as a probabilistic program  \n    \u202f\u202f\u202f var game = new Range(winnerData.Length);  \n    \u202f\u202f\u202f var player = new Range(winnerData.Concat(loserData).Max() + 1);  \n    \u202f\u202f\u202f var playerSkills = Variable.Array&lt;double&gt;(player);  \n    \u202f\u202f\u202f playerSkills[player] = Variable.GaussianFromMeanAndVariance(6, 9).ForEach(player);  \n\n    \u202f\u202f\u202f var winners = Variable.Array&lt;int&gt;(game);  \n    \u202f\u202f\u202f var losers = Variable.Array&lt;int&gt;(game);  \n\n    \u202f\u202f\u202f using (Variable.ForEach(game))  \n    \u202f\u202f\u202f {  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ The player performance is a noisy version of their skill  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f var winnerPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[winners[game]], 1.0);  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f var loserPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[losers[game]], 1.0);  \n<\/code><\/pre>\n<p>\u202f\u202f\u202f\u202f\u202f\u202f\u202f         \/\/ The winner performed better in this game    <br \/>\n        \u202f\u202f\u202f\u202f\u202f\u202f\u202f Variable.ConstrainTrue(winnerPerformance &gt; loserPerformance);  <br \/>\n        \u202f\u202f\u202f }  <\/p>\n<pre><code>    \u202f\u202f\u202f \/\/ Attach the data to the model  \n    \u202f\u202f\u202f winners.ObservedValue = winnerData;  \n    \u202f\u202f\u202f losers.ObservedValue = loserData;  \n\n    \u202f\u202f\u202f \/\/ Run inference  \n    \u202f\u202f\u202f var inferenceEngine = new InferenceEngine();  \n    \u202f\u202f\u202f var inferredSkills = inferenceEngine.Infer&lt;Gaussian[]&gt;(playerSkills);  \n\n    \u202f\u202f\u202f \/\/ The inferred skills are uncertain, which is captured in their variance  \n    \u202f\u202f\u202f var orderedPlayerSkills = inferredSkills  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f.Select((s, i) =&gt; new { Player = i, Skill = s })  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f.OrderByDescending(ps =&gt; ps.Skill.GetMean());  \n\n    \u202f\u202f\u202f foreach (var playerSkill in orderedPlayerSkills)  \n    \u202f\u202f\u202f {  \n    \u202f\u202f\u202f\u202f\u202f\u202f\u202f Console.WriteLine($&quot;Player {playerSkill.Player} skill: {playerSkill.Skill}&quot;);  \n    \u202f\u202f\u202f }  \n    }  \n   The result of these games is only win or lose, there is no draw, official example\u201c https:\/\/github.com\/dotnet\/infer\/blob\/master\/src\/Tutorials\/ChessAnalysis.cs \u201dI can't understand. How to use a draw game Infet.net Ranking players\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ML Training course - Cost",
        "Question_created_time":1592141346953,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35883\/ml-training-course-cost",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,  <\/p>\n<p>I am working in E&amp;Y. Wanted to know info about training course.  <\/p>\n<p>if we want to do training course i.e &quot; Azure Machine Learning&quot; for the team(10 people), What would be the cost involved for instructor based training.  <\/p>\n<p>If you can provide us quote , it would be great.  <\/p>\n<p>Thanks &amp; Regards,  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can you give me an example of a draw with Infer.net",
        "Question_created_time":1593357487593,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/40647\/can-you-give-me-an-example-of-a-draw-with-infer-ne",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>On the web\u201c <a href=\"https:\/\/learn.microsoft.com\/en-au\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net\">https:\/\/learn.microsoft.com\/en-au\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net<\/a> \u201dFor Infer.net Probability programming example of. In this example, there are only wins or losses, no draws. Can you give me an example of a draw, which can be used in the machine learning of E-sports Bo 2 or football, thank you<\/p>",
        "Question_closed_time":1593434922093,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>The <a href=\"https:\/\/dotnet.github.io\/infer\/userguide\/Chess%20Analysis.html\">Chess Analysis<\/a> example in the Infer.NET documentation includes draws.  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Practice Exam for DP-100",
        "Question_created_time":1593082618390,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39948\/practice-exam-for-dp-100",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>no practice exam for the Azure certification DP-100 seems to be available in the official channels. It would, however, be very helpful for preparing.  <br \/>\nBy any chance, do you plan to introduce such a resource any time soon?  <\/p>\n<p>Thanks and best regards  <br \/>\nTim<\/p>",
        "Question_closed_time":1593083339537,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi,    <\/p>\n<p>Microsoft Certification \/ Exams are currently not supported in the Q&amp;A forums, the supported products are listed over here <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/products\">https:\/\/learn.microsoft.com\/en-us\/answers\/products<\/a> (more to be added later on).      <\/p>\n<p>You can ask the experts in the dedicated <strong>Microsoft Certification - Preparation Resources<\/strong> forum over here:        <br \/>\n<a href=\"https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep\">https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep<\/a>    <\/p>\n<p>(Please don't forget to accept helpful replies as answer)      <\/p>\n<p>Best regards,      <br \/>\nLeon    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Pathway for code free predictive modeling",
        "Question_created_time":1592869306553,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38841\/pathway-for-code-free-predictive-modeling",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am looking at Azure's training modules and it states I can learn no-code models with Azure, but it also tells me I should know python. I'm a little confused at where I should spend time training in most efficient pathway. My goal is to just do predictive modeling within Azure. I have technical\/IT literacy however coding is at a basic level.   <\/p>\n<p>Ideally id like some sort of Certification, if possible from just &quot;Create no-code predictive models with Azure Machine Learning&quot;  <\/p>\n<p>Is &quot;Microsoft Certified: Azure Data Scientist Associate&quot; going to require a lot of pre work on python\/torch\/tensor? I'd ideally like Azure to be my entry. <\/p>",
        "Question_closed_time":1592924808467,
        "Answer_score_count":2.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks for reaching out. Azure machine learning has a drag and drop interface (Designer) that supports code free predictive modeling. <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/paths\/create-no-code-predictive-models-azure-machine-learning\/\">Create no-code predictive models with Azure Machine Learning<\/a> training modules is a great starting point and provides a pathway for <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/certifications\/azure-data-scientist\">Azure Data Scientist Associate certification<\/a>. However, you also need programming experience and familiarity with various data science processes\/principles to be successful on the certification exam.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Cannot open dataset in Notebook",
        "Question_created_time":1592952110927,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39391\/cannot-open-dataset-in-notebook",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>If I select the dataset in my experiment in Azure ML Studio and ty to open it in the Notebook Python 3 I'm getting the following error:  <\/p>\n<p>Service call failed. Error 409 (Notebook already exists) when requesting \/notebooks?api-version=2.0  <\/p>\n<p>The thing is I don't even have the Notebook menu on the left hand - I've seen this option in documentation, though it's pretty old (from 2015) and was wondering how can I add it into my workspace.<\/p>",
        "Question_closed_time":1592986989907,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=d5b8850d-e3b2-475b-9119-90bd050e6e25\">@Olga Arapova  <\/a> In Azure Machine Learning Studio classic portal the notebooks feature has retired recently. Before the retirement a banner was available on the portal to download the notebooks and data. Here is the message for reference.    <\/p>\n<blockquote>\n<p>The notebooks(preview) feature will be shut down at <strong>4\/13\/2020<\/strong>. After shut down the notebooks tab will disappear and the notebooks data can not be restored. Please download your notebooks data before <strong>4\/13\/2020<\/strong>. Click <a href=\"https:\/\/aka.ms\/studio-download-notebooks\">here<\/a> to check how to download your data. If you have further question, <a href=\"https:\/\/portal.azure.com\/#blade\/Microsoft_Azure_Support\/HelpAndSupportBlade\/overview\">contact us<\/a>    <\/p>\n<\/blockquote>\n<p>If the notebook was not saved then this notebook would not be available now.     <\/p>\n<p>The new Machine Learning portal ml.azure.com will help you to create a new notebook and use Jupyter. If you want to get started on the same from the new portal this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks\">documentation<\/a> will help you get started.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Endpoint not being created Azure Designer",
        "Question_created_time":1592922691007,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39203\/endpoint-not-being-created-azure-designer",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_body":"<p>I created a simple recommendation model in Azure Designer. The model is able to train and from that, I created an inference pipeline. I ran it and deployed it, under a new AKS inference cluster and even experiment. However, the endpoint is just not being created. I can see the model is registered with a new version but no endpoint is created. Below, I have attached a screenshot of the inference pipeline in designer.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/10505-screenshot-2020-06-23-at-162828.png?platform=QnA\" alt=\"10505-screenshot-2020-06-23-at-162828.png\" \/>    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to Cancel Upload? - Azure Machine Learning Studio",
        "Question_created_time":1592921687557,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39201\/how-to-cancel-upload-azure-machine-learning-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,  <\/p>\n<p>Please will you tell me how to cancel a dataset upload?  <\/p>\n<p>I tried to upload a small (321kb) CSV to Azure Machine Learning Studio.  The upload has been running for more than 1 hour, but it still says uploading.  <\/p>\n<p>I tried to upload other files (different names), and they are hanging too....same symptoms.  <\/p>\n<p>It seems the first problem is blocking all subsequent upload attempts.  <\/p>\n<p>Until today uploads worked perfectly.....multiple file types, multiple sizes, multiple dates, were all OK.  <\/p>\n<p>I have plenty of space left in my environment.  <\/p>\n<p>I tried closing and restarting my browser....same problem.  I accessed my AMLS via a different computer...same problem.  <\/p>\n<p>Thanks in advance for any advice you can give.  <\/p>",
        "Question_closed_time":1592933611233,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p>Well, I don't know if you (<a href=\"\/users\/na\/?userid=d67fe4ea-5ec6-4e6b-b93c-404092429abd\">@GiftA-MSFT  <\/a>) did something to help, but it's solved!  Thanks if you did take that initiative, I appreciate it.  :-)    <\/p>\n<p>...or it could be that after 4-5 hours the upload just completed.  My internet connection was fine (it's a 40Mb line), so I'm not sure what the solution was.  Perhaps patience alone is the answer.    <\/p>\n<p>Anyway, thanks for taking an interest in my problem either way.      <\/p>\n<p>Best wishes.  :-)<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Out-of-memory error webservice deployed with Azure ML Studio",
        "Question_created_time":1592827334117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38509\/out-of-memory-error-webservice-deployed-with-azure",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have a webservice which exposes a predictive model. It has been deployed with Auzure ML Studio. Since the last model re-training and webservice deployment, in circa 1% of the cases in production, I get the following out-of-memory (possibly correlated) errors:<\/p>\n<p>1) &quot;The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.&quot;  <br \/>\n2) &quot;The following error occurred during evaluation of R script: R_tryEval: return error: Error: cannot allocate vector of size 57.6 Mb&quot;<\/p>\n<p>Please note that these errors occur exclusively while trying to consume the webservice, and not while model training, evaluation and deployment.<\/p>\n<p>Also, consuming the webservice in batch mode, as suggested <a href=\"https:\/\/social.microsoft.com\/Forums\/azure\/he-IL\/ccf4c683-f904-4117-8a4e-3258a56515f9\/azureml-execure-r-script-cannot-allocate-vector-of-size-818-mb?forum=MachineLearning\">here<\/a>, is not a viable option for our business use case.<\/p>\n<p>Is there a way to increase the memory limit for Azure webservices?<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":1592916913067,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks for reaching out. Currently, there's no way to increase memory limit in Classic Studio. We encourage customers to try <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-designer\">Azure Machine Learning designer (preview)<\/a>, which provides similar drag and drop ML modules plus scalability, version control, and enterprise security. Furthermore, with Designer, the endpoints are deployed to AKS where no limit other than cluster resource is imposed.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to consume easily for test Azure ML Studio webservice",
        "Question_created_time":1592224847787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/36106\/how-to-consume-easily-for-test-azure-ml-studio-web",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Dear,<\/p>\n<p>Does someone manage to consume an experiments deployed in a webservice via an external source just for testing. (multiple users want to test)  <br \/>\nThe solutions I have is :  <br \/>\n** from excel but requires addons on users laptops  <br \/>\n** from a webpage bu requires coding<\/p>\n<p>I would like to have a shared webpage for example and from there :  <br \/>\n<strong>* users enter features values  <br \/>\n*<\/strong> users get in reply via the webservice the predicted value.  <br \/>\n==&gt; SharePoint might be useful ?? Microsoft Apps ??  <br \/>\nI need to select a solution that avoids any coding work as it is only for users testing....<\/p>\n<p>Regards,<\/p>\n<p>Mohamed.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"in Azure Machine Learning service, how to update python pickle file 's ML model parameter?",
        "Question_created_time":1592180368837,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35933\/in-azure-machine-learning-service-how-to-update-py",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>after using Azure Auto ML or Designer, model creates Pickle file.  <\/p>\n<p>i tried to develop model in python pickle file by tunning some parameter by set_params method  <\/p>\n<p>as you know this pickle file has 'Pipeline', 'y_transformer', 'y_transformer_name' key.  <\/p>\n<p>and Pipeline has parameter setting  <\/p>\n<p>but as i wrote,  <\/p>\n<p>a.pipeline.set_params (memory = 'n')  <\/p>\n<p>this code is work.  <\/p>\n<p>memory parameter is changed.  <\/p>\n<p>but  <\/p>\n<p>a.pipeline.set_params (XGBoostClassifier__base_score = 0.6)  <\/p>\n<p>this code is not work.  <\/p>\n<p>please let me know how to change model's hyperparameter<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning best model's update paramete with python pickle",
        "Question_created_time":1591866370453,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/34853\/azure-machine-learning-best-models-update-paramete",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Hi  <\/p>\n<p>i am trying to Azure Machine Learning best model's update parameter with python pickle type  <\/p>\n<p>best model trained by xgboost.  <\/p>\n<p>i load model through pickle and tried to change parameter.  <\/p>\n<p>import joblib  <\/p>\n<p>a=joblib.load(&quot;model.pkl&quot;)  <\/p>\n<p>a.pipeline.set_params(XGBoostClassifier__base_score=0.6)  <\/p>\n<p>but it doesn't work.  <\/p>\n<p>however   <\/p>\n<p>a.pipeline.set_params(memory='n')  <\/p>\n<p>this code is works.  <\/p>\n<p>let me know how to change model's parameter.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Linear Regression Large Values",
        "Question_created_time":1591119581903,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31250\/linear-regression-large-values",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>I am trying to make a model that does simple counting (ex when I input 14, it outputs 15 or when I input 273 it outputs 274). OLS linear regression comes out to be the most accurate model, and it works really well for numbers with up to 7 digits. However, when I input a number that is more than 7 digits, (ex. 743829543), instead of returning the input +1, it will return a number that has the same first seven digits, but the other digits will be completely off. Is this just a function of the model? What can I do to fix this\/what dataset can I use to train the model to get more accurate outputs?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AzureML cosmosDB integration",
        "Question_created_time":1592481284737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37574\/azureml-cosmosdb-integration",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I would like to know why azureML has no inbuilt integration with cosmosDB.For ML studio cosmosDB is one of the input data sources,why is it not considered in azureML?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Connect 2 separate experiments via webservice - Azure MLS Classic",
        "Question_created_time":1592407262483,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37128\/connect-2-separate-experiments-via-webservice-azur",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>I have 2 experiments A and B in Azure MLS classic. I need the web service output of experiment A as one of the web service inputs for experiment B.  Please let me know if it is possible and if yes, how I can do it.<\/p>",
        "Question_closed_time":1592433417623,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I used export module in experiment A and import module in experiment B to transfer the output of A as input of B.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Convert web service output to a dataset Azure MLS classic",
        "Question_created_time":1592408319737,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37214\/convert-web-service-output-to-a-dataset-azure-mls",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Is it possible to convert a web service output as a dataset or a csv file ? I want to consume this in another experiment.<\/p>",
        "Question_closed_time":1592416585020,
        "Answer_score_count":0.0,
        "Answer_comment_count":2.0,
        "Answer_body":"<p>You can delete or export in-product data stored by Azure Machine Learning Studio (classic) by using the Azure portal, the Studio (classic) interface, PowerShell, and authenticated REST APIs. This article tells you how.    <\/p>\n<p>Telemetry data can be accessed through the Azure Privacy portal.    <\/p>\n<p>More details please refer to: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr<\/a>    <\/p>\n<p>And also you can use one of the Azure Machine Learning Studio Module - &quot;Export Data&quot; to do it : <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN<\/a>    <\/p>\n<p>Let me know if you have more questions.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure ml notebooks sharing and compute selection.",
        "Question_created_time":1591956129183,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35432\/azure-ml-notebooks-sharing-and-compute-selection",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>What kind of collaboration do we need among the data scientists or developers who need to share these notebooks? What kind of compute does these notebooks require? Is it all single node? <\/p>",
        "Question_closed_time":1591962208857,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a>@azureml056-5112<\/a> Please follow the below for managing compute instances. <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance<\/a> All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed.<\/p>\n<p>All notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Azure Machine Learning Web Service returning Internal Server Error",
        "Question_created_time":1592326778243,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/36823\/azure-machine-learning-web-service-returning-inter",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_body":"<p>Getting following error while submitting request to machine learning service. Where can I get more details of this error?  <br \/>\nError Message: An unknown error occurred.  <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning resync keys not working - no longer able to access files\/submit experiments to ML service",
        "Question_created_time":1591893115170,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_body":"<p>I followed this tutorial: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key<\/a> - to update the access keys of my default blob datastore linked to my Machine Learning service. This worked a month ago. After doing it today, every time when submitting an experiment I get the error:    <br \/>\n&quot;Job preparation failed: HTTP Error 403: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature&quot;    <\/p>\n<p>When opening log files for an experiment I get:     <br \/>\n&quot;403: You are not authorized to access this resource.&quot;    <\/p>\n<p>The resync keys operation from the command line works, as I can see in the Machine Learning service Activity log. The Python SDK code also works, as I tried updating the resource group name or default datastore and this gets through.    <\/p>\n<p>Any ideas on how to fix this? I am at a loss.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"View Logistic Regression Model Weights in Machine Learning Studio Enterprise",
        "Question_created_time":1591270358033,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32045\/view-logistic-regression-model-weights-in-machine",
        "Question_score_count":0,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_body":"<p>In ML Studio Classic you can see the logistic regression model weights (intercept and coefficients) when you click on the output from &quot;Train model&quot; module. This feature however is not available in the new ML Studio Enterprise. I only get the Trained_model blob in blob storage. Seeing the weights is a must have when building credit scoring models and this current deficiency is what's keeping us from switching to ML Studio Enterprise.  <\/p>\n<p>Is there a plan to re-introduce this feature from the ML Studio Classic? Alternatively is there a way I can serialize the data.ilearner file and get the model weights from there?  <\/p>\n<p>I know I could use the &quot;Train Python model&quot; module instead, but the &quot;Evaluate Model&quot; module fails with an unspecified error when I use that.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"More convenient service to read avro files from Azure Data Lake Gen2",
        "Question_created_time":1591655876897,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/33682\/more-convenient-service-to-read-avro-files-from-az",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi,  <\/p>\n<p>I have to read lots of avro files created by an Event Hub Capture in a Data Lake Gen2. Data must be filtered, processed and then applied to train a machine learning model. I'm considering Azure Databricks and the Azure Machine Learning service itself for this ETL.  <\/p>\n<p>What is the best option in order to take advantage of the hierarchical namespace of files in the lake? Is it definitely Databricks, due to the Hadoop compatible access to data? What about working with datastores and the python SDK in AML service? Would be the data access efficiency comparable?  <\/p>\n<p>One critical requirement I have is the data filtering step, i.e. reading from the lake just the captured avro files containing specific data (unable to be inferred from the file path though). Does Spark-avro in Databricks give some advantage in this regard? For example with respect to the azure.storage.filedatalake python package, which doesn't offer avro-specific functions.  <\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deployment of Multiple Models to Container Instance Fails in Azure DevOps",
        "Question_created_time":1592223294357,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/36104\/deployment-of-multiple-models-to-container-instanc",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi Team,    <\/p>\n<p>I am trying to deploy 2 ML models ( which is registered in Model Registry ) to Azure Container Instance using DevOps Release pipeline using AZ CLI ML extension    <\/p>\n<p>My ACI Configuration is :    <\/p>\n<p><code>containerResourceRequirements:       cpu: 1       memoryInGB: 4     computeType: ACI <\/code>    <\/p>\n<p>Inference Config :    <\/p>\n<p><code>entryScript: score.py     runtime: python     condaFile: conda_dependencies.yml     extraDockerfileSteps:     schemaFile:     sourceDirectory:     enableGpu: False     baseImage:     baseImageRegistry:<\/code>    <\/p>\n<p>All score.py, conda_dependencies.yml, aciDeploymentConfig.yml is placed in a flattened directory which is publised in to DevOps pipeline artifcat and looks like    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/10000-files.png?platform=QnA\" alt=\"10000-files.png\" \/>    <\/p>\n<p>DevOps Deploy command looks like     <\/p>\n<p><code>az ml model deploy -g $(ml.resourceGroup) -w $(ml.workspace) --name $(service.name.staging) -f .\/model.json -m &quot;GloVe:4&quot; --dc aciDeploymentConfig.yml --ic inferenceConfig.yml --overwrite --debug <\/code>    <\/p>\n<p>Also i have set the working directory as the folder where all above files are placed. something like     <\/p>\n<p>$(System.DefaultWorkingDirectory)\/_Symptom-Code-Indexing\/symptom_model\/a    <\/p>\n<p>Its getting in to an exception as     <\/p>\n<p>2020-06-08T12:50:27.9202657Z     &quot;error&quot;: {    <br \/>\n2020-06-08T12:50:27.9208361Z         &quot;message&quot;: &quot;Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;InvalidOverwriteRequest&quot;,&quot;message&quot;:&quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;823e8483923846b1958c08ffaba074ff&quot;}}'&quot;    <br \/>\n2020-06-08T12:50:27.9212109Z     }    <br \/>\n2020-06-08T12:50:27.9212376Z }}    <br \/>\n2020-06-08T12:50:27.9213437Z {'Azure-cli-ml Version': '1.6.0', 'Error': WebserviceException:    <br \/>\n2020-06-08T12:50:27.9214158Z  Message: Received bad response from Model Management Service:    <br \/>\n2020-06-08T12:50:27.9214688Z Response Code: 400    <br \/>\n2020-06-08T12:50:27.9217800Z Headers: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}    <br \/>\n2020-06-08T12:50:27.9222115Z Content: b'{&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;InvalidOverwriteRequest&quot;,&quot;message&quot;:&quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;823e8483923846b1958c08ffaba074ff&quot;}}'    <br \/>\n2020-06-08T12:50:27.9223705Z  InnerException None    <br \/>\n2020-06-08T12:50:27.9224049Z  ErrorResponse     <br \/>\n2020-06-08T12:50:27.9224320Z {    <br \/>\n2020-06-08T12:50:27.9224617Z     &quot;error&quot;: {    <br \/>\n2020-06-08T12:50:27.9229025Z         &quot;message&quot;: &quot;Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;InvalidOverwriteRequest&quot;,&quot;message&quot;:&quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;823e8483923846b1958c08ffaba074ff&quot;}}'&quot;    <br \/>\n2020-06-08T12:50:27.9230782Z     }    <br \/>\n2020-06-08T12:50:27.9230908Z }}    <br \/>\n2020-06-08T12:50:27.9231134Z Event: Cli.PostExecute [&lt;function AzCliLogging.deinit_cmd_metadata_logging at 0x7fea2ca1f730&gt;]    <br \/>\n2020-06-08T12:50:27.9231431Z az_command_data_logger : exit code: 1    <br \/>\n2020-06-08T12:50:27.9275693Z telemetry.save : Save telemetry record of length 7390 in cache    <br \/>\n2020-06-08T12:50:27.9280735Z telemetry.check : Negative: The \/home\/vsts\/work\/_temp\/.azclitask\/telemetry.txt was modified at 2020-06-08 12:47:41.161160, which in less than 600.000000 s    <br \/>\n2020-06-08T12:50:27.9290480Z command ran in 55.735 seconds.    <br \/>\n2020-06-08T12:50:28.1525434Z ##[error]Script failed with exit code: 1    <br \/>\n2020-06-08T12:50:28.1536650Z [command]\/opt\/hostedtoolcache\/Python\/3.6.10\/x64\/bin\/az account clear    <br \/>\n2020-06-08T12:50:29.9078943Z ##[section]Finishing: Deploy Model to ACI    <\/p>\n<p>But when i tried to Deploy it using Python SDK it works as well. Is there any permission issues or login to be set before using DevOps Release. I have not done any sort of login in my DevOps Build pipeline.    <\/p>\n<p>Any pointers on what is going wrong here ? It would be really helpful.    <\/p>\n<p>Thanks,    <br \/>\nSrijith    <\/p>",
        "Question_closed_time":1592223420340,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>They're actively answering Devops question in dedicated forums here.  <\/p>\n<p><a href=\"https:\/\/developercommunity.visualstudio.com\/spaces\/21\/index.html\">https:\/\/developercommunity.visualstudio.com\/spaces\/21\/index.html<\/a>  <\/p>\n<p>--please don't forget to <strong>Accept as answer<\/strong> if the reply is helpful--  <\/p>\n<hr \/>\n<p>Regards, Dave Patrick ....    <br \/>\nMicrosoft Certified Professional    <br \/>\nMicrosoft MVP [Windows Server] Datacenter Management    <\/p>\n<p>Disclaimer: This posting is provided &quot;AS IS&quot; with no warranties or guarantees, and confers no rights.  <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Access to neural network model",
        "Question_created_time":1591889003457,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/34890\/access-to-neural-network-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>We have built numerous diagnostic models which can be reduced to equations and code that will allow us to repeat the work. We have the code physically available to us, so it can be installed in our own software.  <\/p>\n<p>Now I would like to use artificial neural networks to build a prediction model. After I build that model, will I be able to take that model and transfer it to our own software environment? My concern is that the prediction model will just be a black box. Thanks<\/p>",
        "Question_closed_time":1591950718437,
        "Answer_score_count":0.0,
        "Answer_comment_count":1.0,
        "Answer_body":"<p><a>@OliverBathe-8330<\/a> Please follow the below Deployment scenarios. If possible can you please add more details about the use case.<\/p>\n<p>Option A: Use the DevOps pipeline integration to rollout to production Using same approach as in the <a href=\"https:\/\/github.com\/Microsoft\/MLOpsPython\">MLOps repo<\/a>, set up a <a href=\"https:\/\/github.com\/microsoft\/MLOpsPython\/blob\/master\/docs\/getting_started.md#set-up-build-release-trigger-and-release-multi-stage-pipeline\">release trigger for your DevOps release pipeline<\/a> listening from your dev workspace model registry but then deploy to your production workspace (requires registering again in Prod model registry, call model.deploy() in the Prod workspace<\/p>\n<p>Option B: Use the AML pipeline to rollout to production Following same example as above, add additional PythonScriptStep in your AML pipeline to register and deploy model in the Production workspace<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Jupyter link is not working in Azure ML studio",
        "Question_created_time":1591784712670,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/34363\/jupyter-link-is-not-working-in-azure-ml-studio",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I am trying to create an experiment, For that When I am trying to create Jupypter notebook on running compute Instance, It redirects me to the Login page again and again. So I am not able to proceed further. I think there's a small glitch<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating datasets in Azure Machine Learning service from more than 100 paths",
        "Question_created_time":1591718920387,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/34010\/creating-datasets-in-azure-machine-learning-servic",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,    <\/p>\n<p>I need to create a dataset in Azure Machine Learning service from an Azure Data Lake Gen2 registered as a Datastore. Data in the lake are 1000's of avro files stored by an Event Hub Capture following the pattern [EventHub]\/[Partition]\/[YYYY]\/[MM]\/[DD]\/[HH]\/[mm]\/[ss], so there is one path for each file.    <\/p>\n<p>According to the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#use-the-sdk\">datasets documentation<\/a> it is recommended &quot;... creating dataset referencing less than 100 paths in datastores for optimal performance.&quot;    <\/p>\n<p>What would be the alternative\/recommended approach in my application? Streaming data are continuously captured by the Event Hub.    <\/p>\n<p>Thanks    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"(UserError) Error when parsing request; unable to deserialize request body",
        "Question_created_time":1591616365497,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/33313\/(usererror)-error-when-parsing-request-unable-to-d",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_body":"<p>Hi, getting this error when i run an azureml experiment with custom_docker_image (basegpu image of mcr) - can anybody help me understand this? Have tested this in local compute and it works, not sure why this does not work on a training cluster vm?<\/p>\n<pre><code>   azureml._restclient.exceptions.ServiceException: ServiceException:\n        Code: 400\n        Message: (UserError) Error when parsing request; unable to deserialize request body\n        Details:\n\n        Headers: {\n            &quot;Date&quot;: &quot;Mon, 08 Jun 2020 11:03:52 GMT&quot;,\n            &quot;Content-Type&quot;: &quot;application\/json; charset=utf-8&quot;,\n            &quot;Transfer-Encoding&quot;: &quot;chunked&quot;,\n            &quot;Connection&quot;: &quot;keep-alive&quot;,\n            &quot;Request-Context&quot;: &quot;appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b&quot;,\n            &quot;x-ms-response-type&quot;: &quot;error&quot;,\n            &quot;Strict-Transport-Security&quot;: &quot;max-age=15724800; includeSubDomains; preload&quot;\n        }\n        InnerException: {\n        &quot;additional_properties&quot;: {},\n        &quot;error&quot;: {\n            &quot;additional_properties&quot;: {},\n            &quot;code&quot;: &quot;UserError&quot;,\n            &quot;message&quot;: &quot;Error when parsing request; unable to deserialize request body&quot;,\n            &quot;details_uri&quot;: null,\n            &quot;target&quot;: null,\n            &quot;details&quot;: [],\n            &quot;inner_error&quot;: null,\n            &quot;debug_info&quot;: null,\n            &quot;message_format&quot;: null,\n            &quot;message_parameters&quot;: null,\n            &quot;reference_code&quot;: null\n        },\n        &quot;correlation&quot;: {\n            &quot;operation&quot;: &quot;e96d6285280f5849a4a5e3f172d65d36&quot;,\n            &quot;request&quot;: &quot;1beee8ecb7180147&quot;\n        },\n        &quot;environment&quot;: &quot;westeurope&quot;,\n        &quot;location&quot;: &quot;westeurope&quot;,\n        &quot;time&quot;: {}\n    }\n<\/code><\/pre>",
        "Question_closed_time":1591884305637,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>My bad, after giving it some days and looking at the code, I noticed i had forgotten to add the parameters for the estimator configuration. Here is the estimator configuration that works for me:   <\/p>\n<pre><code>estimator = Estimator(source_directory=experiment_folder,\n                      compute_target=compute_target,\n                      script_params=script_params,\n                      entry_script='rps_efn_b0.py',\n                      node_count=1,        \n                      conda_packages=['ipykernel'],\n                      pip_packages = ['azureml-sdk',\n                                      'pyarrow',\n                                      'pyspark',\n                                      'azureml-mlflow',\n                                      'joblib',\n                                      'matplotlib',\n                                      'Pillow',\n                                      'tensorflow==2.2',\n                                      'tensorflow-datasets',\n                                      'tensorflow-hub',\n                                      'azureml-defaults',\n                                      'azureml-dataprep[fuse,pandas]'],\n                      custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')\n<\/code><\/pre>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"TensorFlow 2.2.0 update for the tensorflow estimator for Azure ML, or disable horovod?",
        "Question_created_time":1591339346177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32334\/tensorflow-2-2-0-update-for-the-tensorflow-estimat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>I would like to use the tensorflow hub to retrain existing models, however tensorflow supports the hub library only on their 2.2 version. And The Estimator azure presents supports tf 2.0.  <\/p>\n<p>When I list tensorflow 2.2 as a required dependency as a pip package, during docker image creation the system fails - it seems like horovod is responsible, - that it cannot find the correct libraries.   <\/p>\n<p>Is this possible to be fixed? as in either an Estimator with tf 2.2 support, or an esitmator without the horovod - as I do not need a distributed system for my solution. <\/p>",
        "Question_closed_time":1591454811350,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Following the pointers from <a>@romungi-MSFT<\/a>, defining estimator with gpubase image; &quot;mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04&quot; solves the problem, and Tensorflow 2.2 can be included. Tensorflow uses GPU by default when available.<\/p>\n<pre><code> estimator = Estimator(source_directory=experiment_folder,\n                       compute_target=compute_target,\n                       script_params=script_params,\n                       entry_script='rps_efn_b0.py',\n                       node_count=1,        \n                       conda_packages=['ipykernel'],\n                       pip_packages = ['azureml-sdk',\n                                       'pyarrow',\n                                       'pyspark',\n                                       'azureml-mlflow',\n                                       'joblib',\n                                       'matplotlib',\n                                       'Pillow',\n                                       'tensorflow==2.2',\n                                       'tensorflow-datasets',\n                                       'tensorflow-hub',\n                                       'azureml-defaults',\n                                       'azureml-dataprep[fuse,pandas]'],\n                       custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')\n<\/code><\/pre>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Cross validation with Azure ML Python SDK",
        "Question_created_time":1591343397597,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32461\/cross-validation-with-azure-ml-python-sdk",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_body":"<p>Does Azure ML Python SDK support cross validation? In the graphical Designer, there is a cross validation module but I haven't found anything similar in the SDK documentation.  <\/p>\n<p>Of course, there probably exist many frameworks for cross-validation in Python but it would be nice to have a native Azure ML module for cross-validation, similar to the Hyperparameter tuning module. I would like to be able to give a single Dataset object and the Azure ML framework would take care of slicing the source Dataset into separate fold datasets. Azure ML should also take care of assigning different folds to the compute nodes and running the folds in parallel.<\/p>",
        "Question_closed_time":1591612380897,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a>@LauriLehman-8626<\/a> It's not supported to use Designer built-in module in python SDK today but we are working on the module SDK private preview which can enable this. We would like understand more about your use-case, can you please send an email to Azcommunity@microsoft.com so that we can invite you to the private preview if you are interested.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"How to use Labeled image datasets to perform an image binary classification in Azure ML Designer",
        "Question_created_time":1591294037683,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I try to train a model for image binary classification in Azure Machine Learning Designer.    <\/p>\n<p>First, I have used the Label Tool, to set a label on each images :    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9143-labeltool.jpg?platform=QnA\" alt=\"9143-labeltool.jpg\" \/>    <\/p>\n<p>Then, I have exported it as an Azure ML DataSet in order to import it in my ML workflow in the designer, as you can see below :    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9087-importdataset.jpg?platform=QnA\" alt=\"9087-importdataset.jpg\" \/>    <\/p>\n<p>Then, in order to apply image transformation and to train my model, I have connected my DataSet to a &quot;convert to image directory&quot; module :    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9144-workflow.jpg?platform=QnA\" alt=\"9144-workflow.jpg\" \/>    <\/p>\n<p>When I execute the workflow I have the following error :     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/9145-error.jpg?platform=QnA\" alt=\"9145-error.jpg\" \/>    <\/p>\n<p>Also, I could not find any documentations about all of these modules in Azure Machine Learning Designer :    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/8990-modules-azureml.jpg?platform=QnA\" alt=\"8990-modules-azureml.jpg\" \/>    <\/p>\n<p>So I am not sure about my understanding of how to proceed.    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Machine Learning\/Performance issue with Writing to CSV file - C#",
        "Question_created_time":1590149443723,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/28770\/machine-learning-performance-issue-with-writing-to",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Hi,  <\/p>\n<p>I developed a Machine Learning (ML.NET) -- .NET Core console application (using Multiple classes prediction template).  I've created the ML Model class and I'm now applying the ML Model to another .NET Core console application to predict the class\/type of stream bed.  This app is residing on my desktop, not Azure.  <\/p>\n<p>The ML app reads each row from the CSV input data and predicts the type of stream bed.  As it makes the prediction row by row, I store each row prediction in a StringBuilder.  When all rows have been read, I call the File.WriteAllText() function.  <\/p>\n<p>The Machine Learning console app is working fine, but now, my issue is how do I improve performance?  When I use CSV input file for my app that consists of over 100K rows, the app runs very slowly  (it writes the result to a CSV file at the rate of 1,000+ rows per hour!).  All my data are over 100K rows each, and I need to process about 50 separate CSV files.  <\/p>\n<p>Is there a better way of doing this?  Should I read\/write each row first, instead of storing all the prediction rows to a StringBuilder before writing to CSV file?  <\/p>\n<p>Or, is there a faster way of writing the results to a CSV file?    <\/p>\n<p>Appreciate any advice.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do we create learning virtual machine AI assistants with smart home control and self-driving vehicle funtionality?",
        "Question_created_time":1591266810177,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31993\/how-do-we-create-learning-virtual-machine-ai-assis",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I am developing Conscious Quantum Coding Living AI Virtual Assistants to help with everything.   <\/p>\n<p>Jodi, The AI Motor Home  <br \/>\nJodi will be an integrative, quantum coded, learning\/self-improving, online\/cloud, virtual machine, life conscious Living AI assistant who fully controls, and self drives, an RV\/Motor home  <\/p>\n<p>How would you create a Living AI assistant for a motor home?<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML Dataset and Snapshot",
        "Question_created_time":1591050286117,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31026\/azure-ml-dataset-and-snapshot",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi experts,    <\/p>\n<p>My customer want to snapshot datasets for reproducibility. I found method &quot;<a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.dataset(class)?view=azure-ml-py#create-snapshot-snapshot-name--compute-target-none--create-data-snapshot-false--target-datastore-none-\">create_snapshot<\/a>&quot;, but found that it is deprecated. Is there any alternative way for dataset snapshot ?    <\/p>\n<p>Thanks,    <br \/>\nKeita    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rest api to create or update azure ML workspace doesn't create dependant resources",
        "Question_created_time":1591181902550,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31569\/rest-api-to-create-or-update-azure-ml-workspace-do",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Problem with <a href=\"https:\/\/learn.microsoft.com\/en-gb\/rest\/api\/azureml\/workspacesandcomputes\/workspaces\/createorupdate\">https:\/\/learn.microsoft.com\/en-gb\/rest\/api\/azureml\/workspacesandcomputes\/workspaces\/createorupdate<\/a> API... In the request body, Is it mandatory to create storage account, app insights, key vault, registration resources before? Ideally since these are dependent resources, shouldn\u2019t it be created as part of workflow creation?    <br \/>\nI get below response when dependent resources are not created prior.    <\/p>\n<pre><code>`{  \n  \u201cerror\u201d: {  \n    \u201ccode\u201d: \u201cValidationError\u201d,  \n    \u201cmessage\u201d: \u201cOne or more validation errors occured.\u201c,  \n    \u201cmessageFormat\u201d: null,  \n    \u201cmessageParameters\u201d: null,  \n    \u201creferenceCode\u201d: null,  \n    \u201cdetailsUri\u201d: null,  \n    \u201ctarget\u201d: \u201cCan not perform requested operation on nested resource. Parent resource \u2018&amp;lt;resourceid&amp;gt;\u2019 not found.\u201c,  \n    \u201cdetails\u201d: [],  \n    \u201cinnerError\u201d: null,  \n    \u201cdebugInfo\u201d: null  \n  },  \n  \u201ccorrelation\u201d: {  \n    \u201coperation\u201d: \u201c&amp;lt;opid&amp;gt;\u201c,  \n    \u201crequest\u201d: \u201c&amp;lt;reqid&amp;gt;\u201d  \n  },  \n  \u201cenvironment\u201d: \u201cwestus\u201d,  \n  \u201clocation\u201d: \u201cwestus\u201d,  \n  \u201ctime\u201d: \u201c2020-06-03T07:13:14.6463577+00:00&amp;#34;  \n}`  \n<\/code><\/pre>\n<p>I need an API which works similar to <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/workspace?view=azure-cli-latest\">https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/workspace?view=azure-cli-latest<\/a>    <\/p>",
        "Question_closed_time":1591266732953,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=3808bcc5-5aa6-41c8-bdfa-ab818e88679f\">@Harshini K S  <\/a>,    <\/p>\n<p>Yes, the REST API needs the other resource ids to be mentioned in the request body or they need to be created prior to this call unlike azure cli which provides the option to create them in a single request with input parameters. You could also try to use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-workspace-template\">ARM<\/a> template to create all the resources by calling this action from PS or cli.    <\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Deploy AzureML Model locally: cannot import name 'convert_inputs'",
        "Question_created_time":1591165699300,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31601\/deploy-azureml-model-locally-cannot-import-name-co",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_body":"<p>I have trained a model using azure AutoML and downloaded the model. Then I created a new conda env using the conda file and tried to execute the scoring_file_v_1_0_0.py which is in the zip. I receive this error:  <\/p>\n<p>&gt; WARNING - Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'convert_inputs'.  <\/p>\n<p>Is this still some dependency problem or am I doing something unexpected? I did expect the script to open a web server to serve the model.<\/p>",
        "Question_closed_time":1591288865200,
        "Answer_score_count":1.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>I am sorry, the problem was something path related that got mixed up within my jupyter notebook setup and a moved directory. So actually the pickle was not where the framework expect it. Can be closed.<\/p>\n",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Azure ML studio designer modules and the Python SDK",
        "Question_created_time":1591108790960,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31305\/azure-ml-studio-designer-modules-and-the-python-sd",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>I have been searching the documentation and cannot find this answer. Is every module in the Azure ML designer available in the Python SDK? I would like to create pipelines via the SDK using transformation and feature engineering methods available in the Designer, but can't find any reference to those modules in the SDK.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Machine Learning Studio (classic) Export Data",
        "Question_created_time":1591053033787,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31081\/azure-machine-learning-studio-(classic)-export-dat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello,  <\/p>\n<p>I am using Azure MLStudio (classic). I am able to connect to SQLServer Managed Instance(private) using Import Data module and On-Prem SQL Database connection through Data Gateway.   <\/p>\n<p>I am not able to Export Data to exactly the same database. Could you please help me with that?  <\/p>\n<p>Our Managed Instance connot be made public.   <\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure AutoML Continuously-Updating Forecast",
        "Question_created_time":1591022875527,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/30971\/azure-automl-continuously-updating-forecast",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hi! I'm new to this, and I'm trying to create a machine learning model to forecast monthly spend based on the spending of previous months. I have been experimenting with AutoML, and I'm wondering:  <\/p>\n<ol>\n<li> How could I pull a data set from a database rather than upload a file?  <\/li>\n<li> Every month, new spending data is added to the database. Is it possible for the ML model to automatically recompute each month, now taking into account the new data?  <br \/>\nThanks  <\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure ML - User impersonation - Compute Instance creation",
        "Question_created_time":1590602219437,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/30031\/azure-ml-user-impersonation-compute-instance-creat",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_body":"<p>Good evening,  <\/p>\n<p>Is there a way to create a compute instance in Azure Machine Learning by impersonating a user?.  <\/p>\n<p>Thank you so much.<\/p>",
        "Question_closed_time":1590772415770,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p><a>@SergioMuoz-4502<\/a> In the current scenario there is no option to create a compute instance with an impersonate user that can be used to run Jupyter or JupyterHub as it can only be used by user who created it.<\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Microsoft Azure ML : How can I add multiple score labels",
        "Question_created_time":1590575222127,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/29846\/microsoft-azure-ml-how-can-i-add-multiple-score-la",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Hello all,  <\/p>\n<p>I created an experiment in Azure ML.:  <br \/>\n** 10 columns used as features;  <br \/>\n** 03 columns required to be predicted via Azure ML experiment =&gt; 3 components prices to predict!   <\/p>\n<p>What I did : My experiment has been divided into 3 modules that deliver each a &quot;score label&quot;  <\/p>\n<p>At the end of the process, how can I merge\/add these 3 score labels into one only column:  <br \/>\n** total price = price component 1 + price component 2 + price component 3.   <br \/>\n** And multiply this total value by another column (from the dataset) so that I get only 1 score label.  <\/p>\n<p>Regards,  <\/p>\n<p>Mohamed.<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Don't show button for teams bot",
        "Question_created_time":1589929289250,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/28063\/dont-show-button-for-teams-bot",
        "Question_score_count":0,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_body":"<p>Hi,    <\/p>\n<p>I am deploy Azure web app bot.    <br \/>\nIf I test bot in Azure web-chat, I can see button, how i add in program:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/8408-%D1%81%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA.png?platform=QnA\" alt=\"8408-%D1%81%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA.png\" \/>    <\/p>\n<p>But when I connect bot to channel in Teams - he doesn't show button.    <br \/>\nI use cookiecutter.    <br \/>\nMay be you can help and tell me what is a problem?    <\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Qna, see what bot is answering the users to improve the bot?",
        "Question_created_time":1589736695060,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/27561\/qna-see-what-bot-is-answering-the-users-to-improve",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>Can I read all the users asked questions and the bot answers, to improve the bot?  <\/p>\n<p>(And if I add a simple &quot;iframe tag&quot; to a website to add the bot, can I change the &quot;didn't find a answer to your question &quot; default bot answer?  )<\/p>",
        "Question_closed_time":null,
        "Answer_score_count":null,
        "Answer_comment_count":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model file is not found for Registration of model in training Pipeline.",
        "Question_created_time":1589329342560,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/26470\/model-file-is-not-found-for-registration-of-model",
        "Question_score_count":1,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>&quot;We want  the model  to automatically register model every time there is a new model. we created the model in the process and write it out to a pipeline data set.To persist it then we upload and read it for registration.    <\/p>\n<p>We are using .\/output to send the file to output. The issue is that it cannot find it in the file path . How can we validate its existence?  &quot;  <\/p>\n<p>[Note: As we migrate from MSDN, this question has been posted by an\u202fAzure Cloud Engineer\u202fas a frequently asked question] Source: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/1369621f-ebc2-4e79-abe9-9f1165aea6c6\/model-file-is-not-found-for-registration-of-model-in-training-pipeline?forum=MachineLearning\">MSDN<\/a>  <\/p>",
        "Question_closed_time":1589360659693,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Can you verify that the script that is actually writing the model file to the location you expect:<\/p>\n<pre><code>with open(model_name, 'wb') as file:\n       joblib.dump(value = model, filename = os.path.join('.\/outputs\/', model_name))\n<\/code><\/pre>\n<p>Inside in your train python script, you just need to do something like this:<\/p>\n<h1 id=\"persist-the-model-to-the-local-machine\">persist the model to the local machine<\/h1>\n<pre><code>tf.saved_model.save(model,'.\/outputs\/model\/')\n<\/code><\/pre>\n<h1 id=\"register-the-model-with-run-object\">register the model with run object<\/h1>\n<pre><code>run.register_model(model_name,'.\/outputs\/model\/')\n<\/code><\/pre>\n<p>Source: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/1369621f-ebc2-4e79-abe9-9f1165aea6c6\/model-file-is-not-found-for-registration-of-model-in-training-pipeline?forum=MachineLearning\">MSDN<\/a><\/p>\n",
        "Question_self_resolution":0.0
    },
    {
        "Question_title":"Save R objects in Azure ML and use them in other experiment?",
        "Question_created_time":1589328890080,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/26562\/save-r-objects-in-azure-ml-and-use-them-in-other-e",
        "Question_score_count":0,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_body":"<p>&quot;Is it possible to save R object in Azure storage (not a trained model) and then use it in a new ML experiment?   <\/p>\n<p>My specific example is:  <br \/>\nRunning PCA with R (&quot;&quot;prcomp&quot;&quot;) and then apply the transformation over new data.   <\/p>\n<p>It can be done within a single R script component with the following code:  <\/p>\n<pre><code>prin_comp &lt;- prcomp(dataset1, scale= TRUE)\ndataset2&lt;-predict(prin_comp, newdata=dataset2)\n<\/code><\/pre>\n<p>But I want to save the new object &quot;&quot;prin_comp&quot;&quot; and call it in a new ML experiment.  <\/p>\n<p>Is it possible?  <\/p>\n<p>(I know there is PCA component in Azure ML but I'm still asking on this approach).&quot;  <\/p>\n<p>[Note: As we migrate from MSDN, this question has been posted by an\u202fAzure Cloud Engineer\u202fas a frequently asked question] Source: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/7d52578e-1ede-4606-ba3d-267f8f254630\/save-r-objects-in-azure-ml-and-use-them-in-other-experiment?forum=MachineLearning\">MSDN<\/a>  <\/p>",
        "Question_closed_time":1589362822827,
        "Answer_score_count":0.0,
        "Answer_comment_count":0.0,
        "Answer_body":"<p>Thanks for reaching out. Currently, you cannot save an R object in one experiment and call it directly in another experiment. You need to export the data into your azure storage and import the data into another experiment using the export\/import data modules. In Azure ML (Preview), you can create\/register datasets to use across experiments.    <\/p>\n<p>Hope this helps. Thanks.    <\/p>\n<p>Source: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/module-reference#data-preparation-modules\">Azure Documentation<\/a>    <\/p>\n",
        "Question_self_resolution":0.0
    }
]