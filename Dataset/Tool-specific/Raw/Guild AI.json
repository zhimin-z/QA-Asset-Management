[
    {
        "Question_title":"About the Troubleshooting category",
        "Question_link":"https:\/\/my.guild.ai\/t\/about-the-troubleshooting-category\/13",
        "Question_created_time":1591308511920,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":390,
        "Question_has_accepted_answer":false,
        "Question_body":"<p><a href=\"\/new-topic?category=troubleshooting\">Get help<\/a> with a problem you\u2019re facing. If you have a general question, use <a href=\"\/c\/general\">General<\/a>.<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Confusion on multistep operations, restarting substeps, and copied files?",
        "Question_link":"https:\/\/my.guild.ai\/t\/confusion-on-multistep-operations-restarting-substeps-and-copied-files\/998",
        "Question_created_time":1676938696104,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have a guild operation <code>main<\/code> that runs 3 steps which are other operations: <code>impute<\/code>, <code>evaluate<\/code>, and <code>predict<\/code>. The latter two require on the <code>impute<\/code> operation (specifically a model checkpoint and some data output).<br>\n(<a href=\"https:\/\/github.com\/davzaman\/autopopulus\/blob\/dev\/guild.yml\" rel=\"noopener nofollow ugc\">guild.yml<\/a> file for reference)<\/p>\n<ol>\n<li>When one of the steps fails (e.g. <code>evaluate<\/code>), the <code>main<\/code> op shows error and so does <code>evaluate<\/code>. If I fix the error in the code and restart the run with something like <code>for hash in $(guild select --operation evaluate --error --all); do guild run -y --background --restart $hash --force-sourcecode; done<\/code>,  then the <code>evaluate<\/code> op fixes to completed, but the <code>main<\/code> operation does not. It doesn\u2019t seem very possible to update it, but it is slightly unclean and annoying to keep track of what broke and what is fixed. I end up with something like:<\/li>\n<\/ol>\n<pre><code class=\"lang-plaintext\">[71:ec03c916]   evaluate  2023-02-20 14:43:57  completed  dvae myexperiment\n[72:957ecb30]   evaluate  2023-02-20 14:43:56  completed  dvae myexperiment\n[73:19493e6b]   evaluate  2023-02-20 14:43:56  completed  dvae myexperiment\n...\n[127:fe72a7ff]  predict   2023-02-18 20:58:56  completed  dvae \n[128:617bc8fd]  impute    2023-02-18 20:26:16  completed  dvae myexperiment\n[129:2b155ff0]  main      2023-02-18 20:26:14  error      dvae \n[130:39125144]  predict   2023-02-18 20:21:08  completed  dvae \n[131:5c4ed46a]  impute    2023-02-18 19:45:25  completed  dvae myexperiment\n[132:c542fcbe]  main      2023-02-18 19:45:24  error      dvae \n<\/code><\/pre>\n<p>It said <code>error<\/code> for <code>main<\/code> but it\u2019s really been fixed sine the <code>evaluate<\/code> op was fixed.<br>\nAnother issue is also what files are stored under each op which leads me to the next point, where ill use <code>run 132<\/code> as an example:<\/p>\n<ol start=\"2\">\n<li>If I look at what is stored under the <code>main<\/code> op I see:<\/li>\n<\/ol>\n<pre><code class=\"lang-shell\">me@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a$ ls\nevaluate  impute  options.yml  predict\n<\/code><\/pre>\n<p>If I drill into the directories I see:<\/p>\n<pre><code class=\"lang-plaintext\">me@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a$ cd evaluate\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a\/evaluate$ ls\nF.O.  options.yml  serialized_models\n<\/code><\/pre>\n<p>If <code>evaluate<\/code> fails and I rerun it, does that mean that the <code>evaluate<\/code>folder will be updated too (is it a symlink)? There seems to be some redundancy too which leads me to:<\/p>\n<ol start=\"3\">\n<li>If I look at the output of the substeps <code>impute<\/code> and <code>predict<\/code> I see:<\/li>\n<\/ol>\n<pre><code class=\"lang-plaintext\"># impute op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/5c4ed46a12e145158b2351621ee81345\/serialized_models$ ls\nAEDitto_STATIC.pt  imputed_data.pkl  STATIC_test_dataloader.pt\n# predict op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/391251446fe041048d93d80deda6ac8a\/serialized_models$ ls\nAEDitto_STATIC.pt  imputed_data.pkl  STATIC_test_dataloader.pt\n<\/code><\/pre>\n<p>I also see<\/p>\n<pre><code class=\"lang-plaintext\"># impute op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/5c4ed46a12e145158b2351621ee81345$ ls F.O.\/0.33\/MNAR\\(G\\)\/dvae\/lightning_logs\/version_0\/\nevents.out.tfevents.1676780435.lambda2.6521.0\nevents.out.tfevents.1676780445.lambda2.6521.1\nevents.out.tfevents.1676780453.lambda2.6521.2\nhparams.yaml\n# predict op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/391251446fe041048d93d80deda6ac8a$ ls F.O.\/0.33\/MNAR\\(G\\)\/dvae\/lightning_logs\/version_0\/\nevents.out.tfevents.1676780435.lambda2.6521.0\nevents.out.tfevents.1676780445.lambda2.6521.1\nevents.out.tfevents.1676780453.lambda2.6521.2\nhparams.yaml\n<\/code><\/pre>\n<p>It looks like it copies over everything from the <code>impute<\/code> op top the parents: <code>main<\/code>, and dependent steps: <code>predict<\/code>, and <code>evaluate<\/code>. This is a lot of redundancy especially for expensive\/large models and artifacts. This is making me run out of space on my machine.<\/p>\n<p>My questions are<br>\na) How do I avoid redundancy in stored artifacts between parent and child steps like <code>main<\/code> having substeps.<br>\nb) How do I avoid redundancy amongst sibling runs where one may be dependent on another? While <code>evaluate<\/code> relies on the artifacts from <code>impute<\/code> I don\u2019t want it to store all the artifacts all over again (including the model checkpoints, data, and the logging files), I just want <code>evaluate<\/code> to use the checkpointed data and model. <a href=\"https:\/\/my.guild.ai\/t\/guild-file-cheatsheet\/192#required-operation-files-14\">I know there\u2019s a <code>select:<\/code> option<\/a> but it seems to be regex, making it complicated to select the checkpointed model AND data. Also even if that solves excluding the logged files, I don\u2019t want to copy over the files it relies on to the final logged artifacts.<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Resolving a nested ini\/cfg file changes its format",
        "Question_link":"https:\/\/my.guild.ai\/t\/resolving-a-nested-ini-cfg-file-changes-its-format\/995",
        "Question_created_time":1676295820136,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":18,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>First, thanks for the awesome tool!<\/p>\n<p>I am having some trouble with the following behaviour. I use <code>.ini<\/code> config files with nested sections, and import the flags from there, but when Guild resolves the files and write a copy to the run dir, the format changes and the nesting is lost. I would need it to keep the same formatting.<\/p>\n<p>I have a config file with nested sections, like:<\/p>\n<pre data-code-wrap=\"config\"><code class=\"lang-plaintext\">[ingredients]\ngreens = cabbage\n\n[ingredients.meat]\ntype = pork belly\nmarbled = true\n\n[ingredients.carbs]\ntype = noodles\n\n[ingredients.carbs.make]\n\n[ingredients.carbs.make.water]\nadd_miso = true\ncontainer = cooking pot\ntemp = 100\n<\/code><\/pre>\n<p>And a guild file:<\/p>\n<pre data-code-wrap=\"guild\"><code class=\"lang-plaintext\">cook:\n  exec: cat source_config.cfg\n  flags-import: all\n  flags-dest: config:source_config.cfg\n<\/code><\/pre>\n<p>Running this operation gives prints out the resulting config file in the run dir:<\/p>\n<pre><code class=\"lang-plaintext\">[ingredients]\ncarbs = {'make': {'water': {'add_miso': True, 'container': 'cooking pot', 'temp': 100}}, 'type': 'noodles'}\ngreens = paksoi\nmeat = {'marbled': True, 'type': 'pork belly'}\n<\/code><\/pre>\n<p>I can understand what happened, but for my purposes, this is a destructive change: I can\u2019t read this config file inside the run.<\/p>\n<p>Practically speaking, I use guild to run machine learning experiments backed by Spacy. I read in the created config file with <code>confection<\/code> (Spacy\u2019s config handler), which doesn\u2019t support reading those dicts. The upshot is that I can\u2019t use guild to run sweeps. Would love to see a solution to this.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2023-02-13T15:11:22.526Z",
                "Answer_body":"<p>For your consideration, here is a snippet sketching a function with approximately the behavior I\u2019m looking for. Modified from <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/main\/guild\/util.py#L1391\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">guildai\/util.py at main \u00b7 guildai\/guildai \u00b7 GitHub<\/a><\/p>\n<pre><code class=\"lang-python\">def encode_cfg(data):\n    import io\n    import configparser\n\n    cfg = configparser.ConfigParser()\n\n    def encode_section(trace: list[str], d: dict):\n        section_key = \".\".join(trace) if trace else configparser.DEFAULTSECT\n        if trace:\n            cfg.add_section(section_key)\n\n        # First treat the non-dict options in `d`.\n        # Collect the dict options as we go.\n        dict_options = []\n        for k, v in sorted(d.items()):\n            if isinstance(v, dict):\n                dict_options.append((k, v))\n            else:\n                cfg.set(section_key, k, str(v))\n\n        # Then go recursively into the dict options.\n        for k, v in dict_options:\n            local_trace = trace + [k]\n            encode_section(local_trace, v)\n\n    encode_section([], data)\n\n    io = io.StringIO()\n    cfg.write(io)\n    return io.getvalue()\n\n\ntest_data = {\n    \"type\": \"recipe\",\n    \"ingredients\": {\n        \"carbs\": {\n            \"make\": {\n                \"water\": {\n                    \"add_miso\": True,\n                    \"container\": \"cooking pot\",\n                    \"temp\": 100,\n                }\n            },\n            \"type\": \"noodles\",\n        },\n        \"greens\": \"cabbage\",\n        \"meat\": {\"marbled\": True, \"type\": \"pork belly\"},\n    },\n}\n\nprint(encode_cfg(test_data))\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code class=\"lang-plaintext\">[DEFAULT]\ntype = recipe\n\n[ingredients]\ngreens = cabbage\n\n[ingredients.carbs]\ntype = noodles\n\n[ingredients.carbs.make]\n\n[ingredients.carbs.make.water]\nadd_miso = True\ncontainer = cooking pot\ntemp = 100\n\n[ingredients.meat]\nmarbled = True\ntype = pork belly\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2023-02-20T20:34:06.281Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/camiel\">@Camiel<\/a> welcome and thank you for the report!<\/p>\n<p>Yeah, I can see how this behavior is annoying - the radical change in format it is a bit surprising but I\u2019m guessing this is the behavior in the Python INI support (perhaps later versions).<\/p>\n<p>I\u2019ll create a project that replicates and see what we can do to address it. Stay tuned!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Using flags-dest in pipelines",
        "Question_link":"https:\/\/my.guild.ai\/t\/using-flags-dest-in-pipelines\/971",
        "Question_created_time":1672820729030,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":26,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I can\u2019t seem to find a use case which describe using <code>flags-dest<\/code> in a pipeline of steps that all specifies flags using <code>flags-dest<\/code> and <code>flags-import<\/code>.<\/p>\n<p>It seems I must explicitly specify the flags that needs to be passed to individual steps in a pipeline, which is quite trivial. I wonder if there\u2019s a way I can automatically pass the flags to all the steps in the pipeline? E.g. something like this<\/p>\n<pre><code class=\"lang-yaml\">ops1:\n  flags-dest: config:config.yaml\n  flags-import: all\n  ...\n\nops2:\n  flags-dest: config:config.yaml\n  flags-import: all\n  ...\n\npipeline:\n  flags-dest: config:config.yaml\n  flags-import: all\n  steps:\n    - run: ops2\n      $include:all-flags\n    - run: ops2\n      $include:all-flags\n\n# This works less convinient obviously if I have many flags\npipeline_current:\n  flags-dest: config:config.yaml\n  flags-import: all\n  steps:\n    - ops1 flag1=${flag1} flag2=${flag2}\n    - ops2 flag1=${flag1} flag2=${flag2}\n\n<\/code><\/pre>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"__main__ has no attribute __spec__ pytorch-lightning multiGPU",
        "Question_link":"https:\/\/my.guild.ai\/t\/main-has-no-attribute-spec-pytorch-lightning-multigpu\/946",
        "Question_created_time":1666401932704,
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":138,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>When using guild to run experiments on multiple GPUs with pytorch-lightning I get the following error:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/main.py\", line 219, in &lt;module&gt;\n10\/21\/2022 5:54:52 PM\tmain()\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/main.py\", line 95, in main\n10\/21\/2022 5:54:52 PM\timputed_data = get_imputation_logic(args)(args, data)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/task_logic\/ae_imputation.py\", line 119, in ae_imputation_logic\n10\/21\/2022 5:54:52 PM\tae_imputer = create_autoencoder(args, data, settings)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/task_logic\/tuner.py\", line 69, in create_autoencoder\n10\/21\/2022 5:54:52 PM\tae_imputer.fit(data)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/models\/ap.py\", line 148, in fit\n10\/21\/2022 5:54:52 PM\tself._fit(data)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/.guild\/runs\/4d62c69c236641b8b2d384bed79b64de\/.guild\/sourcecode\/autopopulus\/models\/ap.py\", line 166, in _fit\n10\/21\/2022 5:54:52 PM\tself.trainer.fit(self.ae, datamodule=data)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 770, in fit\n10\/21\/2022 5:54:52 PM\tself._call_and_handle_interrupt(\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 721, in _call_and_handle_interrupt\n10\/21\/2022 5:54:52 PM\treturn self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/launchers\/subprocess_script.py\", line 92, in launch\n10\/21\/2022 5:54:52 PM\tself._call_children_scripts()\n10\/21\/2022 5:54:52 PM\tFile \"\/home\/davina\/mambaforge\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/launchers\/subprocess_script.py\", line 109, in _call_children_scripts\n10\/21\/2022 5:54:52 PM\tif __main__.__spec__ is None: # pragma: no-cover\n10\/21\/2022 5:54:52 PM\tAttributeError: 'dict' object has no attribute '__spec__'\n<\/code><\/pre>\n<p>So I went into the file <code>\/home\/davina\/mambaforge\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/launchers\/subprocess_script.py\", line 109, in _call_children_scripts<\/code> and changed <code>if __main__.__spec__ is None<\/code> to <code>if True<\/code> as a stopgap, and it seemed to work. For some reason <code>__main__<\/code> is a dictionary.<\/p>\n<p>This isn\u2019t the exact same problem, but I happened to find a somewhat relevant problem <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/3859\" rel=\"noopener nofollow ugc\">here<\/a>.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-22T14:43:36.869Z",
                "Answer_body":"<p>Grab the latest version of Guild, 0.8.2. This should be fixed in that version. There was a regression in 0.8.1.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-26T01:26:13.177Z",
                "Answer_body":"<p>I am having problems with 0.8.2. Refreshing flags actually runs the program, and additionally, <code>guild.plugins.import_argparse_flags_main<\/code> actually takes up a lot of the %CPU. It also does not properly parse the flags. I downgraded back to 0.8.1 and the problem went away.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-11-02T15:26:00.195Z",
                "Answer_body":"<p>Shoot - sorry about that! Do you have a short example or some config that reproduces this?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-11-18T17:50:16.249Z",
                "Answer_body":"<p>Apologies for the late reply. Caught a nasty cold. I tried to create a MWE to trigger this problem but I got swamped with other work and wasn\u2019t able to get one working for you. I will try working on this over the next few days and get back to you.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-12-14T20:40:44.357Z",
                "Answer_body":"<p>I believe this specific problem has gone away, I am having different issues that I\u2019ve messaged you about! If we come to a conclusion I\u2019ll share it here for posterity.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Use parameters with include flags",
        "Question_link":"https:\/\/my.guild.ai\/t\/use-parameters-with-include-flags\/952",
        "Question_created_time":1667442665957,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":64,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m trying to use parameters to set portions of flags, but it seems that the parameters don\u2019t affect flags which have been imported. Here\u2019s a simple case:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">- config: config\n  flags:\n    flag-key: \"{{param-key}}\"\n\n- model: model\n  params:\n    param-key: param-value\n  operations:\n    op:\n      main: path\n      flags:\n        $include: config\n<\/code><\/pre>\n<p>This results in flag:<br>\nflag-key: \u2018{{param-key}}\u2019<br>\nwhereas I\u2019d want it to be  the same result as if I declared the flag directly in the operation config:<br>\nflag-key: param-value<\/p>\n<p>In my specific use-case I\u2019m also getting the parameters from a config which this model extends, in case that affects the issue. Essentially the setup is that we have all parameters in a single config for organization, and there\u2019s many models\/operations which each use one of a few different sets of flags, and all flag sets reference the parameters.  Any recommendations or workarounds would be appreciated, thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-11-10T21:41:25.875Z",
                "Answer_body":"<p>Found a workaround of using yaml anchors instead of $include.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Strange out-of-memory behavior on Guild with XGBoost",
        "Question_link":"https:\/\/my.guild.ai\/t\/strange-out-of-memory-behavior-on-guild-with-xgboost\/931",
        "Question_created_time":1665986502533,
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":143,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi all, I\u2019m using Guild to manage and tune XGBoost models for a binary classification problem. My dataset is around 2MB and has around 20K rows of 15 features. My XGBClassifier has around 100 estimators, the max depth is 6, and the tree method is <code>gpu-hist<\/code>.<\/p>\n<p>When I run my program in VS Code it executes with no problems. When I run the same program in the command line with Guild, it also finishes without throwing any error. But when I look at the run in <code>guild view<\/code> or <code>guild runs<\/code>, it says that the run exited with an error status <code>3221226505<\/code>.<\/p>\n<p>Online sources say this generic python error is some form of out of memory error. However, this can\u2019t be the case as I monitored the RAM and VRAM usage while executing my program and they were both very low.<\/p>\n<p>When I switch the tree method to just <code>hist<\/code> (cpu-only training) and re-run the program, <code>guild view<\/code> now shows the run as <code>completed<\/code>.<\/p>\n<p>May I know if this is a bug? My GPU is a Quadro T1000, my XGBoost version is <code>1.6.2<\/code>, and here is part of the <code>guild check<\/code> output:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild_version:             0.8.1\npython_version:            3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]                            \nplatform:                  Windows 10 AMD64                                                                               \npsutil_version:            5.9.2\ntensorboard_version:       2.10.1\ncuda_version:              11.7\nnvidia_smi_version:        516.69\nlatest_guild_version:      0.8.1   \n<\/code><\/pre>\n<p>Thank you!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-17T17:23:57.599Z",
                "Answer_body":"<p>These resource-related issues can be tough to track down.<\/p>\n<p>Do you see this exit code consistently (i.e. every time) when you run with Guild? These OOM issues are sometimes intermittent.<\/p>\n<p>A solid way to test for this is to reboot your system (sorry, I know that\u2019s a common trope!) and then to immediately run the offending command in Guild. This would provide an environment that might have more available memory.<\/p>\n<p>If Guild consistently triggers this, you can disable some potential causes using a few environment variables:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">set GUILD_PLUGINS= \nset LOG_INIT_SKIP=1 \nset NO_RUN_OUTPUT=1\nguild run ...\n<\/code><\/pre>\n<p>With this , Guild is just passing through the command to Python and will not do any additional work. If there\u2019s a memory related issue with Guild, that should fix it. If that works, please let me know and we can further track the issue down.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-18T08:52:28.675Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, thanks for the suggestions!<\/p>\n<p>Yes, every time I use the <code>gpu_hist<\/code> tree method and run my experiment with Guild, the issue persists. (i.e. the exit code doesn\u2019t appear on the console output, but appears in <code>guild view<\/code> and <code>guild runs<\/code>. If I run the experiment with a hyperparameter optimizer, the error does get logged to the console though) Rebooting and running the command straightaway\/Setting the environment variables also didn\u2019t work.<\/p>\n<p>I put a print statement at the end of my program and ran it in VSCode as well as Guild. In VSCode, the program exits almost immediately after the print. In Guild, there is a significant delay of around 4 seconds after the print before the program exits.<\/p>\n<p>Perhaps the issue is in Guild\u2019s cleanup? Or is there an environment variable I can set to disable that too?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-18T15:54:16.320Z",
                "Answer_body":"<p>You may be running into the same behavior when you run from the command line or from the VS Code terminal. Exit codes aren\u2019t printed anywhere so you could be getting a resource-related exit without knowing it, regardless of whether Guild is used.<\/p>\n<p>If you running from the Windows prompt (I recommend this, as opposed to a VS Code terminal, at least for this test), run this after running your code with Python directly (don\u2019t use Guild):<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">echo %errorlevel%\n<\/code><\/pre>\n<p>If you get a non-zero exit code here, it\u2019s your code \u2014 something\u2019s eating up something when you use gpu-hist.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-19T00:21:14.325Z",
                "Answer_body":"<p>I just tried this. <code>echo %errorlevel%<\/code> returns <code>0<\/code> after I run the Python file directly in the command line.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-19T15:22:11.352Z",
                "Answer_body":"<p>How are you running the operation with Guild? Are you running a Python script directly or are you using a Guild file with a <code>main<\/code> spec for the operation?<\/p>\n<p>You can remove Guild\u2019s Python support from the mix by running your operation this way:<\/p>\n<pre><code class=\"lang-yaml\">test:\n  exec: python .guild\/sourcecode\/test.py\n  output-scalars: off\n  plugins: off\n<\/code><\/pre>\n<p>This is as close to a pass-through to your code as possible.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-26T01:54:31.063Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, sorry for the late response!!<\/p>\n<p>I am using a Guild file in the operation-only format. My XGBoost operation looks like this (I only included 2 of my flags, I have a total of 12)<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">XGBClassifier:\n  description: Train XGBClassifier on dataset\n  main: XGBClassifier\n  flags:\n    N_ESTIMATORS:\n      type: int\n    MAX_DEPTH:\n      type: int\n  output-scalars:\n    AVG_ACC: 'AVG_ACC: (\\value)'\n    AVG_SENS: 'AVG_SENS: (\\value)'\n    AVG_SPEC: 'AVG_SPEC: (\\value)'\n<\/code><\/pre>\n<p>Then I run the experiment with<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild run XGBClassifier\n<\/code><\/pre>\n<p>After trying your suggestion, the run now shows up as \u2018completed\u2019 in <code>guild runs<\/code> . When I restore the <code>output-scalars<\/code> and remove <code>plugins: off<\/code>, there is also no issue. So the problem likely stems from <code>main: XGBClassifier<\/code> and the large number of flags.<\/p>\n<p>However, I also noticed that the console started to output my print statements in a very jerky manner once I implemented your suggestion. The text would print, but it would intermittently appear as a lot of lines at one shot, instead of coming out line by line.<\/p>\n<p>Thank you!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-11-10T05:13:26.342Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a> , sorry for the trouble, may I know if there\u2019s any update on this? Thank you very much!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pytorch Lightning, Distributed Data Parallel & remote",
        "Question_link":"https:\/\/my.guild.ai\/t\/pytorch-lightning-distributed-data-parallel-remote\/953",
        "Question_created_time":1667510518376,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":221,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nI\u2019ve setup my model with Pytorch Lightning, and want to train it on a remote workstation (single machine, multiple GPUs) using multiple GPUs. The recommended strategy to use is DDP.<\/p>\n<p>I\u2019ve successfully run the model locally on 1 GPU, remotely on 1 GPU using DDP and DP strategies, and on multiple GPUs using DP strategy.<\/p>\n<p>However, when running DDP strategy with multiple GPUs on the remote, the processs hangs indefinitely on the first GPU initialization. The only indication in the Guild output that something is not correct is this:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">Installing package and its dependencies\nProcessing .\/gpkg.my_package-0.1-py2.py3-none-any.whl\nInstalling collected packages: gpkg.my_package\nSuccessfully installed gpkg.my_package-0.1\nStarting my_model:train on my_remote as 65f7f7f516f54c78900bcd313a6f906c\n[some file resolves]\n[some PLT info]\n \n**guild.op_main: missing required arg**\n\nINFO: [pytorch_lightning.utilities.distributed] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1\/2\n<\/code><\/pre>\n<p>The process never progresses from this stage. Running <code>nvidia-smi<\/code> shows no processes on any GPUs, and running <code>htop<\/code> shows no processes on the CPU.<\/p>\n<p>Below the training part of the script:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\"># Define the Pytorch Lightning trainer\ntrainer = pl.Trainer(\n        # auto_scale_batch_size='binsearch',\n        auto_lr_find=config.auto_lr,\n        fast_dev_run=config.fast_dev_run,\n        max_epochs=config.epochs,\n        accelerator=\"gpu\",\n        strategy='ddp',\n        devices=config.gpus,\n        precision=16,\n        callbacks=[\n            # pl.callbacks.StochasticWeightAveraging(swa_lrs=1e-2),\n            pl.callbacks.EarlyStopping(monitor='val_auc', mode='max'),\n            pl.callbacks.LearningRateMonitor()\n        ]\n)\n\n# Tune the training parameters\ntrainer.tune(model)\n# Train\ntrainer.fit(model=model)\n# Test\ntrainer.test(model=model)\n<\/code><\/pre>\n<p>And the guild.yml file:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">- package: gpkg.my_package\n  description: My package\n  version: 0.1\n  data-files:\n    - '..\/datasets\/'\n    - 'my_model\/models\/model_definition.py'\n    - 'my_model\/train.py'\n    - 'my_model\/models\/loss.py'\n    - 'my_model\/models\/memory.py'\n    - 'my_model\/config.yaml'\n    - '.\/training_utils.py'\n    - '.\/model_utils.py'\n\n- model: my_model\n  description: \n  operations:\n    train:\n      description: Train my model\n      label: \"my_model:train - dataset: ${dataset_name}\"\n      sourcecode:\n        - my_model\/train.py\n        - my_model\/models\/model_definition.py\n        - my_model\/models\/loss.py\n        - my_model\/models\/memory.py\n        - training_utils.py\n        - model_utils.py\n      requires:\n        - config: my_model\/config.yaml\n        - file: ..\/datasets\/\n      main: my_model\/train\n      flags-dest: config:my_model\/config.yaml\n      flags-import: all\n      flags:\n        # Training parameters\n        auto_lr: True\n        epochs: 2\n        fast_dev_run: 100\n        gpus: (0,)\n        av: False\n        # Dataset parameters\n        dataset_name: my_dataset\n        batch_size: 2\n        num_workers: 6\n        model_input_size: (256,256)\n        data_path: '..\/..\/..\/data\/use_case\/my_dataset'\n        fraction: 1.0\n        crop_params: False\n        win_len: 16\n        # Model parameters\n        channels: 3\n        mem_dim: 2000\n        thresh: 0.0025\n        loss_weight: 0.0002\n        lr: 10e-5\n        wd: 10e-4\n<\/code><\/pre>\n<p>Perhaps there is a mistake in the package part? It\u2019s not entirely clear to me if that\u2019s the correct way to do this, and perhaps I\u2019m doing something redundant and\/or incorrect that prevents Guild from properly initializing my scripts?<\/p>\n<p>Thanks!<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Dependencies problem",
        "Question_link":"https:\/\/my.guild.ai\/t\/dependencies-problem\/943",
        "Question_created_time":1666248030613,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":87,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hello! Pretty new to guild.ai and trying to use it on my recent project. I tried to run my code with guild.ai wrapper, but it does not run due to a dependencies issue (\u201cbpe_simple_vocab_16e6.txt.gz\u201d is missing from the running folder, despite every other file in the same folder with it being included). I tried to solve it by including requires in my guild.yml:<\/p>\n<p>requires:<\/p>\n<ul>\n<li>file: pkgs\/openai\/bpe_simple_vocab_16e6.txt.gz<\/li>\n<\/ul>\n<p>but despite the relative path is correct, the error pops up saying<\/p>\n<p>ERROR: resolving required source \u2018file:pkgs\/openai\/bpe_simple_vocab_16e6.txt.gz\u2019 in file:pkgs\/openai\/bpe_simple_vocab_16e6.txt.gz resource<br>\nTraceback (most recent call last):<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/op_dep.py\u201d, line 236, in resolve_source<br>\nsource_paths = _resolve_source_for_location(<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/op_dep.py\u201d, line 267, in _resolve_source_for_location<br>\nreturn resolver.resolve(resolve_context)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 114, in resolve<br>\nresolved = self._resolve_source_files(source_path, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 138, in _resolve_source_files<br>\nreturn resolve_source_files(source_path, self.source, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 553, in resolve_source_files<br>\nreturn _resolve_source_file_or_archive_files(source_path, source, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 618, in _resolve_source_file_or_archive_files<br>\nreturn _resolve_archive_files(source_path, archive_type, source, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 674, in _resolve_archive_files<br>\nunpacked = _ensure_unpacked(source_path, archive_type, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 686, in _ensure_unpacked<br>\nunpacked = _unpack(source_path, archive_type, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 711, in _unpack<br>\nreturn _gunzip(source_path, unpack_dir)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 749, in _gunzip<br>\nreturn _gen_unpack(<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 806, in _gen_unpack<br>\nextract(unpack_dir, to_extract)<br>\nFile \u201c\/home\/hyang\/.local\/lib\/python3.9\/site-packages\/guild\/resolver.py\u201d, line 781, in extract<br>\nwith open(dest, \u201cwb\u201d) as f_out:<br>\nFileNotFoundError: [Errno 2] No such file or directory: \u2018\/home\/hyang\/deadclip\/CyCLIP\/env\/.guild\/cache\/resources\/6d8d1935c2ed1916a4210b8f6391e63d846c5f02d88deced8f8fa21b\/bpe_simple_vocab_16e6.txt\u2019<br>\nguild: run failed because a dependency was not met: unexpected error resolving \u2018file:pkgs\/openai\/bpe_simple_vocab_16e6.txt.gz\u2019 in file:pkgs\/openai\/bpe_simple_vocab_16e6.txt.gz resource: FileNotFoundError(2, \u2018No such file or directory\u2019)<\/p>\n<p>I also tried to toy with the relative path with \u201c\u2026\u201d or use the absolute path, but it still didn\u2019t work<\/p>\n<p>Any help would be appreciated :))<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-21T17:28:45.618Z",
                "Answer_body":"<p>Could you plot the directory tree? Specifically, where\u2019s the sourcecode, the guild file and the resources file are?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-28T20:07:48.476Z",
                "Answer_body":"<p>|-CyCLIP<br>\n-----|-guild.yml<br>\n-----|-pkgs<br>\n----------|-openai<br>\n-----------------|-bpe_simple_vocab_16e6.txt.gz<br>\n-----|-src<br>\n----------|-main.py<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Torch.multiprocessing.spawn fails",
        "Question_link":"https:\/\/my.guild.ai\/t\/torch-multiprocessing-spawn-fails\/929",
        "Question_created_time":1665950939224,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":159,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have some code that works standalone, but fails when run from guild.  The offending line is:<\/p>\n<pre><code>torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, args))\n<\/code><\/pre>\n<p>and the complaint is:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">  [...] \n  File \"\/usr\/lib\/python3.10\/multiprocessing\/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n  File \"\/usr\/lib\/python3.10\/multiprocessing\/context.py\", line 288, in _Popen\n    return Popen(process_obj)\n  File \"\/usr\/lib\/python3.10\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\n    super().__init__(process_obj)\n  File \"\/usr\/lib\/python3.10\/multiprocessing\/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n  File \"\/usr\/lib\/python3.10\/multiprocessing\/popen_spawn_posix.py\", line 42, in _launch\n    prep_data = spawn.get_preparation_data(process_obj._name)\n  File \"\/usr\/lib\/python3.10\/multiprocessing\/spawn.py\", line 183, in get_preparation_data\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\nAttributeError: 'dict' object has no attribute '__spec__'\n<\/code><\/pre>\n<p>Does anyone have any tips?  I\u2019m not sure I really understand what\u2019s failing in the spawn call\u2026  Thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-17T17:38:14.680Z",
                "Answer_body":"<p>I\u2019m sorry you\u2019re running into this! I created an <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-929-torch-multiprocessing-spawn-fails\">issue resolution doc<\/a> that easily reproduces this. I\u2019ll spend some time looking into it.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-17T17:58:48.903Z",
                "Answer_body":"<p>Still investigating but there is a work-around - if you your script using Python using Guild\u2019s <code>exec<\/code> spec this way:<\/p>\n<aside class=\"onebox githubblob\" data-onebox-src=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/93de41a7741148e838e8c65e9b74b6854d11ad49\/my.guild.ai-929-torch-multiprocessing-spawn-fails\/guild.yml#L1-L2\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/93de41a7741148e838e8c65e9b74b6854d11ad49\/my.guild.ai-929-torch-multiprocessing-spawn-fails\/guild.yml#L1-L2\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/93de41a7741148e838e8c65e9b74b6854d11ad49\/my.guild.ai-929-torch-multiprocessing-spawn-fails\/guild.yml#L1-L2\" target=\"_blank\" rel=\"noopener\">guildai\/issue-resolution\/blob\/93de41a7741148e838e8c65e9b74b6854d11ad49\/my.guild.ai-929-torch-multiprocessing-spawn-fails\/guild.yml#L1-L2<\/a><\/h4>\n\n\n\n    <pre class=\"onebox\"><code class=\"lang-yml\">\n      <ol class=\"start lines\" start=\"1\" style=\"counter-reset: li-counter 0 ;\">\n          <li>test-exec:<\/li>\n          <li>  exec: python .guild\/sourcecode\/test.py<\/li>\n      <\/ol>\n    <\/code><\/pre>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Note that this form doesn\u2019t support Python global variable based flags - you\u2019d need to either pass command line arguments along or use config files.<\/p>\n<p>Still looking into the underlying issue but I wanted to get you a workaround sooner than later.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild error - Not a git repository",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-error-not-a-git-repository\/927",
        "Question_created_time":1665192152022,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":69,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>fatal: not a git repository (or any of the parent directories): .git<br>\nTraceback (most recent call last):<br>\nFile \u201c\/home\/sjoshi\/anaconda3\/envs\/clip\/.guild\/runs\/894a22b5465840858109bc4504a0295c\/.guild\/sourcecode\/simclr.py\u201d, line 46, in <br>\nargs.git_hash = subprocess.check_output([\u2018git\u2019, \u2018rev-parse\u2019, \u2018HEAD\u2019])<br>\nFile \u201c\/home\/sjoshi\/anaconda3\/envs\/clip\/lib\/python3.10\/subprocess.py\u201d, line 420, in check_output<br>\nreturn run(*popenargs, stdout=PIPE, timeout=timeout, check=True,<br>\nFile \u201c\/home\/sjoshi\/anaconda3\/envs\/clip\/lib\/python3.10\/subprocess.py\u201d, line 524, in run<br>\nraise CalledProcessError(retcode, process.args,<br>\nsubprocess.CalledProcessError: Command \u2018[\u2018git\u2019, \u2018rev-parse\u2019, \u2018HEAD\u2019]\u2019 returned non-zero exit status 128.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-08T14:46:42.106Z",
                "Answer_body":"<p>Your code is running inside another directory, not your project directory. The new directory is not a git repo, which is why you\u2019re seeing this error.<\/p>\n<p>I created a doc that describes what\u2019s going on and gives you some working code to use if you need it:<\/p>\n<aside class=\"onebox githubfolder\" data-onebox-src=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-927-guild-error-not-a-git-repository\">\n  <header class=\"source\">\n      <img src=\"https:\/\/github.githubassets.com\/favicons\/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-927-guild-error-not-a-git-repository\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <h3><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-927-guild-error-not-a-git-repository\" target=\"_blank\" rel=\"noopener\">issue-resolution\/my.guild.ai-927-guild-error-not-a-git-repository at master \u00b7...<\/a><\/h3>\n\n  <p><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-927-guild-error-not-a-git-repository\" target=\"_blank\" rel=\"noopener\">master\/my.guild.ai-927-guild-error-not-a-git-repository<\/a><\/p>\n\n  <p><span class=\"label1\">Scratch repo for recreating and resolving Guild AI issues - issue-resolution\/my.guild.ai-927-guild-error-not-a-git-repository at master \u00b7 guildai\/issue-resolution<\/span><\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>The approach here is to include your git repo as a dependency for the build. The example provides examples of copying the repo (expensive but safe - there\u2019s no chance of getting different results depending on when the code is run) and linking (efficient but sensitive to when you run the code).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-08T20:36:55.189Z",
                "Answer_body":"<p>Thanks for the prompt response!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Opening source file causes File not found exception",
        "Question_link":"https:\/\/my.guild.ai\/t\/opening-source-file-causes-file-not-found-exception\/903",
        "Question_created_time":1659175674039,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":77,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi, I just started using guild and I\u2019m trying to integrate it with an existing project.<br>\nI have the following directory structure:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">project\/\n\u251c\u2500 configs\/\n\u2502  \u251c\u2500 __init__.py\n\u2502  \u251c\u2500 cfg1.py\n\u2502  \u251c\u2500 cfg2.py\n\u251c\u2500 utils\/\n\u2502  \u251c\u2500 base_config.py\n<\/code><\/pre>\n<p>Where the config files contain something similar to<\/p>\n<pre><code class=\"lang-python\">from utils.base_config import BaseConfig\n\nclass Config(BaseConfig):\n    class Model:\n        architecture: MLP\n        class Parameters:\n             pass\n\nif __name__ == \"__main__\":\n    Config.init()\n    train.main()\n<\/code><\/pre>\n<p>and <code>BaseConfig.py<\/code> among other things does this<\/p>\n<pre><code class=\"lang-python\">import __main__\n\nclass BaseConfig:\n    @classmethod\n    def init(cls):\n        with Path('configs\/__init__.py').open('w+') as f:\n            f.writelines([f'from .{Path(str(__main__)).stem } import Config'])\n            f.flush()\n<\/code><\/pre>\n<p>Now, when I run <code>guild run configs\/cfg1.py<\/code> I get the following error:<\/p>\n<pre><code class=\"lang-python\">Traceback (most recent call last):\n  File \"C:\\Users\\username\\PycharmProjects\\project\\configs\\cfg1.py\", line 56, in &lt;module&gt;\n    Config.init()\n  File \"C:\\Users\\username\\PycharmProjects\\project\\utils\\base_config.py\", line 13, in init\n    with Path('configs\/__init__.py').open('w+') as f:\n  File \"C:\\Users\\username\\.conda\\envs\\project_env\\lib\\pathlib.py\", line 1252, in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n  File \"C:\\Users\\username\\.conda\\envs\\project_env\\lib\\pathlib.py\", line 1120, in _opener\n    return self._accessor.open(self, flags, mode)\nFileNotFoundError: [Errno 2] No such file or directory: 'configs\\\\__init__.py'\n<\/code><\/pre>\n<p>Then, when I look into the <code>sourcecode<\/code> directory of the run I see that only <code>__init__.py<\/code>, <code>cfg1.py<\/code> and <code>cfg2.py<\/code>are present and the directory structure is not preserved (i.e. the three files are not under <code>configs<\/code>).  Any idea on how to solve this?<\/p>\n<p>Also, I was wondering how I could log the configuration file. I tried playing with <code>flag-dest:config<\/code> but couldn\u2019t manage to make it work.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-07T13:38:32.671Z",
                "Answer_body":"<p>Thanks for the detailed report and my apologies for the very late reply here!<\/p>\n<p>I believe this issue is related to <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-903-123-opening-source-file-causes-file-not-found-exception\">this problem<\/a> \u2014 Guild is not correctly running <code>cfg1.py<\/code> as a module inside the <code>configs<\/code> package but rather as a top-level script inside a subdirectory.<\/p>\n<p>You can create a Guild file in your project root that looks like this:<\/p>\n<pre><code class=\"lang-yaml\"># guild.yml\n\nconfig1:\n  main: configs.cfg1\n<\/code><\/pre>\n<p>This tells Guild that the <code>cf1<\/code> script is actually a module inside <code>configs<\/code>. Guild uses this to configure the Python system path as needed.<\/p>\n<p>The behavior you\u2019re seeing is by design, but I think this design is bad! Guild should spot that <code>cfg1.py<\/code> is inside a package (indicated by the presence of <code>__init__.py<\/code>) and do the right thing there.<\/p>\n<p>I\u2019ll make sure this is fixed and lands in the next release. In the meantime, using the Guild file there should work or you.<\/p>\n<p>Sorry again!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild view not working in jupyterhub",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-view-not-working-in-jupyterhub\/922",
        "Question_created_time":1664820465043,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am using GuildAI in a Jupyter Lab server provisioned in Jupyterhub. To view the UI, I run the command <code>guild view --host=localhost --port=5000<\/code> but am getting the error \u201cFailed to load resource: the server responded with a status of 404 (Not Found)\u201d. On the other hand, <code>guild tensorboard --host=localhost --port=5000<\/code> works fine for me. I\u2019m not sure what\u2019s the issue or how to debug it.<\/p>\n<p>Packages:<br>\nguildai==0.8.1<br>\njupyterhub==1.5.0<br>\njupyterlab==3.4.7<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-10-04T14:24:49.236Z",
                "Answer_body":"<p>Hello and welcome! Could you post a screen shot of the web page showing the 404? I wonder if this is coming from Guild or from a proxy sitting between your browser and Guild. I sadly don\u2019t know anything about Jupyterhub but I\u2019d like to make sure Guild is working there!<\/p>\n<p>I\u2019ll see if I can replicate with a new account there.<\/p>\n<p>Sorry you\u2019re facing this!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-04T23:53:08.533Z",
                "Answer_body":"<p>Thank you very much for the quick response. I have attached the screenshot. It seems like the issue might be due to static css and js files and the paths are wrong when I proxy the Guild View UI using Jupyter server proxy (<code>guild view --host localhost --port 8888<\/code>). Any tips to resolve this would be much appreciated!<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/1016d960fc1b7889525dcea08e77c1a8619600c8.png\" data-download-href=\"\/uploads\/short-url\/2ikANHFL54fTWvObhxLmCw676VW.png?dl=1\" title=\"Guild_View_Error\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/1016d960fc1b7889525dcea08e77c1a8619600c8_2_690x358.png\" alt=\"Guild_View_Error\" data-base62-sha1=\"2ikANHFL54fTWvObhxLmCw676VW\" width=\"690\" height=\"358\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/1016d960fc1b7889525dcea08e77c1a8619600c8_2_690x358.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/1016d960fc1b7889525dcea08e77c1a8619600c8_2_1035x537.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/1016d960fc1b7889525dcea08e77c1a8619600c8_2_1380x716.png 2x\" data-dominant-color=\"F2F2F3\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Guild_View_Error<\/span><span class=\"informations\">2552\u00d71327 132 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-05T17:51:22.429Z",
                "Answer_body":"<p>The paths that are being requested appear to all be hub related (not something related to Guild View). What is the URL you\u2019re starting with in the browser? If Guild View is running on port 8888 it ought to simply be <code>http:\/\/&lt;host&gt;:8888\/<\/code>.<\/p>\n<p>Not to get too wonky here, but if you look at the \u2018Server\u2019 header in the response to any of those 404s, you should see this, if Guild View is providing the result (I suspect it is):<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">Server: Werkzeug\/2.2.2 Python\/&lt;version&gt;\n<\/code><\/pre>\n<p>If you type that into the browser and get a redirect, there\u2019s a proxy sitting in the middle that\u2019s trying to point you to hub related pages.<\/p>\n<p>I wasn\u2019t able to find a way to setup a JupyerHub account so I\u2019m taking stabs in the dark here.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dask scheduler cannot find python library",
        "Question_link":"https:\/\/my.guild.ai\/t\/dask-scheduler-cannot-find-python-library\/880",
        "Question_created_time":1653513089021,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>When I use <code>guild run dask:scheduler<\/code> with staged guild runs, those staged guild runs cannot find one of my Python libraries. The guild runs work if I run them outside of the dask scheduler.<\/p>\n<p>This particular Python library is not part of my Python virtual environment but is discovered by Python through my PYTHONPATH or PATH.<\/p>\n<p>The terminal I am running the dask scheduler in has the same environment variables.<\/p>\n<p>Any ideas?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-08-13T15:43:05.625Z",
                "Answer_body":"<p>Sorry for the late reply. A number of posts here have fallen through the cracks. Taking a look at this now.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-10-04T15:10:55.942Z",
                "Answer_body":"<p>Please let me know if you need support with this. I know it\u2019s an old topic.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild runs very slow",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-runs-very-slow\/919",
        "Question_created_time":1663441155671,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":105,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Similarly to what has been described in <a href=\"https:\/\/my.guild.ai\/t\/guild-run-hangs-very-slow\/362\">this thread<\/a>, running the following command results in hanging for a while before we see any results:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild run train\n<\/code><\/pre>\n<p>The Guild file contains the following:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">train:\n  main: script\n<\/code><\/pre>\n<p>The script is simply:<\/p>\n<pre data-code-wrap=\"py\"><code class=\"lang-nohighlight\">print(\"Hello, world!\")\n<\/code><\/pre>\n<p>I believe the hanging is related to the fact that I have a data folder which contains thousands of files each corresponding to a sample of the dataset I\u2019m using in my experiments. This is because:<\/p>\n<ol>\n<li>When using the <code>--debug<\/code> flag, Guild hangs just after copying one <code>.csv<\/code> file within the data folder (none of the thousands of sample files are copied to the target directory, though).<\/li>\n<li>When I remove the data folder, the hanging stops.<\/li>\n<\/ol>\n<hr>\n<p>My questions are:<\/p>\n<ol>\n<li>Is this a bug? If so, how can I circumvent this issue?<\/li>\n<li>How am I supposed to make my dataset accessible by the training script, since it is run from a totally different directory and there are thousands of files it needs to access?<\/li>\n<\/ol>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-09-28T15:05:55.374Z",
                "Answer_body":"<p>Apologies for the late reply here! I\u2019m looking into this now. I suspect it\u2019s Guild\u2019s scanning for source code files to copy but I want to confirm this before getting the correct config to you.<\/p>\n<p>As for getting your script access to the data dir, you\u2019d do that using a <code>file<\/code> dependency in your Guild file.<\/p>\n<pre><code class=\"lang-yaml\">train:\n  main: script\n  requires:\n    - file: data\n      target-type: link\n<\/code><\/pre>\n<p>The target type \u2018link\u2019 there tells Guild NOT to copy all those files per run but just to link to the directory. If you want to copy, omit <code>targe-type<\/code> or use the value <code>copy<\/code> (the default behavior since 0.8).<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Notebook copying to html error",
        "Question_link":"https:\/\/my.guild.ai\/t\/notebook-copying-to-html-error\/906",
        "Question_created_time":1659633919425,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":386,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I did manage to get Guild to run my notebook, but I did get a couple warnings and 1 error:<\/p>\n<h2>\n<a name=\"h-2-warnings-1\" class=\"anchor\" href=\"#h-2-warnings-1\"><\/a>2 Warnings<\/h2>\n<p>1). \u201cWARNING: Skipping potential source code file .\/tcn_kerasAPI_gpu_data_generator.ipynb because it\u2019s too big. To control which files are copied, define \u2018sourcecode\u2019 for the operation in a Guild file.\u201d<\/p>\n<p>I\u2019m just wondering why I was even seeing that warning when my actual run command was:<\/p>\n<p>guild run tcn_kerasAPI_gpu_guild_ai_data_generator.ipynb<\/p>\n<p>So you see I wasn\u2019t even running the notebook that it says is \u201ctoo big\u201d.  That\u2019s a different notebook file entirely.  Is there some reason Guild would be \u201ccopying over\u201d a notebook file other than the one I\u2019m running?<\/p>\n<p>2). I\u2019m not sure why I got this warning:<\/p>\n<p>[NbConvertApp] WARNING | Config option <code>kernel_spec_manager_class<\/code> not recognized by <code>NbConvertApp<\/code>.<\/p>\n<p>===================<\/p>\n<h2>\n<a name=\"h-1-error-2\" class=\"anchor\" href=\"#h-1-error-2\"><\/a>1 Error<\/h2>\n<p>Tho\u2019 I did manage to get a successful run and saw expected output images (in Tensorboard) for my notebook, at the end of the run, when Guild was trying to convert the notebook to html via \u201cnbconvert\u201d, I did see this error:<\/p>\n<p>\u201cAttributeError: module \u2018jinja2\u2019 has no attribute \u2018Markup\u2019\u201d<\/p>\n<p>I guess it\u2019s not critical, but of course it\u2019s nicer for a run not to end on an error of course <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"> :).<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-08-06T11:13:51.509Z",
                "Answer_body":"<p>Guild copies all your sourcecode in order to run your notebook command.<\/p>\n<p>So if you haven\u2019t specified what sourcecode to include or exclude guild will automatically copy notebooks and python files. You can read more here: <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197\" class=\"inline-onebox\">Guild File Reference<\/a><\/p>\n<p>I am unsure about the <code>kernel_spec_manager_class<\/code>. Is this a class you have developed?<\/p>\n<p>Regarding the error: that is a dependency problem. Try upgrading <code>nbconvert<\/code>or <code>guildai<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-09-09T16:49:47.028Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/mabrandt_nasa\">@mabrandt_nasa<\/a> that Guild is complaining about the size of a file it needs to run the notebook is a bug! Sorry about that.<\/p>\n<p>I\u2019ll open an issue so we can track that.<\/p>\n<p>As for the warning and error messages, this seems like a potential library version conflict. I know jinja2 rev\u2019d its APIs and I recall seeing that error come up before. I\u2019ll take a look.<\/p>\n<p>Thanks for the report!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I tag\/label multiple runs?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-do-i-tag-label-multiple-runs\/910",
        "Question_created_time":1661527216949,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":94,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hello,<\/p>\n<p>I\u2019m struggling to achieve the following:<br>\nIn TensorBoard I can only differenciate multiple runs by ID, as the comment is truncated, so the hyperparameters are mostly not shown.<br>\nFor example:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">42afef82 my_model:train 2022-08-23 02:02:04 architecture=DenseNet-121 batch_size=24 classes=14 comment='DenseNet\/experiments\/lightning_logs\/version_0\n<\/code><\/pre>\n<p>In this example, the hyper-parameter dropout is not visible.<br>\nNow, what I would love to do is to compare specific runs, e.g. all runs with <code>dropout=0.1<\/code>, in TensorBoard.<\/p>\n<p>Based on the docs AFAIK the only possibility is to filter the runs by tag and then run TensorBoard specifically for these runs, instead of using guild view \u2192 click on TensorBoard \u2192 filter inside TensorBoard.<\/p>\n<p>Therefore, my question is: how do I tag\/label multiple runs?<\/p>\n<p>I discovered, that I can display all <code>dropout=0.1<\/code> runs using:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild runs list --list-all -Fl=dropout=0.1\n<\/code><\/pre>\n<p>However, running <code>guild runs tag -Fl=dropout=0.1 -a dropout=0.1<\/code> tags only one run.<\/p>\n<p>Furthermore, I also want to tag runs where <code>dropout<\/code> wasn\u2019t a hyper-parameter but hardcoded. How do I select those? Is there something like a negative lookaround?<\/p>\n<p>Thanks!<\/p>\n<p>Cheers,<br>\nAlessandro<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-08-30T08:26:50.474Z",
                "Answer_body":"<p>Hi Alessandro,<\/p>\n<p>I can\u2019t try your example because I don\u2019t have your experiments.<br>\nHowever, I think you can add \u2018:\u2019 at the end of your command as in:<br>\n<code>guild runs tag -Fl=dropout=0.1 -a dropout=0.1 :<\/code> to tag multiple runs.<\/p>\n<p>Cheers,<br>\nJosue<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-08-30T09:40:00.727Z",
                "Answer_body":"<p>Awesome, that works. Thanks Josue!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Distributed training hanging",
        "Question_link":"https:\/\/my.guild.ai\/t\/distributed-training-hanging\/867",
        "Question_created_time":1651096364646,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":1625,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Python: 3.9.12<br>\nPytorch: \u20181.11.0+cu102\u2019<br>\nPytorch-lightning: 1.6.1<br>\nguildai: 0.8.0<\/p>\n<p>I\u2019m trying to run distributed training (DDP) on my 1 machine with 4 GPUs. It works fine if I just run it normally with python. However, when I run with guild, it hangs.<\/p>\n<pre><code class=\"lang-python\">INFO: [pytorch_lightning.utilities.distributed] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1\/4\nINFO: [torch.distributed.distributed_c10d] Added key: store_based_barrier_key:1 to store for rank: 0\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\nINFO: [torch.distributed.distributed_c10d] Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\n...\nTraceback (most recent call last):\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/main.py\", line 223, in &lt;module&gt;\n    main()\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/main.py\", line 81, in main\n    results = get_imputation_logic(args)(args, data)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/task_logic\/ae_imputation.py\", line 101, in ae_imputation_logic\n    ae_imputer = create_autoencoder_with_tuning(args, data, settings)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/utils\/tuner.py\", line 43, in create_autoencoder_with_tuning\n    ae_imputer.fit(data)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/models\/ap.py\", line 128, in fit\n    self._fit(data.longitudinal, \"longitudinal\")\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/.guild\/runs\/896d6a07fe044bb5a40b01c4e6a4064f\/.guild\/sourcecode\/autopopulus\/models\/ap.py\", line 139, in _fit\n    self.trainer[longitudinal_or_static].fit(ae, datamodule=data)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 768, in fit\n    self._call_and_handle_interrupt(\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 719, in _call_and_handle_interrupt\n    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/launchers\/subprocess_script.py\", line 93, in launch\n    return function(*args, **kwargs)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 809, in _fit_impl\n    results = self._run(model, ckpt_path=self.ckpt_path)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1169, in _run\n    self.strategy.setup_environment()\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/ddp.py\", line 151, in setup_environment\n    self.setup_distributed()\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/strategies\/ddp.py\", line 191, in setup_distributed\n    init_dist_connection(self.cluster_environment, self._process_group_backend)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/distributed.py\", line 354, in init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/torch\/distributed\/distributed_c10d.py\", line 627, in init_process_group\n    _store_based_barrier(rank, store, timeout)\n  File \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.9\/site-packages\/torch\/distributed\/distributed_c10d.py\", line 255, in _store_based_barrier\n    raise RuntimeError(\nRuntimeError: Timed out initializing process group in store based barrier on rank: 0, for key: store_based_barrier_key:1 (world_size=4, worker_count=1, timeout=0:30:00)\n<\/code><\/pre>\n<p>Some related errors:<\/p>\n<ul>\n<li><a href=\"https:\/\/discuss.pytorch.org\/t\/timed-out-initializing-process-group-in-store-based-barrier\/119803\/9\" rel=\"noopener nofollow ugc\">Timed out initializing process group in store based barrier<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/pytorch\/pytorch\/issues\/52848\" rel=\"noopener nofollow ugc\">Pytorch Issue<\/a><\/li>\n<\/ul>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-04-29T14:33:03.563Z",
                "Answer_body":"<p>Do you have a short example I can try running to reproduce this?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-08-18T02:57:29.518Z",
                "Answer_body":"<p>I know I\u2019m a million months behind on this, my project got sidetracked, but I\u2019m working on a MWE.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pipeline depending on multiple of the same operation",
        "Question_link":"https:\/\/my.guild.ai\/t\/pipeline-depending-on-multiple-of-the-same-operation\/891",
        "Question_created_time":1655386885562,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":112,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have the following setup:<\/p>\n<pre><code class=\"lang-yaml\">- model: my_model\n  operations:\n    train: \n      main: scripts.train\n      flags:\n        a: 1\n    evaluate: \n      main: scripts.evaluate\n      requires:\n          - operation: train\n    train_evaluate:\n      flags:\n        a: 1\n      steps:\n      - run: train a=${a}\n      - run: evaluate\n    compare_evaluate:\n      main: scripts.compare\n      requires:\n        - train_evaluate_run_1\n        - train_evaluate_run_2\n    compare:\n      steps:\n      - run: train_evaluate a=1\n      - run: train_evaluate a=2\n      - run: compare_evaluate # HERE\nresources:\n  train_evaluate_run_1:\n    - operation: train_evaluate\n      name: train_evaluate_run_1\n  train_evaluate_run_2:\n    - operation: train_evaluate\n      name: train_evaluate_run_2\n<\/code><\/pre>\n<p>How to tell guild to resolve two different resources in the <code>compare_evaluate<\/code> run (with the # HERE tag)?<\/p>\n<p>The goal is to have a script\/notebook that takes as input two <code>train_evaluate<\/code> runs and compares them using custom plotting etc. and have all that specified in a single pipeline.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-06-17T07:30:59.793Z",
                "Answer_body":"<p>Would you consider creating an addition pipeline to include the two different runs?<\/p>\n<pre><code class=\"lang-yaml\">op:\n  ...\n\nwrapper:\n  steps:\n    - op [flags 1]\n    - op [flags 2]\n\ncompare: \n  ...\n  requires:\n    - operation: wrapper\n      select: \n        - file: op\/XXX\n        - file: op_2\/XXX # guild automatically rename operations by adding _[#] \n                         # if there are multiple steps with the same operation\n\npipeline: \n  steps:\n    - wrapper\n    - compare\n<\/code><\/pre>\n<p>I am not 100% this would work but here\u2019s a direction for you to try.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-07-11T18:47:08.755Z",
                "Answer_body":"<p>Tried it out and it works. Thx for your suggestion!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild does not catch scalar outputs when formatting values",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-does-not-catch-scalar-outputs-when-formatting-values\/890",
        "Question_created_time":1655380881913,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":154,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>Thank you very much for making this fantastic experiment manager and making it free!<\/p>\n<p>I noticed an unexpected behavior of Guild\u2019s <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#output-scalars-15\">output scalar<\/a>, so I report it here. Shortly, when the output strings are formatted with \u2018.e\u2019, they can not be caught by Guild. Below is a script to reproduce with Guild 0.8.1<\/p>\n<p>In scalar.py, I had<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">import argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--a\", type=float, default=1.0)\n    args = parser.parse_args()\n    print(f\"step: {100}\")\n    print(f\"value: {args.a:.2e}\")\n\n\nif __name__ == \"__main__\":\n    main()\n<\/code><\/pre>\n<p>and in guild.yml, I had<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">scalar:\n  main: scalar\n  flags-dest: args\n  flags-import: all\n<\/code><\/pre>\n<p>Then in console, I got<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">(.venv) \u279c  gscalar guild run scalar\nYou are about to run scalar\n  a: 1.0\nContinue? (Y\/n)\nstep: 100\nvalue: 1.00e+00\n(.venv) \u279c  gscalar guild runs info\nid: 0b6abb0dc8bc4bb2914c01e504a5865e\noperation: scalar\nfrom: ~\/project\/gscalar\/guild.yml\nstatus: completed\nstarted: 2022-06-16 19:58:39\nstopped: 2022-06-16 19:58:39\nmarked: no\nlabel: a=1.0\nsourcecode_digest: 59509472e567014859244cbc4ce14ccd\nvcs_commit:\nrun_dir: ~\/project\/gscalar\/guild_home\/runs\/0b6abb0dc8bc4bb2914c01e504a5865e\ncommand: \/Users\/kyika\/project\/gscalar\/.venv\/bin\/python -um guild.op_main scalar -- --a 1.0\nexit_status: 0\npid:\ntags:\nflags:\n  a: 1.0\nscalars:\n<\/code><\/pre>\n<p>The last line above shown that Guild records no scalar. I guess this is because values was formatted with \u201ce+00\u201d, which was not recognized by Guild.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-06-21T15:05:40.031Z",
                "Answer_body":"<p>Good old scientific notation. Thanks for the report. We will look into a fix for the next release.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Specify guild home location on SSH remote",
        "Question_link":"https:\/\/my.guild.ai\/t\/specify-guild-home-location-on-ssh-remote\/866",
        "Question_created_time":1651083462913,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":106,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have a remote SSH with a OS disk and a data disk. I want to put my guild runs on the data disk, so on my ssh machine I have set my <code>GUILD_HOME=\/mnt\/guild_runs<\/code>.<\/p>\n<p>When I want to run from my local machine like <code>guild runs --remote ssh-machine<\/code> it cannot find the runs on the remote. When I run with additional debug information I see that the ssh command guild issues overwrites my <code>GUILD_HOME<\/code> env variable.<\/p>\n<p>Is there a way to tell guild where my <code>GUILD_HOME<\/code> is on my remote? I know I can do <code>venv-path<\/code>, but since my venv path and <code>GUILD_HOME<\/code> directory aren\u2019t the same, I don\u2019t think this solves it.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-04-27T18:24:33.800Z",
                "Answer_body":"<p>I see this undocumented (sorry about that!) \u2014 you can use <code>guild-home<\/code> as a config attr for the remote:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">remotes:\n  my-remote:\n    guild-home: \/mnt\/guild_runs\n<\/code><\/pre>\n<p>I\u2019ll make sure this gets added to the docs. Sorry again.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-04-27T18:26:25.527Z",
                "Answer_body":"<p>No worries - that worked!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Process flag value in guild.yml for pipelines",
        "Question_link":"https:\/\/my.guild.ai\/t\/process-flag-value-in-guild-yml-for-pipelines\/860",
        "Question_created_time":1650387338552,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":107,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Say I have a pipeline that takes as input a path as a flag:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">preprocess_bag:\n  flags:\n    bag_path: \"path\/to\/bag.bag\"\n  steps:\n    - decode_bag bag_path=${bag_path}\n    - dump_bag bag_bag=${bag_path_but_with_some_processed} # i.e. strip entire path down to only bag.bag\n<\/code><\/pre>\n<p>What I am essentially looking for is something like <a href=\"https:\/\/www.gnu.org\/software\/make\/manual\/html_node\/File-Name-Functions.html\" rel=\"noopener nofollow ugc\">Make File Name Functions<\/a> that I can use to manipulate the flags.<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Get run ID before\/during the corresponding run",
        "Question_link":"https:\/\/my.guild.ai\/t\/get-run-id-before-during-the-corresponding-run\/844",
        "Question_created_time":1648140890873,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":152,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hey, my issue is the following:<br>\nDuring my run I am training several models and save their checkpoint. In the end I need to load them all for the final testing procedure. However, since the models are saved in  <code>.guild\/runs\/ID\/my_saved_model.ckpt<\/code> and I don\u2019t know the current <code>ID<\/code>, there is no way to re-load the models into my training script. Is there a way to pass the current\/future <code>ID<\/code> into my python script?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-25T15:04:38.014Z",
                "Answer_body":"<p>When Guild runs your operation, it runs the process with the run directory as the current working directory. Any relative paths will resolve to the run directory, always. So you can open the file in question using <code>open('my_saved_model.ckpt')<\/code>.<\/p>\n<p>If you are talking about a separate operation for loading and testing \u2014 i.e. you have a <code>train<\/code> operation and a separate <code>test<\/code> operation, you\u2019ll need to setup dependencies to ensure that your checkpoint files are available to your test operation.<\/p>\n<p>In both cases \u2014 i.e. when you train and test in the same operation and when your train and test operations are separate \u2014 you use a relative path to get to the files.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-25T15:23:51.131Z",
                "Answer_body":"<p>As an addendum, you can get the run ID and the run dir using environment variables:<\/p>\n<ul>\n<li><code>RUN_ID<\/code><\/li>\n<li><code>RUN_DIR<\/code><\/li>\n<\/ul>\n<p>But these are rarely needed. If you want to access run directory files, use relative paths. This also keeps your code independent from Guild. E.g. if you\u2019re relying on Guild specific env vars, you need to make sure you set these up for each run if you ever want to run your code independently of Guild.<\/p>\n<p><em>Any change to your code that prevents it from running correctly without Guild should be considered an anti-pattern.<\/em><\/p>\n<p>A pattern that I recommend is to use command line options to point to files-of-interest where the default is the cwd:<\/p>\n<pre><code class=\"lang-python\">import argparse\n\np = argparse.add_argument('--data-files', default='.')\np = argparse.add_argument('--checkpoint-files', default='.')\ndo_something(p.parse_args())\n<\/code><\/pre>\n<p>You can certainly use other defaults, but you\u2019ll need to keep those paths in mind when you define dependencies (i.e. make sure the required files land in the right subdir \u2014 it\u2019s easy to do this with <code>target-path<\/code> attr in the dependency).<\/p>\n<p>You can also specify the data location as a part of the <code>main<\/code> spec:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  main: train --data-files . --checkpoint-files .\n\ntest:\n  main: test --checkpoint-files .\n  requires:\n    - operation: train\n<\/code><\/pre>\n<p>This is all maybe too much information (TMI <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> ) but it might be helpful background info to understand how Guild works here and what good design looks like.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remotes config doesn't work for Gist",
        "Question_link":"https:\/\/my.guild.ai\/t\/remotes-config-doesnt-work-for-gist\/840",
        "Question_created_time":1647929797879,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":146,
        "Question_has_accepted_answer":false,
        "Question_body":"<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">train:\n  description: train\n  main: tests\/train\n  sourcecode:\n    - exclude: '*.json'\n\nremotes:\n  remotename:\n    type: gist\n    user: username\n    gist-name: results.md\n<\/code><\/pre>\n<p>This remote doesn\u2019t show up when I run <code>guild remotes<\/code><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-22T19:49:49.335Z",
                "Answer_body":"<p>You need to define remotes in <a href=\"https:\/\/my.guild.ai\/t\/user-config-reference\/173\">User Config<\/a>. Guild is going to interpret your example as having a <code>remotes<\/code> operation (it\u2019s parallel to <code>train<\/code>, which is treated as an operation).<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Issue with defining source code in guild.yml",
        "Question_link":"https:\/\/my.guild.ai\/t\/issue-with-defining-source-code-in-guild-yml\/833",
        "Question_created_time":1647306584584,
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":124,
        "Question_has_accepted_answer":false,
        "Question_body":"<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">sort_sv_by_score:\n  description: Runs validation of sorting singular vectors by score\n  main: tests\/sort_sv_by_score\n  sourcecode:\n    -exclude: '*.json'\n<\/code><\/pre>\n<p>This is my guild.yml file. I have a bunch of .json files in my directory (my results logs from previous experiments). When I run this operation though, despite specifying exclude, it attempts to copy over all the .json files.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-19T17:57:15.172Z",
                "Answer_body":"<p>Hi and welcome! I\u2019m sorry you\u2019re running into this. The issue is subtle \u2014 you need a space between the dash and your <code>exclude<\/code>.<\/p>\n<p>Here\u2019s a sample project that illustrates the issue:<\/p>\n<aside class=\"onebox githubfolder\" data-onebox-src=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\">\n  <header class=\"source\">\n      <img src=\"https:\/\/github.githubassets.com\/favicons\/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <h3><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\" target=\"_blank\" rel=\"noopener\">issue-resolution\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml at...<\/a><\/h3>\n\n  <p><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\" target=\"_blank\" rel=\"noopener\">master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml<\/a><\/p>\n\n  <p><span class=\"label1\">Scratch repo for recreating and resolving Guild AI issues - issue-resolution\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml at master \u00b7 guildai\/issue-resolution<\/span><\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>The Guild file:<\/p>\n<aside class=\"onebox githubblob\" data-onebox-src=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\/guild.yml\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\/guild.yml\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\/guild.yml\" target=\"_blank\" rel=\"noopener\">guildai\/issue-resolution\/blob\/master\/my.guild.ai-833-issue-with-defining-source-code-in-guild-yml\/guild.yml<\/a><\/h4>\n\n\n      <pre><code class=\"lang-yml\">test:\n  sourcecode:\n    - exclude: '*.json'\n\ntest-broken:\n  main: test\n  sourcecode:\n    -exclude: '*.json'\n<\/code><\/pre>\n\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Guild should give you some help here, not just ignore the issue! I\u2019ll look into what\u2019s going on so others don\u2019t need to face this.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-19T18:46:26.448Z",
                "Answer_body":"<p>The next release of Guild will warn you when it sees something like this. Sorry again for the frustation!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-22T05:48:56.488Z",
                "Answer_body":"<p>Thank you, appreciate the prompt response!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"TensorBoard HPARAM not working",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-hparam-not-working\/835",
        "Question_created_time":1647539306680,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":396,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am trying to use the HPARAM tab in tensorboard together with guild<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild --debug tensorboard 1\n<\/code><\/pre>\n<p>When I navigate to the HPARAM tab this is what I get:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b.png\" data-download-href=\"\/uploads\/short-url\/hTCwjWGkWGpnber9a2bv5j8RbaX.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b_2_690x356.png\" alt=\"image\" data-base62-sha1=\"hTCwjWGkWGpnber9a2bv5j8RbaX\" width=\"690\" height=\"356\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b_2_690x356.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b_2_1035x534.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b_2_1380x712.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/7d6e8b08fb55eac7111f7519e67f7947be7fc80b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2505\u00d71296 153 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The runs are not actually showing up. Any idea why this is happening? There are no errors in the debug output from guild.<\/p>\n<p><strong>Versions<\/strong><br>\nguildai==0.8.0rc1<br>\ntensorboard==2.8.0<br>\ntensorboard-data-server==0.6.1<br>\ntensorboard-plugin-wit==1.8.1<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-19T18:56:08.323Z",
                "Answer_body":"<p>It\u2019s hard to know from this view.<\/p>\n<p>In the debug output, you should see some info about Guild\u2019s handling of hparam entries in the TF event logs. I\u2019m using the <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\/get-started\">Get Started<\/a> <code>train.py<\/code> to test.<\/p>\n<p>Generate a run:<\/p>\n<pre><code class=\"lang-command\">guild run train.py -y\n<\/code><\/pre>\n<p>Run TB:<\/p>\n<pre><code class=\"lang-command\">guild --debug tensorboard 1\n<\/code><\/pre>\n<pre><code class=\"lang-output\">...\nDEBUG: [guild] hparam experiment: hparams=['noise', 'sourcecode', 'x'] metrics=['loss', 'time']\n<\/code><\/pre>\n<p>And the view is as expected:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a.png\" data-download-href=\"\/uploads\/short-url\/grpXv43yfNqR8Pq0ARpIv9cS3sm.png?dl=1\" title=\"Screenshot from 2022-03-19 13-54-16\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a_2_690x261.png\" alt=\"Screenshot from 2022-03-19 13-54-16\" data-base62-sha1=\"grpXv43yfNqR8Pq0ARpIv9cS3sm\" width=\"690\" height=\"261\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a_2_690x261.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a_2_1035x391.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a_2_1380x522.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/733c3be29ef33b549bafb270c0b7ecd5903d889a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-03-19 13-54-16<\/span><span class=\"informations\">3812\u00d71444 138 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The fact that you\u2019re seeing an <strong>HPARAMS<\/strong> tab in TensorBoard indicates that the TF logs in fact contain the hparam entries.<\/p>\n<p>The issue may be in the selection state in the left panel\u2014you may have some settings there that are filtering out the runs. TB may be using some defaults that automatically filter out the runs.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-19T18:58:08.330Z",
                "Answer_body":"<p>I\u2019m using TB 2.8.0 as well FWIW<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best way to specify boolean argparse flags",
        "Question_link":"https:\/\/my.guild.ai\/t\/best-way-to-specify-boolean-argparse-flags\/834",
        "Question_created_time":1647534360656,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":198,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>What is the best way to combine argparse and guild with a boolean flag?<\/p>\n<p>I currently do something like this:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\"># In python argparse\ndata.add_argument('--enable_augmentation', dest='enable_augmentation', action='store_true',\n                    help=\"Whether or not apply augmentation on training dataset\")\n\n<\/code><\/pre>\n<p>And<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\"># guild.yml\n  enable_augmentation:\n    default: no\n    arg-switch: yes\n    type: boolean\n<\/code><\/pre>\n<p>Is this the preferred way?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-19T18:47:34.151Z",
                "Answer_body":"<p>Yes that looks correct!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Nb-replace with boolean value",
        "Question_link":"https:\/\/my.guild.ai\/t\/nb-replace-with-boolean-value\/830",
        "Question_created_time":1646940828346,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":148,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I want to use guild to run a notebook as an experiment. I also want to parameterize the notebook by using guilds search and replace option with notebooks.<\/p>\n<p>One of my parameters is a boolean value. How should I define the <code>nb-replace<\/code> to work with booleans?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-19T17:40:15.949Z",
                "Answer_body":"<p>I wanted to make sure Guild was working here so I created an <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/my.guild.ai-830-nb-replace-with-boolean-value\">issue resolution doc<\/a>.<\/p>\n<p>Here\u2019s an example Guild file:<\/p>\n<aside class=\"onebox githubblob\" data-onebox-src=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/guild.yml\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/guild.yml\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/guild.yml\" target=\"_blank\" rel=\"noopener\">guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/guild.yml<\/a><\/h4>\n\n\n      <pre><code class=\"lang-yml\">test:\n  notebook: test.ipynb\n  flags:\n    x:\n      type: boolean\n      nb-replace: x = (.*)\n<\/code><\/pre>\n\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>And the Notebook source (copied from <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/test.ipynb\">test.ipynb<\/a>):<\/p>\n<pre><code class=\"lang-python\">def test():\n    x = True\n    if x:\n        print(\"It is alive!\")\n    else:\n        print(\"Sad :(\")\n\ntest()\n<\/code><\/pre>\n<p>You can test this by running:<\/p>\n<pre><code class=\"lang-command\">guild run test -y\n<\/code><\/pre>\n<p>You can run the example code in <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/blob\/master\/my.guild.ai-830-nb-replace-with-boolean-value\/README.md\"><code>README.md<\/code><\/a> this way:<\/p>\n<pre><code class=\"lang-command\">guild check -nt README.md\n<\/code><\/pre>\n<p>If you\u2019re running into problems, you can try experimenting with changes to that project to reflect your case (e.g. fork the <a href=\"https:\/\/github.com\/guildai\/issue-resolution\">repo<\/a>, make changes that show your case and submit a PR \u2014 we can then see exactly what\u2019s going on). The example above may be overly simplistic.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Local run vs remote run dependencies",
        "Question_link":"https:\/\/my.guild.ai\/t\/local-run-vs-remote-run-dependencies\/812",
        "Question_created_time":1645549217715,
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":198,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have run some operations on remotes successfully in the past. However, there was always a some discrepancy between the imports for local and remote runs that I needed to fix by trial and error.<\/p>\n<p>In my current setup, I switched from flags as global variables in the training script to flags in config.yml files. And I\u2019m unable to make it work on remotes.<\/p>\n<p><strong>Project structure<\/strong><br>\nProject:<\/p>\n<ul>\n<li>[some folders]<\/li>\n<li>datasets \u2192 module, contains data loaders + their config.yml files<\/li>\n<li>zoo \u2192 guild Home for local runs<\/li>\n<li>models \u2192 model definitions<\/li>\n<li>\n<ul>\n<li>guild.yml<\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li>abstract_model.py<\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li>conv_lstm \u2192 model I want to run<\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li>\n<ul>\n<li>model.py \u2192 model definition<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li>\n<ul>\n<li>train.py \u2192 training script<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li>\n<ul>\n<li>config.yml \u2192 flags<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p><strong>Guild file<\/strong><\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\"># Standard convolutional LSTM\n- model: conv_lstm\n  description: Convolutional LSTM\n  operations:\n    train_local:\n      description: Train Convolutional LSTM\n      sourcecode:\n        - conv_lstm\/train.py\n        - conv_lstm\/model.py\n        - abstract_model.py\n      requires:\n        - config: conv_lstm\/config.yml\n        - file: ..\/datasets\/\n      main: conv_lstm\/train\n      flags-dest: config:conv_lstm\/config.yml\n      flags-import: all\n      flags:\n        epochs: 100\n        dataset_args:\n          - dataset_name: ucsd\n            batch_size: 2\n      output-scalars:\n        train_loss: 'Train mse: (\\value)'\n        test_acc: 'Test mse: (\\value)'\n    train_remote:\n      description: Train Convolutional LSTM on remote\n      sourcecode:\n        - conv_lstm\/train.py\n        - conv_lstm\/model.py\n        - abstract_model.py\n      requires:\n        - config: conv_lstm\/config.yml\n        - file: ..\/datasets\/\n      main: conv_lstm\/train\n      flags-dest: config:conv_lstm\/config.yml\n      flags-import: all\n      flags:\n        optimizer: Adam\n        loss: mse\n        learning_rate: 0.001\n        epochs: 100\n        dev: True\n        gpus: [7]\n        dataset_args:\n          - dataset_name: ucsd\n            batch_size: 2\n            train_path: ~\/data\/ucsd\/UCSDped1\/Train\/\n            test_path: ~\/data\/ucsd\/UCSDped1\/Test\/\n      output-scalars:\n        train_loss: 'Train mse: (\\value)'\n        test_acc: 'Test mse: (\\value)'\n<\/code><\/pre>\n<p><strong>Training script<\/strong><\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">sys.path.append('..\/')\nsys.path.append('..\/..\/datasets')\n# Tensorflow logging level\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport tensorflow as tf\nimport yaml\nfrom model import ConvLSTM\nfrom datasets.data_loader import DataLoader\n\n\n# Load the model configuration\nclass Config(object):\n    def __init__(self, filename):\n        self.__dict__.update(yaml.safe_load(open(filename)))\n\n\nconfig = Config(\"config.yml\")\n\n(...)\n<\/code><\/pre>\n<p><strong>Current situation &amp; error<\/strong><br>\nI\u2019m able to run \u2018conv_lstm:train_local\u2019 without any issues, and everything works as expected. However, almost the same configuration, with a few flags changed, fails to run on remote.<\/p>\n<p>Issue 1: I cannot see any evidence of the config.yml file being copied to the remote<br>\nIssue 2: the remote run fails to find the main training script, even though it works locally.<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild -H \/home\/bleporowski\/Projects\/mad\/zoo run conv_lstm:train_remote --remote [remote_name] --gpus 7\nYou are about to run conv_lstm:train_remote as a batch (1 trial) on [remote_name]\n  dataset_args: [{batch_size: 2, dataset_name: ucsd, test_path: ~\/data\/ucsd\/UCSDped1\/Test\/, train_path: ~\/data\/ucsd\/UCSDped1\/Train\/}]\n  dev: yes\n  epochs: 100\n  gpus: [7]\n  learning_rate: 0.001\n  loss: mse\n  optimizer: Adam\nContinue? (Y\/n) y\nBuilding package\npackage src: \/home\/bleporowski\/Projects\/mad\/models\npackage dist: \/tmp\/guild-remote-stage-eq7ahi7e\nrunning clean\nremoving 'build\/lib' (and everything under it)\nremoving 'build\/bdist.linux-x86_64' (and everything under it)\n'build\/scripts-3.8' does not exist -- can't clean it\nremoving 'build'\nrunning bdist_wheel\nrunning build\nrunning build_py\npackage init file '\/home\/bleporowski\/Projects\/mad\/models\/__init__.py' not found (or not a regular file)\ncreating build\ncreating build\/lib\ncreating build\/lib\/conv_lstm\ncopying \/home\/bleporowski\/Projects\/mad\/models\/abstract_model.py -&gt; build\/lib\/conv_lstm\ncopying \/home\/bleporowski\/Projects\/mad\/models\/guild.yml -&gt; build\/lib\/conv_lstm\ninstalling to build\/bdist.linux-x86_64\/wheel\nrunning install\nrunning install_lib\ncreating build\/bdist.linux-x86_64\ncreating build\/bdist.linux-x86_64\/wheel\ncreating build\/bdist.linux-x86_64\/wheel\/conv_lstm\ncopying build\/lib\/conv_lstm\/guild.yml -&gt; build\/bdist.linux-x86_64\/wheel\/conv_lstm\ncopying build\/lib\/conv_lstm\/abstract_model.py -&gt; build\/bdist.linux-x86_64\/wheel\/conv_lstm\nrunning install_egg_info\nrunning egg_info\nwriting conv_lstm.egg-info\/PKG-INFO\nwriting dependency_links to conv_lstm.egg-info\/dependency_links.txt\nwriting entry points to conv_lstm.egg-info\/entry_points.txt\nwriting namespace_packages to conv_lstm.egg-info\/namespace_packages.txt\nwriting top-level names to conv_lstm.egg-info\/top_level.txt\nreading manifest file 'conv_lstm.egg-info\/SOURCES.txt'\nwriting manifest file 'conv_lstm.egg-info\/SOURCES.txt'\nCopying conv_lstm.egg-info to build\/bdist.linux-x86_64\/wheel\/conv_lstm-0.0.0-py3.8.egg-info\nrunning install_scripts\ncreating build\/bdist.linux-x86_64\/wheel\/conv_lstm-0.0.0.dist-info\/WHEEL\ncreating '\/tmp\/guild-remote-stage-eq7ahi7e\/conv_lstm-0.0.0-py2.py3-none-any.whl' and adding 'build\/bdist.linux-x86_64\/wheel' to it\nadding 'conv_lstm\/abstract_model.py'\nadding 'conv_lstm\/guild.yml'\nadding 'conv_lstm-0.0.0.dist-info\/METADATA'\nadding 'conv_lstm-0.0.0.dist-info\/PACKAGE'\nadding 'conv_lstm-0.0.0.dist-info\/WHEEL'\nadding 'conv_lstm-0.0.0.dist-info\/entry_points.txt'\nadding 'conv_lstm-0.0.0.dist-info\/namespace_packages.txt'\nadding 'conv_lstm-0.0.0.dist-info\/top_level.txt'\nadding 'conv_lstm-0.0.0.dist-info\/RECORD'\nremoving build\/bdist.linux-x86_64\/wheel\nInitializing remote run\nCopying package\nsending incremental file list\nconv_lstm-0.0.0-py2.py3-none-any.whl\n\nsent 3,558 bytes  received 35 bytes  1,437.20 bytes\/sec\ntotal size is 3,424  speedup is 0.95\nInstalling package and its dependencies\nProcessing .\/conv_lstm-0.0.0-py2.py3-none-any.whl\nInstalling collected packages: conv-lstm\nSuccessfully installed conv-lstm-0.0.0\nStarting conv_lstm:train_remote on charybdis as 8a26ca399039412fb31c7791d293b507\nWARNING: [Errno 2] No such file or directory: 'conv_lstm\/config.yml'\nWARNING: [Errno 2] No such file or directory: 'conv_lstm\/config.yml'\nWARNING: cannot import flags from conv_lstm\/train: No module named conv_lstm\/train\nWARNING: cannot import flags from conv_lstm\/train: No module named conv_lstm\/train\nINFO: [guild] Running trial 05afef0858f74b4198af160c6d904e2e: conv-lstm\/conv_lstm:train_remote (dataset_args={batch_size: 2, dataset_name: ucsd, test_path: ~\/data\/ucsd\/UCSDped1\/Test\/, train_path: ~\/data\/ucsd\/UCSDped1\/Train\/}, dev=yes, epochs=100, gpus=7, learning_rate=0.001, loss=mse, optimizer=Adam)\nINFO: [guild] Resolving config:conv_lstm\/config.yml dependency\nERROR: [guild] Trial 05afef0858f74b4198af160c6d904e2e exited with an error: (1) run failed because a dependency was not met: could not resolve 'config:conv_lstm\/config.yml' in config:conv_lstm\/config.yml resource: cannot find source file 'conv_lstm\/config.yml'\nRun 8a26ca399039412fb31c7791d293b507 stopped with a status of 'completed'\n\n<\/code><\/pre>\n<p>Do remote runs require everything to become a module, with \u2018<strong>init<\/strong>.py\u2019? Or should the guild file be in a different location?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-03-03T17:17:20.121Z",
                "Answer_body":"<p>Sorry for the late reply here! I thought someone had replied to this but I had my messages crossed. Taking a look now.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-03T17:49:58.131Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/cptpirx\">@CptPirx<\/a>,<\/p>\n<p>We think your issue is the lack of a data-files entry: <a href=\"https:\/\/my.guild.ai\/t\/packages\/223\" class=\"inline-onebox\">Packages<\/a><\/p>\n<p>Garrett and I discussed the unintuitive behavior that explicitly listed sourcecode and files are not being included. We\u2019ll file a feature request for straightening this out, so that the data-files entry is only necessary for files not explicitly listed in other fields.<\/p>\n<p>EDIT: issue filed at <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/323\" class=\"inline-onebox\">Package explicitly listed sourcecode and config entries without data-files \u00b7 Issue #323 \u00b7 guildai\/guildai \u00b7 GitHub<\/a><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-07T16:00:50.556Z",
                "Answer_body":"<p>After adding appropriate data-files entries in the package, as suggested, everything works.<\/p>\n<p>Thank you both for quick help, as always  <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-03-07T16:05:40.637Z",
                "Answer_body":"<p>I\u2019ll echo <a class=\"mention\" href=\"\/u\/msarahan\">@msarahan<\/a> with a mea culpa \u2014 Guild should figure that stuff out and not require the extra work. We\u2019ll get that cleaned up! Thanks for your patience.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dask Scheduler not utilizing all available resources",
        "Question_link":"https:\/\/my.guild.ai\/t\/dask-scheduler-not-utilizing-all-available-resources\/822",
        "Question_created_time":1646331949841,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":197,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hey all,<\/p>\n<p>I\u2019ve been trying to get the dask scheduler to work with my guild runs. Let\u2019s say I have 2 GPUs and I\u2019d like to put at max, 2 runs on each GPU.<\/p>\n<p>According to the guides (<a href=\"https:\/\/my.guild.ai\/t\/parallel-processing-with-dask-scheduler\/550\" class=\"inline-onebox\">Parallel processing with Dask scheduler<\/a>) I\u2019ve implemented two sets of commands. The first set is two commands to stage the set of runs across the 2 gpus. These commands look something like this:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild run model:train   param1_to_sweep=[10, 20, 30]\n                        param2_to_sweep=[1,2,3,4,5]\n                        --label my_hp_runs\n                        --optimizer random\n                        --trials 5\n                        --tag dask:GPU0=1\n                        --stage-trials\n                        --gpus 0\n\nguild run model:train   param1_to_sweep=[10, 20, 30]\n                        param2_to_sweep=[1,2,3,4,5]\n                        --label my_hp_runs\n                        --optimizer random\n                        --trials 5\n                        --tag dask:GPU1=1\n                        --stage-trials\n                        --gpus 1\n<\/code><\/pre>\n<p>After the runs are staged, I spin up the scheduler with the associated resources that would allow 2 runs per GPU.<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">guild run dask:scheduler run-once=yes\n                         workers=10\n                         resources='GPU0=2 GPU1=2'\n                         dashboard-address=8890\n<\/code><\/pre>\n<p>I\u2019m able to open up the dashboard and can see GPU0 and GPU1 resources avalible. The trouble happens when I see dask only puts 2 runs of GPU0 and none on GPU1. To be more clear, about the schedule of runs that actually happen I\u2019ll label each of the staged runs below:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">run id  0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n----------------------------------------------\nGPU     0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1\n<\/code><\/pre>\n<p>Assuming all the runs take the same amount of time the runs get ran in the following \u2018sets\u2019<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">Set  | run ids\n---------------\n0    | 0,1 - The initial two runs get put on GPU0\n1    | 2,3 - GPU0 runs 0 and 1 ended, so 2 more get put on\n2    | 4, 5, 6 - GPU0 runs 2,3 end and there is only one GPU0 run left that gets executed (4). Then 2 runs go on GPU2\n3    | 7, 8 - Similar behavior to set 1\n4    | 9   - The remaining runs in the GPU2 queue. \n<\/code><\/pre>\n<p>The expected behavior would be the following sets<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">Set  | run ids\n---------------\n0    | 0,1,5,6 - 2 runs on each gpu\n1    | 2,3,7,8 - 2 runs on each gpu\n2    | 4,9 - 1 run on each gpu, queue finishes\n<\/code><\/pre>\n<p>Does anyone know why this could be happening or have I just implemented the dask scheduler wrong?<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Tracking source code that is a python package",
        "Question_link":"https:\/\/my.guild.ai\/t\/tracking-source-code-that-is-a-python-package\/816",
        "Question_created_time":1645779758913,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":145,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m very sorry if this is already documented.<br>\nthe scripts I run are all part of a python package I\u2019m working on, the packages are installed using conda with.<\/p>\n<p>pip install -e<\/p>\n<p>which makes a symbolic link from conda to my package\u2019s directory.<\/p>\n<p>When I run the experiment with guild it stores the source code of all the files in the package\u2013which is good. However, when I try to restart the run, the program starts by using the main function in my<br>\nguild sourcecode folder\u2013which is what I want-- but the moment it tries to use a module imported from its parent package it starts using code in the packages main directory instead of the version of that file saved by Guild. How could i get guild to use the files saved by guild?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-02-25T23:11:40.224Z",
                "Answer_body":"<p>Hello and welcome!<\/p>\n<p>Packages are not copied per run but rather used from the environment (shared across runs). If you upgrade a package in the environment and then restart a run that uses that package, the new version is used.<\/p>\n<p>From what I\u2019m hearing, you want a separate environment per run. Guild happens to do this for remote runs, but not for local. I think this would be a good feature though as it provides a higher level of isolation and insulates restarts from any package changes.<\/p>\n<p>As a workaround, you could run your operations over ssh+localhost using the <code>--remote<\/code> option. Something like this:<\/p>\n<pre><code class=\"lang-yaml\"># ~\/.guild\/config.yml\n\nremotes:\n  localhost:\n    type: ssh\n    host: localhost\n<\/code><\/pre>\n<pre><code class=\"lang-command\">guild run your_op --remote localhost\n<\/code><\/pre>\n<p>Since your project is structured under a package, this should work without issue.<\/p>\n<p>Running this way you\u2019ll get a copy of the environment per run. You can see this by running <code>guild open --path .guild<\/code> \u2014 look under <code>job-packages<\/code> and you\u2019ll see the required packages there. These are used for the environment when running the operation.<\/p>\n<p>This is a bit of a pain \u2014 to run with the remote operation \u2014 but I think it\u2019ll give you the isolation you\u2019re looking for.<\/p>\n<p>Let me know if this makes sense and how it goes if you try it.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-02-26T11:19:00.858Z",
                "Answer_body":"<p>Thanks Garrett. I will need to have a look at the documentation for the --remote option. although it sounds like it will solve my problem.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remote connection error with jump host",
        "Question_link":"https:\/\/my.guild.ai\/t\/remote-connection-error-with-jump-host\/807",
        "Question_created_time":1644268231237,
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":311,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nmy institution has recently changed the configuration of our remote workstations.<\/p>\n<p>Now the connection goes through a jump host, and we cannot use a ssh pair here. I have a proxy configured, so manually I connect to the workstation with \u2018ssh [workstation]\u2019. The jump host requires a password on every connection, followed by an app authentication. The workstation has a ssh pairing with my local machine, so I only have to login to the jump host. That\u2019s the policy, and cannot be changed.<\/p>\n<p>I have successfully manged to run a guild check on that remote. I have configured a training script, config files etc. so that it all runs smoothly locally.<\/p>\n<p>However, when I try to run the train operation on the remote, I get the following errors:<\/p>\n<pre><code>Initializing remote run\nPassword: \nCopying package\nPassword: \nConnection timed out during banner exchange\nrsync: connection unexpectedly closed (0 bytes received so far) [sender]\nrsync error: unexplained error (code 255) at io.c(235) [sender=3.1.3]\nTraceback (most recent call last):\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/bin\/guild\", line 8, in &lt;module&gt;\n    sys.exit(main())\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/main_bootstrap.py\", line 40, in main\n    _main()\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/click\/core.py\", line 1128, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/click\/core.py\", line 1053, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/click\/core.py\", line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/click\/core.py\", line 1395, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/click\/core.py\", line 754, in invoke\n    return __callback(*args, **kwargs)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run.py\", line 649, in run\n    run_impl.main(args)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 1514, in main\n    _dispatch_op(S)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 1610, in _dispatch_op\n    _dispatch_op_cmd(S)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 1797, in _dispatch_op_cmd\n    _confirm_and_run(S)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 1874, in _confirm_and_run\n    _run(S)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 2075, in _run\n    _run_remote(S)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/run_impl.py\", line 2082, in _run_remote\n    remote_impl_support.run(_remote_args(S))\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/commands\/remote_impl_support.py\", line 125, in run\n    run_id = remote.run_op(**_run_kw(args))\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/remotes\/ssh.py\", line 243, in run_op\n    remote_run_dir = self._init_remote_run(tmp.path, opspec, restart)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/remotes\/ssh.py\", line 265, in _init_remote_run\n    self._copy_package_dist(package_dist_dir, remote_run_dir)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/remotes\/ssh.py\", line 330, in _copy_package_dist\n    ssh_util.rsync_copy_to(\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/site-packages\/guild\/remotes\/ssh_util.py\", line 129, in rsync_copy_to\n    subprocess.check_call(cmd)\n  File \"\/home\/bleporowski\/anaconda3\/envs\/marvel\/lib\/python3.8\/subprocess.py\", line 364, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['rsync', '-vr', '-e', \"ssh -oConnectTimeout=10 -o 'ProxyCommand ssh -oConnectTimeout=100  -W %h:%p [user]@[jumphost]'\", '\/tmp\/guild-remote-stage-ahx9az7p\/', '[user]@[workstation]:~\/anaconda3\/envs\/time-gop\/.guild\/runs\/5d5d24d410c648f897630ef102538a1e\/.guild\/job-packages\/']' returned non-zero exit status 255.\n<\/code><\/pre>\n<p>I\u2019m curious about two things:<\/p>\n<ul>\n<li>Why do I have to login twice, once after \u2018Initializing remote run\u2019 log, and then again after \u2018Copying package\u2019 log?<\/li>\n<li>I have set up my remotes in the guild\/config.yml to have a timeout of 100 seconds for both the jump host and the second step connection. However, from the trace it seems that the guild\/config.yml timeout is not properly read?<\/li>\n<\/ul>\n<p>This is the guild\/config.yml:<\/p>\n<pre><code>remotes:\n [remote-name]:\n  type: ssh\n  host: [workstation]\n  proxy: ssh -oConnectTimeout=100 -W %h:%p [user]@[jump host]\n  connect-time: 100\n  user: [user]\n  conda-env: ~\/anaconda3\/envs\/time-gop  \n  init: source ~\/anaconda3\/etc\/profile.d\/conda.sh | guild -H ~\/projects\/protime-gop\n<\/code><\/pre>\n<p>the obvious reason would be that the connection times out, as per the error log. However, the config timeout value doesn\u2019t seem to actually change the value invoked with the remote command.<\/p>\n<p>Have I made a mistake while creating my guild\/config.yml? Or it is a bug? Or maybe some other reason?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-02-07T21:20:05.193Z",
                "Answer_body":"<p>Can you try running <code>rsync<\/code> from your local system to the jump host? We should replicate the problem outside of Guild.<\/p>\n<p>You\u2019re being asked for password auth multiple times because Guild can establish multiple ssh connections over the course of a run command (e.g. ssh, rsync, ssh, etc.) If you can cache the auth session for the jumphost to avoid the multiple challenges, that would be ideal.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-02-07T21:41:22.391Z",
                "Answer_body":"<p>Connecting with rsync to the workstation, with the following command, works without errors:<\/p>\n<pre><code>rsync guild.yml [user]@[workstation]:\n<\/code><\/pre>\n<p>and the file is uploaded to the workstation.<\/p>\n<p>Interestingly, while ssh and guild require logging in to the jump host, rsync seems to bypass that somehow, and I copy the file from my local machine to the workstation without password prompt and authorization. I have very limited knowledge in this area, but I think it\u2019s a bit weird.<\/p>\n<p>Running the same command with the jumphost:<\/p>\n<pre><code>rsync guild.yml [user]@[jump host]:\n<\/code><\/pre>\n<p>gives no errors, and again I do not have to login. However, this time the file is not copied to the jump host.<\/p>\n<p>Edit:<br>\nI believe that the issues is really this part of the command that guild sends:<\/p>\n<pre><code>subprocess.CalledProcessError: Command '['rsync', '-vr', '-e', \"ssh -oConnectTimeout=10\n<\/code><\/pre>\n<p>It seems to me that with the multiple authorizations that guild requires, those 10 seconds are too short. But as I mentioned before, setting connect-time in the guild config doesn\u2019t seem to influence the \u2018oConnectTimeout\u2019 parameter.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-02-08T21:30:32.772Z",
                "Answer_body":"<p>Are you seeing a delay of 10 seconds or more when you run rsync manually? This would be an easy fix if it\u2019s just a matter of bumping up the timeout value.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-02-09T09:06:04.855Z",
                "Answer_body":"<p>When using rsync manually, no. Probabably because somehow it caches\/avoids authorisation, so there is no real possibility for delay.<\/p>\n<p>When running on remote from Guild, everytime I\u2019m prompted for the password I have to wait until the authorization app fires, and then authorize on my phone. The error occurs every time on the second password prompt, after \u2018copying package\u2019, hence my suspicion that the 10 second timeout here is to blame.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-02-10T16:58:47.995Z",
                "Answer_body":"<p>Ah that makes sense. I\u2019d be curious if you can get the run to complete by bumping this timeout to at least let you auth and get past your current blocker.<\/p>\n<p>The real solution is to fix the auth problem. This is likely an environment difference between the shell you\u2019re using to run the commands manually and the OS process that Guild is using to run the same commands. It\u2019d be nice to know how the system is caching the auth state from your shell.<\/p>\n<p>For the temporary workaround (getting a higher timeout), you can set the <code>connect-timeout<\/code> attribute of the remote to something like 60.<\/p>\n<pre><code class=\"lang-yaml\">remotes:\n  your-remote:\n    connect-timeout: 100\n<\/code><\/pre>\n<p>One problem though - there\u2019s a bug in the current release where that value isn\u2019t passed along to one of the rsync calls. I just committed a fix for this to the master branch in GitHub. If you run Guild from source, you\u2019ll get this fix.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"WinError 1314 when trying to do a grid search",
        "Question_link":"https:\/\/my.guild.ai\/t\/winerror-1314-when-trying-to-do-a-grid-search\/800",
        "Question_created_time":1642757463278,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":612,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nI\u2019m having trouble when trying to do a search with guild on a Windows 10 machine.<\/p>\n<p>I took the example code fromt the tutorial<\/p>\n<pre><code>import numpy as np\n\n# Hyperparameters\nx = 0.1\nnoise = 0.1\n\n# Simulated training loss\nloss = (np.sin(5 * x) * (1 - np.tanh(x ** 2)) + np.random.randn() * noise)\n\nprint(\"loss: %f\" % loss)\n<\/code><\/pre>\n<p>I\u2019m running it from console with<\/p>\n<pre><code>guild run test.py x=\"[1,0,-1]\"\n<\/code><\/pre>\n<p>When executing i get an error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File \"c:\\users\\x\\appdata\\local\\programs\\python\\python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\users\\x\\appdata\\local\\programs\\python\\python38\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_main.py\", line 41, in &lt;module&gt;\n    main()\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_main.py\", line 27, in main\n    batch_util.handle_trials(batch_run, trials)\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 73, in handle_trials\n    _run_trials(batch_run, trials)\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 135, in _run_trials\n    trial_runs = _init_trial_runs(batch_run, trials)\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 144, in _init_trial_runs\n    return [init_trial_run(batch_run, trial) for trial in trials]\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 144, in &lt;listcomp&gt;\n    return [init_trial_run(batch_run, trial) for trial in trials]\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 149, in init_trial_run\n    _link_to_trial(batch_run, run)\n  File \"C:\\Users\\x\\AppData\\Roaming\\Python\\Python38\\site-packages\\guild\\batch_util.py\", line 168, in _link_to_trial\n    os.symlink(rel_trial_path, trial_link)\nOSError: [WinError 1314] A required privilege is not held by the client.\n\n '..\\\\749cba372c474a1598aac11e2d4fb902' -&gt; 'C:\\\\Users\\\\x\\\\Anaconda3\\\\.guild\\\\runs\\\\045f73f210fb463f814f3334fd30825d\\\\749cba372c474a1598aac11e2d4fb902'\n<\/code><\/pre>\n<p>I don\u2019t have administrator permissions on the machine and I\u2019m probably not going to get them.<\/p>\n<p>Installing it via pip with --User flag doesnt fix it, either.<\/p>\n<p>Can I fix this somehow without having to run as admin?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-02-02T20:06:07.651Z",
                "Answer_body":"<p>Hello! Unfortunately Guild requires symbolic link permissions. If you can\u2019t run as Admin you\u2019ll need to get those permissions. That\u2019s a pain I realize \u2014 I wish this was easier. I would reach out to your system admin to get those setup.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Date\/Datetime flags in YAML file are not recognized",
        "Question_link":"https:\/\/my.guild.ai\/t\/date-datetime-flags-in-yaml-file-are-not-recognized\/798",
        "Question_created_time":1642615429696,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":134,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have set up a YAML file with the flags for my single operation. When I run the guild run command, all flags get imported except for date and datetime flags. Will I have to write them as strings and parse them into dates myself on my main script?<\/p>\n<p>Contents of my YAML file:<\/p>\n<pre><code>N_LEADS: 30\nWINDOW_RANGE: [-395, -1]\nLAST_EOM_TRAIN: 2019-12-31\nLEAD_RANGE: [-60, -50]\nN_ESTIMATORS: 2\nEOM_PRED_BENCH: 2021-07-31 00:00:00\nAS_OF_PRED_BENCH: 2021-06-01 00:00:00\n<\/code><\/pre>\n<p>What shows up when running the guild run command:<\/p>\n<pre><code>You are about to run main\n  LEAD_RANGE: -60 -50\n  N_ESTIMATORS: 2\n  N_LEADS: 30\n  WINDOW_RANGE: -395 -1\n<\/code><\/pre>\n<p>Thank you for your help!<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Stage trials error",
        "Question_link":"https:\/\/my.guild.ai\/t\/stage-trials-error\/741",
        "Question_created_time":1627609081354,
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":275,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019ve tested the <code>--stage-trials<\/code> feature with <code>queues<\/code> today, all worked great. But now I call <code>guild run op--staged-trials<\/code>, and check with <code>guild runs<\/code>, some runs are staged, others show errors<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/8fee18f78b819bce49fcc791997addfc1beed81c.png\" data-download-href=\"\/uploads\/short-url\/kxgoN75AKZNvWS4wd90nbgU9u0I.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/8fee18f78b819bce49fcc791997addfc1beed81c.png\" alt=\"image\" data-base62-sha1=\"kxgoN75AKZNvWS4wd90nbgU9u0I\" width=\"690\" height=\"175\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/8fee18f78b819bce49fcc791997addfc1beed81c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">753\u00d7192 5.41 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>A minute later I try <code>guild runs<\/code> again, and all runs show as <code>error<\/code> without me having done anything. What could cause the staged trials to flip to errors all of a sudden? This always happens now.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/3e9499c087f43e99cf0b7df8049e6a1fdd03a241.png\" data-download-href=\"\/uploads\/short-url\/8VBYFfkCYF3cwNgAMfGh4A2J561.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/3e9499c087f43e99cf0b7df8049e6a1fdd03a241.png\" alt=\"image\" data-base62-sha1=\"8VBYFfkCYF3cwNgAMfGh4A2J561\" width=\"690\" height=\"176\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/3e9499c087f43e99cf0b7df8049e6a1fdd03a241_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">757\u00d7194 5.21 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-07-30T17:29:23.645Z",
                "Answer_body":"<p>I believe I was able to fix this. After running <code>ps -u username<\/code>, I found there were some zombie <code>guild<\/code> and <code>python<\/code> processes still running. After killing them, the staging immediately worked again. This may or may not be related to me using <code>queue<\/code> the day before. I did stop them with <code>guild stop -Fo queue<\/code>, but it may not have completely killed the processes.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-14T16:58:07.631Z",
                "Answer_body":"<p>Yeah that sounds like a queue that is still running \u2014 cleaning up the errant processes is the right solution there.<\/p>\n<p>Guild uses runs to track these queue processes \u2014 this is why they\u2019re run as runs and not some other Guild process, which would otherwise disappear from view when run. Runs are all represented on disk (the run dir) and tied to OS processes via pid and lock files. This is standard operating procedure for process orchestration.<\/p>\n<p>Guild could use some housekeeping functions, for example, scanning for orphaned processes and providing a way to forceably stop them.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-15T18:08:22.833Z",
                "Answer_body":"<p>Yeah I think some sort of automatic housekeeping would be great as this seems to be a common issue. Thanks!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Running jobs show as errors on cluster",
        "Question_link":"https:\/\/my.guild.ai\/t\/running-jobs-show-as-errors-on-cluster\/746",
        "Question_created_time":1628278406504,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":262,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Not sure if this is a bug or a feature request, but here is the issue: I stage a bunch of jobs on computer 1, part of a cluster with a shared file system. When I call <code>guild runs<\/code> on any computer in the cluster, it will properly show all staged files. If I start a queue on computer 1 it will promptly launch the first staged job:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/48c319be5e838f51786c86a2f2ff3699552b8cdd.png\" data-download-href=\"\/uploads\/short-url\/anGnutFiNKGSAB3mEKYpbp9fAgR.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/48c319be5e838f51786c86a2f2ff3699552b8cdd.png\" alt=\"image\" data-base62-sha1=\"anGnutFiNKGSAB3mEKYpbp9fAgR\" width=\"690\" height=\"15\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/48c319be5e838f51786c86a2f2ff3699552b8cdd_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1095\u00d725 1.94 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>If I then log into computer 2, the running job will show as error:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/9464fe7e0aaa6cccbf30dbc317d508cb5ec6718f.png\" data-download-href=\"\/uploads\/short-url\/laL2L6avIgccXVOeb1x78OHbgIf.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/9464fe7e0aaa6cccbf30dbc317d508cb5ec6718f.png\" alt=\"image\" data-base62-sha1=\"laL2L6avIgccXVOeb1x78OHbgIf\" width=\"690\" height=\"25\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/9464fe7e0aaa6cccbf30dbc317d508cb5ec6718f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1158\u00d743 3.29 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Why would it show as error instead of just \u201crunning\u201d?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-01-14T16:34:14.284Z",
                "Answer_body":"<p>Guild determines if a run is \u201crunning\u201d by looking at the pid file and checking for a running pid. There are two major problems here:<\/p>\n<ul>\n<li>A run terminated in a way that leaves its pid file (e.g. power loss, SIGKILL, etc) can later show up as \u201crunning\u201d when that pid is recycled<\/li>\n<li>When checking status on a shared file system, the local process sees a different list of pids<\/li>\n<\/ul>\n<p>Guild needs to differentiate remote runs from local when checking this status. To get actual bona fide status, Guild needs an interface to the remote system, which it has, but this requires a <code>guild pull<\/code> or <code>guild sync<\/code> op before running <code>guild runs<\/code>.<\/p>\n<p>We\u2019ll take a look at this for either 0.7.5 or 0.8. Thanks for the report and sorry for the super long response time!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-15T18:05:50.123Z",
                "Answer_body":"<p>No worries, and thanks for the explanation!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to combine flags from multiple operations in pipelines to enable parameter searches across multiple operations?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-to-combine-flags-from-multiple-operations-in-pipelines-to-enable-parameter-searches-across-multiple-operations\/328",
        "Question_created_time":1598537665027,
        "Question_answer_count":8,
        "Question_score_count":2,
        "Question_view_count":759,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Let say I have 2 operations preprocessing and training.<br>\nEach has a series of flags that I want to do a hyper parameter search over.<br>\nHere is a rough idea of what my operations would look like<\/p>\n<pre><code>preprocessing:\n  flags:\n    a:\n    b:\ntraining:\n  flags:\n    c:\n    d:\n<\/code><\/pre>\n<p>Neglecting the practicality of this scenario, I want to run my preprocessing operation every time I run train.  Is there a way to achieve this with pipelines or a similar method?  I know I could do<\/p>\n<pre><code>mypipeline:\n  flags:\n    a: [1,2,3]\n    b: [4,5,6]\n    c: [12,13,14]\n    d: [15,16,17]\n  steps:\n    - preprocessing a=${a} b=${b}\n    - train c=${c} d=${d}\n<\/code><\/pre>\n<p>and this would solve my problem, but when both operations have a lot of parameters it would end up requiring a lot of copying and pasting between the pipeline and operation flags.  Is there a better\/more efficient way to achieve this?  I basically want the pipline to \u201cinherit\u201d the flags of the steps its performing if possible.  The documentation seems to hint at something like this<\/p>\n<aside class=\"quote no-group\" data-username=\"guildai\" data-post=\"1\" data-topic=\"197\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/guildai\/40\/103_2.png\" class=\"avatar\"><a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197\/1\">Guild File Reference<\/a>\n<\/div>\n<blockquote>\n<p>You can include references to step flag values as needed to pass through user-specified values.<\/p>\n<\/blockquote>\n<\/aside>\n<p>But when I create a pipeline with no flags and attempt to pass a flag which is defined by one of the steps I get an error saying that the flag does not exists.  Is what I am trying to do possible with Guild?<\/p>\n<p>Thanks.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-08-28T00:12:51.361Z",
                "Answer_body":"<p>I started to think the copy\/paste solution wouldn\u2019t actually solve my problem because I also needed an additional run that I could only run once before <em>preprocessing<\/em> and <em>train<\/em>.  Since it is outside the pipeline my steps cannot access it without <em>isolate-runs<\/em>.  However this requires using the run: operation attribute in my step<\/p>\n<pre><code>steps:\n  - run: preprocessing\n    isolate-runs: False\n    flags: \n      a:\n      b:\n<\/code><\/pre>\n<p>vs<\/p>\n<pre><code>steps:\n  - preprocessing a=${a} b=${b}\n<\/code><\/pre>\n<p>There is no way to transfer the pipeline flags to the step flags as far as I know.  However it turns out you can do this instead.<\/p>\n<pre><code>steps:\n  - run: \"preprocessing a=${a} b=${b}\"\n    isolate-runs: False\n<\/code><\/pre>\n<p>I found this by accident and couldn\u2019t find anything regarding it in the documentation.  I figured I would leave it here incase someone has a similar issue.  A reference to where this behavior is mentioned would be helpful.<\/p>\n<p>edit: corrected third guild file bit<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-28T14:05:05.017Z",
                "Answer_body":"<p>In this case, you can pass the steps flag values along this way:<\/p>\n<pre><code class=\"lang-yaml\">steps:\n  - run: preprocessing\n    flags:\n      a: ${a}\n      b: ${b}\n<\/code><\/pre>\n<p>Though what you\u2019ve done is also fine (note in your example you\u2019ve left off the <code>$<\/code> in the flag ref - I know what you meant <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=9\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"> )<\/p>\n<p>I\u2019ll reply to your previous post separately.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-28T14:08:41.275Z",
                "Answer_body":"<p>Unfortunately you have to duplicate the flag defs for the pipeline operation. This is on the near term road map to be addressed.<\/p>\n<p>How many flags are you rolling up to the pipeline op?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-29T23:59:03.533Z",
                "Answer_body":"<p>Right now I have around 10 and could potentially use more in the future.<br>\nBeing able to access the step flags from the pipeline would defiantly help a lot.<\/p>\n<p>As another solution I tried using <em>$include<\/em> and was also having issues.  I made two configs for train and preprocessing and then included both in the pipeline<\/p>\n<pre><code>    run_train:\n      flags:\n        $include: preprocessing-flags\n        $include: train-flags\n      steps:\n        - run: preprocessing\n          flags:\n          a: ${a}\n          b: ${b}\n        - train\n          flags:\n          c: ${c}\n          d: ${d}\n<\/code><\/pre>\n<p>but it only detected the flags for the last $include attribute.  In this case train-flags.  Can only one $include be used or am I possibly doing something wrong?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-30T11:32:01.022Z",
                "Answer_body":"<p>Provide a list for the <code>$include<\/code> attr:<\/p>\n<pre><code class=\"lang-yaml\">run_train:\n  flags:\n    $include:\n      - preprocessing-flags\n      - train-flags\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-30T13:56:45.173Z",
                "Answer_body":"<p>Thanks, that did it.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-31T16:44:08.205Z",
                "Answer_body":"<p>Is this still on the roadmap?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-14T16:16:17.697Z",
                "Answer_body":"<p>It is - sorry this is indeed taking too long to get in. Looking at this for the next major release (0.8) along with DvC integration, generalized run query support (there\u2019s an excellent PR waiting for merge related to tags but I want to see generalized flexible query support across all attrs).<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"TensorBoard Hparm Parallel Coordinate View Problem",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-hparm-parallel-coordinate-view-problem\/753",
        "Question_created_time":1629491848267,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m having an issue with the TensorBoard Hparm Parallel Coordinate View. It seems to be duplicated the axes on the lower half.<\/p>\n<p>This happens when I make a new project and just follow the get-started.ipynb file.<\/p>\n<p>I\u2019m using a Mac and Safari browser, and here are the versions info:<\/p>\n<pre><code>guild_version:             0.7.3\ntensorboard_version:       2.6.0\n<\/code><\/pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb.jpeg\" data-download-href=\"\/uploads\/short-url\/oDDDcjhGMAurXRar09EHL2ltw3p.jpeg?dl=1\" title=\"Screen Shot 2021-08-20 at 4.24.55 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb_2_517x336.jpeg\" alt=\"Screen Shot 2021-08-20 at 4.24.55 PM\" data-base62-sha1=\"oDDDcjhGMAurXRar09EHL2ltw3p\" width=\"517\" height=\"336\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb_2_517x336.jpeg, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb_2_775x504.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb_2_1034x672.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/acaf444ae1126cf7cdea1a9aa3bebec91d370cbb_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2021-08-20 at 4.24.55 PM<\/span><span class=\"informations\">1920\u00d71249 181 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Additionally, when I remove one of the variables, the entire plot grows at least 30% in size. Is there a way I can keep this constant.<\/p>\n<p>Lastly, runs in a notebook don\u2019t seem to save an output.index file and guild view throws an error from this.<\/p>\n<p>Thanks for the help! Let me know if I need to share anything else.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-09-04T00:50:55.914Z",
                "Answer_body":"<p>Can you share a minimum working example?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-14T16:06:42.952Z",
                "Answer_body":"<p>In this case you\u2019re running TensorBoard as provided by Google (Guild doesn\u2019t monkey patch TensorBoard or otherwise modify it. I find TB to have a number of strange sizing issues. The underlying framework Google uses is <em>very<\/em> complex and hard to contribute to\/fix so our strategy has been to \u201ctake it as is and be forever grateful\u201d <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=11\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>Things I try in these cases:<\/p>\n<ul>\n<li>\n<p>First and foremost, after modifying Guild runs (new runs, deleted runs) restart TensorBoard \u2014 the dynamic behavior works well in most cases but in some cases TB just doesn\u2019t handle new data well. A restart often cleans that up.<\/p>\n<\/li>\n<li>\n<p>Play around with browser zoom - sometimes that balances out strange font and UI sizing.<\/p>\n<\/li>\n<li>\n<p>Play with resizing the browser window.<\/p>\n<\/li>\n<\/ul>\n<p>I wish I could give you a better answer here \u2014 I\u2019m basically blaming TensorBoard for all of this. But in this case, Guild really isn\u2019t involved beyond laying out the TB log dir.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to specify flags-import: all with remote runs",
        "Question_link":"https:\/\/my.guild.ai\/t\/unable-to-specify-flags-import-all-with-remote-runs\/749",
        "Question_created_time":1628617693656,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":325,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have an operation in that looks like this<\/p>\n<pre><code>  operations:\n    prepare:\n      main: operations.prepare\n      flags-import: all\n      output-scalars: off\n<\/code><\/pre>\n<p>which has a number of different flags specified with argparse in <code>operations\/prepare.py<\/code>. I can run it just fine locally, but when I try run it remote with any flag set I get <code>guild: unsupported flag &lt;flag&gt;<\/code> for every flag. I can run it remote as long as I don\u2019t set flags. Also, if I specify the flags explicitly in <code>guild.yml<\/code> like this it works fine:<\/p>\n<pre><code>    prepare:\n      main: operations.prepare\n      flags:\n        &lt;flag1&gt;:\n        &lt;flag2&gt;:\n      output-scalars: off\n<\/code><\/pre>\n<p>Any idea what might be wrong here?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-09-04T00:52:17.414Z",
                "Answer_body":"<p>Can you share how the args are specified in your Python script?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-14T15:54:17.054Z",
                "Answer_body":"<p>Sorry for getting back to this so late. I can\u2019t recreate this. To better track resolution I created a <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/318\">GitHub issue<\/a>.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Tensorboard FileNot found error on Windows-10, guild-0.7.3.dev1",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-filenot-found-error-on-windows-10-guild-0-7-3-dev1\/569",
        "Question_created_time":1616632467283,
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":421,
        "Question_has_accepted_answer":false,
        "Question_body":"<pre><code>C:\\Users\\sarat.chinni\\Codes_sequencing\\biobench\\sandbox\\Sarat\\incorp_basecalling (feature\/incorp_basecalling -&gt; origin)\n(biobench-thMxqAli) \u03bb guild tensorboard\nPreparing runs for TensorBoard\nERROR: error removing C:\\Users\\SARAT~1.CHI\\AppData\\Local\\Temp\\guild-tensorboard-88wle55x: [WinError 3] The system cannot find the path specified: \"C:\\\\Users\\\\SARAT~1.CHI\\\\AppData\\\\Local\\\\Temp\\\\guild-tensorboard-88wle55x\\\\d83224a9 dnn_classifier_train 2021-03-24 17_18_48 batch_size=32 dense_activation=relu dense_units='128 128' drop_out=0.0 fileName=black_and_white_1sec.pickle l2_decay=0.001 num_epochs=100 seed=42 verify_saved=no\"\nTraceback (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2288.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2288.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sarat.chinni\\.virtualenvs\\biobench-thMxqAli\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 94, in _run_tensorboard\n    monitor.run_once(exit_on_error=True)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\run_util.py\", line 89, in run_once\n    self._refresh_logdir(runs)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\run_util.py\", line 97, in _refresh_logdir\n    self.refresh_run_cb(run, path)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 275, in f\n    return _refresh_run(run, run_logdir, state)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 281, in _refresh_run\n    _refresh_tfevent_links(run, run_logdir, state)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 292, in _refresh_tfevent_links\n    _init_tfevent_link(tfevent_path, link, run, state)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 304, in _init_tfevent_link\n    util.ensure_dir(link_dir)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\util.py\", line 74, in ensure_dir\n    os.makedirs(d)\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2288.0_x64__qbz5n2kfra8p0\\lib\\os.py\", line 213, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2288.0_x64__qbz5n2kfra8p0\\lib\\os.py\", line 223, in makedirs\n    mkdir(name, mode)\nFileNotFoundError: [WinError 3] The system cannot find the path specified: \"C:\\\\Users\\\\sarat.chinni\\\\AppData\\\\Local\\\\Temp\\\\guild-tensorboard-88wle55x\\\\d83224a9 dnn_classifier_train 2021-03-24 17_18_48 batch_size=32 dense_activation=relu dense_units='128 128' drop_out=0.0 fileName=black_and_white_1sec.pickle l2_decay=0.001 num_epochs=100 seed=42 verify_saved=no\"\n\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-10-05T10:11:10.537Z",
                "Answer_body":"<p>I have the same problem. I think the issue is that the filename created by guild ai is too long! Shortening the filename by shortening the names of the operations and hyperparameters is really unsatisfactory. Does anybody know another workaround\/solution?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-06T15:28:08.271Z",
                "Answer_body":"<p>Try running with a label for your operation <code>guild run OP --label MY_EXPERIMENT<\/code><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-07T13:06:23.774Z",
                "Answer_body":"<p>That works <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-14T16:38:53.107Z",
                "Answer_body":"<p>Ugh, I\u2019m glad you\u2019re able to work around that but that\u2019s an awful bug in Guild. I\u2019ll take a look at this now and see if there\u2019s a solution that doesn\u2019t require you to hack the filename this way!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-13T16:49:03.675Z",
                "Answer_body":"<p>This issue should be fixed in the forthcoming 0.7.5. There was a bug that wasn\u2019t correctly truncating the filename.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Staged pipeline steps not given labels",
        "Question_link":"https:\/\/my.guild.ai\/t\/staged-pipeline-steps-not-given-labels\/791",
        "Question_created_time":1641249403629,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":220,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019ve noticed that guild applies that labels I give to pipelines to each pipeline step when the pipeline stage is ran directly.  However, if I instead stage the pipeline operation and then run the staged pipeline operation this doesn\u2019t happen.  Instead only the pipeline operation receives label, not the steps of the pipeline.   For example, lets say my <code>guild.yml<\/code> is given as follows.  The contents of <code>train.py<\/code> and <code>test.py<\/code> aren\u2019t really important.<\/p>\n<pre><code>- operations:\n    mypipeline:\n        steps:\n            - train\n            - test\n\n    train:\n        sourcecode:\n            dest: .\n            select: train.py\n        exec: \"python train.py\"\n\n    test:\n        sourcecode:\n            dest: .\n            select: test.py\n        exec: \"python test.py\"\n<\/code><\/pre>\n<p>If I run <code>guild run mypipeline -y --label debug<\/code> I get<\/p>\n<pre><code>[1:b21131b7]   test                                      2022-01-03 17:27:55  completed  debug\n[2:8dd06463]   train                                     2022-01-03 17:27:55  completed  debug\n[3:092f43f2]   mypipeline                                2022-01-03 17:27:54  completed  debug\n<\/code><\/pre>\n<p>But if I run <code>guild run mypipeline -y --label debug --stage &amp;&amp; guild run queue -y<\/code> I get the following.  Note that only the <code>mypipeline<\/code> operation receives the label <code>debug<\/code> while the step operations receive no label.<\/p>\n<pre><code>[1:5b2c8b79]   test                                      2022-01-03 17:28:48  completed\n[2:85ae374c]   train                                     2022-01-03 17:28:47  completed\n[3:a0dc7ef1]   mypipeline                                2022-01-03 17:28:46  completed   debug\n<\/code><\/pre>\n<p>Note that similar commands like <code>guild run mypipeline -y --label debug --stage &amp;&amp; guild run --start $(guild select 1)<\/code> have the same effect.<\/p>\n<p>Is this intended behavior? If so how can I make it so that the steps of the staged pipeline operation receive the same label as the pipeline operation that started them?  Thanks<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2022-01-03T22:40:22.107Z",
                "Answer_body":"<p>This looks like a bug. Guild stores run params in staged runs and my guess is that it\u2019s either not storing this particular param or not using it when starting the staged run. I\u2019ll take a look.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-07T18:24:30.642Z",
                "Answer_body":"<p>This is fixed in master and will be available in the next release (a pre-release will go out later today with this - look for 0.7.5.dev3).<\/p>\n<p>Thanks for the detailed report!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2022-01-07T20:08:14.313Z",
                "Answer_body":"<p>Good to hear, thanks.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Flag not recognized: No module named --batch_size",
        "Question_link":"https:\/\/my.guild.ai\/t\/flag-not-recognized-no-module-named-batch-size\/770",
        "Question_created_time":1633451275980,
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":634,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi there,<br>\nout of the blue my guild script now claims:<\/p>\n<blockquote>\n<p>guild: No module named --batch_size<\/p>\n<\/blockquote>\n<p>Batch size is a flag, as defined in the guild.yml<\/p>\n<pre><code>flags:\n        batch_size:\n          default: 32\n<\/code><\/pre>\n<p>The batch size is an argument of the arg parser<\/p>\n<pre><code>        parser.add_argument(\"--batch_size\", type=int, default=8)\n<\/code><\/pre>\n<p>I don\u2019t understand the error message, as it worked before and it is not a syntactic error:<\/p>\n<pre><code>You are about to run model:train\n  batch_size: 32\n<\/code><\/pre>\n<p>Do you have an idea what could have gone wrong?<br>\nI did not change the code and call guild with <code>guild run train<\/code>.<\/p>\n<p>Previously I had a similar error, where the <code>accelerator<\/code> flag of the PyTorch Lightning Trainer wouldn\u2019t be recognized (same error message).<\/p>\n<p>Thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-10-05T22:56:54.560Z",
                "Answer_body":"<p>Looks like the indentation of the flags specification might be wrong.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-08T09:48:52.350Z",
                "Answer_body":"<p>Thanks for replying. The configuration file is correct when comparing to the <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197\">file reference<\/a>. I noticed that the <code>--batch_size<\/code> flag is the first one, alphabetically. If I add another flag that comes first, then the <code>batch_size<\/code> flag is recognized.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-08T12:48:58.143Z",
                "Answer_body":"<p>I was able to narrow it down further: if i specify the gpus as a comma separated string, then the error occurs:<\/p>\n<pre><code class=\"lang-yaml\">gpus:\n  # works\n  default: 0\n  # does not work\n  default: 0,1\n  # does not work either\n  default: \"0,1\"\n<\/code><\/pre>\n<p>How should I encode this?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-08T15:00:11.379Z",
                "Answer_body":"<p>Have a look at the <a href=\"https:\/\/my.guild.ai\/t\/flags\/42#flag-value-decoding\">flag value decoding<\/a> documentation and <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#flag-arg-split\">arg-split<\/a>.<\/p>\n<p>Note that guild has  <a href=\"https:\/\/my.guild.ai\/t\/command-run\/146#control-visible-gpus\">integrated support<\/a> for choosing GPUs.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-13T15:57:00.864Z",
                "Answer_body":"<p>There are a few mysterious things here that I\u2019m scratching my head over. Do you have a small example I can run to reproduce this?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-14T08:49:54.574Z",
                "Answer_body":"<p>Hi,<\/p>\n<p>I was able to resolve some\/the issue:<\/p>\n<ol>\n<li>use <code>arg-switch: yes<\/code> for switches. This caused some errors without indicating the culprit, e.g.<\/li>\n<\/ol>\n<pre><code class=\"lang-yaml\">      flags:\n        deterministic:\n          default: yes\n          arg-switch: yes\n<\/code><\/pre>\n<ol start=\"2\">\n<li>use <code>arg-split<\/code> for nargs, e.g.<\/li>\n<\/ol>\n<pre><code class=\"lang-yaml\">        pos_weight:\n          default: \"50 1\"\n          arg-split: yes\n<\/code><\/pre>\n<ol start=\"3\">\n<li>*PyTorch Lightning\u2019s (PL) ArgParser does tricky things:<br>\nFor <a href=\"https:\/\/pytorch-lightning.readthedocs.io\/en\/1.4.9\/advanced\/multi_gpu.html\" rel=\"noopener nofollow ugc\">multi-gpu flags<\/a> they <a href=\"https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/563\" rel=\"noopener nofollow ugc\">do not use nargs<\/a> instead you use strings.<\/li>\n<li>It was difficult for me to find out about the <code>arg-split<\/code> option and I\u2019m still not sure if my output is a string or an integer.<\/li>\n<\/ol>\n<p>In PL you can select a specific GPU with <code>--gpus \"3\"<\/code> and select the first three GPUs with <code>--gpus 3<\/code>. Two specific GPUs can be selected with <code>--gpus \"1,3\"<\/code>, for e.g. GPU 1 and 3. <a href=\"https:\/\/pytorch-lightning.readthedocs.io\/en\/latest\/advanced\/multi_gpu.html\" rel=\"noopener nofollow ugc\">In the latest PL Version<\/a> they dropped the <code>--gpus \"3\"<\/code> option; instead you can use <code>--gpus \"3,\"<\/code> to target a specific GPU.<\/p>\n<h1>\n<a name=\"example-1\" class=\"anchor\" href=\"#example-1\"><\/a>Example<\/h1>\n<h2>\n<a name=\"installation-2\" class=\"anchor\" href=\"#installation-2\"><\/a>Installation<\/h2>\n<pre><code>$ pip install torch==1.9.1+cu111 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n$ pip install pytorch-lightning lightning-bolts guildai\n<\/code><\/pre>\n<h2>\n<a name=\"filestructure-3\" class=\"anchor\" href=\"#filestructure-3\"><\/a>Filestructure<\/h2>\n<pre><code>test-guild\n| guild.yaml\nL test_guild\n    | __init__.py\n    L  main.py\n<\/code><\/pre>\n<h2>\n<a name=\"mainpy-4\" class=\"anchor\" href=\"#mainpy-4\"><\/a>main.py<\/h2>\n<pre><code class=\"lang-python\">import os\nfrom argparse import ArgumentParser\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, random_split\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom pl_bolts.datasets import DummyDataset\n\nclass LitAutoEncoder(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def training_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('train_loss', loss)\n        return loss\n        # --------------------------\n\n    def validation_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('val_loss', loss)\n        # --------------------------\n\n    def test_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('test_loss', loss)\n        # --------------------------\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\nif __name__ == \"__main__\":\n\n    train = DummyDataset((1, 28, 28), (1,))\n    train = DataLoader(train, batch_size=32)\n    val = DummyDataset((1, 28, 28), (1,))\n    val = DataLoader(val, batch_size=32)\n    test = DummyDataset((1, 28, 28), (1,))\n    test = DataLoader(test, batch_size=32)\n\n    # init model\n    ae = LitAutoEncoder()\n\n    # Initialize a trainer\n    parser = ArgumentParser()\n    parser = pl.Trainer.add_argparse_args(parser)\n    args = parser.parse_args()\n    trainer = pl.Trainer.from_argparse_args(args)\n\n    # Train the model \u26a1\n    trainer.fit(ae, train, val)\n<\/code><\/pre>\n<h2>\n<a name=\"guildyaml-5\" class=\"anchor\" href=\"#guildyaml-5\"><\/a>guild.yaml<\/h2>\n<pre><code>- model: test-guild\n  sourcecode:\n    - \"*.py\"\n  operations:\n    train:\n      main: test_guild.main\n      flags:\n        max_steps:\n          default: 2000\n        gpus:\n          default: \"1,3\"\n<\/code><\/pre>\n<p>Now, <code>python test_guild\/main.py --gpus \"1,3\" --max_steps=2000<\/code> and <code>guild run main<\/code> are identical.<\/p>\n<p>I really like the experiment tracking capabilities of guild.ai; getting pytorch lightning and guild.ai working together is sometimes tough but worth it.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-14T16:35:41.279Z",
                "Answer_body":"<p>This thread covers a number of different issues. One that\u2019s highlighted by <a class=\"mention\" href=\"\/u\/alessandro\">@Alessandro<\/a>\u2019s latest post (thank you for the terrific detail!) is that Guild wasn\u2019t handling some of the PyTorch Lightning CLI args on flags import. This has been fixed and will be available in the next release (0.7.5). You can test the functionality in the pre-release version 0.7.5.dev2. <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\/pytorch-lightning\">This example<\/a> shows the new behavior.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-15T15:41:41.980Z",
                "Answer_body":"<p>That looks awesome! Great work!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild run can't find module\/relative import",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-run-cant-find-module-relative-import\/735",
        "Question_created_time":1626396791066,
        "Question_answer_count":18,
        "Question_score_count":0,
        "Question_view_count":1075,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hello,<\/p>\n<p>I have my project structured as follows:<\/p>\n<pre><code>classification\/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 coordinate_conv.py\n\u251c\u2500\u2500 cosine_annealing.py\n\u251c\u2500\u2500 data_generator.py\n\u251c\u2500\u2500 deformable_conv.py\n\u251c\u2500\u2500 drop_block.py\n\u251c\u2500\u2500 nnet_blocks.py\n\u251c\u2500\u2500 infer.py\n\u251c\u2500\u2500 model.py\n\u251c\u2500\u2500 train.py\n\u2514\u2500\u2500 utils.py\n<\/code><\/pre>\n<p>Where every python script is a module, and arguments are passed with <code>argparse<\/code>. So I would run <code>train.py<\/code> as<\/p>\n<pre><code>python -m classification.train \\\n    --model-name model \\\n    --train-data path\/to\/train\/data \\\n    --cycles 3 \\\n    --no-require-clean\n<\/code><\/pre>\n<ol>\n<li>\n<p>If I run <code>guild run<\/code> outside the <code>classification<\/code> folder, having configured <code>guild.yml<\/code> according to the documentation (tried both: <code>main: classification.train<\/code> and <code>main: classification\/train<\/code>), <code>guild<\/code> tells me it cannot find the <code>classification.train<\/code> module.<\/p>\n<\/li>\n<li>\n<p>if I run <code>guild run train.py<\/code> from inside the <code>classification<\/code> folder, <code>guild<\/code> tells me it cannot do relative imports with no known parent package (expected I guess).<\/p>\n<\/li>\n<\/ol>\n<p>So how would I run the training script with the above project structure, argparse, and relative imports?<\/p>\n<p>Thanks!<br>\n-fernando<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-07-16T13:37:53.493Z",
                "Answer_body":"<p>Hey, could also provide the <code>guild.yml<\/code> file and the error messages you get?<\/p>\n<p>Maybe somebody more knowledgeable will have a better answer; here is my suggestion though:<\/p>\n<p>I\u2019d start simple and build up from that =&gt; start with just the two following files and nothing more:<br>\nguild.yml:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  main: classification.train\n<\/code><\/pre>\n<p>classification\/train.py:<\/p>\n<pre><code class=\"lang-python\">print(\"hello world\")\n<\/code><\/pre>\n<p>now <code>guild ops<\/code> should show you the <code>train<\/code> operation and <code>guild run train<\/code> should succeed.<br>\nAnd if this works then you can work towards finding the issue you have <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-16T16:49:44.390Z",
                "Answer_body":"<p>Thanks <a class=\"mention\" href=\"\/u\/matejnikl\">@MatejNikl<\/a> , both the <code>guild.yml<\/code> and error message are as I described above:<\/p>\n<pre><code>&gt; cat guild.yml\ntrain:\n  main: classification.train\n<\/code><\/pre>\n<pre><code>&gt; guild run train\nYou are about to run train\nContinue? (Y\/n)\nWARNING: Skipping potential source code file \/Users\/fspaolo\/dev\/sentinel-1-ee\/classification\/detections_test.csv because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.\nWARNING: Found more than 100 source code files but will only copy 100 as a safety measure. To control which files are copied, define 'sourcecode' for the operation in a Guild file.\nguild: No module named classification.train\n<\/code><\/pre>\n<p>Maybe due to the 100 sourcecode limit my modules are not being copied (which it wouldn\u2019t make sense as the module is being specified in <code>guild.yml<\/code>\u2026 it should be the priority code to copy)?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-16T18:28:07.939Z",
                "Answer_body":"<p>You have to specify the <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197\">sourcecode.<\/a><\/p>\n<pre><code>train:\n  sourcecode:\n    - '*.py'\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-16T23:22:19.750Z",
                "Answer_body":"<p>I did figure that out actually (which seems counter intuitive as I am telling guild the path to my python code\/module\u2026 so all python scripts in there should be \u201csourcecode\u201d by default, no?).<\/p>\n<p>Then I ran into another problem. My code is calling a <code>git<\/code> command at execution. But guild is running the code from another (temporary) folder, which is not a git repository\u2026 so I get an error: \u201cthe current directory is not a git repo\u201d\u2026 I then <em>change my code<\/em> and disable the git command\u2026 and get another error: <code>PathNotFoundError: nothing found at path ''<\/code>. Is this because the path to the data is relative and the code is being ran from a different directory? If so, many things will break obviously. Do I have to figure out what breaks myself and come up with a workaround?<\/p>\n<p>I am not doing anything out of the ordinary here. My project structure is standard, using modules, relative imports, argparse and git. So how do I run this<\/p>\n<pre><code>python -m classification.train \\\n    --model-name model \\\n    --train-data path\/to\/train\/data \\\n    --cycles 3 \\\n    --no-require-clean\n<\/code><\/pre>\n<p>with guild (without significant code changes)?<\/p>\n<p>Thanks.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-17T01:43:34.120Z",
                "Answer_body":"<p>You have to specify your data as a guild resource.<\/p>\n<p>What is your use case for your git command?<\/p>\n<p>EDIT: To debug your guild run folder try \u2018guild ls\u2019 to show what is being placed in the runs folder.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-19T14:08:17.681Z",
                "Answer_body":"<p>From <a href=\"https:\/\/my.guild.ai\/t\/runs\/40\">Guild Docs \u2013 Runs<\/a>:<\/p>\n<blockquote>\n<p>Runs serve as a unit of <em>reproducibility<\/em> .<\/p>\n<\/blockquote>\n<p>For that reason each time you do <code>guild run<\/code> it copies your code under a <code>run directory<\/code> made specifically for that run before guild runs the code.<br>\nGulid does this for example so that you have a snapshot of the adhoc code that resulted e.g. in some nice results and you can actually go back to this code and see what you did there.<\/p>\n<p>This run directory becomes the working directory your script will resolve all relative paths to. And since you haven\u2019t told guild to also copy there the train data and the path you specified is relative, the train data are simply not there.<\/p>\n<p>You can either specify the train data as an absolute path just to try if that works. But I would suggest to include your train data in the guild ecosystem somehow as well. At least as a <a href=\"https:\/\/my.guild.ai\/t\/dependencies\/162\">project file dependency<\/a> or probably rather as a <a href=\"https:\/\/my.guild.ai\/t\/dependencies\/162#run-files\">run file dependency<\/a> as your train data perhaps are result as some prepare-train-data operation, aren\u2019t they?<\/p>\n<p>Maybe you could go through the <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\/dependencies\" rel=\"noopener nofollow ugc\">dependencies example<\/a> to get a better understanding of how they work.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-19T16:09:36.020Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/copah\">@copah<\/a> <a class=\"mention\" href=\"\/u\/matejnikl\">@MatejNikl<\/a> Some comments:<\/p>\n<p>Use case for Git:<\/p>\n<ul>\n<li>Before <code>training<\/code> it forces the user to commit the current state of the repository<\/li>\n<li>At run time the code logs the commit state of the repo for that specific run<\/li>\n<\/ul>\n<p>Changing to absolute paths seems to work. Now, this is not the best idea as the whole package\/project is self contained with relative paths. We run this project from different virtual machines on different user environments. So paths like <code>\/User\/username\/project<\/code> will break.<\/p>\n<p>Copying the data to the guild run directly is prohibitive (and bad practice). Our data is huge, data should not be moved around, and we load data from both local machine and cloud storage depending on the situation. The cloud data takes days just to generate.<\/p>\n<p>The whole guild advertisement is that you don\u2019t need to modify your code\/strategy, isn\u2019t it? We implement all Python\/ML best practices in our projects. And we do large-scale ML experiments (with several petabytes of satellite data). So question is: can Guild handle this scenario <em>only<\/em> with the addition of a configuration file? If so, is there a full example somewhere?<\/p>\n<p>Thanks,<br>\n-fernando<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-19T16:27:55.449Z",
                "Answer_body":"<p>Some quick comments:<\/p>\n<p>Guild logs the git sha for you automatically.<\/p>\n<p>Guild resources can be symbolic links, so relative paths still work. Look up the resources docs.<\/p>\n<p>Having a dirty git repo is not an issue under guild since guild copies the entire source code for each run. There is a command called \u2018guild diff RUN_ID \u2014working\u2019 where you can see the difference between the run and working directory source code.<\/p>\n<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a> wrote a great comment on why having to commit your code for each experiment is huge pain. I\u2019ll se if I can find it later. Guild doesn\u2019t enforce this, which makes experimenting faster and easier.<\/p>\n<p>I\u2019ll see if I can write a full example later when I have more time.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-27T18:52:05.177Z",
                "Answer_body":"<p>Thanks <a class=\"mention\" href=\"\/u\/copah\">@copah<\/a> and <a class=\"mention\" href=\"\/u\/matejnikl\">@MatejNikl<\/a> for your excellent answers!<\/p>\n<p><a class=\"mention\" href=\"\/u\/fspaolo\">@fspaolo<\/a> you\u2019re running into some common issues that are frustrating but there are some good reasons for them. That\u2019s an annoying answer I know but bear with me\u2026<\/p>\n<p>ML projects almost always run operations within a source directory. Results are either logged to some project-local directory that\u2019s included in <code>.gitignore<\/code> or logged to a temporary location. E.g. a lot of the examples you run into from Google log under <code>\/tmp<\/code>.<\/p>\n<p>Guild goes out of its way to prevent this. Guild runs from an empty directory, which is the run directory. Each run gets its own directory. Guild copies source code to that directory along with any other files or directories that you need. Guild does its best to guess the source code. It does not even attempt to guess other files\/directories.<\/p>\n<p>You\u2019ve already seen how to control the source code spec. Guild could certainly spend a bit more time figuring out exactly what your source code is but it could still miss important source related files. So it does a light weight test and includes safeguards to prevent copying very large or very many files. If this light weight test doesn\u2019t work, you need to specify the config, as you\u2019ve done.<\/p>\n<p>Regarding data, you want this:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  requires:\n    - file: data\n      target-type: link\n<\/code><\/pre>\n<p>Guild links by default to directories but this will change in the future, so it\u2019s best to explicitly configure it that way.<\/p>\n<p>As for the Git repo status, as was mentioned, Guild does record the git commit for you. If there are changed files, Guild indicates the latest commit with an asterisk. Importantly, as was also mentioned, Guild copies the source code and <em>runs the operations using that code<\/em> and not the code in your project. This is an important feature as it lets you freely modify your project source code when operations are still running without impacting those operations. It also lets you stage several operations, each with their own source code changes.<\/p>\n<p>If this approach doesn\u2019t work, please let us know and we can consider other approaches.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-05T02:44:54.190Z",
                "Answer_body":"<p>Thanks <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a> <a class=\"mention\" href=\"\/u\/copah\">@copah<\/a> <a class=\"mention\" href=\"\/u\/matejnikl\">@MatejNikl<\/a> for elaborating.<\/p>\n<p>I\u2019m still unable to obtain a working example with minimal code modification. For example:<\/p>\n<p>This doesn\u2019t \u200bwork<\/p>\n<pre><code>flags-dest: args\nflags:\n  train-data: data\/file.ext\n<\/code><\/pre>\n<p>but this does<\/p>\n<pre><code>flags-dest: args\nflags:\n  train-data: \/Users\/username\/dev\/project\/package\/data\/file.ext\n<\/code><\/pre>\n<p>Paths cannot be relative within a Python package then? (I\u2019ve tried linking to both the full and relative data paths)<\/p>\n<p>Another problem is that the code generates a few directories to save some stuff (e.g. model weights, log files). Here again I have a problem with the paths:<\/p>\n<p>What should be<\/p>\n<pre><code>untracked\/runs\/20210804T185741\/wts\/weights.wts\n<\/code><\/pre>\n<p>becomes<\/p>\n<pre><code>\/Users\/username\/anaconda3\/envs\/envname\/.guild\/runs\/43bba88802c241ed81bc70bc7d95cf52\/.guild\/sourcecode\/untracked\/runs\/20210804T185741\/wts\/weights.wts\n<\/code><\/pre>\n<p>How can I keep my original path?<\/p>\n<p>Finally, is there a way to capture a specific variable or a <code>print<\/code> statement within the code to be displayed in the terminal, say with <code>guild compare<\/code>? I would like to quickly search for a specific run, hit Enter and have this <em>information<\/em> displayed right in the terminal?<\/p>\n<p>An use case would be to get the full path to the weights, model or config file so I can copy-and-paste it as argument to my inference code (<em>without<\/em> having to search and open any files).<\/p>\n<p>Thanks!<br>\n-fernando<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-05T13:34:56.009Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/fspaolo\">@fspaolo<\/a><\/p>\n<p>You shouldn\u2019t use the <code>flags<\/code> attribute for specifying data resources.<\/p>\n<p>Here\u2019s an example on how to use the <code>resources<\/code> attribute to specify data dependencies via symbolic links:<\/p>\n<pre><code>- model: my_model_name\n  operations:\n    train:\n      flags:\n        model_name:\n          default: \"default_model_name\"\n      requires:\n        - prepared_data\n  resources:\n    prepared_data:\n      - file: data\/my_data_folder\n        target-type: link\n        target-path: data\/\n<\/code><\/pre>\n<p><code>guild<\/code> will link to the <code>data\/my_data_folder<\/code> in the new <code>guild<\/code> run folder and it will all work with relative paths.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-05T16:31:58.961Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/copah\">@copah<\/a><\/p>\n<p>I\u2019m confused now. The path to the data <em>and<\/em> indices files <em>are<\/em> arguments to the training code (parsed through <code>argparse<\/code>):<\/p>\n<pre><code>usage: train.py [-h] --model-name MODEL_NAME --train-data TRAIN_DATA\n                     --train-index TRAIN_INDEX [--cycles CYCLES]\n                     [--cfg-dir CFG_DIR] [--log-level LOG_LEVEL]\n                     [--no-require-clean]\n\ntrain.py: error: the following arguments are required: --train-data, --train-index\n<\/code><\/pre>\n<p>According to the documentation I should parse these command-line arguments as<\/p>\n<pre><code>flags-dest: args\n    flags:\n        arg1: myarg1\n        arg2: myarg2\n<\/code><\/pre>\n<p>\u2026or not?<\/p>\n<p>And what\u2019s <code>- prepared_data<\/code>? I can\u2019t get your example to work (it keeps showing the paths as empty strings <code>\"\"<\/code>).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-05T16:41:33.171Z",
                "Answer_body":"<p>This is my full <code>guild.yml<\/code><\/p>\n<pre><code>- model: classification\n  operations:\n    train:\n      main: classification.train\n      flags-dest: args\n      flags:\n        model-name: model\n        train-data: data\/detection_tiles_v1.zarr\n        train-index: data\/detection_tiles_v1_index.zarr\/train\/0\n        cycles: 3\n        no-require-clean: null\n      requires:\n        - prepared_data\n      sourcecode:\n        - '*.py'\n  resources:\n    prepared_data:\n      - file: data\/detection_tiles_v1.zarr\n      - file: data\/detection_tiles_v1_index.zarr\n        target-type: link\n        target-path: data\/\n<\/code><\/pre>\n<p>which shows<\/p>\n<pre><code>&gt; guild run train\nYou are about to run classification:train\n  cycles: 3\n  model-name: model\n  no-require-clean: yes\n  train-data: data\/detection_tiles_v1.zarr\n  train-index: data\/detection_tiles_v1_index.zarr\/train\/0\nContinue? (Y\/n)\n<\/code><\/pre>\n<p>but raises<\/p>\n<pre><code>zarr.errors.PathNotFoundError: nothing found at path ''\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-05T17:57:26.032Z",
                "Answer_body":"<p>It\u2019s difficult to debug without the code, but you might have to specify the <code>target-path<\/code> for the <code>data\/detection_tiles_v1.zarr<\/code> as well:<\/p>\n<pre><code>- model: classification\n  operations:\n    train:\n      main: classification.train\n      flags-dest: args\n      flags:\n        model-name: model\n        train-data: data\/detection_tiles_v1.zarr\n        train-index: data\/detection_tiles_v1_index.zarr\/train\/0\n        cycles: 3\n        no-require-clean: null\n      requires:\n        - prepared_data\n      sourcecode:\n        - '*.py'\n  resources:\n    prepared_data:\n      - file: data\/detection_tiles_v1.zarr\n        target-type: link\n        target-path: data\/ \n      - file: data\/detection_tiles_v1_index.zarr\n        target-type: link\n        target-path: data\/ \n<\/code><\/pre>\n<p>To debug file paths etc try run <code>guild ls RUN_ID<\/code> then you can see what the folder structure looks like from the guild folder.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-08-19T22:29:35.155Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/fspaolo\">@fspaolo<\/a><\/p>\n<p>Did it work for you?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-13T18:04:56.534Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/copah\">@copah<\/a><\/p>\n<p>Sorry for the late reply (got swamped with work)! Yes, it works so far. We are currently evaluating Guild with our ML pipelines (in order to find the \u201cright\u201d tool for our organization\u2019s needs). One of the challenges we have is managing\/tracking our complex data flow. We deal with large amounts of global satellite data from multiple sources, and need to be able to run (and track) the same ML code on both local and virtual machines (in the cloud). Any specific doc or discussion I could read on managing\/tracking multiple runs (with the same code and data source) on different machines?<\/p>\n<p>Thank you!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-13T19:03:23.275Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/fspaolo\">@fspaolo<\/a><\/p>\n<p>Have a look at this discussion: <a href=\"https:\/\/my.guild.ai\/t\/data-versioning\/210\" class=\"inline-onebox\">Data versioning<\/a><\/p>\n<p>We use a combination of DvC and guild, but will migrate to guild completely when support for DvC tracked files arrives.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-13T21:30:37.984Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/fspaolo\">@fspaolo<\/a>, Guild\u2019s current support this is similar in concept to the way git is designed \u2014 you push and pull data\/content (in Guild\u2019s case, runs) to and from machines based on your workflow. Like git, Guild doesn\u2019t have a central point of control. Instead you orchestrate your workflows from various Guild client installations.<\/p>\n<p>Unfortunately, workflows don\u2019t come \u201cout of the box\u201d with Guild. You need to do some wiring based on your organizational requirements. A common workflow is to pull from a source repo and distribute runs to various nodes using the <code>--remote<\/code> option with <code>guild run<\/code>. You can then use the <code>pull<\/code> command to collect the results across the various nodes.<\/p>\n<p>The alternative to this architectural approach is to use a separate orchestration tier that uses Guild to run operations and consolidates results (runs) itself. There are a bunch of these (e.g. Airflow, Kubeflow, Dask and Prefect, to some extent) \u2014 I imagine your organization has looked at some of these. In this case, Guild just becomes another job that\u2019s run by the scheduler.<\/p>\n<p>This advice is super high level and there\u2019s more to dig into. If you\u2019d like to get into the details, I\u2019d be curious to know a few things:<\/p>\n<ul>\n<li>Do you instantiate your VMs dynamically based on a job requirement, or do you have these VMs running and available across jobs?<\/li>\n<li>Are you using a workflow\/orchestration\/scheduler currently?<\/li>\n<li>Are you using any sort of CI\/CD (e.g. Jenkins) tool to pull from source control and run jobs?<\/li>\n<\/ul>\n<p>As <a class=\"mention\" href=\"\/u\/copah\">@copah<\/a> mentioned, Guild has a forthcoming support for DvC, which will let you pull resources from DvC, which is a way to synchronize on versioned data. You should be able to start using Guild before that however, as Guild can grab resources from URLs (which DvC provides).<\/p>\n<p>You still have the somewhat complex problem of VM instantiation and job orchestration. Guild provides a specific facility for that (described at a high level above) but there are lots of other options. I\u2019d start with what your org is looking at and see how Guild can fit into that.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed",
        "Question_link":"https:\/\/my.guild.ai\/t\/operatornotallowedingrapherror-using-a-tf-tensor-as-a-python-bool-is-not-allowed\/739",
        "Question_created_time":1627001084083,
        "Question_answer_count":8,
        "Question_score_count":3,
        "Question_view_count":2143,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>When I try to run the mnist example I get the following:<\/p>\n<p>OperatorNotAllowedInGraphError: using a <code>tf.Tensor<\/code> as a Python <code>bool<\/code> is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-07-26T18:05:51.830Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/melnimr\">@melnimr<\/a> - this may have been resolved. What version of Guild are you using?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-27T17:48:05.864Z",
                "Answer_body":"<p>It is 0.7.3<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-27T18:14:00.519Z",
                "Answer_body":"<p>This would have been fixed in 0.7.4, which isn\u2019t generally available. However, you can install a pre-release version this way:<\/p>\n<pre><code class=\"lang-command\">pip install --pre guildai\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-21T08:41:24.955Z",
                "Answer_body":"<p>I have the same issue even I execute this command.  Is there a solution or not yet please ?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-21T13:26:16.832Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/diiib98\">@DiiiB98<\/a> and welcome!<\/p>\n<p>Just to make sure I\u2019m looking at the same example, could you give me a link to what you\u2019re running here?<\/p>\n<p>Thanks!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-21T16:00:00.484Z",
                "Answer_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2.jpeg\" data-download-href=\"\/uploads\/short-url\/lBBNsbWugxXYuJ9NPVLbsZNwW4i.jpeg?dl=1\" title=\"resulat\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2_2_547x500.jpeg\" alt=\"resulat\" data-base62-sha1=\"lBBNsbWugxXYuJ9NPVLbsZNwW4i\" width=\"547\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2_2_547x500.jpeg, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2_2_820x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2_2_1094x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/976e03124f469e8d8257ae3e1e0b364c332ec0e2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">resulat<\/span><span class=\"informations\">1920\u00d71753 327 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nYou find in this link the files used and this is the result after runninf the gridsearch with this command.<br>\n<a href=\"https:\/\/drive.google.com\/drive\/folders\/19GGoQ08vQDrBKdswh8R6gcSvKTQOd6an?usp=sharing\" rel=\"noopener nofollow ugc\">Files<\/a><br>\nThank you for your answer<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-11-18T19:45:51.369Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a> I\u2019m hitting this as well. Is this the same issue: <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/278\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Summary plugins not working with TensorFlow 2 \u00b7 Issue #278 \u00b7 guildai\/guildai \u00b7 GitHub<\/a><\/p>\n<p>if so, what\u2019s the easiest way to disable the plugins?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-12-08T02:25:46.203Z",
                "Answer_body":"<p>I just committed a <a href=\"https:\/\/github.com\/guildai\/guildai\/commit\/5ead7bd931178a6cafb8ad7687486a3319ecd28e\">change<\/a> to address this \u2014 these plugins are not handling the TF 2.2+ API changes atm and so in this case they at least don\u2019t break the operation.<\/p>\n<p>Look for this in the next pre-release (probably tomorrow) or officially in 0.7.5.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Redirecting Standard Output",
        "Question_link":"https:\/\/my.guild.ai\/t\/redirecting-standard-output\/774",
        "Question_created_time":1635368459517,
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":542,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have a guild file with the following lines:<\/p>\n<pre><code>train:\n  description: Train a model\n  exec: python -m model.utils.run &gt; logfile\n<\/code><\/pre>\n<p>The train command works correctly, however it does not redirect the standard output to \u201clogfile\u201d. I am able to see the standard output in the \u201cLog\u201d tab of the guild view server, but this also contains the output of the tqdm progress bar used in the code, which is not ideal.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-11-04T12:09:49.003Z",
                "Answer_body":"<p>Using logger and tqdm with guild needs some tweaking becuase guild take over your logger steam handler.<\/p>\n<p>In short you need to use a handler like this:<\/p>\n<pre><code class=\"lang-python\">class TqdmLoggingHandler(logging.Handler):\n    def __init__(self, level=logging.NOTSET, verbose=False):\n        super().__init__(level)\n        self.verbose = verbose\n\n    def emit(self, record):\n        try:\n            msg = self.format(record)\n            if self.verbose:\n                tqdm.write(msg)\n                self.flush()\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)\n\n\n_stream_handler = TqdmLoggingHandler(verbose=verbose)\n_stream_handler.setFormatter(formatter)\nlogger.addHandler(_steam_handler)\n<\/code><\/pre>\n<p>This should correctly direct your <code>tqdm.write<\/code> to the log file. The progress-bar on the other hand is a little bit tricky as basically you need to flush the progress bar to STDOUT but not to logger stream handler. See  <a href=\"https:\/\/stackoverflow.com\/questions\/38543506\/change-logging-print-function-to-tqdm-write-so-logging-doesnt-interfere-wit\" rel=\"noopener nofollow ugc\">this<\/a> for more details.<br>\nI would recommend simply use software like <code>lnav<\/code> to filter them out.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-11-15T17:04:10.774Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/teracamo\">@teracamo<\/a> thanks for the example!<\/p>\n<p><a class=\"mention\" href=\"\/u\/ap000\">@ap000<\/a> there are couple issues in play here. You would typically not redirect output to a file (e.g. <code>logfile<\/code>) because Guild does this by default. You can find the operation output (joined stdout and stderr streams) in <code>.guild\/output<\/code> under each run directory.<\/p>\n<p>You can view this file using:<\/p>\n<pre><code class=\"lang-command\">guild cat --output [RUN]\n<\/code><\/pre>\n<p>However, as you\u2019ve pointed out, Guild has a <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/54\">known issue<\/a> when run with <code>tqdm<\/code> .<\/p>\n<p>The workaround is to disable Guild\u2019s output capture by setting the env variable <code>NO_RUN_OUTPUT=1<\/code>. In this case you can capture output yourself using file redirection.<\/p>\n<p>You want something like this:<\/p>\n<pre><code class=\"lang-yaml\">test-workaround:\n  exec: bash -c \"python -m model.utils.run 2&gt;&amp;1 | tee logfile\"\n  env:\n    NO_RUN_OUTPUT: 1\n<\/code><\/pre>\n<p>This turns off Guild\u2019s run output capture and directs your script output to <code>logfile<\/code>. The <code>2&gt;&amp;1<\/code> is optional, and includes stderr output in the result.<\/p>\n<p>However! For this to work, you need to install <code>0.7.5.dev1<\/code>, which has a fix to support this.<\/p>\n<p>For anyone interested in more details (e.g. to work on this issues hint hint <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=10\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"> ) refer to the corresponding <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/54-logging-with-tqdm-results-in-jumbled-output\">issue resolution doc<\/a>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-11-16T14:08:13.758Z",
                "Answer_body":"<p>Thank you both for your responses! I was able to work around the tqdm issue with the NO_RUN_OUTPUT flag as an immediate solution and will look into using the provided TqdmLoggingHandler in the future. Thanks so much!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Import flags from dependency",
        "Question_link":"https:\/\/my.guild.ai\/t\/import-flags-from-dependency\/765",
        "Question_created_time":1631895678247,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":238,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have the following guild yaml structure:<\/p>\n<pre><code>prepare-config:\n    main: model.utils.prepare-config\n    sourcecode: \n        root: \/home\/\n        dest: .\n        select: '*.py'\n\ntrain:\n    main: model.utils.run\n    sourcecode: \n        root: \/home\/\n        dest: .\n        select: '*.py'\n    requires:\n      - operation: prepare-config\n        select: prepare-config-output.json\n        target-type: copy\n        target-path: .\n    flags-dest: config:prepare-config-output.json\n    flags-import: all\n<\/code><\/pre>\n<p>In the run directory for the \u201ctrain\u201d operation I can see that the \u201cprepare-config-output.json\u201d file has been copied successfully. However when I perform \u201cguild run train --help-op\u201d I don\u2019t see any of the parameters in \u201cprepare-config-output.json\u201d. I am even able to run \u201cguild run train\u201d successfully using the parameters in \u201cprepare-config-output.json\u201d, but it seems as though the flags are not imported and I cant use something like \u201cguild run train.py lr=[0.1, 0.01, 0.001]\u201d for example.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-09-21T13:38:35.094Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ap000\">@ap000<\/a> and welcome!<\/p>\n<p>I\u2019m not able to recreate this. I created an <a href=\"https:\/\/github.com\/guildai\/issue-resolution\/tree\/master\/308-flags-not-being-imported-from-config-files\">issue resolution doc<\/a> to run your example. I\u2019m running 0.7.4.rc1.<\/p>\n<p>That\u2019s a pre-release that you can install using <code>pip install --pre --upgrade guildai<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-10-04T03:12:02.221Z",
                "Answer_body":"<p>My guess is your second operation never saw the json thrown by the first operation because you ran them separately.<\/p>\n<p>To run two operations as a pipeline, you need to define a third operation \u201cpipeline\u201d:<\/p>\n<pre><code class=\"lang-yaml\">op1:\n  ...\n\nop2:\n ...\n\npipeline:\n  flags:\n    op1flags: \"default\"\n    op2flags: \"default\"\n  steps: \n    - op1 op1flags=${op1flags}\n    - op2 op2flags=${op2flags}\n<\/code><\/pre>\n<p>If you run <code>op1<\/code> and <code>op2<\/code> in two separate commands, they are strangers to each others unless you specify which run id of the upstream operation to use, like this:<\/p>\n<pre><code class=\"lang-bash\">guild run op1 ...\nguild runs\n# [1:xxxop1id] ...\nguild run op2 op1=[xxxop1id]\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Specifying different target types for the same operation",
        "Question_link":"https:\/\/my.guild.ai\/t\/specifying-different-target-types-for-the-same-operation\/761",
        "Question_created_time":1631302538330,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":303,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am trying to link and copy different files from the same operation resource in my guild stage.  It seems that specifying an operation multiple times only results in the last operation being used.  Here is an example that matches what I\u2019m trying to do where a operation train is used as a resource.  The file model.pth is linked while config.json is copied.<\/p>\n<pre><code>test:\n  exec: \"python test.py\"\n  requires:\n    - operation: train\n      select:\n        - file: model.pth\n          target-type: link\n        - file: config.json\n          target-type: copy\n<\/code><\/pre>\n<p>Is there any way to achieve this kind of functionality? Thanks<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-09-17T02:15:07.061Z",
                "Answer_body":"<p>You need to do it through a pipeline, or manually assign the run ID yourself.<\/p>\n<pre><code class=\"lang-yaml\">op1:\n  exec: func_1\n  flag: \n    a: 1E5\n    b: 1E-5\n  requires: ...\n\nop2:\n  exec: func_2\n  flag: \n    b: 1E-5\n    c: ''\n  require: \n    - operation: op1\n      select: '[folder or file generated by op1]'\n\npipeline:\n  flag:\n    a: 1E5\n    b: 1E-5\n    c: ''\n  steps:\n    - op1 a=${a} b=${b}\n    - op2 b=${b} c=${c}\n<\/code><\/pre>\n<p>This is covered in <a href=\"https:\/\/my.guild.ai\/t\/pipelines\/163\">https:\/\/my.guild.ai\/t\/pipelines\/163<\/a>.<\/p>\n<p>Also, note that your <code>exec<\/code> attribute should assign the moduel\/function name rather than the command to execute for python scripts. This lead to funny behavior if you have multiple <code>argparsers<\/code> in the script.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Wrong conversion of default args leads to errors in Pytorch Lightning",
        "Question_link":"https:\/\/my.guild.ai\/t\/wrong-conversion-of-default-args-leads-to-errors-in-pytorch-lightning\/759",
        "Question_created_time":1630583418088,
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":558,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi!<br>\nI wanted to test guild.ai in combination with pytorch lightning.<br>\nHowever I am facing the problem that default arguments are not omitted but used with an empty string <code>''<\/code>.<br>\nSmall Example:<\/p>\n<p><code>main.py<\/code><\/p>\n<pre><code>from argparse import ArgumentParser\n\n\ndef main(args):\n    model = LightningModule()\n    trainer = Trainer.from_argparse_args(args)\n    trainer.fit(model)\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser()\n    parser = Trainer.add_argparse_args(parser)\n    args = parser.parse_args()\n\n    main(args)\n<\/code><\/pre>\n<p>Running <code>guild run main.py deterministic=true<\/code> doesn\u2019t call <code>python main.py --deterministic true<\/code> but <code>python main.py --deterministic 1  --auto_select_gpus '' --benchmark '' ...<\/code>.<br>\nIn this case Pytorch Lightning throws <code>main.py: error: argument --auto_select_gpus: invalid str_to_bool value: ''<\/code><br>\nHow can I either suppress default flags from being sent or modify the parsing?<br>\nThe <code>str_to_bool<\/code> function is defined <a href=\"https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/bb4887368c7210ba950078e91cd7ae8b512fcaee\/pytorch_lightning\/utilities\/parsing.py#L44\" rel=\"noopener nofollow ugc\">here<\/a>, the <code>add_argparse_args<\/code> <a href=\"https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/a1264a68502ee40fe3ab1cbc2794583d3a56b989\/pytorch_lightning\/utilities\/argparse.py#L159\" rel=\"noopener nofollow ugc\">here<\/a> and the Trainer <a href=\"https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/75350938ca646efc0b4bac432ba2d5d4676662bb\/pytorch_lightning\/trainer\/trainer.py#L101\" rel=\"noopener nofollow ugc\">here<\/a>.<\/p>\n<p>Thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-09-02T14:01:53.668Z",
                "Answer_body":"<p>Can you provide your <code>guild.yaml<\/code> file?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-02T14:18:28.668Z",
                "Answer_body":"<p>I don\u2019t have one.<br>\nInstead of running: <code>python main.py --deterministic true<\/code> I ran <code>guild run main.py deterministic=true<\/code><\/p>\n<p>You can reproduce this with:<\/p>\n<pre><code class=\"lang-python\">import os\nfrom argparse import ArgumentParser\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import MNIST\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom pl_bolts.datasets import DummyDataset\n\ntrain = DummyDataset((1, 28, 28), (1,))\ntrain = DataLoader(train, batch_size=32)\nval = DummyDataset((1, 28, 28), (1,))\nval = DataLoader(val, batch_size=32)\ntest = DummyDataset((1, 28, 28), (1,))\ntest = DataLoader(test, batch_size=32)\n\nclass LitAutoEncoder(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def training_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('train_loss', loss)\n        return loss\n        # --------------------------\n\n    def validation_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('val_loss', loss)\n        # --------------------------\n\n    def test_step(self, batch, batch_idx):\n        # --------------------------\n        # REPLACE WITH YOUR OWN\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log('test_loss', loss)\n        # --------------------------\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\n\n# init model\nae = LitAutoEncoder()\n\n# Initialize a trainer\nparser = ArgumentParser()\nparser = pl.Trainer.add_argparse_args(parser)\nargs = parser.parse_args()\ntrainer = pl.Trainer.from_argparse_args(args)\n\n# Train the model \u26a1\ntrainer.fit(ae, train, val)\n<\/code><\/pre>\n<pre><code class=\"lang-bash\">pip install pytorch-lightning\npip install pytorch-lightning-bolts\npip install guildai\n<\/code><\/pre>\n<p>Now it works with:<br>\n<code>python main.py --deterministic=true --max_steps=4<\/code><br>\nBut not with:<br>\n<code>guild run main.py deterministic=true max_steps=4<\/code><\/p>\n<blockquote>\n<p>main.py: error: argument --auto_select_gpus: invalid str_to_bool value: \u2018\u2019<\/p>\n<\/blockquote>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-02T23:52:15.078Z",
                "Answer_body":"<p>I looked into this and you need to use the <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#flag-arg-switch\">arg-switch<\/a> feature of <code>guild<\/code>.<\/p>\n<p>Create a <code>guild.yaml<\/code> file like this:<\/p>\n<pre><code>- model: auto_encoder\n  source-code: \"*.py\"\n  operations:\n    train:\n      main: main\n      flags:\n        deterministic:\n          arg-switch: yes\n<\/code><\/pre>\n<p>You can now run<\/p>\n<pre><code>guild run auto_encoder:train deterministic=yes\nguild run auto_encoder:train deterministic=no\n<\/code><\/pre>\n<p>And it should be parsed correctly by <code>pytorch-lightning<\/code>.<\/p>\n<p>Note you don\u2019t have to specify all hyperparameters in your guild file since you can use <code>--force-flags<\/code>:<\/p>\n<pre><code>guild run auto_encoder:train deterministic=yes gradient_clip_val=0.1 --force-flags\n<\/code><\/pre>\n<p>I am not sure if you can do <code>arg-switch<\/code> from the CLI without specifying a <code>guild.yaml<\/code> file. Maybe <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>  knows.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-09-03T12:48:27.973Z",
                "Answer_body":"<p>Wow! Thanks a lot. It works perfectly.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild Init Errors on Windows 10",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-init-errors-on-windows-10\/751",
        "Question_created_time":1628886345302,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":263,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am working my way through the example files and have run into a bug where the guild init command fails.<\/p>\n<pre><code>You are about to initialize a Guild environment:\n  Location: C:\\Users\\{USER}\\repos\\ml_framework_testing\\guildai\\iris-svm\\venv\n  Name: iris-svm\n  Python interpreter: default\n  Use system site packages: no\n  Guild: 0.7.3\n  Python requirements:\n    .\\requirements.txt\n  Resource cache: shared\nContinue? (Y\/n) y\nInitializing Guild environment in C:\\Users\\{USER}\\repos\\ml_framework_testing\\guildai\\iris-svm\\venv\nCreating virtual environment\ncreated virtual environment CPython3.7.4.final.0-64 in 1341ms\n  creator CPython3Windows(dest=C:\\Users\\{USER}\\repos\\ml_framework_testing\\guildai\\iris-svm\\venv, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=C:\\Users\\joeyr\\AppData\\Local\\pypa\\virtualenv)\n    added seed packages: pip==21.2.3, setuptools==57.4.0, wheel==0.37.0\n  activators BashActivator,BatchActivator,FishActivator,PowerShellActivator,PythonActivator\nUpgrading pip\nInstalling Guild guildai==0.7.3\nFatal Python error: _Py_HashRandomization_Init: failed to get random numbers to initialize Python\n\nguild: Command '['C:\\\\Users\\\\{USER}\\\\repos\\\\ml_framework_testing\\\\guildai\\\\iris-svm\\\\venv\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', '--no-warn-script-location', 'guildai==0.7.3']' returned non-zero exit status 1.\n<\/code><\/pre>\n<p>Any idea what is going on here or how to fix it? I was getting an access denied error on the Upgrading pip line for a bit until I upgraded manually ahead of time with \u201cpython -m pip install --upgrade pip\u201d.<\/p>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Error while running gp optimizer for Hyperparameter optimization: Cannot find objective 'loss'",
        "Question_link":"https:\/\/my.guild.ai\/t\/error-while-running-gp-optimizer-for-hyperparameter-optimization-cannot-find-objective-loss\/679",
        "Question_created_time":1618193158528,
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":506,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use Guild to do hyperparameter optimization using the gp optimizer. The first three runs started using random initializations as expected. However, even after the 3rd run, it continues to perform random initializations. On examining the output, I noticed that the following information was posted:<\/p>\n<p>INFO: [guild] Random start for optimization (cannot find objective \u2018loss\u2019)<\/p>\n<p>Is this expected? Or am I missing something?<\/p>\n<p>I looked at the scalars using guild runs info and found that all the scalars that I am logging using Tensorboard are displayed correctly.<\/p>\n<p>I would appreciate any help in this matter.<\/p>\n<p>Thanks,<br>\nVishal<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-04-12T02:27:57.725Z",
                "Answer_body":"<p>By default the optimizers look for a scalar named \u2018loss\u2019 to minimize. If that\u2019s what you want, make sure that \u2018loss\u2019 shows up for the generated runs by running <code>guild runs info<\/code>. If you want to minimize (or maximize) a different scalar, specify its name with <code>--min<\/code> (or <code>--max<\/code>) for the run command.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-13T02:15:04.152Z",
                "Answer_body":"<p>Thanks. I used the --minimize and specified the scalar value that I was logging using TensorBoard and wanted to minimize as part of the hyperparameter optimization. The error disappeared as a result.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-13T16:59:45.066Z",
                "Answer_body":"<p>Great! You can specify this scalar in the Guild file so you don\u2019t need to remember to set it each time with the <code>run<\/code> command.<\/p>\n<pre><code class=\"lang-yaml\">op:\n  objective: &lt;name of scalar you want to minimize&gt;\n<\/code><\/pre>\n<p>If you want to maximize, use a negative sign (\u2019<code>-<\/code>\u2019) in front of the scalar name.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-19T20:22:16.828Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, I have a few follow-up questions for this topic.<br>\nI am trying to utilize this <em>specifying the scaler<\/em> functionality in a python script because my experiment does not have a \u2018loss\u2019 value to minimize, and I have gone through the Python API and couldn\u2019t find an example of it being used this way.<\/p>\n<p>So if I am able to specify it in the Guild File that solves one of the two issues!<br>\nThe bigger issue is where would this \u2018objective: &lt; scaler name &gt;\u2019 be inserted with\/alongside the <code>guild.run()<\/code> command in a python script?? Does it go inside the <code>guild.run()<\/code> and if so how is it specified?<\/p>\n<p>I know that for choosing an \u2018Optimizer\u2019 we can add the \u2018_optimizer=\u2019 argument inside the parentheses.<\/p>\n<p>Thanks in advance.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-27T18:12:02.345Z",
                "Answer_body":"<p>Specify the scalar that you want to either minimize or maximize using the <code>_minimize<\/code> or <code>_maximize<\/code> keyword argument to the <code>run()<\/code> function. Let\u2019s say you want to maximize the scalar <code>val_acc<\/code> (e.g. validation accuracy). Use this:<\/p>\n<pre><code class=\"lang-python\">from guild import ipy as guild\n\ndef train(lr, epochs):\n  for _ in range(epochs):\n    val_acc = _train_and_validate(lr)  # Example function\n    print(\"val_acc: %f\" % val_acc)\n\nguild.run(\n  train, \n  lr=guild.loguniform(1e-5, 1e-1),\n  epochs=10, \n  _optimizer=\"gp\", \n  _maximize=\"val_acc\", \n  _max_trials=10,\n  _opt_random_starts=2\n)\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild runs on remote not found",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-runs-on-remote-not-found\/738",
        "Question_created_time":1626996133100,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":252,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019ve setup a remote in the <code>guild.yml<\/code> file. No problem running <code>guild pull --remote server<\/code> and the like. But how does one run a remote op from the local computer? There must be something simple I\u2019m missing. Running:<\/p>\n<pre><code>guild run train --remote server\n<\/code><\/pre>\n<p>Always yields <code>guild: cannot find operation train<\/code>. This kind of makes sense, how would guild know the location of the ops on the remote? My <code>guild.yml<\/code> looks something like:<\/p>\n<pre><code>  server:\n    type: ssh\n    description: Remote servers\n    user: username\n    host: server.domain\n    conda-env: \/home\/path\/to\/anaconda3\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-07-26T18:08:50.040Z",
                "Answer_body":"<p>If you\u2019re running that command from a local directory containing the Guild file, Guild should see the operation. You can list the operations that Guild can see by running:<\/p>\n<pre><code class=\"lang-command\">guild operations\n<\/code><\/pre>\n<p>If you run the <code>train<\/code> operation remotely, Guild looks in the current directory and packages up what\u2019s needed remotely, copies that content to the remote server, and then runs the operation on that server.<\/p>\n<p>If you instead want to run an operation from a directory that\u2019s on a remote server, your only approach is to ssh to that server and run it from that directory. In that case you don\u2019t specify the <code>--remote<\/code> operation \u2014 you\u2019re already connected to the remote server and are running it locally there.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-27T17:04:00.056Z",
                "Answer_body":"<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"2\" data-topic=\"738\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<p>If you run the <code>train<\/code> operation remotely, Guild looks in the current directory and packages up what\u2019s needed remotely, copies that content to the remote server, and then runs the operation on that server.<\/p>\n<\/blockquote>\n<\/aside>\n<p>Ahhhh I see, this is the part I did not understand. Now it makes sense. Thanks!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Running multiple batches of an experiment with different hyperparameter flag values",
        "Question_link":"https:\/\/my.guild.ai\/t\/running-multiple-batches-of-an-experiment-with-different-hyperparameter-flag-values\/724",
        "Question_created_time":1624051984492,
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":364,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am trying to utilize the grid search capability of guild to run an experiment multiple times with different hyperparameter flag values in a python file for SVM on the iris dataset.<\/p>\n<p>My hyperparameter flags are defined as a dictionary:<br>\nhyperparam_dict = {\u2018kernel\u2019: \u2018linear\u2019, \u2018test_split\u2019: 0.1, \u2018random_seed\u2019: 2, \u2018degree\u2019: 4, \u2018gamma\u2019: 50} and I want to be able to run the experiment with various values for each hyperparameter to test the accuracy value of every combination of flag values\u2026 e.g \u2018test_split\u2019 = [0.1, 0.2, 0.3], \u2018degree\u2019= [1, 2, 3, 4], etc.<\/p>\n<p>When I follow the example from the get-started.ipynb:<br>\n_ = guild.run(train, x=[-0.5,-0.4,-0.3,-0.2,-0.1])<br>\nwith my code:<br>\nguild.run(main, hyperparam_dict[\u2018test_split\u2019] =  [0.1, 0.2, 0.3],) I am getting an error.<\/p>\n<p>Is there any way what I am trying to achieve, be done??<\/p>\n<p>Looking for any help to try and resolve this issue!<\/p>\n<p>Thank you.<\/p>\n<p>Original guild.yml file:<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/a15c24e93e41c11d4bd4960f978ec4c8b2a9631e.png\" alt=\"image\" data-base62-sha1=\"n1si1CVnP83aIsR6893PR5wXRVQ\" width=\"536\" height=\"425\"><\/p>\n<p>Notebook commands where I am trying to achieve running multiple runs of an experiment with three different  'test_split\" values to be tested.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/c66eda4f888723d0624bac1b6a69ef5d75f7a89c.png\" data-download-href=\"\/uploads\/short-url\/sjq2ufe4bGzrQn5kM5Fk1zyT0q8.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/c66eda4f888723d0624bac1b6a69ef5d75f7a89c.png\" alt=\"image\" data-base62-sha1=\"sjq2ufe4bGzrQn5kM5Fk1zyT0q8\" width=\"690\" height=\"197\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/c66eda4f888723d0624bac1b6a69ef5d75f7a89c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">727\u00d7208 9.91 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-06-25T04:25:58.675Z",
                "Answer_body":"<p>You should update the dict value before you call <code>guild.run<\/code>, i.e.<\/p>\n<pre><code class=\"lang-python\">hyperparm_dict['test_split'] = [.5, .4, .3]\nguild.run(main, **hyperparam_dict)\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-02T18:41:28.069Z",
                "Answer_body":"<p>You can also use this syntax:<\/p>\n<pre><code class=\"lang-python\">guild.run(main, test_split=[0.5, 0.4, 0.3], **hyperparam_dict)\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-07-19T16:37:54.364Z",
                "Answer_body":"<p>Thank you both for the reply, I was able to fix the issue and it is working properly now. The solution that worked ended up being updating the dictionary within the guild.yml file before the guild.run command is executed.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Flags are not being tracked\/captured during a guild run inside a docker container",
        "Question_link":"https:\/\/my.guild.ai\/t\/flags-are-not-being-tracked-captured-during-a-guild-run-inside-a-docker-container\/717",
        "Question_created_time":1622846349934,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":310,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am trying to execute an experiment.py file that is called upon in guild.yml. The guild.yml file contains 5 flags for an svm experiment on the iris dataset. When I execute \u2018guild run model:train\u2019 on my local machine in a terminal, there are no issues and the <code>flags<\/code> are properly captured in the \/.guild directory. However, when I execute the experiment in a Docker container, the flags are no longer being tracked by guild. Is there any way to debug this??<br>\nOr where in the source code are the flags picked up by guild to create the Flags file in \/.guild directory.<br>\nPlease help!<\/p>\n<p>guild.yml file:<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/9917a5497d13a1a0217004c62eaee40ae9117b5f.png\" alt=\"image\" data-base62-sha1=\"lQjIeUjvD969jrZdz9AUmi1LCwL\" width=\"542\" height=\"321\"><\/p>\n<p>terminal output display of what in inside the \/.guild directory: (notice flags is just an empty dictionary)<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/b0b0d9e9a6511673b88d4aa093dc95ca7a280c8d.png\" data-download-href=\"\/uploads\/short-url\/pd4W5283z3KfZvKgLj5qtTat1Pn.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/b0b0d9e9a6511673b88d4aa093dc95ca7a280c8d.png\" alt=\"image\" data-base62-sha1=\"pd4W5283z3KfZvKgLj5qtTat1Pn\" width=\"690\" height=\"75\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/b0b0d9e9a6511673b88d4aa093dc95ca7a280c8d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">960\u00d7105 4.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-06-11T10:00:31.793Z",
                "Answer_body":"<p>Hi<\/p>\n<p>Guild is saving all created files (e.g. new run directory with code, tensorboard summaries, etc.) into the \/root\/.guild and some things into the \/tmp (profiling files and some tensorboard stuff). Since you are running your guild code in docker because of this the guild is creating all of this in the container and at the end of the run when the docker is terminated all of these files are deleted. There is workaround there when you are calling the docker you have to add new volumes something like -v \u201cfolder_for_results_on_your_host:\/root\/.guild\u201d -v \u201cfolder_for_tmp_results_on_your_host:\/tmp\u201d, this way you will have all runs out of the docker and they will persists.<\/p>\n<p>For example I am using something like this:<\/p>\n<p>docker run -it --rm --gpus device=none -v \u201c$(pwd):\/work_dir\u201d <strong>-v \u201c$(pwd)\/guild_results:\/root\/.guild\u201d<\/strong> <strong>-v \u201c$(pwd)\/guild_tmp:\/tmp\u201d<\/strong> docker_name:docker_tag guild run MODEL:OPERATION -y<\/p>\n<ul>\n<li>work_dir is name of my working directory in docker<\/li>\n<li>$(pwd)\/guild_results: folder in my project folder where I want to save all guild runs results<\/li>\n<li>$(pwd)\/guild_tmp: folder in my project folder where I want to save all temporary guild results<\/li>\n<li>MODEL: model name from your guild file (if you are using any)<\/li>\n<li>OPERATION: operation name from your guild file (if you are using any)<\/li>\n<\/ul>\n<p>I don\u2019t know if you are running guild view in docker or not but in case you are running then you should also add the volumes into docker run command which you are using for the guild view. If you are running guild view on your machine (not in docker) then just change <strong>$(pwd)\/guild_results<\/strong> with <strong>\/root\/.guild<\/strong> (and also for the temporary files if you are genereting any).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-06-17T16:49:17.296Z",
                "Answer_body":"<p>Thank you for your response!<br>\nI was able to resolve the issue.<br>\nThe error persisted because in my guild.run() command, I only referenced the main() function from my experiment.py file as the argument for that run command\u2013&gt; guild.run(main), but I also needed to add a dictionary of flags I wanted to be tracked as a second argument. For reference, my final command looks like guild.run(main, flags_dict). This fixed the issue, and the flags from the guild.yml file are now properly being tracked and displayed in the \/.guild output directory.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Operations as dependencies during checks",
        "Question_link":"https:\/\/my.guild.ai\/t\/operations-as-dependencies-during-checks\/701",
        "Question_created_time":1620166635120,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":259,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have a <code>guild<\/code> model that looks something like this:<\/p>\n<pre><code>- include: source_code_config.yml\n- model: _check\n  extends:\n    - source_code_config\n  operations:\n    _test_segmentation_training:\n      steps:\n        - run: segmentation:train dryrun=yes num_epochs=1 input_database=\"x.csv\"\n          expect:\n            - file: experiments\/best_model.pt\n    _test_segmentation_testing:\n      steps:\n        - run:segmentation:test input_database=\"x.csv\"\n          expect:\n            - output: \"Testing done.\"\n    _all:\n      steps:\n        - _test_segmentation_training\n        - _test_segmentation_testing\n<\/code><\/pre>\n<p>I use this for integration testing my training and tests scripts.<\/p>\n<p>The <code>segmentation<\/code> model looks something like this:<\/p>\n<pre><code>- model: segmentation\n  extends:\n    - source_code_config\n  operations:\n    train:\n      main: scripts\/training\/train_segmentation\n      flags:\n        $include:\n          - segmentation_flags\n          - train_flags\n          - common_flags\n      requires:\n        - prepared_data\n    test:\n      main: scripts\/training\/test_segmentation\n      flags:\n        batch_size: 1\n        $include:\n          - test_flags\n          - common_flags\n      requires:\n        - prepared_data\n        - trained_model\n  resources:\n    trained_model:\n      sources:\n        - operation: train\n          select:\n            - experiments\n            - .guild\/attrs\/flags\n          target-type: copy\n          rename:\n            - flags training-flags.yml # See https:\/\/github.com\/guildai\/guildai\/blob\/0.7.2\/examples\/upstream-flags\/guild.yml\n<\/code><\/pre>\n<p>Now when I run<\/p>\n<pre><code>guild run segmentation:train\n<\/code><\/pre>\n<p>Followed by:<\/p>\n<pre><code>guild run segmentation:test\n<\/code><\/pre>\n<p><code>guild<\/code> will automatically resolve the <code>trained_model<\/code> dependency and find the latest <code>segmentation:train<\/code> run.<\/p>\n<p>If I instead run:<\/p>\n<p><code>guild _check:_all<\/code><\/p>\n<p>The <code>_test_segmentation_training<\/code> runs successfully, but the <code>_test_segmentation_testing<\/code> operation is not able to resolve the <code>trained_model<\/code> resource.<\/p>\n<p>Ideally I would be able to run this pipeline as a step in my integration testing.<\/p>\n<p>EDIT:<\/p>\n<p>Using <code>guild<\/code> version <code>0.7.3<\/code><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-05-07T19:17:48.390Z",
                "Answer_body":"<p>You\u2019re running into a purported safeguard where steps can only see runs generated within the parent steps operation. To tell Guild to look at all runs, set <code>isolate-runs: no<\/code> within the step.<\/p>\n<p>Here\u2019s an example:<\/p>\n<aside class=\"onebox githubgist\">\n  <header class=\"source\">\n      <a href=\"https:\/\/gist.github.com\/gar1t\/b3cd7e75bfe72780ddc39455e0e4452f\" target=\"_blank\" rel=\"noopener\">gist.github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/gist.github.com\/gar1t\/b3cd7e75bfe72780ddc39455e0e4452f\" target=\"_blank\" rel=\"noopener\">https:\/\/gist.github.com\/gar1t\/b3cd7e75bfe72780ddc39455e0e4452f<\/a><\/h4>\n<h5>guild.yml<\/h5>\n<pre><code class=\"YAML\">up: guild.pass\n\ndown:\n  main: guild.pass\n  requires:\n    - operation: up\n      warn-if-empty: no\n\nup-steps:\n  steps:<\/code><\/pre>\nThis file has been truncated. <a href=\"https:\/\/gist.github.com\/gar1t\/b3cd7e75bfe72780ddc39455e0e4452f\" target=\"_blank\" rel=\"noopener\">show original<\/a>\n\n<p>\n<\/p>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>This is annoyingly subtle behavior\u2014Guild should at least print a message pointing you to an answer.<\/p>\n<p>Be sure to disable <code>isolate-runs<\/code> the two applicable steps\/pipeline operations.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error while publishing runs",
        "Question_link":"https:\/\/my.guild.ai\/t\/error-while-publishing-runs\/700",
        "Question_created_time":1620146008305,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":270,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to publish a particular run using the command <code>guild runs publish --dest &lt;path of destination&gt; &lt;run id&gt;<\/code>. However, I get the following error.<\/p>\n<pre><code>Traceback (most recent call last):\n  File \"\/usr\/local\/bin\/guild\", line 8, in &lt;module&gt;\n    sys.exit(main())\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/main_bootstrap.py\", line 40, in main\n    _main()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/click\/decorators.py\", line 21, in new_func\n    return f(get_current_context(), *args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/commands\/runs_publish.py\", line 113, in publish_runs\n    runs_impl.publish(args, ctx)\nAttributeError: module 'guild.commands.runs_impl' has no attribute 'publish'\n<\/code><\/pre>\n<p>Any recommendations on how to solve this? I am using guild version 0.7.2.<\/p>\n<p>Thanks,<br>\nVishal<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-05-07T18:58:48.262Z",
                "Answer_body":"<p>That\u2019s a bug! Sorry about that. We\u2019ll get that fixes ASAP.<\/p>\n<p>In the meantime, you can use the alternative path to that command this way (omit the <code>runs<\/code> part):<\/p>\n<pre><code class=\"lang-command\">guild publish --dest &lt;path of destination&gt; &lt;run id&gt;\n<\/code><\/pre>\n<p>A number of the sub-commands under <code>guild runs<\/code> are available as top-level commands.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-05-07T19:03:38.752Z",
                "Answer_body":"<p>This is fixed in master and will be available in 0.7.4 (will be released in the next couple weeks). In the meantime again - just use the alternative command form <code>guild publish ...<\/code>.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"OperatorNotAllowedInGraphError: Error while using Guild run",
        "Question_link":"https:\/\/my.guild.ai\/t\/operatornotallowedingrapherror-error-while-using-guild-run\/697",
        "Question_created_time":1619977129009,
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":884,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use a code with guild. I checked the code using python  and the code runs successfully. However, when I try to use the code using guild run  it gives me the following error. On looking at the error closely, I found that the code gives me an error in the model.fit function of keras. I am not sure what is happening when we use guild run in this function that is triggering the error?<\/p>\n<p>Any help or suggestion in this matter would be greatly appreciated.<\/p>\n<p>Thanks in advance,<br>\nVishal<\/p>\n<p>Full error below.<\/p>\n<pre><code>File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py\", line 108, in _method_wrapper\n    return method(self, *args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py\", line 1098, in fit\n    tmp_logs = train_function(iterator)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/def_function.py\", line 780, in __call__\n    result = self._call(*args, **kwds)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/def_function.py\", line 823, in _call\n    self._initialize(args, kwds, add_initializers_to=initializers)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/def_function.py\", line 697, in _initialize\n    *args, **kwds))\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/function.py\", line 3213, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/function.py\", line 3075, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/framework\/func_graph.py\", line 986, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/eager\/def_function.py\", line 600, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/framework\/func_graph.py\", line 973, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\ntensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in user code:\n\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py:806 train_function  *\n        return step_function(self, iterator)\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py:799 step_function  **\n        write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py:2757 write_scalar_summaries\n        summary_ops_v2.scalar('batch_' + name, value, step=step)\n    \/usr\/local\/lib\/python3.6\/dist-packages\/guild\/python_util.py:321 wrapper\n        cb(self._func, *args, **kw)\n    \/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/summary_util.py:198 _handle_scalar_ops_v2\n        vals = self._summary_values(step)\n    \/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/summary_util.py:179 _summary_values\n        return self._summary_cache.for_step(global_step)\n    \/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/summary_util.py:246 for_step\n        return self._val if step == self._step else None\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/framework\/ops.py:877 __bool__\n        self._disallow_bool_casting()\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/framework\/ops.py:487 _disallow_bool_casting\n        \"using a `tf.Tensor` as a Python `bool`\")\n    \/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/framework\/ops.py:474 _disallow_when_autograph_enabled\n        \" indicate you are trying to use an unsupported feature.\".format(task))\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-05-04T14:13:16.807Z",
                "Answer_body":"<p>This is a bug in Guild that I believe has been fixed. What version are you using? You can use <code>guild --version<\/code> to check.<\/p>\n<p>You can try temporarily upgrading to the pre-release version to see if that resolves the issue.<\/p>\n<pre><code class=\"lang-command\">pip install guildai --pre --upgrade\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-05-04T15:11:48.466Z",
                "Answer_body":"<p>Thanks for the reply. I am using version guild 0.7.2. Is the bug fixed after this version?<\/p>\n<p>We got a temporary workaround and it seems that guild did not like the \u201cmodel.fit\u201d function in the main script. Shifting the model.fit function to the utilities folder and calling the function from utils in the main script worked - magically!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-05-07T18:56:21.625Z",
                "Answer_body":"<p>The fix is in either 0.7.3 or 0.7.4 (pre-release). If you\u2019re happy with the workaround, that\u2019s great\u2014or if you want to see if the issue is fixed in 0.7.3 or 0.7.4, you can upgrade to see.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dynamically generated parameters in pipeline",
        "Question_link":"https:\/\/my.guild.ai\/t\/dynamically-generated-parameters-in-pipeline\/699",
        "Question_created_time":1620135807746,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":275,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Conceptually I have a two stage pipeline. Where the first stage generates a set of flags (\u201chyper-hyper parameters\u201d). Then in the second stage I want to combine those with a set of hyper parameters to optimize. The challenge is that since they\u2019re created dynamically\u2026 I can\u2019t know ahead of time how many there are.<\/p>\n<p>I can do it manually like this<\/p>\n<p><code>guild run train x='[1,2,3] y='[1,2,3]'' @bigbatch.csv<\/code><\/p>\n<p>What I would like to do is for the train step to use a generated bigbatch.csv from the upstream pipeline<\/p>\n<p>I\u2019ve attached what I think it should look like at the guild.yml level<\/p>\n<pre><code>train:\n  description: Sample training script\n  flags-import: all\n  requires:\n    - operation: bigbatch\nbigbatch:\n  description: make file bigbatch.csv\n<\/code><\/pre>\n<p>This gives me  a symlink to the correct file called bigbatch.csv in the \u201ctrain folder\u201d after the <code>guild train<\/code> operation. However when I use the \u201c@\u201d batch notation the bigbatch.csv is taken from my cwd. Is there any way to reference batch parameters in the guild.yml?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-05-04T14:29:45.957Z",
                "Answer_body":"<p>This is a bit of a hack but I think could be an approach that works for you:<\/p>\n<aside class=\"onebox githubgist\">\n  <header class=\"source\">\n      <a href=\"https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187\" target=\"_blank\" rel=\"noopener\">gist.github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187\" target=\"_blank\" rel=\"noopener\">https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187<\/a><\/h4>\n<h5>bigbatch.py<\/h5>\n<pre><code class=\"Python\">with open(\"bigbatch.csv\", \"w\") as f:\n    f.write(\"\"\"x,y\n1,2\n3,4\n\"\"\")<\/code><\/pre>\n\n<h5>gistfile1.txt<\/h5>\n<pre><code class=\"Text\">bigbatch: {}\n\ntrain-batch:\n  exec: guild run train @bigbatch.csv -y\n  requires:\n    - operation: bigbatch\n      select: bigbatch.csv\n  sourcecode:\n    dest: .\n    exclude: '*.csv'<\/code><\/pre>\nThis file has been truncated. <a href=\"https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187\" target=\"_blank\" rel=\"noopener\">show original<\/a>\n<h5>guild.yml<\/h5>\n<pre><code class=\"YAML\">bigbatch: {}\n\ntrain-batch:\n  exec: guild run train @bigbatch.csv -y\n  requires:\n    - operation: bigbatch\n      select: bigbatch.csv\n  sourcecode:\n    dest: .\n    exclude: '*.csv'<\/code><\/pre>\nThis file has been truncated. <a href=\"https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187\" target=\"_blank\" rel=\"noopener\">show original<\/a>\n\n<p>\n  There are more than three files. <a href=\"https:\/\/gist.github.com\/gar1t\/7a10da5eb950bc9855eac6207982b187\" target=\"_blank\" rel=\"noopener\">show original<\/a>\n<\/p>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Take a look and let me know if you have any questions or run into issues.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-05-04T15:03:14.193Z",
                "Answer_body":"<p>This looks really promising and I can get <code>guild train-batch<\/code> to run. My challenge is that I would like to be able to do something like\u2026<\/p>\n<p><code>guild train-batch x='[1,2,3]'<\/code> (or any HPO-type syntax) to do the outer product of the bigbatch with the HPO.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-05-04T17:35:23.773Z",
                "Answer_body":"<p>You can pass through flag values in a command spec using <code>${FLAG_NAME)<\/code> so you could parameterize a list of values this way:<\/p>\n<aside class=\"onebox githubgist\">\n  <header class=\"source\">\n      <a href=\"https:\/\/gist.github.com\/gar1t\/4cdbe645df4924ca4522abec8511d99d\" target=\"_blank\" rel=\"noopener\">gist.github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/gist.github.com\/gar1t\/4cdbe645df4924ca4522abec8511d99d\" target=\"_blank\" rel=\"noopener\">https:\/\/gist.github.com\/gar1t\/4cdbe645df4924ca4522abec8511d99d<\/a><\/h4>\n<h5>bigbatch.py<\/h5>\n<pre><code class=\"Python\">with open(\"bigbatch.csv\", \"w\") as f:\n    f.write(\"\"\"x,y\n1,2\n3,4\n\"\"\")<\/code><\/pre>\n\n<h5>guild.yml<\/h5>\n<pre><code class=\"YAML\">bigbatch: {}\n\ntrain-batch:\n  exec: guild run train @bigbatch.csv x=\"${x}\" -y\n  flags:\n    x:\n      required: yes\n  requires:\n    - operation: bigbatch\n      select: bigbatch.csv<\/code><\/pre>\nThis file has been truncated. <a href=\"https:\/\/gist.github.com\/gar1t\/4cdbe645df4924ca4522abec8511d99d\" target=\"_blank\" rel=\"noopener\">show original<\/a>\n<h5>train.py<\/h5>\n<pre><code class=\"Python\">x = 0\ny = 0\n\nprint(\"x=%s\" % x)\nprint(\"y=%s\" % y)<\/code><\/pre>\n\n\n<p>\n<\/p>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Note though that when you run <code>train-batch<\/code> you need to quote the string arg to tell Guild the value is a string and not a list. Like this:<\/p>\n<pre><code class=\"lang-command\">guild run train-batch x=\"'[5,6,7,8]'\"\n<\/code><\/pre>\n<pre><code class=\"lang-output\">You are about to run train-batch\n  bigbatch: ef0d8d741ea94bc8a1202f0815812b6e\n  x: '[5,6,7,8]'\nContinue? (Y\/n)\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild doesn't copy module to new source code location",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-doesnt-copy-module-to-new-source-code-location\/690",
        "Question_created_time":1619015850647,
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":594,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>When I use the command <code>guild run train,py<\/code> I get the error <code>Error: can't important module_1<\/code>. When I look in the folder to which guildai copies the source code after I call guild run, I can see that <code>module_1<\/code> was indeed not copied. There is nothing special about that module_1 (normal code files). How can I debug this issue further?<\/p>\n<p>Here is my folder structure:<\/p>\n<p>Folder structure:<\/p>\n<pre><code>guild.yml\ntrain.py\nmodule_1\nmodule_2\nmodule_3\n<\/code><\/pre>\n<p>guild.yml<\/p>\n<pre><code>train:\n  description: Training script\n  main: train\n  # sourcecode:\n  #   - '*.py'\n  flags-dest: global:params\n  flags-import: all\n  flags:\n    ## general\n    gpu:\n      description:\n      default: 0\n    seed:\n      description:\n      default: 0\n...\n<\/code><\/pre>\n<p>Thanks for your help!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-04-21T17:12:16.681Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jan_r\">@jan_r<\/a>, I\u2019m sorry you\u2019re running into issues here.<\/p>\n<p>Guild should be picking up any Python modules from <code>module_*<\/code> dirs and copying them to the <code>.guild\/sourcecode<\/code> directory in the run. Note that Guild does not attempt to duplicate your project structure. Source code files do not appear in the run directory root, at least by default.<\/p>\n<p>You can view the list of source code files for a run this way:<\/p>\n<pre><code class=\"lang-command\">guild ls --sourcecode  # shows source code files for latest run\n<\/code><\/pre>\n<p>You can test the source code copy logic ahead of time for a run this way:<\/p>\n<pre><code class=\"lang-command\">guild run train --test-sourcecode\n<\/code><\/pre>\n<p>This gives you a detailed list of files that are copied and those that are skipped based on the <code>sourcecode<\/code> config for the operation.<\/p>\n<p>Note that <code>guild run train.py<\/code> runs the the script directly. In this case, because your operation is named <code>train<\/code> (no <code>.py<\/code> extension), Guild does not use the config in <code>guild.yml<\/code>. You need to use <code>guild run train<\/code>, which uses the operation name in <code>guild.yml<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-21T17:13:56.011Z",
                "Answer_body":"<p>One thought here \u2014 the <code>module_*<\/code> dirs must each have a <code>__init__.py<\/code> file to indicate they\u2019re a package. In my tests, when I removed that file I get the error message you show above.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-24T11:32:06.669Z",
                "Answer_body":"<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"2\" data-topic=\"690\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<p><code>guild run train --test-sourcecode<\/code><\/p>\n<\/blockquote>\n<\/aside>\n<p>That\u2019s good advice thanks! Unfortunately, they relevant .py files in my module which are not copied don\u2019t appear in the list of skipped files nor in the list of copied files. The module has a <code>__init__.py<\/code> file so it\u2019s a proper module.<\/p>\n<p>Do you have any other tricks I could use for debugging?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-26T13:36:40.448Z",
                "Answer_body":"<p>Are the Python source code files stored under a linked directory? What OS is this? Thanks!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"sqlite3.OperationalError: disk I\/O error when using the scratch drive on Linux cluster for storage of guild runs",
        "Question_link":"https:\/\/my.guild.ai\/t\/sqlite3-operationalerror-disk-i-o-error-when-using-the-scratch-drive-on-linux-cluster-for-storage-of-guild-runs\/684",
        "Question_created_time":1618280824715,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":295,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use Guild for hyperparameter optimization. I am running max-trials of 50 and want to store these temporary models in the \/scratch drive on the Linux cluster. I checked that the drive is mounted corrected and I am able to read and write properly in the drive. However, when i submit my guild run, I get the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File \"\/usr\/lib\/python3.6\/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"\/usr\/lib\/python3.6\/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_gp_main.py\", line 77, in &lt;module&gt;\n    main()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_gp_main.py\", line 30, in main\n    skopt_util.handle_seq_trials(batch_run, _suggest_x)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_util.py\", line 210, in handle_seq_trials\n    _run_seq_trials(batch_run, suggest_x_cb)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_util.py\", line 234, in _run_seq_trials\n    batch_flag_vals,\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_util.py\", line 266, in _iter_seq_trials\n    prev_trials = prev_trials_cb()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/plugins\/skopt_util.py\", line 224, in &lt;lambda&gt;\n    prev_trials_cb = lambda: batch_util.trial_results(batch_run, [objective_scalar])\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/batch_util.py\", line 404, in trial_results\n    return trial_results_for_runs(trial_runs(batch_run), scalars)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/batch_util.py\", line 408, in trial_results_for_runs\n    index = _run_index_for_scalars(runs)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/batch_util.py\", line 423, in _run_index_for_scalars\n    index = indexlib.RunIndex()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/index.py\", line 314, in __init__\n    self._db = self._init_db()\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/index.py\", line 323, in _init_db\n    self._init_tables(db)\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/guild\/index.py\", line 349, in _init_tables\n    \"\"\"\nsqlite3.OperationalError: disk I\/O error\n<\/code><\/pre>\n<p>I checked my \/scratch drive and found that the runs and cache folders are created. Also found that one folder was created inside runs. But this folder was empty.<\/p>\n<p>The same command works perfectly when I run using my GUILD_HOME as a different drive. I am not sure if I am missing anything here.<\/p>\n<p>I would appreciate any help from your side.<\/p>\n<p>Thanks,<br>\nVishal<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-04-13T07:26:56.902Z",
                "Answer_body":"<p>What was the nature of the drive? Is it a network drive (i.e. nfs)?<br>\nAm I correct that you specified <code>GUILD_HOME=\/scratch<\/code> and got this error?<\/p>\n<p>It seems that you are running from a system python, if you didn\u2019t specify <code>GUILD_HOME<\/code>, it\u2019s likely your default <code>GUILD_HOME<\/code> is placed under directories where you don\u2019t have write privilege (Could be somewhere other than <code>\/scratch<\/code>).<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dask scheduler not using multiple gpus on remote",
        "Question_link":"https:\/\/my.guild.ai\/t\/dask-scheduler-not-using-multiple-gpus-on-remote\/583",
        "Question_created_time":1617036688225,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":457,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nIt\u2019s a fresh feature and most likely I\u2019m doing something wrong, but I cannot get the Dask scheduler to work properly on a remote with 4 gpus.<\/p>\n<p>This is what I do, and apart from the remote part it is basically a copy of the steps in the How To guide:<\/p>\n<ol>\n<li>\n<p>Connect to remote. I have successfully staged runs on remote, run them directly, and also used multiple gpus by assigning runs to gpus manually using --gpus flag. So the remote works corectly.<\/p>\n<\/li>\n<li>\n<p>Start the Dask scheduler on the remote.<\/p>\n<\/li>\n<li>\n<p>Then I stage trials on remote, let\u2019s say 4, with different parameters, using a single command.<\/p>\n<\/li>\n<\/ol>\n<pre><code>guild run TABL:train window=[100,200,300,400] --remote cerberus --stage-trials\n<\/code><\/pre>\n<ol start=\"4\">\n<li>The trials are sent to remote, and the scheduler starts them. If workers is set to 4, it starts correctly 4 processes of loading data etc.<\/li>\n<\/ol>\n<p>And this is where something goes wrong. After doing the pre-procesing stage and creating 4 models concurrently, the scheduler places all 4 models and training processses on all 4 gpus (which can be seen on the screenshot - all gpus have allocated memory). And then only begins the training on 1 gpu.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6.png\" data-download-href=\"\/uploads\/short-url\/2PTbvO3vWfJgJUE57EqoCMII9Jc.png?dl=1\" title=\"Screenshot from 2021-03-29 18-26-25\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6_2_490x500.png\" alt=\"Screenshot from 2021-03-29 18-26-25\" data-base62-sha1=\"2PTbvO3vWfJgJUE57EqoCMII9Jc\" width=\"490\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6_2_490x500.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/13e1f55d40cd637c5f942a9330bfa853e5a3ccf6_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2021-03-29 18-26-25<\/span><span class=\"informations\">731\u00d7745 103 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p><strong>Expected<\/strong><br>\nI would expect the scheduler to assign the trials to available gpus and train them concurrently. Furthermore, when the number of trials is bigger than the number of gpus, I would expect the scheduler to automatically run the pending operation when a gpus becomes free.<\/p>\n<p>Did I understand what the scheduler is capable of correctly? Is there maybe some manual step somewhere that I missed?<\/p>\n<p>Thanks in advance.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-31T22:19:46.513Z",
                "Answer_body":"<p>By default the scheduler will simply run the staged runs concurrently, up to the number of workers specified. It doesn\u2019t assign runs to GPUs. This is a good feature idea, but the initial pass doesn\u2019t do this.<\/p>\n<p>Instead, you need to <a href=\"https:\/\/my.guild.ai\/t\/parallel-processing-with-dask-scheduler\/550#scheduling-runs-on-specific-gpus\">assign runs to GPUs explicitly<\/a>. This uses Dask resources to limit runs, as well as configuring each run for the target GPU.<\/p>\n<p>The real target is to support this with just the <code>run<\/code> command\u2014so you don\u2019t need to mess with schedulers. But this first pass introduced concurrency with Dask distributed and so exposes the resource based scheduling that Dask offers.<\/p>\n<p>If you have any questions about the steps in <a href=\"https:\/\/my.guild.ai\/t\/parallel-processing-with-dask-scheduler\/550#scheduling-runs-on-specific-gpus\">Scheduling Runs on Specific GPUs<\/a> please feel free to followup here. We\u2019ll look for ways to clean this up, either via better docs or tweaks to the code.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-04-05T07:03:28.712Z",
                "Answer_body":"<p>Ok, thanks for the clarification, I\u2019ll continue assigning the runs manually <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remote stop not working",
        "Question_link":"https:\/\/my.guild.ai\/t\/remote-stop-not-working\/584",
        "Question_created_time":1617118654840,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":299,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>After running <code>guild runs stop X -r server<\/code>, the processes are still running on the remote and GPU memory has not been released even though guild reports the run as terminated.<\/p>\n<p>I think it may be pytorch\u2019s data loader worker processes that are still running but I\u2019m not sure. I think I saw something about this subject before but I couldn\u2019t find it here or on github. Has anyone else experienced this issue?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-31T22:26:19.748Z",
                "Answer_body":"<p>I wonder if Python\u2019s <code>multiprocessing<\/code> module is in play here. 0.7.3 has some rework of the stop function and the SIGTERM might not be propagating to the child processing.<\/p>\n<p>I\u2019ll see if I can replicate this with a simple <code>multiprocessing<\/code> example. This wouldn\u2019t need PyTorch.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-31T22:29:51.527Z",
                "Answer_body":"<p>Ref to GitHub issue: <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/281\" class=\"inline-onebox\">0.7.3 stop not working with PyTorch data loader \u00b7 Issue #281 \u00b7 guildai\/guildai \u00b7 GitHub<\/a><\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild --remote option not recognized",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-remote-option-not-recognized\/578",
        "Question_created_time":1616750140636,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":314,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m running Guild AI 0.7.3 and following the instructions for remote running <a href=\"https:\/\/my.guild.ai\/t\/remotes\/171\" class=\"inline-onebox\">Remotes<\/a> I run the command to check everything is set up correctly<\/p>\n<pre><code>guild --remote dev check\n<\/code><\/pre>\n<p>guild: unrecognized option \u2018\u2013remote\u2019<br>\nTry \u2018guild --help\u2019 for more information.<\/p>\n<p>I have configured my remote and can access it using ssh, my ~\/.guild\/config.yml looks like this.<\/p>\n<pre><code>remotes:\n    dev:\n      type: ssh\n      description: DSVM on Azure for development\n      host: dl\n<\/code><\/pre>\n<p>Is the tutorial outdated? Should I be able to run things remotely?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-26T09:17:58.149Z",
                "Answer_body":"<p>Wow that example is totally wrong, sorry about that! This is what you want.<\/p>\n<pre><code class=\"lang-command\">guild check --remote dev\n<\/code><\/pre>\n<p>I\u2019ll fix those docs ASAP.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Detect SimpleNamespace as flag",
        "Question_link":"https:\/\/my.guild.ai\/t\/detect-simplenamespace-as-flag\/567",
        "Question_created_time":1616438128886,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":266,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi, I\u2019m trying to tune hyperparameters using guild. These are defined as follows:<\/p>\n<pre><code>from types import SimpleNamespace\nparams = SimpleNamespace(\n    embedding_dim = 256,\n    window_size = 5,\n    batch_size = 2048,\n    epochs = 2,\n    preprocessed = f'{DATASET_ROOT}\/{DATASET_PREFIX}',\n    working = f'{WORKING_ROOT}\/{DATASET_PREFIX}',\n    modelname = f'{WORKING_ROOT}\/{DATASET_VERSION}.pt',\n    train = True\n)\n<\/code><\/pre>\n<p>Guild won\u2019t find them by default and I am having a hard time working around this. I am  new to guild so maybe there is an answer in the DOCS i haven\u2019t found.<\/p>\n<p>Thanks in advance<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-24T20:09:04.466Z",
                "Answer_body":"<p>Hello and welcome! This is not supported using <code>SimpleNamespace<\/code> for flags directly, but you can use a standard Python dict this way:<\/p>\n<pre><code class=\"lang-python\">from types import SimpleNamespace\n\nparam_vals = {\n    \"foo\": 123,\n    \"bar\": \"hello there\",\n}\n\nparams = SimpleNamespace(**param_vals)\n\nprint(params)\n<\/code><\/pre>\n<p>The Guild file (<code>guild.yml<\/code>) needs to look like this in this case:<\/p>\n<pre><code class=\"lang-yaml\">op:\n  flags-dest: global:param_vals\n  flags-import: all\n<\/code><\/pre>\n<p>Support for <code>SimpleNamespace<\/code> based globals is a great idea! In the meantime, this workaround will get you past the blocker.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-25T07:03:13.876Z",
                "Answer_body":"<p>Thanks for the response!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-25T20:40:59.567Z",
                "Answer_body":"<p>We have a branch started for this feature:<\/p>\n<aside class=\"onebox githubfolder\">\n  <header class=\"source\">\n      <img src=\"https:\/\/github.githubassets.com\/favicons\/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/namespace-flags-dest\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:180\/180;\"><img src=\"https:\/\/avatars.githubusercontent.com\/u\/19977227?s=400&amp;amp;v=4\" class=\"thumbnail\" width=\"180\" height=\"180\"><\/div>\n\n<h3><a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/namespace-flags-dest\" target=\"_blank\" rel=\"noopener\">guildai\/guildai<\/a><\/h3>\n\n<p><a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/namespace-flags-dest\" target=\"_blank\" rel=\"noopener\">namespace-flags-dest<\/a><\/p>\n\n  <p><span class=\"label1\">Experiment tracking, ML developer tools. Contribute to guildai\/guildai development by creating an account on GitHub.<\/span><\/p>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>From the look of it, it\u2019s completed but we won\u2019t merge to master until 0.7.3 is released (hopefully later today).<\/p>\n<p>To support this, you need to use the <code>namespace<\/code> dest type like this:<\/p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/guild.yml#L24-L28\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/guild.yml#L24-L28\" target=\"_blank\" rel=\"noopener\">guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/guild.yml#L24-L28<\/a><\/h4>\n<pre class=\"onebox\"><code class=\"lang-yml\"><ol class=\"start lines\" start=\"24\" style=\"counter-reset: li-counter 23 ;\">\n<li>namespace:<\/li>\n<li>  description: Use a SimpleNamespace for flag values<\/li>\n<li>  main: global_namespace<\/li>\n<li>  flags-dest: namespace:params<\/li>\n<li>  flags-import: all<\/li>\n<\/ol><\/code><\/pre>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>With that, this code works as expected:<\/p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/global_namespace.py#L17-L25\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/global_namespace.py#L17-L25\" target=\"_blank\" rel=\"noopener\">guildai\/guildai\/blob\/namespace-flags-dest\/examples\/flags\/global_namespace.py#L17-L25<\/a><\/h4>\n<pre class=\"onebox\"><code class=\"lang-py\"><ol class=\"start lines\" start=\"17\" style=\"counter-reset: li-counter 16 ;\">\n<li>params = SimpleNamespace(<\/li>\n<li>    i=123,<\/li>\n<li>    f=1.123,<\/li>\n<li>    s=\"hello\",<\/li>\n<li>    b=False,<\/li>\n<li>    l=[1, 2, \"foo\"],<\/li>\n<li>)<\/li>\n<li>\n<li>print(params)<\/li>\n<\/ol><\/code><\/pre>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Thanks for the question\u2014I think it\u2019s a solid feature. The namespace interface is much cleaner than using dicts.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot open Tensorboard with Guild - unhashable type 'Dict'",
        "Question_link":"https:\/\/my.guild.ai\/t\/cannot-open-tensorboard-with-guild-unhashable-type-dict\/563",
        "Question_created_time":1615470431294,
        "Question_answer_count":9,
        "Question_score_count":4,
        "Question_view_count":621,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nFirst of all, great job, loving Guild so far.<\/p>\n<p>I have successfully created a queue, staged runs and completed them. I can run \u2018guild view\u2019 or \u2018tensorboard\u2019 standalone and see the logs.<\/p>\n<p>However, I cannot run \u2018guild tensorboard\u2019 or similary start tensorboard from guild view. In both cases I get an error with the following traceback:<\/p>\n<pre><code>(anomaly_detection) E:\\source\\repos\\anomaly_simulation\\Zoo&gt;guild -H E:\/source\/repos\/anomaly_simulation\/Results tensorboard\nPreparing runs for TensorBoard\nTraceback (most recent call last):\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\blepo\\Anaconda3\\envs\\anomaly_detection\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 94, in _run_tensorboard\n    monitor.run_once(exit_on_error=True)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 80, in run_once\n    runs = self.list_runs_cb()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 119, in f\n    _ensure_hparam_experiment(runs, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 134, in _ensure_hparam_experiment\n    hparams = _experiment_hparams(runs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 146, in _experiment_hparams\n    hparams.setdefault(name, set()).add(val)\nTypeError: unhashable type: 'dict'\n<\/code><\/pre>\n<p>Any idea what may be causing it and what is the solution?<\/p>\n<p>My system is Windows 10, Guild version is 0.7.2, and Python is 3.8.5.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-15T19:33:09.704Z",
                "Answer_body":"<p>My apologies for the late reply! (I had started a reply but never sent it!)<\/p>\n<p>This is a bug in Guild. One of your runs has a map\/dict flag value, which Guild is not correctly handling when setting up the hparam info for TensorBoard. You should be able to work around this by using the <code>--skip-hparams<\/code> option when running the <code>tensorboard<\/code> command:<\/p>\n<pre><code class=\"lang-command\">guild tensorboard --skip-hparams\n<\/code><\/pre>\n<p>You can alternatively omit the applicable run using a filter.<\/p>\n<p>I opened an issue for this <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/276\">here<\/a>. This will be fixed in the next release.<\/p>\n<p>Thanks for the report and sorry again for getting back so late!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-16T14:03:15.439Z",
                "Answer_body":"<p>Thanks for the reply and no worries, it\u2019s still very fast support <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=9\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"><\/p>\n<p>On Ubuntu both filtering and using --skip-hparams works.<\/p>\n<p>On Windows 10, however, after using the filtering command I get the following error:<\/p>\n<pre><code>(anomaly_detection) E:\\source\\repos\\anomaly_simulation\\Zoo&gt;guild -H E:\\source\\repos\\anomaly_simulation\\Zoo\\Results tensorboard --tag binary\nPreparing runs for TensorBoard\nTraceback (most recent call last):\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\blepo\\Anaconda3\\envs\\anomaly_detection\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 94, in _run_tensorboard\n    monitor.run_once(exit_on_error=True)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 89, in run_once\n    self._refresh_logdir(runs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 97, in _refresh_logdir\n    self.refresh_run_cb(run, path)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 275, in f\n    return _refresh_run(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 281, in _refresh_run\n    _refresh_tfevent_links(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 292, in _refresh_tfevent_links\n    _init_tfevent_link(tfevent_path, link, run, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 306, in _init_tfevent_link\n    _init_hparam_session(run, link_dir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 314, in _init_hparam_session\n    _add_hparam_experiment(state.hparam_experiment, writer)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 328, in _add_hparam_experiment\n    writer.add_hparam_experiment(hparams, metrics)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 125, in add_hparam_experiment\n    self._add_summary(_HParamExperiment(hparams, metrics))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 108, in _add_summary\n    self._get_writer().add_event(event)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 99, in _get_writer\n    self._writer = self._writer_init()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 92, in &lt;lambda&gt;\n    self._writer_init = lambda: EventFileWriter(\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 57, in __init__\n    self._writer = tensorboard.AsyncWriter(\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\plugins\\tensorboard.py\", line 70, in AsyncWriter\n    event_file_writer.RecordWriter(open(filename, \"wb\")), max_queue_size, flush_secs\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\blepo\\\\AppData\\\\Local\\\\Temp\\\\guild-tensorboard-4xhgkuo_\\\\52d15085 ResNet_train 2021-03-15\n<\/code><\/pre>\n<p>When using the --skip-hparams, the error is as follows:<\/p>\n<pre><code>(anomaly_detection) E:\\source\\repos\\anomaly_simulation\\Zoo&gt;guild -H E:\\source\\repos\\anomaly_simulation\\Zoo\\Results tensorboard --skip-hparams\nPreparing runs for TensorBoard\nTraceback (most recent call last):\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\util.py\", line 641, in _windows_symlink\n    subprocess.check_output(args, shell=True, stderr=subprocess.STDOUT)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\subprocess.py\", line 411, in check_output\n    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\subprocess.py\", line 512, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['mklink', 'C:\\\\Users\\\\blepo\\\\AppData\\\\Local\\\\Temp\\\\guild-tensorboard-0mf82txu\\\\52d15085 ResNet_train 2021-03-15 19_31_12 binary binarize=yes dev=no dimensionality=125 horizon=1 learning_rate=0.001 n_feature_maps=64 optimizer=adam window=100\\\\.guild\\\\events.out.tfevents.1615862999.blez-au.17693.0', 'E:\\\\source\\\\repo\ns\\\\anomaly_simulation\\\\Zoo\\\\Results\\\\runs\\\\52d15085552c457e92147334e33664de\\\\.guild\\\\events.out.tfevents.1615862999.blez-au.17693.0']' returned non-zero exit status 1.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\blepo\\Anaconda3\\envs\\anomaly_detection\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 94, in _run_tensorboard\n    monitor.run_once(exit_on_error=True)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 89, in run_once\n    self._refresh_logdir(runs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 97, in _refresh_logdir\n    self.refresh_run_cb(run, path)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 275, in f\n    return _refresh_run(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 281, in _refresh_run\n    _refresh_tfevent_links(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 292, in _refresh_tfevent_links\n    _init_tfevent_link(tfevent_path, link, run, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 308, in _init_tfevent_link\n    util.symlink(tfevent_src, tfevent_link)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\util.py\", line 625, in symlink\n    _windows_symlink(target, link)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\util.py\", line 643, in _windows_symlink\n    raise OSError(e.returncode, e.output.decode(errors=\"ignore\").strip())\nPermissionError: [Errno 1] The system cannot find the path specified.\n<\/code><\/pre>\n<p>I\u2019m running commands from PyCharm both on Ubuntu and Windows 10.<\/p>\n<p>I\u2019m ok with using it on Ubuntu, and in the future I will just not use dictionaries. But I thought it may be worth to let you know of the issues on Windows <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-16T14:10:44.651Z",
                "Answer_body":"<p>I\u2019ll take a look at this on Windows\u2014it looks like there might be something else going on there.<\/p>\n<p>The latest release candidate went out last night, which has a fix for the dict support. You should be able to use TensorBoard without the <code>--skip-hparams<\/code> or filtering workarounds now. You\u2019ll need to use the <code>--pre<\/code> option when upgrading Guild:<\/p>\n<pre><code class=\"lang-command\">pip install --upgrade --pre guildai\n<\/code><\/pre>\n<p>You should get <code>0.7.3rc2<\/code>, which has the fix.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-16T14:12:31.583Z",
                "Answer_body":"<p>Brilliant, thanks once again <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-16T16:55:03.545Z",
                "Answer_body":"<p>The issue here I think are unrelated to the flag value type support (original issue). I confirmed that the fix in rc2 is working on Windows.<\/p>\n<p>I think you may be running into something related to your file system on the Windows machine. I\u2019m not able to recreate that error because I think our setups may be different.<\/p>\n<p>A couple questions:<\/p>\n<ul>\n<li>\n<p>Do you see the same errors when running from a standard Windows Command Prompt (rather than the PyCharm terminal?)<\/p>\n<\/li>\n<li>\n<p>Is the current directory on a network drive or otherwise mounted on a different path from what appears as the terminal cwd (e.g. under a symlinked dir, etc.)?<\/p>\n<\/li>\n<\/ul>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-17T11:05:17.233Z",
                "Answer_body":"<p>I forgot to say that I\u2019m using Anaconda both on Ubuntu and Windows.<\/p>\n<p>I think you are correct, because upgrading guild to rc2 didn\u2019t fix the issue in PyCharm terminal. As you said, there is no longer need to filter the samples. However, the same error as before happens, with the \u2018cannot find the path\u2019.<\/p>\n<p>When running<\/p>\n<pre><code>(anomaly_detection) &gt;guild -H E:\\source\\repos\\anomaly_simulation\\Zoo\\Results tensorboard\n<\/code><\/pre>\n<p>directly in Anaconda Prompt the error is similar:<\/p>\n<pre><code>Preparing runs for TensorBoard\nTraceback (most recent call last):\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\blepo\\Anaconda3\\envs\\anomaly_detection\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 44, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 86, in _run_tensorboard\n    monitor.run_once(exit_on_error=True)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 89, in run_once\n    self._refresh_logdir(runs)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\run_util.py\", line 97, in _refresh_logdir\n    self.refresh_run_cb(run, path)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 282, in f\n    return _refresh_run(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 288, in _refresh_run\n    _refresh_tfevent_links(run, run_logdir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 299, in _refresh_tfevent_links\n    _init_tfevent_link(tfevent_path, link, run, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 313, in _init_tfevent_link\n    _init_hparam_session(run, link_dir, state)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 321, in _init_hparam_session\n    _add_hparam_experiment(state.hparam_experiment, writer)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\tensorboard.py\", line 335, in _add_hparam_experiment\n    writer.add_hparam_experiment(hparams, metrics)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 125, in add_hparam_experiment\n    self._add_summary(_HParamExperiment(hparams, metrics))\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 108, in _add_summary\n    self._get_writer().add_event(event)\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 99, in _get_writer\n    self._writer = self._writer_init()\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 92, in &lt;lambda&gt;\n    self._writer_init = lambda: EventFileWriter(\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\summary.py\", line 57, in __init__\n    self._writer = tensorboard.AsyncWriter(\n  File \"c:\\users\\blepo\\anaconda3\\envs\\anomaly_detection\\lib\\site-packages\\guild\\plugins\\tensorboard.py\", line 69, in AsyncWriter\n    record_writer = event_file_writer.RecordWriter(open(filename, \"wb\"))\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\blepo\\\\AppData\\\\Local\\\\Temp\\\\guild-tensorboard-koqw_bh0\\\\52d15085 ResNet_train 2021-03-15 19_31_12 binary binarize=yes dev=no dimensionality=125 horizon=1 learning_rate=0.001 n_feature_maps=64 optimizer=adam window=100\\\\.guild\\\\events.out.tfevents.0000000000.hparams'\n<\/code><\/pre>\n<p>The Anaconda environment is placed on drive C, while the code and Guild home are on E. I don\u2019t know if that\u2019s relevant, but in the traceback above guild\/tensorboard look for the runs in a weird directory.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-19T16:42:36.941Z",
                "Answer_body":"<p>That\u2019s helpful information! I\u2019ll play around with Anaconda and see if that might be the issue. I suspect there\u2019s a path link involved here that\u2019s causing issues on Windows. The cross drive\/volume issue is a good data point.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-22T16:27:26.049Z",
                "Answer_body":"<p>I have encounter this too, but the problem was because I included special characters in the HParams (e.g. labels, tags \u2026etc). So far I notice \u201c{}.\/\u201d might cause problem.<\/p>\n<p>Basically, I changed the code a little bit to work arround this:<\/p>\n<pre><code class=\"lang-python\"># line 142 of ...python\/lib\/site-packages\/python3.7\/guild\/tensorboard.py\ndef _experiment_hparams(runs):\n    hparams = {}\n    for run in runs:\n        for name, val in (run.get(\"flags\") or {}).items():\n            # ==Add this these lines==\n            if isinstance(val, dict):\n                val = str(val)\n            # ==end==\n            hparams.setdefault(name, set()).add(val)\n        hparams.setdefault(SOURCECODE_HPARAM, set()).add(_run_sourcecode(run))\n    return hparams\n<\/code><\/pre>\n<p>My guess is there\u2019s an <code>eval()<\/code> some where that convert the string to values for putting them into hparams properly, and the labels are turned into value, list or dicts, but I was too lazy to dig into the code<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-23T13:36:30.748Z",
                "Answer_body":"<p>Awesome! Yep, that\u2019s the right approach. This fix is available in rc2, which is available as a pre-release.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Docs using -o option outdated",
        "Question_link":"https:\/\/my.guild.ai\/t\/docs-using-o-option-outdated\/568",
        "Question_created_time":1616319728869,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":243,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>In restart-batch-to-continue-optimization the \u201cguild select -o train.py+gp\u201d command actually doesn\u2019t work. I tried with \u201cguild select -Fo gp\u201d and it seemed to work.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-23T13:29:39.361Z",
                "Answer_body":"<p>Thank you! All fixed.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Logging scalars when running ray[tune] tuning fails in a guild run",
        "Question_link":"https:\/\/my.guild.ai\/t\/logging-scalars-when-running-ray-tune-tuning-fails-in-a-guild-run\/557",
        "Question_created_time":1615255994962,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":427,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>In my project I have a bit of automatic tuning of my pytorch-lightning models using ray and then I also automatically apply the model. The logging that ray[tune] uses is a SummaryWriter from tensorboardX package. I am also using tensorboardX SummaryWriter for logging other things in my project. For my own logging, there is no issue with this, but for some reason guild fails with the calls to <code>add_scalar()<\/code> when it\u2019s called from the tune library.<\/p>\n<p>The trace:<\/p>\n<pre><code>3\/8\/2021 5:40:52 PM\nTraceback (most recent call last):\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/ray\/tune\/trial_runner.py\", line 594, in _process_trial\n3\/8\/2021 5:40:52 PM\ndecision = self._process_trial_result(trial, result)\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/ray\/tune\/trial_runner.py\", line 666, in _process_trial_result\n3\/8\/2021 5:40:52 PM\nself._callbacks.on_trial_result(\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/ray\/tune\/callback.py\", line 192, in on_trial_result\n3\/8\/2021 5:40:52 PM\ncallback.on_trial_result(**info)\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/ray\/tune\/logger.py\", line 393, in on_trial_result\n3\/8\/2021 5:40:52 PM\nself.log_trial_result(iteration, trial, result)\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/ray\/tune\/logger.py\", line 631, in log_trial_result\n3\/8\/2021 5:40:52 PM\nself._trial_writer[trial].add_scalar(\n3\/8\/2021 5:40:52 PM\nFile \"\/home\/davina\/miniconda3\/envs\/ap\/lib\/python3.8\/site-packages\/guild\/python_util.py\", line 239, in wrapper\n3\/8\/2021 5:40:52 PM\ncb(wrapped_bound, *args, **kw)\n3\/8\/2021 5:40:52 PM\nTypeError: _handle_scalar() got an unexpected keyword argument 'global_step'\n<\/code><\/pre>\n<p>The line from tune in question in full is <code>self._trial_writer[trial].add_scalar(full_attr, value, global_step=step)<\/code>. This fails.<\/p>\n<p>In my own project I have the following line: <code> logger.add_scalar(f\"{prefix}\/{tag}\", scalar_value, global_step, walltime)<\/code> and this does not fail.<\/p>\n<p>So I went into the ray.tune library and I changed the call to <code>self._trial_writer[trial].add_scalar(full_attr, value, step)<\/code> and reran it. The failure went away.<\/p>\n<p>I dug into the <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/e9271824141583b96a6de7d1d5cebd44a04e43fe\/guild\/plugins\/summary_util.py#L181\" rel=\"noopener nofollow ugc\">github<\/a> source, and it looks like <code>_handle_scalar()<\/code> is expecting <code>step<\/code> and not <code>global_step<\/code>.<\/p>\n<p>I originally needed help with this but as I wrote this I ended up figuring out the answer. Looks like there\u2019s a potential bug here?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-11T15:24:43.849Z",
                "Answer_body":"<p>Thanks for the report - and my apologies for the late reply!<\/p>\n<p>Taking a look at this now.<\/p>\n<p>In the meantime, I suggest disabling Guild\u2019s output scalar support if you\u2019re not using it. Generally if you\u2019re logging directly using tensorboardX or another TF summary logger, you can turn off output scalars as there\u2019s no point doing any extra work looking at the script output for summaries.<\/p>\n<pre><code class=\"lang-yaml\">op:\n  output-scalars: off\n<\/code><\/pre>\n<p>If you have a lot of operations that you need to configure, you can use the <code>operation-defaults<\/code> attribute of a model:<\/p>\n<pre><code>- model: ''  # or use the model name\n  operation-defaults:\n    output-scalars: off\n  operations:\n    op1: {}\n    op2: {}\n<\/code><\/pre>\n<p>I\u2019ll update here with my findings on the behavior you\u2019re seeing (a bug in Guild somewhere no doubt, just not sure what yet).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-11T20:06:43.796Z",
                "Answer_body":"<p>Hi, no problem.<\/p>\n<p>Ah I think I had turned off output scalars for my base operation and had a bunch of other operations and assumed that it would percolate up for some reason. I\u2019ll ad that in to all my operations.<\/p>\n<p>Yeah I think that in your <code>_handle_scalars()<\/code> method, you\u2019ve named the argument <code>step<\/code> but tensorboardX calls it <code>global_step<\/code>, so if a call to tensorboardX uses the argument name when being passed in (e.g., <code>global_step=step<\/code>) it complains because the <code>_handle_scalars()<\/code> called it <code>step<\/code> instead of <code>global_step<\/code> so we get <code>_handle_scalar() got an unexpected keyword argument 'global_step'<\/code>. That\u2019s my guess, though I may be diagnosing something irrelevant haha<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-11T20:22:41.466Z",
                "Answer_body":"<p>Your assessment is right! I\u2019m cleaning these up now with some tests.<\/p>\n<p>In retrospect this is unrelated to output scalars so please ignore my earlier examples.<\/p>\n<p>If you have defined plugins for the operation in question, you should be able to fix this issue by removing that line or setting it to an empty list. Guild may be auto-detecting something there, so setting this explicitly may solve the issue:<\/p>\n<pre><code class=\"lang-yaml\">op:\n  plugins: []\n<\/code><\/pre>\n<p>I\u2019ll update here when a fix is ready.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to view runs on all remotes?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-to-view-runs-on-all-remotes\/554",
        "Question_created_time":1614500077203,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":377,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi, I have concurrent runs on multiple remotes (say 4 runs on 4 different remote). Is there a way to view the status of all runs from a single interface? I would imagine that <code>guild runs<\/code> should show them, but for some reason the remote runs appear as \u201cterminated\u201d (while in fact running) and switch to \u201ccompleted\u201d when they are finished.<br>\nI am working with a cluster that has shared drives if that could be taken advantage of.<\/p>\n<p>Thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-03-01T14:40:33.045Z",
                "Answer_body":"<p>Guild has an issue when showing \u201crunning\u201d status on shared drives where the underlying processes are owned by another system. Unfortunately there\u2019s no good workaround for that, other than using Guild\u2019s remote copy\/sync capability. However that\u2019s quite inefficient as it requires whole copies of the runs just to get an accurate status.<\/p>\n<p>I\u2019ll bump the priority on this item as it comes up a fair amount, esp e.g. when working with Slurm and other HPC envs that use shared drives.<\/p>\n<p>I opened a new <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/272\">issue on GitHub<\/a> to explicitly track the resolution of this problem. If you watch that issue you\u2019ll get updates when it\u2019s resolved.<\/p>\n<p>Sorry about that!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-03-01T14:51:35.000Z",
                "Answer_body":"<p>Thank you.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Regular expression not detecting latest successful run for required operation dependency",
        "Question_link":"https:\/\/my.guild.ai\/t\/regular-expression-not-detecting-latest-successful-run-for-required-operation-dependency\/549",
        "Question_created_time":1614186759263,
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":374,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>According to the docs I can specify multiple supported operations for a required statement by using regular expressions<\/p>\n<aside class=\"quote no-group\" data-username=\"guildai\" data-post=\"1\" data-topic=\"197\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/guildai\/40\/103_2.png\" class=\"avatar\"><a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197\/1\">Guild File Reference<\/a>\n<\/div>\n<blockquote>\n<p>Value is a regular expression matching a suitable operation name. Multiple operations are supported by specifying the appropriate regular expression.<\/p>\n<\/blockquote>\n<\/aside>\n<p>An example is also given<\/p>\n<aside class=\"quote no-group\" data-username=\"guildai\" data-post=\"1\" data-topic=\"192\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/guildai\/40\/103_2.png\" class=\"avatar\"><a href=\"https:\/\/my.guild.ai\/t\/guild-file-cheatsheet\/192\/1\">Guild File Cheatsheet<\/a>\n<\/div>\n<blockquote>\n<p>Require <code>model.ckpt<\/code> from any operation that starts with <code>train-<\/code> :<\/p>\n<pre><code>train:\n  requires:\n    - operation: ^train-\n      select: model\\.ckpt\n<\/code><\/pre>\n<\/blockquote>\n<\/aside>\n<p>However whenever I try to selecting the latest run using regular expressions, for example using the following guild file<\/p>\n<pre><code>\ntrain-pull:\n    main: script\n    \ntrain-extract:\n    main: script\n\ntest:\n  requires:\n  - operation: ^train-\n<\/code><\/pre>\n<p>The latest successful run is not detected<\/p>\n<pre><code>guild: run failed because a dependency was not met: could not resolve 'operation:^train-' in ^train- resource: no suitable run for ^train-\n<\/code><\/pre>\n<p>If I specify the run id then the run is detected, but this seems to work regardless of if the passed run id is compatible with the regular expression given in the guild file.<\/p>\n<p>Instead of this behavior I would expect guild to detect the latest run done for either train-pull  or train-extract and use it as the operation requirement for test.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-02-24T17:23:54.402Z",
                "Answer_body":"<p>There\u2019s a bug in the docs. The regex is a full match, not a starts-with. You need this:<\/p>\n<pre><code class=\"lang-yaml\">test:\n  requires:\n  - operation: ^train-.+\n<\/code><\/pre>\n<p>Also, as a tip, you can include a <code>name<\/code> attribute to cleanup the interface to that requirement.<\/p>\n<pre><code class=\"lang-yaml\">test:\n  requires:\n  - operation: ^train-.+\n    name: train\n<\/code><\/pre>\n<p>This lets you specify a run ID for the dependency using a flag-like syntax:<\/p>\n<pre><code class=\"lang-command\">guild run test train=&lt;run ID&gt;\n<\/code><\/pre>\n<p>Use whatever name makes most sense. I just picked <code>train<\/code> as an example.<\/p>\n<p>Guild intentionally disregards the op requirement when you specify a full run ID. The rationale here is that if you\u2019re specifying a full ID, you are intentionally overriding any specs in the Guild file. If you use a partial run ID, Guild uses the op requirement spec.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-24T17:31:43.113Z",
                "Answer_body":"<p>Thanks for the quick reply, that worked perfectly.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"EDITOR with VS Code not working on Windows",
        "Question_link":"https:\/\/my.guild.ai\/t\/editor-with-vs-code-not-working-on-windows\/545",
        "Question_created_time":1613457478077,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":284,
        "Question_has_accepted_answer":false,
        "Question_body":"<aside class=\"quote no-group\" data-username=\"guildai\" data-post=\"1\" data-topic=\"146\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/guildai\/40\/103_2.png\" class=\"avatar\"> guildai:<\/div>\n<blockquote>\n<p>Guild uses the editor defined in <code>VISUAL<\/code> or <code>EDITOR<\/code> environment variables.<\/p>\n<\/blockquote>\n<\/aside>\n<p>I had set the EDITOR variable to code in Windows 10. This is opening up a file in VS Code. But the file is immediately deleted and guild is auto-confirming the default values, So I am not able to change the values in the text editor.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-02-16T14:54:15.199Z",
                "Answer_body":"<p>This sounds like a bug. Would you mind <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\">opening an issue on GitHub<\/a> for this? Just paste your message in from here. Thanks a lot!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T14:14:49.352Z",
                "Answer_body":"<p>(copied from GitHub issue update)<\/p>\n<p>Okay - I take it back. I would not call this a bug. What you\u2019re seeing I believe is expected behavior.<\/p>\n<p>Define <code>EDITOR<\/code> using the <code>code<\/code> command with the <code>-w<\/code> option (wait). This causes VS Code to block until you close the file. This is a requirement for the Guild interface to that file.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"OSError: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions",
        "Question_link":"https:\/\/my.guild.ai\/t\/oserror-winerror-10013-an-attempt-was-made-to-access-a-socket-in-a-way-forbidden-by-its-access-permissions\/546",
        "Question_created_time":1613603564104,
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":3189,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I get forbidden access even when I run with administrative privileges. I re-run in again and it usually works. How can I fix this  behavior?<\/p>\n<pre><code>(biobench-thMxqAli) \u03bb guild tensorboard 1\nPreparing runs for TensorBoard\nWARNING: Guild took 27.80 seconds to prepare runs. To reduce startup time, try running with '--skip-images' or '--skip-hparams' options or reduce the number of runs with filters. Try 'guild tensorboard --help' for filter options.\nWARNING: webfiles.zip static assets not found: c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\plugins\\webfiles.zip\n2021-02-17 15:04:42.417335: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2021-02-17 15:04:42.417554: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nTraceback (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sarat.chinni\\.virtualenvs\\biobench-thMxqAli\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 98, in _run_tensorboard\n    tensorboard.serve_forever(\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 636, in serve_forever\n    run_simple_server(app, host, port, ready_cb)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 602, in run_simple_server\n    server, _ = make_simple_server(tb_app, host, port)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\guild\\tensorboard.py\", line 615, in make_simple_server\n    server = serving.make_server(host, port, app, threaded=True)\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\werkzeug\\serving.py\", line 847, in make_server\n    return ThreadedWSGIServer(\n  File \"c:\\users\\sarat.chinni\\.virtualenvs\\biobench-thmxqali\\lib\\site-packages\\werkzeug\\serving.py\", line 740, in __init__\n    HTTPServer.__init__(self, server_address, handler)\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\socketserver.py\", line 452, in __init__\n    self.server_bind()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\http\\server.py\", line 138, in server_bind\n    socketserver.TCPServer.server_bind(self)\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\socketserver.py\", line 466, in server_bind\n    self.socket.bind(self.server_address)\nOSError: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-02-18T00:09:14.422Z",
                "Answer_body":"<p>My guess is that the initial port selected is in use and Guild isn\u2019t cycling correctly to a new port. That\u2019s surprising though because the port is chosen at random and it would be terrifically low odds consistently pick a port that\u2019s in use.<\/p>\n<p>How often are you seeing this error?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T00:14:13.270Z",
                "Answer_body":"<p>I observe it quite often, once in 5-10 runs(kind of once in 1-2 days).<\/p>\n<p>I usually run it again, once or twice and it starts working.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T00:20:49.348Z",
                "Answer_body":"<p>My guess is wrong, at least on Windows 10. This is quite surprising to me, but you can bind to a port in use without errors. I don\u2019t think subsequent bindings are active but I would expect an error.<\/p>\n<p>E.g. on Windows 10, using either admin or non-admin command prompts, you can run this command as many times as you like:<\/p>\n<pre><code>&gt; python -m http.server 8080\n<\/code><\/pre>\n<p>The first time 8080 is bound appears to be the active socket listener. Subsequent commands won\u2019t get connections. Very surprising behavior for an operating system.<\/p>\n<p>But anyway, that\u2019s unrelated I think.<\/p>\n<p>What version of Windows are you running?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T00:26:31.234Z",
                "Answer_body":"<p>I am using Windows-10. Is the error due to already used ports from previous guild sessions?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T00:30:10.881Z",
                "Answer_body":"<p>I don\u2019t think so. You can run this command multiple times without errors on Windows 10:<\/p>\n<pre><code class=\"lang-command\">guild tensorboard --port 8080\n<\/code><\/pre>\n<p>I wonder if the range of legal ports on Windows 10 is narrower than Guild thinks. Let me take a look.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-02-18T00:37:27.416Z",
                "Answer_body":"<p>I\u2019m not able to recreate a problem by picking the outer range of the ports that Guild uses.<\/p>\n<p>On you system, can you replicate the error when you run either of these commands?<\/p>\n<pre><code class=\"lang-command\">guild tensorboard --port 49152\n<\/code><\/pre>\n<pre><code class=\"lang-command\">guild tensorboard --port 65535\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Scalars not getting saved",
        "Question_link":"https:\/\/my.guild.ai\/t\/scalars-not-getting-saved\/527",
        "Question_created_time":1611248492978,
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":363,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m new to guild.ai and trying to use the guild.yml files to save all relevant information including scalars. The scalars are however not being saved.<\/p>\n<p>This is my code:<\/p>\n<pre><code>boston = load_boston()\nX = pd.DataFrame(boston.data, columns=boston.feature_names)\ny = boston.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nnamedf = ['X_train', 'X_test']\nnamenp = ['y_train', 'y_test']\n\nreg = Ridge(alpha=0.9)\nfitted = reg.fit(X, y)\n\nprint(\"score: %f\" % fitted.score(X, y))\n<\/code><\/pre>\n<p>and this is my guild.yml file:<\/p>\n<pre><code>ridge-regression:\n  description: fit ridge regression using boston data.\n  notebook: Checklist.ipynb\n  flags:\n    alpha:\n      description: alpha value in ridge regression\n      nb-replace: 'alpha=(\\d+)'\n  output-scalers:\n    score: 'score: (\\value)'\n<\/code><\/pre>\n<p>When I print out all information on the command line there are no scalars to be seen. Does anyone know why?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-21T17:47:53.850Z",
                "Answer_body":"<p>The problem is the spelling of <code>output-scalars<\/code> attribute - you have a typo there.<\/p>\n<p>It would be nice if Guild told you that but sadly you can mistype attribute names and Guild just ignores them, in many cases.<\/p>\n<p>You may run into other problems, related to the patterns. For those you can use the <code>--test-output-scalars<\/code> option to see how Guild applies the patterns for an operation. That would look like this:<\/p>\n<pre><code class=\"lang-command\">guild cat --output &lt;run ID to test&gt; | guild run &lt;op&gt; --test-output-scalars -\n<\/code><\/pre>\n<p>Note the use of <code>-<\/code> (dash) as the argument  to <code>--test-output-scalars<\/code>. That tells Guild to read from stdin. Otherwise you can use a filename containing output to test.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T18:55:46.436Z",
                "Answer_body":"<p>Thank you for your reply! The misspelling was a one-off <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/smiley.png?v=9\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"> The problem was that I was printing to the Jupyter notebook and not to the console\u2026<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T19:41:04.112Z",
                "Answer_body":"<p>The code that you have in the original post looks okay to me. This <code>print(\"score: ...\")<\/code> line will print to the output for the cell but Guild will see this.<\/p>\n<p>How did you change your code to get this working?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-25T17:07:49.423Z",
                "Answer_body":"<p>I added the line:<\/p>\n<pre><code>sys.stdout = open('\/dev\/stdout', 'w') \n<\/code><\/pre>\n<p>before printing the score. Guild didn\u2019t seem to be finding the output from the cell before.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-26T12:26:55.892Z",
                "Answer_body":"<p>I\u2019m glad you have this working! This sounds like it may be a Guild bug. If it\u2019s convenient to reproduce this problem, could you paste the cell contents of the broken version here\u2014or share a simplified ipynb (e.g. via attachment, gist, etc.)?<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dependecies Problem",
        "Question_link":"https:\/\/my.guild.ai\/t\/dependecies-problem\/523",
        "Question_created_time":1611065190742,
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":536,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Dear all,<br>\nI am new to Guild.ai<br>\nI have a train file called train.py that needs as input a parameter (using argparse) that is called config_filepath .<br>\nI am trying over and over to run:<br>\nguild run train.py config_filepath=config_thyroid_segnet_multi_h5.json<\/p>\n<p>but nothing works. Everytime I get the following message:<br>\nFileNotFoundError: [Errno 2] No such file or directory: \u2018config_thyroid_segnet_multi_h5.json\u2019<\/p>\n<p>The funny part is that if I check in the runs directory (performing guild ls) the file is there. What am I doing wrong? I tried also to create a guild.yml file like following:<br>\ntrain.py:<br>\ndescription: Say hello to my friends<br>\nmain: train<br>\ndefault: yes<br>\nflags-import:<br>\n- config_filepath<\/p>\n<p>And alternatively to create a guild.yml with the tag requires.<\/p>\n<p>Nothing works\u2026<\/p>\n<p>Thanks in advance for your support<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-19T19:57:16.865Z",
                "Answer_body":"<p>Hello and welcome!<\/p>\n<p>I\u2019m guessing the file you\u2019re looking for is being picked up as source code and is located under <code>.guild\/sourcecode<\/code> under the run directory.<\/p>\n<p>For example, I would expect this to not show the file:<\/p>\n<pre><code class=\"lang-command\">guild ls\n<\/code><\/pre>\n<p>I would expect it to appear in this case:<\/p>\n<pre><code class=\"lang-command\">guild ls --sourcecode\n<\/code><\/pre>\n<p>There are a number of ways you might address this:<\/p>\n<ol>\n<li>Specify an absolute path to the config file rather than a relative path.<\/li>\n<li>Modify your script to look under <code>.guild\/sourcecode<\/code> when it gets a relative path for this value.<\/li>\n<li>Modify the Guild file to store your source code under the run directory root.<\/li>\n<li>Modify the Guild file to make all possible config files available as a dependency.<\/li>\n<li>Get real fancy and use a flag reference in your dependency spec to resolve only the file needed.<\/li>\n<\/ol>\n<p>Haha, sorry - that\u2019s lot of approaches. Let me fill in each. You have an important question and the answers here are generally helpful.<\/p>\n<p><strong>Option 1 - absolute paths<\/strong><\/p>\n<p>This is a quick-and-dirty method that takes the relative path problem off the table. Use this to get things working ASAP. It\u2019s not a good solution because it\u2019s totally surprising and unintuitive.<\/p>\n<p><strong>Option 2 - look for config files under source code dir<\/strong><\/p>\n<p>Any time you\u2019re changing your code to accommodate Guild it\u2019s an anti-pattern. In some cases Guild may be missing an important feature and there\u2019s no other simple way to fix the problem. In this case, I think there are better options.<\/p>\n<p><strong>Option 3 - Save source code in the run root<\/strong><\/p>\n<p>You can do this with this config:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  sourcecode:\n    dest: .\n<\/code><\/pre>\n<p>This isn\u2019t bad but it now floods your run directory with all your source code files. Personally I like to have the source code out-of-view and <code>.guild\/sourcecode<\/code> is a good spot. This lets you focus on your run-generated files and required files for each run.<\/p>\n<p><strong>Option 4 - Include all possible config files as dependencies<\/strong><\/p>\n<p>This is the option that I prefer as it\u2019s not terribly complicated and is pretty good spelling of what you want I think.<\/p>\n<p>In your Guild file, it\u2019d look like this:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  requires:\n    - file: config_.*\\.json\n<\/code><\/pre>\n<p>Note the pattern is a regular expression and not a glob wildcard. Sorry about that! There\u2019s an issue that talks about changing this to globs by default.<\/p>\n<p>This is slightly brute force as it copies all possible config files rather than just the one you want. Still, it\u2019s direct and avoids the head-scratchingly strange pattern used in the last option.<\/p>\n<p><strong>Option 5 - use a flag ref in your dependency spec<\/strong><\/p>\n<p>This approach uses a flag to specify the config file\u2014or part of the filename\u2014and uses that flag value in a dependency spec.<\/p>\n<pre><code class=\"lang-yaml\">train:\n  flags-import: all\n  flags-import-skip:\n    - config_filepath\n  flags:\n    config:\n      description: Config to use in train\n      required: yes\n      choices: [...]  # optionally make legal values available\n      arg-name: config_filepath\n  requires:\n    - file: ${config}\n<\/code><\/pre>\n<p>You could spell the file pattern as <code>${config}_h5.json<\/code> and make it more of a name than a filename.<\/p>\n<p>You want to skip importing <code>config_filepath<\/code> because that exposes the user to the problem you\u2019re facing now.<\/p>\n<p>This method is more complicated but I think it\u2019s nice to insulate the user from file path details. I\u2019m not officially recommending this because option 4 is so much simpler. But this is probably the approach I\u2019d take in a serious effort to Guildify a project.<\/p>\n<p>Clear as mud?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T11:28:48.333Z",
                "Answer_body":"<p>Thank you very much for your answer. I actually tried your best solution and now the problem that I face in Windows 10 Home Edition is:<br>\nguild: run failed because a dependency was not met: unable to link to dependency source: [Errno 1] You do not have sufficient privilege to perform this operation.<\/p>\n<p>The only solution that works is the absolute path, but it\u00b4s a solution that I don\u00b4t want to use.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T13:21:56.740Z",
                "Answer_body":"<p>If you open your command line app as Administrator this error goes away.<\/p>\n<p>Alternatively, add <code>target-type: copy<\/code> to the file dependency:<\/p>\n<pre><code>op:\n  requires:\n    - file: ...\n      target-type: copy\n<\/code><\/pre>\n<p>This tells Guild to copy the files rather than link to them so you won\u2019t need that privilege in Windows.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T13:31:23.740Z",
                "Answer_body":"<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"2\" data-topic=\"523\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<pre><code>config_.*\\.json\n<\/code><\/pre>\n<\/blockquote>\n<\/aside>\n<p>Thank you very much. It works if I input as file directly the name of the file (and  I have to repeat the target-type: copy after each of them). The regular expression that you sent me, in spite being correct, doesn\u00b4t work:<br>\nguild: run failed because a dependency was not met: could not resolve 'file:config_.<em>.json\u2019 in file:config_.<\/em>.json resource: cannot find source file 'config_.*.json<\/p>\n<pre><code>train:\n  description: training script\n  requires:\n    - file: config_.*\\.json\n      target-type: copy\n    - file: .*\\.schema\n      target-type: copy\n  flags-import: all\n\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-21T19:35:35.403Z",
                "Answer_body":"<p>I gave you totally wrong semantics there! Here\u2019s what you want:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  description: training script\n  requires:\n    - file: .\n      select: config_.*\\.json\n      target-type: copy\n      name: config\n    - file: .\n      select: .*\\.schema\n      target-type: copy\n      name: schema\n  flags-import: all\n<\/code><\/pre>\n<p>This spelling is maybe a bit surprising but here\u2019s what\u2019s going on. You\u2019re not resolving a single file but a set of files coming from a container. Guild lets you resolve files from directories or archives. In this case the files you want are in the project directory (<code>.<\/code>) you <em>select<\/em> them using the pattern in <code>select<\/code>. This technique can be applied to selecting files from a tar or zip file as well. That\u2019s why the spelling is perhaps a little odd.<\/p>\n<p>I added <code>name<\/code> there to help the progress read better. Otherwise Guild makes up a name using the file spec.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-22T12:18:35.238Z",
                "Answer_body":"<p>Amazing, thank you very much, this is exactly what I was searching for. Your library is amazing, I would just suggest to improve the documentation because I would have never reached your solution without you.<br>\nThank you again<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Sharing sourcecode attribute between models",
        "Question_link":"https:\/\/my.guild.ai\/t\/sharing-sourcecode-attribute-between-models\/525",
        "Question_created_time":1611158818181,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":238,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have a <code>guild.yml<\/code> that looks like this:<\/p>\n<pre><code>- include: guild\/model1.yml\n- include: guild\/model2.yml\n- include: guild\/model3.yml\n<\/code><\/pre>\n<p>where <code>guild\/model1.yml<\/code> and <code>guild\/model2.yml<\/code> looks something like this:<\/p>\n<pre><code>- model: model1\/model2\n  sourcecode:\n    - exclude:\n        dir:\n          - data\n          - build\n          - libs\n    - include:\n        dir:\n          - scripts\n          - module\n<\/code><\/pre>\n<p>As you notice, I have to specify the <code>sourcecode<\/code> attribute for each model, which gets a bit tedious. I am wondering if there is a better way to do this. Any suggestion?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-20T16:31:41.115Z",
                "Answer_body":"<p>Create another <code>yml<\/code> file that defines some config to inherit from and include that common file as needed in your model defs.<\/p>\n<p>See <a href=\"https:\/\/github.com\/gar1t\/guild-includes-example\" class=\"inline-onebox\">GitHub - gar1t\/guild-includes-example<\/a>.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compare command not working with hiplot on Windows 10",
        "Question_link":"https:\/\/my.guild.ai\/t\/compare-command-not-working-with-hiplot-on-windows-10\/514",
        "Question_created_time":1610356086236,
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":270,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am able to use <code>hiplot<\/code> in Jupyter notebook and also start using it via command line using <code>python -m hiplot<\/code>. But when I try to use it with <code>guild compare<\/code> I get invalid windows application error.<\/p>\n<pre><code>C:\\Users\\sarat.chinni\\Codes_sequencing\\hiplot&gt;guild compare --tool hiplot\nPreparing data for compare\nTraceback (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sarat.chinni\\Codes_sequencing\\biobench\\sandbox\\Sarat\\supervised_sequencing\\.venv\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    _main()\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\main_bootstrap.py\", line 66, in _main\n    guild.main.main()\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\click\\decorators.py\", line 21, in new_func\n    return f(get_current_context(), *args, **kwargs)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\click_util.py\", line 213, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\commands\\compare.py\", line 224, in compare\n    compare_impl.main(args, ctx)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\commands\\compare_impl.py\", line 73, in main\n    _compare_with_tool(args)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\commands\\compare_impl.py\", line 566, in _compare_with_tool\n    _compare_with_hiplot(args)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\commands\\compare_impl.py\", line 579, in _compare_with_hiplot\n    hiplot.compare_runs(get_data_cb)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\plugins\\hiplot.py\", line 36, in compare_runs\n    _handle_default(hiplot, data)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\plugins\\hiplot.py\", line 52, in _handle_default\n    _generate_hiplot_html(hiplot, csv_path, html_path)\n  File \"c:\\users\\sarat.chinni\\codes_sequencing\\biobench\\sandbox\\sarat\\supervised_sequencing\\.venv\\lib\\site-packages\\guild\\plugins\\hiplot.py\", line 100, in _generate_hiplot_html\n    html = subprocess.check_output([hiplot_include, \"--format\", \"html\", csv_path])\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 411, in check_output\n    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 489, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 854, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2032.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 1307, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\nOSError: [WinError 193] %1 is not a valid Win32 application\n<\/code><\/pre>\n<p>Does this has to do anything with <code>hiplot<\/code> is python script and not windows executable?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-11T15:13:45.508Z",
                "Answer_body":"<p>I\u2019m able to recreate. Yes it\u2019s a fault with Guild in assuming that HiPlot provides a Windows script for the library (and lack of tests on Windows). This will be fixed in the next release.<\/p>\n<p>There\u2019s unfortunately no easy work around for this, beyond running in a Linux VM.<\/p>\n<p>I\u2019ll update here with progress.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-20T07:19:13.577Z",
                "Answer_body":"<p>Thanks for addressing this issue, I am able to use <code>hiplot<\/code> on windows with <code>guildai-0.7.3.dev1<\/code>.<\/p>\n<p>I am not able to install <code>guildai-0.7.2<\/code>(latest stable release) with python-3.8 in windows-10, looks like wheel files are missing in <a href=\"https:\/\/pypi.org\/project\/guildai\/#files\" rel=\"noopener nofollow ugc\">PyPi website<\/a>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-20T14:53:54.449Z",
                "Answer_body":"<p>Yes indeed \u2014 good catch! I\u2019m working to get the missing Windows platforms built now.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-20T16:25:08.779Z",
                "Answer_body":"<p>All fixed - thanks for the note!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild runs showing as error instead of pending",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-runs-showing-as-error-instead-of-pending\/518",
        "Question_created_time":1610486130764,
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":392,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019ve been using my guild.yml file with no issue so far. I\u2019m not sure what happened but suddenly my pending runs are showing up as errors (no logs, no error messages, but the environment somehow hasn\u2019t been resolved either).<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/c780081e0276246cae200732bc38d932d3a3adef.png\" alt=\"Screen Shot 2021-01-12 at 1.07.45 PM\" data-base62-sha1=\"ssRk2IH4fTBNzGvi7VQNIuHVTL9\" width=\"357\" height=\"195\"><br>\nThis behavior also shows on <code>guild runs<\/code>:<\/p>\n<pre><code>[1:1609e5a4]   imputer   2021-01-12 13:14:13  error      none ckd\n[2:9ceadd83]   imputer   2021-01-12 13:14:12  running    none ckd\n[3:323f949e]   imputer+  2021-01-12 13:14:12  running    \n[4:b9c5ba05]   fo        2021-01-12 13:14:09  running \n<\/code><\/pre>\n<p>The pending run eventually ran and succeeded, and the error went away. But it\u2019s unclear why there was an error in the first place. I took a look at guild view and I see this, which looks strange:<\/p>\n<pre><code>ERROR: 128.97.25.29 - - [12\/Jan\/2021 05:11:03] code 400, message Bad request syntax ('\\t\\x00\\x00\\x00\\x01\\x00\\x00\\x00\u00ff\u00fe\u00ff\\x0fQ\\x00u\\x00a\\x00l\\x00y\\x00s\\x00P\\x00r\\x00o\\x00b\\x00e\\x00T\\x00e\\x00s\\x00t\\x00\\x02\\x00\\x00\\x00')\nERROR: 128.97.25.29 - - [12\/Jan\/2021 05:11:03] code 400, message Bad request syntax ('\u00ff\u00ff\u00ff\u00ff')\nERROR: 128.97.25.29 - - [12\/Jan\/2021 05:11:48] code 400, message Bad request syntax ('\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\nERROR: 128.97.25.29 - - [12\/Jan\/2021 05:12:33] code 400, message Bad request syntax ('gqw7')\nERROR: 127.0.0.1 - - [12\/Jan\/2021 11:06:18] code 400, message Bad request syntax ('\\t\\x00\\x00\\x00\\x01\\x00\\x00\\x00\u00ff\u00fe\u00ff\\x0fQ\\x00u\\x00a\\x00l\\x00y\\x00s\\x00P\\x00r\\x00o\\x00b\\x00e\\x00T\\x00e\\x00s\\x00t\\x00\\x02\\x00\\x00\\x00')\nERROR: 127.0.0.1 - - [12\/Jan\/2021 11:06:18] code 400, message Bad request syntax ('\u00ff\u00ff\u00ff\u00ff')\nERROR: 127.0.0.1 - - [12\/Jan\/2021 11:07:03] code 400, message Bad request syntax ('\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\nERROR: 127.0.0.1 - - [12\/Jan\/2021 11:07:48] code 400, message Bad request syntax ('gqw7')\n<\/code><\/pre>\n<p>However, when I do a longer run or try to use queues, they never run. They just show as errors.<\/p>\n<p>Not sure how to debug.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-12T22:43:17.195Z",
                "Answer_body":"<p>Sorry you\u2019re running into these issues! I suspect the 400s you\u2019re seeing in the View logs are unrelated and represent some other problem.<\/p>\n<p>The status <code>error<\/code> there is a misnomer - it should read something like <code>unknown<\/code>. I believe what\u2019s going on is that View and the runs list are catching the run in the middle of initialization. This typically is very fast (milliseconds) so you would not typically catch the run in this state. In your case something is slowing the init down a LOT.<\/p>\n<p>Depending on the number of runs and file count, View can take a long time to update its status. So if it catches the runs in this intermediary state, it could show in View for quite some time. That said, you\u2019re seeing this over and over, so something else is systematically making init MUCH slower than normal.<\/p>\n<p>My first thought with something like this is that your system is in a degraded state. E.g. extremely low memory to trigger swapping or a disk problem that will cause high wait times on disk IO.<\/p>\n<p>But if that\u2019s the case you would <em>probably<\/em> see major issues all over the place. It\u2019s possible that this problem is showing up for Guild runs because they\u2019re hitting sectors on the disk that are causing problems. I don\u2019t give this idea much credence as it\u2019s a bit of a stretch.<\/p>\n<p>The other area \u2014 and more likely the culprit \u2014 is that there are inter-process locks that causing run init to wait on other runs. I need to look at the code to see what could be going on.<\/p>\n<p>In the meantime, stop all running Guild queues and see if this problem keeps popping up. To be certain you\u2019re stopping all queues, check your process list:<\/p>\n<p>On Linux:<\/p>\n<pre><code class=\"lang-command\">ps -ef | grep queue_main\n<\/code><\/pre>\n<p>On macOS:<\/p>\n<pre><code class=\"lang-command\">ps -aux | grep queue_main\n<\/code><\/pre>\n<p>With the queues out of the way, I suspect the issue will clear up. If not, I think it\u2019s something with the environment.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-12T23:01:15.837Z",
                "Answer_body":"<p>No problem, thanks so much for the detailed breakdown!<\/p>\n<p>It turns out you were right. It looks like there were some rogue queue processes floating on my machine. Once I killed them, it fixed!<\/p>\n<p>For background, I have this script:<\/p>\n<pre><code class=\"lang-bash\">guild run fo --stage-trials\nguild run all-imputers --stage-trials\nfor _ in `seq 10`; do guild run queue --background -y; done\n<\/code><\/pre>\n<p>Then I would monitor my runs (which takes a few hours), and then once it\u2019s done I had another script to kill the queues:<\/p>\n<pre><code>guild stop -o queue\nguild runs rm -o queue\n<\/code><\/pre>\n<p>I guess something had gone wrong because the queue processes were still alive, so I added the following line to the end of the script: <code>pkill $(ps -ef | grep queue_main | awk '{print $2}')<\/code><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-12T23:10:43.126Z",
                "Answer_body":"<p>That\u2019s helpful input. Guild could provide a command to look for these rogue processes.<\/p>\n<p>I think this is also a case for a proper scheduler \u2014 one with a UI to view and report status. Queues are a nice abstraction but as you demonstrate they rely on some higher level coordination.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dependency mismatch between guild.ai and tensorflow",
        "Question_link":"https:\/\/my.guild.ai\/t\/dependency-mismatch-between-guild-ai-and-tensorflow\/512",
        "Question_created_time":1610084094576,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":606,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I currently have tensorflow installed, When I try to install guild.ai There is a dependency version conflict and pipenv is not able to resolve it. The version conflicting dependency is tensorboard.<\/p>\n<pre><code>sarat@sarat-pc:~\/Codes\/guild_start $ pipenv install guildai\nInstalling guildai...\nAdding guildai to Pipfile's [packages]...\n\u2714 Installation Succeeded \nPipfile.lock (66d06e) out of date, updating to (085a73)...\nLocking [dev-packages] dependencies...\nLocking [packages] dependencies...\nBuilding requirements...\nResolving dependencies...\n\u2718 Locking Failed! \n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/resolver.py\", line 741, in _main\n[ResolutionFailure]:       resolve_packages(pre, clear, verbose, system, write, requirements_dir, packages, dev)\n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/resolver.py\", line 702, in resolve_packages\n[ResolutionFailure]:       results, resolver = resolve(\n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/resolver.py\", line 684, in resolve\n[ResolutionFailure]:       return resolve_deps(\n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/utils.py\", line 1395, in resolve_deps\n[ResolutionFailure]:       results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(\n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/utils.py\", line 1108, in actually_resolve_deps\n[ResolutionFailure]:       resolver.resolve()\n[ResolutionFailure]:   File \"\/home\/sarat\/.local\/lib\/python3.8\/site-packages\/pipenv\/utils.py\", line 833, in resolve\n[ResolutionFailure]:       raise ResolutionFailure(message=str(e))\n[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies.\n  First try clearing your dependency cache with $ pipenv lock --clear, then try the original command again.\n Alternatively, you can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation.\n  Hint: try $ pipenv lock --pre if it is a pre-release dependency.\nERROR: Could not find a version that matches tensorboard&lt;2.3.0,&gt;=2.0.0,~=2.4 (from tensorflow==2.4.0-&gt;-r \/tmp\/pipenvjhzpx270requirements\/pipenv-2yv9nm20-constraints.txt (line 2))\nTried: 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0, 1.12.0, 1.12.1, 1.12.2, 1.13.0, 1.13.1, 1.14.0, 1.15.0, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.4.0\nSkipped pre-versions: 1.6.0rc0\nThere are incompatible versions in the resolved dependencies:\n  tensorboard&lt;2.3.0,&gt;=2.0.0 (from guildai==0.7.1.post1-&gt;-r \/tmp\/pipenvjhzpx270requirements\/pipenv-2yv9nm20-constraints.txt (line 3))\n  tensorboard~=2.4 (from tensorflow==2.4.0-&gt;-r \/tmp\/pipenvjhzpx270requirements\/pipenv-2yv9nm20-constraints.txt (line 2))\n<\/code><\/pre>\n<p>So pipenv is not able to find compatible tensorflow and guild.ai versions.<\/p>\n<p>What version of tensorflow does guild.ai support?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2021-01-08T14:49:41.862Z",
                "Answer_body":"<p>Guild does support TB 2.4 but that\u2019s available in 0.7.2. Good news is that will be released within a week. If you want you can use a pre-release version. Install it using:<\/p>\n<pre><code class=\"lang-command\">pip install --upgrade --pre guildai\n<\/code><\/pre>\n<p>If that still gives you trouble please let us know and we\u2019ll get it resolved ASAP. The latest TensorBoard is intended to be fully supported.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2021-01-09T03:35:46.332Z",
                "Answer_body":"<p>I have installed the pre-release version of guild-0.7.2 and there is no tensorboard version conflict.<\/p>\n<pre><code>pipenv install guildai==0.7.2rc1\n<\/code><\/pre>\n<p>Thanks for quick response.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Module 'yaml' has no attribute 'encode_val'",
        "Question_link":"https:\/\/my.guild.ai\/t\/module-yaml-has-no-attribute-encode-val\/503",
        "Question_created_time":1608144416901,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":405,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi, I have just  installed guildai on a new server in a conda env (py 3.7) and get this error. I have tried reinstalling  PyYAML and pip.<br>\nLet me know if you have suggestions!<br>\nThanks, Shannon<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-12-16T19:20:59.625Z",
                "Answer_body":"<p>What are you running that generates this error? What version of Guild are you running?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-16T21:59:54.036Z",
                "Answer_body":"<p>I just am running a guild.yml file (so guild run\u2026) Running this file works fine on the other servers. I just installed guilai with pip install guildai.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-17T15:36:01.252Z",
                "Answer_body":"<p>Okay got it. Thanks for this report!<\/p>\n<p>I released <code>0.7.1.post1<\/code>, which fixes this issue. Go ahead an upgrade via <code>pip install --upgrade guildai<\/code> to get the fix.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Debugging and profiling guild",
        "Question_link":"https:\/\/my.guild.ai\/t\/debugging-and-profiling-guild\/500",
        "Question_created_time":1607965561395,
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":512,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I sometimes see <code>guild<\/code> taking a long time to start a run compared to just running the command that I get from <code>--print-cmd<\/code>. I realise this is because <code>guild<\/code> has to resolve dependencies etc., but I would like to understand if there is an easy way to debug and especially profile what steps \/ operations that is expensive in the <code>guild<\/code> command.<\/p>\n<p>I am aware of the <code>guild --debug<\/code> flag, but in my particular case it doesn\u2019t provide much info about what is taking a long time.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-12-15T19:47:26.311Z",
                "Answer_body":"<p>Run your command with <code>PROFILE=1<\/code> env var like this:<\/p>\n<pre><code class=\"lang-command\">PROFILE=1 guild run ...\n<\/code><\/pre>\n<p>You\u2019ll get a couple of Python profile stats written.<\/p>\n<p>A nice way to view these files is with <a href=\"https:\/\/jiffyclub.github.io\/snakeviz\/\">SnakeViz<\/a>. Guild prints the instructions for running <code>snakeviz<\/code> when you run with the profile flag.<\/p>\n<p>If you need help interpreting anything just attach both stat files and I\u2019ll take a look.<\/p>\n<p>The shorter you can make your code the better. Otherwise the startup cost\/time will be overshadowed by the actual run time.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T22:33:34.706Z",
                "Answer_body":"<p>That\u2019s pretty sweet!<\/p>\n<p>I\u2019ve profiled the run that takes a long time. You can find the results <a href=\"https:\/\/drive.google.com\/file\/d\/1-OBwznTVA_KtbJGZo8yUgi8RLIEUPaMo\/view?usp=sharing\" rel=\"noopener nofollow ugc\">here<\/a>.<\/p>\n<p>As you can see it takes a looong time. This happened after I did a big refactoring of my <code>guild<\/code> file into multiple <code>guild<\/code> files using inheritance.<\/p>\n<p>Is the above happening because it is looking for source code in the root dir?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T22:55:26.025Z",
                "Answer_body":"<p>It looks like you have a directory with a lot of files - over 1M. Guild is example those files to see if they\u2019re candidates for source code copy. By default Guild only looks at I think around 100 files unless you\u2019ve configured the <code>sourcecode<\/code> attr for the operation.<\/p>\n<p>You can see what\u2019s going on by running:<\/p>\n<pre><code class=\"lang-command\">guild run &lt;op&gt; --test-sourcecode\n<\/code><\/pre>\n<p>This should take all that time but you\u2019ll see where the files are.<\/p>\n<p>You can remove a directory from consideration (Guild won\u2019t scan it) this way:<\/p>\n<pre><code class=\"lang-yaml\">op:\n  sourcecode:\n    - exclude:\n        dir: &lt;dir containing lots of files&gt;\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T23:30:50.935Z",
                "Answer_body":"<p>So I have the <code>sourcecode<\/code> attribute specified, but I guess not it in the right way.<\/p>\n<p>My current folder structure looks like this:<\/p>\n<pre><code>training\/\nscripts\/\nguild\/\n   flags\/\n           classification.yml\n           common.yml\n           segmentation.yml\n    base_model.yml\n    classification_model.yml\n    segmentation_model.yml\n    utils.yml      \nguild.yml\n<\/code><\/pre>\n<p>My main <code>guild.yml<\/code> looks like this:<\/p>\n<pre><code>- include: guild\/segmentation_model.yml\n- include: guild\/classification_model.yml\n<\/code><\/pre>\n<p>These two <code>guild<\/code> files in turn looks like this:<\/p>\n<pre><code>guild\/segmentation_model.yml\n-----------------------------\n- include:\n    - base_model.yml\n    - utils.yml\n    - flags\/segmentation.yml\n    - flags\/common.yml\n\n- model: segmentation_model\n  sourcecode:\n    - scripts\n    - training\n    - guild.yml\n  extends:\n    - base_model\n    - utils\n  operations:\n    convert_to_onnx:\n      flags:\n        $include: onnx_flags_segmentation\n    train:\n      flags:\n        batch_size: 1\n        $include:\n          - segmentation_flags\n          - train_flags\n          - common_flags\n    test:\n      flags:\n        $include:\n          - common_flags\n          - test_flags\n<\/code><\/pre>\n<pre><code>guild\/classification_model.yml\n-------------------------------\n- include:\n    - base_model.yml\n    - utils.yml\n    - flags\/classification.yml\n    - flags\/common.yml\n\n- model: classification_model\n  sourcecode:\n    - scripts\n    - training\n    - guild.yml\n  extends:\n    - base_model\n    - utils\n  operations:\n    train:\n      flags:\n        batch_size: 0\n        $include:\n          - classification_flags\n          - train_flags\n          - common_flags\n    convert_to_onnx:\n      flags:\n        $include: onnx_flags_classification\n<\/code><\/pre>\n<p>The <code>base_model.yml<\/code> looks like this:<\/p>\n<pre><code>base_model.yml\n--------------------------------\n- config: base_model\n  sourcecode:\n    select:\n      - scripts\n      - training\n      - guild.yml\n  operations:\n    train:\n      main: scripts\/training\/train_model --input_database ...\n      requires: prepared_data\n    test:\n      main: scripts\/training\/test_model --input_database ...\n      requires:\n        - operation: train\n        - prepared_data\n  resources:\n    prepared_data:\n      sources: ...\n<\/code><\/pre>\n<p>The command<\/p>\n<pre><code>guild run classification_model:train\n<\/code><\/pre>\n<p>Is what takes a long time. The interesting thing is that the <code>sourcecode<\/code> directory in the run directory only contains the sourcecode that I have specified.<\/p>\n<pre><code>$ ls ~\/...\/.guild\/runs\/5d239a67d97d4bd4952e2b1cc2b10083\/.guild\/sourcecode\/\nguild.yml  scripts  training\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T23:34:01.459Z",
                "Answer_body":"<p>It\u2019s the scanning\/testing of a large number of files that\u2019s taking time.<\/p>\n<p>What does this command reveal?<\/p>\n<pre><code class=\"lang-command\">guild run classification_model:train --test-sourcecode\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T23:35:24.171Z",
                "Answer_body":"<p>It scans through the entire directory:<\/p>\n<pre><code>training\/\ndata\/\n3rd_party_lib\/\nscripts\/\nguild\/\nguild.yml\n<\/code><\/pre>\n<p>So also <code>data<\/code> and <code>3rd_part_lib<\/code> which are the heavy folders.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-15T23:37:28.584Z",
                "Answer_body":"<p>Refer the example I provided above. You need to explicitly exclude any directories containing large numbers of files - unless you want those scanned for consideration as source code files. This is what\u2019s taking time. The code snippet above will address that.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-16T00:39:39.430Z",
                "Answer_body":"<p>I see - thank you! It works now <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Rearranging columns in guild compare",
        "Question_link":"https:\/\/my.guild.ai\/t\/rearranging-columns-in-guild-compare\/496",
        "Question_created_time":1607455711413,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":240,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi there!<\/p>\n<p>First off, thanks a lot for making Guild!<\/p>\n<p>I was wondering if there is a way to rearrange the columns in <code>guild compare<\/code>? It seems like by default the scalars come after the flags whereas I\u2019d like for it to be the other way round.<\/p>\n<p>Second, I\u2019m noticing that if I use <code>guild compare -cc<\/code> followed by a comma-separated list of column names which include both flags and scalars, only the scalars get outputted correctly; the values for the flag columns are empty.<\/p>\n<p>FWIW I\u2019m on Guild version 0.7.1:<\/p>\n<pre><code>% pip freeze | grep guildai                                                                                                                               20-12-08 - 14:26:45\nguildai==0.7.1\n<\/code><\/pre>\n<p>EDIT: here is a quick example to reproduce things.<\/p>\n<p>Here\u2019s my toy <code>guild.yml<\/code> file:<\/p>\n<pre><code>- operations:\n    quick_example:\n      description: \"Quick example\"\n      exec: \"echo \\\"Loss: 0.123\\\"\"\n      flags:\n        log_file:\n          type: string\n          default: \"example.log\"\n      output-scalars:\n        - loss: 'Loss: (\\value)'\n<\/code><\/pre>\n<p>If I run <code>guild run quick_example<\/code> and then <code>guild_compare<\/code>, I see<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8.png\" data-download-href=\"\/uploads\/short-url\/vezbGnqgINBlCyo0RrLJKtjFQLK.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8_2_517x42.png\" alt=\"image\" data-base62-sha1=\"vezbGnqgINBlCyo0RrLJKtjFQLK\" width=\"517\" height=\"42\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8_2_517x42.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8_2_775x63.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8_2_1034x84.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/dae8f403971fd56cf3ac5e4b506538faffed2da8_2_10x10.png\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1350\u00d7110 5.76 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg><\/div><\/a><\/div><\/p>\n<p>However, if I run <code>guild compare -cc log_file,loss<\/code> I get<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/30bf182e19fbc50a4b89c31a42ed85cc964b4039.png\" alt=\"image\" data-base62-sha1=\"6XekRJDBHwfTbaXShdnSESkYNMR\" width=\"377\" height=\"99\"><\/p>\n<p>Thanks a lot in advance!<br>\njks<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-12-08T21:02:37.145Z",
                "Answer_body":"<p>To show flags in a column listing you need to prefix the name with <code>=<\/code>. E.g. <code>guild compare -cc loss,=log_file<\/code>.<\/p>\n<p>In your Guild file, specify the columns you want in order using the operation <code>compare<\/code> attribute like this:<\/p>\n<pre><code class=\"lang-yaml\"># guild.yml\n\nquick_example:\n  ...\n  compare:\n    - last loss step as step\n    - loss\n    - =log_file\n<\/code><\/pre>\n<p>Unfortunately there\u2019s no way to generalize the order to place flags after scalars. This configuration is all per operation.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-08T21:33:25.270Z",
                "Answer_body":"<p>Thank you <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>! This seems to be what I needed \u2013 per-operation configuation should be just fine.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remove accidentally recorded flags from runs",
        "Question_link":"https:\/\/my.guild.ai\/t\/remove-accidentally-recorded-flags-from-runs\/470",
        "Question_created_time":1606745426615,
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":316,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi the loss of every epoch has been recorded in my experiments. I dont want to delete the runs, but can these unwanted flags be removed from the overview shown in guild compare?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-30T15:01:06.987Z",
                "Answer_body":"<p>You can define <code>compare<\/code> in the Guild file associated with the runs and list the columns that you want to appear for the runs. For example, assume your operation is named <code>train<\/code> and logged both <code>loss<\/code> and <code>accuracy<\/code> scalars. Since you don\u2019t want <code>loss<\/code> to appear in compare, just list <code>accuracy<\/code> like this:<\/p>\n<pre><code class=\"lang-yaml\">train:\n  compare: [accuracy]\n<\/code><\/pre>\n<p>This scheme breaks if the Guild file is moved as the runs maintain a reference to the Guild file location. So if you move the runs to another system Guild won\u2019t know that you\u2019ve defined a custom set of compare cols.<\/p>\n<p>Btw, I\u2019m assuming that <code>loss<\/code> is a <em>scalar<\/em> and not a <em>flag<\/em>. Flags are the user inputs to a run and scalars are numeric outputs. It\u2019s a perfectly normal point of confusion. I mention this because you specify a flag for a compare list using a <code>=<\/code> prefix. E.g. <code>compare: [=learning-rate, =dropout, loss, accuracy]<\/code>.<\/p>\n<h4>Side note about archving runs<\/h4>\n<p>If you\u2019re not otherwise interested in these runs lately, you might consider <em>archiving<\/em> them using the <a href=\"\/commands\/export\"><code>export<\/code><\/a> command. E.g. I prefer to keep a relatively recent list of runs active and use archival folders within my project.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T19:33:10.098Z",
                "Answer_body":"<p>Hi Garret, thanks! but I also want to view the runs in tensorboard. Is there any method to delete the scalars (or ignore them in tensorboard and guild view)?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T19:38:21.984Z",
                "Answer_body":"<p>Ignore my comments about archiving - that applies when you aren\u2019t actively working with the runs but want fast access to them.<\/p>\n<p>By defining <code>compare<\/code> attribute for the operation you can specify the columns that appear in both Compare and View. Just omit the scalars you don\u2019t want to view. See the example in my previous comment.<\/p>\n<p>There\u2019s no easy way to remove already-logged scalars from a run. These come from append only logs.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-02T18:45:40.845Z",
                "Answer_body":"<p>Hi Garret,<br>\nI have moved the runs from a cloud server to my laptop and would like to view them without some scalars. Is there a command that I can use to only compare\/view some of the flags and scalars?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-02T18:47:05.027Z",
                "Answer_body":"<p>It is not really feasible for me to change every guild.yml in every run retrospectively<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-02T19:01:42.316Z",
                "Answer_body":"<p>You just need to change it for the project - not for each run.<\/p>\n<p>How many projects would be effected by this?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-02T19:13:19.061Z",
                "Answer_body":"<p>It\u2019s only one project and around 50 runs. I dont have another guild file for the project so far. I have an anaconda env where I installed guildai and added the runs to guild home.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-02T20:32:41.069Z",
                "Answer_body":"<p>If the runs aren\u2019t associated with a Guild file (i.e. they were run directly with scripts) you can use a short Python script to do this. You want to write the <code>compare<\/code> run attribute with the list of columns you want for compare and view.<\/p>\n<p>Here\u2019s a script you can run for this.<\/p>\n<pre><code class=\"lang-python\"># Save to set_compare.py\nimport argparse\n\nfrom guild import ipy as guild\n\np = argparse.ArgumentParser()\np.add_argument(\"op\", help=\"Name of operation.\")\np.add_argument(\"cols\", help=\"Comma delimited list of columns for compare.\")\np.add_argument(\"--preview\", action=\"store_true\", help=\"Preview but don't change anything.\")\nargs = p.parse_args()\n\nop = args.op\ncols = [col.strip() for col in args.cols.split(\",\")]\n\nif args.preview:\n    print(\"PREVIEW - CHANGES WILL NOT BE MADE\")\nfor _, row in guild.runs(operations=(op,)).iterrows():\n    print(\"Setting run %s compare cols to %s\" % (row.run, cols))\n    if not args.preview:\n        row.run.run.write_attr(\"compare\", cols)\n<\/code><\/pre>\n<p>From the command line, run:<\/p>\n<pre><code class=\"lang-command\">python set_compare.py train.py a,b,c --preview\n<\/code><\/pre>\n<p>Where <code>train.py<\/code> is the name of the operation and <code>a,b,c<\/code> is the list of cols you want to show for the runs. Once the operation looks right to you, remove the <code>--preview<\/code> switch to apply the changes.<\/p>\n<p>To test the columns you can use <code>guild compare -cc &lt;cols&gt;<\/code>. Remember that flags need to be prefixed with <code>=<\/code>. Scalars do not.<\/p>\n<p>This is admittedly painful and at this point you\u2019re probably wishing you never asked <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>However, it\u2019s much harder to delete the actual logged values. You\u2019d need to recreate the TF event files for the runs. As these are append only files, you can\u2019t simply delete from them.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-03T16:52:39.740Z",
                "Answer_body":"<p>Great! This works great. I created the file in my guild home directory and ran it with teh guild compare command in a bash script! Thanks for helping with this!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Status flag is \"terminated\" when experiment is still \"running\"",
        "Question_link":"https:\/\/my.guild.ai\/t\/status-flag-is-terminated-when-experiment-is-still-running\/461",
        "Question_created_time":1606300246699,
        "Question_answer_count":10,
        "Question_score_count":3,
        "Question_view_count":358,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I currently run experiments. But their status flag says \u201cterminated\u201d instead of \u201crunning\u201d. This is quite annoying since now I can\u2019t delete all terminated runs without also deleting active runs.<\/p>\n<p>Excerpt of output when running <code>guild runs info<\/code>:<\/p>\n<pre><code>status: terminated\nstarted: 2020-11-25 05:59:38\nstopped:\n<\/code><\/pre>\n<p>Is it bug or did I cause this somehow?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-25T18:04:38.886Z",
                "Answer_body":"<p>When an operation is stopped using an interrupt \u2014 e.g. by pressing <code>Ctrl-c<\/code> or via <code>SIGINT<\/code> or <code>SIGKILL<\/code> (e.g. used by <code>guild stop<\/code>) the status is <code>terminated<\/code>. You can see the exit code in <code>guild runs info<\/code>.<\/p>\n<p>A terminated run is typically not a problem \u2014 there are many reasons you\u2019d want to stop a run.<\/p>\n<p>You can delete terminated runs by filtering with <code>-T<\/code> (FYI this option is changing to <code>-Ft<\/code> in 0.7.1). Run this:<\/p>\n<pre><code class=\"lang-command\">guild runs rm -T\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-25T18:07:03.041Z",
                "Answer_body":"<p>I should add that if the operation is in fact still running and shows as terminated, this is a bug.<\/p>\n<p>You can test if the run process is alive by running <code>kill -0 &lt;pid&gt;<\/code> where <code>&lt;pid&gt;<\/code> is the pid that shows up in <code>guild runs info<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-25T21:55:25.873Z",
                "Answer_body":"<p>Hi Garrett,  my run seems to be terminated my ssh session times out. The run will take a day, so I cant stay on the server for this  amount of time<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T05:36:51.204Z",
                "Answer_body":"<p>Any chances you are running your jobs on a remote servers or a cluster? In that case, its normal and its not supported now because guild grab the PID for the job status and if won\u2019t be able to get it if you run on a cluster. You can see <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/239\" rel=\"noopener nofollow ugc\">this<\/a> issue for more.<\/p>\n<p>You might also consider maintaining a session by using <code>tmux<\/code>, you can install it through <code>apt-get install tmux<\/code>. Use <code>tmux<\/code> to open a persistent session, use <code>tmux ls<\/code> to list existing sessions and to reconnect a session, use <code>tmux attach -t [session]<\/code><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:08:04.505Z",
                "Answer_body":"<p>I run my jobs on a remote cluster. Do you already have a plan on how to fix the status flag for remote jobs? I use guildai quite frequently and happy to submit a PR if you give me some hints on how to best attack this issue.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:23:21.095Z",
                "Answer_body":"<p>IMO one elegant way to solve this is to write the status to a file (since cluster most likely have shared file system) and then read it when calling <code>guild compare<\/code> or <code>guild view<\/code>, the file should also check if guild is terminated properly. But I am not sure if this aligns with the Devs design pattern.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-27T20:57:05.823Z",
                "Answer_body":"<p>I just ran a test using a long running operation that looks like this:<\/p>\n<pre><code class=\"lang-python\">import time\n\ntime.sleep(1000000)\n<\/code><\/pre>\n<p>I start the run this way:<\/p>\n<pre><code class=\"lang-command\">guild run test -r my-remote\n<\/code><\/pre>\n<p>I can safely <code>Ctrl-c<\/code> the session, which disconnects from the remote operation. I can also explicitly kill the underlying <code>ssh<\/code> command. Either way, the run continues on the remote server. Guild only relies on the <code>ssh<\/code> connection to start the run \u2014 not to actually maintain running. Guild is technically \u201cwatching\u201d the run after it starts to avoid the problem you\u2019re mentioning. The watching is just a log tail. You can kill it and not affect the run itself.<\/p>\n<p>Note that when I run this on a remote, the run does not appear in any local runs list until I explicitly pull the run.<\/p>\n<p>When I view the runs on the remote, I see it running \u2014 even after I kill the ssh connection.<\/p>\n<pre><code class=\"lang-command\">guild runs -r my-remote\n<\/code><\/pre>\n<pre><code class=\"lang-output\">[1:62af7e9e]  gpkg.anonymous-cbedc848\/test  2020-11-27 12:27:41  running  \n<\/code><\/pre>\n<p>When I pull the run, I get the current run at the point of the pull. When I list runs locally, I see that it\u2019s running along with the remote name.<\/p>\n<pre><code class=\"lang-command\">guild pull my-remote 62af7e9e\n<\/code><\/pre>\n<pre><code class=\"lang-command\">guild runs\n<\/code><\/pre>\n<pre><code class=\"lang-output\">[1:62af7e9e]  gpkg.anonymous-cbedc848\/test  2020-11-27 12:27:41  running (my-remote)  \n<\/code><\/pre>\n<p>In this case, Guild reflects the status at the time of the pull. Guild does not automatically sync the status in the background (Guild doesn\u2019t use long-running agents unless you explicitly start them). To get the latest from the remote, run <code>pull<\/code> again.<\/p>\n<p>Guild has <a href=\"\/commands\/sync\"><code>sync<\/code><\/a> command that\u2019s convenient for sync\u2019ing local runs with their remote counterparts. Unfortunately that command is fubar\u2019d in the 0.7.0 release. That\u2019s fixed for 0.7.1 though. You just run <code>guild sync<\/code> and any local runs that are still running are sync\u2019d with the current remote status.<\/p>\n<p>From my end, aside from the broken <code>sync<\/code> command (which you don\u2019t need anyway), this is working as expected. To help track down the issue, could you identify the stage where it breaks down for you?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T14:06:51.604Z",
                "Answer_body":"<p>thank you this works well!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-03T13:16:59.198Z",
                "Answer_body":"<p>You are right that works. For me and I guess a few others as well, the problem is that I submit jobs to a remote cluster to which I can\u2019t ssh into. So I can\u2019t pull new updates about the run.<br>\nBut it\u2019s not that big of a problem just a bit inconvenient.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-12-03T15:23:30.254Z",
                "Answer_body":"<p>How do you access files from that server? Do you use a networked file system, locally mounted?<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Loading custom event-file summaires",
        "Question_link":"https:\/\/my.guild.ai\/t\/loading-custom-event-file-summaires\/489",
        "Question_created_time":1606949313280,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":233,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using tensorboardX to store event files to disk into a folder that\u2019s different for every run.<br>\nHow do I configure guild where to find these event files?<\/p>\n<p>Thanks!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-12-03T15:22:13.879Z",
                "Answer_body":"<p>If you save the summary files to a relative path, Guild will find them automatically. If you save them outside the run directory, there\u2019s no way for Guild to find them. At that point they are not part of the run, by definition.<\/p>\n<p>The logging APIs often save to a timestamp directory by default because they assume you\u2019re running from your project directory. But Guild runs each operation from a new, unique directory. So the recommended practice for a Guild run is to write to a consistent relative path - e.g. either directly in the run directory or in a consistently named subdirectory.<\/p>\n<p>Note that the relative path shows up in TensorBoard so you can use this to write namespaced events. E.g. to keep \u201ctrain\u201d and \u201ceval\u201d events clearly separated.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild.ipy incorrect home?",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-ipy-incorrect-home\/484",
        "Question_created_time":1606912176799,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":198,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>How does <code>guild.ipy<\/code> home get defined?<\/p>\n<p>When I run<\/p>\n<pre><code>import guild.ipy as guild\n\nguild.runs()\n<\/code><\/pre>\n<p>I get different results from the following (which feels like it should be default behavior)<\/p>\n<pre><code>import sys\nguild_home = '{}\/.guild'.format(sys.exec_prefix)\nguild.set_guild_home(guild_home)\n\nguild.runs()\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-12-02T12:58:06.267Z",
                "Answer_body":"<p>By default Guild home is <code>~\/.guild<\/code> when not running in a virtual env. When running in a virtual env it\u2019s <code>&lt;env home&gt;\/.guild<\/code>.<\/p>\n<p>You can change this from the CLI by setting <code>GUILD_HOME<\/code> env or by using the <code>-H<\/code> option right after the <code>guild<\/code> command:<\/p>\n<pre><code class=\"lang-command\">guild -H &lt;alt home&gt; ...\n<\/code><\/pre>\n<p>When using <code>guild.ipy<\/code> you get the default location unless you use <code>set_guild_home(path)<\/code>.<\/p>\n<p>You can see what the path is with <code>guild.config.guild_home()<\/code>:<\/p>\n<pre><code class=\"lang-python\">&gt;&gt;&gt; from guild import config\n&gt;&gt;&gt; config.guild_home()\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild check error",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-check-error\/466",
        "Question_created_time":1606470797572,
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":286,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>,<\/p>\n<p>I am using guild after some time\u2026<\/p>\n<p>I have installed the guild using <code>pip install guild<\/code> and execute <code>guild check<\/code>. I got the following error:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\alphar&gt; guild check\nguild_version:             0.7.1.dev3\nguild_install_location:    c:\\programdata\\anaconda3\\lib\\site-packages\\guild\nguild_home:                C:\\ProgramData\\Anaconda3\\.guild\nguild_resource_cache:      C:\\ProgramData\\Anaconda3\\.guild\\cache\\resources\nTraceback (most recent call last):\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    guild.main.main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    _main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 40, in _main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\click_util.py\", line 201, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check.py\", line 104, in check\n    check_impl.main(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 87, in main\n    _check(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 92, in _check\n    _check_impl(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 107, in _check_impl\n    _print_info(check)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 156, in _print_info\n    _print_guild_info()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 179, in _print_guild_info\n    cli.out(\"installed_plugins:         %s\" % _format_plugins())\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\check_impl.py\", line 191, in _format_plugins\n    return \", \".join([name for name, _ in sorted(plugin.iter_plugins())])\nTypeError: '&lt;' not supported between instances of 'CPUPlugin' and 'CPUPlugin'\n<\/code><\/pre>\n<p>I get the same error with <code>pip install --pre --user guildai<\/code>.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-27T15:55:57.670Z",
                "Answer_body":"<p>I believe this has been fixed but the release may not be GA. What version of guild are you running?<\/p>\n<pre><code class=\"lang-command\">guild --version\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-28T10:10:28.842Z",
                "Answer_body":"<p>The output is:<\/p>\n<pre><code>guild 0.7.1.dev3\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T13:42:20.599Z",
                "Answer_body":"<p>Hah right it was in your original output!<\/p>\n<p>Okay I thought that had been fixed but it hadn\u2019t landed in any release. The latest pre-release should work for you. Please upgrade guild by running <code>pip install guildai --pre --upgrade<\/code>. You should get 0.7.1.rc1 now on Windows.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T14:30:53.458Z",
                "Answer_body":"<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"4\" data-topic=\"466\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<p>pip install guildai --pre --upgrade<\/p>\n<\/blockquote>\n<\/aside>\n<p>Now, I get this output:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\alphar&gt; guild check\nguild_version:             0.7.1.rc1\nguild_install_location:    c:\\programdata\\anaconda3\\lib\\site-packages\\guild\nguild_home:                C:\\ProgramData\\Anaconda3\\.guild\nguild_resource_cache:      C:\\ProgramData\\Anaconda3\\.guild\\cache\\resources\ninstalled_plugins:         ERROR: '&lt;' not supported between instances of 'CPUPlugin' and 'CPUPlugin'\npython_version:            3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\npython_exe:                c:\\programdata\\anaconda3\\python.exe\nplatform:                  Windows 10 AMD64\npsutil_version:            5.6.3\ntensorboard_version:       2.2.2\ncuda_version:              10.1.243\nnvidia_smi_version:        451.48\nlatest_guild_version:      0.7.0.post1\nguild: there are problems with your setup\nRefer to the issues above for more information or rerun check with the --verbose option.\n<\/code><\/pre>\n<p>I am not sure if the error message is even important, everything works as expected.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T15:07:07.812Z",
                "Answer_body":"<p>Haha - no, that\u2019s definitely not what we want there. It\u2019s better than crashing but there\u2019s still work to be done. I\u2019ll do some more research. Thanks for the report.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T15:51:57.549Z",
                "Answer_body":"<p>It looks like you\u2019re running from master? Would you be able to try out recent commits to test this plugins list behavior? There\u2019s something going on in your env that I\u2019m unable to reproduce.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Run R script returns: guild: error running r: [WinError 193] %1 is not a valid Win32 application",
        "Question_link":"https:\/\/my.guild.ai\/t\/run-r-script-returns-guild-error-running-r-winerror-193-1-is-not-a-valid-win32-application\/467",
        "Question_created_time":1606477388142,
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":597,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I tried to run R script. I have guild.yml file inside my root directory (R project). Ia m not sure if guild can work for plain R scripts inside R project?<\/p>\n<p>Here is my guild.yml:<\/p>\n<pre><code>r:\n  description: Backtesting with BackCUSUM estimation of volatility structural breaks\n  # exec: Rscript .guild\/sourcecode\/train.r ${flag_args}\n  exec: C:\/Users\/Mislav\/Documents\/GitHub\/alphar\/R\/volatilityR.R ${flag_args}\n  flags:\n    contract: 'SPY5'\n    upsample: FALSE\n    std_window: 30\n    backcusum_rolling_window: 100\n    backcusum_type: 'bq'\n  output-scalars:\n    cumulatice_return: 'cumulative_return: (\\value)'\n    sharpe_ratio: 'sharpe_ratio: (\\value)'\n<\/code><\/pre>\n<p>When I execute the script with <code>guild run r<\/code> I get the error:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\alphar&gt; guild run r\nYou are about to run r\n  backcusum_rolling_window: 100\n  backcusum_type: bq\n  contract: SPY5\n  std_window: 30\n  upsample: no\nContinue? (Y\/n) y\nguild: error running r: [WinError 193] %1 is not a valid Win32 application\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-27T17:56:15.797Z",
                "Answer_body":"<p>The commented out <code>exec<\/code> I think is a better starting point. You want to run <code>Rscript<\/code> as your executable. The <code>exec<\/code> attr is different from <code>main<\/code> in that it is the actual command that Guild runs. The <code>main<\/code> attr is a Python specific implementation that knows about Python scripts. <code>exec<\/code> doesn\u2019t know anything about R scripts.<\/p>\n<p>You can see what Guild runs for any operation using the <code>--print-cmd<\/code> option:<\/p>\n<pre><code class=\"lang-command\">guild run r --print-cmd\n<\/code><\/pre>\n<p>If you try to run that command directly in Windows, you should see the same error message.<\/p>\n<p>Assuming that <code>guild.yml<\/code> is in <code>&lt;home&gt;\/GitHub\/alphar\/R<\/code> I think this is what you want:<\/p>\n<pre><code class=\"lang-yaml\">r:\n  exec: Rscript .guild\/sourcecode\/volatilityR.R\n<\/code><\/pre>\n<p>Note the important relative path for the R script. You don\u2019t want to use absolute paths for two reasons:<\/p>\n<ul>\n<li>\n<p>You lose the isolation benefits of strictly running the code copied to the run dir. You don\u2019t want to load\/run any code from your project. By restricting your runs to the run directory, you are assured that the run source code is what actually ran. If you run code from your project directory, you enter a race condition where changes to your project code can accidentally leak  into the operation.<\/p>\n<\/li>\n<li>\n<p>It makes your projects non-portable.<\/p>\n<\/li>\n<\/ul>\n<p>The relative path to <code>.guild\/sourcecode\/...<\/code> points to the default location where Guild copies project soure code. If you want to change that location, you can use the <code>dest<\/code> attribute of the operation <code>sourcecode<\/code> config.<\/p>\n<pre><code class=\"lang-yaml\">r:\n  sourcecode:\n    dest: .\n  exec: Rscript volatilityR.R\n<\/code><\/pre>\n<p>Personally I would recommend against this as I like to see only the input and outputs for a run in the run directory root. I present this example though to show the relationship between the source code arguments used in <code>exec<\/code> and the location of source code files relative to the run directory.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-28T10:39:39.622Z",
                "Answer_body":"<p>Maybe I need to go one step back and explain my intentions.<\/p>\n<p>I would like to set up R project and use guild functionality. If I get it right, guild should be language agnostic. So I thought I can use R scripts in a similar way as I used python scripts. I know I won\u2019t be able to use some functionalities in guid that are specific to python and I am OK with that.<\/p>\n<p>Now, R projects usually have the following structure (figure 4.1): <a href=\"https:\/\/r-pkgs.org\/package-structure-state.html\" rel=\"noopener nofollow ugc\">https:\/\/r-pkgs.org\/package-structure-state.html<\/a><\/p>\n<p>The file I want to run is in <code>&lt;home&gt;\/GitHub\/alphar\/R<\/code> and the project root is <code>&lt;home&gt;\/GitHub\/alphar<\/code>.<\/p>\n<p>I thought I can use guild by just making guild.yml in project root. and run files with <code>guild run<\/code>. I am not sure if this is true.<\/p>\n<p>The alternative would be to developed a python project and use R functions inside it. My plan is to use both R and python functions inside my project and thought guild would be a great tool to use both.<\/p>\n<p>I know it is recommended to set up guild project when I use python, but what if I use R project?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-28T17:51:51.149Z",
                "Answer_body":"<p>All of this is possible. I\u2019ll reiterate a few key points from my previous post:<\/p>\n<ul>\n<li>\n<p>Use <code>exec<\/code> to execute any OS process. In the case of R, you want to run <code>Rscript<\/code> with the path to the applicable script.<\/p>\n<\/li>\n<li>\n<p>Use the run source code rather than hard-code any paths to your project files.<\/p>\n<\/li>\n<\/ul>\n<p>You can put the Guild file in the project root. This will make it easier to spot and run. It will look something like this for an operation:<\/p>\n<pre><code class=\"lang-yaml\"># guild.yml located in &lt;home&gt;\/GitHub\/alphar\n\nop:\n  exec: Rscript .guild\/sourcecode\/R\/op.R\n<\/code><\/pre>\n<p>Where <code>op.R<\/code> is the R script you want to run, assuming it\u2019s located in the <code>R<\/code> subdirectory.<\/p>\n<p>When you try this, what are you seeing?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-29T10:22:01.504Z",
                "Answer_body":"<p>If I use your approach it returns:<\/p>\n<pre><code>You are about to run r\n  backcusum_rolling_window: 100\n  backcusum_type: bq\n  contract: SPY5\n  std_window: 30\n  upsample: no\nContinue? (Y\/n)\nguild: error running r: [WinError 2] The system cannot find the file specified\n<\/code><\/pre>\n<p>Additionally, the <code>guild run r --print-cmd<\/code> returns:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\alphar&gt; guild run r --print-cmd\nRscript .guild\/sourcecode\/R\/volatilityR.R --backcusum_rolling_window 100 --backcusum_type bq --contract SPY5 --std_window 30 --upsample ''\n<\/code><\/pre>\n<p>I have to say I don\u2019t have .guild folder in my root. IS hat automatically added by guild run?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-29T18:54:39.058Z",
                "Answer_body":"<p><code>Rscript<\/code> is the program that runs R scripts. You should verify that you can run this at all:<\/p>\n<pre><code class=\"lang-command\">Rscript --version\n<\/code><\/pre>\n<p>If that runs without error, the issue is path related. If it doesn\u2019t run, you need to make sure it\u2019s installed and <a href=\"https:\/\/www.google.com\/search?q=setting+path+windows+10\">available on the path<\/a>.<\/p>\n<p>The <code>.guild<\/code> directory is in the <em>run directory<\/em> \u2014 not your project directory. Guild operations run within a newly created directory. You can see that directory when you run <code>guild runs info<\/code>. If you want to see all of the files associated with a run, use <code>guild ls -a<\/code> (<code>-a<\/code> is used there to list all files).<\/p>\n<p>I suggest running the <code>r<\/code> operation in the Guild <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\">examples<\/a>. That\u2019s as simple as it gets. You\u2019ll need to install the <code>argparser<\/code> library from R to run that.<\/p>\n<p>Start R:<\/p>\n<pre><code class=\"lang-command\">R\n<\/code><\/pre>\n<p>From the R shell:<\/p>\n<pre><code>&gt; install.packages(\"argparser\")\n<\/code><\/pre>\n<p>Then run the Guild example:<\/p>\n<pre><code class=\"lang-command\">cd &lt;guild src repo&gt;\/examples\/languages\n<\/code><\/pre>\n<pre><code class=\"lang-command\">guild run r -y\n<\/code><\/pre>\n<p>The op should run without errors.<\/p>\n<p>Once you have that working, you can iterate with your project. If you run into any other issues, please include the specific error messages with details, etc. here as you\u2019ve been doing.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T14:32:48.251Z",
                "Answer_body":"<p>R bin folder was not in the path <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/see_no_evil.png?v=9\" title=\":see_no_evil:\" class=\"emoji\" alt=\":see_no_evil:\"><\/p>\n<p>It works now. Thanks.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-30T15:08:35.574Z",
                "Answer_body":"<p>Great! I\u2019ll be curious to hear how your experience goes with R. I\u2019m not aware of a lot of Guild users running R but I\u2019d like to make this a smoother experience for those who do.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Tensorboard logging twice + is slow",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-logging-twice-is-slow\/423",
        "Question_created_time":1603173353724,
        "Question_answer_count":10,
        "Question_score_count":1,
        "Question_view_count":1345,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I  have an operation, let\u2019s call it <code>a<\/code> that is kinda the \u201cbase operation\u201d that I could run a number ways with different flags.  Then I have another operation <code>b<\/code> that has one step  that runs operation <code>a<\/code> with the proper flags.<\/p>\n<p>What\u2019s strange to me is that I seem to get multiple of everything I logged with tensorboard. Additionally, <code>guild view<\/code>  is pretty  slow to open  my runs,  and viewing in tensorboard from  there is much slower (takes 10+s) . I saw someone had an issue with symlinks but I don\u2019t think that\u2019s the issue here since I don\u2019t have any set up. I feel like these issues are probably linked, considering I wasn\u2019t having this problem before. If I run just 1 configuration I ended up with:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985.png\" data-download-href=\"\/uploads\/short-url\/ppPT2noEZFMHbXQsJsQEYjoFJoF.png?dl=1\" title=\"Screen Shot 2020-10-19 at 10.35.07 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985_2_690x162.png\" alt=\"Screen Shot 2020-10-19 at 10.35.07 PM\" data-base62-sha1=\"ppPT2noEZFMHbXQsJsQEYjoFJoF\" width=\"690\" height=\"162\" srcset=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985_2_690x162.png, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985.png 1.5x, https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/optimized\/1X\/b222065eb8fc000afea6c9a9eeae0cf0addca985_2_10x10.png\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2020-10-19 at 10.35.07 PM<\/span><span class=\"informations\">779\u00d7184 45.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg><\/div><\/a><\/div><\/p>\n<p>Not sure how to go about fixing this, I probably  did something wrong.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-20T14:41:13.834Z",
                "Answer_body":"<p>The duplication in results in TensorBoard is by design. Steps (pipeline) ops inherit the scalar results of their child runs. To avoid this, use a filter to limit the runs that you\u2019re viewing in TensorBoard. E.g. to view just the <code>ap<\/code> results (which include <code>imputer<\/code>) run:<\/p>\n<pre><code class=\"lang-command\">guild tensorboard --operation ap\n<\/code><\/pre>\n<p>Re slow performance in View, you\u2019re right this is not likely an issue with symlinks (you\u2019d have seen poor performance with <code>guild tensorboard<\/code> as well in that case \u2013 though this has been fixed).<\/p>\n<p>Guild View is missing some optimizations, which cause it to slow down when viewing more and more runs. When running View in this case, you can work around this by limiting the runs you show. Use filters, e.g.<\/p>\n<p>But to address the issue with TensorBoard performance, I recommend just running <code>guild tensorboard<\/code> and not launching via View.<\/p>\n<p>View is due for a series of enhancements including performance optimization \u2014 but until then these are the workaround I recommend.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-25T12:06:12.707Z",
                "Answer_body":"<p>I face the same issue but I am unsure how to resolve it. I have an operation called <code>start<\/code> which I run when I start an experiment. For every run, there are two entries in Tensorboard. How can I filter out one of them?<\/p>\n<p><code>guild tensorboard --operation start<\/code> doesn\u2019t work.<\/p>\n<p>Do you mind sharing some details where the second entry in Tensorboard is coming from?<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/50463d322584fcb8434aaade01eeb94055edcab7.png\" alt=\"Screenshot 2020-11-25 at 13.03.53\" data-base62-sha1=\"bs8GpFUxJikxKUZNXl2BrQpyPjh\" width=\"300\" height=\"253\"><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T10:51:09.635Z",
                "Answer_body":"<p>Is it possible that your code is also writing to the tensorboard in a directory under the working directory or a directory you requested in the resources?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:05:37.691Z",
                "Answer_body":"<p>This is the way I log results right now:<\/p>\n<pre><code>torch.utils.tensorboard import SummaryWriter\nself.writer = SummaryWriter()\nself.writer.add_scalar('Loss\/train', loss_train\/(batch_idx+1), global_step\n<\/code><\/pre>\n<p>Does this create the duplicate entry in tensorboard?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:32:39.473Z",
                "Answer_body":"<p>From <a>here<\/a> it says that by default it writes to <code>.\/runs\/<\/code> so I guess this is most likely whats happening.<\/p>\n<p>What I recommend is to create a static directory on your machine and write all runs to that directory (of course you need to clean it yourself from time to time otherwise it could bleed your hardisc dry in no time).<\/p>\n<p>And then you change your line to<\/p>\n<pre><code class=\"lang-python\">self.writer = SummaryWriter('\/some\/static\/path\/')\n<\/code><\/pre>\n<p>Or better still, use env variable to specify where to write it so you track your experiment better:<\/p>\n<pre><code class=\"lang-bash\">TENSORBOARD_LOGDIR=\/some\/dir\/;guild run XXX\n<\/code><\/pre>\n<pre><code class=\"lang-python\">import os\nTENSORBOARD_LOGDIR=os.environ('TENSORBOARD_LOGDIR')\nself.writer = SummaryWriter(TENSORBOARD_LOGDIR)\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:48:33.686Z",
                "Answer_body":"<p>Ok it since this static logging directory is not inside the run folder it won\u2019t be shown on tensorboard, right?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T11:53:34.166Z",
                "Answer_body":"<p>Correct, as long as it not under guild\u2019s home directory (usually <code>~\/.guild<\/code>).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T13:48:00.980Z",
                "Answer_body":"<p>Ok the only purpose of logging to the static dir is to trigger guildai?<br>\nThese seems a bit hacky.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-26T14:19:15.148Z",
                "Answer_body":"<p>Actually the purpose is to NOT trigger guild\u2019s tensorboard so you don\u2019t show duplicate items in it.<\/p>\n<p>Generally, you want something to be logged by guild, and you write those into the <code>flags<\/code> and <code>scalars<\/code> in your .yml file so that they will show up on the tensorboard and there\u2019s something that\u2019s more complicated and guild doesn\u2019t support yet like network parameters histograms so that you write them into another tensorboard logdir that you manage yourself.<\/p>\n<p>If you want to write your own data output to the same tensorboard <code>event<\/code> that guild manage, you can do so by specifying the logdir to be the <code>.guild<\/code> folder in a run sub-directory. You can do that by:<\/p>\n<pre><code class=\"lang-python\">self.writer = SummaryWriter('.\/.guild\/')\n<\/code><\/pre>\n<p>You can also understand more about guild run file hierarchy by browsing the run sub-directory, try <code>guild ls<\/code> and explore the it. Note that under the run sub-directory, there\u2019s a hidden directory <code>.guild<\/code> that hold the source code, the tensorboard event and the environmental variables\u2026etc.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-27T16:30:10.184Z",
                "Answer_body":"<p>Just to add a bit to the excellent info <a class=\"mention\" href=\"\/u\/teracamo\">@teracamo<\/a> provides\u2026<\/p>\n<p>TensorBoard doesn\u2019t really know about \u201cruns\u201d in the Scalars plugin. It enumerates unique <em>directories<\/em> that contain TF event files under it\u2019s log directory. It calls them runs in the UI, but it has not idea what a run is. In fact, it\u2019s quite common to log events under separate subdirectories for a run to help organize the layout in TB. E.g. you\u2019ll see \u201ctrain\u201d and \u201cvalidate\u201d or \u201ceval\u201d subdirs used to separate scalars.<\/p>\n<p>The reason you\u2019re seeing two separate \u201cruns\u201d there is that there are TF event files landing in separate subdirectories. That\u2019s confusing. It\u2019d be better if TB used a term other than \u201cruns\u201d. Alas, that\u2019s the way they present the info.<\/p>\n<p>The somewhat odd appearance of <code>&lt;run dir&gt;\/.guild<\/code> in this list is because Guild writes its TF event logs in a subdirectory <code>.guild<\/code>. This is to avoid possible collisions with any files that your script runs. As <a class=\"mention\" href=\"\/u\/teracamo\">@teracamo<\/a> says, it\u2019s sometimes helpful to poke around this directory to see what Guild saves with your run. You don\u2019t need to worry too much about it, but it\u2019s there in plain view if you ever need to understand something in more detail.<\/p>\n<p>Okay, to the problem at hand! As I see it there are three options to address the point of confusion:<\/p>\n<ol>\n<li>\n<p>Don\u2019t worry about it. It\u2019s okay to have multiple subdirs in TB associated with a run. Look at the two runs and in your head say, \u201cone run, one run\u201d until the problem resolves itself <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=9\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"><\/p>\n<\/li>\n<li>\n<p>If you\u2019re already logging scalars, you don\u2019t really need Guild\u2019s <a href=\"https:\/\/my.guild.ai\/t\/scalars\/160#output-scalars\">output scalar<\/a> support. You can disable it for a single operation this way:<\/p>\n<\/li>\n<\/ol>\n<pre><code class=\"lang-yaml\">op:\n  output-scalars: no\n<\/code><\/pre>\n<p>Alternatively, use the <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#operation-defaults\"><code>operation-defaults<\/code><\/a> model attr in <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#full-format\">\u201cfull format\u201d<\/a> Guild file.<\/p>\n<pre><code class=\"lang-yaml\">- operation-defaults:\n    output-scalars: no\n  operations:\n    op: ...\n\n<\/code><\/pre>\n<p>This eliminates the <code>.guild<\/code> entry in the runs list in TB. That\u2019s simple enough but you\u2019ll be responsible for logging scalars. Since you\u2019re doing that already, I think this is a pretty good option.<\/p>\n<ol start=\"3\">\n<li>Write your summaries to <code>&lt;run dir&gt;\/.guild<\/code>. This will consolidate the summaries you write with the summaries that Guild writes. I personally don\u2019t like this option and would discourage it. I think your TF event files should land wherever you want them \u2014 root of the run dir or a subdirectory. That\u2019s a pretty standard convention in TensorFlow land and writing to <code>.guild<\/code> is a bit unconventional.<\/li>\n<\/ol>\n<p>I was hoping for an <code>output-scalars<\/code> attribute that let you write to a different directory but 0.7.0 doesn\u2019t support this. I think that\u2019d be a good option 4. Something like this:<\/p>\n<pre><code class=\"lang-yaml\">- op:\n  output-scalars:\n    summary-path: .  # This is hypothetical - Guild 0.7.0 does not support this\n<\/code><\/pre>\n<p>Long winded responses but hopefully it gives you some useful background.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Exporting guild runs from remote sever",
        "Question_link":"https:\/\/my.guild.ai\/t\/exporting-guild-runs-from-remote-sever\/457",
        "Question_created_time":1606228056115,
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":462,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi Garret and co,<br>\nI have used guild on my last project and liked it! This time, I am running my scripts on different remote servers. I would like to import the runs to my desktop to view them all together. I am not sure how to do this. I would prefer a solution that doesnt involve the remote configuration, because I dont know much about it and my system requires often to enter passwords.<br>\nThanks for the help!<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-24T15:44:50.709Z",
                "Answer_body":"<p>Hi Shannon! I\u2019m glad you\u2019re enjoying Guild.<\/p>\n<p>To view runs that are on one machine from another machine, you have a few options:<\/p>\n<ul>\n<li>\n<p>Connect to the remote server over a terminal (generally <code>ssh<\/code>) and use Guild\u2019s terminal based commands to view runs. This can get you surprisingly far as you can get to all run info including generated files over a terminal. The notable exception is that the <a href=\"\/commands\/open\"><code>open<\/code><\/a> command is limited to terminal based commands. E.g. you can\u2019t run <code>open<\/code> on a remote server over ssh to view a using a windowing app running on your desktop.<\/p>\n<\/li>\n<li>\n<p>Run <a href=\"\/commands\/view\"><code>guild view<\/code><\/a> on the remote server on a port that is available to you (ports below 1024 will require root privilege) and that you can access from your desktop. This often requires opening ports in firewalls. This is the sort of problem you have running any web based app on a remote server \u2014 e.g. TensorBoard, etc.<\/p>\n<\/li>\n<li>\n<p>Use an HTTP server running on your remote server to make a directory available for browsing. A simple way to do this is to run <code>python -m http.server &lt;port&gt;<\/code> from a directory on the remote server. Guild runs will be under <code>$GUILD_HOME\/runs<\/code>. Each run is saved in a unique directory that corresponds to the run ID. Then, from your local system, navigate to the remote host + port and you should see the directory listing, which you can browse to view\/download files, etc. Note that this approach is all low level file access. In a pinch this is a good way to look at files remotely.<\/p>\n<\/li>\n<li>\n<p>Use a shared network file system like NFS or <a href=\"https:\/\/en.wikipedia.org\/wiki\/Samba_(software)\">Samba<\/a>.<\/p>\n<\/li>\n<li>\n<p>Copy the runs from the remote server to your local system.<\/p>\n<\/li>\n<\/ul>\n<p>In the case of copy, you can use Guild\u2019s <a href=\"\/commands\/pull\"><code>pull<\/code><\/a> command, but this requires a remote config, which you\u2019ve said you\u2019d prefer to avoid. I think this is the most robust approach of the alternatives.<\/p>\n<ul>\n<li>\n<p>You get a local copy of the runs, so you have full access to the programs installed on your system.<\/p>\n<\/li>\n<li>\n<p>You\u2019re not relying on network based file systems, which are notoriously fickle \u2014 IO errors and poor performance.<\/p>\n<\/li>\n<li>\n<p>Other than user auth (ssh) there\u2019s nothing to configure \u2014 e.g. no servers to run, etc.<\/p>\n<\/li>\n<\/ul>\n<p>If you\u2019re concerned about the need to enter a password all the time, you can setup <a href=\"https:\/\/www.google.com\/search?q=password+less+authentication+ssh\">passwordless auth for ssh<\/a>. This can be a bit technical, but once you have it configured, it\u2019s quite streamlined. The only maintenance overhead you have when using new remote servers is to include your public ssh key in your remote user\u2019s <code>~\/.ssh\/authorized_keys<\/code> file.<\/p>\n<p>If you prefer to copy runs yourself, you can use any standard file copy protocol such as <code>scp<\/code>, <code>rsync<\/code>, or <code>ftp<\/code>. FTP can be configured to avoid password auth but honestly there\u2019s more work there than setting up ssh private key access (see link above a list of resources).<\/p>\n<p>To manually copy runs, copy <code>$GUILD_HOME\/runs<\/code> from the remote to local. Depending on the configuration, you can initiate the copy from your local system or from the remote (pushing runs from remote to your local system).<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-24T16:57:19.703Z",
                "Answer_body":"<p>I should note \u2014 as you asked specifically about <em>exporting<\/em> \u2014 that the <a href=\"\/commands\/export\"><code>export<\/code><\/a> command applies to local runs, not remote. Use <code>export<\/code> to select specific runs from your environment and copy or move them to a directory. This is useful for archiving or backup.<\/p>\n<p>To get runs from a different system, the <a href=\"\/commands\/pull\"><code>pull<\/code><\/a> command is what you\u2019d use, assuming you go through Guild rather than copy runs yourself.<\/p>\n<p>You could use <code>export<\/code> on the remote server to copy\/move runs to a directory, which you can then copy yourself to some location. E.g. you could then use <a href=\"https:\/\/s3tools.org\/s3cmd\"><code>s3cmd<\/code><\/a> to copy the exported runs to S3, where you could access them from your local machine. That said, I\u2019d recommend using Guild <a href=\"\/commands\/push\"><code>push<\/code><\/a> with an S3 remote for this.<\/p>\n<p>Using S3 this way you can implement a \u201cruns sink\u201d where you push all runs from any server. With runs consolidated in a single location, you can pull whatever you need from any other server. This is a nice pattern as you get both a backup of all runs as well as a scheme for sharing across any number of users and systems.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-25T21:58:28.883Z",
                "Answer_body":"<p>Great I think the manual option is fine for me !<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Storing the guild artifacts on s3 using `guild run -r s3-dev`",
        "Question_link":"https:\/\/my.guild.ai\/t\/storing-the-guild-artifacts-on-s3-using-guild-run-r-s3-dev\/449",
        "Question_created_time":1605200901861,
        "Question_answer_count":5,
        "Question_score_count":4,
        "Question_view_count":528,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I wanted to store all my runs in s3 bucket directly instead of the local guildai home directory. So,  I configured my <code>~\/.guild\/config.yml<\/code> in the following way which I thought will setup my s3 remote location and I can automatically save the sourcecode and artifacts that I save locally into s3 bucket.<\/p>\n<pre><code>remotes:\n  s3-dev:\n    type: s3\n    description: Production runs\n    bucket: cortex-model-data\n    region: eu-central-1\n<\/code><\/pre>\n<p>and I have my <code>guild.yml<\/code>as follows<\/p>\n<pre><code>- model: AlwaysPredictMean\n  description: A dummy model which always predicts mean\n  operations:\n    train:\n      description: Training Pipeline Sample Code\n      main: training\/train\n      flags-import: all\n      output-scalars: '(\\key): (\\value)'\n<\/code><\/pre>\n<p>when I run the script using <code>guild run --remote s3-dev<\/code> , I get the following error message<\/p>\n<pre><code>\u00b1 |feature\/guildai U:1 \u2717| \u2192 guild run -r s3-dev\nYou are about to run AlwaysPredictMean:train on s3-dev\n  comment: Description for a given training run\n  config: training\/config\/example.yml\n  data: tests\/test_df.csv\n  epochs: 10\n  model_class: training.example_model::AlwaysPredictMean\n  use_case: example_use_case\nContinue? (Y\/n) y\nguild: remote 's3-dev' does not support this operation\n<\/code><\/pre>\n<p>Can someone let me know what exactly is the problem and why can\u2019t I use guild.ai to store in the specified s3. Thanks<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-12T17:57:29.291Z",
                "Answer_body":"<p>S3 remotes are only for file storage. You can\u2019t run anything in S3. If you want to run on a remote server, which is what you\u2019re asking for with the <code>--remote<\/code> option, you need either an <a href=\"\/reference\/remotes#ssh\"><code>ssh<\/code><\/a> or <a href=\"https:\/\/my.guild.ai\/reference\/remotes#ec2\"><code>ec2<\/code><\/a> remote type.<\/p>\n<p>If you want to run your operation locally, omit the <code>--remote<\/code> option \u2014 you\u2019ll get runs in your current Guild environment. Then use <a href=\"\/commands\/push\"><code>guild push s3-dev<\/code><\/a> to copy those runs to S3.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-13T08:52:27.693Z",
                "Answer_body":"<p>Thanks a lot. Now it is more clear. I misunderstood that if I run a script with a remote s3 config, my runs (including sourcecode and artifacts) are automatically saved to s3. I will do it manually by using <code>guild push s3-dev<\/code><\/p>\n<p>Thanks also for building this nice tool.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-13T15:50:12.734Z",
                "Answer_body":"<p>I could see the value of automatically sync\u2019ing with a remote env during and especially after a run. Guild does not currently support this. I could see an enhancement to Guild along the line of <code>--push-to-remote<\/code> or <code>--push-on-success<\/code> that does this. That\u2019s a good idea. Though that poor run command already has quite a few options - it\u2019s going to evolve into it\u2019s own language grammar <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=9\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"> Still, I like the thinking!<\/p>\n<p>In defense of Guild\u2019s \u201cseparation of concerns\u201d Tao, you can accomplish what you\u2019re looking for this way:<\/p>\n<pre><code class=\"lang-command\">guild run &lt;options&gt; &amp;&amp; guild push s3-dev\n<\/code><\/pre>\n<p>This works on shells that support <code>&amp;&amp;<\/code>, which will execute the second command only when the first command succeeds (exit code of 0).<\/p>\n<p>If you wanted to push regardless of the result, use:<\/p>\n<pre><code class=\"lang-command\">guild run &lt;options&gt;; guild push s3-dev\n<\/code><\/pre>\n<p>Note this will push all runs, not just the latest. As Guild uses rsync (or similar) protocols, this is efficient. But you may want to just push the latest. In that case add the <code>1<\/code> argument to the push command. This tells Guild to only push the latest run (i.e. the run with index <code>1<\/code>).<\/p>\n<p>Wait, there\u2019s more!<\/p>\n<p>If you would like to always sync runs to your S3 bucket, you could create a repeating command <code>guild push<\/code> that runs, say, every 10 minutes, 30 minutes, etc. Most POSIX systems offer cron for this, but there are myriad ways to run scheduled commands. Now this is moving you into \u201csys op\u201d territory, which you might not want enter - beware there be dragons <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=9\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"> But such is life. If this logic was moved into the <code>run<\/code> command you\u2019d need to worry about command failure (e.g. SIGKILLs) or system failure (e.g. batter\/power loss, etc.) Using something like cron is a nice separation of concerns because cron can back-fill on various failures to complete your backups even when Guild or the system unexpected crashes. E.g. your system loses power during a long training run where you have various interim checkpoints. You restart, cron runs automatically to backup your partial runs. You can then restart the run using <code>guild run --restart &lt;run ID&gt;<\/code> and be on your merry way, letting cron run every so often to refresh the backup. I don\u2019t think this scheme is terribly complicated yet it\u2019s quite robust.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-16T06:18:10.999Z",
                "Answer_body":"<p>Thanks garrett, I understand the concern. Coming from mlflow where you can set_tracking_uri to s3 remote, I thought guild also has this option. Having the artifacts stored in a remote s3 bucket makes it easier to collaborate in a small team and track the progress. But after looking at the number of options available for <code>guild run<\/code> and <code>guild push<\/code>, it makes sense to have these two functions separate.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-16T13:26:30.056Z",
                "Answer_body":"<p>I think it\u2019s a great idea and one more option to <code>run<\/code> isn\u2019t a problem. I opened an issue on GitHub to track progress this.<\/p>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/252\" target=\"_blank\" rel=\"noopener\">github.com\/guildai\/guildai<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/252\" target=\"_blank\" rel=\"noopener\">Ability to sync with remote during run without explicit push command<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-11-16\" data-time=\"13:25:18\" data-timezone=\"UTC\">01:25PM - 16 Nov 20 UTC<\/span>\n      <\/div>\n\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/gar1t\" target=\"_blank\" rel=\"noopener\">\n          <img alt=\"gar1t\" src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/84ac3354a76fe15593cedb56fe486a0ed93d5440.jpeg\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          gar1t\n        <\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n<\/div>\n\n<div class=\"github-row\">\n  <p class=\"github-content\">It's convenient to be able to sync run artifacts with a remote (e.g. S3 bucket, etc.) as a function of the...<\/p>\n<\/div>\n\n<div class=\"labels\">\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">enhancement<\/span>\n<\/div>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"`guild export` and underlying shututil dead-slow for samba drives",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-export-and-underlying-shututil-dead-slow-for-samba-drives\/442",
        "Question_created_time":1604534963382,
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":410,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>This is a very specific issue, but I wanted to raise it either way.<\/p>\n<p>I am using <code>guild export<\/code> to export runs to a Samba share mounted in Linux. This is incredibly slow. I see <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/9ddeb46a11e8c37a8ecb452b3b32f5c245297f2c\/guild\/commands\/runs_impl.py#L1193\" rel=\"noopener nofollow ugc\">here<\/a> that <code>guild<\/code> uses <code>shututil<\/code>. This is a known issue for <code>shututil<\/code> and they suggest a monkey patch in this issue <a href=\"https:\/\/github.com\/SickChill\/SickChill\/issues\/3292#issuecomment-289728670\" rel=\"noopener nofollow ugc\">here<\/a>.<\/p>\n<p>I think I am going to experiment with ways to patch <code>guild<\/code>. Since we are using Azure, I want to see if I can utilize <code>azcopy<\/code>, which is orders of magnitude faster.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-11-05T16:19:55.555Z",
                "Answer_body":"<p>Thank you for this! If you have some success with this, I encourage you to submit a PR or a gist. I can help integrate and confirm with you that the fix\/patch works in the next release.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-13T16:31:58.131Z",
                "Answer_body":"<p>I decided to abandon the Samba drive. It simply to slow and too much of pain to get to work properly in Azure.<\/p>\n<p>If we used Amazon, we could utilize the <code>guild push<\/code> command to an <code>s3<\/code> bucket. Instead I am now opting for storing guild runs in dvc, which has support for Azure.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-13T16:35:15.598Z",
                "Answer_body":"<p>I wonder if Guild could support DVC as a remote type. E.g.<\/p>\n<pre><code class=\"lang-yaml\"># ~\/.guild\/config.yml\n\nremotes:\n  dvc:\n    type: dvc\n    # Config here as needed.\n<\/code><\/pre>\n<pre><code class=\"lang-command\">guild push dvc  # syncs runs with DVC\n<\/code><\/pre>\n<p>Do you think this would be useful, or are you thinking just place the <code>$GUILD_HOME\/runs<\/code> under DVC control independently?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-11-13T16:37:33.190Z",
                "Answer_body":"<p>I am doing the latter now, i.e. placing guild runs under DVC control. That works OK for now, but more integrated support for dvc by guild would be amazing.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I test my Guild file?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-do-i-test-my-guild-file\/434",
        "Question_created_time":1603822545054,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":425,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I know guild has support for some testing and checks of the guild file setup. I just can\u2019t find the documentation for it.<\/p>\n<p>Ideally I would like to have some unit tests running that tests that the <code>guild.yml<\/code> is correctly setup and that some of the <code>operations<\/code> and <code>models<\/code> works as expected.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-28T14:27:04.723Z",
                "Answer_body":"<p>You\u2019re right - the docs are missing for this. I created a hot-to article.<\/p>\n<aside class=\"quote quote-modified\" data-post=\"1\" data-topic=\"437\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\">\n    <a href=\"https:\/\/my.guild.ai\/t\/test-your-guild-file\/437\">Test your Guild file<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/howto\/11\"><span class=\"badge-category-bg\" style=\"background-color: #F69B73;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Step-by-step guides, examples, and tips for getting the most from Guild AI.\">How To<\/span><\/a>\n  <\/div>\n  <blockquote>\n    You can test your Guild file by creating an operation that uses steps to run the operations you\u2019d like to test. Steps support various <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#step-check\">checks<\/a> that Guild performs to validate run output. \nWhen testing your operations, it\u2019s a good idea to use flag values to keep run time to a minimum. In some cases you may want to modify your scripts to support flags that indicate \u201ctest mode\u201d or \u201crun quickly\u201d mode. \nWhen creating test operations, you can an underscore prefix with the operation name to indicate the \u2026\n  <\/blockquote>\n<\/aside>\n",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Source custom shell script when running in remote virtual environment",
        "Question_link":"https:\/\/my.guild.ai\/t\/source-custom-shell-script-when-running-in-remote-virtual-environment\/368",
        "Question_created_time":1602179862963,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":467,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I am using a <code>ssh<\/code> remote with the following setup:<\/p>\n<pre><code>remotes:\n  azure-deeplearning:\n    type: ssh\n    host: deeplearning.guild.ai\n    venv-path: mypath\/.training_venv\n    user: myuser\n    use-prerelease: yes\n<\/code><\/pre>\n<p>The <code>venv<\/code> gets correctly activated. The issue is that I need to source a setup file after the <code>venv<\/code> gets activated. If I were to do it manually on the remote I would do:<\/p>\n<pre><code>source mypath\/.training-venv\/bin\/activate\nsource my_custom_bash.sh\n<\/code><\/pre>\n<p>How would this fit into the guild remote workflow?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-13T17:53:56.717Z",
                "Answer_body":"<p>My apologies for the late reply! I had typed a reply but never send it.<\/p>\n<p>You can use something like this:<\/p>\n<pre><code class=\"lang-yaml\">remotes:\n  azure-deeplearning:\n    venv-activate: source mypath\/.training_venv\/bin\/activate &amp;&amp; source my_custom_bash.sh\n<\/code><\/pre>\n<p>Refer to <a href=\"https:\/\/my.guild.ai\/t\/remotes-reference\/172#ssh-venv-activate\" class=\"inline-onebox\">Remotes Reference<\/a> for info on the <code>venv-activate<\/code> attribute for <code>ssh<\/code> remotes.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-26T17:03:16.705Z",
                "Answer_body":"<p>Thank you for this. This works, but I also want to change the working directory to <code>mypath<\/code>. I have tried using <code>cd<\/code> in the <code>venv-activate<\/code> but that breaks. I also tried using the <code>remoteCommand<\/code> in my ssh config, but that wont\u2019 work either.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-28T12:44:06.685Z",
                "Answer_body":"<p>The current working directory should not be meaningful in the context of a remote environment. Guild will use the remote run directory as cwd.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild compare \/ view \/ tensorboard hangs",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-compare-view-tensorboard-hangs\/427",
        "Question_created_time":1603449092502,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":378,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have about 15 runs which where I perform about 60000 steps and log a loss for each step. When I try to view these using <code>guild runs<\/code> it works fine, but trying to extract the best run using compare or viewing the results using view \/ tensorboard it loads for a long time until I can actually view the information.<\/p>\n<p>What could be the reason for this? Am I logging too much per run?<\/p>\n<p>EDIT: I realised that <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a> has said elsewhere that the view is due for an overhaul, perhaps that will fix this problem.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-26T13:57:22.481Z",
                "Answer_body":"<p>Does this long delay occur again and again, or only after the initial view for a run?<\/p>\n<p>Guild caches the log info it reads from the TF summary files. These files can take quite a while to read. But once they\u2019re read, the data is caches and Guild should be very fast.<\/p>\n<p>Views in TensorBoard will continue to take a long time because TensorBoard always reads the data anew.<\/p>\n<p>Unfortunately this is the nature of the TF summary files.<\/p>\n<p>If any of your TF event files are over 1G, you\u2019ll notice this delay and it can be up to several minutes for files over 100G.<\/p>\n<p>The only way around that I\u2019m aware of is to log with less frequency. But 60000 steps is not that much so there might be another issue here.<\/p>\n<p>To try:<\/p>\n<ul>\n<li>Does Guild Compare take the same long time after running it twice?<\/li>\n<li>Does TensorBoard, when run manually (e.g. run <code>tensorboard --logdir &lt;some_run_dir&gt;<\/code>, take a long time to show scalars?<\/li>\n<\/ul>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-26T16:22:02.516Z",
                "Answer_body":"<p>Thanks for the response <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, will try this!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Custom post-hoc analysis",
        "Question_link":"https:\/\/my.guild.ai\/t\/custom-post-hoc-analysis\/425",
        "Question_created_time":1603226512765,
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":259,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I would like to do some custom post-hoc analysis on various things I\u2019ve logged into tensorboard. I\u2019m doing bootstrapping and want to calculate mean and confidence interval. I know there\u2019s the <code>ipy<\/code> widget, and I\u2019ve gotten semi far with that as it gives you <code>avg_value<\/code> etc. But I\u2019d like to get access to all the values logged for, say, <code>precision<\/code> so that I can calculate the confidence intervals. I know this data is logged in tensorboard and tensorflow has some guides but they do not work with the version of tensorboard that comes  with guild. How do you advise I would do something like this?<\/p>\n<p>I  can log this separately, sure but it ends up being a pain and cluttering up all my logs. I cannot visualize them the way I\u2019d like in tensorboard, so I\u2019d rather do this analysis ad-hoc when comparing runs myself.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-20T22:51:45.375Z",
                "Answer_body":"<p>This is not currently supported, but it\u2019s a very reasonable request so I added it! It\u2019s <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/754384a695859d87157271333b5437ef2ac505ea\/guild\/ipy.py#L641-L657\">in master<\/a> now and will land in the next release.<\/p>\n<p>In the meantime, you can use this code to get the low level scalar detail:<\/p>\n<pre><code class=\"lang-python\">from guild import ipy\nfrom guild import tfevent\n\nrun = ipy.runs().iloc[0].run.value\nfor path, _run_id, scalars in tfevent.scalar_readers(run.dir):\n    for tag, val, step in scalars:\n        print(run.dir, path, tag, val, step)\n<\/code><\/pre>\n<p><span data-guild-class=\"caption\">API that you can use today<\/span><\/p>\n<p>Note that this API is unofficial and could change (though that\u2019s not likely). You\u2019ll want to use <code>guild.ipy<\/code> when that feature is available. That will look like this:<\/p>\n<pre><code class=\"lang-python\">from guild import ipy\n\nscalars = ipy.runs().iloc[0].scalars_detail()\nprint(scalars)\n<\/code><\/pre>\n<p><span data-guild-class=\"caption\">0.7.1 API \u2014 not yet released<\/span><\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Data Filepath Flag",
        "Question_link":"https:\/\/my.guild.ai\/t\/data-filepath-flag\/376",
        "Question_created_time":1602795008595,
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":328,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hello, I\u2019m converting a project to guild and I have a question about setting a filepath as a flag.<\/p>\n<p>At the top of my training script I have a variable data_fp = \u201c\u2026\/\u2026\/data\/dtype2\/processed_data.npy\u201d<br>\nbefore this was a guild project I was just cutting and pasting different filepaths when I want to train the model on new data but now I want to be able to set it as a flag.<\/p>\n<p>When I try to run this with guild I get an error because it doesn\u2019t see that path. Is there a way to do set this up so that the script can see the data from the \/run directory?<\/p>\n<p>Also, currently my folder structure is like this and my guild file is :<\/p>\n<pre><code>proj\/\n  data\/\n    dtype1\/\n      raw_data.npy\n    dtype2\/\n      processed_data.npy\n  scripts\/\n    guild.yml\n    data_processing\/\n      process_data.py\n    model\/\n      train.py\n      ...\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-15T22:26:29.124Z",
                "Answer_body":"<p>The easiest way is to make the <code>data<\/code> directory available to the run using a dependency.<\/p>\n<pre><code class=\"lang-yaml\"># guild.yml\n\ntest:\n  requires:\n    - file: data\n<\/code><\/pre>\n<p>Then define a flag that uses the relative path to the file. E.g.<\/p>\n<pre><code class=\"lang-python\"># test.py\n\ndata = \"data\/bar.txt\"\nprint(open(data).read())\n<\/code><\/pre>\n<p>A working example of this is here:<\/p>\n<aside class=\"onebox allowlistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https:\/\/github.githubassets.com\/favicons\/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https:\/\/github.com\/gar1t\/guild-example-1\" target=\"_blank\" rel=\"noopener\">GitHub<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/9c36309bef676db543d88d3f3144eb5b84ccff6c.jpeg\" class=\"thumbnail onebox-avatar\" width=\"400\" height=\"400\">\n\n<h3><a href=\"https:\/\/github.com\/gar1t\/guild-example-1\" target=\"_blank\" rel=\"noopener\">gar1t\/guild-example-1<\/a><\/h3>\n\n<p>Contribute to gar1t\/guild-example-1 development by creating an account on GitHub.<\/p>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>There are a couple other approaches that occur to me but lets start with this one as it\u2019s the most straight forward. If you run into issues or have questions, just ask here and we can work through them.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-16T00:26:40.321Z",
                "Answer_body":"<p>I just changed the guild file to look like this but it isn\u2019t working yet. This is what the guild file looks like now.<\/p>\n<pre><code>train:\n  description: Train a flow model based on a data file and optionally save the parameters\n  main: scripts\/flow_model\/optim_flow_model\n  flags-dest: globals\n  flags-import: all\n  requires:\n    - file: data\/saved_npy\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-16T00:34:17.972Z",
                "Answer_body":"<p>That will create <code>saved_py<\/code> in the run directory. You can confirm this by running:<\/p>\n<pre><code class=\"lang-command\">guild ls\n<\/code><\/pre>\n<p>That\u2019s a good way to see what Guild creates in the run directory. Your script runs in that location, so if it can\u2019t find something, it\u2019s either because it\u2019s not there or your script expects it in another location.<\/p>\n<p>You have a few options:<\/p>\n<ol>\n<li>Just link to the <code>data<\/code> directory (omit <code>saved_npy<\/code>) \u2014 this will make the entire data tree available. Currently Guild symlinks to the directory so you\u2019re not copying any files there.<\/li>\n<\/ol>\n<pre><code class=\"lang-yaml\">train:\n  requires:\n    - file: data\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Specify a <code>target-path<\/code> of <code>data<\/code> so that the <code>saved_npy<\/code> directory is accessible as <code>data\/saved_npy<\/code>.<\/li>\n<\/ol>\n<pre><code class=\"lang-yaml\">train:\n  requires:\n    - file data\/saved_npy\n      target-path: data\n<\/code><\/pre>\n<ol start=\"3\">\n<li>Modify your script to look in <code>saved_npy<\/code>.<\/li>\n<\/ol>\n<p>If you\u2019re running into another issue, what is the error message you\u2019re getting?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-19T12:54:51.407Z",
                "Answer_body":"<p>I went with option two and it worked, thanks for your help!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Specifying guild home through -H doesn't work",
        "Question_link":"https:\/\/my.guild.ai\/t\/specifying-guild-home-through-h-doesnt-work\/369",
        "Question_created_time":1602276095982,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":418,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I want to compare runs in a different path by using the <code>-H<\/code> option. My new path is called <code>experiments<\/code>:<\/p>\n<pre><code>$ ls experiments\na26ffe4727584d359e16f2a28af5dfab  cache\n<\/code><\/pre>\n<p>Now If I do:<\/p>\n<pre><code>$ guild -H experiments runs\n<\/code><\/pre>\n<p>There is no output. Same with other commands. Am I using the command run?<\/p>\n<p>This is the output of <code>guild check<\/code>:<\/p>\n<pre><code>guild_version:             0.7.0\nguild_install_location:    \/mypath\/.training_venv\/lib\/python3.6\/site-packages\/guild\nguild_home:                \/mypath\/.training_venv\/.guild\nguild_resource_cache:      \/mypath\/.training_venv\/.guild\/cache\/resources\ninstalled_plugins:         cpu, disk, exec_script, gpu, keras, memory, perf, python_script, queue, skopt\npython_version:            3.6.9 (default, Jul 17 2020, 12:50:27) [GCC 8.4.0]\npython_exe:                \/mypath\/.training_venv\/bin\/python3\nplatform:                  Linux 5.4.0-48-generic x86_64\npsutil_version:            5.6.3\ntensorboard_version:       2.2.2\ncuda_version:              10.0.130\nnvidia_smi_version:        440.100\nlatest_guild_version:      0.7.0.post1\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-13T17:34:24.425Z",
                "Answer_body":"<p>You need to store your runs under a <code>runs<\/code> subdirectory. Take a look at <a href=\"https:\/\/my.guild.ai\/t\/environments\/164#guild-home\" class=\"inline-onebox\">Environments<\/a> \u2013 that shows a complete structure for what Guild home should look like.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild run hangs \/ very slow",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-run-hangs-very-slow\/362",
        "Question_created_time":1601685221068,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":402,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have successfully used guild in some older project, but in this new project I am having a hard time debugging what is going on.<\/p>\n<p>I am trying to do:<\/p>\n<pre><code>guild run model:train -y\n<\/code><\/pre>\n<p>But the operation hangs without any output to the console.<\/p>\n<p>If I do<\/p>\n<pre><code>guild run model:train -y --print-cmd\n<\/code><\/pre>\n<p>And execute it directly with python and exact same arguments it gets executed right away.<\/p>\n<p>How do I debug this behavior?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-10-04T15:25:35.126Z",
                "Answer_body":"<p>Could you run <code>guild --debug run model:train<\/code> and past the output here? Note that <code>--debug<\/code> must occur between <code>guild<\/code> and <code>run<\/code> and that you\u2019re omitting <code>-y<\/code>. We want to see where things get stuck.<\/p>\n<p>Please spot-check for any private\/sensitive data such as hostnames, paths, secrets, etc. and remove those before posting.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-08T17:52:05.749Z",
                "Answer_body":"<p>Sorry for the late reply. I wasn\u2019t aware of the <code>--debug<\/code> option. The issue went away after a reboot, so this can be closed. Thank you for the fast reply.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Where to look for error logs",
        "Question_link":"https:\/\/my.guild.ai\/t\/where-to-look-for-error-logs\/357",
        "Question_created_time":1601350696211,
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":971,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>After defining a guild operation, when I try running, I am getting the following error<br>\n<code>ERROR: [guild] trial &lt;RUNHASH&gt; exited with an error (see log for details)<\/code>.<\/p>\n<p>Presumably something went wrong in the run but I have no idea what. And I am not sure where to look for the log. If I open <code>guild view<\/code> and look for the log there, there is nothing there. Which might be expected becasue that\u2019s supposed to be the log of that the program outputs on the terminal. But then, I am still not sure where to look for the actual error log that the error message is talking about.<\/p>\n<p>How I can troubleshoot this?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-30T16:03:33.050Z",
                "Answer_body":"<p>The operation itself may not be logging any error information. Guild doesn\u2019t actually know if there\u2019s error content in the log \u2014 that message points you there but if nothing is logged, there\u2019s nothing to see.<\/p>\n<p>You can see the exit code for the trial by running <code>guild runs info TRIAL_RUN_ID<\/code> and look for <code>exit_status<\/code>. It should be non-zero, which indicates an error.<\/p>\n<p>You can see the output generated by the trial using <code>guild cat --output TRIAL_RUN_ID<\/code>. I\u2019m guessing that output does not contain any information about the error.<\/p>\n<p>Assuming that the script is failing but not showing any details, you can re-run the trial to try and recreate the problem. Use <code>guild run --proto TRIAL_RUN_ID<\/code>. This will generate a new run using the same source code and flags.<\/p>\n<p>Start with those steps and please update here if you\u2019re unable to resolve the issue. We can dig in further once we have more info.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-01T08:51:46.152Z",
                "Answer_body":"<p>Hi,<br>\nI faced the issue which occurs even before the actual execution of the main() function of my training code and this message <code>ERROR: [guild] trial TRIAL_RUN_ID exited with an error (see log for details)<\/code> is shown.<br>\nI tried all of the above and only guild run --proto TRIAL_RUN_ID showed the following error msg:<\/p>\n<pre><code>Resolving config:resources\/config\/config.toml dependency\nguild: run failed because a dependency was not met: could not resolve 'config:resources\/config\/config.toml' in config:resources\/config\/config.toml resource: error loading config from \/media\/data\/resources\/config\/config.toml: unsupported file type for '\/media\/data\/resources\/config\/config.toml'\n<\/code><\/pre>\n<p>Assuming this is something to do with \u2018config\u2019 keyword in the \u2018requires\u2019 field  of guild.yml file, changing it to \u2018file\u2019 keyword worked. Maybe the \u2018config\u2019 keyword has some special usage which I might have missed or aware of.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-04T15:32:51.054Z",
                "Answer_body":"<p>That\u2019s a good point. The output generated by Guild about dependency resolution errors will not appear in run logs but is shown on the console. In this case you need to scan console output for these messages. Again, Guild only knows when a trial fails by its exit code. It doesn\u2019t otherwise know why. That information should appear in the output. If the script doesn\u2019t show an error message, there\u2019s no information to go off of.<\/p>\n<p><code>config<\/code> is quite different from <code>file<\/code>. When you use <code>config<\/code>, you specify a JSON or YAML file that Guild uses to generate a new file containing flag values. Guild does not support <code>toml<\/code> format, so the error message is accurate.<\/p>\n<p>This is covered in more detail here: <a href=\"https:\/\/my.guild.ai\/t\/dependencies\/162#configuration-files\" class=\"inline-onebox\">Dependencies<\/a>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-10-05T11:44:56.724Z",
                "Answer_body":"<p>Okay, thank you for the explanation.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error with gp: TypeError: '<' not supported between instances of 'Version' and 'tuple'",
        "Question_link":"https:\/\/my.guild.ai\/t\/error-with-gp-typeerror-not-supported-between-instances-of-version-and-tuple\/352",
        "Question_created_time":1600932087603,
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":1347,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>,<\/p>\n<p>When I run the execute run as grid serach it works as expected (there are lots of flags):<\/p>\n<pre><code>guild run --max-trials 2 lightgbm:train num_leaves=range[40:150:10] max_depth=range[2:7:1] learning_rate=range[0.01:0.1:0.01] boosting_type=[gbdt] colsample_bytree=[0.75,0.8,0.85,0.9,0.95] subsample=[0.75,0.8,0.85,0.9,0.95] min_child_samples=[0.5,1.0,2.0,3.0,4.0,5.0,10.0] n_estimators=[100,250,500,1000]\n<\/code><\/pre>\n<p>But when I specify the gp optimizer:<\/p>\n<pre><code>guild run --max-trials 2 lightgbm:train num_leaves=range[40:150:10] max_depth=range[2:7:1] learning_rate=range[0.01:0.1:0.01] boosting_type=[gbdt] colsample_bytree=[0.75,0.8,0.85,0.9,0.95] subsample=[0.75,0.8,0.85,0.9,0.95] min_child_samples=[0.5,1.0,2.0,3.0,4.0,5.0,10.0] n_estimators=[100,250,500,1000] --maximize mean_score --optimizer gp\n<\/code><\/pre>\n<p>I get an error:<\/p>\n<pre><code>Continue? (Y\/n)\nTraceback (most recent call last):\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_gp_main.py\", line 83, in &lt;module&gt;\n    main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_gp_main.py\", line 36, in main\n    skopt_util.handle_seq_trials(batch_run, _suggest_x)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_util.py\", line 209, in handle_seq_trials\n    _run_seq_trials(batch_run, suggest_x_cb)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_util.py\", line 225, in _run_seq_trials\n    for trial_flag_vals, is_trial_random_start, prev_trials, x0 in _iter_seq_trials(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_util.py\", line 263, in _iter_seq_trials\n    suggested_x, random_state = _suggest_x(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_util.py\", line 370, in _suggest_x\n    return suggest_x_cb(dims, x0, y0, is_random_start, random_state, suggest_opts)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\skopt_gp_main.py\", line 40, in _suggest_x\n    res = skopt.gp_minimize(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\gp.py\", line 264, in gp_minimize\n    return base_minimize(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\base.py\", line 271, in base_minimize\n    next_x = optimizer.ask()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\", line 332, in ask\n    return self._ask()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\", line 398, in _ask\n    return self.space.rvs(random_state=self.rng)[0]\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\space\\space.py\", line 764, in rvs\n    if sp_version &lt; (0, 16):\nTypeError: '&lt;' not supported between instances of 'Version' and 'tuple'\n<\/code><\/pre>\n<p>Here is the train script: <a href=\"https:\/\/github.com\/MislavSag\/trademl\" rel=\"noopener nofollow ugc\">https:\/\/github.com\/MislavSag\/trademl<\/a><br>\nThe operation I run is the <code>- model: lightgbm<\/code><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-24T15:29:01.927Z",
                "Answer_body":"<p>What version of skopt and numpy are you running there? Also, have you tried this with the 0.7.1.dev3 or are you on 0.7.0.post1?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-24T15:45:05.046Z",
                "Answer_body":"<p>I have 0.7.1.dev2 version. numpy version is 1.16.6. skopt version is 0.7.4<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-24T15:49:59.171Z",
                "Answer_body":"<p>Okay, the issue is with scikit-learn. Which version of that are you using?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-24T15:51:58.193Z",
                "Answer_body":"<p>sklearn version is \u20180.22.2.post1\u2019<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-24T15:59:19.433Z",
                "Answer_body":"<p>I think you might be running a different version of sklearn when you get that error message. The easiest way to ensure you have the right info is to edit this file:<\/p>\n<p><code>c:\\programdata\\anaconda3\\lib\\site-packages\\skopt\\space\\space.py<\/code><\/p>\n<p>At the top of the file, add these lines:<\/p>\n<pre><code>import sklearn\nprint(\"#######\", sklearn.__version__, sklearn.__file__)\n<\/code><\/pre>\n<p>Then run the Guild <code>run<\/code> command above to recreate the error. The output will contain the printed info above.<\/p>\n<p>This will tell you for sure which version is used and from where. My guess is that it\u2019s from a different Python location and you\u2019re running 0.23.x. From what I\u2019m seeing in the source, the error that you\u2019re getting is not possible with 0.22.2.post1.<\/p>\n<p>Edit: It may be possible that 0.22.2.post1 is used \u2014 then we need to find out what\u2019s changing this <code>sp_version<\/code> after it\u2019s initially parsed. But first let\u2019s version the version and location.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-24T18:19:35.242Z",
                "Answer_body":"<p>I conform it works with sklearn 22.2. I installed when I was trying to update guild to last dev3.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Tensorboard version conflict",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-version-conflict\/353",
        "Question_created_time":1600941341725,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":1027,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Guildai tensorboard functionallity don\u0107t work for me for some time. Now I would like to make it work.<\/p>\n<p>If I execute command <code>guild tensorboard --started 'last 1 hour'<\/code>  I get:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; guild tensorboard --started 'last 1 hour'\nPreparing runs for TensorBoard\n2020-09-24 11:32:59.909813: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\nTraceback (most recent call last):\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    guild.main.main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    _main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 40, in _main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\click_util.py\", line 201, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 98, in _run_tensorboard\n    tensorboard.serve_forever(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 607, in serve_forever\n    app = create_app(logdir, reload_interval, tensorboard_options=tensorboard_options)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 508, in create_app\n    plugins = _tensorboard_plugins(disabled_plugins)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 522, in _tensorboard_plugins\n    base_plugins = tensorboard.base_plugins()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\tensorboard.py\", line 232, in base_plugins\n    return list(set(default.get_plugins() + default.get_dynamic_plugins()))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\tensorboard\\default.py\", line 122, in get_dynamic_plugins\n    return [\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\tensorboard\\default.py\", line 123, in &lt;listcomp&gt;\n    entry_point.load()\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 2471, in load\n    self.require(*args, **kwargs)\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 2494, in require\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 790, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.VersionConflict: (requests 2.18.4 (c:\\users\\mislav\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('requests&lt;3,&gt;=2.21.0'))\n<\/code><\/pre>\n<p><code>Conda list requests<\/code> gives:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; conda list requests\n# packages in environment at C:\\ProgramData\\Anaconda3:\n#\n# Name                    Version                   Build  Channel\nrequests                  2.24.0             pyh9f0ad1d_0    conda-forge\nrequests-oauthlib         1.3.0                    pypi_0    pypi\n<\/code><\/pre>\n<p>so it is greater than 2.21 and lower than 3?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-24T15:36:38.218Z",
                "Answer_body":"<p>I haven\u2019t seen this sort of error from <code>pkg_resources<\/code>. I\u2019m surprised it\u2019s checking versions and failing there for what it\u2019s being asked to do (simply load entry points).<\/p>\n<p>Do you see the same error when you run tensorboard directly (without Guild)?<\/p>\n<p>I would certainly try upgrading requests (e.g. <code>pip install --upgrade requests<\/code>). This particular version requirement is not coming from Guild \u2014 my guess is that it\u2019s from tensorboard.<\/p>\n<p>Whatever conda is showing you there is different from what is coming from c:\\users\\mislav\\appdata\\roaming\\python\\python38\\site-packages. I\u2019d run the <code>pip<\/code> from the python38 location to verify that requests is 2.18.4.<\/p>\n<p>The safest way to run pip for a given Python instance is this way:<\/p>\n<pre><code class=\"lang-command\">python -m pip [ARGS]...\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting full run id",
        "Question_link":"https:\/\/my.guild.ai\/t\/getting-full-run-id\/343",
        "Question_created_time":1600093581539,
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":632,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Is there a way to print out the full run id when using guild compare?<\/p>\n<p>I wanted to run through the results and then inspect the folder containing the output of the run in .guild, but the output of guild compare is the shortened run id so I can\u2019t directly find the folder.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-15T14:28:07.892Z",
                "Answer_body":"<p>Use the <code>-c, --cols<\/code> option to include the run <code>id<\/code> attribute this way:<\/p>\n<pre><code class=\"lang-command\">guild compare -c .id\n<\/code><\/pre>\n<p>This appends the full ID to the table. The prefix <code>.<\/code> indicates the name is an a run attribute. If you wanted to indicate a scalar you\u2019d omit the prefix. If you wanted to indicate a flag you\u2019d use <code>=<\/code> as the prefix.<\/p>\n<p>See <a href=\"https:\/\/my.guild.ai\/t\/command-compare\/77#column-specs\">Column Specs<\/a> for more info.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-16T03:46:57.504Z",
                "Answer_body":"<p>I find <code>for i in {1..X};do guild open --marked --cmd \"echo\" ${i};done<\/code> to be more useful than <code>guild compare<\/code> in this case cause it gives you the full directory.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-17T14:09:55.662Z",
                "Answer_body":"<p>Out of curiosity, what do you do with these run directories? Do they feed an automated process or are you using them manually to access run files?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-17T14:39:16.852Z",
                "Answer_body":"<p>I needed to access them manually in this case. I was running a set of experiments and after I started analyzing the results, I realized there were another set of metrics that I wanted to compute. Luckily I had saved the network weights using guild, so I iterated over each run, reloaded the weights, and then computed these additional metrics.<\/p>\n<p>If there is a nicer way to do this I would definitely like to know, but I didn\u2019t think this process was too painful to code up.<\/p>\n<p>If there was also way to save these new metrics to the run folders that would be great, I didn\u2019t look into whether that was possible.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-18T14:34:59.573Z",
                "Answer_body":"<p>You can use the <code>guild.ipy<\/code> module to iterate over runs to get their directory.<\/p>\n<pre><code class=\"lang-python\">from guild import ipy\n\nfor _, row in ipy.runs().iterrows():\n    run = row.run.value\n    print(\"%s: %s\" % (run.id, run.dir))\n<\/code><\/pre>\n<p>The <code>ipy<\/code> module is primarily intended for interactive use but it works just as well for scripting like this. You just need Pandas as it uses data frames for the interface.<\/p>\n<p>If you\u2019d prefer not to install Pandas, there\u2019s another API but it\u2019s not officially released for general use. I\u2019m happy to help you with that though - it\u2019s stable and will be released at some point.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Scalar not saved if pipeline is used",
        "Question_link":"https:\/\/my.guild.ai\/t\/scalar-not-saved-if-pipeline-is-used\/339",
        "Question_created_time":1599736313219,
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":369,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Here is my guild file:<\/p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/guild.yml\" target=\"_blank\" rel=\"nofollow noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/guild.yml\" target=\"_blank\" rel=\"nofollow noopener\">MislavSag\/trademl\/blob\/master\/guild.yml<\/a><\/h4>\n<pre><code class=\"lang-yml\">- config: model-base\n  resources:\n    prepared-data:\n      - operation: prepare-data\n\n- operations:\n    prepare-data:\n      main: trademl.modeling.prepare\n      flags-import: all\n      flags:\n        input_path:\n          description: Path to read data from. \n          arg_name: input_path\n          type: string\n          default: D:\/market_data\/usa\/ohlcv_features\n        output_path:\n          description: Main path where to save output\n          arg_name: output_path\n          type: string\n          default: D:\/algo_trading_files\n<\/code><\/pre>\n\n  This file has been truncated. <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/guild.yml\" target=\"_blank\" rel=\"nofollow noopener\">show original<\/a>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>If I run prepare or random-forest operation it saves the scalars.<\/p>\n<p>But if I run the pipeline <code>pipeline-rf-opt<\/code> that includes prepare and random-forst as step, it doesn\u2019t save scalars. I call it like this:<\/p>\n<pre><code class=\"lang-command\">guild run pipeline-rf-opt \\\n  data-include_ta=1 \\\n  data-label_tuning=0 \\\n  data-label=[day_5] \\\n  data-pca=0 \\\n  data-tb_volatility_lookback=[50] \\\n  data-tb_volatility_scaler=1.0 \\\n  data-correlation_threshold=0.95 \\\n  data-scaling='none' \\\n  random-input_data_path='D:\/algo_trading_files' \\\n  random-forest-depth=4 \\\n  random-forest-maxf=10 \\\n  random-n_estimators=350 \\\n  random-min_weight_fraction_leaf=0.1\n<\/code><\/pre>\n<p>It is just one run.<\/p>\n<p>What could be the reason it doesn\u2019t save scalars?<\/p>\n<p>But it saves flags.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-10T15:33:21.074Z",
                "Answer_body":"<p>You can check to confirm that the step runs for <code>pipeline-rf-opt<\/code> are linked as expected:<\/p>\n<pre><code class=\"lang-command\">guild ls -o pipeline-rf-opt\n<\/code><\/pre>\n<p>You should see directories for <code>prepare-data<\/code> and <code>random-forest:train<\/code>. These are links to the step runs. Guild uses these to traverse to the TF summary (event) files where the scalars are saved. These should be rolled up so they appear when you run:<\/p>\n<pre><code class=\"lang-command\">guild runs info -o pipeline-rf-opt\n<\/code><\/pre>\n<p>I\u2019ve confirmed this is working as expected on a sample pipeline. If you\u2019re seeing something different we can troubleshoot further.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-12T08:02:53.676Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, here is to output of the guild command you posted above:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; guild ls -o pipeline-rf-opt\nC:\\ProgramData\\Anaconda3\\.guild\\runs\\a54248ea3eb449a7a4d34742cb554231:\n  prepare-data\n  random-forest_train\n(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt;\n<\/code><\/pre>\n<p>And for second command:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; guild runs info -o pipeline-rf-opt\nid: a54248ea3eb449a7a4d34742cb554231\noperation: pipeline-rf-opt\nfrom: C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\guild.yml\nstatus: completed\nstarted: 2020-09-10 10:47:54\nstopped: 2020-09-10 10:49:21\nmarked: no\nlabel: data-correlation_threshold=0.95 data-include_ta=1 data-label=day_5 data-label_tuning=0 data-lookforward=240 data-pca=0 data-scaling=none data-tb_volatility_lookback=50 data-tb_volatility_scaler=1.0 random-class_weight=balanced_subsample random-forest-depth=4 random-forest-maxf=10 random-input_data_path=D:\/algo_trading_files random-min_weight_fraction_leaf=0.1 random-n_estimators=350\nsourcecode_digest: ab24b5d70397046e7839099d287466bf\nvcs_commit: git:68b7932fa199927ab461df76757fe9c2f410bfef*\nrun_dir: C:\\ProgramData\\Anaconda3\\.guild\\runs\\a54248ea3eb449a7a4d34742cb554231\ncommand: c:\\programdata\\anaconda3\\python.exe -um guild.steps_main\nexit_status: 0\npid:\nsteps:\n\n  isolate-runs: no\n  needed: yes\n  run: prepare-data include_ta=${data-include_ta} label_tuning=${data-label_tuning} label=${data-label} tb_volatility_lookback=${data-tb_volatility_lookback} tb_volatility_scaler=${data-tb_volatility_scaler} correlation_threshold=${data-correlation_threshold} pca=${data-pca} scaling=${data-scaling}\n\n\n  isolate-runs: yes\n  needed: yes\n  run: random-forest:train input_data_path=${random-input_data_path} max_depth=${random-forest-depth} max_features=${random-forest-maxf} n_estimators=${random-forest-maxf}  n_estimators=${random-n_estimators} min_weight_fraction_leaf=${random-min_weight_fraction_leaf}\n\nflags:\n  data-correlation_threshold: 0.95\n  data-include_ta: 1\n  data-label: day_5\n  data-label_tuning: 0\n  data-lookforward: 240\n  data-pca: 0\n  data-scaling: none\n  data-tb_volatility_lookback: 50\n  data-tb_volatility_scaler: 1.0\n  random-class_weight: balanced_subsample\n  random-forest-depth: 4\n  random-forest-maxf: 10\n  random-input_data_path: D:\/algo_trading_files\n  random-min_weight_fraction_leaf: 0.1\n  random-n_estimators: 350\nscalars:\n(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt;\n<\/code><\/pre>\n<p>So, there are no scalars. I am not sure what can be the reason. Here are the 2 script I use in steps:<br>\n<\/p><aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/prepare.py\" target=\"_blank\" rel=\"nofollow noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/prepare.py\" target=\"_blank\" rel=\"nofollow noopener\">MislavSag\/trademl\/blob\/master\/trademl\/modeling\/prepare.py<\/a><\/h4>\n<pre><code class=\"lang-py\">from pathlib import Path\nimport os\nimport numpy as np\nimport pandas as pd\nfrom numba import njit\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport mlfinlab as ml\nfrom mlfinlab.feature_importance import get_orthogonal_features\nimport trademl as tml\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport mfiles\nmatplotlib.use(\"Agg\")  # don't show graphs because thaty would stop guildai script\n\n\n<\/code><\/pre>\n\n  This file has been truncated. <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/prepare.py\" target=\"_blank\" rel=\"nofollow noopener\">show original<\/a>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<br>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_lstm.py\" target=\"_blank\" rel=\"nofollow noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_lstm.py\" target=\"_blank\" rel=\"nofollow noopener\">MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_lstm.py<\/a><\/h4>\n<pre><code class=\"lang-py\">from pathlib import Path\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nfrom numba import njit\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport json\nimport sys\nimport os\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport kerastuner as kt\nimport mlfinlab as ml\nimport trademl as tml\nfrom tensorboardX import SummaryWriter\nmatplotlib.use(\"Agg\")\n\n<\/code><\/pre>\n\n  This file has been truncated. <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_lstm.py\" target=\"_blank\" rel=\"nofollow noopener\">show original<\/a>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-15T09:40:37.906Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, I have just discovered how the pipeline works. It saves scalars in separate folders (in my case prepare and random_forest_train). I thought it would save everything in the pipeline folder. I am not sure how can I know which parameters I used in the prepare step if I inspect result in random forest operation.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-15T14:39:23.995Z",
                "Answer_body":"<p>I see <code>guild runs info<\/code> is not helpful in this case. It should show step run IDs at least so you can further inspect them.<\/p>\n<p>Your best bet for this I think is to use <code>guild compare<\/code> with a range selector to show the pipeline and its step runs. This assumes the pipeline and steps ran in isolation \u2014 i.e. there aren\u2019t any other runs interleaved.<\/p>\n<p>Something like this:<\/p>\n<pre><code class=\"lang-command\">guild compare 1:4\n<\/code><\/pre>\n<p>Assuming your pipeline has three steps and was the last thing to run, this would show the flag values for each of the steps.<\/p>\n<p>I think Guild <code>compare<\/code> could support a <code>--show-steps<\/code> option that implicitly selects the steps for a pipeline. That way you could run <code>guild compare --show-steps &lt;pipeline run&gt;<\/code>.<\/p>\n<p>It\u2019d also be good to show step info in <code>guild runs info<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-15T14:46:59.931Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/mislav\">@mislav<\/a> would you mind <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\">opening an issue<\/a> for this problem? It\u2019s a general problem that I\u2019d describe as \u201cHard to view pipeline results as a whole\u201d. If that doesn\u2019t capture what you think the issues are, feel free to use whatever title you think is best. With an issue we can track progress on the solution.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-15T17:55:23.027Z",
                "Answer_body":"<p>I have opened the issue here: <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/238\" rel=\"noopener nofollow ugc\">https:\/\/github.com\/guildai\/guildai\/issues\/238<\/a><\/p>\n<p>\u0107Mayvbe you have a quick fix for 3. That\u2019s what I encounter right now<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-16T13:00:12.631Z",
                "Answer_body":"<p>I can\u2019t recreate the behavior where Guild mistakenly states \u201cthe following runs match this operation\u201d for different flag values. The matching runs are listed so it should be straight forward to verify the set of flag values. If Guild is stating that two runs with different flag values are the same, that\u2019s a bug.<\/p>\n<p>I assume you\u2019re using <code>--needed<\/code> for some other reason. If not, just omit and this problem goes away. If you must use <code>--needed<\/code> then I think one approach is to use an additional flag to differentiate runs that are truly different, even though they have the same flag values. For example:<\/p>\n<pre><code class=\"lang-command\">guild run op a=1 b=2 seq=1 --needed\n<\/code><\/pre>\n<p>and:<\/p>\n<pre><code class=\"lang-command\">guild run op a=1 b=2 seq=2 --needed\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to view logs from trials\/batches",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-to-view-logs-from-trials-batches\/334",
        "Question_created_time":1599571635016,
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":272,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I usually use <code>guild cat --output 89549e30 | less +G<\/code> to view the stdout logs, but it seems like there is a separate logging channel for trial-level operations. How would one access these logs?<\/p>\n<p><code>ERROR: [guild] trial efb7377f334b4b5da8411e2437771e91 exited with an error (see log for details)<\/code><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-09-09T12:10:39.761Z",
                "Answer_body":"<p>The output for trial <code>efb7377<\/code> should appear in the output for the batch run. You can verify by running <code>guild cat --output efb7377<\/code> - if you\u2019re not seeing output in the batch run I suspect the output for the trial is empty.<\/p>\n<p>It\u2019s possible that a trial exits with an error without generating output. The message that Guild shows points you to that output but doesn\u2019t know when it\u2019s empty, so it\u2019s misleading in that case.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T17:39:52.199Z",
                "Answer_body":"<p>Thanks for explaining! It does sometimes output <code>(None, -9)<\/code> (or something along those lines), but usually it\u2019s just an empty output. Only happens on the remote machine though, but that might be a different issue\u2026<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Installation problems",
        "Question_link":"https:\/\/my.guild.ai\/t\/installation-problems\/295",
        "Question_created_time":1597999937041,
        "Question_answer_count":16,
        "Question_score_count":1,
        "Question_view_count":519,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I have reopened the issue on GitHub. I am not sure if you see it, so I just wanted to forward the link here\u010c<br>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/133\" target=\"_blank\" rel=\"nofollow noopener\">github.com\/guildai\/guildai<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/133\" target=\"_blank\" rel=\"nofollow noopener\"> pip install guildai on macos x fails<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-03-01\" data-time=\"14:37:48\" data-timezone=\"UTC\">02:37PM - 01 Mar 20 UTC<\/span>\n      <\/div>\n\n        <div class=\"date\">\n          closed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-03-01\" data-time=\"15:15:51\" data-timezone=\"UTC\">03:15PM - 01 Mar 20 UTC<\/span>\n        <\/div>\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/mdiephuis\" target=\"_blank\" rel=\"nofollow noopener\">\n          <img alt=\"mdiephuis\" src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/ebde3a729b99195a01fadd847aa66b1763a50c8b.jpeg\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          mdiephuis\n        <\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n<\/div>\n\n<div class=\"github-row\">\n  <p class=\"github-content\">Runnning\npip install guildai\nERROR: Could not find a version that satisfies the requirement guildai (from versions: none)\nERROR: No matching distribution found for...<\/p>\n<\/div>\n\n<div class=\"labels\">\n<\/div>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<\/p>\n<p>For some reason, I can\u0107t install guildai on windows, after reinstalling anaconda, but I was able to install it before.<\/p>\n<p>Before update, I was able to install it.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-08-22T13:44:55.456Z",
                "Answer_body":"<p>I updated the GitHub issue with a comment. Your conda env is using Python 3.8 and prebuilt wheels aren\u2019t yet available for Guild for that version. When you create your conda env, if you specify Python 3.6 or 3.7 you should be able to install Guild without issue.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-24T08:35:32.543Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a><\/p>\n<p>Thanks for explanation.<\/p>\n<p>Do you know when will Guild.ai approximately be available for python 3.8?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-24T11:51:16.790Z",
                "Answer_body":"<p>I\u2019ll try to get this released this week. I\u2019ll keep you posted!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-24T14:09:19.265Z",
                "Answer_body":"<p>Great. Thanks!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-27T13:58:46.431Z",
                "Answer_body":"<p>You should be able to install now for Python 3.8 on Windows using the pre-release version:<\/p>\n<pre><code class=\"lang-command\">pip install --pre guildai\n<\/code><\/pre>\n<p>This will be generally available when 0.7.1 is released.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-28T09:54:43.004Z",
                "Answer_body":"<p>I have installed it successfully. It has some version conflicts with tensorflow 2.3, but it works.<\/p>\n<p>Thanks.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-28T14:12:09.391Z",
                "Answer_body":"<p>What version conflicts are you seeing?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-31T09:16:08.133Z",
                "Answer_body":"<p>It was because of the tensorboard 2.3, if I remember right.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-31T11:28:51.000Z",
                "Answer_body":"<p>0.7.1.dev2 should work fine with TB 2.3. If you\u2019re seeing issues, please let us know and we\u2019ll get them resolved ASAP. Thanks!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-31T12:01:55.281Z",
                "Answer_body":"<p>It didn\u2019t get eny error with <code>pip install --pre guildai<\/code> know. Thanks.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-07T11:03:44.192Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, is it possible to upgrade requirement to scikit-learn&gt;=0.19.1. Now it is:<br>\nscikit-learn&gt;=0.19.1,&lt;0.23.0<\/p>\n<p>IS there a problem with scikit-learn=0.23.0?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T12:06:24.156Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/mislav\">@mislav<\/a> - this is a temporary restriction for the pre-release. I expect to support the latest from scikit-learn. There are API related issues related to changes to numpy that I hope are resolved before 0.7.1 is released.<\/p>\n<p>You can force an install of a particular version using <code>pip install scikit-learn==VER<\/code>.<\/p>\n<p>I\u2019m running tests on 0.20.4 now to see how that goes.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T12:30:30.929Z",
                "Answer_body":"<p>Still issues with 0.20.4. You can try forcing that version but you may end up with an error on optimization using any of the scikit-learn optimizers. I\u2019m seeing <code>ValueError: array must not contain infs or NaNs<\/code> in our tests.<\/p>\n<p>I don\u2019t offhand know what the root cause is but the goal is to fix this for 0.7.1. If need be we\u2019ll monkey-patch the upstream libraries.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T13:04:37.513Z",
                "Answer_body":"<p>I wanted to install it with scikit-learn 0.23, not 0.20? In the end I downgraded it to 0.22.2.post1.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T13:23:02.543Z",
                "Answer_body":"<p>Sorry - I meant 0.23.2 - this version is problematic.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-09-09T13:45:40.968Z",
                "Answer_body":"<p>I works for now. I will wait for new release. Maybe 0.23 will be supported.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Passing arguments, defined in guild.yml file when using Python's argparse",
        "Question_link":"https:\/\/my.guild.ai\/t\/passing-arguments-defined-in-guild-yml-file-when-using-pythons-argparse\/329",
        "Question_created_time":1598602229021,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":882,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Guild version 0.7.0<\/p>\n<p>I noticed that flags, defined in guild.yml are not passed normally as arguments to config.yml if I use argparse in my Python code. It seems it wants to pass them python arguments even though flags-dest and flags-import are off.<\/p>\n<p>My workflow usually consists of defining main hyperparameters in the config.yml file, but for choosing which gpu to run it on (in my testing phase) I use argparse. Is there a way to combine those two?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-08-28T14:11:29.421Z",
                "Answer_body":"<p>In 0.7 flags are independent of support for configuration files. In a future release we\u2019ll promote config files as a proper flags interface. It will also be possible to configure multiple interfaces to direct some flags to one destination and other flags to another. Alas none of this is available yet.<\/p>\n<p>You can sill get this done though. Use the config dependency type: <a href=\"https:\/\/my.guild.ai\/t\/dependencies\/162#configuration-files\" class=\"inline-onebox\">Dependencies<\/a>.<\/p>\n<p>Here\u2019s an example:<\/p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/dependencies\/guild.yml#L38-L46\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/dependencies\/guild.yml#L38-L46\" target=\"_blank\" rel=\"noopener\">guildai\/guildai\/blob\/master\/examples\/dependencies\/guild.yml#L38-L46<\/a><\/h4>\n<pre class=\"onebox\"><code class=\"lang-yml\"><ol class=\"start lines\" start=\"38\" style=\"counter-reset: li-counter 37 ;\">\n<li>config:<\/li>\n<li>  description: Configuration file dependency<\/li>\n<li>  main: guild.pass<\/li>\n<li>  requires:<\/li>\n<li>    - config: config.yml<\/li>\n<li>  flags:<\/li>\n<li>    lr: null<\/li>\n<li>    batch-size: null<\/li>\n<li>    dropout: null<\/li>\n<\/ol><\/code><\/pre>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>You want to specify <code>args<\/code> for <code>flag-dest<\/code>. By default this will pass all flags as command line options. You can disable that for specific flags using <code>arg-skip: yes<\/code>. You can do this for every arg that you don\u2019t parse with argparse.  To skip all flags by default, set <code>default-flag-arg-skip<\/code> to <code>yes<\/code> for the operation.<\/p>\n<pre><code class=\"lang-yaml\">op:\n  flags-dest: args\n  default-flag-arg-skip: yes\n  flags:\n    # Add your flag defs used for config.yml\n    gpu:\n      arg-skip: no\n  requires:\n    - config: config.yml\n<\/code><\/pre>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I use variadic args?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-do-i-use-variadic-args\/293",
        "Question_created_time":1597749472435,
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":632,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m using a Python argument parser that would like to take multiple directories as input, so I have:<\/p>\n<pre><code>parser = argparse.ArgumentParser()\nparser.add_argument(\n    \"--model_dirs\", action=\"store\", type=str, help=\"Path to trained models.\", nargs=\"+\", required=True\n)\n<\/code><\/pre>\n<p>It appears this is supported because I see some usage of it in an example: <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/2cc91df428d53c403962f300d3173f319dae782d\/examples\/detectron2\/demo.py#L47\" rel=\"nofollow noopener\">https:\/\/github.com\/guildai\/guildai\/blob\/2cc91df428d53c403962f300d3173f319dae782d\/examples\/detectron2\/demo.py#L47<\/a><\/p>\n<p>How do I pass multiple values in the CLI so that Guild will separate them?<\/p>\n<p><code>guild run ... model_dirs=\"foo bar\" -&gt; args.model_dirs = [\"foo bar\"]<\/code><br>\n<code>guild run ... model_dirs=foo bar -&gt; errors<\/code><br>\n<code>guild run ... \"model_dirs=foo bar\" -&gt; args.model_dirs = [\"foo bar\"]<\/code><\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-08-22T12:45:25.496Z",
                "Answer_body":"<p>Hmm - that example is misleading. That file is copied from the upstream sources but isn\u2019t used by Guild in the way you\u2019re expecting there.<\/p>\n<p>Guild doesn\u2019t support multiple flag values as a single assignment. This has come up a few times before \u2014 I believe there\u2019s a GitHub issue for that. I\u2019ll revive that issue and copy you there so you have a reference to it.<\/p>\n<p>This is tricky for Guild (I think) as Guild doesn\u2019t support lists for flag values, which is what you\u2019re talking about here.<\/p>\n<p>In the meantime, the official approach for this is to use a single string value and parse the value as you see fit. An easy way to enable support for a list is to use Python\u2019s <code>shlex<\/code> module to parse a string.<\/p>\n<p>With this example you need to remote <code>nargs='+'<\/code> in your arg config (this breaks you argparse interface though, not so great):<\/p>\n<pre><code>import shlex\n\nmodel_dirs = shlex.split(args.model_dirs)\n<\/code><\/pre>\n<p>To support <code>nargs='+'<\/code> with Guild:<\/p>\n<pre><code>if os.getenv(\"GUILD_OP\") and args.model_dirs:\n    args.model_dirs = shlex.split(args.model_dirs[0])\n<\/code><\/pre>\n<p>I think the later is a better pattern as it preserves your intended interface. The use of Guild is a change, but as Guild formalizes <em>flags<\/em> as an interface (rather than args) I think this is okay. Of course what\u2019s not okay is the modification to code for Guild\u2019s sake, which we want to avoid.<\/p>\n<details>\n<summary>\nImplementation Notes<\/summary>\n<h3>Flag attr <code>is-list<\/code>\n<\/h3>\n<p>I can imagine a flag attr <code>is-list<\/code> (boolean) that enables this behavior automatically. Guild would detect this when importing the flag when <code>nargs<\/code> is a list-enabling value. The question I have is whether this string-parsing via shlex is the right interface.<\/p>\n<p>The list notation (e.g. <code>model_dirs=[a,b,c]<\/code>) is used for generating trials. We can\u2019t use that to get a list value for a single run. I\u2019ve wondered what interface we should provide. Introducing another list specification is tricky. We\u2019re already annoying zsh users with the use of <code>[...]<\/code> as zsh treats square brackets as tokens. Other tokens to avoid: <code>(...)<\/code>, <code>{...}<\/code>, <code>#...#<\/code> \u2014 the list goes on <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>Then there\u2019s the issue of lists of lists for multiple runs. E.g. <code>model_dirs=[[a,b,c],[d,e,f]]<\/code>.<\/p>\n<p>Using the shell parsing logic via <code>shlex.split<\/code> is a way to handle this, as long as Guild knows the flag is a list. I think this is reasonable though \u2014 the flag attr <code>type<\/code> overrides the default parsing rules. So <code>is-list<\/code> tells Guild to treat values as lists, parsing them with Python\u2019s <code>shlex.split(VAL, posix=True)<\/code> algorithm.<\/p>\n<h3>Flag attr <code>parser<\/code>\n<\/h3>\n<p>This could be spelled as a \u201ccommand line arg parser\u201d rather than \u201cis a list\u201d. This is independent of <code>type<\/code>, which gives a hint as to how the value might be parsed (e.g. list of int, etc.)<\/p>\n<pre><code>train:\n  flags:\n    model_dirs:\n      parser: shlex\n<\/code><\/pre>\n<p>The value for <code>parser<\/code> could be a reference to a Python function (e.g. <code>utils.parse_model_dirs<\/code>). The function signature would be <code>(arg_val)<\/code> or <code>(arg_val, flag_def)<\/code> (i.e. arity of 1 or 2).<\/p>\n<p>If a string, the reference could be a reference to <code>guild.flag_util.parse_&lt;str&gt;<\/code>. So e.g. <code>shlex<\/code> would invoke <code>guild.flag_util.parse_shlex<\/code>.<\/p>\n<p>The advantage of this approach over <code>is-list<\/code> is obviously flexibility \u2014 users can concoct their own flag parsing routines as needed (e.g. sets, maps, JSON, etc.) The spelling <code>parser: shlex<\/code> also provides the important detail that the strings must be formatted as shlex-parseable strings, which is otherwise implicit.<\/p>\n<p>The counterpoint is that this is complicating things to accommodate edge cases. And while this scheme works nicely with Python globals, it does not work seamlessly with <code>argparse<\/code> or other command line arg interfaces. A simple \u201clist plus type\u201d scheme does. E.g. <code>argparse<\/code> doesn\u2019t support maps or other non-list structures.<\/p>\n<p>The only case that occurs to me where <code>parser<\/code> is not a stretch to specify a different list interface. E.g. <code>parser: csv<\/code> would indicate that values are parsed using comma delimiters.<\/p>\n<\/details>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-24T11:49:02.537Z",
                "Answer_body":"<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"2\" data-topic=\"293\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<p>Guild doesn\u2019t support multiple flag values as a single assignment. This has come up a few times before \u2014 I believe there\u2019s a GitHub issue for that. I\u2019ll revive that issue and copy you there so you have a reference to it.<\/p>\n<\/blockquote>\n<\/aside>\n<p><img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/+1.png?v=9\" title=\":+1:\" class=\"emoji only-emoji\" alt=\":+1:\"><\/p>\n<aside class=\"quote group-guildai_staff\" data-username=\"garrett\" data-post=\"2\" data-topic=\"293\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/garrett\/40\/123_2.png\" class=\"avatar\"> garrett:<\/div>\n<blockquote>\n<p>In the meantime, the official approach for this is to use a single string value and parse the value as you see fit<\/p>\n<\/blockquote>\n<\/aside>\n<p>I ended up passing a directory, and using a glob pattern to filter things underneath.<\/p>\n<p>My use case here is that I have trained multiple models with Guild, and want to obtain some summary statistics over all the models trained: e.g. averaging accuracies, plotting all the confusion matrices, plotting ROC curves for all models together.<\/p>\n<p>Right now my approach is to mark the desired runs and export them to a directory. My script then takes the directory, and processes all the run directories.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-08-24T12:36:11.965Z",
                "Answer_body":"<p>Hah, you\u2019ve identified another planned feature in your use case!<\/p>\n<p>Guild (0.7) lacks a coherent strategy to support summary operations across multiple runs. I\u2019d like to see an easy for for users to perform an operation across a set of runs.<\/p>\n<details>\n<summary>\nImplementation Notes<\/summary>\n<p>This strikes me as a map-reduce problem.<\/p>\n<p>My quick thoughts on this:<\/p>\n<ul>\n<li>Should be possible to control the set of runs being summarized from the command line \u2014 i.e. this logic should not be hard-coded in a script.<\/li>\n<li>The summary operation would receive some structure to iterate over, or a callback with state.<\/li>\n<li>The summary results should be available as run output, scalars, etc. \u2014 i.e. the summary run is like any other run.<\/li>\n<li>The interface should not require a Guild library import, though Guild should provide a simple API to support this. <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-0333\/\">WSGI<\/a> is a good example of a framework agnostic API in Python.<\/li>\n<\/ul>\n<h4>Util support for main module<\/h4>\n<p>Following the batch util pattern (used for batches\/optimizers):<\/p>\n<pre><code class=\"lang-yaml\">summary-op:\n  main: summary_main\n<\/code><\/pre>\n<pre><code class=\"lang-python\"># summary_main.py\n\nfrom guild import summary_util\n\ndef summarize(run, state):\n    state.setdefault(\"run-ids\", []).append(run.id)\n\nif __name__ == \"__main__\":\n    result = summary_util.summarize(summarize, {})\n    print(result[\"run-ids\"])\n<\/code><\/pre>\n<p>Alternatively:<\/p>\n<pre><code class=\"lang-python\"># summary_main.py (alt interface)\n\nfrom guild import summary_util\n\nif __name__ == \"__main__\":\n    run_ids = [run.id for run in summary_util.iter_runs()]\n    print(run_ids)\n<\/code><\/pre>\n<h4>Guild independent Python interface (novel)<\/h4>\n<p>The intent of this interface is to provide an interface that\u2019s independent of Guild. The approach, naming conventions, etc. are entirely speculative at this point.<\/p>\n<pre><code class=\"lang-yaml\">summary-op:\n    summary-callbacks: summary\n<\/code><\/pre>\n<pre><code class=\"lang-python\"># summary.py\n\ndef summary_init(parent_run):\n    return {}\n\ndef summary_run(run, state):\n    state.setdefault(\"run-ids\", []).append(run[\"id\"])\n\ndef summary_finish(state):\n    print(state[\"run-ids\"])\n<\/code><\/pre>\n<p>We need three functions: init state, handle run, and finish. The example above specifies a Python module. Guild should assume three functions by default when a single item is specified (e.g. <code>summary_init\/1<\/code>, <code>summary_run\/2<\/code>, and <code>summary_finish\/1<\/code> above). The value could alternatively be a three-tuple where each function is specified explicitly.<\/p>\n<p>Run arguments to these functions should be Python dict-like object used to access run-to-be-summarized attributes. This should not be a Guild-specific interface (though Guild might provide a lazy loading optimization). This follows the WSGI <code>environ<\/code> pattern where request state is provided by a framework neutral data structure.<\/p>\n<p>This approach introduces a new pattern: the callback interface. I\u2019d expect this to be applied to batch\/optimizers as well.<\/p>\n<\/details>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to set PYTHONPATH and possible effects?",
        "Question_link":"https:\/\/my.guild.ai\/t\/how-to-set-pythonpath-and-possible-effects\/287",
        "Question_created_time":1597011694991,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":565,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m using Blender in my project which has it\u2019s own python implementation separate to that of my environment.  When I run guild with my project it writes to PYTHONPATH which interferes with sys.path  and causes problems with the blender installation of python.  Is there any easy way to set the PYTHONPATH in my guild files to overcome this issue?  Also are there any problems that might occur from setting PYTHONPATH while guild is running? Thanks.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-08-10T12:32:44.212Z",
                "Answer_body":"<p>Guild modifies the system path by inserting the run source code directory at the front of the path. This can cause undesirable results if you\u2019re unintentionally copying source code files for a run that collide with system packages and modules.<\/p>\n<p>You can show the files that Guild copies as source code by running:<\/p>\n<pre><code class=\"lang-command\">guild run &lt;operation&gt; --test-sourcecode\n<\/code><\/pre>\n<p>See <a href=\"\/docs\/operations#operation-source-code\">Operation Source Code<\/a> for more information.<\/p>\n<p>You can disable this behavior altogether by <a href=\"\/cheatsheets\/guildfile#sourcecode-disable\">disabling source code<\/a> for your operation. In this case Guild doesn\u2019t modify the Python system path at all.<\/p>\n<p>However, in this case you lose the feature of creating source code copies of your project.<\/p>\n<p>Regarding modifying the <code>PYTHONPATH<\/code> environment variable while Guild is running, this should not be an issue, though typically this won\u2019t affect module loading as (I believe) once the Python VM is running it uses <code>sys.path<\/code> exclusively and ignored the <code>PYTHONPATH<\/code> environment. The environment variable would come into play for calls to <code>subprocess.Popen<\/code> when <code>env<\/code> is not otherwise specified, which may be important for Blender.<\/p>\n<p>If you can identify the specific problem that\u2019s occurring with Blender I can offer a more specific solution.<\/p>\n<p>P.S. If you want the painful details of Guild\u2019s behavior wrt to <code>PYTHONPATH<\/code>, see <a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/master\/guild\/tests\/pythonpath.md\">these tests<\/a>.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NameError: name 'argparse' is not defined",
        "Question_link":"https:\/\/my.guild.ai\/t\/nameerror-name-argparse-is-not-defined\/256",
        "Question_created_time":1595612979502,
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":3345,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<br>\nStarting from a fresh environment with python 3.7.3 and doing a <code>pip install guildai<\/code>, when trying to run<br>\n<code>guild tensorboard<\/code><br>\nI get this error:<br>\nFile \u201c\/Users\/louis-emmanuelmartinet\/.pyenv\/versions\/3.7.3\/envs\/ds-gathering\/lib\/python3.7\/site-packages\/tensorboard_plugin_wit\/wit_plugin_loader.py\u201d, line 73, in define_flags<br>\nexcept argparse.ArgumentError:<br>\nNameError: name \u2018argparse\u2019 is not defined<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-07-24T17:50:58.777Z",
                "Answer_body":"<p>When I fix this by hand doing <code>import argparse<\/code> then I get:<br>\n\u201cFile \u201c\/Users\/louis-emmanuelmartinet\/.pyenv\/versions\/3.7.3\/envs\/ds-gathering\/lib\/python3.7\/site-packages\/guild\/tensorboard.py\u201d, line 525, in create_app<br>\nreturn application.standard_tensorboard_wsgi(<br>\nAttributeError: module \u2018tensorboard.backend.application\u2019 has no attribute \u2018standard_tensorboard_wsgi\u2019\u201d<\/p>\n<p>Any thoughts?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-24T17:54:51.529Z",
                "Answer_body":"<p>TensorBoard 2.3.0 landed and changed their API on us.<\/p>\n<p>This will get you back and running.<\/p>\n<pre><code class=\"lang-command\">pip install tensorboard==2.2.2\n<\/code><\/pre>\n<p>I\u2019ll get a patch out for this ASAP.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-25T13:53:59.941Z",
                "Answer_body":"<p><a href=\"\/releases\/0.7.0.post1\">0.7.0.post1<\/a> is out which handles this with a version downgrade for TensorBoard. This is a short term solution \u2014 0.7.1 will have proper support for 2.3.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NameError: guild doesnt recognize defined variable?",
        "Question_link":"https:\/\/my.guild.ai\/t\/nameerror-guild-doesnt-recognize-defined-variable\/245",
        "Question_created_time":1595362145946,
        "Question_answer_count":9,
        "Question_score_count":2,
        "Question_view_count":1113,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I tried to train a random forest using guildai. Here is my script:<br>\n<\/p><aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py\" target=\"_blank\" rel=\"nofollow noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py\" target=\"_blank\" rel=\"nofollow noopener\">MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py<\/a><\/h4>\n<pre><code class=\"lang-py\"># fundamental modules\nimport numpy as np\nimport pandas as pd\nfrom numba import njit\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport sys\nimport os\nfrom pathlib import Path\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom mlfinlab.ensemble import SequentiallyBootstrappedBaggingClassifier\nfrom sklearn.base import clone\nimport xgboost\nimport shap\nimport mlfinlab as ml\nimport trademl as tml\n\n<\/code><\/pre>\n\n  This file has been truncated. <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py\" target=\"_blank\" rel=\"nofollow noopener\">show original<\/a>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>It works as expected if I jsut execute the script loccaly. But if I run it through guild:<\/p>\n<pre><code>`guild run --yes --max-trials 2 random_forest:train num_threads=4 tb_volatility_scaler=[1,1.5,2] ts_look_forward_window=[1200,2400] sample_weights_type=[returns,time_decay,trend_scanning] max_depth=range[2:6:1] max_features=range[5:100:5] n_estimators=range[50:1000:50] min_weight_fraction_leaf=range[0.01:0.1:0.01] class_weight=[balanced_subsample,balanced]`\nit returns an error:\n(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; guild run --yes --max-trials 2 random_forest:train num_threads=4 tb_volatility_scaler=[1,1.5,2] ts_look_forward_window=[1200,2400] sample_weights_type=[returns,time_decay,trend_scanning] max_depth=range[2:6:1] max_features=range[5:100:5] n_estimators=range[50:1000:50] min_weight_fraction_leaf=range[0.01:0.1:0.01] class_weight=[balanced_subsample,balanced]\ne[33mWARNING: Could not parse requirement: -umpye[0m\ne[33mWARNING: Could not parse requirement: -illowe[0m\ne[33mWARNING: Could not parse requirement: -umpye[0m\ne[33mWARNING: Could not parse requirement: -illowe[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\data\\sampe_Data.csv because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\trademl\\modeling\\random_forest\\X_TEST.csv because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\trademl\\modeling\\random_forest\\nn_sample.csv because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\trademl\\modeling\\random_forest\\rf_model.json because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\trademl\\modeling\\random_forest\\rf_model_25.json because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\ne[33mWARNING: Skipping potential source code file C:\\Users\\Mislav\\Documents\\GitHub\\trademl\\trademl\\modeling\\random_forest\\rf_model_25_ts.json because it's too big. To control which files are copied, define 'sourcecode' for the operation in a Guild file.e[0m\nINFO: [guild] Running trial c8f45a92942845fa9ef7fc8d5d8afd73: random_forest:train (class_weight=balanced, cv_number=4, labeling_technique=triple_barrier, max_depth=2, max_features=70, min_weight_fraction_leaf=0.02, n_estimators=950, num_threads=4, sample_weights_type=trend_scanning, structural_break_regime=all, tb_triplebar_min_ret=0.004, tb_triplebar_num_days=10, tb_volatility_lookback=50, tb_volatility_scaler=2, ts_look_forward_window=2400)\nINFO: [numexpr.utils] Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\nINFO: [numexpr.utils] NumExpr defaulting to 8 threads.\n2020-07-21 21:58:55.448030 100.0% apply_pt_sl_on_t1 done after 0.19 minutes. Remaining 0.0 minutes.\ndropped label:  0 0.00015123254524373645\n'fit' took 53.25 seconds to run.\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\.guild\\runs\\c8f45a92942845fa9ef7fc8d5d8afd73\\.guild\\sourcecode\\trademl\\modeling\\train_rf.py\", line 202, in &lt;module&gt;\n    sample_weight_train=sample_weigths,\nNameError: name 'sample_weigths' is not defined\n<\/code><\/pre>\n<p>It says sample_weight is not defined, but it is defined in the script and it works if I just execute it inside my IDE.<\/p>\n<p>OS: WIndows<br>\nIDE: VSCode<br>\nguild version: 0.7.0.rc11<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-07-21T20:23:39.909Z",
                "Answer_body":"<p>There\u2019s a case there the variable <code>sample_weigths<\/code> is not initialized:<\/p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py#L181\" target=\"_blank\" rel=\"noopener\">github.com<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https:\/\/github.com\/MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py#L181\" target=\"_blank\" rel=\"noopener\">MislavSag\/trademl\/blob\/master\/trademl\/modeling\/train_rf.py#L181<\/a><\/h4>\n<pre class=\"onebox\"><code class=\"lang-py\"><ol class=\"start lines\" start=\"171\" style=\"counter-reset: li-counter 170 ;\">\n<li>        num_threads=1)<\/li>\n<li>elif sample_weights_type == 'time_decay':<\/li>\n<li>    sample_weigths = ml.sample_weights.get_weights_by_time_decay(<\/li>\n<li>        labeling_info.reindex(X_train.index),<\/li>\n<li>        data.loc[X_train.index, 'close_orig'],<\/li>\n<li>        decay=0.5, num_threads=1)<\/li>\n<li>elif labeling_technique == 'trend_scanning':<\/li>\n<li>    sample_weigths = labeling_info['t_value'].reindex(X_train.index).abs()<\/li>\n<li># elif labeling_technique == 'none':<\/li>\n<li>#     sample_weigths = None<\/li>\n<li class=\"selected\">\n<\/li><li>\n<\/li><li>### CROS VALIDATION STEPS<\/li>\n<li>if cv_type == 'purged_kfold':<\/li>\n<li>    cv = ml.cross_validation.PurgedKFold(<\/li>\n<li>        n_splits=cv_number,<\/li>\n<li>        samples_info_sets=labeling_info['t1'].reindex(X_train.index))<\/li>\n<li>\n<\/li><li>\n<\/li><li>### MODEL<\/li>\n<li># MLDP str 98\/99<\/li>\n<\/ol><\/code><\/pre>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>You want an <code>else<\/code> clause in there. If there isn\u2019t a legit value in that case, use an assertion to catch the problem before it gets out of the init block.<\/p>\n<pre><code class=\"lang-python\">if a == 1:\n  b = \"one\"\nelif a == 2:\n  b = \"two\"\nelse:\n  assert False, a\n<\/code><\/pre>\n<p>Guild is likely setting <code>sample_weights_type<\/code> to something that you\u2019re not checking for, which is why you\u2019re seeing different behavior when running with Guild.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T06:46:55.065Z",
                "Answer_body":"<p>Sorry <span class=\"mention\">@garret<\/span>, I have found \u2018the bug\u2019, last one should be<\/p>\n<pre><code>elif sample_weights_type == 'trend_scanning':\n<\/code><\/pre>\n<p>not<\/p>\n<pre><code>elif labeling_technique == 'trend_scanning':\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T12:37:38.266Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, do you know what can be the reason for guild not to save scalars in my same script? I saved them before.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T15:35:41.673Z",
                "Answer_body":"<p>Make sure your output scalar config is picking up the script output as expected. Use <code>--test-output-scalars<\/code> on some sample run output to see how the rules are applied. Check out the <a href=\"https:\/\/my.guild.ai\/t\/guild-file-reference\/197#output-scalars\"><em>Guild File Reference<\/em><\/a> for pointers.<\/p>\n<p>You can evaluate the output of your latest run with this command:<\/p>\n<pre><code class=\"lang-command\">guild cat --output | guild run train --test-output-scalars -\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/my.guild.ai\/t\/commands-cheatsheet\/193#debug-an-operation\"><em>Command Cheatsheet<\/em><\/a> has some other examples to help debug operations.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T16:23:22.010Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, I have just discovered that guild doesn\u2019t save scalars when I use option:<\/p>\n<pre><code>$Env:NO_RUN_OUTPUT=1 \n<\/code><\/pre>\n<p>I use this option because you recommended it in this thread: <a href=\"https:\/\/my.guild.ai\/t\/timeout-error\/196\/10\" class=\"inline-onebox\">Timeout error<\/a><\/p>\n<p>But above option really solved my timeout error problem.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T16:30:30.587Z",
                "Answer_body":"<p>Ah, yes indeed - good catch!<\/p>\n<p>The two options are to a) see if that timeout problem still occurs. As I\u2019ve mentioned that\u2019s a real bear of a problem if it can\u2019t be recreated consistently. IIRC your project uses multi-threading libraries and getting multi-threading processes to run reliably is something humankind has been fighting for for a long time.<\/p>\n<p>Option b), which is I think what you should consider at this point, is to log the scalar values explicitly using one of the various logging libraries for TF summaries. See <a href=\"https:\/\/my.guild.ai\/t\/scalars\/160#tensorboard-summaries\">this section<\/a> for help.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T16:46:38.480Z",
                "Answer_body":"<p>I don\u2019t have experience with TensorBoard Summaries, but I will check out <a href=\"https:\/\/github.com\/lanpa\/tensorboardX\" rel=\"nofollow noopener\">tensorBoardX<\/a> since I have various models to test.<\/p>\n<p>Do you have example hoe to implement it with guild?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-22T16:54:22.684Z",
                "Answer_body":"<p>You bet! Here are some links:<\/p>\n<ul>\n<li><a href=\"https:\/\/github.com\/lanpa\/tensorboardX\">https:\/\/github.com\/lanpa\/tensorboardX<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/scalars\/train_with_tensorboardX.py\">https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/scalars\/train_with_tensorboardX.py<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/tensorboard\/projector2.py\">https:\/\/github.com\/guildai\/guildai\/blob\/master\/examples\/tensorboard\/projector2.py<\/a><\/li>\n<\/ul>\n<p>I don\u2019t recall if your project uses Pytorch but <a href=\"https:\/\/pytorch.org\/docs\/stable\/tensorboard.html\">this lib<\/a> will be available to you without having to install yet-another-dependency (tensorboardX). Otherwise tensorboardX is pretty light and works great!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-23T12:41:40.532Z",
                "Answer_body":"<p>I tried with tensorboardx writer and it works. Thanks.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Random search unexpectedly failling with TypeError",
        "Question_link":"https:\/\/my.guild.ai\/t\/random-search-unexpectedly-failling-with-typeerror\/240",
        "Question_created_time":1595019412387,
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":433,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I was unable to replicate this in a minimalistic example so I didn\u2019t create an issue. I\u2019m guessing my guild.yml file is very incorrect or something. Might also be some package versions that are incorrect in this venv?<\/p>\n<p>Command:<\/p>\n<pre><code>guild run train batch_size=[16,32] --optimizer random\n<\/code><\/pre>\n<p>guild.yml snippet:<\/p>\n<pre><code>    train:\n      main: train\n      flags-import: all\n      output-scalars: off\n      requires:\n        - database\n<\/code><\/pre>\n<p>train.py snippet:<\/p>\n<pre><code>parser.add_argument('--batch_size', type=int, default=256)\n<\/code><\/pre>\n<p>Stacktrace:<\/p>\n<pre><code>Traceback (most recent call last):\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 192, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/guild\/plugins\/random_main.py\", li\nne 23, in &lt;module&gt;\n    from . import skopt_util\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/guild\/plugins\/skopt_util.py\", line 27, in &lt;module&gt;\n    import skopt\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/skopt\/__init__.py\", line 44, in &lt;module&gt;\n    from . import callbacks\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/skopt\/callbacks.py\", line 17, in &lt;module&gt;\n    from skopt.utils import dump\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/skopt\/utils.py\", line 3, in &lt;module&gt;\n    from sklearn.utils import check_random_state\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/__init__.py\", line 64, in &lt;module&gt;\n    from .base import clone\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/base.py\", line 14, in &lt;module&gt;\n    from .utils.fixes import signature\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/utils\/__init__.py\", line 14, in &lt;module&gt;\n    from . import _joblib\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/utils\/_joblib.py\", line 22, in &lt;module&gt;\n    from ..externals import joblib\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/__init__.py\", line 119, in &lt;module&gt;\n    from .parallel import Parallel\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/parallel.py\", line 28, in &lt;module&gt;\n    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/_parallel_backends.py\", line 22, in &lt;module&gt;\n    from .executor import get_memmapping_executor\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/executor.py\", line 14, in &lt;module&gt;\n    from .externals.loky.reusable_executor import get_reusable_executor\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/externals\/loky\/__init__.py\", line 12, in &lt;module&gt;\n    from .backend.reduction import set_loky_pickler\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/externals\/loky\/backend\/reduction.py\", line 125, in &lt;module&gt;\n    from sklearn.externals.joblib.externals import cloudpickle  # noqa: F401\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/externals\/cloudpickle\/__init__.py\", line 3, in &lt;module&gt;\n    from .cloudpickle import *\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py\", line 152, in &lt;module&gt;\n    _cell_set_template_code = _make_cell_set_template_code()\n  File \"\/home\/richard\/Documents\/league\/venv\/lib\/python3.8\/site-packages\/sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py\", line 133, in _make_cell_set_template_code\n    return types.CodeType(\nTypeError: an integer is required (got type bytes)\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-07-17T21:05:43.188Z",
                "Answer_body":"<p>The issue was resolved by installing the latest version of scikit-learn. I think I had an older version of scikit-learn installed and when I upgraded guild to 0.7.0 it did not follow.<\/p>\n<p><code>pip install -U scikit-learn<\/code><\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-17T22:28:08.768Z",
                "Answer_body":"<p>What version did you end up installing?<\/p>\n<p>Guild guards against a bug in a version of sklearn that breaks scikit-optimize but that should be lifted.<\/p>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/17198\" target=\"_blank\" rel=\"noopener\">github.com\/scikit-learn\/scikit-learn<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/17198\" target=\"_blank\" rel=\"noopener\">sklearn.utils.fixes.MaskedArray removed in 0.23.0<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-05-12\" data-time=\"23:16:41\" data-timezone=\"UTC\">11:16PM - 12 May 20 UTC<\/span>\n      <\/div>\n\n        <div class=\"date\">\n          closed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-05-13\" data-time=\"06:52:26\" data-timezone=\"UTC\">06:52AM - 13 May 20 UTC<\/span>\n        <\/div>\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/gar1t\" target=\"_blank\" rel=\"noopener\">\n          <img alt=\"gar1t\" src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/84ac3354a76fe15593cedb56fe486a0ed93d5440.jpeg\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          gar1t\n        <\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n<\/div>\n\n<div class=\"github-row\">\n  <p class=\"github-content\">In scikit-learn 0.23.0:\n&gt;&gt;&gt; import skopt\nTraceback (most recent call last):\n File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n File \"venv\/lib\/python3.6\/site-packages\/skopt\/__init__.py\", line 54, in &lt;module&gt;\n...<\/p>\n<\/div>\n\n<div class=\"labels\">\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">Bug: triage<\/span>\n<\/div>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>I\u2019ll fix that as I think that\u2019s been resolved upstream. Sorry about that! I\u2019m glad you got is sorted.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-19T19:31:13.905Z",
                "Answer_body":"<p>I upgraded to scikit-learn 0.23.1 and it resolved my issue<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Timeout error",
        "Question_link":"https:\/\/my.guild.ai\/t\/timeout-error\/196",
        "Question_created_time":1592656643969,
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":736,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi <a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>,<\/p>\n<p>I can\u2019t figure out why sometimes I get timeout error when I run experiments. Here is my running command:<\/p>\n<pre><code>guild run train tb_volatility_lookback=range[30:300:10]\n<\/code><\/pre>\n<p>it hangs after some time and when I click ctr + c to abort it the below error shows up.<\/p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\runpy.py\u201d, line 193, in _run_module_as_main<br>\nINFO: [numexpr.utils] NumExpr defaulting to 8 threads.<br>\n\u201c<strong>main<\/strong>\u201d, mod_spec)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\runpy.py\u201d, line 85, in _run_code<br>\nexec(code, run_globals)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\batch_main.py\u201d, line 38, in <br>\nmain()<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\batch_main.py\u201d, line 26, in main<br>\nbatch_util.handle_trials(batch_run, trials)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\batch_util.py\u201d, line 54, in handle_trials<br>\n_run_trials(batch_run, trials)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\batch_util.py\u201d, line 79, in _run_trials<br>\n_start_trial_run(run, stage)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\batch_util.py\u201d, line 117, in _start_trial_run<br>\nrun_impl.run(restart=run.id, stage=stage)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1940, in run<br>\nmain(args)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1017, in main<br>\n_dispatch_op(S)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1101, in _dispatch_op<br>\n_dispatch_op_cmd(S)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1286, in _dispatch_op_cmd<br>\n_confirm_and_run(S)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1354, in _confirm_and_run<br>\n_run(S)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1544, in _run<br>\n_run_local(S)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1575, in _run_local<br>\n_run_op(op, S.args)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\commands\\run_impl.py\u201d, line 1683, in _run_op<br>\nextra_env=extra_env,<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op.py\u201d, line 160, in run<br>\nexit_status = _run(run, op, quiet, stop_after, extra_env)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op.py\u201d, line 195, in _run<br>\nexit_status = _op_wait_for_proc(op, proc, run, quiet, stop_after)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op.py\u201d, line 230, in _op_wait_for_proc<br>\nreturn _op_watch_proc(op, proc, run, quiet, stop_after)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op.py\u201d, line 238, in _op_watch_proc<br>\nreturn _proc_wait(proc, stop_after)<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op.py\u201d, line 259, in <strong>exit<\/strong><br>\nself._output.wait_and_close()<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op_util_legacy.py\u201d, line 254, in wait_and_close<br>\nself.close()<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op_util_legacy.py\u201d, line 219, in close<br>\nlock = self._acquire_output_lock()<br>\nFile \u201cC:\\ProgramData\\Anaconda3\\lib\\site-packages\\guild\\op_util_legacy.py\u201d, line 232, in _acquire_output_lock<br>\nraise RuntimeError(\u201ctimeout\u201d)<br>\nRuntimeError: timeout<\/p>\n<\/blockquote>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-20T13:30:57.226Z",
                "Answer_body":"<p>Is this project generally available where I could try to reproduce this?<\/p>\n<p>This is a deadlock, which is typically hard to track down because it\u2019s hard to recreate. I\u2019d typically ask for a simplified version, but chances are good that as you simplify the project, the issue goes away.<\/p>\n<p>If you\u2019re not able to share the project, we\u2019ll need to come up with a strategy for debugging this.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-20T13:38:06.688Z",
                "Answer_body":"<p>I should be easy reproducible. Here is my modul <a href=\"https:\/\/github.com\/MislavSag\/trademl\/tree\/master\/trademl\/modeling\" rel=\"nofollow noopener\">https:\/\/github.com\/MislavSag\/trademl\/tree\/master\/trademl\/modeling<\/a>.<\/p>\n<p>In the root the following command should be executed:<br>\nguild run --yes --max-trials 150 train labeling_technique=[trend_scanning] tb_volatility_scaler=[1,1.5,2] tb_triplebar_num_days=[10,20,30,50] tb_triplebar_min_ret=[0.04,0.05,0.06] tb_volatility_lookback=range[30:300:10] sample_weights_type=[returns,time_decay]<\/p>\n<p>EDIT: the data is problem! I have data locally. I plan to put it on SQL\u2026<\/p>\n<p>So unfortunately right now it is not possible to reproduce.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-20T19:04:54.561Z",
                "Answer_body":"<p>I created a <a href=\"https:\/\/github.com\/gar1t\/trademl\">fork<\/a> of this project and made some changes so I could run up to the point where the train script needs the h5 data.<\/p>\n<p>If you can recreate this problem with sample data that you can sent me, I\u2019ll see if I can recreate it.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-20T19:10:42.749Z",
                "Answer_body":"<p>As a work around for this problem, try setting <code>NO_RUN_OUTPUT=1<\/code> when you run the operation.<\/p>\n<pre><code class=\"lang-command\">NO_RUN_OUTPUT=1 guild run train tb_volatility_lookback=range[30:300:10]\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-21T08:50:20.523Z",
                "Answer_body":"<p>It worked when I used lower number of flags. Maybe there was a problem with one grid search (one flag contained range function), but it works now. I will try to debug it by adding new flags ans see on which one it stops working.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-21T14:12:28.668Z",
                "Answer_body":"<p>Threading problems are notorious for suddenly appearing and suddenly disappearing. They are highly nondeterministic and therefore hard to track down and fix.<\/p>\n<p>My bet is that you\u2019ll run into this again.<\/p>\n<p>I think the best course would be to produce some sanitized test data (nothing private) that, along with the full set of flags, reproduces the deadlock. With that, hopefully, I can reproduce it on a system. With that I can fix it. Short of that, it\u2019ll be tough.<\/p>\n<p>Otherwise, I suggesting setting <code>NO_RUN_OUTPUT=1<\/code> in your environment to make sure Guild never runs the code in question. With that you can safely run the script without risk of it deadlocking. You can write your output to logs as needed.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-07T15:45:02.258Z",
                "Answer_body":"<p><a class=\"mention\" href=\"\/u\/garrett\">@garrett<\/a>, when I run <code>NO_RUN_OUTPUT=1<\/code> option,<br>\n<code>NO_RUN_OUTPUT=1 guild run --yes --max-trials 32 random_forest_sklearnopt:train num_threads=4 tb_volatility_lookback=[50,200] ts_look_forward_window=[600,1200,2400,4800] sample_weights_type=[returns,time_decay]<\/code><\/p>\n<p>I get the error:<\/p>\n<pre><code>NO_RUN_OUTPUT=1 : The term 'NO_RUN_OUTPUT=1' is not recognized as the name of a cmdlet, function, script file, or opera\nble program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.\nAt line:1 char:1\n+ NO_RUN_OUTPUT=1 guild run --yes --max-trials 32 random_forest_sklearn ...\n+ ~~~~~~~~~~~~~~~\n    + CategoryInfo          : ObjectNotFound: (NO_RUN_OUTPUT=1:String) [], CommandNotFoundException\n    + FullyQualifiedErrorId : CommandNotFoundException\n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-08T11:22:27.477Z",
                "Answer_body":"<aside class=\"quote no-group\" data-username=\"mislav\" data-post=\"8\" data-topic=\"196\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/77aa72\/40.png\" class=\"avatar\"> mislav:<\/div>\n<blockquote>\n<p><code>is not recognized as the name of a cmdlet<\/code><\/p>\n<\/blockquote>\n<\/aside>\n<p>This looks like PowerShell. Consult the docs for setting env vars in that shell. <a href=\"https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.core\/about\/about_environment_variables?view=powershell-7\">This doc<\/a> from Microsoft seems to apply.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-11T14:21:46.881Z",
                "Answer_body":"<p>I set it like:<br>\n$Env:NO_RUN_OUTPUT=1<\/p>\n<p>It works fine on first try. I will see if there will be problems in the future.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Hyperopt TPE vs Skopt Gaussian Processes",
        "Question_link":"https:\/\/my.guild.ai\/t\/hyperopt-tpe-vs-skopt-gaussian-processes\/226",
        "Question_created_time":1594425943757,
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":1057,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>In developing the <a href=\"\/examples\/hyperopt\">Hyperopt example<\/a> I wanted to compare its performance to Scikit Optimize \u2014 specifically the gp optimizer.<\/p>\n<p>I ran 50 trials for each optimizer, minimizing loss for the <a href=\"\/start\">Get Started<\/a> mock training script.<\/p>\n<p>Scatterplot results for <code>tpe<\/code>:<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/8ecf41f9c817b7f95164b7b316e22df93557e59f.png\" alt=\"Screenshot from 2020-07-10 18-54-25\" data-base62-sha1=\"knlQBjfmWovvTNYOIf57tOMzfRB\" width=\"617\" height=\"483\"><\/p>\n<p>Scatterplot results for <code>gp<\/code>:<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/d53d68bff805218b9b3d82c06020af617d5b30f8.png\" alt=\"Screenshot from 2020-07-10 18-53-32\" data-base62-sha1=\"uqpgIYD2oMdbIxugfwf1HAXQWdq\" width=\"627\" height=\"475\"><\/p>\n<p>Notice the concentration of trials around the minimum for <code>gp<\/code>. I would have expected this for <code>tpe<\/code>. I wonder if the example is implemented incorrectly.<\/p>\n<h3>Steps to reproduce<\/h3>\n<p>From the <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\/hyperopt\">example dir<\/a> generate 50 trials using <code>tpe<\/code>:<\/p>\n<pre><code class=\"lang-command\">guild run train -o tpe -m50 x=[-2.0:2.0] -t tpe\n<\/code><\/pre>\n<p>Next generate 50 trials using <code>gp<\/code>:<\/p>\n<pre><code class=\"lang-command\">guild run train -o gp -m50 x=[-2.0:2.0] -t gp\n<\/code><\/pre>\n<p>View the tpe trials in TensorBoard:<\/p>\n<pre><code class=\"lang-command\">guild tensorboard -l tpe\n<\/code><\/pre>\n<p>Click <strong>HPARAMS<\/strong> and then the scatterplot tab. Deselect all flags and metrics except x and loss.<\/p>\n<p>Do the same for the gp trials:<\/p>\n<pre><code class=\"lang-command\">guild tensorboard -l gp\n<\/code><\/pre>",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Issues with Guild file - output-scalars and sourcecode",
        "Question_link":"https:\/\/my.guild.ai\/t\/issues-with-guild-file-output-scalars-and-sourcecode\/218",
        "Question_created_time":1593895791379,
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":559,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>This looks like it would solve the issue but I\u2019m getting new issues with my guild file.<\/p>\n<p>It\u2019s complaining about <code>output-scalars: off<\/code><\/p>\n<pre><code>  operations:\n    search_lr:\n      main: search_lr\n      flags-import: all\n      output-scalars: off\n      requires:\n        - database\n    train:\n<\/code><\/pre>\n<pre><code>ERROR: error loading guildfile from .: error in \/home\/richard\/Documents\/league\/guild.yml: invalid value for output-scalars: False\n<\/code><\/pre>\n<p>I checked here: <a href=\"https:\/\/my.guild.ai\/t\/scalars\/160\" class=\"inline-onebox\">Scalars<\/a> and it seems like I\u2019m doing it correctly?<\/p>\n<p>If I remove that then it starts complaining about my sourcecode:<\/p>\n<pre><code>  sourcecode:\n    - '*.py'\n    - '*.json'\n    - guild.yml\n    - exclude:\n        file:\n          - riot_api_key.py\n        dir:\n          - tb\n          - checkpoints\n          - matches\n          - match_histories\n<\/code><\/pre>\n<pre><code>ERROR: error loading guildfile from .: error in \/home\/richard\/Documents\/league\/guild.yml: invalid exclude value: {'file': ['riot_api_key.py'], 'dir': ['tb', 'checkpoints', 'matches', 'match_histories']}\n<\/code><\/pre>\n<p>The list probably continues after fixing these issues so I think it\u2019s better to wait with this.<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-07-04T20:59:52.339Z",
                "Answer_body":"<p>I\u2019ll look into the <code>off<\/code> issue - likely a bug.<\/p>\n<p>For your <code>exclude<\/code> spec, it\u2019s either <code>dir<\/code> or <code>file<\/code>. The intent is to denote what type of path is being excluded. There\u2019s an optimization for excluding dirs where Guild doesn\u2019t bother scanning the dir for matches. Otherwise an exclude is treated as a pattern is applied to every file in your project.<\/p>\n<p>You want this:<\/p>\n<pre><code class=\"lang-yaml\"> sourcecode:\n    - '*.py'\n    - '*.json'\n    - guild.yml\n    - exclude: riot_api_key.py\n    - exclude:\n        dir:\n          - tb\n          - checkpoints\n          - matches\n          - match_histories\n<\/code><\/pre>\n<p>I\u2019ve never really liked this spelling. There are other options that apply to <code>include<\/code> and <code>exclude<\/code> so there\u2019s some sense to it, but it\u2019s not particularly intuitive to me.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-04T21:02:48.364Z",
                "Answer_body":"<p>Regarding the <code>output-scalars<\/code> error when you use <code>off<\/code> what version of Guild are you using? This is working on my end with 0.7.0.rc11.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-04T21:40:47.280Z",
                "Answer_body":"<p>I used the latest master 341abcd46eb13158275cf5254888d32b4b8203cf<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-04T21:54:45.620Z",
                "Answer_body":"<p>I can\u2019t explain this error with <code>output-scalars<\/code>. Guild doesn\u2019t even generate that string format.<\/p>\n<p>It\u2019s possible that an older version of Guild is in play here?<\/p>\n<p>Does <code>guild check<\/code> shows version <code>0.7.0.rc11<\/code> and <code>guild_install_location<\/code> pointing to the repo code?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-04T21:56:41.106Z",
                "Answer_body":"<p>The next is to see if there\u2019s a small Guild file that replicates that and send it my way. Looking over the current source I just don\u2019t see how it\u2019s possible to get that error message.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-05T15:46:57.987Z",
                "Answer_body":"<p>You were right. I pulled latest master but it fetched only up to 0.6.4. Didn\u2019t care to find out why but cloned everything again instead. I gave up at the point of updating my PATH variable after building guild. Sorry I don\u2019t feel strongly enough about this to warrant this much time. I can wait for the next release.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-05T15:50:28.776Z",
                "Answer_body":"<p>Understandable. For a quick check you can run the script directly (<code>&lt;repo&gt;\/guild\/scripts\/guild<\/code>) without configuring your path. Setting up an alias to that works as well if you want to run from source. No biggie though. There\u2019ll be a quick followup release to 0.7 with this fix.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-05T16:04:39.235Z",
                "Answer_body":"<p>Ok. I tried this <code>&lt;repo&gt;\/guild\/scripts\/guild tensorboard 1<\/code> and it started very quickly. Seems to work.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Tensorboard taking long to startup",
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-taking-long-to-startup\/212",
        "Question_created_time":1593771427991,
        "Question_answer_count":6,
        "Question_score_count":2,
        "Question_view_count":950,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I\u2019m getting this warning:<\/p>\n<p>WARNING: Guild took 9.56 seconds to prepare runs. To reduce startup time, try running with \u2018\u2013skip-images\u2019 or \u2018\u2013skip-hparams\u2019 options or reduce the number of runs with filters. Try \u2018guild tensorboard --help\u2019 for filter options.<\/p>\n<p>Adding skip-images or skip-hparams does not help.<\/p>\n<p>I suspect this happens because I have a resource (symbolic link) to a directory with a lot of files. Is it possible to configure guild tensorboard to ignore this directory?<\/p>\n<p>I found the -O option in: <a href=\"https:\/\/my.guild.ai\/t\/command-tensorboard\/127\" class=\"inline-onebox\">Command: tensorboard<\/a><br>\nbut adding -O logdir=tb did not work (had to abort because it never finished).<\/p>\n<p>Any ideas?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-07-03T12:23:47.051Z",
                "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/samedii\">@samedii<\/a> welcome to the new site!<\/p>\n<p>There\u2019s no easy workaround that I can think of. To me this behavior is arguably a bug. Guild is following symlinks to find run files that might be used for various TensorBoard plugins (e.g. projections, etc.) and I don\u2019t understand why.<\/p>\n<p>I\u2019ll spend some time investigating and look at changing this this. There may be a good reason for the current behavior.<\/p>\n<p>Either way I\u2019ll address this in master. 0.7 is frozen - rc11 is the last release candidate barring some world ending bug that\u2019s discovered.<\/p>\n<p>Are you able to compile and run from source?<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-03T13:09:05.696Z",
                "Answer_body":"<p>Hello <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><br>\nI see, thanks for checking! I don\u2019t think I had any trouble running from source when I did so previously.<\/p>\n<p>I confirmed that the issue was the symbolic link. When I removed it, guild started tb very quickly.<\/p>\n<p>I think this issue would be solved for my specific case if I could specify where to look for tb-logs in the guild.yml. I could maybe use -O logdir=dir\/to\/guild\/runs\/id\/tb already but that\u2019s quite a hassle<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-03T13:22:29.023Z",
                "Answer_body":"<p><code>-O<\/code> is meant to pass options along to TensorBoard without any knowledge of what\u2019s being passed. I think <code>logdir<\/code> needs to be explicitly ignored (with warning message) as Guild takes over the function of setting up and specifying the logdir that TensorBoard sees.<\/p>\n<p>I see what you\u2019re getting at. I agree this should be in the Guild file. I hate to complicate things, but given the flexibility of the tool, where the script can put files anywhere it wants, I think the spec would have to follow the line of <code>sourcecode<\/code> and use Guild\u2019s file select spec.<\/p>\n<p>I think maybe this interface?<\/p>\n<pre><code class=\"lang-yaml\">op:\n  tensorboard:\n    logdir: relpath-to-tb-files\n<\/code><\/pre>\n<p>In this case <code>logdir<\/code> is a fully supported file select spec like that used for <code>sourcecode<\/code>.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-03T14:43:51.040Z",
                "Answer_body":"<p>Yes that would work well in my case and I think most people can easily adapt their code to it if they have these kinds of issues<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-03T14:50:55.909Z",
                "Answer_body":"<p>I just applied this commit:<\/p>\n<aside class=\"onebox githubcommit\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/commit\/341abcd46eb13158275cf5254888d32b4b8203cf\" target=\"_blank\">github.com\/guildai\/guildai<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Commit\">\n    <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M10.86 7c-.45-1.72-2-3-3.86-3-1.86 0-3.41 1.28-3.86 3H0v2h3.14c.45 1.72 2 3 3.86 3 1.86 0 3.41-1.28 3.86-3H14V7h-3.14zM7 10.2c-1.22 0-2.2-.98-2.2-2.2 0-1.22.98-2.2 2.2-2.2 1.22 0 2.2.98 2.2 2.2 0 1.22-.98 2.2-2.2 2.2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/guildai\/guildai\/commit\/341abcd46eb13158275cf5254888d32b4b8203cf\" target=\"_blank\">Don't traverse symlinks when linking to run files for TensorBoard<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        committed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-07-03\" data-time=\"14:44:15\" data-timezone=\"UTC\">02:44PM - 03 Jul 20 UTC<\/span>\n      <\/div>\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/gar1t\" target=\"_blank\">\n          <img alt=\"gar1t\" src=\"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/84ac3354a76fe15593cedb56fe486a0ed93d5440.jpeg\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          gar1t\n        <\/a>\n        \n      <\/div>\n\n      <div class=\"lines\" title=\"changed 1 files with 2 additions and 2 deletions\">\n        <a href=\"https:\/\/github.com\/guildai\/guildai\/commit\/341abcd46eb13158275cf5254888d32b4b8203cf\" target=\"_blank\">\n          <span class=\"added\">+2<\/span>\n          <span class=\"removed\">-2<\/span>\n        <\/a>\n      <\/div>\n    <\/div>\n\n  <\/div>\n<\/div>\n\n\n  <div class=\"github-row\">\n    <pre class=\"github-content\" style=\"white-space: normal;\">It's not clear why symlinks were being traversed in the first\nplace. TensorBoard should avoid letting linked files in anyway. This\nmay have...<\/pre>\n  <\/div>\n\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>If you grab the latest from master that issue should be resolved for you. Just make sure you\u2019re using Guild from source.You can run <code>guild check<\/code> and look for <code>guild_install_location<\/code> to confirm it\u2019s running from the repo and not from an installed package. (You may need to run <code>hash-r<\/code> to clear your shell\u2019s cached location of the <code>guild<\/code> exe.)<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-07-04T21:04:54.103Z",
                "Answer_body":"<p>3 posts were split to a new topic: <a href=\"\/t\/issues-with-guild-file-output-scalars-and-sourcecode\/218\">Issues with Guild file - output-scalars and sourcecode<\/a><\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Guild pull no matching run found",
        "Question_link":"https:\/\/my.guild.ai\/t\/guild-pull-no-matching-run-found\/198",
        "Question_created_time":1592832356985,
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":348,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi,<\/p>\n<p>I am having problems with pulling runs from a remote server.<\/p>\n<pre><code>guild runs --remote remote\n\n[1:5c07e941]  srl\/state:train-rl  2020-06-22 14:45:06  completed  env=SingleGoal-v01\n<\/code><\/pre>\n<p>When I try to pull the run it tells me there is no matching run was found:<\/p>\n<pre><code>guild pull remote 5c07e941 \n\nGetting remote run info \nguild: could not find a run matching '5c07e941'\n<\/code><\/pre>\n<p>My <code>config.yml<\/code> looks as follows:<\/p>\n<pre><code>remotes:\n  remote:\n    type: ssh\n    host: remote\n    user: username\n    guild-home: \/home\/username\/guild\n    guild-env: \/home\/username\/guild\/venv\n<\/code><\/pre>\n<p>The guild version I use is <code>0.7.0.rc11<\/code>.<br>\nPushing a run to the remote works fin.<\/p>\n<p>Have I done something wrong or is it a bug?<\/p>\n<p>Kind regards,<br>\nBart<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-22T13:34:53.053Z",
                "Answer_body":"<p>Hello and welcome! I\u2019m sorry you\u2019re facing this issue. This certainly appears buggy. I\u2019m not able to easily replicate this on rc11 so there may be something specific to your case.<\/p>\n<p>A few questions:<\/p>\n<ul>\n<li>What happens when you use the full run ID (you can get that by including the <code>--verbose<\/code> flag to <code>guild runs<\/code>)<\/li>\n<li>What happens when you use the run index (i.e. <code>1<\/code> in this the example above, but it\u2019ll be different if there are new runs)<\/li>\n<li>Can you pull other runs using the short run ID? If you only have the one run, generate one more \u2014 <a href=\"https:\/\/github.com\/guildai\/guildai\/tree\/master\/examples\/hello\">something simple<\/a> is fine.<\/li>\n<li>If you run <code>guild pull remote<\/code> (no run args) does Guild pull the runs as expected?<\/li>\n<\/ul>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T13:39:01.613Z",
                "Answer_body":"<p>Eh, sorry - hold of on that list of TODOs for a moment.<\/p>\n<p>Where are your runs located on this remote? Based on the config, they should be in <code>\/home\/username\/guild\/runs<\/code>. But Guild will setup your environment so they\u2019re under <code>\/home\/username\/guild\/venv\/.guild\/runs<\/code>.<\/p>\n<p>Try deleting <code>guild-home<\/code> attr (or comment it out) from your user config. In the meantime I\u2019ll setup something with that particular config and see if I can replicate this.<\/p>\n<p>Your list from <code>guild runs<\/code> should match what <code>pull<\/code> sees \u2014 that it doesn\u2019t here I think indicates a bug somewhere.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T13:43:20.012Z",
                "Answer_body":"<p>Hey Garrett,<\/p>\n<p>Thanks for you quick response.<\/p>\n<p>Removing the <code>guild-home<\/code> attribute solved the problem.<\/p>\n<p>Cheers,<br>\nBart<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T14:00:16.228Z",
                "Answer_body":"<p>Great!<\/p>\n<p>I tried to recreate the issue where <code>guild runs -r &lt;remote&gt;<\/code> sees something different from <code>guild pull &lt;remote&gt;<\/code> that might explain what you saw above \u2014 I can\u2019t recreate it. Is it possible that you modified your config in between running the <code>runs list<\/code> and <code>pull<\/code> commands?<\/p>\n<p>For posterity, to fill in some information on the difference between <code>guild-env<\/code> and <code>guild-home<\/code>:<\/p>\n<ul>\n<li>\n<code>guild-env<\/code> is used to activate a virtual environment whenever running on the remote host. You can see what\u2019s going on under the covers by including the <code>--debug<\/code> option to <code>guild<\/code> (e.g. <code>guild --debug run -r remote<\/code>)<\/li>\n<li>Unless <code>guild-home<\/code> is specified, Guild assumes <code>&lt;guild-env&gt;\/.guild<\/code> on the remote host.<\/li>\n<li>You can set <code>guild-home<\/code> independently of <code>guild-env<\/code> \u2014 this just means that runs live in a different location. <code>guild-env<\/code> is still used to activate the virtual environment.<\/li>\n<\/ul>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T14:25:15.510Z",
                "Answer_body":"<p>No I did not modify the config in between running the the <code>runs list<\/code> and <code>pull<\/code> commands.<\/p>\n<p>I added the <code>guild-home = \/home\/username\/guild<\/code> attribute and re-ran the commands using the <code>--debug<\/code> flag. The <code>guild pull<\/code> ssh command does not have the <code>export GUILD_HOME=\/home\/username\/guild;<\/code> attribute whereas the <code>guild runs -r remote<\/code> does:<\/p>\n<pre><code>guild --debug pull remote\n\nGetting remote run info\nDEBUG: [guild.remotes.ssh_util] ssh cmd: ['ssh', '-oStrictHostKeyChecking=no', 'username@remote', 'set -e; source \/home\/username\/guild\/venv\/bin\/activate; guild runs list --json'] \n<\/code><\/pre>\n<pre><code>guild --debug runs -r remote\n\nDEBUG: [guild.remotes.ssh_util] ssh cmd: ['ssh', '-oStrictHostKeyChecking=no', 'username@remote', 'set -e; source \/home\/username\/guild\/venv\/bin\/activate; export COLUMNS=80; export GUILD_HOME=\/home\/username\/guild; guild runs list '] \n<\/code><\/pre>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T14:44:49.009Z",
                "Answer_body":"<p>What you\u2019re seeing is behavior from an older version of Guild. Could you double check your local version of Guild?<\/p>\n<pre><code class=\"lang-command\">guild --version\n<\/code><\/pre>\n<p>The remote version is not in play for this behavior.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T15:02:59.915Z",
                "Answer_body":"<p>That was it.<\/p>\n<p>I installed the latest pre-release but had not deactivated and sourced the environment afterwards. Now everything is working correctly (also with the <code>guild-home<\/code> attribute).<\/p>\n<p>Sorry for the trouble <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/sweat_smile.png?v=9\" title=\":sweat_smile:\" class=\"emoji\" alt=\":sweat_smile:\">.<\/p>\n<p>Bart<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-22T15:04:23.903Z",
                "Answer_body":"<p>Haha no worries. Glad everything\u2019s working!<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Problem setting up environment on Windows",
        "Question_link":"https:\/\/my.guild.ai\/t\/problem-setting-up-environment-on-windows\/190",
        "Question_created_time":1592554051359,
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":910,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>I tried to follow this instructions <a href=\"https:\/\/my.guild.ai\/t\/environments\/164\" class=\"inline-onebox\">Environments<\/a><\/p>\n<p>and when I set:<\/p>\n<pre><code>export GUILD_HOME=guild-rf\n<\/code><\/pre>\n<p>I get error:<\/p>\n<pre><code>export : The term 'export' is not recognized as the name of a cmdlet, function, script file, or operable program. Check\n the spelling of the name, or if a path was included, verify that the path is correct and try again.\nAt line:1 char:1\n+ export GUILD_HOME=.\\guild-rf\\\n+ ~~~~~~\n    + CategoryInfo          : ObjectNotFound: (export:String) [], CommandNotFoundException\n    + FullyQualifiedErrorId : CommandNotFoundException\n<\/code><\/pre>\n<p>I get similar error for:<\/p>\n<pre><code>GUILD_HOME=&lt;path&gt; guild &lt;command&gt; ...\n<\/code><\/pre>\n<p>I have also tried to define everything inside python:<\/p>\n<pre><code># confing\n\nGUILD_HOME = \"guild-rf\"\n\nDELETE_RUNS_ON_INIT = True\n\n# import packages\n\nimport guild.ipy as guild\n\nimport os\n\n# Initialize Guild Home\n\nif not os.path.exists(GUILD_HOME):\n\n    os.mkdir(GUILD_HOME)\n\n    \n\nguild.set_guild_home(GUILD_HOME)\n\n# HERE RUN MY TRAIN SAVED IN SUBMODUL (LOOK AT ABOVE GUILD YML)\n\n_ = guild.run(train)\n<\/code><\/pre>\n<p>I get:<\/p>\n<blockquote>\n<p>_ = guild.run(train)<\/p>\n<p><strong>---------------------------------------------------------------------------<\/strong> <strong>NameError<\/strong> Traceback (most recent call last) <strong>c:\\Users\\Mislav\\Documents\\GitHub\\trademl\\manage_guild.py<\/strong> in <strong>----&gt; [22](file:\/\/\/C:\/Users\/Mislav\/Documents\/GitHub\/trademl\/manage_guild.py?line=21)<\/strong> _ <strong>=<\/strong> guild <strong>.<\/strong> run <strong>(<\/strong> train <strong>)<\/strong> <strong>NameError<\/strong> : name \u2018train\u2019 is not defined<\/p>\n<\/blockquote>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-19T13:21:18.904Z",
                "Answer_body":"<p>The docs are skewed toward POSIX systems like Linux and macOS and documentation for Windows-specific gotchas is spotty.<\/p>\n<p>I started a document so we can start to fill this information in:<\/p>\n<aside class=\"quote quote-modified\" data-post=\"1\" data-topic=\"191\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sjc6.discourse-cdn.com\/standard11\/user_avatar\/my.guild.ai\/guildai\/40\/103_2.png\" class=\"avatar\">\n    <a href=\"https:\/\/my.guild.ai\/t\/help-with-windows\/191\">Help with Windows<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/docs\/13\"><span class=\"badge-category-bg\" style=\"background-color: #7777CA;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Start with Documentation Overview or Get Started Guide.\">Documentation<\/span><\/a>\n  <\/div>\n  <blockquote>\n    Overview\nThis guide provides details for using and configuring Guild for Windows environments. \nActivate Virtual Environments\nCommand Line\nTo activate a virtual environment on Windows, run activate.bat, which is located in the Scripts directory of the virtual environment: \n&lt;venv&gt;\\Scripts\\activate.bat\n\nPower Shell\nIf you\u2019re running Power Shell, run Activate.ps1 instead: \n&lt;venv&gt;\\Scripts\\Activate.ps1\n\nSet Environment Variables\nGuild makes use of various environment variables, in particular GUILD_\u2026\n  <\/blockquote>\n<\/aside>\n\n<p>Regarding <code>ipy<\/code> I would not go down that road. That interface is not really for running Guild CLI commands but rather for running functions within a Notebook. It\u2019s very different from a typical use of Guild.<\/p>\n<p>If you want to invoke Guild CLI commands, from Python, use the <code>subprocess<\/code> module and treat Guild as you would any program.<\/p>\n<p>But back to the environment setup\u2026 you might consider skipping the virtual environment setup and focus on getting your project working. Once you\u2019re happy with things you can take the step to use isolated environments.<\/p>\n<p>You\u2019re already using <code>conda<\/code> so you can just keep doing that without messing around with environment variables, etc.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-19T15:58:37.898Z",
                "Answer_body":"<p>I think than the best solution is work with default setup (save all runs in default .guild directory). thanks.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ValueError: empty body on If",
        "Question_link":"https:\/\/my.guild.ai\/t\/valueerror-empty-body-on-if\/187",
        "Question_created_time":1592405849984,
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":367,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi!<\/p>\n<p>Using Guild AI version 0.6.6 inside a virtual environment, I receive the following error:<\/p>\n<pre><code>$ guild run main.py\nYou are about to run \/mnt\/volume1\/Dropbox\/X\/Y\/W\/main.py\n  DEBUG: yes\n  TRAIN: yes\n  batch_norm: yes\n  cudanum: 0\n  ...\n  \nContinue? (Y\/n) Y\nTraceback (most recent call last):\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 290, in &lt;module&gt;\n    main()\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 57, in main\n    _main()\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 84, in _main\n    _try_module(arg1, rest_args)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 134, in _try_module\n    _dispatch_module_exec(_flags_dest(args), module_info)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 215, in _dispatch_module_exec\n    _exec_module_with_globals(module_info, flags, args)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 271, in _exec_module_with_globals\n    _module_with_globals(module_info, globals)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 278, in _module_with_globals\n    _gen_exec(module_info, exec_script)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 251, in _gen_exec\n    exec_cb()\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/op_main.py\", line 277, in exec_script\n    python_util.exec_script(path, globals)\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/python_util.py\", line 353, in exec_script\n    code = _compile_script(src, filename, _node_filter(globals))\n  File \"\/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages\/guild\/python_util.py\", line 384, in _compile_script\n    dont_inherit=True)\nValueError: empty body on If\n<\/code><\/pre>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-17T16:01:57.347Z",
                "Answer_body":"<p>This should be fixed in the latest prerelease version. Could you give that a try?<\/p>\n<pre><code class=\"lang-command\">pip install guildai --pre --upgrade\n<\/code><\/pre>\n<p>Edit: fixed command to include <code>--upgrade<\/code> option.<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-18T10:41:24.501Z",
                "Answer_body":"<p>Hi,<\/p>\n<p>the following command did not upgrade guildai.<\/p>\n<pre><code>$ pip install guildai --pre\nRequirement already satisfied: guildai in \/home\/USER\/.virtualenvs\/my_venv\/lib\/python3.7\/site-packages (0.6.6)\n...\n<\/code><\/pre>\n<p>By also adding the <code>--upgrade<\/code> argument, I managed to upgrade to 0.7.0.rc9. It works fine now.<\/p>\n<p>Thanks!<\/p>",
                "Answer_has_accepted":false
            },
            {
                "Answer_created_time":"2020-06-18T11:39:27.691Z",
                "Answer_body":"<p>The lastest version is 0.7.0.rc11. It\u2019s surprising that you got only rc9. This suggests we\u2019re missing a release for your platform, but as far as I know rc11 is available for all platforms that rc9 supports so that\u2019s strange.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Precision-recall dashboard not showing",
        "Question_link":"https:\/\/my.guild.ai\/t\/precision-recall-dashboard-not-showing\/155",
        "Question_created_time":1591888269332,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":427,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>Hi Garrett,<\/p>\n<p>I think this should be fixed in rc10 (<a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/173\" rel=\"nofollow noopener\">https:\/\/github.com\/guildai\/guildai\/issues\/173<\/a>) but unfortunately I am still not seeing the PR dashboard when viewing results through Guild. I can try to make an MWE if needed but is there an obvious gotcha\u2019?<\/p>\n<p>To be clear, if I navigate to <code>...\/.guild\/runs\/{RUN_HASH}<\/code> and run <code>tensorboard --logdir .<\/code> then the PR dashboard shows up. If I call <code>guild tensorboard<\/code> there is no sign of that dashboard.<\/p>\n<p>I am explicitly saving the precision-recall event files in a scalars folder in the run directory. I can send\/upload one of these event files if that would help debugging (the example one is only 400B)? N.b. the info in event files that don\u2019t contain the PR curves do show up in <code>guild tensorboard<\/code>.<\/p>\n<p>Thanks again for the hard work.<\/p>\n<p>Chris<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-11T15:21:31.013Z",
                "Answer_body":"<p>Shoot I\u2019m sorry it\u2019s not working - thanks for checking this!<\/p>\n<p>I\u2019ll reply on the <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/173\">GitHub issue<\/a> so the record is one spot.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Parallel batch trial pipeline",
        "Question_link":"https:\/\/my.guild.ai\/t\/parallel-batch-trial-pipeline\/142",
        "Question_created_time":1591810114957,
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":360,
        "Question_has_accepted_answer":false,
        "Question_body":"<p>In a batched trial pipeline see <a href=\"https:\/\/github.com\/guildai\/guildai\/issues\/196\" rel=\"nofollow noopener\">196<\/a>, how can we run as fast as possible parallelizing everything we can ?<\/p>\n<p>Example Pipeline:<\/p>\n<pre><code>operation_1: # has no dependencies\n\noperation_2: \n    requires:\n        - operation: operation_1\n    flags-dest: globals\n    flags-import:\n        - some_param\n\noperation_3: \n    requires:\n        - operation: operation_2\n    flags-dest: globals\n    flags-import:\n        - some_other_param\n\npipeline:\n  steps:\n    - run: operation_1\n    - run: operation_2\n      flags:\n        some_param: [a, b]\n    - run: operation_3\n      flags:\n        some_other_param: [1, 2, 3]\n<\/code><\/pre>\n<pre><code># create 6 queues as we have 6 batch trials that can be done in parallel (a1, a2, a3, b1, b2, b3, c1, c2, c3)\n# run this command 6 times\nguild run queue --background \n\nguild run pipeline --stage\n<\/code><\/pre>\n<p>For some reason this leads to out of sequence events happening, like operation 2 being run before operation 1 resulting in an error. Is this the correct way to do this?<\/p>\n<p>Further, is there a good way of timing this to sanity check parallel works faster i.e time batched trials run?<\/p>",
        "Answer_list":[
            {
                "Answer_created_time":"2020-06-10T23:26:07.272Z",
                "Answer_body":"<p>Don\u2019t use staged runs for this. Just run your pipelines in the background. At some point Guild will be optimized for parallel runs and you won\u2019t have to think about this (as you say - we want to run everything as fast as possible). But at the moment, you need to use parallel OS processes to manage parallel runs.<\/p>",
                "Answer_has_accepted":false
            }
        ]
    }
]