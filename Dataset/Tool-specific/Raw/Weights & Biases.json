[
    {
        "Question_title":"About the W&B Help category",
        "Question_link":"https:\/\/community.wandb.ai\/t\/about-the-w-b-help-category\/539",
        "Question_created_time":"2021-09-13T16:24:10.999Z",
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":1089,
        "Question_body":"<p>Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Changing path or removing cache of artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/changing-path-or-removing-cache-of-artifacts\/4275",
        "Question_created_time":"2023-04-25T07:11:20.716Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":160,
        "Question_body":"<p>I am having an issue of running wandb on a slurm cluster and the artifacts populate in my user dir <code>~\/.local\/share\/wandb\/artifacts\/staging<\/code>. This dir is populated with <code>tmp*<\/code> files. I want to change the environment variable to reroute this path, but none of the paths listed on the <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/storage#docusaurus_skipToContent_fallback\">storage docs<\/a> do it.<\/p>\n<p>Those same docs say that you can run<code>$ wandb artifact cache cleanup 1GB<\/code> from the cmd line but it is unclear of this is for the cache <code>~\/.cache<\/code>. Since this command only caps the cache it is hard to tell if it is working without hitting the <code>1GB<\/code> limit. Can you help clarify if this command is for <code>~\/.local\/share\/wandb\/artifacts\/staging<\/code> or if it is for <code>~\/.cache<\/code>? Thanks for any help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Allow unlimited failed runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/allow-unlimited-failed-runs\/4482",
        "Question_created_time":"2023-05-29T14:17:48.994Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":11,
        "Question_body":"<p>Hello,<\/p>\n<p>I want to find the best hyperparameters using wandb, however, some combinations of them raises cuda memory error, how could I tell wandb that still runs with new hyperparameter combinations if there are these errors? So I do not need to check that all possible combinations do not raise a memory cuda error. I am afraid that  the whole sweep will stop after a specific number of runs has failed.<\/p>\n<p>Could I use some try except or  tell wandb to always execute new runs (like \u201callow unlimited failed runs\u201d) ?<\/p>\n<p>Thanks in advance<\/p>",
        "Question_closed_time":"2023-05-29T15:28:02.966Z",
        "Answer_body":"<p>The solution is WANDB_AGENT_MAX_INITIAL_FAILURES=1000<\/p>\n<p>Solved <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_self_resolution":1.0
    },
    {
        "Question_title":"Wandb connection problem",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-connection-problem\/4484",
        "Question_created_time":"2023-05-29T14:25:26.351Z",
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":11,
        "Question_body":"<p>Hello all, I was able to run and automatically upload my results to wandb yesterday but is unable to do this today (received error of Network error(ReadTimeout). Then i tried the wandb offline command and ran my codes successfully, but encountered Network error (ConnectTimeout) while trying to sync it to wandb online (this was a few hours later since the ReadTimeout error appeared). Was wondering what is the issue here\u2026is there a problem with wandb today? can anyone help?<\/p>\n<p>Here is the latest log  in debug-cli.root.log:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/9\/9e4a5ffd9b9e24d3d73d6c7098a6fd2aa1b87df7.png\" data-download-href=\"\/uploads\/short-url\/mAiMQTOULpcWYBD4EbKduD8Ym3B.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/9e4a5ffd9b9e24d3d73d6c7098a6fd2aa1b87df7_2_651x500.png\" alt=\"image\" data-base62-sha1=\"mAiMQTOULpcWYBD4EbKduD8Ym3B\" width=\"651\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/9e4a5ffd9b9e24d3d73d6c7098a6fd2aa1b87df7_2_651x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/9e4a5ffd9b9e24d3d73d6c7098a6fd2aa1b87df7_2_976x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/9\/9e4a5ffd9b9e24d3d73d6c7098a6fd2aa1b87df7.png 2x\" data-dominant-color=\"ECECEC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1283\u00d7984 376 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot delete project owned by team, as an admin",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-delete-project-owned-by-team-as-an-admin\/4472",
        "Question_created_time":"2023-05-26T19:32:37.872Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":22,
        "Question_body":"<p>I am an admin of a team, and I have a project that I would like to delete. However, when I try to delete it from the team\u2019s home page, I get \u201cError occured while trying to delete project\u201d similar to <a href=\"https:\/\/community.wandb.ai\/t\/deleting-a-project\/3942\">this post<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I want to change my team organization to academic",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-want-to-change-my-team-organization-to-academic\/4480",
        "Question_created_time":"2023-05-29T08:05:40.981Z",
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":13,
        "Question_body":"<p>I have an organization that has exceeded the 250 hour limit. I added a university email account in User Settings, but I can\u2019t change my organization to academic version. How can I change it to academic?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What are the files under \"artifact\/\" for each run?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-are-the-files-under-artifact-for-each-run\/4438",
        "Question_created_time":"2023-05-22T06:34:22.272Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":61,
        "Question_body":"<p>In an effort to comply with the 100GB storage limits, I have been looking closely at the \u201cusage\u201d page (<code>https:\/\/wandb.ai\/usage\/your-username-here<\/code>), and indexing, then deleting files using the <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/\">export API<\/a>. There is sometimes a significant discrepancy between the runs size reported by <code>https:\/\/wandb.ai\/usage\/your-username-here\/your-project-here\/runs<\/code> VS <code>https:\/\/wandb.ai\/usage\/your-username-here\/your-project-here\/runs\/your-run-here<\/code>.<\/p>\n<p>There is a set of files that are returned when using <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/run#files\">Run.files()<\/a> call, but they are invisible when looking at the run on the web dashboard (I suspect they are the cause of that size report discrepancy). In the extreme case of some of my runs, they are json files, with paths starting with <code>artifact\/<\/code>, and they number in the <strong>tens of thousands<\/strong>: e.g.:<\/p>\n<pre><code class=\"lang-auto\">artifact\/142190504\/wandb_manifest.json\nartifact\/142190516\/wandb_manifest.json\nartifact\/142190533\/wandb_manifest.json\nartifact\/142190533\/wandb_manifest.json.deadlist\nartifact\/142190544\/wandb_manifest.json\nartifact\/142190544\/wandb_manifest.json.deadlist\n<\/code><\/pre>\n<p>These files obviously relate to artifacts, but the artifacts themselves are queried through <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/run#logged_artifacts\">Run. logged_artifacts()<\/a>. I have been deleting artifacts in my past runs, keeping only less than 400 per run (these are very small artifacts), and I have been expecting the count of these \u201cmanifest\u201d files to go down, But it instead seemed to have created additional <code>.deadlist<\/code> files\u2026<\/p>\n<p>My questions are:<\/p>\n<ol>\n<li>What are these files?<\/li>\n<li>Are they important?<\/li>\n<li>What can I expect to happen if I manually delete them through the export API?<\/li>\n<li>Are they counted towards the 100GB limit?<\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Both GPU usage and GPU TIme Spent Accessing Memory is low",
        "Question_link":"https:\/\/community.wandb.ai\/t\/both-gpu-usage-and-gpu-time-spent-accessing-memory-is-low\/4476",
        "Question_created_time":"2023-05-26T21:09:46.269Z",
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":21,
        "Question_body":"<p>What does it mean when both GPU Usage and GPU Time Spent Accessing Memory is low. I was under the impression that these two would normally add to 100. My GPU Usage is at about 20% and the GPU time spent accessing memory is at 4%. Could someone help me understand what might be causing this and potentially how  I might be able to solve this.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sync problems",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sync-problems\/4457",
        "Question_created_time":"2023-05-23T18:54:34.409Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":42,
        "Question_body":"<p>I run wandb on a cluster. Job nodes don\u2019t have internet so I need to run <code>wandb sync --sync-all<\/code> from login nodes.<br>\nIf I kill the job, the command keep syncing the killed runs over and over again: I run the command, the run is synced, I re-run the command (to sync new runs) and the old runs are synced again.<br>\nI suspect it\u2019s because how the job was killed, that maybe <code>wandb.finish()<\/code> was not called. Could that be it?<\/p>\n<p>I then try to selectively sync only runs belonging to a project with <code>wandb sync -p myproj<\/code> but it just says<\/p>\n<pre><code class=\"lang-auto\">wandb: Number of runs to be synced: 46\nwandb: Showing 5 runs to be synced:\nwandb:   wandb\/offline-run-20230523_123938\n... [list of the 5 runs]\nwandb: NOTE: use wandb sync --clean to delete 81 synced runs from local directory.\nwandb: NOTE: use wandb sync --sync-all to sync 46 unsynced runs from local directory.\n<\/code><\/pre>\n<p>But the 5 runs are not actually synced.<br>\nI also try tried cleaning with <code>wandb sync --clean<\/code>  but nothing happens, despite it says that there are 81 runs that can be deleted.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Box plot - sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/box-plot-sweep\/4406",
        "Question_created_time":"2023-05-15T15:56:27.460Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":40,
        "Question_body":"<p>Hi.<br>\nI\u2019m running a sweep on some hyper-parameter (let\u2019s say learning_rate).<br>\nIn each run, I  obtain a list of length N: rewards = [1, 2, 3, 4, 5, \u2026].<br>\nDuring the sweep, I want to obtain a box plot for each individual run (where the x-axis is the hyper-parameter (learning_rate)), and ultimatly I want to view all of the box plots in the same figure so i can compare the hyper-parameter values.<br>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Jobs keep failed from second one",
        "Question_link":"https:\/\/community.wandb.ai\/t\/jobs-keep-failed-from-second-one\/4439",
        "Question_created_time":"2023-05-22T06:41:40.385Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":59,
        "Question_body":"<p>Hey guys,<\/p>\n<p>I\u2019m stuck in some issue.<br>\nnow I\u2019m using Pytorch Lightning model, and i can track and visualize the training process.<\/p>\n<p>and also I can create Sweep project, and the first job ran well.<\/p>\n<p>and then after that, from second job, it failed.<\/p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: \ud83d\ude80 View run XXXX at: http:\/\/&lt;my w&amp;b&gt;\nwandb: Synced 4 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\nwandb: Find logs at: &lt;my log path&gt;\nRun kwnhxowe errored: ValueError(\"Type mismatch (&lt;class 'float'&gt; vs. &lt;class 'int'&gt;) with values (0.XXXX vs. 0) for config key: ***\")\nwandb: ERROR Run kwnhxowe errored: ValueError(\"Type mismatch (&lt;class 'float'&gt; vs. &lt;class 'int'&gt;) with values (0.XXXX vs. 0) for config key: ***\")\n<\/code><\/pre>\n<p>Is there anyone who knows the solution to handle this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When resuming a sweep with Bayesian optimization, are the previous runs kept into consideration?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/when-resuming-a-sweep-with-bayesian-optimization-are-the-previous-runs-kept-into-consideration\/4440",
        "Question_created_time":"2023-05-22T07:48:15.514Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":48,
        "Question_body":"<p>When I resume a sweep with <code>method<\/code> set to <code>bayes<\/code> (in its configuration), i.e. with <code> wandb sweep --resume<\/code>, does the Bayesian optimization process keep into consideration the parameter values already explored before the sweep was interrupted? Or is the previous history of the sweep ignored?<\/p>",
        "Question_closed_time":"2023-05-25T17:34:33.778Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/fantauzzi\">@fantauzzi<\/a> , whenever you pause a sweep and then resume it, all methods of a sweep retain history of the parameter values already explored. Resuming will pick up where the sweep left off and run to completion.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Notebook\/full code for \"Hyperparameter Optimization for HuggingFace\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/notebook-full-code-for-hyperparameter-optimization-for-huggingface\/4434",
        "Question_created_time":"2023-05-21T10:38:02.031Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":51,
        "Question_body":"<p>Hello<\/p>\n<p>I want to parallellize my sweeps with WANDB over different GPUs and I came across this post below. It looks promising but unfortunately a full notebook is missing.<\/p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/amogkam\/transformers\/reports\/Hyperparameter-Optimization-for-HuggingFace-Transformers--VmlldzoyMTc2ODI\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7a7a7077833cb4ec4be6e63ad7c2db322d3e15a6.png\" class=\"site-icon\" data-dominant-color=\"FFCC33\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/amogkam\/transformers\/reports\/Hyperparameter-Optimization-for-HuggingFace-Transformers--VmlldzoyMTc2ODI\" target=\"_blank\" rel=\"noopener\" title=\"10:36AM - 27 September 2020\">W&amp;B \u2013 27 Sep 20<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/9\/9db0393d181ccd91c77e6a32aef75e2a272ccfb4.png\" class=\"thumbnail onebox-avatar\" data-dominant-color=\"81979F\" width=\"300\" height=\"300\">\n\n<h3><a href=\"https:\/\/wandb.ai\/amogkam\/transformers\/reports\/Hyperparameter-Optimization-for-HuggingFace-Transformers--VmlldzoyMTc2ODI\" target=\"_blank\" rel=\"noopener\">Hyperparameter Optimization for HuggingFace Transformers<\/a><\/h3>\n\n  <p>This article explains three strategies for hyperparameter optimization for HuggingFace Transformers, using W&amp;B to track our experiments.<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Can you please share this code? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Lines cannot be aligned",
        "Question_link":"https:\/\/community.wandb.ai\/t\/lines-cannot-be-aligned\/4463",
        "Question_created_time":"2023-05-25T03:18:41.055Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":23,
        "Question_body":"<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/14c345610de5fa934d043c1a332a5c76fbff5e93.png\" alt=\"image\" data-base62-sha1=\"2XFULECuzuYsTcwk4bi5mK4xWhl\" width=\"653\" height=\"383\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"In the log file, the style of the printed table will not be aligned",
        "Question_link":"https:\/\/community.wandb.ai\/t\/in-the-log-file-the-style-of-the-printed-table-will-not-be-aligned\/4464",
        "Question_created_time":"2023-05-25T10:10:18.693Z",
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":17,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/f618f8f5662c4691220aa3a9f01228e257bd156b.png\" data-download-href=\"\/uploads\/short-url\/z74XAhSt2W8nK16fI4plqIRQeVR.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/f618f8f5662c4691220aa3a9f01228e257bd156b.png\" alt=\"image\" data-base62-sha1=\"z74XAhSt2W8nK16fI4plqIRQeVR\" width=\"690\" height=\"459\" data-dominant-color=\"3C3B3D\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1214\u00d7809 25.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>we hope:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/4948b7f343c665217d712ea11a5be5f7c49d7e10.png\" data-download-href=\"\/uploads\/short-url\/asiEytrp7t2rsKmq0AMe3INMunS.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/4948b7f343c665217d712ea11a5be5f7c49d7e10.png\" alt=\"image\" data-base62-sha1=\"asiEytrp7t2rsKmq0AMe3INMunS\" width=\"690\" height=\"291\" data-dominant-color=\"F5F5F5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1484\u00d7626 19 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Bayesian sweep repeating the runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bayesian-sweep-repeating-the-runs\/4455",
        "Question_created_time":"2023-05-23T14:27:42.797Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":32,
        "Question_body":"<p>I\u2019m trying to run a bayesian hyperparameter sweep for some inference parameters. I\u2019ve run the sweep initialization command and then started 6 parallel workers on 6 different GPUs. These do one run and then something happened at the second run because, even though the runs are completed and the results saved on the wandb table, the runs start repeating themselves (the third run has the same hyperparameters of the second one and appears to even be the same run on the wandb table, so the total count of runs is always 12).<br>\nThis is the <a href=\"https:\/\/wandb.ai\/gcorso\/confgen_svgd\/sweeps\/lkl7t842\">sweep<\/a>  which I\u2019m happy to share privately if useful.<\/p>\n<p>Thank you very much for the help,<br>\nGabriele<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to login",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-login\/4335",
        "Question_created_time":"2023-05-03T20:51:16.135Z",
        "Question_answer_count":10,
        "Question_score_count":3,
        "Question_view_count":529,
        "Question_body":"<p>I am unable to login to wandb init. This is the error code:<\/p>\n<pre><code class=\"lang-auto\">wandb.init()\nTraceback (most recent call last):\n  File \"\/opt\/conda\/lib\/python3.7\/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"\/opt\/conda\/lib\/python3.7\/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/__main__.py\", line 1, in &lt;module&gt;\n    from wandb.cli import cli\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/cli\/cli.py\", line 932, in &lt;module&gt;\n    @display_error\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/click\/core.py\", line 1234, in decorator\n    cmd = command(*args, **kwargs)(f)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/click\/decorators.py\", line 115, in decorator\n    cmd = _make_command(f, name, attrs, cls)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/click\/decorators.py\", line 89, in _make_command\n    callback=f, params=params, **attrs)\nTypeError: __init__() got an unexpected keyword argument 'no_args_is_help'\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1169, in init\n    raise e\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1146, in init\n    wi.setup(kwargs)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 172, in setup\n    self._wl = wandb_setup.setup(settings=setup_settings)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 327, in setup\n    ret = _setup(settings=settings)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 320, in _setup\n    wl = _WandbSetup(settings=settings)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 303, in __init__\n    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 114, in __init__\n    self._setup()\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 250, in _setup\n    self._setup_manager()\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 277, in _setup_manager\n    self._manager = wandb_manager._Manager(settings=self._settings)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_manager.py\", line 145, in __init__\n    self._service.start()\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/service\/service.py\", line 199, in start\n    self._launch_server()\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/service\/service.py\", line 193, in _launch_server\n    _sentry.reraise(e)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/analytics\/sentry.py\", line 146, in reraise\n    raise exc.with_traceback(sys.exc_info()[2])\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/service\/service.py\", line 191, in _launch_server\n    self._wait_for_ports(fname, proc=internal_proc)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/sdk\/service\/service.py\", line 121, in _wait_for_ports\n    context=context,\nwandb.sdk.service.service.ServiceStartProcessError: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environmentvariable.\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: Network error (SSLError), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-network-error-sslerror-entering-retry-loop\/4408",
        "Question_created_time":"2023-05-15T17:05:10.172Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":48,
        "Question_body":"<p>Its my first time to use wandb and I\u2019m having issue with the initialisation. I did enter my API key.<\/p>\n<p>This issue get triggered when I call wandb.init():<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nwandb: W&amp;B API key is configured. Use <code>wandb login --relogin<\/code> to force relogin<\/p>\n<p>I tried relogin many times but same issue keeps recurring. Could you please advise?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Exporting api stopped working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/exporting-api-stopped-working\/4404",
        "Question_created_time":"2023-05-15T14:19:52.491Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":43,
        "Question_body":"<p>Hello,<\/p>\n<p>The following code until recently was working. right now it only send back \u201cNone\u201d for every logged value.<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api(timeout=109)\nentity, project = \"barthelemymp\", \"Generalization_below20out\"  # set to your entity and project \ngen = api.run(\"barthelemymp\/Generalization_below20out\/6hz5riae\")\nresults300 = {}\n\nfor row in gen.scan_history():\n    if \"epochT\" in row.keys():\n        if row[\"epochT\"] == 300:\n            for k in row.keys():\n                if \"_e\" in k:\n                    print(k)\n                    results300[k] = 1- row[k]\n                    \n\n<\/code><\/pre>\n<p>Mainly here I save every logged value which name end in \u201c_e\u201d at epoch 300.<br>\nEventhough the code is probably not the most efficient until recently it was loading the correct values (for the same run). Something changed apparently<\/p>\n<p>I really need to be able to have access to this data. What happened ?<\/p>\n<p>Best<\/p>\n<p>Barthelemy<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error installing @wandb\/sdk",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-installing-wandb-sdk\/4374",
        "Question_created_time":"2023-05-11T04:13:49.798Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":53,
        "Question_body":"<p>Hi - tried to install JS lib with most recent langchain version, but failed.<br>\nWhen i forced install, there was a runtime error as well. Maybe SDK hasn\u2019t caught up to most recent langchain version?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/eeed937064538e9dbb56f6e12befa07cdc59d26d.png\" data-download-href=\"\/uploads\/short-url\/y5EDO4fdEWd8RakxKMamNcED4q9.png?dl=1\" title=\"Screenshot 2023-05-10 at 9.08.44 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_690x382.png\" alt=\"Screenshot 2023-05-10 at 9.08.44 PM\" data-base62-sha1=\"y5EDO4fdEWd8RakxKMamNcED4q9\" width=\"690\" height=\"382\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_690x382.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_1035x573.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/eeed937064538e9dbb56f6e12befa07cdc59d26d.png 2x\" data-dominant-color=\"2D2C2C\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-05-10 at 9.08.44 PM<\/span><span class=\"informations\">1136\u00d7630 92.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to store a raw data artifact on s3 which requires MFA",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-store-a-raw-data-artifact-on-s3-which-requires-mfa\/4397",
        "Question_created_time":"2023-05-14T04:15:21.342Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":52,
        "Question_body":"<p>i would like to store my artifacts on s3.  I was looking at:<\/p>\n<p><a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/track-external-files\">https:\/\/docs.wandb.ai\/guides\/artifacts\/track-external-files<\/a><\/p>\n<p>but do not see anything in regards to s3 iam which requires MFA.   Is it possible to store remote artifacts on s3 if the s3 requires MFA? Any help is appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb error by usage of mlflow",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-by-usage-of-mlflow\/4401",
        "Question_created_time":"2023-05-14T19:24:32.896Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":56,
        "Question_body":"<p>I 'm getting the exact same error with this <a href=\"https:\/\/community.wandb.ai\/t\/wandb-error-by-usage-of-mlflow-and-hydra-regarding-protobuf-lib\/3866\/1\">one<\/a> .  I tried to  create a new venv either with conda, venv but, downgrade protobuf but it persists.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Elapsed time per epoch much slower for sweep than for individual runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/elapsed-time-per-epoch-much-slower-for-sweep-than-for-individual-runs\/4061",
        "Question_created_time":"2023-03-15T21:45:58.983Z",
        "Question_answer_count":10,
        "Question_score_count":0,
        "Question_view_count":117,
        "Question_body":"<p>When I run the same model individually as I would in a sweep, the performance is much better in terms of time elapsed per epoch. In one recent test I saw a 3x improvement (10min vs 30min). I am running the bayes sweep, minimizing the val\/loss,  and using hyperband with min_iter = 1. Both jobs run on a single A100 40Gb GPU. I have also included the following line as I am running on SLURM:<br>\nwandb agent --count 1 SWEEP_ID<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cross entropy ranges from 0 to 1?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cross-entropy-ranges-from-0-to-1\/4201",
        "Question_created_time":"2023-04-09T20:10:34.109Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":138,
        "Question_body":"<p><a href=\"https:\/\/wandb.ai\/sauravmaheshkar\/cross-entropy\/reports\/What-Is-Cross-Entropy-Loss-A-Tutorial-With-Code--VmlldzoxMDA5NTMx\">This post states that<\/a> \u2018Cross entropy loss is a metric used to measure how well a classification model in machine learning performs. The loss (or error) is measured as a number between 0 and 1, with 0 being a perfect model. The goal is generally to get your model as close to 0 as possible.\u2019 But as far as I understand, there is no upper bound for cross-entropy loss, as it is nothing but KL divergence differed by some constant.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error in W&B_Prompts_Quickstart notebook",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-in-w-b-prompts-quickstart-notebook\/4411",
        "Question_created_time":"2023-05-16T07:36:59.108Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":48,
        "Question_body":"<p>I have the following error while running <a href=\"http:\/\/wandb.me\/prompts-quickstart\" rel=\"noopener nofollow ugc\">W&amp;B_Prompts_Quickstart notebook<\/a> <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" data-download-href=\"\/uploads\/short-url\/jwFkh0P5adLx7fGnRM3YtxxLn4p.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" alt=\"image\" data-base62-sha1=\"jwFkh0P5adLx7fGnRM3YtxxLn4p\" width=\"690\" height=\"289\" data-dominant-color=\"F4F4F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">774\u00d7325 8.32 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2023-05-16T10:13:37.937Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/tinsae\">@tinsae<\/a> thanks for reporting this issue. There\u2019s a breaking change with newer LangChain version, and the Growth team is working on a fix.<\/p>\n<p>You could run the Prompts Quickstart notebook for now by pinning a previous LangChain version which I just tested and seems to be working fine. Could you please change the installation section as follows:<\/p>\n<pre><code class=\"lang-auto\">!pip install \"wandb&gt;=0.15.2\" -qqq\n!pip install \"langchain==v0.0.158\" openai\n<\/code><\/pre>\n<p>Would this work for you?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to create a copy of wandb plots online as well as offline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-create-a-copy-of-wandb-plots-online-as-well-as-offline\/4172",
        "Question_created_time":"2023-04-03T10:42:42.128Z",
        "Question_answer_count":12,
        "Question_score_count":0,
        "Question_view_count":146,
        "Question_body":"<p>Hi Everyone,<\/p>\n<p>How I can create a copy of a wandb logs? For example, I trained a model for 100 epochs and now I like to try several different configurations on top of it. The wandb should show me the previous logs and new logs on the same figure.<br>\nSuppose I have \u201cbase_experiment\u201d and on top of it, i want to run 4 different experiments. So I will have the following 5 experiments;<\/p>\n<ol start=\"0\">\n<li>base_experiment<\/li>\n<li>base_experiment_followed_by_configuration_1<\/li>\n<li>base_experiment_followed_by_configuration_2<\/li>\n<li>base_experiment_followed_by_configuration_3<\/li>\n<li>base_experiment_followed_by_configuration_4<\/li>\n<\/ol>\n<p>How i can create a copy of base experiment and use it for other 4 experiments?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log stats with different global steps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-stats-with-different-global-steps\/4375",
        "Question_created_time":"2023-05-11T05:56:21.634Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":71,
        "Question_body":"<pre><code class=\"lang-auto\">wandb.log(train_stats, step=train_step)\nwandb.log(test_stats, step=test_step)\n<\/code><\/pre>\n<p>In my code, training and testing happen in parallel. I get training stats at every step, but testing stats are available only once in a while (I don\u2019t pause training to wait for testing results). For instance, I may get testing stats at steps [10, 12, 20, 33].<br>\nThe problem with this is that above commands doesn\u2019t work if <code>test_step<\/code> and <code>train_step<\/code> are not the same. Only the first <code>log<\/code> succeeds, and the second is not logged at all (no error, the program keeps running). If I pass the same step, e.g., <code>wandb.log(test_stats, step=train_step)<\/code> then it works.<\/p>\n<p>Is it possible to log stats with different steps?<\/p>",
        "Question_closed_time":"2023-05-18T17:47:57.050Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/parisi\">@parisi<\/a> ,<\/p>\n<p>You\u2019re welcome! I\u2019m glad to hear that <code>define_metric<\/code> is working well for your use case. Unfortunately, there isn\u2019t a direct method to hide the <code>steps charts<\/code> in the SDK. However, you can drag the steps chart to the hidden panel section of your main\/run workspace. By doing so, any subsequent runs logged will automatically have the steps chart hidden from view. Marking initial inquiry resolved on our end, but please do reach out again anytime we could be of help.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to log a table of media to artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-a-table-of-media-to-artifacts\/4377",
        "Question_created_time":"2023-05-11T08:53:28.624Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":66,
        "Question_body":"<p>I am busy with an audio generation diffusion  project and would like to save and image and an audio file every epoch and track their evolving as artifacts, here is my current code:<\/p>\n<h1>\n<a name=\"log-media-table-1\" class=\"anchor\" href=\"#log-media-table-1\"><\/a>Log media table<\/h1>\n<pre><code>            wandb_table_media = wandb.Table(\n                    columns=['Epoch', 'Step', 'Clean-Images', \n                             'Generated-Mel-Images', 'Generated-Audio'])\n            img_shape = np.reshape(images[0], (1, 256, 256))\n            wandb_table_media.add_data(\n                epoch, \n                global_step, wandb.Image(clean_images[0]),\n                wandb.Image(img_shape),\n                wandb.Audio(normalize(audios[0]), sample_rate=sample_rate))\n            wandb.log({'wandb_table_media': wandb_table_media})\n            \n        # Log media artifact\n        \n            media_artifact = wandb.Artifact(\n                f'media-table-{args.project_name}',\n                type='table',\n                description='media-table'\n                )\n            media_artifact.add(wandb_table_media, \"media-table-sonic-diffusion\")\n            wandb.log_artifact(media_artifact,\n                               aliases=[f'step_{global_step}', f'epoch_{epoch}'])\n<\/code><\/pre>\n<p>It logs the table artifact fine in WANDB\u2026how do i create a table in WANDB to view these images and audio files?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run number of hyperparameter sweep?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-number-of-hyperparameter-sweep\/4419",
        "Question_created_time":"2023-05-17T20:15:39.476Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":49,
        "Question_body":"<p>Hi there,<\/p>\n<p>When running a hyperparameter sweep, is there any option to access the run number of a particularl run, within the train() function?<\/p>\n<p>I have:<\/p>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep=sweep_configuration, project='hyperparam_sweeps_dev')\n\nwandb.agent(sweep_id, function=train, count=8)\n<\/code><\/pre>\n<p>and would like to have a variable inside the train function that corresponds to the run number, which In this case would be from 1-8.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Expressions don't work for bar plots",
        "Question_link":"https:\/\/community.wandb.ai\/t\/expressions-dont-work-for-bar-plots\/4302",
        "Question_created_time":"2023-04-30T21:55:17.692Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":57,
        "Question_body":"<p>I am plotting evaluation accuracies in a bar plot on my dashboard. I would like to subtract the baseline accuracy from these values, so I type the expression<\/p>\n<p>${summary:final_val\/acc} - 0.726<\/p>\n<p>(where 0.726 is the baseline accuracy) into the expressions box, but nothing changes.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding media to a finished run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-media-to-a-finished-run\/4420",
        "Question_created_time":"2023-05-18T01:40:58.929Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":32,
        "Question_body":"<p>Some metrics I want to add to evaluate the performance of each trained ML model are very expensive to calculate, and need to be calculated after execution of the training script. But for the purposes of keeping all my plots together, it\u2019d be great to have these metrics added to the finished run, post hoc. Is it possible to do something like re-initialise a run in a seperate script, to add some additional media to the dashboard?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Artifacts version",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifacts-version\/4379",
        "Question_created_time":"2023-05-11T14:29:47.945Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":55,
        "Question_body":"<p>Is there a way to either 1) set a max to the number of versions an artifact can have (if more are uploaded then oldest get deleted), or 2) keep only the latest version?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Filter just one plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/filter-just-one-plot\/4390",
        "Question_created_time":"2023-05-12T22:06:02.225Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":45,
        "Question_body":"<p>I am doing a big sweep over my hyperparameters. I can plot the same statistic (accuracy) in multiple plots, grouping each plot by a different hyperparameter. Then, by looking at the plots I can see which hyperparameters perform best.<br>\nAt this point, I need to plot the accuracy in one plot filtering according to the best hyperparameters. I can use the filter button above the runs, but that filters ALL plots. I want to filter only one plot.<br>\nHow can I do that?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.finish() takes too long to finish",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-finish-takes-too-long-to-finish\/4415",
        "Question_created_time":"2023-05-17T01:44:44.091Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":55,
        "Question_body":"<p>I was working with wandb to track my experiment.<br>\nThe experiment run on the GKE cluster by using MLFlow Projects.<br>\nBut, from several weeks ago (I suggest it\u2019s around the release of wandb 0.15.0), I found that my training job doesn\u2019t exit just after it finished the traininig job. It finished almost after 24 hours.<br>\nI didn\u2019t mkae breaking change in my code. So I\u2019m suspecting whether there is discrepency on this situation.<br>\nBecause of that reason, I started to fix version of wandb to be 0.14.2 rather than 0.15.0.<br>\nCan I get the help?<br>\nHere is the last log from the running process.<\/p>\n<hr>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success).<br>\nwandb: Network error (ReadTimeout), entering retry loop.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"BUG: Line-Plot, X-Axis Settings not working in report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-line-plot-x-axis-settings-not-working-in-report\/4417",
        "Question_created_time":"2023-05-17T07:18:42.591Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":30,
        "Question_body":"<p>If one combines two Line-Plots in one report, data points vanish if one sets the X-Axis Max to something in the range of existing data points. For example, WandB crops away a big portion of the blue line if setting the X-Max to 6M but it clearly has more than 6M (see screenshots).  What\u2019s happening here?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/9\/98dc8098b54028cebc832276757f22756b6f8c89.jpeg\" data-download-href=\"\/uploads\/short-url\/lOgZYlWwsqAJjHyMl3XUEBGawm5.jpeg?dl=1\" title=\"Screenshot 2023-05-17 at 09.26.32\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/98dc8098b54028cebc832276757f22756b6f8c89_2_604x499.jpeg\" alt=\"Screenshot 2023-05-17 at 09.26.32\" data-base62-sha1=\"lOgZYlWwsqAJjHyMl3XUEBGawm5\" width=\"604\" height=\"499\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/98dc8098b54028cebc832276757f22756b6f8c89_2_604x499.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/98dc8098b54028cebc832276757f22756b6f8c89_2_906x748.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/9\/98dc8098b54028cebc832276757f22756b6f8c89_2_1208x998.jpeg 2x\" data-dominant-color=\"F5F5F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-05-17 at 09.26.32<\/span><span class=\"informations\">1920\u00d71588 112 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to log to multiple runs simultaneously",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-log-to-multiple-runs-simultaneously\/4387",
        "Question_created_time":"2023-05-12T14:01:35.935Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":70,
        "Question_body":"<p>I\u2019d like to log to multiple separate runs (experiments) from a single script, but I\u2019m not sure if it\u2019s possible to do this so I\u2019m asking for help here.<\/p>\n<p>The issue I\u2019m facing is that my code uses a relatively small model, but is bottlenecked by data loading so GPU utilization is quite low. Thus, the goal is to update multiple individual models per batch, which would help \u2018hide\u2019 the data loading time by spending more time with GPU compute.<br>\nThen for each model, I\u2019d have a corresponding \u2018run\u2019 object in WandB:<\/p>\n<pre><code class=\"lang-python\">for x, labels in dataloader:\n    loss1 = model1(x, labels)\n    loss2 = model2(x, labels)\n    ...\n    lossN = modelN(x, labels)\n    run1.log({'loss': loss1.item()})\n    run2.log({'loss': loss2.item()})\n    ....\n    runN.log({'loss': lossN.item()})\n<\/code><\/pre>\n<p>The issue is that the traditional <code>wandb.log()<\/code> seems like a call to some global run instance and can\u2019t be split into multiple individual instances.<\/p>\n<p>Is it possible to achieve this with WandB? Perhaps using <code>wandb.Api()<\/code> is a starting point, but I\u2019m not sure if it\u2019s feasible.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to speed up batch delete of files & artifacts?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-speed-up-batch-delete-of-files-artifacts\/4251",
        "Question_created_time":"2023-04-21T03:41:22.710Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":166,
        "Question_body":"<p>I have been concerned with trying to stay within the 100GB limit on files and artifact storage imposed by Wandb, so I have the idea to delete files &amp; artifacts on old runs.<\/p>\n<p>However, I do not want to delete all files on those runs! It is definitely useful to be able to see the progression of generated files over time. I don\u2019t need to see all 50,000 or so logged steps on each run, but I\u2019ll just keep 100 of them evenly spaced in time. so I programmed a script to do that by indexing all my files on Wandb using the Python API, grouping them, sorting them, and selecting files to delete.<\/p>\n<p>My issue comes with how slow the current API seems to be to delete files &amp; artifacts: Using <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/file#delete\">File.delete<\/a>, it takes around 2s per file. With hundreds of runs and tens of thousands of files per run, I am then looking at weeks of time needed to delete the files I need to delete.<\/p>\n<p>I then tried to refactor my code into parallel workers, thinking I could increase that speed several fold, but I quickly ran into the 200 call\/minute <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/limits#rate-limits\">rate limit<\/a>. It even started to affect my ongoing runs.<\/p>\n<p>Is there any better way I could prune the files &amp; artifacts so that I could have the process complete faster?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Default grouping range",
        "Question_link":"https:\/\/community.wandb.ai\/t\/default-grouping-range\/4381",
        "Question_created_time":"2023-05-11T20:46:14.151Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":51,
        "Question_body":"<p>When I group runs using the \u201cgroup\u201d field, all my plots are grouped nicely. However, the default range for all is min\/max. I need to use std dev, and the only way to do that is to manually change it for every plot. This is very annoying. Isn\u2019t there a way to select std dev as default grouping range?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Average multiple runs over one parameter",
        "Question_link":"https:\/\/community.wandb.ai\/t\/average-multiple-runs-over-one-parameter\/4371",
        "Question_created_time":"2023-05-10T19:29:05.478Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":49,
        "Question_body":"<p>I am doing a sweep over multiple parameters. For every configuration, I also have a seed to control randomness.<br>\nFor instance, let\u2019s say I am sweeping over learning rate in [0.1, 0.01] and batch size in [16, 32]. This will give me 4 runs, and for each I will have two runs with seed 1 and 2, treated as hyperparameter, for a total of 8 runs.<br>\nI\u2019d like to average ALL plots over the 2 seeds. So, instead of having 8 curves per plot I\u2019ll have only 4.<br>\nI can do this manually by grouping over learning rate and batch size. However, in practice, I have way more hyperparameters than 2, and I don\u2019t want to manually add all of them one by one to the group.<\/p>\n<p>Is there a way to, basically, \u201cgroup over all but one\u201d hyperparameter?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to plot config value on x-axis versus metric on y-axis in a report?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-plot-config-value-on-x-axis-versus-metric-on-y-axis-in-a-report\/4317",
        "Question_created_time":"2023-05-02T07:32:22.733Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":68,
        "Question_body":"<p>I have a multiple runs with a varying hyperparameter (for simplicities sake: number of training samples).<\/p>\n<p>I would like to plot the mean and standard deviation of the accuracy after finished training in relationship to the number of training samples used.<\/p>\n<p>y=accuracy<br>\n^<br>\n| ----------   x<br>\n|  ------  x<br>\n| --x<br>\n_____________  x-axis = training samples from config<\/p>\n<p>Currently I only see wandb reports being able to plot metrics against their time\/step stamp.<\/p>\n<p>Weave is a possibility but even afters years of matplotlib use I haven\u2019t figured out how to use weave as I can\u2019t find a understandable documentation.<\/p>\n<p>Exporting the data to a Jupyter notebook is also a possibility which I have done, but it sort of undermines the purpose of wandb for quick run comparison and visualization as it includes laborious fiddling with matplotlib.<\/p>\n<p>Any help on how to use config values on the x-axis of plots is greatly appreciated. <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep UI icon bug",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-ui-icon-bug\/4403",
        "Question_created_time":"2023-05-15T13:06:59.614Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":40,
        "Question_body":"<p>Hi the size of icons in the sweep pannel has a bug.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/29950955f81eb70062033f11614523153afcb8ab.png\" data-download-href=\"\/uploads\/short-url\/5VQSTFb976mRm4eJNcWLwiYv1nd.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/29950955f81eb70062033f11614523153afcb8ab_2_329x500.png\" alt=\"image\" data-base62-sha1=\"5VQSTFb976mRm4eJNcWLwiYv1nd\" width=\"329\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/29950955f81eb70062033f11614523153afcb8ab_2_329x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/29950955f81eb70062033f11614523153afcb8ab_2_493x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/29950955f81eb70062033f11614523153afcb8ab_2_658x1000.png 2x\" data-dominant-color=\"F6F7F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1106\u00d71680 133 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resuming training",
        "Question_link":"https:\/\/community.wandb.ai\/t\/resuming-training\/4360",
        "Question_created_time":"2023-05-08T15:54:11.086Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":55,
        "Question_body":"<p>Hey everyone, Im new to WandB and would love some advice.<\/p>\n<p>This is my current setup:<\/p>\n<ol>\n<li>Run the model first time and save the model every epoch (based on a variable) using the following:<\/li>\n<\/ol>\n<h1>\n<a name=\"log-wandb-artifact-1\" class=\"anchor\" href=\"#log-wandb-artifact-1\"><\/a>log wandb artifact<\/h1>\n<pre><code>            model_artifact = wandb.Artifact(\n                f'{args.project_name}',\n                type='model',\n                description='sonic-diffusion-model-256'\n                )\n        \n            model_artifact.add_dir(args.output_dir)\n            wandb.log_artifact(\n                model_artifact,\n                aliases=[f'step_{global_step}', f'epoch_{epoch}']\n<\/code><\/pre>\n<ol start=\"2\">\n<li>i have resume as \u2018True\u2019 in the configs<\/li>\n<li>I then load the last saved model (i am using diffusion from hugging face):<\/li>\n<\/ol>\n<p>if wandb.run.resumed:<br>\nprint(\u201cResuming run\u2026\u201d)<br>\nartifact_name = args.model_resume_name<br>\nartifact = wandb.use_artifact(artifact_name)<\/p>\n<pre><code>    # Download the model file(s) and return the path to the downloaded artifact\n    artifact_dir = artifact.download()\n\n    pipeline = AudioDiffusionPipeline.from_pretrained(artifact_dir)\n\n    mel = pipeline.mel\n    model = pipeline.unet\n<\/code><\/pre>\n<p>How do i continue training from the last epoch i left off from? Is 3) above even necessary? does the resume load the optimizer settings, learning rate at specific epoch?<\/p>\n<p>The docs are not very clear.<\/p>\n<p>I hope i am articulating myself properly.<\/p>\n<p>Mark<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Missing image panels in UI, even though media appears under files",
        "Question_link":"https:\/\/community.wandb.ai\/t\/missing-image-panels-in-ui-even-though-media-appears-under-files\/4351",
        "Question_created_time":"2023-05-06T23:10:17.784Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":53,
        "Question_body":"<p>Dear wandb community,<\/p>\n<p>I am facing some issues seeing logged images in the UI. I log my images under <code>pairs\/train<\/code>, <code>pairs\/Y18-jj-long<\/code>, <code>pairs\/Y18-jj-long-augmented<\/code>, and <code>pairs\/Y18-jj-short<\/code>. However, not all panels (if any) would sometimes appear. I can find the media logged locally as well as in the project under <code>Files &gt;  root \/ media \/ images \/ pairs<\/code>.  The code I use for logging these images goes as <code>wandb_image = wandb.Image(image); wandb.log({f'pairs\/{prefix}': wandb_image}, step=it)<\/code>, where <code>image<\/code> is an <code>np.uint8<\/code> numpy array of shape <code>(H, W, 3)<\/code> with values in [0, 255]. I use wandb 0.15.2. The height and width of images vary across steps, one image was for example (3360, 4265, 3). These are example runs demonstrating the issue (part of a private project):<\/p>\n<ul>\n<li>\n<a href=\"https:\/\/wandb.ai\/user72\/train-vos\/runs\/2igdf0cg?workspace=user-user72\" class=\"inline-onebox\">Weights &amp; Biases<\/a> - no image panels<\/li>\n<li>\n<a href=\"https:\/\/wandb.ai\/user72\/train-vos\/runs\/m4j5ely0?workspace=user-user72\" class=\"inline-onebox\">Weights &amp; Biases<\/a> - only the image panel <code>pairs\/Y18-jj-long<\/code> appears, others are missing<\/li>\n<\/ul>\n<p>I tried clearing the workspace, logging to a different project, and logging to a different team\/entity. I am facing this issue of images not appearing in a panel since yesterday. Until then I only had one \u201cpairs\/train\u201d images logged and there were no major problems. Now I want to have 4 image panels under \u201cpairs\/\u2026\u201d. If relevant, wandb crashed a few times yesterday, asking me to fill a crash report for feedback, not sure if this is related. For more code context, the relevant part of the codebase is logged under \u201cartifacts &gt; code\u201d.<\/p>\n<p>Any ideas on why the images do not appear in a panel in the UI?<br>\nShould I be aware of certain limits of the UI or the amount of data logged or image resolution?<\/p>\n<p>Best regards,<br>\nFrano<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"\"rate limit exceeded\" blocking access to wandb dashboard",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rate-limit-exceeded-blocking-access-to-wandb-dashboard\/4292",
        "Question_created_time":"2023-04-28T03:20:58.589Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":69,
        "Question_body":"<p>Hi,<\/p>\n<p>Similar to other posts, I have accidentally exceeded the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/limits#rate-limits\">wandb rate limitations<\/a>.<\/p>\n<p>I am completely unable to view my wandb console, even after stopping the processes that caused the rate limit to trigger, and waiting several days:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/be66cc18a480fc50288337f35a815cb86e9de8d2.png\" data-download-href=\"\/uploads\/short-url\/ramXBVzI8tCgfMITlbAXRrwYf4u.png?dl=1\" title=\"wandb rate limit exceeded\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/be66cc18a480fc50288337f35a815cb86e9de8d2_2_690x270.png\" alt=\"wandb rate limit exceeded\" data-base62-sha1=\"ramXBVzI8tCgfMITlbAXRrwYf4u\" width=\"690\" height=\"270\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/be66cc18a480fc50288337f35a815cb86e9de8d2_2_690x270.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/be66cc18a480fc50288337f35a815cb86e9de8d2_2_1035x405.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/be66cc18a480fc50288337f35a815cb86e9de8d2_2_1380x540.png 2x\" data-dominant-color=\"FEFCFD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb rate limit exceeded<\/span><span class=\"informations\">1613\u00d7633 9.66 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>It seems entirely appropriate to me for wandb to enforce a rate limit, but I don\u2019t think that rate limit should apply to the web interface, for an extended time, especially after stopping the excessive requests.<\/p>\n<p>What can I do to resolve this, and how should I avoid triggering it in the future?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb sync confusing personal project for team project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sync-confusing-personal-project-for-team-project\/4315",
        "Question_created_time":"2023-05-01T16:04:18.371Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":103,
        "Question_body":"<p>I have a project \u201cfoo\u201d on my personal wandb account (entity \u201cuser\u201d). However, I am also a member of a team (\u201cteam\u201d). When I try to sync an offline run using <code>wandb sync path\/to\/foo\/run<\/code>, I want it to be saved in project \u201cfoo\u201d on my personal account. However, wandb creates a new project \u201cfoo\u201d that is owned by \u201cteam\u201d.<\/p>\n<p>Is there any way I can fix this? Do I need to change the way I\u2019m logged in to my wandb account? wandb says that I am logged in as <code>user (team)<\/code>, but I\u2019m not sure how to change that.<\/p>",
        "Question_closed_time":"2023-05-02T13:35:36.819Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/adamoyoung\">@adamoyoung<\/a> thanks for reporting this issue. Could you please provide the <code>--entity<\/code> and <code>--project<\/code> arguments as follows:<br>\n<code>wandb sync -e personal -p foo path\/to\/foo\/run<\/code><\/p>\n<p>Would this work for you? There\u2019s a <code>Project Defaults<\/code> section in your <a href=\"https:\/\/wandb.ai\/settings\">personal settings page<\/a> where this in your case seems to be configured for your team entity. You may change that if you wanted the default to be your personal account.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How do I share a private project with another user?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-share-a-private-project-with-another-user\/4263",
        "Question_created_time":"2023-04-23T14:36:46.285Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":212,
        "Question_body":"<p>I have a private project that is under my account. How do I share it with another person so that the other person can read everything in the project, upload results\/experiments to that project, and basically have the same function as myself? Is it possible to do this while making the project still private among the two of us?<\/p>\n<p>For example this link has something similar but the person asked to make it public. I am hoping to keep it private among the two of us.<\/p><aside class=\"quote\" data-post=\"1\" data-topic=\"1873\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/ecc23a\/40.png\" class=\"avatar\">\n    <a href=\"https:\/\/community.wandb.ai\/t\/get-a-link-to-share-project\/1873\">Get a link to share project<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/w-b-support\/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at support@wandb.com\">W&amp;B Help<\/span><\/a>\n  <\/div>\n  <blockquote>\n    I have an existing project. I want to be able to make it public and share it to someone so that they can take a look at the graphs\n  <\/blockquote>\n<\/aside>\n\n<p>If this is not possible, it seems like a wandb \u201cteam\u201d might be doable. Is there a way to transfer my private project to the team so that we don\u2019t lose information from my earlier runs?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hyperparameter sweep within some subdomain of possible values",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hyperparameter-sweep-within-some-subdomain-of-possible-values\/4008",
        "Question_created_time":"2023-03-06T17:43:15.063Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":78,
        "Question_body":"<p>Hi there! I\u2019m looking to run a hyerparameter sweep across a wide range of resnet configurations. I would like to explore two relevant paramters - the number of resnet blocks, and the number of filters in each resnet block. I would like the option for both of these hyperparameters to be large, but not at the same time! As this model will just take too long to train, and so my sweep time will be dominated by just one or two modules. So in the 2D domain of n_resnet_blocks and n_conv_filters, I want to explore some subdomain of this. Is there some way this could be done within the sweep configuration? An obvious approach would be just to run consecutive sweeps, capping each dimension to some sensible value while exploring the other one, but it\u2019d just be neater if the space could be explored within a single sweep. So interested to hear any ideas!<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"A small UI design issue, which is uncomfortable to my eyes",
        "Question_link":"https:\/\/community.wandb.ai\/t\/a-small-ui-design-issue-which-is-uncomfortable-to-my-eyes\/4348",
        "Question_created_time":"2023-05-06T20:50:33.483Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":33,
        "Question_body":"<p>Let me first say that I really like the <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> and have &gt;900 runs logged into its platform. my small issue is that  I use wandb in Night mode. However, when I want to delete a run (screenshot attached), the entire screen turns white. This sudden transition is painful to my eyes. It would be great if this could as well be in black.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ac461cf4c2ffcf0921999390ec87b7a73867bb9d.jpeg\" data-download-href=\"\/uploads\/short-url\/oA0laXOG86Pc97aBsxsFFySDV4p.jpeg?dl=1\" title=\"Screenshot 2023-05-06 at 22.48.15\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_690x393.jpeg\" alt=\"Screenshot 2023-05-06 at 22.48.15\" data-base62-sha1=\"oA0laXOG86Pc97aBsxsFFySDV4p\" width=\"690\" height=\"393\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_690x393.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_1035x589.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_1380x786.jpeg 2x\" data-dominant-color=\"D6D6D6\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-05-06 at 22.48.15<\/span><span class=\"informations\">2652\u00d71514 169 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"100% offline sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/100-offline-sweep\/3482",
        "Question_created_time":"2022-12-01T10:27:07.034Z",
        "Question_answer_count":14,
        "Question_score_count":8,
        "Question_view_count":924,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using wandb sweeps for bayesian optimisation . However I recently got access to new powerfull gpus which are not connected to internet. So i\u2019m trying to use the offline mode of wandb that seems to works fine with regular runs but doesn\u2019t with sweeps. Indeed even in offline mode a connexion seems to still be required in order to create the sweep and to synchronise the data after a run (for the optimisation process).<\/p>\n<p>Is there any way  to run a 100% offline sweep and to synchronise it manually at the end off  each run or of the whole sweep ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Saving error stopping sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/saving-error-stopping-sweep\/4328",
        "Question_created_time":"2023-05-03T08:36:06.247Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":77,
        "Question_body":"<p>Hi, I am trying to run the sweep for tensorflow but it keeps stopping with a broken pipe error. When I checked the logs, I get this traceback error message.<\/p>\n<p>Traceback (most recent call last):<br>\nFile \u201c\/nobackup\/eeerog\/.\/general_training_model_5classes.py\u201d, line 713, in <br>\nwandb.agent(sweep_id = sweep_id, function=train(class_weightsh, class_weightsv, class_weightsc, train_datagen, valid_datagen, nom_classes1 = 5, nom_classes2 = 5))<br>\nFile \u201c\/nobackup\/eeerog\/.\/general_training_model_5classes.py\u201d, line 708, in train<br>\nmodel.fit(train_datagen,epochs=3,steps_per_epoch=860, callbacks = [early_stopping,reduce_lr, model_checkpoint_callback, WandbCallback()], validation_data=valid_datagen, validation_steps = 10)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/wandb\/integration\/keras\/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/wandb\/integration\/keras\/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/wandb\/integration\/keras\/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/keras\/engine\/training.py\u201d, line 1145, in fit<br>\ncallbacks.on_epoch_end(epoch, epoch_logs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/keras\/callbacks.py\u201d, line 428, in on_epoch_end<br>\ncallback.on_epoch_end(epoch, logs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/keras\/callbacks.py\u201d, line 1344, in on_epoch_end<br>\nself._save_model(epoch=epoch, logs=logs)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/keras\/callbacks.py\u201d, line 1393, in _save_model<br>\nself.model.save_weights(<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/keras\/engine\/training.py\u201d, line 2124, in save_weights<br>\nself._trackable_saver.save(filepath, session=session, options=options)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/training\/tracking\/util.py\u201d, line 1215, in save<br>\nfile_io.recursive_create_dir(os.path.dirname(file_prefix))<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/lib\/io\/file_io.py\u201d, line 468, in recursive_create_dir<br>\nrecursive_create_dir_v2(dirname)<br>\nFile \u201c\/home\/home02\/eeerog\/.conda\/envs\/deep_learning\/lib\/python3.9\/site-packages\/tensorflow\/python\/lib\/io\/file_io.py\u201d, line 483, in recursive_create_dir_v2<br>\n_pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))<br>\ntensorflow.python.framework.errors_impl.PermissionDeniedError: \/home\/eeerog; Permission denied<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log scale axis for bar plots?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-scale-axis-for-bar-plots\/4331",
        "Question_created_time":"2023-05-03T14:41:44.371Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":36,
        "Question_body":"<p>Can I set my bar plot axis to log scale? I looked over the <a href=\"https:\/\/docs.wandb.ai\/guides\/app\/features\/panels\/bar-plot\">documentation<\/a> but didn\u2019t see this mentioned.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging list of wandb.Plotly not working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-list-of-wandb-plotly-not-working\/4044",
        "Question_created_time":"2023-03-10T16:48:15.888Z",
        "Question_answer_count":16,
        "Question_score_count":1,
        "Question_view_count":377,
        "Question_body":"<p>Hi, I am trying to log multiple connected plots similar to using images, as <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/log#image-from-numpy\">shown in the documentation<\/a>:<\/p>\n<pre><code class=\"lang-auto\">examples = []\nfor i in range(3):\n pixels = np.random.randint(low=0, high=256, size=(100, 100, 3))\n image = wandb.Image(pixels, caption=f\"random field {i}\")\n examples.append(image)\nwandb.log({\"examples\": examples})\n<\/code><\/pre>\n<p>Trying this with <code>wandb.Plotly<\/code> instead of <code>wandb.Image<\/code>:<\/p>\n<pre><code class=\"lang-auto\">plots = []\nfor i in range(3):\n fig = create_plotly_plot(index=i)\n plot = wandb.Plotly(fig)\n plots.append(plot)\nwandb.log({\"examples\": plots})\n<\/code><\/pre>\n<p>results in an error in the UI:<\/p>\n<blockquote>\n<p>Selected runs are not logging media for the key <strong>examples<\/strong>, but instead are logging values of type <strong>list<\/strong>.<\/p>\n<p>If <strong>examples<\/strong> is never supposed to be a media type, please delete this panel and create the proper panel type manually.<\/p>\n<\/blockquote>\n<p>How can I log a list of plots similar to a list of images?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sync offline Run in a other machine",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sync-offline-run-in-a-other-machine\/4218",
        "Question_created_time":"2023-04-14T07:46:55.797Z",
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":158,
        "Question_body":"<p>Hello, I ran a Unet on an other machine whithout internet and retrieved the offline Run. I am trying to sync it with wandb but, there are en issu that say:<\/p>\n<p>wandb: ERROR Uploading artifact file failed. Artifact won\u2019t be committed.<br>\nwandb: ERROR Error uploading [Path of the artefact on the other machine] : FileNotFoundError, [Errno 2] No such file or directory: [Path of the artefact on the other machine]<\/p>\n<p>When I searched for a solution, I couldn\u2019t find anything that realy helped and all the last topics had been finished whithout solution or answer from person who questions.<\/p>\n<p>I tryed this:<\/p>\n<ul>\n<li>\n<p>!wandb sync --project [the name] --entity [the name] [the path]<\/p>\n<\/li>\n<li>\n<p>!wandb sync  [the path]<\/p>\n<\/li>\n<li>\n<p>wandbId=wandb.util.generate_id()<br>\n!wandb sync [the path] --id wandbId<\/p>\n<\/li>\n<\/ul>\n<p>Thank you for your time, I hope you can help me<\/p>\n<p>Have a good day<\/p>",
        "Question_closed_time":"2023-04-24T11:57:29.098Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/seirihiri\">@seirihiri<\/a>, thanks for the explanation! You can set the artifacts folder with the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/environment-variables#optional-environment-variables\">env variable<\/a> <code>WANDB_CACHE_DIR <\/code> and point that to the folder you want. Regarding the artifacts created when running offline, it depends if you\u2019re creating them or not (they can be created not only when logging an <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts#how-it-works\">artifact<\/a> but also when logging tables for example). Let me know if this helps!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Run.finish() hangs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-finish-hangs\/4069",
        "Question_created_time":"2023-03-16T15:15:12.586Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":159,
        "Question_body":"<p>I\u2019m using wandb version 0.14.0 in an ipynb file using vscode as part of assignment 1 of the \u2018Effective MLOps\u2019 course (logging dataset as artifact and visualising data with a table)<\/p>\n<p>When I execute <code>run.finish()<\/code> at the end of my file the cell hangs indefinitely with the message<\/p>\n<pre><code class=\"lang-console\">Waiting for W&amp;B process to finish... (success).\n<\/code><\/pre>",
        "Question_closed_time":"2023-03-16T16:10:24.296Z",
        "Answer_body":"<p>How much data are you logging? It might still be uploading in the background. You can check one of the <code>debug.log<\/code> or <code>debug-internal.log<\/code> files in the <code>wandb<\/code> folder to see if there is any upload activity happening<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Broken pipe error while wandb.init() files are not sync",
        "Question_link":"https:\/\/community.wandb.ai\/t\/broken-pipe-error-while-wandb-init-files-are-not-sync\/4334",
        "Question_created_time":"2023-05-03T17:35:35.271Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":124,
        "Question_body":"<p>Traceback (most recent call last):<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 1150, in init<br>\nrun = wi.init()<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 601, in init<br>\nmanager._inform_init(settings=self.settings, run_id=self.settings.run_id)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_manager.py\u201d, line 208, in _inform_init<br>\nsvc_iface._svc_inform_init(settings=settings, run_id=run_id)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/service\/service_sock.py\u201d, line 38, in _svc_inform_init<br>\nself._sock_client.send(inform_init=inform_init)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 211, in send<br>\nself.send_server_request(server_req)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 155, in send_server_request<br>\nself._send_message(msg)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 152, in _send_message<br>\nself._sendall_with_error_handle(header + data)<br>\nFile \u201c\/home\/aakash\/anaconda3\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 130, in _sendall_with_error_handle<br>\nsent = self._sock.send(data)<br>\nI am using Jupiter notebook on  Ubuntu 20.04 Linux system.<br>\nwandb 23.0.1<br>\nprotobuf-3.20.3 tensorboardx-2.6<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Runs never terminating in Dashboard even when requested to stop in UI with wandb-service killed",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runs-never-terminating-in-dashboard-even-when-requested-to-stop-in-ui-with-wandb-service-killed\/4271",
        "Question_created_time":"2023-04-24T14:14:07.254Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":54,
        "Question_body":"<p>I\u2019ve been trying to stop my runs for a few days now with no luck. Every new experiment I track using wandb shows a state <em>running<\/em> , and when the experiment is completed, it stays in that state even when requested to stop within the runs overview or the project runs sidebar.<\/p>\n<p>The ones that I have requested to stop manually keep showing the <em>green dot<\/em> to indicate that the run is still active but shows state <em>stopping<\/em> (some of these have been in state <em>stopping<\/em> for more than three days). This occurs in all my projects and all runs. I\u2019ve tested with a new project, same issue.<\/p>\n<p>Any help would be greatly appreciated!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to handle resuming and changing config file",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-handle-resuming-and-changing-config-file\/4301",
        "Question_created_time":"2023-04-30T11:55:18.818Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":50,
        "Question_body":"<p>I have the following scenario:<\/p>\n<p>Let\u2019s say I have started a run with a specific config, e.g. at the beginning of my run I would do something like this<\/p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 2000}\nwandb.init(config = config, ...)\n<\/code><\/pre>\n<p>Now after some time, I realize I want to change something about my model. For example, here I want to sample more often. I would then stop the run and rerun my script with the correct resume ID<\/p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 1000}\nwandb.init(config = config, id = OLD_ID, resume = \"allow\",  ...)\n<\/code><\/pre>\n<p>I think the behaviour wandb has, is to then have the config be changed to the second config online. Is the first config just overwritten or can it still be seen somewhere?<\/p>\n<p>In my more concrete usecase, I might want to change more big things. For example: I have trained with one dataloader for some time, then wrote a more efficient dataloader and would like to switch.<br>\nIdeally I would want both of the information, the old and the new config to be seen. Is there a way to do this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I develop my writing skills during IT training?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-develop-my-writing-skills-during-it-training\/4326",
        "Question_created_time":"2023-05-03T07:25:22.099Z",
        "Question_answer_count":0,
        "Question_score_count":0,
        "Question_view_count":54,
        "Question_body":"<h5>\n<a name=\"encouraging-your-forming-skills-during-it-planning-can-be-trying-but-there-are-a-couple-of-frameworks-that-you-can-use-to-additionally-foster-your-capacities-to-make-1\" class=\"anchor\" href=\"#encouraging-your-forming-skills-during-it-planning-can-be-trying-but-there-are-a-couple-of-frameworks-that-you-can-use-to-additionally-foster-your-capacities-to-make-1\"><\/a>Encouraging your forming skills during IT planning can be trying, but there are a couple of frameworks that you can use to additionally foster your capacities to make.<\/h5>\n<p>Encouraging your forming skills during IT planning can be trying, but there are a couple of frameworks that you can use to additionally foster your capacities to make. Coming up next are two or three hints that may be valuable: <a href=\"https:\/\/www.sevenmentor.com\/\" rel=\"noopener nofollow ugc\">Best Training Institute in Pune<\/a><\/p>\n<p>Scrutinize comprehensively: Examining generally can open you to different forming styles and help you with understanding how to structure and smooth your considerations. Endeavor to scrutinize different classes, including particular structure, academic papers, online diaries, and reports.<\/p>\n<p><strong>Practice regularly:<\/strong><\/p>\n<p>Creating reliably can help you with chipping away at your capacities, so endeavor to cut out a valuable open door to reliably make. You can start by keeping a journal or forming short pieces on different focuses.<\/p>\n<p><strong>Search for input:<\/strong><\/p>\n<p>Input is central for additional fostering your creating skills, so contemplate conferring your work to others and mentioning helpful investigation. You can moreover use online gadgets like Grammarly or Hemingway to get input on your creation.<\/p>\n<p><strong>Acquire from trained professionals:<\/strong><\/p>\n<p>Look for creating guides and informative activities that are appropriate to your field. You can moreover go to studios or courses on specific arrangement or business forming.<\/p>\n<p><strong>Use an unquestionable and brief creating style:<\/strong><\/p>\n<p>In specific creation, it is crucial to use a sensible and reduced making style. Make an effort not to use language or unnecessarily obfuscated language that can bewilder your perusers. Use list things and subheadings to isolate your substance and simplify it to examine.<\/p>\n<p><strong>Change and update:<\/strong><\/p>\n<p>Changing and rethinking your work is a basic piece of the innovative cycle. Whenever you have created your most vital draft, carve out a time to rethink it and guarantee that it is proficient, coherent, and bungle free.<\/p>\n<p>By following these techniques, you can additionally foster your abilities to create during IT getting ready and produce content that is clear, compact, and securing. Remember, cautious discipline achieves promising outcomes, so the more you make, the better you will transform into. Good luck!<\/p>\n<p>Address- <a href=\"https:\/\/goo.gl\/maps\/QBF6MJVEAtejg9Pk6\" rel=\"noopener nofollow ugc\">A Wing, 5th Floor, Office No 119, Shreenath Plaza, Dnyaneshwar Paduka Chowk, Pune, Maharashtra 411005<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"SageMaker Processing jobs have a less informative config than Training jobs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sagemaker-processing-jobs-have-a-less-informative-config-than-training-jobs\/4307",
        "Question_created_time":"2023-05-01T13:43:27.614Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":20,
        "Question_body":"<p>Hi all,<\/p>\n<p>SageMaker integrates fairly well with wandb through <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/sagemaker\" class=\"inline-onebox\">SageMaker | Weights &amp; Biases Documentation<\/a>. However, whereas training jobs automatically add all arguments (i.e. \u201chyperparameters\u201d in an Estimator <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/estimators.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Estimators \u2014 sagemaker 2.151.0 documentation<\/a>) and some extra information (such as the sagemaker_training_job_name, sagemaker_region) to the wandb config, processing jobs do not. I could of course manually add these to my processing job wandb runs, but would rather have it handled through wandb seamless API.<\/p>\n<p>Is there an intention to close this gap?<\/p>\n<p>PS this post was flagged as \u2018spam\u2019 because it is considered an \u2018advertisement\u2019. Please let me know why. How can I advertise something when it is not even working? Furthermore, I am only providing relevant facts, I am running into a (minor) limitation, and there is no customer service.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to link artifacts programatically to the model registry (a \"collection\")",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-link-artifacts-programatically-to-the-model-registry-a-collection\/4306",
        "Question_created_time":"2023-05-01T13:29:38.571Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":36,
        "Question_body":"<p>Hi all,<\/p>\n<p>I am training a model in a SageMaker pipeline. The pipeline consists of a training step (a training job) and an evaluation step (a processing job). I have integrated both these jobs into run groups for each run of the pipeline. The flow is as follows:<\/p>\n<ol>\n<li>In the training step, the model artefacts with the best performance on the validation set are optionally logged as an Artifact to wandb. This works as expected. There are two Artifacts.<\/li>\n<li>In the evaluation step, the model artefact are loaded via s3 (not via wandb). In case the test performance is sufficient according to some criteria, the model artefacts are to be logged as Artifacts again to wandb for the evaluation run and afterwards these Artifacts are linked to the model registry.<\/li>\n<\/ol>\n<p>Step 2 fails. I have attempted the following:<\/p>\n<ol>\n<li>Use the initiliased wandb run to call link_artifact (<a href=\"https:\/\/docs.wandb.ai\/ref\/python\/run#link_artifact\" class=\"inline-onebox\">Run | Weights &amp; Biases Documentation<\/a>). This worked twice once for one of the models (except for the fact that created a new Model with the same name in the model registry). For the other model nothing is registered.<\/li>\n<li>Use the artifact directly to call link (<a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/artifact#link\" class=\"inline-onebox\">Artifact | Weights &amp; Biases Documentation<\/a>). This has not been implemented\u2026<\/li>\n<\/ol>\n<p>Any support is appreciated. This seems to me to be basic and core functionality.<\/p>\n<p>PS this post was flagged as \u2018spam\u2019 because it is considered an \u2018advertisement\u2019. Please let me know why. How can I advertise something when it is not even working? Furthermore, I am only providing relevant facts, I am running into a serious limitation, there is no clear customer service and only very few (basic and superficial) examples exist.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tensorboard tab not displaying",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorboard-tab-not-displaying\/4313",
        "Question_created_time":"2023-05-01T14:12:23.137Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":58,
        "Question_body":"<p>Hi all,<\/p>\n<p>I would like to display my TensorBoard (TB) tab for a run through the integration outlined in the wandb docs for TensorBoard.<\/p>\n<p>I am using PyTorch (Geometric) and all is going well, except for the fact that no TB tab appears as in the example from the guide. What I have tried:<\/p>\n<ol>\n<li>Use sync_tensorboard=True in wandb.init. Later on create some SummaryWriter. Indeed my tfevents appear nicely in the files section as in your example run. However, no TB tab appears.<\/li>\n<li>Explicitly specify wandb.tensorboard.patch(tensorboard_x=False, pytorch=True) with some rootdir. Do not specify sync_tensorboard=True in wandb.init. Later on create a SummaryWrtier. Again, tfevents appear in Files but no TB tab.<\/li>\n<\/ol>\n<p>Does anyone have advice for how to force the TB tab to appear?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrating Wandb and AWS Lambda - Multiprocessing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/integrating-wandb-and-aws-lambda-multiprocessing\/4160",
        "Question_created_time":"2023-03-31T10:20:40.689Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":184,
        "Question_body":"<p>Hello!<\/p>\n<p>When I try to download an artifact in an AWS Lambda, I get the following error:<\/p>\n<pre><code class=\"lang-auto\">[ERROR] OSError: [Errno 38] Function not implemented\nTraceback (most recent call last):\n  File \"\/var\/task\/on_lambda.py\", line 149, in lambda_entrypoint\n    generate_predictions(\n  File \"\/var\/task\/on_lambda.py\", line 75, in generate_predictions\n    models_data = get_models_data()\n  File \"\/var\/task\/on_lambda.py\", line 156, in &lt;lambda&gt;\n    get_models_data=lambda: get_customer_models_data(\n  File \"\/var\/task\/models.py\", line 38, in get_customer_models_data\n    artifact_dir = artifact.download(root=CUSTOMER_DATA_DIR)\n  File \"\/var\/task\/wandb\/apis\/public.py\", line 3763, in download\n    pool = multiprocessing.dummy.Pool(32)\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/dummy\/__init__.py\", line 124, in Pool\n    return ThreadPool(processes, initializer, initargs)\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/pool.py\", line 927, in __init__\n    Pool.__init__(self, processes, initializer, initargs)\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/pool.py\", line 196, in __init__\n    self._change_notifier = self._ctx.SimpleQueue()\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/context.py\", line 113, in SimpleQueue\n    return SimpleQueue(ctx=self.get_context())\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/queues.py\", line 341, in __init__\n    self._rlock = ctx.Lock()\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/context.py\", line 68, in Lock\n    return Lock(ctx=self.get_context())\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 162, in __init__\n    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\n  File \"\/var\/lang\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 57, in __init__\n    sl = self._semlock = _multiprocessing.SemLock(\n<\/code><\/pre>\n<p>Is there a way around this? It seems to be an issue with multiprocessing. I tried setting <code>WANDB_START_METHOD = thread<\/code> which I saw mentioned in a few places, but the error doesn\u2019t change.<\/p>\n<p>This is how I\u2019m downloading the artifact:<\/p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact(artifact_name)\n    artifact_dir = artifact.download(root=data_dir)\n<\/code><\/pre>\n<p>I saw two other threads on this topic but they didn\u2019t have a solution<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"wandb.errors.CommError: Run initialization has timed out after 60.0 sec",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-errors-commerror-run-initialization-has-timed-out-after-60-0-sec\/4284",
        "Question_created_time":"2023-04-26T08:42:51.327Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":437,
        "Question_body":"<p>Hello,<br>\nI want to achieve the following behavior:<\/p>\n<p>I have a yaml file containing all hyper-parameters for my experiment. One of the parameters is a list of values. I want to run a separate wandb run for each value in the list while all other hyper-parameters are the same.<br>\nFor that I split up the config file (containing the hyper-parameters) into multiple config files, each with a different value from the aforementioned list.<br>\nThen I loop over the config files and  initialize a wandb run. Once the run is over or I abort it, the next wandb run is started with another config file.<\/p>\n<p>Here the loop over the config files:<\/p>\n<pre><code class=\"lang-auto\">for run_config in run_configs:\n   self.create_dirs()  # this created new directories for the run to save the logs and models to\n   self.run_config = copy.deepcopy(run_config)  # populate the run configuration\n   self.run_experiment(self.run_config[\"tag\"])  # run the experiment with the current run configuration\n<\/code><\/pre>\n<p>here the code inside self.run_experiment(tag)<\/p>\n<pre><code class=\"lang-auto\">run = wandb.init(project=\"MyProjectName\", name=\"unique name\", sync_tensorboard=True,  save_code=True,\n                             dir=unique_directory,  config=self.run_config,  notes=\"some notes\",  tags=tag,  reinit=True, id=wandb.util.generate_id(),\n                             entity=\"MyUserName\",  settings=wandb.Settings(start_method=\"fork\"))\n# the settings=wandb.Settings(start_method=\"fork\")) I found in the wandb documentation but it did not solve my issue\n\ntry:\n    # here I train my agent and log stuff to wandb\nexcept KeyboardInterrupt:\n    # this allows to save the model when interrupting training\n    pass\n\nfinally:\n    # Release resources\n    try:\n        self.save_everything(agent)\n         run.finish()\n         env.close()\n         eval_env.close()\n         del agent\n         del env\n         del eval_env\n    except EOFError:\n         pass\nreturn\n<\/code><\/pre>\n<p>So once I manually interrupt the execution my model is saved, the wandb run is finished, everything is deleted and the next iteration of the for-loop begins.<\/p>\n<p>The issue:<\/p>\n<p>However, instead of starting the next wandb run after the first one is over\/was interrupted I get the following error instead:<br>\nError communicating with wandb process, exiting<br>\nwandb Exception: problem<\/p>\n<p>after I updated to wandb version 0.15. I get the following error instead:<\/p>\n<p>wandb: ERROR Run initialization has timed out after 60.0 sec.<\/p>\n<p>EDIT:<br>\nI have solved the issue. The problem seems to be connected to the fact that I am using PyCharm.<br>\nThe problem at hand is that when I interrupt my script in PyCharm using the red Stop-Button in the top right corner, wandb triggers a KeyBoardInterrupt internally and finishes the run. Afterwards, however, I cannot initialize a new run with wandb.init()<br>\nWhen I go to Run\/Edit Configurations inside PyCharm and toggle \u201cEmulate terminal in output console\u201d, I can send the KeyBoardInterrupt usind Control+C inside the output console of PyCharm, In that case wandb allows me to reinitialize a new run after the KeyboardInterrupt was caught.<br>\nSo somehow wandb functions differently in the case where the script receives the KeyBoardInterrupt signal from PyCharm\u2019s red stop button as compared to receiving the KeyBoardInterrupt from the output console with Ctrl+C<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting AttributeError: 'NoneType' object has no attribute '_log' while generating model predictions",
        "Question_link":"https:\/\/community.wandb.ai\/t\/getting-attributeerror-nonetype-object-has-no-attribute-log-while-generating-model-predictions\/4281",
        "Question_created_time":"2023-04-26T06:19:42.866Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":150,
        "Question_body":"<p>I have a function to generate predictions from my pytorch model like so,<\/p>\n<pre><code class=\"lang-py\">@torch.inference_mode()\ndef generate_submission(model, test_loader, name='submission.csv'):\n    test_files = listdir(test_dir)\n    len(test_files)\n\n    predictions = []\n    model.eval()\n    for batch_idx, data in enumerate(test_loader):\n        for key, value in data.items():\n            data[key] = value.to(device)\n        model_output = model(data['Image'])\n        _, preds = torch.max(model_output['Probabilities'], dim=1)\n        #preds.cpu()\n        predictions.append(preds)\n\n    final_predictions = torch.cat(predictions, dim=0).to('cpu')\n    df = pd.DataFrame({'id':test_files, 'category':final_predictions})\n    df.to_csv(name, index = False)\n    \n    return df\n<\/code><\/pre>\n<p>This function works fine without wandb addition in my code, but after adding wandb logging even though that is nowhere in this specific function I get an error.<\/p>\n<pre><code class=\"lang-py\">---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n\/tmp\/ipykernel_23\/3664024534.py in &lt;module&gt;\n----&gt; 1 generate_submission(model, test_loader, name='submission-simple.csv')\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/torch\/autograd\/grad_mode.py in decorate_context(*args, **kwargs)\n     25         def decorate_context(*args, **kwargs):\n     26             with self.clone():\n---&gt; 27                 return func(*args, **kwargs)\n     28         return cast(F, decorate_context)\n     29 \n\n\/tmp\/ipykernel_23\/459273187.py in generate_submission(model, test_loader, name)\n      9         for key, value in data.items():\n     10             data[key] = value.to(device)\n---&gt; 11         model_output = model(data['Image'])\n     12         _, preds = torch.max(model_output['Probabilities'], dim=1)\n     13         #preds.cpu()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/torch\/nn\/modules\/module.py in _call_impl(self, *input, **kwargs)\n   1209         if _global_forward_hooks or self._forward_hooks:\n   1210             for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):\n-&gt; 1211                 hook_result = hook(self, input, result)\n   1212                 if hook_result is not None:\n   1213                     result = hook_result\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py in &lt;lambda&gt;(mod, inp, outp)\n    109             hook = module.register_forward_hook(\n    110                 lambda mod, inp, outp: parameter_log_hook(\n--&gt; 111                     mod, inp, outp, log_track_params\n    112                 )\n    113             )\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py in parameter_log_hook(module, input_, output, log_track)\n    103                 else:\n    104                     data = parameter\n--&gt; 105                 self.log_tensor_stats(data.cpu(), \"parameters\/\" + prefix + name)\n    106 \n    107         log_track_params = log_track_init(log_freq)\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    254             bins = torch.Tensor(bins_np)\n    255 \n--&gt; 256         wandb.run._log(\n    257             {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n    258             commit=False,\n\nAttributeError: 'NoneType' object has no attribute '_log'\n<\/code><\/pre>\n<p>I don\u2019t understand why is wandb.run._log() even being called here? Only in my training loop did I have a wandb.watch() parameter and wandb.log(metrics) and then used wandb.finish() to close it. Why is this being called here?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb resumed offline runs aren't updating when synced",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-resumed-offline-runs-arent-updating-when-synced\/4188",
        "Question_created_time":"2023-04-05T15:12:38.154Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":205,
        "Question_body":"<p>Hi all! Before my question, let me describe my setup. I am running a training, offline, and then I use a checkpoint from that training to resume training later, also offline. I use the same run ID for both the initial training and the resumed trainings, so wandb generates log folders with the same names but different timestamps.<\/p>\n<p>When I run wandb sync --sync-all, it appears to sync all of the directories. However only some of the plots get updated with the new data from the resumed runs while others don\u2019t. Is there any reason why this might happen?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to correctly use wandb hyperparameter tuning with Huggingface?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-correctly-use-wandb-hyperparameter-tuning-with-huggingface\/4058",
        "Question_created_time":"2023-03-15T04:27:03.796Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":238,
        "Question_body":"<p>Hi everyone <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wave.png?v=12\" title=\":wave:\" class=\"emoji\" alt=\":wave:\" loading=\"lazy\" width=\"20\" height=\"20\">, I am using wandb with Huggingface in a AWS Sagemaker notebook and I am refering to the tutorial here: <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/define-sweep-configuration\" class=\"inline-onebox\">Define sweep configuration for hyperparameter tuning.<\/a> and <a href=\"https:\/\/huggingface.co\/docs\/transformers\/hpo_train\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Hyperparameter Search using Trainer API<\/a>.<\/p>\n<p>My codes works well without hyperparameter search, but all runs failed after I enable hyperparameter search.<\/p>\n<p>This is the error message from one of the failed runs:<\/p>\n<pre><code class=\"lang-auto\">Run 0ilv70r3 errored: ValueError(\"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n ...,\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16)\") wandb: ERROR Run 0ilv70r3 errored: ValueError(\"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n ...,\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16)\")\n<\/code><\/pre>\n<p>My model is an object detection model. It seems that the outputs do not fit. I wonder how can I solve this issue.<\/p>\n<p>Here are some useful snippets of my code:<\/p>\n<pre><code class=\"lang-auto\">def wandb_hp_space(trial):\n    return {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n        \"parameters\": {\n            \"learning_rate\": {\"distribution\": \"log_uniform\", \"min\": 1e-6, \"max\": 1e-4},\n            \"per_device_train_batch_size\": {\"values\": [8, 16]},\n        },\n    }\n\n    training_args = TrainingArguments(\n        output_dir=args.output_dir,\n        overwrite_output_dir=True,\n        per_device_train_batch_size=args.per_device_train_batch_size,\n        weight_decay=args.weight_decay,\n        warmup_steps=args.warmup_steps,\n        save_total_limit=args.save_total_limit,\n        learning_rate=args.learning_rate,\n        fp16=True,\n        save_strategy=\"epoch\",\n        logging_strategy='epoch',\n        remove_unused_columns=False,\n        push_to_hub=True,\n        hub_model_id=args.hub_model_id,\n        hub_token=args.hub_token,\n        hub_strategy=\"every_save\",\n        report_to=\"wandb\",\n    )\n\n    def model_init(trial):\n        return AutoModelForObjectDetection.from_pretrained(\n            args.pretrained_model,\n            id2label=CLASS_ID_TO_NAME,\n            label2id=CLASS_NAME_TO_ID,\n            ignore_mismatched_sizes=True,\n        )\n\n    trainer = Trainer(\n        model=None,\n        model_init=model_init,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=test_dataset,\n        data_collator=collate_fn,\n        tokenizer=image_processor,\n    )\n\n    trainer.hyperparameter_search(\n        hp_space=wandb_hp_space,\n        n_trials=5,\n        direction=\"minimize\",\n        backend=\"wandb\",\n    )\n<\/code><\/pre>\n<p>I would greatly appreciate any guidance or advice on how to resolve this issue. Thank you very much in advance for your help! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/pray.png?v=12\" title=\":pray:\" class=\"emoji\" alt=\":pray:\" loading=\"lazy\" width=\"20\" height=\"20\"> <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/pray.png?v=12\" title=\":pray:\" class=\"emoji\" alt=\":pray:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Encountering network error when running sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/encountering-network-error-when-running-sweep\/4290",
        "Question_created_time":"2023-04-27T16:25:41.303Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":77,
        "Question_body":"<p>I\u2019ve been running sweeps without issue for the past few weeks. This morning, however, I ran into the issue below.<\/p>\n<pre><code class=\"lang-auto\">(my_env) \u279c  scripts git:(main) \u2717 wandb agent usr\/dir\/xxxx\nwandb: Starting wandb agent \ud83d\udd75\ufe0f\nwandb: Network error (ReadTimeout), entering retry loop.\n<\/code><\/pre>\n<p>I don\u2019t see any issues on <a href=\"https:\/\/status.wandb.com\/\" rel=\"noopener nofollow ugc\">https:\/\/status.wandb.com\/<\/a>. There also doesn\u2019t seem to be any issues on my side connecting to any other external resource (e.g., github, <code>wget<\/code>ing files.)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Summary value can not be displayed in the scalar chart \/ dashboard?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/summary-value-can-not-be-displayed-in-the-scalar-chart-dashboard\/4294",
        "Question_created_time":"2023-04-28T03:23:07.345Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":43,
        "Question_body":"<p>I define the max metric value in the code. and the summary file looks like this<\/p>\n<pre><code class=\"lang-auto\">  \"loss_total\": {\n    \"min\": -0.7097547054290771\n  },\n<\/code><\/pre>\n<p>but when i add a scalar chart panel on this metric,  the value can not be displayed, which said \u201cSelect runs that logged summary:loss_total.min to visualize data in this chart.\u201d<br>\nIs there something set wrong ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb assertion errror",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-assertion-errror\/4260",
        "Question_created_time":"2023-04-23T06:45:09.854Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":55,
        "Question_body":"<p>Hi,<br>\nsometimes I meet with this kind of error, when I run on a remote device:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/3210bee6d41f470899393ebd804a54d0b8eacb85.png\" data-download-href=\"\/uploads\/short-url\/78TKyZQzgGPLZDlHXk14ZJlglYV.png?dl=1\" title=\"Screenshot from 2023-04-23 08-40-26\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3210bee6d41f470899393ebd804a54d0b8eacb85_2_690x93.png\" alt=\"Screenshot from 2023-04-23 08-40-26\" data-base62-sha1=\"78TKyZQzgGPLZDlHXk14ZJlglYV\" width=\"690\" height=\"93\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3210bee6d41f470899393ebd804a54d0b8eacb85_2_690x93.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3210bee6d41f470899393ebd804a54d0b8eacb85_2_1035x139.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3210bee6d41f470899393ebd804a54d0b8eacb85_2_1380x186.png 2x\" data-dominant-color=\"2A2319\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2023-04-23 08-40-26<\/span><span class=\"informations\">1482\u00d7200 40.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<code>Error: Run xxx errored: AssertionError()<\/code><br>\nDubugging tool in vscode cannot locate it. It just pops up and tells you the run is failed. I can find which line is the reason of this error, but have no idea what happens.<br>\nAfter checking for much time, I can do nothing but disconnect with remote device and connect again. And the problem is gone\u2026 Is there a more specific reason?<br>\nThanks a lot!<br>\nJialei Li<\/p>",
        "Question_closed_time":"2023-04-27T17:56:47.071Z",
        "Answer_body":"<p>Hi,<br>\nI found the reason now. It is relative with other part of my project\u2019s program. It has nothing to do with wandb actually\u2026 Still thanks a lot for your willingness to check error for me <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Why do I have an army of wandb files everywhere? It's overwhelming my disk quota",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-do-i-have-an-army-of-wandb-files-everywhere-its-overwhelming-my-disk-quota\/4221",
        "Question_created_time":"2023-04-14T19:03:35.691Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":108,
        "Question_body":"<p>I think this was caused by wandb<\/p>\n<pre><code class=\"lang-auto\">(mds_env_gpu) brando9~ $ ls\ndata\t\t\t\t\t\t   pymp-5u3y_5ds  pymp-bkacd1x6  pymp-hvosikw7\tpymp-o4ubsmvp  pymp-u2hxw56_\ndebug-cli.brando9.log\t\t\t\t   pymp-5ufiwnum  pymp-bkeosgoh  pymp-hwp6mlgl\tpymp-o5709m1c  pymp-u3pu2_8j\ndiversity-for-predictive-success-of-meta-learning  pymp-5v6yw2ny  pymp-bli8hdga  pymp-hxkt2k6m\tpymp-o5pz2fw4  pymp-u4atcmq1\niit-term-synthesis\t\t\t\t   pymp-5vfjyiy8  pymp-blu04xre  pymp-hy_6a7yv\tpymp-o5qihl07  pymp-u4hs1l_h\nminiconda\t\t\t\t\t   pymp-5vkol09u  pymp-bm04j6u_  pymp-hybr3wao\tpymp-o5v4yyjh  pymp-u5hwvurq\nminiconda.sh\t\t\t\t\t   pymp-5w0ycex5  pymp-bm1af1s4  pymp-hyd9kp9k\tpymp-o78e5rv_  pymp-_u6saect\nproverbot9001\t\t\t\t\t   pymp-5wk26dbe  pymp-bm_hml09  pymp-hyg2wzja\tpymp-o7u0brbq  pymp-u7341z_u\npycoq\t\t\t\t\t\t   pymp-5wv1264k  pymp-bmwsk0ui  pymp-hyujmqqx\tpymp-o8dzl_uf  pymp-u75jwgya\npymp-00y0lbly\t\t\t\t\t   pymp-5x3lfjus  pymp-bnduqemj  pymp-hyvxx7e3\tpymp-o8rez_1_  pymp-u7ca8y7o\n...\n\t\t\t\t   pymp-be9ogs4j  pymp-hptd30xx  pymp-ny7y25f5\tpymp-tudnkgfd  tmpft4wdrhxwandb\npymp-5no2jlmt\t\t\t\t\t   pymp-bedy_tkt  pymp-hpybolff  pymp-nyra71s5\tpymp-t_uf7u5j  tmpfvg5and3wandb\npymp-5ntrk5up\t\t\t\t\t   pymp-beha_4zu  pymp-hq7fmd8n  pymp-nzpgew4t\tpymp-tvqwp5ey  tmpj6j0zfbj\npymp-5omzfs4r\t\t\t\t\t   pymp-bei9ikn0  pymp-hqydweky  pymp-o08sw9t7\tpymp-tvwdr69z  tmpj8tzqwx4\npymp-5_pfdtfd\t\t\t\t\t   pymp-berkyhno  pymp-hr4yovs8  pymp-o0c0lcxr\tpymp-twvu_nlb  tmplgskh1xrwandb-artifacts\npymp-5p_xds_i\t\t\t\t\t   pymp-bgxwfpek  pymp-hr5p_4ss  pymp-o0hmcwva\tpymp-tx00ffcm  tmpmfxif8o4wandb-media\npymp-5q_5m8lf\t\t\t\t\t   pymp-_bgy7q56  pymp-hra_cgtz  pymp-o0jepdlw\tpymp-txu77bbs  tmpol_hgq43wandb-artifacts\npymp-5qxdpjjs\t\t\t\t\t   pymp-bhelzwte  pymp-hrc22cf7  pymp-_o0s21so\tpymp-ty8mdfqa  tmppybf10yp\npymp-5rlt16x0\t\t\t\t\t   pymp-bhfw5927  pymp-hrtr23se  pymp-o1hh7338\tpymp-tykpaaaa  tmpq3i3awq2wandb-media\npymp-5rlwn6_h\t\t\t\t\t   pymp-bhfz8nzu  pymp-hs_0tj_l  pymp-o1mmetf7\tpymp-tz38gxnk  tmpvbj3c1glwandb-artifacts\npymp-5sf007t_\t\t\t\t\t   pymp-bhzzq3ji  pymp-hs60ap_i  pymp-o2pg14r2\tpymp-tz5zx4w5  tmpx795b348wandb-media\npymp-5smqiuo8\t\t\t\t\t   pymp-_bi71ltm  pymp-ht16ywuf  pymp-o3sgbsuh\tpymp-u03tywik  tmpz6nn0yezwandb-media\npymp-5svxeand\t\t\t\t\t   pymp-bia6j600  pymp-htb33wdv  pymp-o41jeuwi\tpymp-u19gfzmg  tmpzkt1j4lt\npymp-5tpni86a\t\t\t\t\t   pymp-bip9y835  pymp-htj63od5  pymp-o48ihbt6\tpymp-u1a3qbtw  tmpzov5_ez7wandb-artifacts\npymp-5turfdfv\t\t\t\t\t   pymp-b_j5cszm  pymp-hu621te7  pymp-o4hse0ac\tpymp-u215nj9s  ultimate-utils\npymp-5_u0d4ov\t\t\t\t\t   pymp-bk6h_1kx  pymp-huvexmsv  pymp-o4tpqmbs\tpymp-u21uakvb  wandb\n<\/code><\/pre>\n<p>I have this:<\/p>\n<pre><code class=\"lang-auto\"># - use local machine as home, can't start with cd because like in .bashrc.user since we need to figure out local path in lfs\n#export LOCAL_MACHINE_PWD=$(python3 -c \"import socket;hostname=socket.gethostname().split('.')[0];print(f'\/lfs\/{hostname}\/0\/brando9');\")\nexport LOCAL_MACHINE_PWD=$(python3 -c \"import socket;hostname=socket.gethostname().split('.')[0];print('\/lfs\/'+str(hostname)+'\/0\/brando9');\")\nmkdir -p $LOCAL_MACHINE_PWD\nexport WANDB_DIR=$LOCAL_MACHINE_PWD\nexport HOME=$LOCAL_MACHINE_PWD\n<\/code><\/pre>\n<p>is it wrong?<\/p>\n<p>Also, why would it take 11T of info?<\/p>\n<pre><code class=\"lang-auto\">(mds_env_gpu) brando9~ $ df -h \/lfs\/hyperturing2\/0\/brando9\/\nFilesystem      Size  Used Avail Use% Mounted on\n\/dev\/md127       11T   11T   48M 100% \/lfs\/hyperturing2\/0\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I move a whole project to a team?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-move-a-whole-project-to-a-team\/4270",
        "Question_created_time":"2023-04-24T13:55:53.640Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":60,
        "Question_body":"<p>I have a personal project with some sweeps on it that I\u2019d like to move to our newly-created team. I see a way to move a run between projects, but not a way to move a whole project. Is this possible?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Summary metric from runs not visible in sweep (bug?)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/summary-metric-from-runs-not-visible-in-sweep-bug\/4276",
        "Question_created_time":"2023-04-25T11:58:31.865Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":50,
        "Question_body":"<p>Greetings WandB, many thanks for your fantastic service!<\/p>\n<p>I have been running several sweeps in a project and only realised that the summary metrics for the sweeping overview got several missing values despite the runs containing and having successfully logged these. Did I log my metrics wrong and need to redo all my experiments, or is it a bug, as described below? <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/innocent.png?v=12\" title=\":innocent:\" class=\"emoji\" alt=\":innocent:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>Please see this first image, containing the run summary of <em>toasty-sweep-31<\/em>, which logged <em><strong>Test_AUC_std<\/strong><\/em> and <em>Test_EER_std<\/em>. Let\u2019s focus on the \u2018Test_AUC_std\u2019 since that column is also visible in the following screenshot showing the sweep summary metrics; however, the same issue appears for several other columns also logged within each run.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/daaa3450969a597cb1f40eef9649cc508f8b01dc.png\" data-download-href=\"\/uploads\/short-url\/vcoKtRVH2OFQYEi2J7FzZW4jySo.png?dl=1\" title=\"summary_metric_in_run\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/daaa3450969a597cb1f40eef9649cc508f8b01dc.png\" alt=\"summary_metric_in_run\" data-base62-sha1=\"vcoKtRVH2OFQYEi2J7FzZW4jySo\" width=\"690\" height=\"363\" data-dominant-color=\"242324\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">summary_metric_in_run<\/span><span class=\"informations\">904\u00d7476 11.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>In the sweep summary metrics, I am showing all columns available, including <em><strong>Test_auc_std<\/strong><\/em>, but now the AUC is lowercase, and the values are missing. Same for the \u201cTest_EER_std\u201d etc.<\/p>\n<p>Since the columns are automatically inferred from runs, how could I \u2018refresh\u2019 the columns to synchronise with the runs? I do not recall logging \u2018Test_auc\u2019, but that may be a spillover from early runs. Is there are way to \u2018recompile\u2019 the project and these summary metrics?<\/p>\n<p>The sweep is available <a href=\"https:\/\/wandb.ai\/aabywan\/SigDraw2\/sweeps\/tnc1g4c7\/table?workspace=user-aabywan\">here<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Choppy table movement (web)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/choppy-table-movement-web\/4211",
        "Question_created_time":"2023-04-13T06:08:22.619Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":79,
        "Question_body":"<p>I have a small (I think) table of around 20 runs and 20 columns. When dragging the slide bar horizontally, visible lag (~500ms) exists when a block of numbers is getting loaded. The latency is acceptable, but the movement seems to be waiting on this lag and the movement becomes choppy. This prevents me from efficiently locate a column I want to look at.<br>\nIs there a way to accomodate this lag? It is okay that the numbers don\u2019t show immediately but at least it should not interfere with the slide bar movement.<br>\nI do not have any complicated contents (images, for example) in the table. Only short strings and numbers.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sync error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sync-error\/4267",
        "Question_created_time":"2023-04-24T12:28:33.448Z",
        "Question_answer_count":7,
        "Question_score_count":3,
        "Question_view_count":121,
        "Question_body":"<p>When I finished the training with the offline mode, I use  the following command to upload the trained results to the cloud service.<\/p>\n<pre><code class=\"lang-auto\">wandb  sync   MY_RUN_DIRECTORY\n<\/code><\/pre>\n<p>But I got the KeyError: \u2018run_url\u2019<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044.jpeg\" data-download-href=\"\/uploads\/short-url\/oQmDb7gGEFmjb7DrMnTKtSiKweM.jpeg?dl=1\" title=\"Screenshot 2023-04-24 202643\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg\" alt=\"Screenshot 2023-04-24 202643\" data-base62-sha1=\"oQmDb7gGEFmjb7DrMnTKtSiKweM\" width=\"690\" height=\"240\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1035x360.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1380x480.jpeg 2x\" data-dominant-color=\"181818\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-04-24 202643<\/span><span class=\"informations\">1396\u00d7487 192 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>How to solve this question?<\/p>",
        "Question_closed_time":"2023-04-24T12:59:05.609Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/lee086824\">@lee086824<\/a> thanks for reporting this issue. There was a regression in wandb <code>v0.14.1<\/code> that would throw this <code>KeyError: 'run_url'<\/code>. Is this your current version, and if so could you please upgrade to our most recent client\/SDK version and try to sync your runs again? Would it work for you?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Bayes method for searching in sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bayes-method-for-searching-in-sweep\/4261",
        "Question_created_time":"2023-04-23T11:30:20.766Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":38,
        "Question_body":"<p>Hi,<br>\nI am using Bayes searching method to sweep through a group of hyper-parameters. Number of all permutations of these 2 hyper-parameters is 15. I set sweep count as 60, in order to get more cases. However when I check the sweep plots, I see this:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21.png\" data-download-href=\"\/uploads\/short-url\/pWsZfhMVsFezceHwQ3Aibtbmbsd.png?dl=1\" title=\"Screenshot from 2023-04-23 13-17-49\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_690x328.png\" alt=\"Screenshot from 2023-04-23 13-17-49\" data-base62-sha1=\"pWsZfhMVsFezceHwQ3Aibtbmbsd\" width=\"690\" height=\"328\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_690x328.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_1035x492.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_1380x656.png 2x\" data-dominant-color=\"F8F8F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2023-04-23 13-17-49<\/span><span class=\"informations\">2460\u00d71170 312 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>There are already 44 sweeps, but it seems many of cases are exactly identical. As a result, I actually only get 6 or 7 cases, even less than grid search. As you can see above, many cases are really superpositioned\u2026<\/p>\n<p>So it confuses me now that how should I understand Bayes searching method.<br>\nAnd there is corresponding code about sweep:<\/p>\n<pre><code class=\"lang-auto\">sweep_configuration = {\n'method': 'bayes',\n'name': f'{args.dataset_name} 3rd class: levels, hidden_size',\n'metric': {'goal': 'minimize', 'name': 'valid\/ber'},\n'parameters':\n{\n    'levels': {'values': [1,2,3,4,5]},\n    'hidden_size': {'values': [1.0,2.0,3.0]}\n}\n}\nargs.tune_count = 60\nwandb.agent(sweep_id, function=Hyper_param_Tune, count=args.tune_count)\n<\/code><\/pre>\n<p>Thanks for any help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Collect results from sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/collect-results-from-sweep\/4238",
        "Question_created_time":"2023-04-19T20:48:57.687Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":42,
        "Question_body":"<p>Hi,<br>\nI am tuning hyper-params with <code>wandb.sweep<\/code>. For now, in order to get the best group of hyper-params, I have to look for the best group on my own and record those params manually. I wonder whether there is a way to extract or collect reuslts of hyper-params automatically by <code>wandb<\/code>?<br>\nThanks a lot!<\/p>",
        "Question_closed_time":"2023-04-20T16:55:19.809Z",
        "Answer_body":"<p>Hello!<\/p>\n<p>We have <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/pytorch\/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=G01IM4yVkc6u\" rel=\"noopener nofollow ugc\">Parallel Coordinate plots and Hyper Parameter Importance Plots<\/a> in the UI that can help with looking for the best group! In terms of collecting results of sweeps, the hyperparameters are automatically logged to the <code>config.yaml<\/code> file in your run\u2019s file tab.  However, if you want to collect the hyperparameters  yourself, you can also access individual hyperparameter values using <code>wandb.config['hyperparameter-name']<\/code> within the <code>main()<\/code> function you are running your sweep on. <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/config\">Here<\/a> is our documentation on ways to use access and update the config file.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to add prior runs to Sweep via Python API?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-add-prior-runs-to-sweep-via-python-api\/4207",
        "Question_created_time":"2023-04-12T18:01:06.655Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":83,
        "Question_body":"<p>Sweeps <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/faq#is-there-a-way-to-add-extra-values-to-a-sweep-or-do-i-need-to-start-a-new-one\">FAQ<\/a> describes a way of adding prior runs to a new sweep via Web\/GUI:<\/p>\n<blockquote>\n<p><strong>Is there a way to add extra values to a sweep, or do I need to start a new one?<\/strong><\/p>\n<p>You cannot change the Sweep configuration once a W&amp;B Sweep has started. But you can go to any table view, and use the checkboxes to select runs, then use the <strong>Create sweep<\/strong> menu option to create a new Sweep configuration using prior runs.<\/p>\n<\/blockquote>\n<p>How do I do the same using WandB Python API?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Debug error with wandb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/debug-error-with-wandb\/4155",
        "Question_created_time":"2023-03-30T16:23:41.703Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":194,
        "Question_body":"<p>Hi,<br>\nI met with a debug error when tuning hyperparams with sweep.<\/p>\n<p><code>wandb: ERROR Run c3yfj87h errored: RuntimeError('cuDNN error: CUDNN_STATUS_INTERNAL_ERROR')<\/code><\/p>\n<p><code>wandb: ERROR Run 542e421i errored: RuntimeError('false INTERNAL ASSERT FAILED at \"..\/c10\/cuda\/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32522')<\/code><\/p>\n<p>When I directly run it with a terminal, there is no such error. It only occurs when I debug. Could someone give some clues about the reason why?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I extract params from sweep and add them into name of wandb.init()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-extract-params-from-sweep-and-add-them-into-name-of-wandb-init\/4146",
        "Question_created_time":"2023-03-29T12:03:52.727Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":96,
        "Question_body":"<p>Hi,<br>\nI am tuning hyper-params with wandb.sweep(). As I know the params are defined in sweep_id and insert into wandb.sweep() like this:<\/p>\n<pre><code class=\"lang-auto\">    sweep_configuration = {\n    'method': 'bayes',\n    'name': 'I dont believe that I can not just give you a name!',\n    'metric': {'goal': 'minimize', 'name': 'Valid\/final_ber'},\n    'parameters':\n    {\n        'batch_size': {'distribution': 'int_uniform','min': 10,'max': 12},\n        'lr': {'distribution': 'int_uniform','max': -3,'min': -4}\n    }\n    }\n    sweep_id = wandb.sweep(sweep=sweep_configuration, project=args.project, entity=args.entity)\n<\/code><\/pre>\n<p>Now I what I want to do is to extract the params <strong>batch_size<\/strong> and <strong>lr<\/strong> from each sweep into the name of <code>wand.init()<\/code>, because I need these information in name of each run to identify them.<br>\nBut in wandb frame, I cannot get access to the params in <code>wandb.config<\/code> before <code>wandb.init()<\/code>. As a result I cannot define argument <strong>name<\/strong>  in <code>wandb.init()<\/code> with params which are given during each sweep.<\/p>\n<pre><code class=\"lang-auto\">......\nwandb.init(name=f'{wandb.config.lr}_{wandb.config.batch_size}')\n......\n\nRun wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\nwandb: ERROR Run wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\n<\/code><\/pre>\n<p>Is there a way to get the params given by <code>wandb.sweep()<\/code> before wandb.init()?<br>\nThanks at advance<\/p>",
        "Question_closed_time":"2023-04-06T21:18:11.261Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/1060111768\">@1060111768<\/a> , it\u2019s not possible to get the sweep parameters before calling <code>wandb.init()<\/code>.<\/p>\n<p>When you run <code>wandb.sweep()<\/code> to define a hyperparameter sweep, it generates a unique sweep ID that is used to link the sweep to the subsequent runs that are generated by the sweep. This sweep ID is used to retrieve the sweep parameters when you initialize WandB by calling <code>wandb.init()<\/code>. The <code>wandb.init()<\/code> function retrieves the sweep parameters from the WandB servers using the sweep ID, and uses them to configure the run. Once you have called <code>wandb.init()<\/code>, you can access the sweep parameters using the <code>config<\/code> object.<\/p>\n<p>Instead of specifying a name in wandb init, rename the run immediately after initializing the run.<br>\nExample:<\/p>\n<pre><code class=\"lang-auto\">run =  wandb.init(config=config)\nrun.name=f\"{wandb.config.lr}_{wandb.config.batch_size}\"\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Multivariate Time Series Data",
        "Question_link":"https:\/\/community.wandb.ai\/t\/multivariate-time-series-data\/4086",
        "Question_created_time":"2023-03-21T10:50:41.798Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":141,
        "Question_body":"<p>Hi,<br>\nI am trying to use W&amp;B in order to run experiments with satellite time series data. As we are working on a relatively large scale, we do not work with entire images, but rather one representative pixel for each ROI. This way we end up with a dataset consisting of <code>num_samples<\/code> amount of data points for <code>t<\/code> timesteps and each with <code>num_bands<\/code> channels.<br>\n<strong>One sample<\/strong> might look like that:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png\" data-download-href=\"\/uploads\/short-url\/fY0RrFz6ZlHyaa6uxnty06uvzWu.png?dl=1\" title=\"MTS\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/6fe94f2cac394129b6bc000fc8bf10d1eed512de_2_690x369.png\" alt=\"MTS\" data-base62-sha1=\"fY0RrFz6ZlHyaa6uxnty06uvzWu\" width=\"690\" height=\"369\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/6fe94f2cac394129b6bc000fc8bf10d1eed512de_2_690x369.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png 2x\" data-dominant-color=\"E9EAE4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">MTS<\/span><span class=\"informations\">897\u00d7480 184 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nThe 13 individual lines are the reflectance values for each spectral band over the course of a year for a single sample.<\/p>\n<p>My question is the following:<br>\nIs there a wandb type that produces such representation as an entry in a table? I personally think that handling it as a plot is a bit of an overkill but on the other hand it seems like time series data can only be stored when it is univariate.<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why the weights for my model are not logged while I can see the gradients?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-the-weights-for-my-model-are-not-logged-while-i-can-see-the-gradients\/4174",
        "Question_created_time":"2023-04-03T14:39:46.143Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":128,
        "Question_body":"<p>Hi,<\/p>\n<p>I would like to track the weights and gradients for my model while it trains. I have three networks that are being trained jointly. I am calling \u2018wandb.watch\u2019 for each one of them individually. This allowed me to see the gradients, but for some reason, I can\u2019t see the weights for one of these networks in the \u2018parameters\u2019 tab.<\/p>\n<p>I would appreciate if anyone could help me to figure out what is the issue and how I can fix it.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create wandb.Table with image previews for a big dataset with most efficiency?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-create-wandb-table-with-image-previews-for-a-big-dataset-with-most-efficiency\/3855",
        "Question_created_time":"2023-02-09T10:26:56.479Z",
        "Question_answer_count":6,
        "Question_score_count":2,
        "Question_view_count":220,
        "Question_body":"<p>I have a dataset that has ~40k images. I want to upload them all using arifacts, i used run.add_dir(\u201cpath_to_dir_with_images\u201d).<br>\nI also have a csv that contains the labels of these images as well as the name of the image. Is there a way to create a wandb.Table so that i can explore this csv but also to have a column called images that has a reference to the images from the artifact via the file name. So that when i do EDA i can look at the images that are in the artifact instead of adding a column \u201cimages\u201d to the csv and populating it with wandb.Image objects and then uploading it as a wandb.Table?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NotFoundError() in Sweep after 1 epoch",
        "Question_link":"https:\/\/community.wandb.ai\/t\/notfounderror-in-sweep-after-1-epoch\/4205",
        "Question_created_time":"2023-04-11T12:11:45.373Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":80,
        "Question_body":"<p>Hey there,<br>\nI am currently trying to run a sweep for my model. Every time, after the first epoch has finished training, I get the following output:<\/p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced rich-sweep-1: https:\/\/wandb.ai\/prosit-compms\/intensity_normalization_optimization\/runs\/axdt1t4l\nwandb: Synced 6 W&amp;B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\/wandb\/run-20230411_132216-axdt1t4l\/logs\nRun axdt1t4l errored: NotFoundError()\nwandb: ERROR Run axdt1t4l errored: NotFoundError()\n<\/code><\/pre>\n<p>Soon after this, a new Agent starts and the same error appears after 1 epoch.<br>\nDoes anyone have an idea what might be causing this error.<\/p>\n<p>The Sweep and the run is visible in the wandb UI.<\/p>\n<p>It would be a great help to me if anyone has a suggestion on how to resolve this issue.<\/p>\n<p>Using wandb version: 0.14.2<br>\npython version: 3.9.15<\/p>\n<p>The Debug file: <a href=\"https:\/\/drive.google.com\/file\/d\/1_7ZYlrGKnMBrIgcoO6eO68r4O6PE_gMu\/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug.log<\/a><br>\nThe internal debug file: <a href=\"https:\/\/drive.google.com\/file\/d\/1gSzLi-ytrlh7if9Ov86FcGczhlzEtIWI\/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug-internal.log<\/a><br>\nThank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WARNING .wandb file is incomplete (invalid padding)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/warning-wandb-file-is-incomplete-invalid-padding\/4153",
        "Question_created_time":"2023-03-30T12:37:06.946Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":94,
        "Question_body":"<p>Hello all!<\/p>\n<p>I am running a lot of runs per day (~2K sometimes) and have been encountering some strange errors in a handful of my runs. I am doing this on a large computation cluster, so to avoid putting too much strain on the network for every run I<\/p>\n<ol>\n<li>set wandb to run offline (<code>export WANDB_MODE=\"offline\"<\/code>)<\/li>\n<li>set the <code>WANDB_DIR<\/code> to be a tmp directory (<code>WANDB_DIR=$(mktemp -d)<\/code>)<\/li>\n<li>Run my run as normal (runs are relatively short often taking ~2-20 minutes)<\/li>\n<li>Sync my wandb runs (<code>wandb sync $WANDB_DIR\/wandb\/offline*<\/code>)<\/li>\n<li>Clean up my tmpdir (<code>rm -rf $WANDB_DIR <\/code>)<\/li>\n<\/ol>\n<p>The full script is below:<\/p>\n<pre><code class=\"lang-auto\">my_config= # some config unique to this run\nexport WANDB_MODE=\"offline\"\nexport WANDB_DIR=$(mktemp -d)\npython train.py --config $my_config \nwandb sync $WANDB_DIR\/wandb\/offline*\nrm -rf $WANDB_DIR \n\n<\/code><\/pre>\n<p>In 99% of runs this works totally fine, however in a handful I get messages like:<\/p>\n<pre><code class=\"lang-auto\">Syncing: https:\/\/wandb.ai\/some_run ... wandb: WARNING .wandb file is incomplete (invalid padding), be sure to sync this run again once it's finished\ndone.\n<\/code><\/pre>\n<p>If I actually <em>look<\/em> at <code>some_run<\/code>, it seems totally normal and I don\u2019t see any missing data. Furthermore the <code>wandb sync<\/code> command returns 0 exit code so I would assume all is well despite the error message. But the existence of the error is concerning and I am not sure the best way to deal with it or if it needs to be delt with at all. I am grateful for any advice people have!<\/p>",
        "Question_closed_time":"2023-04-17T20:01:28.163Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/evanv\">@evanv<\/a> , apologies for the delay.<\/p>\n<p>The <code>invalid padding<\/code> error occurs when  wandb tries to read data from your run file, but the file may not be  in an expected format. This could happen for a variety of reasons including file corruption, or issues when the file is read. When wandb scans your file and finds a discrepency with the format, it raises a warning informing you to  <code>sync this run again once it's finished<\/code> as precautionary measure. If it successfully synced the first time around, then great, if not try again.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Create both sweep and start an agent for it in shell script",
        "Question_link":"https:\/\/community.wandb.ai\/t\/create-both-sweep-and-start-an-agent-for-it-in-shell-script\/4091",
        "Question_created_time":"2023-03-21T19:52:16.936Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":151,
        "Question_body":"<p>I want to build a replication package for a paper, where we are using W&amp;B to generate and store our results.<\/p>\n<p>Ideally I would just give people a bash or powershell script which creates the sweeps and creates an agent to run a sweep.  In all cases it is sufficient to run a single agent on a single computer.<\/p>\n<p>My ideal script would look something like<\/p>\n<pre><code class=\"lang-bash\">wandb sweep --name MyExperiment1 sweep_1.yaml\nwandb agent  XXXXXXXX\nwandb sweep --name MyExperiment2 sweep_2.yaml\nwandb agent  YYYYYYYYY\n<\/code><\/pre>\n<p>etc.   In all cases the <code>yaml<\/code> would be a grid with a finite number of iterations before finishing.  I guess I could also do things like <code>wandb agent XXXXXXX &amp;<\/code> to have a child process.<\/p>\n<p>But I am not sure how I get the sweepid returned from the wandb sweep to call <code>wandb agent<\/code>?  Are there any tricks?  I guess I can also use the python calls to create a sweep and an agent directly, but in that case I am not sure how to tell it to use a <code>yaml<\/code> file?<\/p>\n<p>Alternatively, is this the sort of thing that a job queue is best used for?  If so, any templates on how to handle that?  I guess my shell script would just create all of the jobs for a queue and then a single agent would run it?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging Datasets other than files (for example: tensorflow_dataset object)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-datasets-other-than-files-for-example-tensorflow-dataset-object\/4148",
        "Question_created_time":"2023-03-29T15:49:56.196Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":81,
        "Question_body":"<p>Hello,<\/p>\n<p>I see many examples in the documentation for logging actual files as datasets\/artifacts, but how do I log datasets that aren\u2019t files? For example, I am using tensorflow_datasets to download my dataset directly into train and validation splits and would like to log these directly. Is there an easy way to do this or can they only live in a table object?<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use the same parameter but produce different results in Bayesian Sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/use-the-same-parameter-but-produce-different-results-in-bayesian-sweep\/4186",
        "Question_created_time":"2023-04-05T03:48:10.649Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":164,
        "Question_body":"<p>I was trying to use Sweep for hyperparameter tuning.   And I want to do grid sweep in tuning. Coincidently I happend to use the Bayes Sweep (since last time I use the bayes for tuning). Then something weird happened.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/eab8bc4fae8510d8bd8187cc1a1434ecb341a135.png\" data-download-href=\"\/uploads\/short-url\/xurwnzUO5SdxA25PtlOLTx1c0L3.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_690x132.png\" alt=\"image\" data-base62-sha1=\"xurwnzUO5SdxA25PtlOLTx1c0L3\" width=\"690\" height=\"132\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_690x132.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_1035x198.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_1380x264.png 2x\" data-dominant-color=\"F9F9F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1868\u00d7358 27.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nI can understand the Bayes search may choose same combination of hyperparameters, But why the same hyperparameters come into different results? And I check my code, I definitely have set the seed. Is there anything I missed?<br>\nAnd this is the yaml config I use:<\/p>\n<blockquote><\/blockquote>\n<p>method: bayes<br>\nproject: classify<br>\nname: roberta-large<br>\nmetric:<br>\ngoal: maximize<br>\nname: best_valid_metric<br>\nparameters:<br>\ntask:<br>\nvalues: [\u201cemotion\u201d]<br>\nbatch_size:<br>\nvalues: [8, 16, 32]<br>\nplm_learning_rate:<br>\nvalues: [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]<br>\nother_learning_rate:<br>\nvalues: [1e-4, 2e-4, 3e-4, 4e-4, 5e-4]<br>\ndropout:<br>\nvalues: [0, 0.3, 0.5]<br>\nmodel_name:<br>\nvalue: 1<br>\nnum_labels:<br>\nvalue: 8<br>\ncommand:<\/p>\n<ul>\n<li>${env}<\/li>\n<li>${interpreter}<\/li>\n<li>${program}<\/li>\n<li>\u201c\u2013use_wandb\u201d<\/li>\n<li>${args}<\/li>\n<\/ul>",
        "Question_closed_time":"2023-04-05T08:29:32.199Z",
        "Answer_body":"<p>Dear Zhuojun,<\/p>\n<p>would you be able to confirm if you are using wandb server locally or our public cloud offering?<\/p>\n<p>This is a known bug that has now been fixed in our latest version of wandb serve 0.31.0 which was released yesterday.<\/p>\n<p>Upgrading to this version should fix the issue that you are experiencing with sweep combinations (repetition) of what should be permutations of parameters.<\/p>\n<p>Warm regards,<\/p>\n<p>Frida<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Stable Baslines3: step vs global_step vs tensorboard step",
        "Question_link":"https:\/\/community.wandb.ai\/t\/stable-baslines3-step-vs-global-step-vs-tensorboard-step\/4178",
        "Question_created_time":"2023-04-04T07:00:08.048Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":158,
        "Question_body":"<p>Hello Community,<\/p>\n<p>I have a very basic question regarding the stable baseline3 integration.<br>\nI want to plot basic stuff like the average episode reward. However, I am confused by the terms step and global_step. What is the difference between them?<br>\nWhen plotting global_step over step I was expecting a straight line, but it turns out there is no linear relationship between those two values.<br>\nCould someone explain to me the increment-rules of step and global_step?<\/p>\n<p>Also, when looking at the tensor board plots from within the WandB dashboard, I can see that the number of steps tensor board uses as x-axis differs to both global_step and step used in the wandb plots. Something is very weird.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Duplicate runs after 500 runs when using local controller",
        "Question_link":"https:\/\/community.wandb.ai\/t\/duplicate-runs-after-500-runs-when-using-local-controller\/4105",
        "Question_created_time":"2023-03-23T09:12:45.969Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":108,
        "Question_body":"<p>I deploy a wandb server in my local server, and use grid search to sweep hyperparameters with 4 parallel agents.<\/p>\n<p>In my case, the size of the search space exceeds 500, and each run takes about 2 minutes to finish.<\/p>\n<p>I always find that after 500 runs finish, the generated hyperparameter configurations of the newly started runs from the beginning again. That is, the configuration of the 501st run (or possibly the 502nd run) is the same as that of the first run, the configuration of the 502nd run (or possibly the 503rd run) is the same as that of the second run, and so on.<\/p>\n<p>I also check the log of the local controller, and the number of runs keeps to be 500 as follows:<br>\n\u2026<br>\nSweep: t3muh8oq (grid) | Runs: 470 (Running: 2, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 471 (Running: 3, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 4, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 3, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 4, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 3, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 4, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 3, Finished: 471)<br>\nSweep: t3muh8oq (grid) | Runs: 475 (Running: 3, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 4, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 2, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 477 (Running: 3, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 4, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 3, Finished: 475)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 2, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 479 (Running: 3, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 4, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 3, Finished: 477)<br>\nSweep: t3muh8oq (grid) | Runs: 481 (Running: 3, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 4, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 3, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 4, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 3, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 4, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 2, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 485 (Running: 3, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 486 (Running: 3, Finished: 483)<br>\nSweep: t3muh8oq (grid) | Runs: 487 (Running: 3, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 4, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 3, Finished: 485)<br>\nSweep: t3muh8oq (grid) | Runs: 489 (Running: 3, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 4, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 3, Finished: 487)<br>\nSweep: t3muh8oq (grid) | Runs: 491 (Running: 3, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 4, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 3, Finished: 489)<br>\nSweep: t3muh8oq (grid) | Runs: 493 (Running: 3, Finished: 490)<br>\nSweep: t3muh8oq (grid) | Runs: 494 (Running: 2, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 495 (Running: 3, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 4, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 3, Finished: 493)<br>\nSweep: t3muh8oq (grid) | Runs: 497 (Running: 3, Finished: 494)<br>\nSweep: t3muh8oq (grid) | Runs: 498 (Running: 3, Finished: 495)<br>\nSweep: t3muh8oq (grid) | Runs: 499 (Running: 3, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I store a sweep_id in a cli environment variable so that it runs in a wandb agent later?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wandb-agent-later\/4157",
        "Question_created_time":"2023-03-31T05:52:28.958Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":183,
        "Question_body":"<p>how do I run a wandb sweep in a cli\/terminal\/bash and store the sweep id in a env variable to use it later in the wandb agent cli command?<\/p>\n<p>Is this really correct\/recommended way?<\/p>\n<pre><code class=\"lang-auto\">export SWEEP_ID=$(wandb sweep sweep.yaml --project &lt;your-project-name&gt; | awk '\/ID:\/{print $2}')\nwandb agent --count $N $SWEEP_ID\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I'm facing assert isinstance( AssertionError: Insufficient permissions to fetch Artifact)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/im-facing-assert-isinstance-assertionerror-insufficient-permissions-to-fetch-artifact\/3998",
        "Question_created_time":"2023-03-04T01:38:50.066Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":87,
        "Question_body":"<p>I dont have much interest on the artifacts and I\u2019m just trying to run  my training and log my results on the webapi and it throws me an error :     assert isinstance(<br>\nAssertionError: Insufficient permissions to fetch Artifact with id QXXX.XXXX4 . This works perfectly fine on my other machine. Please let me know if any one knows what exactly is happening here.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I have two different run files to log to the same sweep?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-have-two-different-run-files-to-log-to-the-same-sweep\/4150",
        "Question_created_time":"2023-03-29T17:18:55.191Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_body":"<p>I noticed that the config file can have the program to run. I want all my runs for two different methods (and therefore use two different files and want to avoid refactoring). Can\u2019t the agent take the file path? (I know it can\u2019t) Or some alternative?<\/p>\n<pre><code class=\"lang-auto\">export SWEEPID=$(wandb sweep config.yaml)\nNUM=10\nwandb agent train_sl.py --count $NUM $SWEEPID\nwandb agent train_maml.py --count $NUM $SWEEPID\n<\/code><\/pre>\n<p>cross: <a href=\"https:\/\/stackoverflow.com\/questions\/75880299\/0-vote-how-do-i-have-two-different-run-files-to-log-to-the-same-sweep\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">wandb - 0 Vote How do I have two different run files to log to the same sweep? - Stack Overflow<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I faced an error while following the Fine-tune GPT-3 with Weights & Biases",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-faced-an-error-while-following-the-fine-tune-gpt-3-with-weights-biases\/4183",
        "Question_created_time":"2023-04-04T18:25:52.203Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":69,
        "Question_body":"<p>While following <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/openai\/Fine_tune_GPT_3_with_Weights_%26_Biases.ipynb#scrollTo=93tQxYhLgkUE\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab<\/a>,  the \u201cCreate a fine-tuned model\u201d section created the following error.<\/p>\n<p>CommError: Project {entity}\/GPT-3 does not contain artifact: \u201cwiki-dataset-train:latest\u201d<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hyperparameter tuning combined with k-fold cross validation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hyperparameter-tuning-combined-with-k-fold-cross-validation\/3881",
        "Question_created_time":"2023-02-14T15:16:52.496Z",
        "Question_answer_count":13,
        "Question_score_count":2,
        "Question_view_count":510,
        "Question_body":"<p>I found <a href=\"https:\/\/github.com\/wandb\/examples\/blob\/master\/examples\/wandb-sweeps\/sweeps-cross-validation\/train-cross-validation.py\" rel=\"noopener nofollow ugc\">this official example<\/a> showcasing an implementation of k-fold cross validation using Sweeps. However, I am doing hyperparameter tuning with sweeps so I am coming from a different angle: I want to do k-fold CV for one given set of parametersr for each sweep run. I would imagine that there should be sub-groups for each CV-group in the sweep view of the web interface.<\/p>\n<p>Is this possible to do with Wandb or should I look elsewhere?<\/p>\n<p>Thank you!<\/p>\n<p>EDIT: the rationale behind it is to prevent optimizing hyper parameters to overfit the test set. If you have another means to reach this goal, I am open for it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Handling a variable defined for a project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/handling-a-variable-defined-for-a-project\/4099",
        "Question_created_time":"2023-03-22T15:18:40.900Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":60,
        "Question_body":"<p>I am new to wandb so this might be a basic question,<\/p>\n<p>I want to assign, modify and keep track of a variable assigned to a project. The use case would be let\u2019s say I have a variable \u201ccount\u201d assigned to a project staging with several workers collaborating on this project. Then lets say user A performs some runs offline and now wants to sync them to the project, then A would want to first retrieve the value of the \u201ccount\u201d variable, assign it or tag it to all his runs and then sync them and finally increment \u201ccount\u201d for the project. Now if user B wants to start his experiments he  should be able to retrieve the current \u201ccount\u201d value assign it to his set runs before syncing  them, I would really appreciate any help on what would be the best way to achieve this.<br>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrating W&B with Lightning CLI",
        "Question_link":"https:\/\/community.wandb.ai\/t\/integrating-w-b-with-lightning-cli\/4190",
        "Question_created_time":"2023-04-05T19:26:24.789Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":142,
        "Question_body":"<p>I\u2019m using the PyTorch Lightning CLI, with code that looks like this<\/p>\n<pre><code class=\"lang-auto\">def main():\n    cli = CLI(model class, data module)\n\nif __name__ == \"__main__\":\n    main()\n\n<\/code><\/pre>\n<p>To launch, I do something like this:<\/p>\n<pre><code class=\"lang-auto\">python -u main.py fit \n<\/code><\/pre>\n<p>I saw you can integrate it with the PT Lightning <a href=\"https:\/\/wandb.ai\/manan-goel\/MNIST\/reports\/How-to-Integrate-PyTorch-Lightning-with-Weights-Biases--VmlldzoxNjg1ODQ1\">trainer<\/a>, but I\u2019m not sure how to integrate it with the CLI. How can one do this?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the correct way to resume a paused or crashed run?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-is-the-correct-way-to-resume-a-paused-or-crashed-run\/4196",
        "Question_created_time":"2023-04-07T21:59:40.888Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":176,
        "Question_body":"<p>Hi I am new to using WandB. I have my project setup with Tensorflow and am logging to WandB by syncing my Tensorboard <code>wandb.init(project='my-project', sync_tensorboard=True)<\/code>.<\/p>\n<p>Sometimes this run may crash or I have to pause the run to retrieve certain artifacts. Then when the run reinitiates how do I ensure that this is not logged as a new run in WandB? but instead just a continuation of the previous one. The step counters also seem to be reset when this happens, even though the step counters are accurate in tensorboard<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"BrokenPipeError on Ubuntu machine",
        "Question_link":"https:\/\/community.wandb.ai\/t\/brokenpipeerror-on-ubuntu-machine\/4117",
        "Question_created_time":"2023-03-24T09:28:14.773Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":295,
        "Question_body":"<p>A VAE built using PyTorch runs smoothly when I train it directly. However, with wandb sweeps, I encounter the following BrokerPipeError. According to some forum threads, the main cause seems to be the more than one <code>num_workers<\/code> in the DataLoader module when running on Windows OS. However, I have a DGX-station running Ubuntu, and I still get the error.<\/p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"\/opt\/conda\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"\/opt\/conda\/lib\/python3.8\/threading.py\", line 870, in run\n    Exception in thread self._target(*self._args, **self._kwargs)NetStatThr\n:\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 276, in check_stop_status\nTraceback (most recent call last):\n  File \"\/opt\/conda\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n    self._loop_check_status(\n      File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 214, in _loop_check_status\nself.run()\n  File \"\/opt\/conda\/lib\/python3.8\/threading.py\", line 870, in run\n    local_handle = request()\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 787, in deliver_stop_status\n    self._target(*self._args, **self._kwargs)\nreturn self._deliver_stop_status(status)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 258, in check_network_status\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 585, in _deliver_stop_status\n    self._loop_check_status(\nreturn self._deliver_record(record)  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 214, in _loop_check_status\n\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 560, in _deliver_record\n    handle = mailbox._deliver_record(record, interface=self)\n    local_handle = request()  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 455, in _deliver_record\n\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 795, in deliver_network_status\n    interface._publish(record)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 221, in send_record_publish\n    return self._deliver_network_status(status)\n      File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 601, in _deliver_network_status\nself.send_server_request(server_req)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 152, in _send_message\n    return self._deliver_record(record)\n      File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 560, in _deliver_record\nself._sendall_with_error_handle(header + data)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 130, in _sendall_with_error_handle\n    handle = mailbox._deliver_record(record, interface=self)\nsent = self._sock.send(data)  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 455, in _deliver_record\n\nBrokenPipeError: [Errno 32] Broken pipe\n    interface._publish(record)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n<\/code><\/pre>\n<p>Any help would be greatly appreciated. Thank you in advance!<\/p>",
        "Question_closed_time":"2023-04-06T19:01:16.343Z",
        "Answer_body":"<p>Hello! Looks like it there is a Connection issue between your machine and the <code>wandb<\/code> server. Is there a load balancer, a VPN, or a proxy that your machine is behind that may be blocking the connection? The reason I ask is because  <code>sent = self._sock.send(data)<\/code>  is the main error in the stack trace which means that the client is struggling to send data to the server.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Stable Baselines3: Recording Video and uploading it to WandB",
        "Question_link":"https:\/\/community.wandb.ai\/t\/stable-baselines3-recording-video-and-uploading-it-to-wandb\/4179",
        "Question_created_time":"2023-04-04T07:13:34.213Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":96,
        "Question_body":"<p>Hello Community,<\/p>\n<p>I am using the Stable Baslines3 integration and my goal is to record videos of every Nth rollout. I want those videos to appear in my WandB dashboard. I followed the instructions here: <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/stable-baselines-3\" class=\"inline-onebox\">Stable Baselines 3 | Weights &amp; Biases Documentation<\/a> and also watched the YT workshop talking about the WandB integration. However, I am still not able to see the recorded videos in my dashboard. The videos are recorded and saved to my local machine, but they are never uploaded. What might be the issue here? Could you provide me with an example?<br>\nAlso if anyone is experienced with stable baslines3 it would be very helpful if you could tell me how to best record videos every Nth rollout (the default is that you record the video every Nth timestep for a fixed amount of steps.) I want to record a video every Nth rollout till the done signal is reached (not a fixed length of steps).<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: Network error (ConnectTimeout), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-network-error-connecttimeout-entering-retry-loop\/4162",
        "Question_created_time":"2023-04-01T00:38:21.318Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":398,
        "Question_body":"<p>my code :<\/p>\n<pre><code class=\"lang-auto\">import wandb\nfor x in range(10):\n    run = wandb.init(settings=wandb.Settings(start_method=\"thread\"))\n    for y in range (100):\n        wandb.log({\"metric\": x+y})\n    run.finish()\n<\/code><\/pre>\n<p>output:<\/p>\n<pre><code class=\"lang-auto\">wandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.14.0\nwandb: Run data is saved locally in \/home\/xyc\/Code\/RumorDG\/method\/CDCL\/wandb\/run-20230401_083434-fi3tttps\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run clear-firebrand-1\nwandb: \u2b50\ufe0f View project at https:\/\/wandb.ai\/moailaozi\/uncategorized\nwandb: \ud83d\ude80 View run at https:\/\/wandb.ai\/moailaozi\/uncategorized\/runs\/fi3tttps\nwandb: Waiting for W&amp;B process to finish... (success).\nwandb: Network error (ConnectTimeout), entering retry loop.\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: ERROR Run xxjba37s errored: FileNotFoundError(2, 'No such file or directory')",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-run-xxjba37s-errored-filenotfounderror-2-no-such-file-or-directory\/4129",
        "Question_created_time":"2023-03-26T08:21:00.483Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":195,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use sweeps for the first time, I am having this issue.<\/p>\n<p>after exceuting wandb.agent(sweep_id, function=wandb_train_func, count=1), this is the output:<\/p>\n<p>Create sweep with ID: lg85skzc Sweep URL: <a href=\"https:\/\/wandb.ai\/victoreduardo-fonsecamedina\/KNN_1st_attempt\/sweeps\/lg85skzc\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>wandb: Agent Starting Run: xxjba37s with config: wandb: batch_size: 3 wandb: learning_rate: 0.03880829630118215 wandb: momentum: 0.925717097296538 wandb: num_epochs: 10 wandb: optimizer: sgd wandb: WARNING Ignored wandb.init() arg project when running a sweep. wandb: WARNING Ignored wandb.init() arg entity when running a sweep.<\/p>\n<p>Tracking run with wandb version 0.14.0<\/p>\n<p>Run data is saved locally in <code>\/ibex\/scratch\/fonsecv\/Machine_Learning_Course\/Notebooks\/KNN\/wandb\/run-20230325_172833-xxjba37s<\/code><\/p>\n<p>Waiting for W&amp;B process to finish\u2026 <strong>(failed 1).<\/strong> Press Control-C to abort syncing.<\/p>\n<p>View run <strong>KNN_1<\/strong> at: <a href=\"https:\/\/wandb.ai\/victoreduardo-fonsecamedina\/KNN_1st_attempt\/runs\/xxjba37s\" class=\"inline-onebox\">Weights &amp; Biases<\/a><br>\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)<\/p>\n<p>Find logs at: <code>.\/wandb\/run-20230325_172833-xxjba37s\/logs<\/code><\/p>\n<p>wandb: ERROR Run xxjba37s errored: FileNotFoundError(2, \u2018No such file or directory\u2019)<\/p>\n<p>I don\u2019t know which file or directory is the error referring to.<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Will each agent always use the same seed?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/will-each-agent-always-use-the-same-seed\/4138",
        "Question_created_time":"2023-03-28T15:07:49.172Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":62,
        "Question_body":"<p>if I use wandb with sweeps and run an agent with 10 counts but my config file has the same hyperparams, will it also use the same seed?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I select a GPU before running a wandb agent?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-select-a-gpu-before-running-a-wandb-agent\/4135",
        "Question_created_time":"2023-03-27T16:28:00.682Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":284,
        "Question_body":"<p>I wanted to run a set of wandb agents but the server that I have access to does not have slurm or any workload manager. How do I have the agent code select an CUDA_VISIBLE_DEVICE automatically according to the gpu memory I need and is available?<\/p>\n<p>I was going to do something hacky like a while loop that checked with a memory error happened after looping all GPUs or the total number of agents the user desired was reached. But was hoping to avoid doing this since this seems the entire reason I am using wandb in the first place.<\/p>\n<hr>\n<p>Some started code<\/p>\n<pre><code class=\"lang-auto\">\"\"\"\nMain Idea:\n- create sweep with a sweep config &amp; get sweep_id for the agents (note, this creates a sweep in wandb's website)\n- create agent to run a setting of hps by giving it the sweep_id (that mataches the sweep in the wandb website)\n- keep running agents with sweep_id until you're done\n\nnote:\n    - Each individual training session with a specific set of hyperparameters in a sweep is considered a wandb run.\n\nref:\n    - read: https:\/\/docs.wandb.ai\/guides\/sweeps\n\"\"\"\n\nimport wandb\nfrom pprint import pprint\nimport math\nimport torch\n\nsweep_config: dict = {\n    \"project\": \"playground\",\n    \"entity\": \"your_wanbd_username\",\n    \"name\": \"my-ultimate-sweep\",\n    \"metric\":\n        {\"name\": \"train_loss\",\n         \"goal\": \"minimize\"}\n    ,\n    \"method\": \"random\",\n    \"parameters\": None,  # not set yet\n}\n\nparameters = {\n    'optimizer': {\n        'values': ['adam', 'adafactor']}\n    ,\n    'scheduler': {\n        'values': ['cosine', 'none']}  # todo, think how to do\n    ,\n    'lr': {\n        \"distribution\": \"log_uniform_values\",\n        \"min\": 1e-6,\n        \"max\": 0.2}\n    ,\n    'batch_size': {\n        # integers between 32 and 256\n        # with evenly-distributed logarithms\n        'distribution': 'q_log_uniform_values',\n        'q': 8,\n        'min': 32,\n        'max': 256,\n    }\n    ,\n    # it's often the case that some hps we don't want to vary in the run e.g. num_its\n    'num_its': {'value': 5}\n}\nsweep_config['parameters'] = parameters\npprint(sweep_config)\n\n# create sweep in wandb's website &amp; get sweep_id to create agents that run a single agent with a set of hps\nsweep_id = wandb.sweep(sweep_config)\nprint(f'{sweep_id=}')\n\n\ndef my_train_func():\n    # read the current value of parameter \"a\" from wandb.config\n    # I don't think we need the group since the sweep name is already the group\n    run = wandb.init(config=sweep_config)\n    print(f'{run=}')\n    pprint(f'{wandb.config=}')\n    lr = wandb.config.lr\n    num_its = wandb.config.num_its\n\n    train_loss: float = 8.0 + torch.rand(1).item()\n    for i in range(num_its):\n        # get a random update step from the range [0.0, 1.0] using torch\n        update_step: float = lr * torch.rand(1).item()\n        wandb.log({\"lr\": lr, \"train_loss\": train_loss - update_step})\n    run.finish()\n\n\n# run the sweep, The cell below will launch an agent that runs train 5 times, usingly the randomly-generated hyperparameter values returned by the Sweep Controller.\nwandb.agent(sweep_id, function=my_train_func, count=5)\n<\/code><\/pre>\n<p>cross: <a href=\"https:\/\/stackoverflow.com\/questions\/75858165\/how-do-i-select-a-gpu-before-running-a-wandb-agent\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How do I select a GPU before running a wandb agent? - Stack Overflow<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Editing code during sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/editing-code-during-sweep\/4161",
        "Question_created_time":"2023-03-31T21:00:24.976Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":62,
        "Question_body":"<p>I was curious about the expected behavior if code is modified during a sweep. It would seem that since each run is launched from the command line that python would re-compile my code for each of those runs. Therefore, if I changed code during a sweep, the next run that starts will use the new code. Is that correct?<\/p>\n<p>My particular use case is that I would like to launch a large sweep and, while that is running, work on my codebase - potentially in a different git branch than the one I launched the sweep from.<\/p>\n<p>Any clarification on how sweeps (and runs) interact with the codebase during runs would be appreciated.<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb fails at init (assert ports_found)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-fails-at-init-assert-ports-found\/3446",
        "Question_created_time":"2022-11-21T05:08:28.866Z",
        "Question_answer_count":7,
        "Question_score_count":3,
        "Question_view_count":1905,
        "Question_body":"<p>Hello,<\/p>\n<p>I am running into an inconsistent issue where some of my training runs (the exact same code run twice) fail. I get the following error:<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1040, in init\n    wi.setup(kwargs)\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 151, in setup\n    self._wl = wandb_setup.setup()\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 320, in setup\n    ret = _setup(settings=settings)\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 315, in _setup\n    wl = _WandbSetup(settings=settings)\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 301, in __init__\n    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 114, in __init__\n    self._setup()\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 242, in _setup\n    self._setup_manager()\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 273, in _setup_manager\n    self._manager = wandb_manager._Manager(\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_manager.py\", line 106, in __init__\n    self._service.start()\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/service\/service.py\", line 106, in start\n    self._launch_server()\n  File \"\/project_dir\/lib\/python3.9\/site-packages\/wandb\/sdk\/service\/service.py\", line 102, in _launch_server\n    assert ports_found\nAssertionError\n<\/code><\/pre>\n<p>Unfortunately, this error occurs before a folder is created in <code>\/project_dir\/wandb\/<\/code>, and as a result I cannot find a more descriptive error message in <code>debug-internal.log<\/code>. As mentioned, this issue only periodically happens. My code is being run on a compute cluster.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tensorboard sync shows incorrect number of steps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorboard-sync-shows-incorrect-number-of-steps\/881",
        "Question_created_time":"2021-10-07T14:37:22.784Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":318,
        "Question_body":"<p>Hello!<\/p>\n<p>I have observed a strange behavior when synchronizing tensorboard runs. Two runs have different lengths in steps when uploaded on wandb. And both are wrong. They are probably different due to multiprocessing. Although, if I open the tensorboard tab in the wandb interface it shows both results correctly.<\/p>\n<p>I can provide the files if I figure out how to attach them here. Or should I upload it somewhere else?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Mention a member on report not available",
        "Question_link":"https:\/\/community.wandb.ai\/t\/mention-a-member-on-report-not-available\/4097",
        "Question_created_time":"2023-03-22T12:34:04.060Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":78,
        "Question_body":"<p>Hi, I have a report created within a team and I cannot mention members on a comment.<br>\nThe sentence \u201c@ to mention a user\u201d does not appear.<br>\nHow so?<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/108393fb2785ee51505faae38fd4a433ab622848.png\" alt=\"Screenshot 2023-03-22 at 12.47.54\" data-base62-sha1=\"2m5xJUrxAoEP6UK6xEvumbFKuY8\" width=\"405\" height=\"307\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to watch the activations of a model?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-watch-the-activations-of-a-model\/4101",
        "Question_created_time":"2023-03-22T19:32:51.262Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":92,
        "Question_body":"<p>I feel divergence is better predicted by activations (or update step) than weights or gradients. How to watch that?<\/p>\n<p>ref: <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/5218\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[Feature]: watch activations &amp; update value, besides weights and gradients \u00b7 Issue #5218 \u00b7 wandb\/wandb \u00b7 GitHub<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I wonder if the utility to aggregate over multiple seeds was added or not in later releases",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-wonder-if-the-utility-to-aggregate-over-multiple-seeds-was-added-or-not-in-later-releases\/4169",
        "Question_created_time":"2023-04-02T22:57:29.445Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":63,
        "Question_body":"<p>Based on this question posted 2 years back : <a href=\"https:\/\/community.wandb.ai\/t\/sweeps-with-multiple-seeds-for-the-same-config-values\/1077\">Sweeps with multiple seeds for the same config values<\/a>, I wonder if the utility to sweep over different parameters meanwhile also being able to aggregate over different seeds was added to wandb or not. If yes, is there a tutorial\/helper link which I can follow to use this facility.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Could not add summary columns for display in Table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/could-not-add-summary-columns-for-display-in-table\/3841",
        "Question_created_time":"2023-02-08T04:57:53.139Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":226,
        "Question_body":"<p>Related: <a href=\"https:\/\/community.wandb.ai\/t\/unable-to-manage-columns-in-project-run-table\/3551\/4\" class=\"inline-onebox\">Unable to manage columns in project run table - #4 by artsiom<\/a><\/p>\n<p>I was unable to make step metric columns visible in the Table view. I tried logging metrics both via <code>run.log<\/code> and <code>wandb.log<\/code>, as well as refreshing the page in my browser. When attempting to drag and drop a column name from \u201cHidden Columns\u201d to \u201cVisible Columns\u201d (see the screenshot), a gap is created, but on mouse release the column name returns to \u201cHidden Columns\u201d. Clicking on column names to move them to \u201cVisible\u201d does not work either. The logged values appear in the web interface elsewhere. Manipulation with non-metric columns (e.g. config values, name, state etc) worked flawlessly as expected.<\/p>\n<p>The problem remained <em>for a fraction of a minute<\/em> after I logged a summary metric using <code>wandb.summary[...] = ...<\/code>. In particular, I tried moving all columns by pressing \u201cShow all\u201d, but without any visible result, and I closed the pop-up (on the screenshot). Suddenly, after 10 or so seconds, all columns became visible.<\/p>\n<p>The problem is similar to the one in the linked post. Unlike there, in my case, refreshing the web-page did not seem to help. I\u2019ll take a wild guess and suggest possible reasons for the bug:<\/p>\n<ol>\n<li>Something was going on in your back-end, and I had to wait till all necessary data validation or calculations are completed that would enable adding metric columns. This is unacceptably long time (several minutes), within which I was able to read relevant reference, search issues, and do a couple of empty test runs to see what\u2019s going on.<\/li>\n<li>There is a bug which prevents conversion step metrics to summary metrics unless at least one summary metric is explicitly added via <code>wandb.summary<\/code>.<\/li>\n<\/ol>\n<p>I hope you will be able to get to the bottom of it and fix it.<\/p>\n<p>I hope this helps.<\/p>\n<p>Regards,<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2ee6cd9cf398c018ac88a42196119a096fc12763.png\" data-download-href=\"\/uploads\/short-url\/6GUslld1E38x1uAv9m6acBIMSwH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2ee6cd9cf398c018ac88a42196119a096fc12763.png\" alt=\"image\" data-base62-sha1=\"6GUslld1E38x1uAv9m6acBIMSwH\" width=\"518\" height=\"500\" data-dominant-color=\"F7F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">667\u00d7643 8.92 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2023-02-10T20:51:21.055Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/avm21\">@avm21<\/a> , I\u2019ve been able to to consistently  reproduce this behavior on my end and flagged it as a bug. I will update you on a timeline for a fix once I have additional info. Thanks again for the insight!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Parse additional arguments to the program when running the wandb agent command from the command line",
        "Question_link":"https:\/\/community.wandb.ai\/t\/parse-additional-arguments-to-the-program-when-running-the-wandb-agent-command-from-the-command-line\/4010",
        "Question_created_time":"2023-03-06T20:09:58.859Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":348,
        "Question_body":"<p>Is it possible to parse additional arguments to the program when running the wandb agent command from the command line?<\/p>\n<p>For example, suppose I have a script <code>train.py<\/code> that takes a <code>--gpu_idx<\/code> argument to specify the GPU index, and I want to run the script with different GPUs using the WandB agent. Can I pass the <code>--gpu_idx<\/code> argument as a key-value pair when running the <code>wandb agent<\/code> command?<\/p>\n<p><code>wandb agent &lt;ID&gt;  --gpu_idx 1<\/code><\/p>\n<p>In the training script, I have something like:<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu_idx', type=int, default=1)\nargs = parser.parse_args()\n\nwandb.init()\nwandb.config.update(args)\n\n# train model with the learning rate\n<\/code><\/pre>",
        "Question_closed_time":"2023-03-20T20:37:48.277Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/liu97\">@liu97<\/a> thanks for the additional context. In that case you won\u2019t be able to do this as you will be using the same <code>yaml<\/code> for all agents. What you could do though in a multi-gpu environment is to specify the GPU as follows:<\/p>\n<pre><code class=\"lang-auto\">CUDA_VISIBLE_DEVICES=0 wandb agent sweep_ID\n<\/code><\/pre>\n<p>Would this work for you? Please also check <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/parallelize-agents#parallelize-on-a-multi-gpu-machine\">this docs page<\/a> for more information.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Sweeps: Waiting for W&B process to finish... (failed 1)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweeps-waiting-for-w-b-process-to-finish-failed-1\/4012",
        "Question_created_time":"2023-03-07T03:01:12.571Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":653,
        "Question_body":"<p>Hi everyone,<br>\nI am trying to sweep my hyperparameters for my TensorFlow model. I am using Bayes as the sweeping method.<\/p>\n<p>In my <code>train()<\/code> function, I have several <code>.fit()<\/code> methods as I am training a progressive GAN and I am required to call <code>model.fit()<\/code> several times.<\/p>\n<p>After completing the first <code>model.fit()<\/code> successfully, the error<\/p>\n<pre><code class=\"lang-auto\">Waiting for W&amp;B process to finish... (failed 1)\n<\/code><\/pre>\n<p>What should I do?<\/p>\n<p>I followed this tutorial here to use Wandb sweeps: <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/tensorflow\/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb#scrollTo=_7eXIA019vAG\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab<\/a><\/p>\n<p>And here is a look at my <code>sweep_train()<\/code> function:<\/p>\n<pre><code class=\"lang-auto\">def sweep_train(config_defaults=None):\n\n    # Initialize wandb with a sample project name\n    run = wandb.init(config=config_defaults, resume=True)  \n    \n    pgan = PGAN(latent_dim = NOISE_DIM, d_steps =  wandb.config.D_STEPS)\n    \n\n    cbk = GANMonitor(num_img = NUM_IMGS_GENERATE, latent_dim = NOISE_DIM)\n\n    cbk.set_steps(steps_per_epoch = STEPS_PER_EPOCH, epochs = wandb.config.EPOCHS) # 110, 6\n    cbk.set_prefix(prefix='0_init')\n\n    \n    \n    train(wandb.config.G_LR, wandb.config.D_LR, wandb.config.R_LR, wandb.config.EPOCHS, wandb.config.D_STEPS, cbk, pgan)\n\n    run.finish()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I print the wandb sweep url in python?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-print-the-wandb-sweep-url-in-python\/4133",
        "Question_created_time":"2023-03-27T04:42:56.317Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":227,
        "Question_body":"<p>For runs I do:<\/p>\n<pre><code class=\"lang-auto\">wandb.run.get_url()\n<\/code><\/pre>\n<p>how do I do the same but for sweeps given the <code>sweep_id<\/code>?<\/p>\n<hr>\n<p>fulls sample run:<\/p>\n<pre><code class=\"lang-auto\">\"\"\"\nMain Idea:\n- create sweep with a sweep config &amp; get sweep_id for the agents (note, this creates a sweep in wandb's website)\n- create agent to run a setting of hps by giving it the sweep_id (that mataches the sweep in the wandb website)\n- keep running agents with sweep_id until you're done\n\nnote:\n    - Each individual training session with a specific set of hyperparameters in a sweep is considered a wandb run.\n\nref:\n    - read: https:\/\/docs.wandb.ai\/guides\/sweeps\n\"\"\"\n\nimport wandb\nfrom pprint import pprint\nimport math\nimport torch\n\nsweep_config: dict = {\n    \"project\": \"playground\",\n    \"entity\": \"your_wanbd_username\",\n    \"name\": \"my-ultimate-sweep\",\n    \"metric\":\n        {\"name\": \"train_loss\",\n         \"goal\": \"minimize\"}\n    ,\n    \"method\": \"random\",\n    \"parameters\": None,  # not set yet\n}\n\nparameters = {\n    'optimizer': {\n        'values': ['adam', 'adafactor']}\n    ,\n    'scheduler': {\n        'values': ['cosine', 'none']}  # todo, think how to do\n    ,\n    'lr': {\n        \"distribution\": \"log_uniform_values\",\n        \"min\": 1e-6,\n        \"max\": 0.2}\n    ,\n    'batch_size': {\n        # integers between 32 and 256\n        # with evenly-distributed logarithms\n        'distribution': 'q_log_uniform_values',\n        'q': 8,\n        'min': 32,\n        'max': 256,\n    }\n    ,\n    # it's often the case that some hps we don't want to vary in the run e.g. num_its\n    'num_its': {'value': 5}\n}\nsweep_config['parameters'] = parameters\npprint(sweep_config)\n\n# create sweep in wandb's website &amp; get sweep_id to create agents that run a single agent with a set of hps\nsweep_id = wandb.sweep(sweep_config)\nprint(f'{sweep_id=}')\n\n\ndef my_train_func():\n    # read the current value of parameter \"a\" from wandb.config\n    # I don't think we need the group since the sweep name is already the group\n    run = wandb.init(config=sweep_config)\n    print(f'{run=}')\n    pprint(f'{wandb.config=}')\n    lr = wandb.config.lr\n    num_its = wandb.config.num_its\n\n    train_loss: float = 8.0 + torch.rand(1).item()\n    for i in range(num_its):\n        # get a random update step from the range [0.0, 1.0] using torch\n        update_step: float = lr * torch.rand(1).item()\n        wandb.log({\"lr\": lr, \"train_loss\": train_loss - update_step})\n    run.finish()\n\n\n# run the sweep, The cell below will launch an agent that runs train 5 times, usingly the randomly-generated hyperparameter values returned by the Sweep Controller.\nwandb.agent(sweep_id, function=my_train_func, count=5)\n<\/code><\/pre>\n<p>cross: <a href=\"https:\/\/stackoverflow.com\/questions\/75852199\/how-do-i-print-the-wandb-sweep-url-in-python\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">machine learning - How do I print the wandb sweep url in python? - Stack Overflow<\/a><\/p>",
        "Question_closed_time":"2023-03-27T16:27:29.666Z",
        "Answer_body":"<p>like <code>wandb.get_sweep_url()<\/code>? Thanks!<\/p>\n<p><a href=\"https:\/\/docs.wandb.ai\/ref\/python\/run?_gl=1*uk130d*_ga*MTYwMTE3MDYzNS4xNjUyMjI2MTE1*_ga_JH1SJHJQXJ*MTY4MDAxNTk2Ny4yNjguMS4xNjgwMDE2MTMyLjQ3LjAuMA\" class=\"inline-onebox\">Run | Weights &amp; Biases Documentation<\/a>\u2026<span class=\"hashtag\">#get_sweep_url<\/span><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Confused about wandb launch usage with docker",
        "Question_link":"https:\/\/community.wandb.ai\/t\/confused-about-wandb-launch-usage-with-docker\/4119",
        "Question_created_time":"2023-03-24T13:34:34.173Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_body":"<p>Sorry if this is covered by docs  couldn\u2019t understand something about wandb jobs (wandb launch);<\/p>\n<p>Basically, does the Dockerfile itself must have an <code>Entrypoint<\/code> attr, which runs a program? Or is it enough to have a docker image which has WANDB_DOCKER, wandb_api_key env variable set, having a python directory codebase which can start wandb runs?? (can\u2019t create a job this way though\u2026), if possible without logging the code.<\/p>",
        "Question_closed_time":"2023-03-24T21:12:02.111Z",
        "Answer_body":"<p>Cleared:<br>\nYeah, the Dockerfile should be complete end to end such that just running the docker file should run the program, it must have <code>Entrypoint<\/code> attr in the Dockerfile, which actually can be changed from the overrides when we pass it to queue.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"How to enable logging of each trial separately?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-enable-logging-of-each-trial-separately\/4115",
        "Question_created_time":"2023-03-24T08:25:15.454Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":115,
        "Question_body":"<p>Within my optuna study, I want that each trial is separately logged by wandb. Currently, the study is run and the end result is tracked in my wandb dashboard. Instead of showing each trial run separately, the end result over all epochs is shown. So, wandb makes one run out of multiple runs.<\/p>\n<p>I found the following <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/_modules\/optuna\/integration\/wandb.html\" rel=\"noopener nofollow ugc\">docs<\/a> in optuna:<\/p>\n<pre><code>Weights &amp; Biases logging in multirun mode.\n\n    .. code::\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">            import optuna\n            from optuna.integration.wandb import WeightsAndBiasesCallback\n\n            wandb_kwargs = {\"project\": \"my-project\"}\n            wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs, as_multirun=True)\n\n\n            @wandbc.track_in_wandb()\n            def objective(trial):\n                x = trial.suggest_float(\"x\", -10, 10)\n                return (x - 2) ** 2\n\n\n            study = optuna.create_study()\n            study.optimize(objective, n_trials=10, callbacks=[wandbc])\n\n<\/code><\/pre>\n<p>I implemented this line of code yet it produces the following error:<\/p>\n<p><code>ConfigError: Attempted to change value of key \"learning_rate\" from 5e-05 to     0.0005657929921495451 If you really want to do this, pass allow_val_change=True to config.update()    wandb: Waiting for W&amp;B process to finish... (failed 1).<\/code><\/p>\n<p>Did anyone succeed in implementing logging per trial in a multi-trial study?<\/p>",
        "Question_closed_time":"2023-03-24T09:38:02.813Z",
        "Answer_body":"<p>I actually solved it now:<br>\nIt seems that the optimizer that i used caused errors in the generation of a value for the learning rate when starting a new trial. Once I took the optimizer back out, the follwing implementation worked and generated separate logs in my wandb dashboard:<\/p>\n<pre><code class=\"lang-auto\">wandb_kwargs = {\"project\": \"my-project\"}\nwandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs, as_multirun=True)\n\n@wandbc.track_in_wandb()\ndef objective(trial):\n    \n    training_args = Seq2SeqTrainingArguments( \n        \"tuning\", \n        num_train_epochs=1,            \n        # num_train_epochs = trial.suggest_categorical('num_epochs', [3, 5, 8]),\n        per_device_eval_batch_size=3, \n        per_device_train_batch_size=3, \n        learning_rate=  trial.suggest_float('learning_rate', low=0.00004, high=0.0001, step=0.0005, log=False),             \n        # per_device_train_batch_size= trial.suggest_categorical('batch_size', [6, 8, 12, 18]),       \n        # per_device_eval_batch_size= trial.suggest_categorical('batch_size', [6, 8, 12, 18]),  \n        disable_tqdm=True, \n        predict_with_generate=True,\n        gradient_accumulation_steps=4,\n        # gradient_checkpointing=True,\n        # weight_decay= False\n        seed = 12, \n        warmup_steps=5,\n        # evaluation and logging\n        evaluation_strategy = \"epoch\",\n        save_strategy = \"epoch\",\n        save_total_limit=1,\n        logging_strategy=\"epoch\",\n        logging_steps = 1, \n        load_best_model_at_end=True,\n        metric_for_best_model = \"eval_loss\",\n        # use_cache=False,\n        push_to_hub=False,\n        fp16=False,\n        remove_unused_columns=True\n    )\n    # optimizer = Adafactor(\n    #     t5dmodel.parameters(),\n    #     lr=trial.suggest_float('learning_rate', low=4e-5, high=0.0001),  #   ('learning_rate', 1e-6, 1e-3),\n    #     # weight_decay=trial.suggest_float('weight_decay', WD_MIN, WD_CEIL),   \n    #     # lr=1e-3,\n    #     eps=(1e-30, 1e-3),\n    #     clip_threshold=1.0,\n    #     decay_rate=-0.8,\n    #     beta1=None,\n    #     # weight_decay= False\n    #     weight_decay=0.1,\n    #     relative_step=False,\n    #     scale_parameter=False,\n    #     warmup_init=False,\n    # )\n    \n    # lr_scheduler = AdafactorSchedule(optimizer)\n    data_collator = DataCollatorForSeq2Seq(tokenizer, model=t5dmodel)\n    trainer = Seq2SeqTrainer(model=t5dmodel,\n                            args=training_args,\n                            train_dataset=tokenized_train_dataset['train'],\n                            eval_dataset=tokenized_val_dataset['validation'],\n                            data_collator=data_collator,\n                            tokenizer=tokenizer,\n                           #  optimizers=(optimizer, lr_scheduler)\n                            )       \n    \n    trainer.train()\n    scores = trainer.evaluate() \n    return scores['eval_loss']\n\nif __name__ == '__main__':\n    t5dmodel = AutoModelForSeq2SeqLM.from_pretrained(\"yhavinga\/t5-base-dutch\",  use_cache=False) \n    tokenizer = AutoTokenizer.from_pretrained(\"yhavinga\/t5-base-dutch\", additional_special_tokens=None)\n    \n    features = {\n    'WordRatioFeature': {'target_ratio': 0.8},\n    'CharRatioFeature': {'target_ratio': 0.8},\n    'LevenshteinRatioFeature': {'target_ratio': 0.8},\n    'WordRankRatioFeature': {'target_ratio': 0.8},\n    'DependencyTreeDepthRatioFeature': {'target_ratio': 0.8}\n    }\n    \n    trainset_processed = get_train_data(WIKILARGE_PROCESSED, 0, 10)  \n    print(trainset_processed)\n    valset_processed = get_validation_data(WIKILARGE_PROCESSED, 0,7)\n    print(valset_processed)\n    tokenized_train_dataset = trainset_processed.map((tokenize_train), batched=True, batch_size=1)\n    tokenized_val_dataset =  valset_processed.map((tokenize_train), batched=True, batch_size=1)   \n    print('Triggering Optuna study')\n    study = optuna.create_study( direction='minimize', pruner=optuna.pruners.MedianPruner()) \n    study.optimize(objective, n_trials=4,callbacks=[wandbc],  gc_after_trial=True)\n<\/code><\/pre>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Histogram produced by wandb.plot.histogram is incorrect",
        "Question_link":"https:\/\/community.wandb.ai\/t\/histogram-produced-by-wandb-plot-histogram-is-incorrect\/4113",
        "Question_created_time":"2023-03-24T06:25:32.422Z",
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":71,
        "Question_body":"<p>I am trying to plot a histogram over a score I am computing. I followed these guidelines to log a single histogram at the end of training:<\/p>\n<ul>\n<li><a href=\"https:\/\/wandb.ai\/wandb\/plots\/reports\/Creating-Custom-Histograms-With-Weights-Biases--VmlldzoyNzE0NzM\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/li>\n<li><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots\" class=\"inline-onebox\">Log and Track Plots from W&amp;B Experiments.<\/a><\/li>\n<\/ul>\n<p>The underlying data table is correctly uploaded to my run but the displayed histogram (figure left side) is clearly wrong as verified by both Excel (figure top right side) and matplotlib (figure bottom right side).<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/52885b1751484d6ea113becd22b13762ef119f60.jpeg\" data-download-href=\"\/uploads\/short-url\/bM7icxbxnxRxjaK1cAFVeOkdgmQ.jpeg?dl=1\" title=\"Screenshot 2023-03-24 at 2.24.38 AM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52885b1751484d6ea113becd22b13762ef119f60_2_690x357.jpeg\" alt=\"Screenshot 2023-03-24 at 2.24.38 AM\" data-base62-sha1=\"bM7icxbxnxRxjaK1cAFVeOkdgmQ\" width=\"690\" height=\"357\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52885b1751484d6ea113becd22b13762ef119f60_2_690x357.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52885b1751484d6ea113becd22b13762ef119f60_2_1035x535.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52885b1751484d6ea113becd22b13762ef119f60_2_1380x714.jpeg 2x\" data-dominant-color=\"97A6B5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-03-24 at 2.24.38 AM<\/span><span class=\"informations\">1920\u00d7994 73.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any hints towards debugging this would be highly appreciated!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Even though I'm active in university, I'm blocked by the 250 hour limit",
        "Question_link":"https:\/\/community.wandb.ai\/t\/even-though-im-active-in-university-im-blocked-by-the-250-hour-limit\/4152",
        "Question_created_time":"2023-03-29T20:32:35.857Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":60,
        "Question_body":"<p>Hi, currently experiencing restrictions due to 250 hour tracking.<\/p>\n<aside class=\"quote\" data-post=\"1\" data-topic=\"4029\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/v\/f6c823\/40.png\" class=\"avatar\">\n    <a href=\"https:\/\/community.wandb.ai\/t\/how-to-delete-a-project-in-an-organization-that-has-exceeded-the-250-hour-limit\/4029\">How to delete a project in an organization that has exceeded the 250 hour limit?<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/w-b-support\/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at support@wandb.com\">W&amp;B Help<\/span><\/a>\n  <\/div>\n  <blockquote>\n    I have an organization that has exceeded the 250 hour limit. I am trying to go into the organization, to delete \nan old project so I can stop exceeding the limit. But it looks like the UI is not letting me. \nIs there a way I delete old projects in my organization to go back under the limit?\n  <\/blockquote>\n<\/aside>\n\n<p>Looking at it here, I know that I can use it as free if it\u2019s a student account, but I wonder if it\u2019s possible to check it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tensorflow + Transformers Hyperparameter Sweeping Example(s)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorflow-transformers-hyperparameter-sweeping-example-s\/4121",
        "Question_created_time":"2023-03-24T18:50:36.386Z",
        "Question_answer_count":4,
        "Question_score_count":3,
        "Question_view_count":88,
        "Question_body":"<p>Hello all,<\/p>\n<p>I followed along with the new MLOps course and I am trying to adapt what I learned there to a different framework\/scenario. I am working with a sequence-to-sequence transformer model (NLP), utilizing Tensorflow as the framework. I am at the point where I would like to leverage a sweep to optimize hyperparameters. I am struggling to find a good example. Can anyone point me to something that is close to what I am trying to achieve? Mainly how to perform sweeps with TF and then I can go from there. Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"With TB SummaryWriter only getting sys logs, no log_scalar shows up",
        "Question_link":"https:\/\/community.wandb.ai\/t\/with-tb-summarywriter-only-getting-sys-logs-no-log-scalar-shows-up\/4089",
        "Question_created_time":"2023-03-21T17:31:01.821Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":119,
        "Question_body":"<p>I have an OS stable diffusion fine tuner and use Tensorboard locally and am trying to integrate wandb with existing code that is largely just calling writer.log_scalar(\u2026).  I setup my SummaryWriter then call wandb.init, but I\u2019m having all sorts of odd behavior where most of the time only system monitors (gpu temp, memory etc) are logged to wandb and my calls to writer.log_scalar simply never get recorded to wandb.<\/p>\n<p>Everything seems to be failing silently and I don\u2019t know why nothing gets recorded.  The other day testing on two machines it works from one but not the other, and it is also now working from Colab notebook instances or docker container runs.<\/p>\n<p>The runs on <a href=\"http:\/\/wandb.com\" rel=\"noopener nofollow ugc\">wandb.com<\/a> are there and created, console output shows it fires up and links me to the run and the run URL works, etc.  But, only system monitors are showing up, none of my items logged with summarywriter, at least a vast majority of instances.<\/p>\n<p>At one point it was working fine, then started to stop working.  I had thought it was an issue with trying to pass in a dict of dicts to config={main: args, opt_cfg: optimizer_cfg} but even passing in dummy objects or simply config=args it fails.  At one point wanb.init was done before writer instantiation, and that was fixed, so I\u2019m not sure at what point things went sideways as I mostly run locally but many users use Colab\/Vast, etc and wandb is a significantly better solution for those cases.<\/p>\n<p>Is there any log file or debugging I can use to troubleshoot this?  Unfortunately it is just not working and doing so silently without any feedback.<\/p>",
        "Question_closed_time":"2023-03-25T21:41:27.814Z",
        "Answer_body":"<p>Ah I think I found the magic combination to work for my training script.  For posterity in case anyone else has the issues and stumbles on this post.  This is a raw torch trainer.<\/p>\n<p>(ex log_folder = \u201clogs\/projectname20230325_124523\u201d and contains the events.out.tfevents\u2026 file)<\/p>\n<pre><code class=\"lang-auto\">        wandb.tensorboard.patch(root_logdir=log_folder, pytorch=False, tensorboard_x=False, save=False)\n        wandb_run = wandb.init(\n            project=args.project_name,\n            config={\"main_cfg\": vars(args), \"optimizer_cfg\": optimizer_config},\n            name=args.run_name\n            )\n        log_writer = SummaryWriter(log_dir=log_folder...)\n\n        log_writer.add_scalar(...)\n<\/code><\/pre>\n<p>tensorboard 2.12.0<br>\nwandb 0.14.0<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Custom Tooltip",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-tooltip\/3750",
        "Question_created_time":"2023-01-25T16:33:09.701Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":180,
        "Question_body":"<p>Hello!<\/p>\n<p>I am trying to plot a ROC curve and is working nicely! Now I want to modify the tooltip to add the Threshold value. I think that can be done with Weave and the Table of Thresholds, False and True Positive Rates but I don\u2019t have too much knowledge about Weave.<\/p>\n<p>Example run with Plot and Table: <a href=\"https:\/\/wandb.ai\/marioparreno\/personal-test\/runs\/n0nlj2l6?workspace=user-marioparreno\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>Weave expression here (at Tooltip field)?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png\" data-download-href=\"\/uploads\/short-url\/4CmcMGALP0orfkQwaBtzXnvcRlH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/205eb72f31cdc9af99a39aee3af3e0072dcc9005_2_353x500.png\" alt=\"image\" data-base62-sha1=\"4CmcMGALP0orfkQwaBtzXnvcRlH\" width=\"353\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/205eb72f31cdc9af99a39aee3af3e0072dcc9005_2_353x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png 2x\" data-dominant-color=\"F9F9F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">387\u00d7547 23.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log the learning rate with pytorch lightning when using a scheduler?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-the-learning-rate-with-pytorch-lightning-when-using-a-scheduler\/3964",
        "Question_created_time":"2023-02-27T17:20:25.190Z",
        "Question_answer_count":6,
        "Question_score_count":4,
        "Question_view_count":516,
        "Question_body":"<p>I\u2019ve been trying to find some documentation, I don\u2019t want to save all the hyperparameters each epoch, just the learning rate.<br>\nWould be so great if you can help me out.<\/p>\n<p>Cheers,<\/p>\n<p>Oli<\/p>",
        "Question_closed_time":"2023-03-23T20:20:46.363Z",
        "Answer_body":"<p>I\u2019m also wondering how this is done! Whether within a sweep configuration or not - when using a lr scheduler, I am trying to track the lr at epoch during training, as it is now dynamic. Even within a sweep, you will have some initial lr  determined during the sweep, but it will not stay constant for the duration of training.<\/p>\n<p>edit:<\/p>\n<p>The example on the <a href=\"https:\/\/pytorch-lightning.readthedocs.io\/en\/1.2.10\/api\/pytorch_lightning.callbacks.lr_monitor.html#learning-rate-monitor\" rel=\"noopener nofollow ugc\">lightning site here<\/a> worked for me:<\/p>\n<pre><code class=\"lang-auto\">&gt;&gt;&gt; from pytorch_lightning.callbacks import LearningRateMonitor\n&gt;&gt;&gt; lr_monitor = LearningRateMonitor(logging_interval='step')\n&gt;&gt;&gt; trainer = Trainer(callbacks=[lr_monitor])\n<\/code><\/pre>\n<p>Passing the <code>WandBLogger<\/code> to the trainer I see my lr is logged on the <code>wandb<\/code> dashboard.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Access local filesystem artifacts without downloading",
        "Question_link":"https:\/\/community.wandb.ai\/t\/access-local-filesystem-artifacts-without-downloading\/4092",
        "Question_created_time":"2023-03-21T20:04:30.135Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":69,
        "Question_body":"<p>I would like to use Artifacts to log and track the usage of my datasets. These datasets live on a local filesystem. I was able to create a reference artifact, but the problem I encounter is that the only way to access the original local filepath is to call <code>artifact.download()<\/code> or <code>artifact.get_path(name).ref<\/code>.<\/p>\n<p>Calling <code>download()<\/code> doesn\u2019t work for me because the files are <em>aleady<\/em> local and very large. I definitely do not want to make a copy.<\/p>\n<p>On the other hand, <code>artifact.get_path(name).ref<\/code> works, but this entails <em>already<\/em> knowing the path of the file since that is what is used for <code>name<\/code> as far as I can tell. I suppose even if I could set a custom <code>name<\/code> for each file in the directory (can you?), I\u2019m not sure one can retrieve those names from the artifact itself and therefore they would need to be known by anyone using the artifact. Ideally one would <em>only<\/em> need the artifact\u2019s name and from there you can see the local file paths for all of the files in that artifact.<\/p>\n<p>In case it\u2019s helpful, I add these files to the artifact by doing:<\/p>\n<p><code>artifact.add_reference(name='data_folder',uri='file:\/\/path\/to\/directory')<\/code><\/p>\n<p>When I use the artifact, I can do<\/p>\n<p><code>files = artifact.files()<\/code>,<\/p>\n<p>which returns an iterable of all of the files, but these <code>File<\/code> objects do not have a way to get the path\/uri either.<\/p>\n<p>Is there anyway to do this?<\/p>\n<p>Thanks and let me know if you have any questions that will help you understand or solve this.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"GPU utilization on wandb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/gpu-utilization-on-wandb\/4108",
        "Question_created_time":"2023-03-23T17:25:52.393Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":60,
        "Question_body":"<p>Hi there, My wandb report shows I  have a GPU utilization of 20%<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/52a56bccd41a7994da3efe429526490a257be7e8.png\" data-download-href=\"\/uploads\/short-url\/bN7z4j28TJlXjIAXwCs9IrIhbqo.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52a56bccd41a7994da3efe429526490a257be7e8_2_690x408.png\" alt=\"image\" data-base62-sha1=\"bN7z4j28TJlXjIAXwCs9IrIhbqo\" width=\"690\" height=\"408\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52a56bccd41a7994da3efe429526490a257be7e8_2_690x408.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52a56bccd41a7994da3efe429526490a257be7e8_2_1035x612.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/52a56bccd41a7994da3efe429526490a257be7e8_2_1380x816.png 2x\" data-dominant-color=\"FDFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1699\u00d71006 86.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nwhile  my nvidia-smi prints the below<br>\n\u00b1----------------------------------------------------------------------------+<br>\n| Processes:                                                                  |<br>\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |<br>\n|        ID   ID                                                   Usage      |<br>\n|=============================================================================|<br>\n|    0   N\/A  N\/A      1296      G   \/usr\/lib\/xorg\/Xorg                 56MiB |<br>\n|    0   N\/A  N\/A      1591      G   \/usr\/bin\/gnome-shell               10MiB |<br>\n|    0   N\/A  N\/A    203353      C   python3                          3432MiB |<br>\nI use gunpowder and pytorch for training, not sure if anyone has encountered this and have a solution. Any insight on this appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Setting panel style for a whole project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/setting-panel-style-for-a-whole-project\/4095",
        "Question_created_time":"2023-03-22T09:56:57.991Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":56,
        "Question_body":"<p>I\u2019m tracking a whole bunch of metrics for deep RL experiments I\u2019m running. These are high variance, as is the nature in deep RL.<\/p>\n<p>Per default, wandb will produce shaded error bands based on min\/max values. This is sort of pointless for my experiments due to the outliers, so I\u2019m switching to standard error based bands.<\/p>\n<p>Right now I\u2019m doing this manually for each individual plot. This can get pretty annoying, e.g. when running hyperparameter sweeps. Is there a way to set a specific panel style as default for a project that I\u2019m just not finding?<\/p>\n<p>If this is not possible, I think it would be a nice quality-of-life improvement to add.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Set the WANDB_PROJECT environment variable cannot name the project properly",
        "Question_link":"https:\/\/community.wandb.ai\/t\/set-the-wandb-project-environment-variable-cannot-name-the-project-properly\/4055",
        "Question_created_time":"2023-03-14T03:42:40.341Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":253,
        "Question_body":"<p>Hi everyone, I am using wandb with Huggingface in a AWS Sagemaker notebook and I am refering to the tutorial here: <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/huggingface\" class=\"inline-onebox\">Hugging Face Transformers | Weights &amp; Biases Documentation<\/a>.<\/p>\n<p>I tried to set the <code>WANDB_PROJECT<\/code> environment variable before setting up the <code>huggingface_estimator<\/code>, which will call <code>train.py<\/code>.<\/p>\n<p><code>train.py<\/code> is where I initialize the <code>Trainer<\/code>. The above tutorial mentions to make sure to set the project name before initializing the <code>Trainer<\/code>, and I think I am doing this correctly here.<\/p>\n<p>Here are some useful snippets of my code.<\/p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.login()\n\nWANDB_PROJECT=my_project_name\n\n...\n\nhuggingface_estimator = HuggingFace(\n  image_uri=image_uri,\n  entry_point='train.py',\n  source_dir='.\/scripts',\n  instance_type='ml.g4dn.xlarge',\n  instance_count=1,\n  role=role,\n  py_version='py39',\n  hyperparameters=hyperparameters,\n)\n<\/code><\/pre>\n<p>train.py<\/p>\n<pre><code class=\"lang-auto\">    training_args = TrainingArguments(\n        output_dir=args.output_dir,\n        per_device_train_batch_size=args.per_device_train_batch_size,\n        num_train_epochs=args.epochs,\n        learning_rate=args.learning_rate,\n        save_strategy=\"epoch\",\n        logging_strategy='epoch',\n        report_to=\"wandb\",\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        data_collator=collate_fn,\n        tokenizer=image_processor,\n    )\n\n    trainer.train()\n<\/code><\/pre>\n<p>I would greatly appreciate any guidance or advice on how to resolve this issue. Thank you very much in advance for your help!<\/p>",
        "Question_closed_time":"2023-03-14T13:09:43.235Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/oschan77\">@oschan77<\/a> ,<\/p>\n<p>You can set the project name in your script like so:<\/p>\n<pre><code class=\"lang-auto\">import os\nos.environ[\"WANDB_PROJECT\"] = \"sentiment-analysis\"\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"ROC and PR curves logging",
        "Question_link":"https:\/\/community.wandb.ai\/t\/roc-and-pr-curves-logging\/3686",
        "Question_created_time":"2023-01-11T23:43:03.638Z",
        "Question_answer_count":14,
        "Question_score_count":0,
        "Question_view_count":239,
        "Question_body":"<p>Hi!<br>\nI am using (and loving) Wandb so far <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>Today I wanted to log my validation roc and pr curves, and I used the command:<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\"val_roc\" : wandb.plot.roc_curve(target_list.numpy(), pred_list.numpy(), labels=None, classes_to_plot=None)})\n<\/code><\/pre>\n<p>My task is a binary classification, and my data is in numpy array in the format [m,n], with m the number of samples and n the number of classes, my case 1 (i.e. [128,1]).<\/p>\n<p>I am encountering the following error:<\/p>\n<pre><code class=\"lang-auto\">  File \"\/home\/mgiordano\/.pyenv\/versions\/3.8.11\/envs\/sepsis\/lib\/python3.8\/site-packages\/wandb\/plot\/roc_curve.py\", line 74, in roc_curve\n    y_true, y_probas[..., i], pos_label=classes[i]\nIndexError: index 1 is out of bounds for axis 1 with size 1\n<\/code><\/pre>\n<p>I think Wandb is trying to compute the curves on other classes, that are not there. Am I missing something?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log in a custom panel",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-in-a-custom-panel\/4046",
        "Question_created_time":"2023-03-10T19:45:23.179Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":97,
        "Question_body":"<p>I\u2019d like to log directly in a given panel instead of having to create the panel manually and add the graphs manually. Is it possible ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to access an organization which has completed '250' tracked hours?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-access-an-organization-which-has-completed-250-tracked-hours\/4081",
        "Question_created_time":"2023-03-18T07:27:14.564Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":156,
        "Question_body":"<p>I am a student of an organization who is working on with other persons on one of my projects. I was using wandb to log my training results but it seems like my free subscription has passed. Now, I cannot retrieve any of my previous work. It is very critical to me since I had logged everything there including Models. If you can assist in it or make this account \u2018academic\u2019, Since I am a university student. Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep calls program with command line parameter in quotes",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-calls-program-with-command-line-parameter-in-quotes\/4016",
        "Question_created_time":"2023-03-07T12:19:39.472Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":101,
        "Question_body":"<p>So\u2026 I found out myself during drafting this, but keep it here for reference\/documentation. It\u2019s a little thing, maybe of help to someone.<\/p>\n<p>My <code>train.py<\/code> reads arguments from the command line and I want to use <code>wandb sweeps<\/code>.<\/p>\n<p>One of the arguments is <code>--config_file overwrite.args<\/code>. I can pass this to <code>train.py<\/code> and process it with <code>ArgumentParser()<\/code> and <code>HfArgumentParser()<\/code> (from Hugging Face). If I use it as part of a <code>sweep config<\/code>, like so:<\/p>\n<pre><code class=\"lang-yaml\">command:\n  - python3\n  - ${program}\n  - --config_file overwrite.args\n  - ${args}\nprogram: train.py\n<\/code><\/pre>\n<p>\u2026 <code>train.py<\/code> is called as <code>train.py \"--config_file overwrite.args\"<\/code> (<em>with<\/em> quotes). This is represented differently in <code>sys.argv<\/code> and function calls like this treat it differently as well:<\/p>\n<pre><code class=\"lang-python\">config_file_parser = argparse.ArgumentParser()\n    config_file_parser.add_argument(\n        \"config_file\", type=str, action=\"append\"\n    )\n    known_args, remaining_args = config_file_parser.parse_known_args()\n<\/code><\/pre>\n<p><em>Without<\/em> quotes, it\u2019s a <code>known_args<\/code>, <em>with<\/em> quotes it\u2019s a <code>remaining_args<\/code>. Additionally, at some point, the <code>HfArgumentParser()<\/code>throws an error <code>ValueError: Unknown configuration arguments<\/code> with the quoted argument.<\/p>\n<p>Therefore, my question\/request: (how) can I get rid of the added quotes?<\/p>\n<p>And the simple answer is: change the sweep config to put the flag\/argument on <em>two<\/em> lines, like so:<\/p>\n<pre><code class=\"lang-yaml\">command:\n  - python3\n  - ${program}\n  - --config_file\n  - overwrite.args\n  - ${args}\nprogram: train.py\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Programmatically running Sweeps using Hydra",
        "Question_link":"https:\/\/community.wandb.ai\/t\/programmatically-running-sweeps-using-hydra\/3960",
        "Question_created_time":"2023-02-27T13:21:48.159Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":152,
        "Question_body":"<p>Hello,<\/p>\n<p>I want to write a python script which runs multiple sweeps after another.  My train.py works with hydra, which I want to keep that way. Until now I was able to run sweeps using the command line and a config.yaml file which has at the end:<br>\ncommand:<\/p>\n<ul>\n<li>${env}<\/li>\n<li>python<\/li>\n<li>${program}<\/li>\n<li>${args_no_hyphens}<br>\nIs there a way to bring this into the dictionary used in the function wandb.sweep in python?<\/li>\n<\/ul>\n<p>Thanks in advance and best regards<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Server socket closed",
        "Question_link":"https:\/\/community.wandb.ai\/t\/server-socket-closed\/4042",
        "Question_created_time":"2023-03-10T07:21:40.353Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":334,
        "Question_body":"<p>RUNNING VERSION 0.13.11<\/p>\n<p>ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine<\/p>\n<p>BrokenPipeError: [Errno 32] Broken pipe<\/p>\n<p>receiving a very long traceback error resulting in either of the above messages (windows\/linux). Occurs when trying to run any sweep.  Occurs when connecting from various machines\/IP addresses<\/p>\n<pre><code class=\"lang-auto\">def train():\n    print(1)\n\nsweep_configuration = {\n    'method' : 'grid',\n    'name' : 'Sweep',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'AUC'\n    },\n    'parameters': {\n        'learn': {'values': [1, 0.1]}\n    }\n}\nsweep_id = wandb.sweep(sweep_configuration)\nwandb.agent(sweep_id, function=train, count=1)\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">wandb: Agent Starting Run: gwiij466 with config:\nwandb: \tlearn: 1\nException in thread Thread-9 (_run_job):\nTraceback (most recent call last):\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3669, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 368, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 331, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1843, in finish\n    return self._finish(exit_code, quiet)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1850, in _finish\n    with telemetry.context(run=self) as tel:\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 42, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 689, in _telemetry_callback\n    self._telemetry_flush()\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 700, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 101, in _publish_telemetry\n    self._publish(rec)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n\nDuring handling of the above exception, another exception occurred:\n\nConnectionAbortedError                    Traceback (most recent call last)\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\backcall\\backcall.py:104, in callback_prototype.&lt;locals&gt;.adapt.&lt;locals&gt;.adapted(*args, **kwargs)\n    102                 kwargs.pop(name)\n    103 #            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\n--&gt; 104             return callback(*args, **kwargs)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:418, in _WandbInit._pause_backend(self)\n    416 if self.backend.interface is not None:\n    417     logger.info(\"pausing backend\")  # type: ignore\n--&gt; 418     self.backend.interface.publish_pause()\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:665, in InterfaceBase.publish_pause(self)\n    663 def publish_pause(self) -&gt; None:\n    664     pause = pb.PauseRequest()\n--&gt; 665     self._publish_pause(pause)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:340, in InterfaceShared._publish_pause(self, pause)\n    338 def _publish_pause(self, pause: pb.PauseRequest) -&gt; None:\n    339     rec = self._make_request(pause=pause)\n--&gt; 340     self._publish(rec)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51, in InterfaceSock._publish(self, record, local)\n     49 def _publish(self, record: \"pb.Record\", local: Optional[bool] = None) -&gt; None:\n     50     self._assign(record)\n---&gt; 51     self._sock_client.send_record_publish(record)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221, in SockClient.send_record_publish(self, record)\n    219 server_req = spb.ServerRequest()\n    220 server_req.record_publish.CopyFrom(record)\n--&gt; 221 self.send_server_request(server_req)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155, in SockClient.send_server_request(self, msg)\n    154 def send_server_request(self, msg: Any) -&gt; None:\n--&gt; 155     self._send_message(msg)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152, in SockClient._send_message(self, msg)\n    150 header = struct.pack(\"&lt;BI\", ord(\"W\"), raw_size)\n    151 with self._lock:\n--&gt; 152     self._sendall_with_error_handle(header + data)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130, in SockClient._sendall_with_error_handle(self, data)\n    128 start_time = time.monotonic()\n    129 try:\n--&gt; 130     sent = self._sock.send(data)\n    131     # sent equal to 0 indicates a closed socket\n    132     if sent == 0:\n\nConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\nwandb: Agent Starting Run: 4maabb7r with config:\nwandb: \tlearn: 0.1\nException in thread Thread-10 (_run_job):\n### same error continuing forwards\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to delete only one billing seat?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-delete-only-one-billing-seat\/3971",
        "Question_created_time":"2023-03-01T09:58:49.548Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":86,
        "Question_body":"<p>I use it in my team.<br>\nWhat should I do to reduce the bill by one person this time by reducing one person?<br>\nI can delete members, but I can\u2019t find the item for deleting sheets\u3002<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb videos in logged tables often stop playback with error message",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-videos-in-logged-tables-often-stop-playback-with-error-message\/3978",
        "Question_created_time":"2023-03-01T21:18:35.374Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":153,
        "Question_body":"<p>I\u2019m logging some pretty big videos in tables  (each 20-80MB) with about 50 rows with such videos. When I\u2019m looking through these on the run dashboard, they sometimes go blank with an error message: pipeline_ERROR_READ: FFmpegDemuxer: data source error<\/p>\n<p>I\u2019m saving the videos locally first as a webm and then wrapping the wandb video object with the filepath name to the constructor and logging the video to a row in a table.<\/p>\n<p>Is this a filesize issue as I\u2019m guessing? Or something else? How would I attempt to fix this issue if not a filesize related issue?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb cannot upload files",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-cannot-upload-files\/4074",
        "Question_created_time":"2023-03-17T08:52:35.287Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":136,
        "Question_body":"<p>As far as I understand wandb cannot finish uploading a file after the training process ends.<br>\nLogs are like the following:<\/p>\n<pre><code class=\"lang-auto\">2023-03-17 10:58:41,519 INFO    SenderThread:38526 [sender.py:transition_state():587] send defer: 14\n2023-03-17 10:58:41,519 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: defer\n2023-03-17 10:58:41,520 DEBUG   SenderThread:38526 [sender.py:send():336] send: final\n2023-03-17 10:58:41,520 INFO    HandlerThread:38526 [handler.py:handle_request_defer():170] handle defer: 14\n2023-03-17 10:58:41,520 DEBUG   SenderThread:38526 [sender.py:send():336] send: footer\n2023-03-17 10:58:41,521 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: defer\n2023-03-17 10:58:41,521 INFO    SenderThread:38526 [sender.py:send_request_defer():583] handle sender defer: 14\n2023-03-17 10:58:41,522 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: poll_exit\n2023-03-17 10:58:41,523 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: server_info\n2023-03-17 10:58:41,523 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: poll_exit\n2023-03-17 10:58:41,524 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: get_summary\n2023-03-17 10:58:41,525 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: server_info\n2023-03-17 10:58:41,525 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: sampled_history\n2023-03-17 10:58:42,143 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: shutdown\n2023-03-17 10:58:42,144 INFO    HandlerThread:38526 [handler.py:finish():842] shutting down handler\n2023-03-17 10:58:42,525 INFO    WriterThread:38526 [datastore.py:close():298] close: \/home\/batu\/wandb\/run-20230317_105832-lvhco0to\/run-lvhco0to.wandb\n2023-03-17 10:58:43,142 INFO    SenderThread:38526 [sender.py:finish():1504] shutting down sender\n2023-03-17 10:58:43,142 INFO    SenderThread:38526 [file_pusher.py:finish():164] shutting down file pusher\n2023-03-17 10:58:43,143 INFO    SenderThread:38526 [file_pusher.py:join():169] waiting for file pusher\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Table with images much larger than originals",
        "Question_link":"https:\/\/community.wandb.ai\/t\/table-with-images-much-larger-than-originals\/4018",
        "Question_created_time":"2023-03-07T16:32:24.249Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":156,
        "Question_body":"<p>I am uploading images to artifact by loading a table with an <code>image<\/code> column, as shown in lesson 1 of your mlops course. However, if I create the image values as <code>wandb.Image(PIL.Image.open(path))<\/code> , my 3GB image folder becomes &gt;30Gb <code>media\/images<\/code> folder in the artifact. If instead I use <code>wandb.Image(path)<\/code> , the artifact\u2019s <code>media\/images<\/code> folder is about 3GB, but each image is loaded into a subfolder with a random name, making difficult to retrieve the image when I download the artifact for training. How can I have the images loaded simply into <code>media\/images<\/code>, with the latter not being enormously bigger than the original one?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Academic account",
        "Question_link":"https:\/\/community.wandb.ai\/t\/academic-account\/3921",
        "Question_created_time":"2023-02-21T01:37:32.575Z",
        "Question_answer_count":11,
        "Question_score_count":0,
        "Question_view_count":137,
        "Question_body":"<p>Hi, I am facing an issue with an academic account. I added the email where the domain is <span class=\"mention\">@diag.uniroma1.it<\/span>, as any domain ending with uniroma1.it is from different faculties in Sapienza. DIAG is the department of computer engineering and automation.<\/p>\n<p>However the account seems to still be considered non-academic. Is there any step necessary from my side?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Graphs drawn using matplotlib have discontinuous subscripts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/graphs-drawn-using-matplotlib-have-discontinuous-subscripts\/3908",
        "Question_created_time":"2023-02-18T09:17:38.949Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":114,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2c2e61fa5ae1ac5b0afc509f77d71de219791970.png\" data-download-href=\"\/uploads\/short-url\/6iQnL94TqoMJVWBZO4La5dsrGKs.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_690x306.png\" alt=\"image\" data-base62-sha1=\"6iQnL94TqoMJVWBZO4La5dsrGKs\" width=\"690\" height=\"306\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_690x306.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_1035x459.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2c2e61fa5ae1ac5b0afc509f77d71de219791970.png 2x\" data-dominant-color=\"EEF0F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1178\u00d7523 38.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom plot: numerical derivative",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-plot-numerical-derivative\/4036",
        "Question_created_time":"2023-03-08T21:10:10.024Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":110,
        "Question_body":"<p>In W&amp;B is it possible to plot something like a numerical derivative?<br>\nie plot something like: loss_{i-1} - loss_i<br>\nI\u2019m trying to define like a \u201cplateau rate\u201d curve to help me see if something is getting close to converging.<\/p>\n<p>Alternatively , is there some notion of \u201ctime\u201d which can be used to define a numerical derivative?<br>\nie can I do something like ${loss@_step-1} or ${loss:_step-1}<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using sweeps for custom data generator in keras",
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-sweeps-for-custom-data-generator-in-keras\/3957",
        "Question_created_time":"2023-02-27T10:46:20.269Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":103,
        "Question_body":"<p>Am using custom data generator as part of my image augmentation. Are you able to use sweeps to try different parameters for such augmentation?<\/p>\n<p>for example:<\/p>\n<pre><code class=\"lang-auto\">idg = CustomDataGenerator(rescale = 1 \/ 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=config.v_kernel_size,\n                              h_kernel_size=config.h_kernel_size,  \n                             height_shift_range = config.height_shift_range, \n                             width_shift_range = config.width_shift_range, \n                             rotation_range = config.rotation_range, \n                             shear_range = config.shear_range,\n                             zoom_range = config.zoom_range,)\n    return idg\n<\/code><\/pre>",
        "Question_closed_time":"2023-03-01T21:07:59.785Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/zookcx\">@zookcx<\/a> thanks for writing in! Is in your example the <code>CustomDataGenerator<\/code> a function that you could call from the main training function? Would something like the following work for you?<\/p>\n<pre><code class=\"lang-auto\">import wandb\ndef main():\n    wandb.init(project='custom-data-sweep')\n    data = CustomDataGenerator(rescale = 1 \/ 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=wandb.config.v_kernel_size,\n                              h_kernel_size=wandb.config.h_kernel_size)\n    wandb.log({'data': data})\n    wandb.finish()\n\n\ndef CustomDataGenerator(rescale = 1 \/ 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=0,\n                             h_kernel_size=0,\n                          ):\n  \n    # add your own custom data generator logic\n    idg = v_kernel_size + h_kernel_size\n\n    return idg\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">\nsweep_config = {\n    'method': 'grid',\n    'project': 'sweep-configs',\n    'parameters': {\n        'v_kernel_size': {\n            'values': [32, 64, 96, 128, 256]\n        },\n        'h_kernel_size': {\n            'values': [32, 64, 96, 128, 256]\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep_config)\nwandb.agent(sweep_id, function=main)\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Add file to artifact without downloading it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-file-to-artifact-without-downloading-it\/3989",
        "Question_created_time":"2023-03-02T23:13:21.912Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":234,
        "Question_body":"<p>I have a large artifact containing a table with 6K images and other columns.<br>\nIs it possible to add another file, for instance a csv, without having to download the artifact, get the table, add the file and the table to a new version of the artifact and log it to wandb?<\/p>\n<p>A possibility would be to create a new version of the artifact with only the csv file and then merge the two versions (from the UI?), but I am sure this is possible.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":"2023-03-03T14:17:42.840Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/tommasodelorenzo\">@tommasodelorenzo<\/a> thanks for writing in! It sounds like that you\u2019re looking for the <code>incremental<\/code> argument that would allow you to add files to existing artifacts. Please have a look to <a href=\"https:\/\/github.com\/wandb\/artifacts-examples\/blob\/master\/incremental-artifacts\/add_to_existing_artifact.py\" rel=\"noopener nofollow ugc\">this<\/a> example, but also more specifically for your case the following snippet should work:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\nrun = wandb.init(entity=ENTITY, project=PROJECT)\nartifact = wandb.Artifact('ARTIFACT-NAME', type='ARTIFACT-TYPE', incremental=True)\nartifact.add_file('\/path\/to\/file.format') #add_dir works too\nrun.log_artifact(artifact)\nrun.finish()\n<\/code><\/pre>\n<p>This  will create a new version with the new files, plus the files from previous version. Would this work for you?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Getting error <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'max_depth'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/getting-error-class-wandb-sdk-wandb-config-config-object-has-no-attribute-max-depth\/3859",
        "Question_created_time":"2023-02-10T14:24:50.033Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":415,
        "Question_body":"<p>I run this code but gives me the mentioned error:<\/p>\n<pre data-code-wrap=\"py\"><code class=\"lang-plaintext\">def train_model(ver=None):\n\n    run = wandb.init(\n    project=\"sdg_test_case1\",\n    name=f\"advanced_analytic_EDA_model_v{ver}\",\n    # config=param,\n    )\n\n\n    param = {\n    \"objective\" : \"binary:logistic\",\n    \"eval_metric\": 'auc',\n    \"predictor\":\"gpu_predictor\",\n    \"random_state\": seed,\n    \"scale_pos_weight\": 2.66,\n    \"max_depth \": wandb.config.max_depth,\n    \"learning_rate\": wandb.config.learning_rate,\n    \"gamma\": wandb.config.gamma,\n    \"min_child_weight\": wandb.config.min_child_weight,\n    \"subsample\": wandb.config.subsample\n\n    }\n\n    bst = xgb.train(\n        param,\n        xg_train,\n        evals=watchlist,\n        verbose_eval=5,\n        callbacks=[WandbCallback()],\n        num_boost_round=50,\n        early_stopping_rounds=3\n    )\n\n    pred = bst.predict(xg_val)\n    pred_class = pred.round()\n\n\n    auc = roc_auc_score(y_test, pred)\n    acc = accuracy_score(y_test, pred_class)\n\n    conf = confusion_matrix(y_test, pred_class)\n    tn, fp, fn, tp=conf.ravel()\n    precision = tp \/ (tp + fp)\n    recall = tp \/ (tp + fn)\n    specificity = tn \/ (tn + fp)\n\n    # print(f\"AUC of ROC: {(auc)}\")\n    # print(f\"accuracy: {(acc)}\")\n    # print(f\"precision: {(precision)}\")\n    # print(f\"recall: {(recall)}\")\n    # print(f\"specificity: {(specificity)}\")\n\n    wandb.log({\n        \"accuracy\":acc,\n        \"precision\":precision,\n        \"recall\":recall,\n        \"specificity\":specificity,\n    })\n    wandb.summary[\"AUC\"] = auc\n\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\"name\": \"AUC\", \"goal\": \"maximize\"},\n    \"parameters\":{\n        \"max_depth\": {\"values\":[2,3,4,5,6,7,8]},\n        \"subsample\": {'distribution': 'uniform','min': 0.7,'max': 1},\n        \"gamma\": {'distribution': 'uniform','min': 0,'max': 0.1},\n        \"learning_rate\": {'distribution': 'uniform','min': 0,'max': 0.1},\n        \"min_child_weight\" : {'distribution': 'uniform','min': 0.9,'max': 1.3}\n\n    }\n}\n\nver = 1\nsweep_id = wandb.sweep(sweep_config,project=\"sdg_test_case\")\nwandb.agent(sweep_id=sweep_id, function=train_model(ver), count=10)\nwandb.finish()\n\n<\/code><\/pre>\n<p>I ran the example <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/quickstart\">here<\/a> and it ran flawlessly, I don\u2019t know where is the issue is, the two codes are similar.<br>\nThank you for your time!<\/p>",
        "Question_closed_time":"2023-02-10T15:46:36.420Z",
        "Answer_body":"<p>solved it by not giving any arguments to the train_model function.<br>\n<code>wandb.agent(sweep_id=sweep_id, function=train_model, count=10) <\/code><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Logged tables in reverse chronological order?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logged-tables-in-reverse-chronological-order\/4006",
        "Question_created_time":"2023-03-06T11:37:44.825Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":93,
        "Question_body":"<p>We have many logged tables. The table panel always appears in a chaotic order, making it very hard to find the desired table. Even A-Z sorting doesn\u2019t really work as expected, the order is still chaotic.<\/p>\n<p>Would there be a possibility for reverse chronological ordering? And\/or accurate A-Z ordering according to the table title I presume?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to delete a project in an organization that has exceeded the 250 hour limit?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-delete-a-project-in-an-organization-that-has-exceeded-the-250-hour-limit\/4029",
        "Question_created_time":"2023-03-08T02:42:41.102Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":149,
        "Question_body":"<p>I have an organization that has exceeded the 250 hour limit. I am trying to go into the organization, to delete<br>\nan old project so I can stop exceeding the limit. But it looks like the UI is not letting me.<\/p>\n<p>Is there a way I delete old projects in my organization to go back under the limit?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hugging Face Accelerate + Sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hugging-face-accelerate-sweeps\/3973",
        "Question_created_time":"2023-03-01T12:24:12.119Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":230,
        "Question_body":"<p>Hi,<\/p>\n<p>I am struggling to get sweeps to work with Hugging Face\u2019s Accelerate library. Specifically, the first run of the sweep works fine, but every run thereafter fails due to re-initialising the Accelerator for every run. In every run from the 2nd, I get the error: <code>AcceleratorState has already been initialized and cannot be changed, restart your runtime completely and pass mixed_precision='bf16' to Accelerate().<\/code><\/p>\n<p>Below is a minimal example of a script which I\u2019m launching using <code>accelerate launch<\/code>. I\u2019d appreciate any suggestions. Thanks!<\/p>\n<pre><code class=\"lang-auto\">import os\nfrom typing import Any, List, Tuple\n\nfrom accelerate import Accelerator\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    Adafactor,\n    PreTrainedTokenizerFast,\n    T5ForConditionalGeneration,\n    T5TokenizerFast,\n)\nimport wandb\n\n\nclass TestDataset(Dataset[Any]):\n    def __init__(self, tokenizer: PreTrainedTokenizerFast) -&gt; None:\n        super().__init__()\n        self._str_prompt = \"This is a \"\n        self._str_target = \"test.\"\n        \n        self._tokenizer = tokenizer\n    \n    def __len__(self) -&gt; int:\n        return 1\n\n    def __getitem__(self, idx: int) -&gt; Tuple[str, str]:\n        return self._str_prompt, self._str_target\n    \n    def collate(self, batch: List[Tuple[str, str]]) -&gt; Tuple[Tensor, Tensor]:\n        prompts = [b[0] for b in batch]\n        targets = [b[1] for b in batch]\n        \n        prompts_tokenized = self._tokenizer(prompts, return_tensors=\"pt\")\n        targets_tokenized = self._tokenizer(targets, return_tensors=\"pt\")\n        \n        return prompts_tokenized[\"input_ids\"], targets_tokenized[\"input_ids\"]\n\n\ndef main() -&gt; None:\n    accelerator = Accelerator(log_with=\"wandb\", mixed_precision=\"bf16\")\n    \n    if accelerator.is_main_process:\n        accelerator.init_trackers(os.environ.get(\"WANDB_PROJECT\"))\n    \n    accelerator.wait_for_everyone()\n    \n    wandb_tracker = accelerator.get_tracker(\"wandb\")\n    multiplier = wandb_tracker.config[\"multiplier\"]\n    \n    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n    tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")\n    opt = Adafactor(params=model.parameters())\n    \n    dataset = TestDataset(tokenizer=tokenizer)\n    data_loader = DataLoader(dataset=dataset, collate_fn=dataset.collate)\n    \n    model, opt, data_loader = accelerator.prepare(model, opt, data_loader)\n    \n    input_ids, labels = next(iter(data_loader))\n    \n    loss = model(input_ids=input_ids, labels=labels).loss\n    \n    loss_gathered = accelerator.gather_for_metrics(loss).mean()\n    accelerator.log({\"loss\": loss_gathered.item() * multiplier})\n    \n    accelerator.end_training()\n\n\nif __name__ == \"__main__\":\n    sweep_configuration = {\n        \"method\": \"random\",\n        \"metric\": {\"goal\": \"maximize\", \"name\": \"loss\"},\n        \"parameters\": {\"multiplier\": {\"values\": list(range(100))}},\n    }\n    \n    sweep_id = wandb.sweep(\n        sweep=sweep_configuration,\n        project=os.environ.get(\"WANDB_PROJECT\"),\n    )\n    wandb.agent(sweep_id, function=main, count=3)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Only one plotly plot is showing despite many uploaded",
        "Question_link":"https:\/\/community.wandb.ai\/t\/only-one-plotly-plot-is-showing-despite-many-uploaded\/3988",
        "Question_created_time":"2023-03-02T19:31:34.765Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":120,
        "Question_body":"<p>I am trying to log a 3d scatter plotly plot every nth iteration. I followed this tutorial <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots\" class=\"inline-onebox\">Log and Track Plots from W&amp;B Experiments.<\/a> to convert the plot into an HTML, add it to a table and then log it. However, in my wandb dashboard, only a single row shows up, so it seems like the table gets overwritten.  Ideally, I would like a slider to go through the plots, but having them all in a table would already be better than what I have right now. Here is my code:<\/p>\n<pre><code class=\"lang-auto\">density_plot_wandb_table = wandb.Table(columns=[\"electron_densities\"])\nfor step in trange(init_step, config.train.n_steps):\n    ...\n     if step%config.plotting.n_plotting_frequency==0:\n            # Create plot\n            fig = go.Figure(data=[go.Scatter3d(x=samples[:config.plotting.n_samples, 0],\n                                           y=samples[:config.plotting.n_samples, 1],\n                                           z=samples[:config.plotting.n_samples,  2],\n                                           mode='markers',\n                                           marker=dict(\n                                             size=1,\n                                             color='#636EFA',\n                                             opacity=0.2\n                                           )\n                                           ),\n                              go.Scatter3d(x=mol.nuclei_position[:, 0],\n                                           y=mol.nuclei_position[:, 1],\n                                           z=mol.nuclei_position[:, 2],\n                                           mode='markers',\n                                           marker=dict(\n                                             size=7,\n                                             color='crimson',\n                                             opacity=1.0\n                                           )\n                                           )\n\n                              ])\n           fig.write_html('{}plots_{}'.format(workdir, step), auto_play=False)\n           density_plot_wandb_table.add_data(wandb.Html('{}plots_{}'.format(workdir, step)))\n           wandb.log({'Mol': density_plot_wandb_table})\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Matplotlib drawing, please can you set the subscript to start at 1 instead of 36",
        "Question_link":"https:\/\/community.wandb.ai\/t\/matplotlib-drawing-please-can-you-set-the-subscript-to-start-at-1-instead-of-36\/3927",
        "Question_created_time":"2023-02-22T01:36:03.995Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":171,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270.png\" data-download-href=\"\/uploads\/short-url\/uY79TH4Hvfbkf7OvkKIHtqppHHi.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png\" alt=\"image\" data-base62-sha1=\"uY79TH4Hvfbkf7OvkKIHtqppHHi\" width=\"690\" height=\"351\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_1035x526.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270.png 2x\" data-dominant-color=\"EBEEF4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1136\u00d7578 38.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<pre><code class=\"lang-auto\">def plot_embeddings(embeddings, label,dataset_name,epoch):\n    len_embedding = len(embeddings)\n    emb_list = np.array(embeddings.tolist())\n    label = np.array(label.tolist())\n\n    color_idx = {}\n    for i in range(len_embedding):\n        color_idx.setdefault(label[i], [])\n        color_idx[label[i]].append(i)\n\n    fig, ax = plt.subplots(figsize=(20,10), dpi= 120)\n    for c, idx in color_idx.items():\n        ax.scatter(emb_list[idx, 0], emb_list[idx, 1], label=c)\n\n    wandb.log({f\"visualization\/Embedding\u2014\u2014{dataset_name}\": fig,\n               f\"visualization\/epoch\": epoch,\n               })\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Traceback error BrokenPipeError: [Errno 32] Broken pipe",
        "Question_link":"https:\/\/community.wandb.ai\/t\/traceback-error-brokenpipeerror-errno-32-broken-pipe\/3951",
        "Question_created_time":"2023-02-26T05:56:50.979Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":1249,
        "Question_body":"<p>Hey guys,<\/p>\n<p>I am getting a Traceback error when I want to run\"wandb.log()\".Any tips what to do?? Thank you so much.<\/p>\n<p>Traceback (most recent call last):<br>\nFile \u201ctrain_spn_voc.py\u201d, line 275, in <br>\nmain(name=args.name)<br>\nFile \u201ctrain_spn_voc.py\u201d, line 180, in main<br>\n\u2018train_acc\u2019: train_acc.avg,<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_run.py\u201d, line 371, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_run.py\u201d, line 334, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_run.py\u201d, line 1713, in log<br>\nself._log(data=data, step=step, commit=commit)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_run.py\u201d, line 1495, in _log<br>\nself._partial_history_callback(data, step, commit)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_run.py\u201d, line 1370, in _partial_history_callback<br>\npublish_step=not_using_tensorboard,<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/interface\/interface.py\u201d, line 586, in publish_partial_history<br>\nself._publish_partial_history(partial_history)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/interface\/interface_shared.py\u201d, line 89, in _publish_partial_history<br>\nself._publish(rec)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/interface\/interface_sock.py\u201d, line 51, in _publish<br>\nself._sock_client.send_record_publish(record)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 221, in send_record_publish<br>\nself.send_server_request(server_req)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 155, in send_server_request<br>\nself._send_message(msg)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 152, in _send_message<br>\nself._sendall_with_error_handle(header + data)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/lib\/sock_client.py\u201d, line 130, in _sendall_with_error_handle<br>\nsent = self._sock.send(data)<br>\nBrokenPipeError: [Errno 32] Broken pipe<br>\nwandb: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Conditional sweep config",
        "Question_link":"https:\/\/community.wandb.ai\/t\/conditional-sweep-config\/4017",
        "Question_created_time":"2023-03-07T13:12:53.379Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":105,
        "Question_body":"<p>I guess the answer to this is \u201cnot supported\u201d when looking at similar requests, but at least\u2026 let me add a +1 to the feature request. Simplified, presume I have two approaches to training a model, each with its own sub-approaches. Is there a way to define a sweep config in a way that I can do a search over sub-approaches that depend on the main approach, i.e., how to build something like:<\/p>\n<pre><code class=\"lang-bash\">python3 train.py --approach a --sub_approach a1\npython3 train.py --approach a --sub_approach a2\npython3 train.py --approach b --sub_approach b1\npython3 train.py --approach b --sub_approach b2\n<\/code><\/pre>\n<p>I could\u2026<\/p>\n<ul>\n<li>do 2 sweeps for a anb b in that toy example, but I think I cannot combine the results of different sweeps into a single graph, right?<\/li>\n<li>Or I could check in <code>train.py<\/code> and abort the program for invalid combinations; in this case I think I need to tell wandb to continue with the sweep since there would be a number of \u201ccrashes\u201d<\/li>\n<li>Or use a different hyper param optimizer and integrate into wandb (but would like to avoid that).<\/li>\n<\/ul>\n<p>Any other options? If different hyper param optimizer, any recommendation because of better\/easier integration with wandb? Thanks for your input\/ideas.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Min loss using Weave panel",
        "Question_link":"https:\/\/community.wandb.ai\/t\/min-loss-using-weave-panel\/3874",
        "Question_created_time":"2023-02-13T17:36:17.932Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":227,
        "Question_body":"<p>I logged loss in my run. I would like to compare runs by min loss. I found <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/736\" rel=\"noopener nofollow ugc\">this<\/a> feature request, which suggests using a Weave panel with:<\/p>\n<pre><code class=\"lang-auto\">runs.map((row) =&gt; row.history[\"loss\"].min)\n<\/code><\/pre>\n<p>This works when I add the panel on the run page (i.e. <code>\/&lt;team&gt;\/&lt;project&gt;\/runs\/&lt;run id&gt;<\/code>). However, when I add the panel on the project page (i.e. <code>\/&lt;team&gt;\/&lt;project&gt;<\/code>), all runs show an empty value.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Nested Log structure which is visible in the UI",
        "Question_link":"https:\/\/community.wandb.ai\/t\/nested-log-structure-which-is-visible-in-the-ui\/3938",
        "Question_created_time":"2023-02-23T11:42:25.691Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":190,
        "Question_body":"<p>i have a model with some somemodules. I want to log the  weights and gradients using a nested \u201cfolder\u201d-strukture so that i can for example navigate like this:<\/p>\n<p>gradients-modeltype1 -model1<br>\ngradietns-modeltype1-model2<br>\ngradients-model2<br>\ngradietns-parameters<\/p>\n<p>and the same with the weights. preferably like a dropdown navigation<\/p>\n<p>your doku states:<\/p>\n<pre><code class=\"lang-auto\">Logging nested metrics is encouraged and is supported in the W&amp;B UI. If you log with a nested dictionary like wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}}), the metrics will be organized into train and val sections in the W&amp;B UI.\n<\/code><\/pre>\n<p>so i tried to use the nested dict stucture with:<\/p>\n<pre><code class=\"lang-auto\">..\n                     weights = layer.get_weights()\n                        if len(weights) == 1:\n                            metrics.update(flatten_dict.flatten({\n                                \"weights\": {\n                                    model_type: {\n                                        model.name: {\n                                            layer.name + \".weights\": _convert_weights(weights[0], histogram=histogram)\n                                        }\n                                    }\n                                }\n                            }))\n....\nreturn flatten_dict.unflatten(metrics)\n<\/code><\/pre>\n<p>but all i get are pathnames with dots in the middle. no folding stucture.  like this I even only get single histograms for all the biases and weights as a list of 300 elements. Not very usefull.<\/p>\n<p>is there a way  to get this working? It realy would help me a lot . I realy hope this feature exists!!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.watch doesnt log anything for me",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-watch-doesnt-log-anything-for-me\/3996",
        "Question_created_time":"2023-03-03T15:09:40.398Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":131,
        "Question_body":"<p>Hi, despite trying many variations and looking through similar issues including <span class=\"hashtag\">#1197<\/span> and <span class=\"hashtag\">#2096<\/span>, I cannot manage to get wandb to log anything about parameters and gradients using wandb.watch(). The documentation has not been helpful. Here\u2019s a sample of what I\u2019m trying to do:<\/p>\n<pre><code class=\"lang-auto\">from torchvision.models import resnet18\nimport torch\n\nm = resnet18()\nm.train()\n\nopt = torch.optim.SGD(m.parameters(),lr=0.1)\n\nloss_fn = torch.nn.BCEWithLogitsLoss()\n\n#track with wandb\nwandb_session = wandb.init(\n    entity='kitzeslab',\n    project=\"trying wandb in opensoundscape\", \n    name='try basic gradient logging',\n)\n\n\n#tried various version of this line, with no criterion argumnet, criterion=loss_fn, etc\n# tried both wandb.watch() and wandb_session.watch()\n# tried 'all' and 'gradients' for log\nwandb_session.watch(models=m,log='all')#,criterion=loss_fn)#,crieterion=torch.nn.BCEWithLogitsLoss)\n\n#train one epoch:\n\nfor samples in train_loader:\n    #please just trust that this is how I get samples from my dataloader\n    samples = collate_samples(samples)\n    tensors = samples['samples']\n    labels = samples['labels']\n\n    #tried both forward() and __call__()\n    logits = m.__call__(tensors) \n\n    # calculate loss\n    loss = loss_fn(logits,labels.float())\n\n    opt.zero_grad()\n    # backward pass: calculate the gradients\n    loss.backward()\n    # update the network using the gradients*lr\n    opt.step()\n    wandb_session.log({'loss':loss})\n    \nwandb_session.finish()\n<\/code><\/pre>\n<p>The loss logs to wandb fine, but I don\u2019t have panels for Parameters or Gradients. Am I doing something wrong?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rerun a deleted run in wandb sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rerun-a-deleted-run-in-wandb-sweep\/3860",
        "Question_created_time":"2023-02-10T15:19:56.664Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":167,
        "Question_body":"<p>Hi,<\/p>\n<p>Assuming I have a sweep of runs. For some reason, I wanna rerun a few of the runs. So I go ahead and delete those runs in the dashboard. But then even if I rerun the command (<code>wandb agent ...<\/code>), wandb is not able to rerun those runs. It will show all runs have been completed. Could wandb add the feature to rerun the runs that are not in the dashboards (for example, those that are deleted)?<\/p>",
        "Question_closed_time":"2023-02-10T23:12:55.536Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/taochen\">@taochen<\/a>, rerunning deleted runs of a sweep is supported for grid search only. Please see the <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/faq#can-i-rerun-a-grid-search\">following guide<\/a> on the steps to take to execute correctly. If you find that does not work for you, provide a link to your workspace and we\u2019ll take a closer look.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Not displaying class labels\/captions in BoundingBoxes2D images",
        "Question_link":"https:\/\/community.wandb.ai\/t\/not-displaying-class-labels-captions-in-boundingboxes2d-images\/3864",
        "Question_created_time":"2023-02-11T17:18:27.239Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":145,
        "Question_body":"<p>Hi all! I\u2019m logging some images to my dashboard using this code:<\/p>\n<pre><code class=\"lang-auto\">box_data = [{\n  \"position\": {\n  \"minX\": xywh[0] - 3,  # ignore the weird  -3\/+3 hardcoded offsets\n  \"minY\": xywh[1] - 3,\n  \"maxX\": xywh[0] + 3,\n  \"maxY\": xywh[1] + 3},\n  \"class_id\": int(cls),\n  \"scores\": {\n  \"class_score\": conf},\n  \"domain\": \"pixel\"} for *xywh, conf, cls in pred.tolist()]\nboxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\nself.bbox_media_panel_images.append(wandb.Image(im, boxes=boxes, caption=path.name))\n<\/code><\/pre>\n<p>My images are filled with tiny cells and I want to have the cleanest visualization of my bounding boxes, without any captions\/class labels. Therefore I\u2019m purposefully not filling in the <code>box_caption<\/code> arg, but the visualization seems to default back to the <code>class_id<\/code> label, which is mandatory. I then still get images where the labels obscure other cells:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/27f98321b3c1510c054aa0b9571e50889e7a584d.jpeg\" data-download-href=\"\/uploads\/short-url\/5HDcklryLT5O91Ofq1miO941zSl.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/27f98321b3c1510c054aa0b9571e50889e7a584d_2_504x499.jpeg\" alt=\"image\" data-base62-sha1=\"5HDcklryLT5O91Ofq1miO941zSl\" width=\"504\" height=\"499\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/27f98321b3c1510c054aa0b9571e50889e7a584d_2_504x499.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/27f98321b3c1510c054aa0b9571e50889e7a584d_2_756x748.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/27f98321b3c1510c054aa0b9571e50889e7a584d.jpeg 2x\" data-dominant-color=\"83A4A0\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">985\u00d7976 125 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any way of <em>just<\/em> visualizing the bounding boxes without captions or labels?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is the wandb.ai server down right now in Germany?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-the-wandb-ai-server-down-right-now-in-germany\/3993",
        "Question_created_time":"2023-03-03T11:27:06.554Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":120,
        "Question_body":"<p>Hi,<br>\nIt seems like wandb server is down right now in Germany. Do you all are facing the same issue?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"KeyError: \u2018fasterrcnn_resnet50\u2019",
        "Question_link":"https:\/\/community.wandb.ai\/t\/keyerror-fasterrcnn-resnet50\/3983",
        "Question_created_time":"2023-03-02T10:48:37.188Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":59,
        "Question_body":"<p>I am trying to run this GitHub repository <a href=\"https:\/\/github.com\/sovit-123\/fasterrcnn-pytorch-training-pipeline#Train-on-Custom-Dataset\" rel=\"noopener nofollow ugc\">faster rcnn-pytorch-custom-dataset <\/a> but I got this error.<\/p>\n<pre><code class=\"lang-auto\">Building model from scratch...\nTraceback (most recent call last):\n  File \"train.py\", line 491, in &lt;module&gt;\n    main(args)\n  File \"train.py\", line 248, in main\n    build_model = create_model[args['model']]\nKeyError: 'fasterrcnn_resnet50'\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced smoke_training: https:\/\/wandb.ai\/samahwa\/fastercnn-pytorch-training-pipeline\/runs\/ejy5jyw8\nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\/wandb\/run-20221128_113545-ejy5jyw8\/logs\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom plot based on a default one",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-plot-based-on-a-default-one\/3912",
        "Question_created_time":"2023-02-18T13:06:19.802Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":152,
        "Question_body":"<p>Hi,<br>\nI\u2019m finding really difficult to follow the documentation about custom plots. I am doing reinforcement learning and using the default plots that group the runs, to compare the rewards, etc. What would be the best way to replicate a default plot and change something about it? In fact, I just want to add a horizontal line (my baseline) but doing it by adding an calculated expression removes the default information.<br>\nMany thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create Parallel Coordinates plot without sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-create-parallel-coordinates-plot-without-sweeps\/3566",
        "Question_created_time":"2022-12-18T20:15:17.195Z",
        "Question_answer_count":10,
        "Question_score_count":0,
        "Question_view_count":294,
        "Question_body":"<p>It would be great to plot hparams without doing sweeps, most of the time I\u2019m doing experiments and I would love the plot to be across runs and not as a sweep. It might be complex to make this feature automated, but I\u2019m fine if it\u2019s within one run, would be great to have something like <code>wandb.plots.ParallelCoordinates<\/code><\/p>",
        "Question_closed_time":"2022-12-19T04:49:34.290Z",
        "Answer_body":"<p>Hi Faris!<\/p>\n<p>You absolutely can use Parallel coordinates plots without sweeps. The web UI has an option to add additional plots on the top right of the graph section which contains the Parallel Coordinates Plot.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to track perplexity?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-track-perplexity\/3967",
        "Question_created_time":"2023-02-28T12:55:24.604Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":82,
        "Question_body":"<p>Hello,<br>\nI\u2019m training some nlp models with huggingface, and I\u2019d like wandb to track the perplexity. How do I do this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Impossible to sync offline runs (.wandb file is empty)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/impossible-to-sync-offline-runs-wandb-file-is-empty\/3904",
        "Question_created_time":"2023-02-17T14:02:19.795Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":221,
        "Question_body":"<p>Hi,<br>\nI perform hyperparameter optimization on a SLURM-based cluster and I\u2019d like to use w&amp;b to monitor my experiments. The thing is there is no internet access on the nodes so I have to use <code>WANDB_MODE=offline<\/code> and sync manually.<\/p>\n<p>However, when I run <code>wandb sync<\/code>, nothing syncs and I get the following error:<\/p>\n<pre><code class=\"lang-auto\">$ for dir in $WORK\/wandb\/offline-run-20230217_142*; do  wandb sync --include-offline --include-synced $dir; done\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142720-t3kpu7v1\/run-t3kpu7v1.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142735-855zx96s\/run-855zx96s.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142753-gr9l3rct\/run-gr9l3rct.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142808-cq0a5u27\/run-cq0a5u27.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142830-51b47xny\/run-51b47xny.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142830-cad80jxd\/run-cad80jxd.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142847-pty3usj9\/run-pty3usj9.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142904-py7ltka6\/run-py7ltka6.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142904-w9yba4gv\/run-w9yba4gv.wandb\nFind logs at: \/tmp\/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: \/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_142904-xg1memac\/run-xg1memac.wandb\n<\/code><\/pre>\n<p>Does anybody knows why I have this issue?<\/p>\n<p>Thanks a lot!<\/p>\n<p>EDIT:<br>\non a new experiment, seeems that the folder <code>wandb<\/code> is arbitrarily created or not  depending on the trials, here is the output of <code>ls<\/code>in the folder:<\/p>\n<pre><code class=\"lang-auto\">$ ls $WORK\/wandb\/offline-run-*\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151514-8b2zeypo:\nfiles  logs  run-8b2zeypo.wandb  run-8b2zeypo.wandb.synced  tmp  wandb\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151528-vet88jij:\nfiles  logs  run-vet88jij.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151542-kpxxwmdn:\nfiles  logs  run-kpxxwmdn.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151557-yt9fz2o1:\nfiles  logs  run-yt9fz2o1.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151622-ruz8rrrk:\nfiles  logs  run-ruz8rrrk.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151622-taa9hzpw:\nfiles  logs  run-taa9hzpw.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151635-nrmgrly9:\nfiles  logs  run-nrmgrly9.wandb  tmp\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151652-10xqq0oi:\nfiles  logs  run-10xqq0oi.wandb  run-10xqq0oi.wandb.synced  tmp  wandb\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151652-cfvzpnaw:\nfiles  logs  run-cfvzpnaw.wandb  run-cfvzpnaw.wandb.synced  tmp  wandb\n\n\/gpfswork\/rech\/xsc\/uxr88bs\/wandb\/offline-run-20230217_151652-ldlx0fun:\nfiles  logs  run-ldlx0fun.wandb  tmp\n<\/code><\/pre>\n<p>the 3 runs that have a <code>wandb<\/code> folder are actually synced, so it seems that the issue is that this folder is not always created.<\/p>\n<p>Do you have an idea why?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Explain metrics displayed in WandB",
        "Question_link":"https:\/\/community.wandb.ai\/t\/explain-metrics-displayed-in-wandb\/3963",
        "Question_created_time":"2023-02-27T17:14:08.303Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":105,
        "Question_body":"<p>Hello there!<\/p>\n<p>I\u2019m looking for a thorough explanation of all the plots displayed in a basic WandB dashboard, such as:<\/p>\n<ul>\n<li>train\/loss<\/li>\n<li>train\/global_step<\/li>\n<li>train\/train_samples_per_second<\/li>\n<li>train\/train_loss<br>\nMainly, I\u2019m looking for practical info, e.g. \u201ca lower train\/train_loss is better\u201d, to be able to diagnose my model runs.<\/li>\n<\/ul>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb background services keep running even after my code ends",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-background-services-keep-running-even-after-my-code-ends\/3946",
        "Question_created_time":"2023-02-24T21:10:12.676Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_body":"<p>When I try running parallelized sweep runs, the wandb keeps waiting and doesn\u2019t terminate even when all the runs show status finished and everything has been logged. What could be the reason for this and how can I resolve this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deleting a project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/deleting-a-project\/3942",
        "Question_created_time":"2023-02-24T12:40:50.116Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":186,
        "Question_body":"<p>Hi,<\/p>\n<p>Do you know I cannot remove any project? All I get is the error below.<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/32cde7edf7c21bdf47a0cbdf8d1f6cceee469985.png\" alt=\"Screenshot 2023-02-24 at 13.38.16\" data-base62-sha1=\"7fr1yfuGSLYlugWpRB5LtXmQNaR\" width=\"381\" height=\"161\"><\/p>\n<p>It might be foolish, but I cannot sort it out.<br>\nP<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb gray scale image does not show the black color",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-gray-scale-image-does-not-show-the-black-color\/3932",
        "Question_created_time":"2023-02-22T18:51:40.839Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":106,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae1cc805b9214fb901fa6efe4ffadea5217cd402.jpeg\" data-download-href=\"\/uploads\/short-url\/oQgK6m4umuMzubtYCAHr0COqijg.jpeg?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_690x143.jpeg\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05\" data-base62-sha1=\"oQgK6m4umuMzubtYCAHr0COqijg\" width=\"690\" height=\"143\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_690x143.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_1035x214.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_1380x286.jpeg 2x\" data-dominant-color=\"C5C1B7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05<\/span><span class=\"informations\">3028\u00d7628 213 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I\u2019m trying to make a mask from the first image.<br>\nThe mask consists of 0, 1 values and it has only one channel.<br>\nTo check the image on Wandb, I used <code>wandb.Image(image)<\/code>.<br>\nBut the mask image do not show the black color, instead it describe the 0 value as gray color like second image.<\/p>\n<p>How can I make the 0 value to the black color?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting ConnectTimeout in offline mode when trying to log an image",
        "Question_link":"https:\/\/community.wandb.ai\/t\/getting-connecttimeout-in-offline-mode-when-trying-to-log-an-image\/3844",
        "Question_created_time":"2023-02-08T13:34:02.911Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":157,
        "Question_body":"<p>I am running wandb in offline mode since I don\u2019t have an internet connection on the compute nodes that I use for my experiments.<br>\nThis works fine when I\u2019m logging training loss and other things.<br>\nWhen I try to log images, however, I get the following warning <code>wandb: Network error (ConnectTimeout), entering retry loop.<\/code>  and the run waits forever.<\/p>\n<p>The logging happens through:<\/p>\n<pre><code class=\"lang-python\">images = []\nfor i in range(10):\n    images.append(wandb.Image(image[i], caption=f\"{caption}.{i}\"))\nwandb.log({category: images})\n<\/code><\/pre>\n<p>I can even see that the offline mode is active since I get the following output when I stop the run:<\/p>\n<pre><code class=\"lang-auto\">wandb: You can sync this run to the cloud by running:\nwandb: wandb sync \/scratch_emmy\/outputs\/wandb\/offline-run-20230208_142336-9685bcf5ea8d5d35ccc9d93b2d035832\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scan_history() is empty",
        "Question_link":"https:\/\/community.wandb.ai\/t\/scan-history-is-empty\/3811",
        "Question_created_time":"2023-02-03T10:24:00.337Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":236,
        "Question_body":"<p>Hi, when I run <code>run.history()<\/code>, I get a sampled version of the history as expected (although the number of samples fluctuates). But when I run <code>run.scan_history()<\/code>, I get an empty object (i.e. 0 rows).<\/p>\n<p>Any idea why this is happening or how it could be fixed?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Workspace table doesn\u2019t load",
        "Question_link":"https:\/\/community.wandb.ai\/t\/workspace-table-doesn-t-load\/3916",
        "Question_created_time":"2023-02-19T09:07:08.490Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":232,
        "Question_body":"<p>Hi, I have a problem with the table view of my Wandb project. It\u2019s made of several different sweeps running in parallel. Runs count goes on, and execution goes on smoothly, but the table won\u2019t load (see attachment). This happens both on mobile and on my pc.<\/p>\n<p>What\u2019s causing this? I\u2019m logging 30 values, and 3 confusion matrices. Could it be for what I\u2019m logging? Thanks.<\/p>\n<p>[<strong>update<\/strong> one of the three parallel processes launching sweeps were killed automatically, without a reason.]<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b5a223e92b9b824e4db5b42554519fb203a2f320.jpeg\" data-download-href=\"\/uploads\/short-url\/pUNNYCgqrPSvf5SPvmR4Xxu3Ch2.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5a223e92b9b824e4db5b42554519fb203a2f320_2_230x500.jpeg\" alt=\"image\" data-base62-sha1=\"pUNNYCgqrPSvf5SPvmR4Xxu3Ch2\" width=\"230\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5a223e92b9b824e4db5b42554519fb203a2f320_2_230x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5a223e92b9b824e4db5b42554519fb203a2f320_2_345x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b5a223e92b9b824e4db5b42554519fb203a2f320_2_460x1000.jpeg 2x\" data-dominant-color=\"232425\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1179\u00d72556 126 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"OSError: Could not find a suitable TLS CA certificate",
        "Question_link":"https:\/\/community.wandb.ai\/t\/oserror-could-not-find-a-suitable-tls-ca-certificate\/3913",
        "Question_created_time":"2023-02-18T17:28:30.448Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":170,
        "Question_body":"<p>I am using wandb with transformers library on a conda environment created on an HPC machine. When I create the environment and install the libraries, the certificate exists under the path \/conda_environments\/\/lib\/python3.8\/site-packages\/certifi\/cacert.pem<br>\nThen after a specific time of training monitoring (around 10 hours), the certificate disappears, and I get the following error, and then the training and the monitoring are stopped.<\/p>\n<p>OSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/scratch\/hpc\/\/conda_environments\/\/lib\/python3.8\/site-packages\/certifi\/cacert.pem<br>\nwandb: ERROR Internal wandb error: file data was not synced<\/p>\n<p>There is a similar issue on the GitHub repo of wandb<\/p><aside class=\"onebox githubissue\" data-onebox-src=\"https:\/\/github.com\/wandb\/wandb\/issues\/1488\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/1488\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com\/wandb\/wandb<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/1488\" target=\"_blank\" rel=\"noopener nofollow ugc\">OSError: Could not find a suitable TLS CA certificate bundle, invalid path<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-11-12\" data-time=\"19:35:10\" data-timezone=\"UTC\">07:35PM - 12 Nov 20 UTC<\/span>\n      <\/div>\n\n        <div class=\"date\">\n          closed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-11-12\" data-time=\"23:16:45\" data-timezone=\"UTC\">11:16PM - 12 Nov 20 UTC<\/span>\n        <\/div>\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/oliviersalaun\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"oliviersalaun\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/c\/cb6e0eab1644203dd4be4823241aa3788c2ccc2b.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          oliviersalaun\n        <\/a>\n      <\/div>\n    <\/div>\n\n    <div class=\"labels\">\n    <\/div>\n  <\/div>\n<\/div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">wandb            0.10.10\nPython 3.8.3\nDebian GNU\/Linux 9 (stretch)\n\nHello,\n<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026<\/a><\/span><span class=\"excerpt hidden\">\nIt seems that whenever I have a model running after a certain number of hours or iterations (in my case, it's beyond 13 hours), my script gets a problem related to some TLS CA certificate. So far, I have not found an issue similar to mine in this repository. I run my script inside a tmux pane. The output is shown below. For some reason, the process did not crash or stop, I had to terminate it manually.\n\n\n\n```\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send                                                           [1814\/1814]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send                                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify                                                               \nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem   \n                                                                                                                                                                                     \nDuring handling of the above exception, another exception occurred:                                                                                                                  \n                                                                                                                                                                                     \nTraceback (most recent call last):                                                                                                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run                                                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send                                                               \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status                                               \nMessage: 'Failed to check stop requested status: %s'                                                                                                                                 \nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)      \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run                                                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send                                                               \nMessage: 'send: stats'                                                                                                                                                               \nArguments: ()                                                                                                                                                                        \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run                                                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send                                                               \nMessage: 'send: stats'                                                                                                                                                               \nArguments: ()                                                                                                                                                                        \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                        \nCall stack:                                                                                                                                                               [1759\/1814]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                        [1704\/1814]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied                                                                                                                             [1649\/1814]\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):                                                                                                                                        [1594\/1814]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send                                                           [1526\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send                                              \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify                                       \nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n                                                                                                                                             \nDuring handling of the above exception, another exception occurred:                                                                          \n                                                                                                                                             \nTraceback (most recent call last):                                                                                                           \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status       \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise                                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper                                                              \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested                                     \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__                                                                  \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute                                                  \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute                                                 \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result                                             \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute                                     \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post                                                                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request                                                                      \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request                                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send                                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify                                                            \nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n                                                                                                                             \nDuring handling of the above exception, another exception occurred:                                                            \n                                                                                                                                      \nTraceback (most recent call last):                                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                              \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                             \nPermissionError: [Errno 13] Permission denied                                                                                                                                  \nCall stack:                                                                                                                                                                    \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                                                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                          \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run                                                   \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run                                                  \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process                                                  \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send                                                         \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request                                                \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status                                         \nMessage: 'Failed to check stop requested status: %s'                                                                                                                           \nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---                                                                                                        \nTraceback (most recent call last):                                                                                           \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                            \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                           \nPermissionError: [Errno 13] Permission denied                                                                                \nCall stack:                                                                                                                  \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                              \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                        \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run \n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send                                                    [1458\/1801]\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result                                     [1390\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap                                                                           [1322\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                        [1254\/1801]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):                                                                                                                                        [1186\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'                                                                                                                                                  [1118\/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request                                           [1050\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                      [982\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                      [914\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush                                                                         [846\/1801]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute                                          [778\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'                                                                                                                                                     [710\/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise                                                                       [642\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner                                                                      [574\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested                              [506\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit                                                                          [438\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 203, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 48, in handle\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 99, in send_request\nMessage: 'send_request: status'                                                                                                                                            [370\/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 140, in send_request_status\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/six.py\", line 702, in reraise\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 24, in wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 768, in check_stop_requested\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/old\/retry.py\", line 96, in __call__\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 130, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 52, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py\", line 60, in _get_result\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py\", line 38, in execute\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 119, in post\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 416, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 101, in send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: \/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/certifi\/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send                                                     [302\/1801]\nMessage: 'send: stats'\nArguments: ()\nValidation loss: 0.1446361123191008\n\nException in thread stdout:\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: history'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 90, in send\nMessage: 'send: summary'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 61, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 260, in _finish\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 38, in finish\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/datastore.py\", line 257, in close\nMessage: 'close: %s'\nArguments: ('\/u\/salaunol\/Documents\/_2020_automne\/1_PREDICT_ARTICLES\/wandb\/run-20201111_132925-2qrgmr2k\/run-2qrgmr2k.wandb',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 61, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 206, in _finish\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 271, in finish\nMessage: 'shutting down handler'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:                                                                                                                                                                [234\/1801]\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/multiprocessing\/spawn.py\", line 116, in spawn_main\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/multiprocessing\/spawn.py\", line 129, in _main\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/multiprocessing\/process.py\", line 315, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/multiprocessing\/process.py\", line 108, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 129, in wandb_internal\nMessage: 'Thread SenderThread:'\nArguments: ()\nThread SenderThread:\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 33, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 60, in _run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 233, in _process\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 92, in send\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 509, in send_summary\nOSError: [Errno 127] Key has expired: '\/u\/salaunol\/Documents\/_2020_automne\/1_PREDICT_ARTICLES\/wandb\/run-20201111_132925-2qrgmr2k\/files\/wandb-summary.json'\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 659, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 279, in _get_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (1, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 381, in _make_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 976, in _validate_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connection.py\", line 361, in connect\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body                                               [166\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 724, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('\/api\/5288891\/store\/', Retry(total=2, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=2, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '\/api\/5288891\/store\/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 659, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 279, in _get_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (2, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 381, in _make_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 976, in _validate_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connection.py\", line 361, in connect\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:                                                                                                                                                                 [98\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 724, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('\/api\/5288891\/store\/', Retry(total=1, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=1, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '\/api\/5288891\/store\/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 659, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 279, in _get_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (3, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 381, in _make_request                                               [30\/1801]\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 976, in _validate_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connection.py\", line 361, in connect\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 724, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('\/api\/5288891\/store\/', Retry(total=0, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=0, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '\/api\/5288891\/store\/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/threading.py\", line 870, in run\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/worker.py\", line 137, in _target\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 311, in send_event_wrapper\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 229, in _send_event\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/sentry_sdk\/transport.py\", line 174, in _send_request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 79, in request\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 171, in request_encode_body\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 336, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 752, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 659, in urlopen\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 279, in _get_conn\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (4, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"\/u\/salaunol\/anaconda3\/envs\/cuda101\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 138, in handle_exit\nMessage: 'Internal process exited'\nArguments: ()\n```<\/span><\/p>\n  <\/div>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>I reproduced this issue several times with different models and different pipelines to check that it was not something related to my code. The common pattern is that this happened only for long training (more than 10 hours)<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get all stdout from log",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-get-all-stdout-from-log\/3895",
        "Question_created_time":"2023-02-16T19:02:49.175Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":376,
        "Question_body":"<p>I am trying to get all the standard output of my run in log. I can see this screen on the web console:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/5fbacd8534d6292b5ce0a30a167fe896d30488a9.png\" data-download-href=\"\/uploads\/short-url\/dERA8zxAjiNltMHn8FqM9a3SvUt.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/5fbacd8534d6292b5ce0a30a167fe896d30488a9.png\" alt=\"image\" data-base62-sha1=\"dERA8zxAjiNltMHn8FqM9a3SvUt\" width=\"690\" height=\"337\" data-dominant-color=\"494B4D\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">776\u00d7380 69.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>However, I can\u2019t copy and paste all of the text (it only copies the current screen) and inspect element also shows that when I scroll down, other things are cleared from memory<\/p>\n<p>I would also be interested if there\u2019s a way to get this stdout from the API, too<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using the python API to delete runs without a particular tag",
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-the-python-api-to-delete-runs-without-a-particular-tag\/3818",
        "Question_created_time":"2023-02-04T07:38:33.565Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":210,
        "Question_body":"<p>How do I use the Python API to find and delete runs without a particular tag?<\/p>\n<p>I tried writing this MongoDB query, but it doesn\u2019t appear to work:<\/p>\n<pre><code class=\"lang-auto\">for r in (api.runs(\n    path...\n    filters={\"tags\": {\"$in\": \"keep\"}}\n)):\n<\/code><\/pre>\n<p>This is similar to <a href=\"https:\/\/community.wandb.ai\/t\/using-the-python-api-to-delete-models-with-no-tag-minimal\/1498\">this post<\/a><\/p>",
        "Question_closed_time":"2023-02-06T13:16:24.206Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/turian\">@turian<\/a>, thanks for your question! You can delete runs without a concrete tag with a code like:<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.runs('entity_name\/project_name')\nfor run in runs:\n  if \"keep\" not in run.tags:\n    run.delete()\n<\/code><\/pre>\n<p>Could you please try it and see if it works?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Batch size and other config parameters are inaccessible in the dashboard",
        "Question_link":"https:\/\/community.wandb.ai\/t\/batch-size-and-other-config-parameters-are-inaccessible-in-the-dashboard\/3897",
        "Question_created_time":"2023-02-16T21:31:43.752Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":143,
        "Question_body":"<p>I run this line right before the training loop:<\/p>\n<pre><code class=\"lang-auto\">wandb.config = {\n\"train_steps\": train_steps,\n\"batch_size\": batch_size,\n\"unet1_dim\": unet1_dim,\n\"unet2_dim\": unet2_dim,\n\"unet_training\": unet_training,\n}\n<\/code><\/pre>\n<p>But on the dashboard, I can\u2019t seem to find anything related to batch size. All of the data logged with <code>wandb.log<\/code> is present, but nothing about my hyperparameters. It may be relevant that I\u2019m running offline and syncing with the command <code>wandb sync --sync-all<\/code>.<\/p>",
        "Question_closed_time":"2023-02-17T22:04:09.997Z",
        "Answer_body":"<p>Hello Jaden!<\/p>\n<p>Could try logging your  <code>wandb.config<\/code>  using the following code snippet? Just in case, some further documentation on logging your config can be found <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/config#overview\">here<\/a>.<\/p>\n<pre><code class=\"lang-auto\">config = { \"train_steps\": train_steps, \"batch_size\": batch_size, \"unet1_dim\": unet1_dim, \"unet2_dim\": unet2_dim, \"unet_training\": unet_training }\nwandb.init(project = '&lt;your-project&gt;', config = config)\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Archive runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/archive-runs\/3793",
        "Question_created_time":"2023-02-01T17:46:25.873Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":328,
        "Question_body":"<p>Thanks for your good product.<\/p>\n<p>It would be good to add an archive feature for runs.<\/p>\n<p>In a project, we may try many ideas. But most of them result in no outcomes. It would be good to archive those runs to keep the workspace clean.<\/p>\n<p>It is not a good option to delete them, because we may check them in future for some cases, such as ablation study.<\/p>",
        "Question_closed_time":"2023-02-17T21:51:42.465Z",
        "Answer_body":"<p>I believe currently wandb does support multiple selection. But not in the workspace view. In the table view I can select and tag multiple runs at once.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Team members can not access moved runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/team-members-can-not-access-moved-runs\/3903",
        "Question_created_time":"2023-02-17T08:07:29.270Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_body":"<p>I moved several runs to an existing team following the description here: <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/teams#move-runs-to-a-team\" class=\"inline-onebox\">Teams - Documentation<\/a>. I can see the runs in the team workspace, however the other members of the team still can not access these runs, despite the privacy of these runs showing as \u2018team\u2019. What can I do to share the runs with other members of the team?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"--exclude-globs doesn't work in sync",
        "Question_link":"https:\/\/community.wandb.ai\/t\/exclude-globs-doesnt-work-in-sync\/3899",
        "Question_created_time":"2023-02-17T01:30:06.406Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":371,
        "Question_body":"<p>I use the command to sync offline-run:<\/p>\n<pre><code class=\"lang-shell\">wandb sync --exclude-globs \"**\/*.npy\" --sync-all\n<\/code><\/pre>\n<p>However, the *.npy files are still uploaded. The path of these files are in wandb\/run_id\/files\/array . Is the way I use --exclude-globs incorrect?<\/p>",
        "Question_closed_time":"2023-02-17T02:17:51.431Z",
        "Answer_body":"<p>Find the same question here<\/p><aside class=\"onebox githubissue\" data-onebox-src=\"https:\/\/github.com\/wandb\/wandb\/issues\/3454\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/3454\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com\/wandb\/wandb<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/3454\" target=\"_blank\" rel=\"noopener nofollow ugc\">[Q] How to use `wandb sync --exclude-globs` properly?<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2022-04-01\" data-time=\"05:52:27\" data-timezone=\"UTC\">05:52AM - 01 Apr 22 UTC<\/span>\n      <\/div>\n\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/JinchaoLove\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"JinchaoLove\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/1c4fbc24ed8493cf5d20cb695405d36a1ad9781f.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          JinchaoLove\n        <\/a>\n      <\/div>\n    <\/div>\n\n    <div class=\"labels\">\n    <\/div>\n  <\/div>\n<\/div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">Hi, I want to exclude some large files, such as `*.pt`, when uploading an offlin<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026<\/a><\/span><span class=\"excerpt hidden\">e training directory to W&amp;B. I've tried the command lines `wandb sync --exclude-globs \\*.pt offline-run-xxx` and `wandb sync --exclude-globs \"*.pt\" offline-run-xxx`,  but they doesn't seem to work. May I ask how to use the `--exclude-globs` option properly?<\/span><\/p>\n  <\/div>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Could someone please optimize the wandb Table and set the content in the center",
        "Question_link":"https:\/\/community.wandb.ai\/t\/could-someone-please-optimize-the-wandb-table-and-set-the-content-in-the-center\/3891",
        "Question_created_time":"2023-02-16T13:03:36.577Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":77,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/ea5ee2c35582498d65511b7c76629322ab82b905.png\" data-download-href=\"\/uploads\/short-url\/xrl1eIOWcCl9XiR78obN26zz8PP.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ea5ee2c35582498d65511b7c76629322ab82b905_2_690x162.png\" alt=\"image\" data-base62-sha1=\"xrl1eIOWcCl9XiR78obN26zz8PP\" width=\"690\" height=\"162\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ea5ee2c35582498d65511b7c76629322ab82b905_2_690x162.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ea5ee2c35582498d65511b7c76629322ab82b905_2_1035x243.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ea5ee2c35582498d65511b7c76629322ab82b905_2_1380x324.png 2x\" data-dominant-color=\"F2F9F0\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1761\u00d7415 18.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Configuration sweep key not appearing during sweep run nor changing values",
        "Question_link":"https:\/\/community.wandb.ai\/t\/configuration-sweep-key-not-appearing-during-sweep-run-nor-changing-values\/3868",
        "Question_created_time":"2023-02-12T20:55:21.750Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":69,
        "Question_body":"<p>I\u2019m using stable baselines 3 (SB3) and in order to use one activation function or another, you must pass it to the SB3 algo as kwargs, that is:<\/p>\n<pre><code class=\"lang-auto\">model = A2C(\n            policy=config['policy'],\n            env=env,\n            learning_rate=config['learning_rate'],\n            gae_lambda=config['gae_lambda'],\n            ent_coef=config['ent_coef'],\n            tensorboard_log=LOGS_DIR,\n            device=config['device'],\n            verbose=config['verbose'],\n\n            policy_kwargs=dict(\n                net_arch=dict(\n                    pi=config['policy_nn'],\n                    vf=config['value_nn']),\n                activation_fn=config['activation_fn'],\n                optimizer_class=config['optimizer_class'])\n        )\n<\/code><\/pre>\n<p>where:<\/p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.ReLU\n<\/code><\/pre>\n<p>or<\/p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.Tanh\n<\/code><\/pre>\n<p>If I configure the sweep dictionary key for the \u2018activation_fn\u2019 as:<\/p>\n<pre><code class=\"lang-auto\">'optimizer_fn':{\n    'values': [th.nn.ReLU, th.nn.Tanh]\n}\n<\/code><\/pre>\n<p>Afterwards when running sweeps, those values are not seen by wandb, neither in the plots appears the optimizer_fn been used nor changes to the other option.<\/p>\n<p>Is it because the sweep config dictionary only accepts string for that kind of values?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Very Large numbers in Logged Metrics in Runs Table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/very-large-numbers-in-logged-metrics-in-runs-table\/3853",
        "Question_created_time":"2023-02-09T09:20:42.253Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":90,
        "Question_body":"<p>I\u2019m running physics experiments and tracking it with WandB.<\/p>\n<p>I\u2019m tracking the logarithm of a very large number (logmetric) and a very large number directly (metric).<\/p>\n<p>The logarithmic value of the metric has a numerical value of logmetric=140, but when I track the exponentiated metric which is metric=1.3e+65, the dashboard says \u2018Infinity\u2019.<\/p>\n<p>Is my assumption correct that the dashboard simply translates very large numbers to \u2018Infinity\u2019 (which makes sense)?<br>\nIs there a way to enable scientific number representation?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why I am logging same plot all over again?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-i-am-logging-same-plot-all-over-again\/3878",
        "Question_created_time":"2023-02-14T08:47:12.266Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":147,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to log plt plot as wandb.Image in my sweep, but I have an issue. Wandb.log will log only one first one and then it logs it all over again. Can you help me guys? Pasting my log plot code.<\/p>\n<pre><code class=\"lang-python\">        for name, index in zip(names, indexes):\n            print(index)\n            pca_values = PCA().fit_transform(np.append(y_pred[:,index], y_valid[:,index],0))\n            c_map = [\"red\"] * y_pred.shape[0] + [\"green\"] * y_valid.shape[0]\n\n\n            plt.scatter(pca_values[:,0], pca_values[:,1],c=c_map, s=400,alpha=0.3)\n            for i in range(pca_values.shape[0]):\n                label = f\"P-{i}\" if i &lt; y_pred.shape[0] else str(i - y_pred.shape[0])\n                plt.text(pca_values[i,0], pca_values[i,1], label, ha=\"center\", va=\"center\", color='black')\n            plt.grid('minor')\n            plt.title(name)\n\n            wandb.log(\n                {\n                    f\"{name}_plot\" : wandb.Image(plt)\n                }\n            )\n<\/code><\/pre>\n<p>Can someone help me? It is possible that I have an issue not understanding plt correctly\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep when each experiment consists on 2 trains?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-when-each-experiment-consists-on-2-trains\/3885",
        "Question_created_time":"2023-02-15T09:40:15.003Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":117,
        "Question_body":"<p>Hi! I need to create a sweep where, for each run I actually need the script to run 2 separate training processes, as I need to pre-train some modules (one call to train.py) and then I need to train the actual model using the pre-trained parts (another call to train.py)<br>\nIs there a way of doing this?<br>\nThanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging a tensor of best model residuals",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-a-tensor-of-best-model-residuals\/3846",
        "Question_created_time":"2023-02-08T14:43:00.259Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":87,
        "Question_body":"<p>Hi, I try to log the residuals of the best model of the run and I cannot do it with the wandb_logger (lightning).<\/p>\n<p>I do:<\/p>\n<pre><code class=\"lang-auto\">self.log(\"%s_residuals\" % mode, residuals)\n<\/code><\/pre>\n<p>And I get:<\/p>\n<pre><code class=\"lang-auto\">Exception has occurred: ValueError\n`self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0').mean())`\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 241, in _calculate_loss\n    self.log(\"%s_residuals\" % mode, residuals)\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 209, in validation_step\n    self._calculate_loss(batch, mode=\"val\")\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 270, in train_model\n    trainer.fit(model, train_loader, val_loader)\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 290, in &lt;module&gt;\n    model, results = train_model(\nValueError: `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0').mean())\n<\/code><\/pre>\n<p>Any suggestion on how I can log my best model\u2019s residuals will be helpful!!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"TensorFlow 2 Object Detection API with W&B",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorflow-2-object-detection-api-with-w-b\/3770",
        "Question_created_time":"2023-01-29T19:13:33.564Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":414,
        "Question_body":"<p>Hello everyone! Firstime using Weights and biases. Came from 2 minute papers and  was pleasantly surprised when I heard 3 blue 1 brown in the promo video also! Must be a good tool if 2 of my favorite YouTubers are involved!<\/p>\n<p>Since I\u2019m a new user I included all of my resources links and images in this paste bin:<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/pastebin.com\/wQgmjADX\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/074c06983b1528839dce1ba4483d63e9070d13fa.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https:\/\/pastebin.com\/wQgmjADX\" target=\"_blank\" rel=\"noopener nofollow ugc\">Pastebin<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https:\/\/pastebin.com\/wQgmjADX\" target=\"_blank\" rel=\"noopener nofollow ugc\">[1] TensorFlow 2 Object Detection API:...<\/a><\/h3>\n\n  <p>Pastebin.com is the number one paste tool since 2002. Pastebin is a website where you can store text online for a set period of time.<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<p><em>the last link in the above paste is the link to the imgur images<\/em><\/p>\n<p>I\u2019m developing a Car Object Detection model for a university project using the TensorFlow 2 Object Detection API [1].<br>\nTo get to the point I\u2019m at now where I have a trained model for object detection I was following this tutorial: [2]<\/p>\n<p>My question is how can I Integrate W&amp;B into a \"TensorFlow 2 Object Detection API \" workflow?<\/p>\n<p>I\u2019ve searched around the internet and only found these 2 related questions:<\/p>\n<p>[3]<\/p>\n<p>[4] (first top comment is the same question)<\/p>\n<p>Both of the above sources are unanswered. So I\u2019m sure that some other people in the future might come across this same unanswered problem.<\/p>\n<p>From what I understand W&amp;B works based on callbacks from the model.fit function like so:<\/p>\n<p>[6]<\/p>\n<p>But the \"TensorFlow 2 Object Detection API \" doesn\u2019t directly use the model.fit function but it calls a python script like so:<\/p>\n<p>[7]<\/p>\n<p>(For training I then paste this command into the terminal alternatively I could also just paste it into jupyter)<\/p>\n<p>I asked chat GPT about this problem and this is the answer it provided me:<\/p>\n<p>[8]<\/p>\n<p>I tried Chat GPT\u2019s solution but the results are a bit weird:<br>\nFirst successful run:<br>\nlogs:<br>\n[9]<\/p>\n<p>Charts:<br>\n[10]<\/p>\n<p>My question is what is the correct way to integrate W&amp;B into the \"TensorFlow 2 Object Detection API \"  workflow? Have I done it correctly but am I missing something? Also, where do I specify that W&amp;B should keep track of the loss and other variables or is that done automatically?<\/p>\n<p>Here is what my training looks like in the terminal for more info:<\/p>\n<p>Executing the training command:<br>\n[11]<br>\n\u2026<br>\n<em>A lot of skipped terminal lines<\/em><br>\n\u2026<br>\nEpcoh result logging after the training kicks off:<br>\n[12]<\/p>\n<p>I hope someone can help me out and thanks for all the help I advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Download report as latex causes js errors",
        "Question_link":"https:\/\/community.wandb.ai\/t\/download-report-as-latex-causes-js-errors\/3872",
        "Question_created_time":"2023-02-13T16:48:37.404Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":218,
        "Question_body":"<p>Trying to download a report as latex causes an instrument.js error, and the waiting symbol turns forever. I use chrome on MacOS.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77.jpeg\" data-download-href=\"\/uploads\/short-url\/aV3jmQ0drwgzx2rJ9iyEpD7TJQj.jpeg?dl=1\" title=\"Bildschirmfoto 2023-02-13 um 17.42.14\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg\" alt=\"Bildschirmfoto 2023-02-13 um 17.42.14\" data-base62-sha1=\"aV3jmQ0drwgzx2rJ9iyEpD7TJQj\" width=\"690\" height=\"307\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1035x460.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1380x614.jpeg 2x\" data-dominant-color=\"959190\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Bildschirmfoto 2023-02-13 um 17.42.14<\/span><span class=\"informations\">1886\u00d7841 173 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2023-02-13T18:06:38.268Z",
        "Answer_body":"<p>Found a solution: When carefully loading each graph by scrolling slowly over the whole page, the download finally works.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Network error (SSLError), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/network-error-sslerror-entering-retry-loop\/3641",
        "Question_created_time":"2023-01-05T00:30:47.654Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":742,
        "Question_body":"<p>I am getting this error:<\/p>\n<p>$ python3 wandb-python4.py<br>\nwandb: W&amp;B API key is configured. Use <code>wandb login --relogin<\/code> to force relogin<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nProblem at: \/home\/hp\/wandb-python4.py 4 <br>\nwandb: ERROR Error communicating with wandb process<br>\nwandb: ERROR For more info see: <a href=\"https:\/\/docs.wandb.ai\/library\/init#init-start-error\">https:\/\/docs.wandb.ai\/library\/init#init-start-error<\/a><br>\nTraceback (most recent call last):<br>\nFile \u201c\/home\/hp\/wandb-python4.py\u201d, line 4, in <br>\nrun = wandb.init(project=\u201cwandb-test\u201d)<br>\nFile \u201c\/home\/hp\/.local\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 1078, in init<br>\nrun = wi.init()<br>\nFile \u201c\/home\/hp\/.local\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 719, in init<br>\nraise UsageError(error_message)<br>\nwandb.errors.UsageError: Error communicating with wandb process<br>\nFor more info see: <a href=\"https:\/\/docs.wandb.ai\/library\/init#init-start-error\">https:\/\/docs.wandb.ai\/library\/init#init-start-error<\/a><br>\nwandb: Waiting for W&amp;B process to finish\u2026 (failed 1). Press Control-C to abort syncing.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Trying to run wandb on azure ml, running into issues",
        "Question_link":"https:\/\/community.wandb.ai\/t\/trying-to-run-wandb-on-azure-ml-running-into-issues\/3876",
        "Question_created_time":"2023-02-13T22:36:53.326Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":394,
        "Question_body":"<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1133, in init\n    run = wi.init()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py\", line 787, in init\n    run_start_result = run_start_handle.wait(timeout=30)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 271, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nwandb: ERROR Abnormal program exit\n2023-02-13 22:32:43,972 - mmseg - INFO - Loaded 20000 images\n\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/models\/backbones\/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/models\/losses\/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n  warnings.warn(\n2023-02-13 22:32:52,439 - mmseg - INFO - Loaded 2500 images\n2023-02-13 22:32:52,458 - mmseg - INFO - Start running, host: azureuser@vardhan-cvml, work_dir: \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/work_dirs\/logs\/deeplabv3plus\n2023-02-13 22:32:52,459 - mmseg - INFO - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n -------------------- \nafter_train_iter:\n(ABOVE_NORMAL) OptimizerHook                      \n(NORMAL      ) CheckpointHook                     \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_train_epoch:\n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_epoch:\n(LOW         ) IterTimerHook                      \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_epoch:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_run:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \n2023-02-13 22:32:52,460 - mmseg - INFO - workflow: [('train', 1)], max: 50000 iters\n2023-02-13 22:32:52,460 - mmseg - INFO - Checkpoints will be saved to \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/work_dirs\/logs\/deeplabv3plus by HardDiskBackend.\n2023-02-13 22:32:52.816987: I tensorflow\/core\/platform\/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-13 22:32:59.646354: W tensorflow\/compiler\/xla\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/cv2\/..\/..\/lib64:\n2023-02-13 22:32:59.646501: W tensorflow\/compiler\/xla\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/cv2\/..\/..\/lib64:\n2023-02-13 22:32:59.646517: W tensorflow\/compiler\/tf2tensorrt\/utils\/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nwandb: Currently logged in as: don_v. Use `wandb login --relogin` to force relogin\nThread HandlerThread:\nTraceback (most recent call last):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 49, in run\n    self._run()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 280, in _process\n    self._hm.handle(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 136, in handle\n    handler(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 146, in handle_request\n    handler(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 695, in handle_request_run_start\n    self._system_monitor.probe(publish=True)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_monitor.py\", line 186, in probe\n    self.system_info.publish(system_info)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_info.py\", line 252, in publish\n    self._save_patches()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_info.py\", line 134, in _save_patches\n    if self.git.dirty:\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/git.py\", line 76, in dirty\n    return self.repo.is_dirty()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/repo\/base.py\", line 795, in is_dirty\n    if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 696, in &lt;lambda&gt;\n    return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 1270, in _call_process\n    return self.execute(call, **exec_kwargs)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 1064, in execute\n    raise GitCommandError(redacted_command, status, stderr_value, stdout_value)\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(129)\n  cmdline: git diff --cached --abbrev=40 --full-index --raw\n  stderr: 'error: unknown option `cached'\nusage: git diff --no-index [&lt;options&gt;] &lt;path&gt; &lt;path&gt;\n\nDiff output format options\n    -p, --patch           generate patch\n    -s, --no-patch        suppress diff output\n    -u                    generate patch\n    -U, --unified[=&lt;n&gt;]   generate diffs with &lt;n&gt; lines context\n    -W, --function-context\n                          generate diffs with &lt;n&gt; lines context\n    --raw                 generate the diff in raw format\n    --patch-with-raw      synonym for '-p --raw'\n    --patch-with-stat     synonym for '-p --stat'\n    --numstat             machine friendly --stat\n    --shortstat           output only the last line of --stat\n    -X, --dirstat[=&lt;param1,param2&gt;...]\n                          output the distribution of relative amount of changes for each sub-directory\n    --cumulative          synonym for --dirstat=cumulative\n    --dirstat-by-file[=&lt;param1,param2&gt;...]\n                          synonym for --dirstat=files,param1,param2...\n    --check               warn if changes introduce conflict markers or whitespace errors\n    --summary             condensed summary such as creations, renames and mode changes\n    --name-only           show only names of changed files\n    --name-status         show only names and status of changed files\n    --stat[=&lt;width&gt;[,&lt;name-width&gt;[,&lt;count&gt;]]]\n                          generate diffstat\n    --stat-width &lt;width&gt;  generate diffstat with a given width\n    --stat-name-width &lt;width&gt;\n                          generate diffstat with a given name width\n    --stat-graph-width &lt;width&gt;\n                          generate diffstat with a given graph width\n    --stat-count &lt;count&gt;  generate diffstat with limited lines\n    --compact-summary     generate compact summary in diffstat\n    --binary              output a binary diff that can be applied\n    --full-index          show full pre- and post-image object names on the \"index\" lines\n    --color[=&lt;when&gt;]      show colored diff\n    --ws-error-highlight &lt;kind&gt;\n                          highlight whitespace errors in the 'context', 'old' or 'new' lines in the diff\n    -z                    do not munge pathnames and use NULs as output field terminators in --raw or --numstat\n    --abbrev[=&lt;n&gt;]        use &lt;n&gt; digits to display object names\n    --src-prefix &lt;prefix&gt;\n                          show the given source prefix instead of \"a\/\"\n    --dst-prefix &lt;prefix&gt;\n                          show the given destination prefix instead of \"b\/\"\n    --line-prefix &lt;prefix&gt;\n                          prepend an additional prefix to every line of output\n    --no-prefix           do not show any source or destination prefix\n    --inter-hunk-context &lt;n&gt;\n                          show context between diff hunks up to the specified number of lines\n    --output-indicator-new &lt;char&gt;\n                          specify the character to indicate a new line instead of '+'\n    --output-indicator-old &lt;char&gt;\n                          specify the character to indicate an old line instead of '-'\n    --output-indicator-context &lt;char&gt;\n                          specify the character to indicate a context instead of ' '\n\nDiff rename options\n    -B, --break-rewrites[=&lt;n&gt;[\/&lt;m&gt;]]\n                          break complete rewrite changes into pairs of delete and create\n    -M, --find-renames[=&lt;n&gt;]\n                          detect renames\n    -D, --irreversible-delete\n                          omit the preimage for deletes\n    -C, --find-copies[=&lt;n&gt;]\n                          detect copies\n    --find-copies-harder  use unmodified files as source to find copies\n    --no-renames          disable rename detection\n    --rename-empty        use empty blobs as rename source\n    --follow              continue listing the history of a file beyond renames\n    -l &lt;n&gt;                prevent rename\/copy detection if the number of rename\/copy targets exceeds given limit\n\nDiff algorithm options\n    --minimal             produce the smallest possible diff\n    -w, --ignore-all-space\n                          ignore whitespace when comparing lines\n    -b, --ignore-space-change\n                          ignore changes in amount of whitespace\n    --ignore-space-at-eol\n                          ignore changes in whitespace at EOL\n    --ignore-cr-at-eol    ignore carrier-return at the end of line\n    --ignore-blank-lines  ignore changes whose lines are all blank\n    -I, --ignore-matching-lines &lt;regex&gt;\n                          ignore changes whose all lines match &lt;regex&gt;\n    --indent-heuristic    heuristic to shift diff hunk boundaries for easy reading\n    --patience            generate diff using the \"patience diff\" algorithm\n    --histogram           generate diff using the \"histogram diff\" algorithm\n    --diff-algorithm &lt;algorithm&gt;\n                          choose a diff algorithm\n    --anchored &lt;text&gt;     generate diff using the \"anchored diff\" algorithm\n    --word-diff[=&lt;mode&gt;]  show word diff, using &lt;mode&gt; to delimit changed words\n    --word-diff-regex &lt;regex&gt;\n                          use &lt;regex&gt; to decide what a word is\n    --color-words[=&lt;regex&gt;]\n                          equivalent to --word-diff=color --word-diff-regex=&lt;regex&gt;\n    --color-moved[=&lt;mode&gt;]\n                          moved lines of code are colored differently\n    --color-moved-ws &lt;mode&gt;\n                          how white spaces are ignored in --color-moved\n\nOther diff options\n    --relative[=&lt;prefix&gt;]\n                          when run from subdir, exclude changes outside and show relative paths\n    -a, --text            treat all files as text\n    -R                    swap two inputs, reverse the diff\n    --exit-code           exit with 1 if there were differences, 0 otherwise\n    --quiet               disable all output of the program\n    --ext-diff            allow an external diff helper to be executed\n    --textconv            run external text conversion filters when comparing binary files\n    --ignore-submodules[=&lt;when&gt;]\n                          ignore changes to submodules in the diff generation\n    --submodule[=&lt;format&gt;]\n                          specify how differences in submodules are shown\n    --ita-invisible-in-index\n                          hide 'git add -N' entries from the index\n    --ita-visible-in-index\n                          treat 'git add -N' entries as real in the index\n    -S &lt;string&gt;           look for differences that change the number of occurrences of the specified string\n    -G &lt;regex&gt;            look for differences that change the number of occurrences of the specified regex\n    --pickaxe-all         show all changes in the changeset with -S or -G\n    --pickaxe-regex       treat &lt;string&gt; in -S as extended POSIX regular expression\n    -O &lt;file&gt;             control the order in which files appear in the output\n    --rotate-to &lt;path&gt;    show the change in the specified path first\n    --skip-to &lt;path&gt;      skip the output to the specified path\n    --find-object &lt;object-id&gt;\n                          look for differences that change the number of occurrences of the specified object\n    --diff-filter [(A|C|D|M|R|T|U|X|B)...[*]]\n                          select files by diff type\n    --output &lt;file&gt;       output to a specific file\n'\nwandb: ERROR Internal wandb error: file data was not synced\nProblem at: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/hooks\/logger\/wandb.py 83 before_run\n---------------------------------------------------------------------------\nMailboxError                              Traceback (most recent call last)\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:1133, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1132 try:\n-&gt; 1133     run = wi.init()\n   1134     except_exit = wi.settings._except_exit\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:787, in _WandbInit.init(self)\n    786 # TODO: add progress to let user know we are doing something\n--&gt; 787 run_start_result = run_start_handle.wait(timeout=30)\n    788 if run_start_result is None:\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/mailbox.py:271, in MailboxHandle.wait(self, timeout, on_probe, on_progress, release, cancel)\n    270     if self._interface._transport_keepalive_failed():\n--&gt; 271         raise MailboxError(\"transport failed\")\n    273 found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n\nMailboxError: transport failed\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\nInput In [8], in &lt;cell line: 20&gt;()\n     14 model.CLASSES = datasets[0].CLASSES\n     16 # Create work_dir\n     17 # mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n---&gt; 20 train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n     21                 meta=dict())\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/apis\/train.py:194, in train_segmentor(model, dataset, cfg, distributed, validate, timestamp, meta)\n    192 elif cfg.load_from:\n    193     runner.load_checkpoint(cfg.load_from)\n--&gt; 194 runner.run(data_loaders, cfg.workflow)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/iter_based_runner.py:126, in IterBasedRunner.run(self, data_loaders, workflow, max_iters, **kwargs)\n    122 self.logger.info('Hooks will be executed in the following order:\\n%s',\n    123                  self.get_hook_info())\n    124 self.logger.info('workflow: %s, max: %d iters', workflow,\n    125                  self._max_iters)\n--&gt; 126 self.call_hook('before_run')\n    128 iter_loaders = [IterLoader(x) for x in data_loaders]\n    130 self.call_hook('before_epoch')\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/base_runner.py:317, in BaseRunner.call_hook(self, fn_name)\n    310 \"\"\"Call all hooks.\n    311 \n    312 Args:\n    313     fn_name (str): The function name in each hook to be called, such as\n    314         \"before_train_epoch\".\n    315 \"\"\"\n    316 for hook in self._hooks:\n--&gt; 317     getattr(hook, fn_name)(self)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/core\/hook\/wandblogger_hook.py:106, in MMSegWandbHook.before_run(self, runner)\n    104 @master_only\n    105 def before_run(self, runner):\n--&gt; 106     super(MMSegWandbHook, self).before_run(runner)\n    108     # Check if EvalHook and CheckpointHook are available.\n    109     for hook in runner.hooks:\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/hooks\/logger\/wandb.py:83, in WandbLoggerHook.before_run(self, runner)\n     81     self.import_wandb()\n     82 if self.init_kwargs:\n---&gt; 83     self.wandb.init(**self.init_kwargs)  # type: ignore\n     84 else:\n     85     self.wandb.init()\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:1170, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1168         if except_exit:\n   1169             os._exit(1)\n-&gt; 1170         raise Exception(\"problem\") from error_seen\n   1171 return run\n\nException: problem\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot create academic team",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-create-academic-team\/3849",
        "Question_created_time":"2023-02-08T15:30:47.160Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":323,
        "Question_body":"<p>Unfortunately, I am not able to create an academic team, although my university email address is added in to the profile: b.khaertdinov[at]maastrichtuniversity.nl<\/p>\n<p>Any tips on how to solve this issue are very welcome!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't toggle button for magic link to share report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cant-toggle-button-for-magic-link-to-share-report\/3847",
        "Question_created_time":"2023-02-08T15:13:28.411Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":124,
        "Question_body":"<p>Hi there, I\u2019m new to W&amp;B and was exploring the Report functionality. When trying to share a report publicly I\u2019m unable to toggle the radio button for \u201cAnyone with the magic link can view\u201d, and thus unable to see and share the magic link. From looking through documentation it doesn\u2019t appear as though any other settings are required to be set on my end, but I\u2019ve wondered if I\u2019ve missed something. I\u2019m using W&amp;B through a free personal use account, and I\u2019ve tried this on Chrome and Safari.  I was thinking this feature might have been paywalled recently but I was unable to find if that had been the case. Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb error by usage of mlflow and hydra regarding protobuf lib",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-by-usage-of-mlflow-and-hydra-regarding-protobuf-lib\/3866",
        "Question_created_time":"2023-02-12T17:17:38.609Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":234,
        "Question_body":"<p>Hi all,<br>\nhaving an issue and need some help for Python project inside a Udacity course.<br>\nWe shall use Python 3.8, therefore I am using 3.8.16 and having created a virtual env starting from that version and activated virtual env.<\/p>\n<p>Using Jupyter Lab I am trying to use a pipeline for mlflow, hydra and wandb I am getting the same error as mentioned e.g. in<\/p><aside class=\"onebox githubissue\" data-onebox-src=\"https:\/\/github.com\/espnet\/espnet\/issues\/3708\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/github.com\/espnet\/espnet\/issues\/3708\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com\/espnet\/espnet<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/espnet\/espnet\/issues\/3708\" target=\"_blank\" rel=\"noopener nofollow ugc\">Wandb 0.12.6 leads to Import Failure. Works on reverting to 0.12.2<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2021-10-28\" data-time=\"01:09:34\" data-timezone=\"UTC\">01:09AM - 28 Oct 21 UTC<\/span>\n      <\/div>\n\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/gdebayan\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"gdebayan\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/587184763eb7c4bb085cf14a54010a65cd8272aa.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          gdebayan\n        <\/a>\n      <\/div>\n    <\/div>\n\n    <div class=\"labels\">\n        <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">\n          Bug\n        <\/span>\n    <\/div>\n  <\/div>\n<\/div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">While Looking up ESPNet using this Tutorial: https:\/\/colab.research.google.com\/d<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026<\/a><\/span><span class=\"excerpt hidden\">rive\/1L85G7jdhsI1QKs2o0qCGEbhm5X4QV2zN\n\nI came across this issue when the Library \"Wandb\" is imported.\n\n```\n# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel data\/token_list\/bpe_unigram30\/bpe.model --token_type bpe --token_list data\/token_list\/bpe_unigram30\/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type dump\/raw\/train_nodev\/wav.scp,speech,sound --train_data_path_and_name_and_type dump\/raw\/train_nodev\/text,text,text --valid_data_path_and_name_and_type dump\/raw\/train_dev\/wav.scp,speech,sound --valid_data_path_and_name_and_type dump\/raw\/train_dev\/text,text,text --train_shape_file exp\/asr_stats_raw_bpe30\/logdir\/train.32.scp --valid_shape_file exp\/asr_stats_raw_bpe30\/logdir\/valid.32.scp --output_dir exp\/asr_stats_raw_bpe30\/logdir\/stats.32 --frontend_conf fs=16k\u00a0\n# Started at Wed Oct 27 16:36:43 EDT 2021\n```\n\n```\n\u00a0 \u00a0 from .wandb_init import _attach, init \u00a0# noqa: F401\n\u00a0 File \"\/home\/debayan\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 35, in &lt;module&gt;\n\u00a0 \u00a0 from .backend.backend import Backend\n\u00a0 File \"\/home\/debayan\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/backend\/backend.py\", line 20, in &lt;module&gt;\n\u00a0 \u00a0 from ..interface import interface\n\u00a0 File \"\/home\/debayan\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 21, in &lt;module&gt;\n\u00a0 \u00a0 from wandb.proto import wandb_internal_pb2 as pb\n\u00a0 File \"\/home\/debayan\/.local\/lib\/python3.8\/site-packages\/wandb\/proto\/wandb_internal_pb2.py\", line 15, in &lt;module&gt;\n\u00a0 \u00a0 from wandb.proto import wandb_base_pb2 as wandb_dot_proto_dot_wandb__base__pb2\n\u00a0 File \"\/home\/debayan\/.local\/lib\/python3.8\/site-packages\/wandb\/proto\/wandb_base_pb2.py\", line 21, in &lt;module&gt;\n\u00a0 \u00a0 create_key=_descriptor._internal_create_key,\nAttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key\n```\n\nThis was in Wandb version 0.12.6 .\n\nHowever, when I reverted to Wandb version 0.12.2, it started working as expected.\n\nFeel free to reach out if any questions!<\/span><\/p>\n  <\/div>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>I tried already the mentioned protobuf version 3.20.0 and 3.20.1 and different wandb versions via conda.yml, always getting the same error:<\/p>\n<pre><code class=\"lang-auto\">name: download_data\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.8\n  - requests=2.24.0\n  - pip=20.3.3\n  - mlflow=2.1.1\n  - hydra-core=1.3.1      #1.0.6\n#  - wandb=0.13.10\n  - pip:\n      #- wandb==0.10.21\n      - protobuf==3.20.0\n      - wandb==0.12.2\n      - hydra-joblib-launcher==1.1.2\n<\/code><\/pre>\n<p>Still getting the following stacktrace for the ML model and its param setting:<br>\n<img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/sun_with_face.png?v=12\" title=\":sun_with_face:\" class=\"emoji\" alt=\":sun_with_face:\" loading=\"lazy\" width=\"20\" height=\"20\"> <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/x.png?v=12\" title=\":x:\" class=\"emoji\" alt=\":x:\" loading=\"lazy\" width=\"20\" height=\"20\">  mlflow run . -P hydra_options=\u201crandom_forest_pipeline.random_forest.max_depth=5\u201d<br>\n2023\/02\/12 17:55:15 INFO mlflow.utils.conda: === Creating conda environment mlflow-8284cfd5101c5c151da499d35f932662f514265c ===<br>\nCollecting package metadata (repodata.json): \u2026working\u2026 done<br>\nSolving environment: \u2026working\u2026 done<br>\nPreparing transaction: \u2026working\u2026 done<br>\nVerifying transaction: \u2026working\u2026 done<br>\nExecuting transaction: \u2026working\u2026 done<br>\nInstalling pip dependencies: \u2026working\u2026 done<br>\n2023\/02\/12 18:02:28 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpcv9ww8ry for downloading remote URIs passed to arguments of type \u2018path\u2019 ===<br>\n2023\/02\/12 18:02:28 INFO mlflow.projects.backend.local: === Running command \u2018source \/home\/ilona\/miniconda3\/bin\/\u2026\/etc\/profile.d\/conda.sh &amp;&amp; conda activate mlflow-8284cfd5101c5c151da499d35f932662f514265c 1&gt;&amp;2 &amp;&amp; python main.py $(echo random_forest_pipeline.random_forest.max_depth=5)\u2019 in run with ID \u2018a6d323399b9242c1b227bae18109b69d\u2019 ===<br>\n2023\/02\/12 18:02:39 INFO mlflow.utils.conda: Conda environment mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f already exists.<br>\n2023\/02\/12 18:02:39 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpsxd_dtnx for downloading remote URIs passed to arguments of type \u2018path\u2019 ===<br>\n2023\/02\/12 18:02:39 INFO mlflow.projects.backend.local: === Running command \u2018source \/home\/ilona\/miniconda3\/bin\/\u2026\/etc\/profile.d\/conda.sh &amp;&amp; conda activate mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f 1&gt;&amp;2 &amp;&amp; python run.py --train_data exercise_6\/data_train.csv:latest <br>\n\u2013model_config \/home\/ilona\/MLOps\/nd0821-c2-build-model-workflow-exercises\/lesson-4-training-validation-experiment-tracking\/exercises\/exercise_11\/starter\/outputs\/2023-02-12\/18-02-33\/random_forest_config.yml\u2019 in run with ID \u201859002ca997e54d1dac9fd30e5a418009\u2019 ===<br>\nTraceback (most recent call last):<br>\nFile \u201crun.py\u201d, line 15, in <br>\nimport wandb<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/<strong>init<\/strong>.py\u201d, line 38, in <br>\nfrom wandb import sdk as wandb_sdk<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/sdk\/<strong>init<\/strong>.py\u201d, line 12, in <br>\nfrom .wandb_init import init  # noqa: F401<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 29, in <br>\nfrom .backend.backend import Backend<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/sdk\/backend\/backend.py\u201d, line 17, in <br>\nfrom \u2026interface import interface<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface.py\u201d, line 18, in <br>\nfrom wandb.proto import wandb_internal_pb2 as pb<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/proto\/wandb_internal_pb2.py\u201d, line 15, in <br>\nfrom wandb.proto import wandb_telemetry_pb2 as wandb_dot_proto_dot_wandb__telemetry__pb2<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/wandb\/proto\/wandb_telemetry_pb2.py\u201d, line 34, in <br>\n_descriptor.FieldDescriptor(<br>\nFile \u201c\/home\/ilona\/miniconda3\/envs\/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f\/lib\/python3.8\/site-packages\/google\/protobuf\/descriptor.py\u201d, line 560, in <strong>new<\/strong><br>\n_message.Message._CheckCalledFromGeneratedFile()<br>\nTypeError: Descriptors cannot not be created directly.<br>\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.<br>\nIf you cannot immediately regenerate your protos, some other possible workarounds are:<\/p>\n<ol>\n<li>Downgrade the protobuf package to 3.20.x or lower.<\/li>\n<li>Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).<\/li>\n<\/ol>\n<p>More information: <a href=\"https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Changes made on May 6, 2022 | Protocol Buffers Documentation<\/a><br>\n\u2026<\/p>\n<p>In advance, thank you very much for help and solution proposals,<br>\nIlona<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Network error (ConnectTimeout), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/network-error-connecttimeout-entering-retry-loop\/3772",
        "Question_created_time":"2023-01-29T19:59:37.391Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":220,
        "Question_body":"<p>Hello,<\/p>\n<p>After several tries I am getting stuck when finishing a run about data uploading. It always throws the same error and it seems it \u2018kills\u2019 my network, consuming all resources as when I try to access other pages the internet is very slow.<\/p>\n<p>When I try to do the tests I always have a good connection (around 600Mb), and I tried on different days. I never have connection cuts, just when doing the run finish.<\/p>\n<p>The error I have is the following:<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/a27d197a4c8825679f7e5c459ef89d5f87a2a192.png\" alt=\"Selection_001\" data-base62-sha1=\"nbrnemiqAtyylTXSAgkOD1SYaSS\" width=\"573\" height=\"182\"><\/p>",
        "Question_closed_time":"2023-01-31T21:03:27.678Z",
        "Answer_body":"<p>Hey Mario!<\/p>\n<p>We have been having an influx of traffic lately. Please try again and if you still run into the ConnectTimeout Network error, please send us your debug.log so we can take a closer look.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to sync offline run on another computer?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-sync-offline-run-on-another-computer\/3812",
        "Question_created_time":"2023-02-03T10:29:51.263Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":420,
        "Question_body":"<p>The offline runs are generated by computer A. Because of the lack of network on A, I copied the whole wandb directory to another computer B and excuted the sync command on B. But I have:<\/p>\n<pre><code class=\"lang-shell\">wandb: No runs to be synced.\n<\/code><\/pre>\n<p>I want to know is this way possible?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sync runs on server to a local instance",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sync-runs-on-server-to-a-local-instance\/3829",
        "Question_created_time":"2023-02-06T05:08:33.525Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":267,
        "Question_body":"<p>Hi Everyone.<br>\nI have run wandb in offline mode on a server. However, I don\u2019t want to run <code>wandb.sync<\/code> on them.  I have downloaded the wandb folder to my local pc. I am wondering if there is anyway to look at the logs stored in this wandb folder maybe through a local wandb instance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.watch() when using mixed precision and torch.cuda.amp.GradScaler()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-watch-when-using-mixed-precision-and-torch-cuda-amp-gradscaler\/3754",
        "Question_created_time":"2023-01-26T09:36:28.461Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":102,
        "Question_body":"<p>I have a PyTorch project where I\u2019m using mixed precision gradient scaling. When using <code>wandb.watch()<\/code> to log model gradients  is it possible to unscale them using something like scaler.unscale() at some point in the code prior to logging? My code looks something like the below.<\/p>\n<pre><code class=\"lang-auto\">wandb.init(project=\"my_project\", name='my_run', config=config, mode='online')\nmodel = Net()\nwandb.watch(model, log='all')\noptimiser = my_optim(model.parameters(),lr=lr)\n\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\nfor epoch in range(epochs):\n    for input, target in train_loader:\n        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n             pred = model(input) \n             loss = loss_fn(input, target)\n        scaler.scale(loss).backward()\n        scaler.step(optimiser)\n        scaler.update()\n        optimiser.zero_grad(set_to_none=True)\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accelerate launch and WandB agent , run the main function 4 seperate times for 4 GPUS",
        "Question_link":"https:\/\/community.wandb.ai\/t\/accelerate-launch-and-wandb-agent-run-the-main-function-4-seperate-times-for-4-gpus\/3809",
        "Question_created_time":"2023-02-03T08:57:56.045Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":428,
        "Question_body":"<p>Hello,<\/p>\n<p>So I have changed my YAML file environment variable from \u201cpython3\u201d to \u201caccelerate launch\u201d.  I am trying to use this in conjunction with wandb agent &lt;username\/proj_name\/sweep_id&gt; on a SLURM compute cluster.<\/p>\n<p>So the error is that it runs the main function 4 times, which then instantiates the arguments 4 times and we error out because it is trying to create a page that was created on the first step. And then inevitably fails.<\/p>\n<p>I should mention that the script does work with just python3 and so it is a matter of using \u201caccelerate launch\u201d to take advantage of my multiple GPUs.<\/p>\n<pre><code class=\"lang-bash\">#!\/bin\/bash\n#SBATCH --job-name=tav_mae\n# Give job a name\n#SBATCH --time 02-20:00 # time (DD-HH:MM)\n#SBATCH --nodes=1\n#SBATCH --gpus-per-node=v100l:4 # request GPU\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=6 # maximum CPU cores per GPU request: 6 on Cedar, 16 on Graham.\n#SBATCH --mem=150G # memory per node\n#SBATCH --account=ctb-whkchun # Runs it on the dedicated nodes we have\n#SBATCH --output=\/scratch\/prsood\/tav_mae\/logs\/%N-%j.out # %N for node name, %j for jobID # Remember to mae logs-dir\nmodule load StdEnv\/2020\nmodule load cuda\nmodule load cudnn\/8.0.3\nwandb agent ddi\/TAVFormer2\/ncdfi75j --count 20\n<\/code><\/pre>\n<p>YAML configuration file:<\/p>\n<pre data-code-wrap=\"YAML\"><code class=\"lang-plaintext\">program: ..\/tav_nn.py\ncommand:\n  - ${env}\n  - accelerate\n  - launch\n  - ${program}\n  - \"--dataset\"\n\nmethod: bayes\n\nmetric:\n  goal: minimize\n  name: train\/train_loss\nparameters:\n  epoch: \n    values: [5 , 7 , 9]\n  learning_rate:\n    distribution: uniform\n    min: 0.000001\n    max: 0.0001\n  batch_size:\n    values: [2 , 4 , 8 , 1]\n  weight_decay:\n    values: [0.0001 , 0.00001 , 0.000001 , 0.0000001, 0.00000001]  \n  seed:\n    values: [32, 64, 96]\n  dropout:\n    values: [0.0,0.1,0.2]\n  early_div:\n    values: [True,False]\n  patience:\n    values: [10]\n  clip:\n    values: [1]\n  T_max:\n   values: [5,10]\n  hidden_layers:\n    values: [\"300\"]\n<\/code><\/pre>\n<p>Error output<\/p>\n<pre data-code-wrap=\"console\"><code class=\"lang-plaintext\">wandb: Starting wandb agent \ud83d\udd75\ufe0f\n2023-02-03 00:32:20,126 - wandb.wandb_agent - INFO - Running runs: []\n2023-02-03 00:32:21,726 - wandb.wandb_agent - INFO - Agent received command: run\n2023-02-03 00:32:21,728 - wandb.wandb_agent - INFO - Agent starting run with config:\n        T_max: 10\n        batch_size: 2\n        clip: 1\n        dropout: 0.1\n        early_div: True\n        epoch: 7\n        hidden_layers: 300\n        label_task: emotion\n        learning_rate: 3.736221739657802e-05\n        model: MAE_encoder\n        patience: 10\n        seed: 96\n        weight_decay: 0.0001\n2023-02-03 00:32:21,736 - wandb.wandb_agent - INFO - About to run command: \/usr\/bin\/env accelerate launch ..\/tav_nn.py --dataset ..\/..\/data\/IEMOCAP_df\n2023-02-03 00:32:26,772 - wandb.wandb_agent - INFO - Running runs: ['6fnujhey']\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nThread WriterThread: wandb.init()...\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 28, in write\n    self.open()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '\/project\/6051551\/prsood\/multi-modal-emotion\/TripleModels\/run_slurm\/wandb\/run-20230203_003340-6fnujhey\/run-6fnujhey.wandb'\nThread WriterThread:\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 28, in write\n    self.open()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '\/project\/6051551\/prsood\/multi-modal-emotion\/TripleModels\/run_slurm\/wandb\/run-20230203_003340-6fnujhey\/run-6fnujhey.wandb'\nThread WriterThread:\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 28, in write\n    self.open()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '\/project\/6051551\/prsood\/multi-modal-emotion\/TripleModels\/run_slurm\/wandb\/run-20230203_003340-6fnujhey\/run-6fnujhey.wandb'\nwandb: ERROR Internal wandb error: file data was not synced\nProblem at: ..\/tav_nn.py 106 main...\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 739, in init\n    _ = backend.interface.communicate_run_start(run_obj)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 235, in communicate_run_start\n    result = self._communicate_run_start(run_start)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 484, in _communicate_run_start\n    result = self._communicate(rec)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 255, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/router_sock.py\", line 36, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\nwandb: ERROR Abnormal program exit..\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 739, in init\n    _ = backend.interface.communicate_run_start(run_obj)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 235, in communicate_run_start\n    result = self._communicate_run_start(run_start)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 484, in _communicate_run_start\n    result = self._communicate(rec)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 255, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/interface\/router_sock.py\", line 36, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"..\/tav_nn.py\", line 183, in &lt;module&gt;\n    main()\n  File \"..\/tav_nn.py\", line 106, in main\n    run = wandb.init(project=project_name, entity=\"ddi\" , config = args)\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1116, in init\n    raise Exception(\"problem\") from error_seen\nException: problem\nProblem at:Problem at:Problem at: ..\/tav_nn.py 106 main\n ..\/tav_nn.py  106..\/tav_nn.py  main106\n main\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\nwandb.errors.MailboxError: transport failed\n  File \"\/project\/6051551\/prsood\/sarcasm_venv\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213168 closing signal SIGTERM\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213170 closing signal SIGTERM\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213171 closing signal SIGTERM\nERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 213169) of binary: \/project\/6051551\/prsood\/sarcasm_venv\/bin\/python3\n2023-02-03 00:33:54,480 - wandb.wandb_agent - INFO - Cleaning up finished run: 6fnujhey\n<\/code><\/pre>\n<p>accelerate config file:<\/p>\n<pre><code class=\"lang-bash\">- `Accelerate` version: 0.16.0\n- Platform: Linux-3.10.0-1160.80.1.el7.x86_64-x86_64-with-centos-7.9.2009-Core\n- Python version: 3.7.7\n- Numpy version: 1.21.4\n- PyTorch version (GPU?): 1.10.0 (False)\n- `Accelerate` default config:\n        - compute_environment: LOCAL_MACHINE\n        - distributed_type: FSDP\n        - mixed_precision: no\n        - use_cpu: False\n        - dynamo_backend: NO\n        - num_processes: 4\n        - machine_rank: 0\n        - num_machines: 1\n        - rdzv_backend: static\n        - same_network: True\n        - main_training_function: main\n        - deepspeed_config: {}\n        - fsdp_config: {'fsdp_auto_wrap_policy': 'TRANSFORMER_BASED_WRAP', 'fsdp_backward_prefetch_policy': 'BACKWARD_PRE', 'fsdp_offload_params': True, 'fsdp_sharding_strategy': 2, 'fsdp_state_dict_type': 'SHARDED_STATE_DICT', 'fsdp_transformer_layer_cls_to_wrap': 'TransformerBlock'}\n        - megatron_lm_config: {}\n        - downcast_bf16: no\n<\/code><\/pre>\n<p>My initial python script that it can\u2019t get past<\/p>\n<pre><code class=\"lang-python\">def main():\n    \n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n    project_name = \"MLP_test_text\"\n    args = arg_parse(project_name)\n    run = wandb.init(project=project_name, entity=\"ddi\" , config = args)\n    config = wandb.config\n    np.random.seed(config.seed)\n    torch.random.manual_seed(config.seed)\n\n    \n\n    param_dict = {\n        'epoch':config.epoch ,\n        'patience':config.patience ,\n        'lr': config.learning_rate ,\n        'clip': config.clip ,\n        'batch_size':8,#config.batch_size ,\n        'weight_decay':config.weight_decay ,\n        'model': config.model,\n        'T_max':config.T_max ,\n        'seed':config.seed,\n        'label_task':config.label_task,\n    }\n\n    df = pd.read_pickle(f\"{args.dataset}.pkl\")\n    if param_dict['label_task'] == \"sentiment\":\n        number_index = \"sentiment\"\n        label_index = \"sentiment_label\"\n    else:\n        number_index = \"emotion\"\n        label_index = \"emotion_label\"\n\n\n    df_train = df[df['split'] == \"train\"] \n    df_test = df[df['split'] == \"test\"] \n    df_val = df[df['split'] == \"val\"] \n\n\n        \n    df = df[~df['timings'].isna()] # Still seeing what the best configuration is for these\n\n    \"\"\"\n    Due to data imbalance we are going to reweigh our CrossEntropyLoss\n    To do this we calculate 1 - (num_class\/len(df)) the rest of the functions are just to order them properly and then convert to a tensor\n    \"\"\"\n    \n    \n    weights = torch.Tensor(list(dict(sorted((dict(1 - (df[number_index].value_counts()\/len(df))).items()))).values()))\n    label2id = df.drop_duplicates(label_index).set_index(label_index).to_dict()[number_index]\n    id2label = {v: k for k, v in label2id.items()}\n\n    model_param = {\n        'output_dim':len(weights) ,\n        'dropout' : config.dropout,\n        'early_div' : config.early_div\n    }\n    \n    param_dict['weights'] = weights\n    param_dict['label2id'] = label2id\n    param_dict['id2label'] = id2label\n\n    print(f\" in main \\n param_dict = {param_dict} \\n model_param = {model_param} \\n df {args.dataset} , with df_size = {len(df)} \\n \")\n    \n    world_size = torch.cuda.device_count()\n    print(f\"world_size = {world_size}\" , flush=True)\n   \n    runModel(\"cuda\", world_size ,df_train , df_val , df_test ,param_dict , model_param , run )\n    \nif __name__ == '__main__':\n    main()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AI\/Machine Learning Beginner Looking for Guidance",
        "Question_link":"https:\/\/community.wandb.ai\/t\/ai-machine-learning-beginner-looking-for-guidance\/3817",
        "Question_created_time":"2023-02-03T22:17:47.800Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":126,
        "Question_body":"<p>Hey everyone! I\u2019m not trying to take too much of anyone\u2019s time, but I am a humble video producer extremely fascinated with AI\/ML with a few questions.<\/p>\n<p>I am about to start a graduate program at UT Austin studying AI\/\/ML, and am wondering what path I should take to be able to mix my deep knowledge of creative video production with my nubile AI knowledge. I have completed a Bachelor\u2019s in Video Production, and have been creating video content my entire life. I fully understand this introductory AI course will in no way prepare me to jump into the front lines of AI imaging and video generation, but I am wondering if there\u2019s a market for someone with my video expertise wanting to learn more about AI. Should I be prepared to spend the next few years deep diving into computer science to even be considered in this industry? Or could I build a solid career path with my current knowledge of video production, and a couple more introductory coding\/AI\/ML courses?<\/p>\n<p>Thank you all for your time. I wish you luck in bringing the future to us faster than ever!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Academic account registration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/academic-account-registration\/3644",
        "Question_created_time":"2023-01-05T16:43:21.368Z",
        "Question_answer_count":11,
        "Question_score_count":0,
        "Question_view_count":338,
        "Question_body":"<p>Dear community,<\/p>\n<p>I am trying to add my academic email (from my research institute). However, when I receive a confirmation email and try to open the link - I get en error and can not display the page. My collegue from another institute has the same problem.<br>\nCould you please tell if you had a similar issue and if you solved it?<\/p>\n<p>Kindly,<br>\nViktoriia<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I would like to access the values in a 'run_table' type artifact without downloading the file",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-would-like-to-access-the-values-in-a-run-table-type-artifact-without-downloading-the-file\/3805",
        "Question_created_time":"2023-02-02T22:36:49.008Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":136,
        "Question_body":"<p>I have tried accessing the artifact in various ways, and I seem to get the artifact name, but then the artifact is not recognized as existing if I use wandb.use_artifact() or if I go through logged artifacts and try to access the table, the table does not exist.  I\u2019ve tried two ways:<\/p>\n<p>for key, value in run.summary.items():<br>\nprint(f\"{key}: {value}\")<br>\nif desired_string in key:<br>\nname = (see below for possible combinations of key and value)<br>\nwandb.init()<br>\nartifact = wandb.use_artifact(name)  <span class=\"hashtag\">#I<\/span> get an error here<br>\ntable = artifact.get(name)<br>\ncolumns = table.get_column(\u2018columns\u2019)<br>\nprint(columns)<\/p>\n<p>I\u2019ve tried the following to get the name that will let me use the artifact and table :<br>\nname = key<br>\nname = value[\u2018path\u2019]<br>\nname = ((value[\u2018path\u2019].split(\u2018:\u2019)[0]).split(\u2018\/\u2019)[-1]).split(\u2018.\u2019)[0]<br>\nbecause the path had the format \"media\/table\/given_file_name.table.json<\/p>\n<p>I also tried stepping through the logged objects:<br>\nfor artifact in run.logged_artifacts():<br>\nfname = artifact.name<br>\nftype = artifact.type<br>\nif desired_string in fname and ftype == \u2018run_table\u2019:<br>\nname = fname<br>\ntable = artifact.get(name)<br>\ncolumns = table.get_column(\u2018columns\u2019) # get an error here because table is None<br>\nprint(columns)<\/p>\n<p>I have tried similar string operations as above to get the correct name for the table. I have also tried using the artifact ID instead of the name.<\/p>\n<p>I have no problems downloading the file containing the table data and then processing it, but I would like to access the data directly without downloading. Please help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"LImits of dashboard grouping",
        "Question_link":"https:\/\/community.wandb.ai\/t\/limits-of-dashboard-grouping\/3832",
        "Question_created_time":"2023-02-06T11:58:14.250Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":86,
        "Question_body":"<p>I\u2019ve performed a grid sweep over a set of hyper-parameters and collected the results of a few hundred experiments. I would like to analyze the results by grouping the experiments by the different hyper parameters and compare but i\u2019m running into a limitation.<br>\nThere\u2019s a subtitle at each metric that reads \u201cComputing group metrics from first 100 runs\u201d.<br>\nFrom what I could gather, it means that only the first 100 runs that are found in the sweep contribute to the grouped metrics, and not the first 100 runs of each group.<br>\nSince 100 runs doesn\u2019t cover all my groups, some groups are omitted entirely from the plot and I cannot view and compare all the groups in a single plot.<br>\nIs there a solution to this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"If I'm logging metrics for MLOps from a test pipeline, how do I create a separate api key for that?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/if-im-logging-metrics-for-mlops-from-a-test-pipeline-how-do-i-create-a-separate-api-key-for-that\/3803",
        "Question_created_time":"2023-02-02T22:07:52.133Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":85,
        "Question_body":"<p>How do I create a separate API so that I can log metrics from test pipelines? It doesn\u2019t make sense to use a personal key for that.<\/p>",
        "Question_closed_time":"2023-02-06T12:37:26.565Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/adgudime\">@adgudime<\/a>, thanks for your question! You can use a <a href=\"https:\/\/docs.wandb.ai\/guides\/technical-faq\/general#what-is-a-service-account-and-why-is-it-useful\">service account<\/a> for this purpose,  could you please check if this would work for you? Thanks!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Deleting runs in local wandb instance doesn't delete associated entries in the database",
        "Question_link":"https:\/\/community.wandb.ai\/t\/deleting-runs-in-local-wandb-instance-doesnt-delete-associated-entries-in-the-database\/3821",
        "Question_created_time":"2023-02-04T17:09:56.088Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":169,
        "Question_body":"<p>Our local wandb instance was taking up a lot of space, so we tried to free up it by deleting old underperforming runs. This included around half of all the runs we had.<\/p>\n<p>However, deleting them didn\u2019t result in any freed-up space (mysql tables ended up taking the same size as pre-deletion). Is there any way to delete associated entries in the database?<\/p>\n<p>Thanks for the help!<\/p>",
        "Question_closed_time":"2023-02-07T00:54:13.108Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/oshapio\">@oshapio<\/a>, happy to help with. Today W&amp;B does not reclaim space for deleted runs in the database. Here\u2019s a <a href=\"https:\/\/gist.github.com\/vanpelt\/0c13c556fa82cabdecb70d5ef90a4ea9\" rel=\"noopener nofollow ugc\">SQL procedure<\/a> that will delete the metrics and logs from the sql database for any runs that have been deleted in the UI. We\u2019re planning to integrate this logic into our application soon, but this can be used from a mysql shell to clear up data in the mean time.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How do handle overlapping segmentation masks?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-handle-overlapping-segmentation-masks\/3836",
        "Question_created_time":"2023-02-06T18:12:06.695Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":113,
        "Question_body":"<p>In maskrcnn I\u2019m pretty sure it\u2019s valid to output overlapping segmentation masks, but I\u2019m not sure how to handle this in wandb Masks and I haven\u2019t been able to find an example. The documentation says each \u201cMask\u201d is a 2D numpy array filled with class ids, which implies one class per pixel, right?<\/p>\n<p>Is there a way to visualize the masks if they\u2019re overlapping?<\/p>",
        "Question_closed_time":"2023-02-06T18:56:27.252Z",
        "Answer_body":"<p>I was told by wandb support this was not possible, posting here for transparency<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Compare prediction\/summary scores on a table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/compare-prediction-summary-scores-on-a-table\/3791",
        "Question_created_time":"2023-02-01T16:57:40.403Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":190,
        "Question_body":"<p>At the end of my run, I make predictions on the development set and log these scores to wandb with this command:<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\"best_epoch\": best_epoch, \"dev_micro_acc\": dev_micro_acc, \"dev_weighted_f1\": dev_weighted_f1,\n               \"dev_f1_label1\": dev_f1_label1,\n               \"dev_f05_score\": dev_f05_score, \"dev_roc_auc\": dev_roc_auc})\n<\/code><\/pre>\n<p>These values then appear in the summary section on my overview page for each run. But how can I see them as overview to compare them with other runs? Like, it would be nice to see them as column on the run table such that I can sort there for the best score and therefore identify my best model, but I acknowledge that the config columns probably aren\u2019t the proper place for this.<\/p>\n<p>So where could I see such an overview on wandb?<\/p>",
        "Question_closed_time":"2023-02-02T12:41:12.581Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/harpiye\">@harpiye<\/a>, thanks for writing in! These metrics should appear in the Runs table by default but if this isn\u2019t the case, in the top right corner there\u2019s a <code>Columns<\/code> button and you can manage the visible columns. If you cannot see these metrics there, could you please send me a link to the project and so I can have a look at it?<\/p>\n<p>To be able to compare runs, I\u2019d recommend you to use the <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/panels\/run-comparer\">Run comparer plot<\/a> which you can add from <code>Add panel<\/code> and allows you to compare your different runs. Please let me know if this would work for you!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Horrible performance when viewing charts for WandB run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/horrible-performance-when-viewing-charts-for-wandb-run\/3827",
        "Question_created_time":"2023-02-05T19:58:31.840Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":88,
        "Question_body":"<p>I\u2019ve got several runs of a Pytorch training pipeline that log stuff to WandB. I\u2019m mostly just following the tutorials, not trying to do anything fancy. Generally, I log basic numeric metrics like loss every batch, and more complex metrics like mAP and images with bounding boxes every epoch. I\u2019m training for 100 epochs.<\/p>\n<p>However, when I try to look at the charts on <a href=\"http:\/\/WandB.ai\" rel=\"noopener nofollow ugc\">WandB.ai<\/a>, I\u2019m seeing some truly awful performance from the dashboard. CPU use by the browser is pegged at 100% for several minutes just trying to load the page. When things finally load, they are unresponsive, and CPU usage remains high.<\/p>\n<p>Am I doing something wrong here?  Am I logging too many images? (I\u2019m logging 128 per epoch.) I couldn\u2019t find any guidelines for this in the docs, but maybe I\u2019m just missing them. FWIW, I used to do a similar amount of logging in TensorBoard without an issue. Also, I think that back when I was running YOLOv5 training sessions, it was also doing similar logging, and WandB never seemed to have a problem with that.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb login not working for sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-login-not-working-for-sweep\/3822",
        "Question_created_time":"2023-02-05T00:51:26.979Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":335,
        "Question_body":"<p>Hi folks<br>\nI have been seeing this since Friday Feb 3 afternoon PST. I am using wandb version <code>0.13.7<\/code>. I am logged in at wandb, but when I do<\/p>\n<pre><code class=\"lang-auto\">wandb sweep sweep.yaml\n<\/code><\/pre>\n<p>I see below error<\/p>\n<pre><code class=\"lang-auto\">wandb: ERROR Error while calling W&amp;B API: permission denied (&lt;Response [403]&gt;)\nwandb: ERROR Find detailed error logs at: \/tmp\/debug-cli.ec2-user.log\nError: permission denied\n<\/code><\/pre>\n<p>Below is the complete error log<\/p>\n<pre><code class=\"lang-auto\">2023-02-05 00:45:38 ERROR 403 response executing GraphQL.\n2023-02-05 00:45:38 ERROR {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertSweep\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertSweep\":null}}\n2023-02-05 00:45:38 ERROR Traceback (most recent call last):\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/retry.py\", line 113, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 209, in execute\n    return self.client.execute(*args, **kwargs)  # type: ignore\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/client.py\", line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/client.py\", line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/transport\/requests.py\", line 39, in execute\n    request.raise_for_status()\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/requests\/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https:\/\/api.wandb.ai\/graphql\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/apis\/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2218, in upsert_sweep\n    raise e\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2215, in upsert_sweep\n    check_retry_fn=util.no_retry_4xx,\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/util.py\", line 969, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.UsageError: permission denied\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/cli\/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/cli\/cli.py\", line 941, in sweep\n    launch_scheduler=_launch_scheduler_spec,\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/apis\/internal.py\", line 102, in upsert_sweep\n    return self.api.upsert_sweep(*args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/apis\/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2218, in upsert_sweep\n    raise e\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2215, in upsert_sweep\n    check_retry_fn=util.no_retry_4xx,\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"\/home\/ec2-user\/anaconda3\/envs\/clip_env\/lib\/python3.7\/site-packages\/wandb\/util.py\", line 969, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.CommError: permission denied\n<\/code><\/pre>\n<p>Please suggest<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Find the \"run history at log step\" for a particular artifact using the API?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/find-the-run-history-at-log-step-for-a-particular-artifact-using-the-api\/3819",
        "Question_created_time":"2023-02-04T07:43:20.113Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":64,
        "Question_body":"<p>In the web UI, for a particular dashboard, under metadata I am interested in the \u201cRun history at log step\u201d information. I\u2019d like to retrieve this using the API.<\/p>\n<p>If I use run.scan_history, I get rows with model scores and the epoch and step, but not the artifact ID.<\/p>\n<p>If I have a public API Artifact, I have the artifact ID and version but not the epoch or step. Artifact<\/p>\n<p>How do I find the run history at log step for a particular artifact? I\u2019ve checked the API code and docs but still can\u2019t figure it out.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Different history run lengths of a metric",
        "Question_link":"https:\/\/community.wandb.ai\/t\/different-history-run-lengths-of-a-metric\/3776",
        "Question_created_time":"2023-01-30T03:56:38.658Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":131,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I have been using W&amp;B to log my outputs of experiments and in one case I have a set up with fixed code and the hyperparameters change and the same code is run on the same data for the same amount of steps. However, when I use my own function to retrieve the values logged during training, they are of different lengths and it\u2019s causing quite a headache to plot these metrics over time because they don\u2019t align naturally.<\/p>\n<p>I use my own function to retrieve a metric from a run:<\/p>\n<pre><code class=\"lang-auto\">def get_wandb_history(identifier, key):\n    run = api.run(identifier)\n    run_history = run.history()\n    key_history = run_history[key]\n    key_history = np.array([x for x in key_history if float(x) &gt; 0.0])\n    return key_history\n<\/code><\/pre>\n<p>The penultimate line is because of the NaNs that store info at steps in between epochs.<br>\nI ran 6 different runs where only a single hyperparameter changed. After retrieving the results via the function above, the lengths I have for them are:<\/p>\n<pre><code class=\"lang-auto\">61\n62\n64\n67\n60\n61\n<\/code><\/pre>\n<p>What\u2019s going on here? Is there a better \/ more reliable way to check the stored outputs? In the visualisation tool online, the runs are aligned perfectly and show the effect I was hoping to find. However, when I want to use those values in my own plots, they are not temporally aligned. So, they are being stored correctly for visualisation on the web interface - just not when I want to retrieve them (?)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Histograms over time like tensorboard",
        "Question_link":"https:\/\/community.wandb.ai\/t\/histograms-over-time-like-tensorboard\/3709",
        "Question_created_time":"2023-01-17T22:30:02.048Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":208,
        "Question_body":"<p>Hello everyone,<\/p>\n<p>I am trying to reproduce this kind of histogram over time that is available in tensorboard :<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png\" data-download-href=\"\/uploads\/short-url\/tPHcPfG25CLsBmkGDsWiIbz2KDP.png?dl=1\" title=\"Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d1171085f5a5dcd3b87295a7d67d13c7430ef71d_2_642x500.png\" alt=\"Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08\" data-base62-sha1=\"tPHcPfG25CLsBmkGDsWiIbz2KDP\" width=\"642\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d1171085f5a5dcd3b87295a7d67d13c7430ef71d_2_642x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png 2x\" data-dominant-color=\"3A3D36\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08<\/span><span class=\"informations\">864\u00d7672 48.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>When I use the histogram function from wandb and collect histograms over time I get a superposition of blurry histograms, which is un-usable (I\u2019m not really sure what I am looking at).<br>\nWhat I would expect to see instead for a multi-histogram visualisation would be  like the plot from tensorboard (see above), the offset accross timesteps is important. What\u2019s even more bizarre is that it seems that these plots are already plotted when I hover over the graph in wandb (where I see a clear histogram with a fitted curve above for every timestep I collected).<\/p>\n<p>Would it be possible to visualize those with an offset like in tensorboard? I really want to visualize the evolution of distribution of a value across episodes.<\/p>\n<p>Thanks,<\/p>\n<p>Yann<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Offline Sync Stalls after Missing Artefact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/offline-sync-stalls-after-missing-artefact\/3577",
        "Question_created_time":"2022-12-21T00:22:15.831Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":529,
        "Question_body":"<p>I\u2019m using Hydra+PL+WandB (Offline) to log a sweep of runs.<\/p>\n<p><strong>env<\/strong>:<br>\n<code>Python 3.7.11<\/code><br>\n<code>wandb==0.13.7<\/code><br>\n<code>pytorch-lightning==1.8.4<\/code><br>\n<code>hydra-core==1.3.0<\/code><\/p>\n<p>However, upon seeking to upload my runs to the cloud, I run into some issues:<\/p>\n<pre><code class=\"lang-auto\">(venv) user@machine:~\/***\/multirun\/2022-12-19\/08-18-10$ wandb sync --include-offline .\/400\/wandb\/offline-run-20221219_082002-3ea0vv6x\/\nFind logs at: \/tmp\/debug-cli.aime.log\nSyncing: https:\/\/wandb.ai\/***\/1pyryhlw ... wandb: ERROR Error uploading \"\/***\/.cache\/wandb\/artifacts\/obj\/md5\/8b\/bd5da60d38836c6f93b0db86b40ade\": FileNotFoundError, [Errno 2] No such file or directory: '\/***\/.cache\/wandb\/artifacts\/obj\/md5\/8b\/bd5da60d38836c6f93b0db86b40ade'\n<\/code><\/pre>\n<p>Two things are puzzling:<\/p>\n<ol>\n<li>The upload of all other files in the run is successful, but the sync never finishes due to the lacking artifact file<\/li>\n<li>The artifact has not been logged, at least not deliberately (No checkpoint callbacks) and there <strong>exist no checkpoint file<\/strong> in the <code>\/offline-run-***\/<\/code>-folder<\/li>\n<\/ol>\n<p>The log file shows what you expect, except it doesn\u2019t update past the final file and neither does it finish the process.<\/p>\n<p>I\u2019ve been trying to hack a solution going through the <code>wandb<\/code>-repository, but I\u2019d love some guidance on where to look and how to solve the above.<\/p>\n<p>The <code>sync<\/code>-function should continue execution even if a file is missing in my opinion - However in this particular case, I did not even do any checkpointing.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Moving runs is stuck at 0%",
        "Question_link":"https:\/\/community.wandb.ai\/t\/moving-runs-is-stuck-at-0\/3795",
        "Question_created_time":"2023-02-01T21:33:13.064Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":96,
        "Question_body":"<p>I\u2019m trying to move runs between from one project to another but the UI shows \u201cMoving\u2026 0%\u201d and hangs indefinitely. I\u2019ve tried refreshing my browser and moving different subsets of runs but nothing seems to work. Any idea what might be going on?  Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: Network error (ConnectionError), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-network-error-connectionerror-entering-retry-loop\/3789",
        "Question_created_time":"2023-02-01T12:18:02.442Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":405,
        "Question_body":"<p>I am using wandb version 0.12.21\u2026 My code was working fine till yesterday, but I am getting this error\u2026<\/p>\n<p>wandb: Currently logged in as: shashi7679. Use <code>wandb login --relogin<\/code> to force relogin<br>\nwandb: Appending key for <a href=\"http:\/\/api.wandb.ai\">api.wandb.ai<\/a> to your netrc file: \/root\/.netrc<br>\nwandb: Network error (ConnectionError), entering retry loop.<\/p>\n<p>Problem at: train.py 333 <br>\nProcess wandb_internal:<br>\nTraceback (most recent call last):<br>\nFile \u201ctrain.py\u201d, line 333, in <br>\nTraceback (most recent call last):<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/process.py\u201d, line 315, in _bootstrap<br>\nself.run()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/process.py\u201d, line 108, in run<br>\nself._target(*self._args, **self._kwargs)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\u201d, line 160, in wandb_internal<br>\nthread.join()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/threading.py\u201d, line 1011, in join<br>\nself._wait_for_tstate_lock()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/threading.py\u201d, line 1027, in _wait_for_tstate_lock<br>\nelif lock.acquire(block, timeout):<br>\nKeyboardInterrupt<br>\nwandb.init(project=\u2018Toon-GAN\u2019,config=hyper_parameters)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 1065, in init<br>\nraise e<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 1043, in init<br>\nrun = wi.init()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 689, in init<br>\nbackend.cleanup()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/backend\/backend.py\u201d, line 248, in cleanup<br>\nself.wandb_process.join()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/process.py\u201d, line 149, in join<br>\nres = self._popen.wait(timeout)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/popen_fork.py\u201d, line 47, in wait<br>\nreturn self.poll(os.WNOHANG if timeout == 0.0 else 0)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/popen_fork.py\u201d, line 27, in poll<br>\npid, sts = os.waitpid(self.pid, flag)<br>\nKeyboardInterrupt<br>\n^CTraceback (most recent call last):<br>\nFile \u201c\u201d, line 1, in <br>\nError in atexit._run_exitfuncs:<br>\nTraceback (most recent call last):<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/popen_fork.py\u201d, line 27, in poll<br>\npid, sts = os.waitpid(self.pid, flag)<br>\nKeyboardInterrupt<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/spawn.py\u201d, line 116, in spawn_main<br>\nexitcode = _main(fd, parent_sentinel)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/spawn.py\u201d, line 129, in _main<br>\nreturn self._bootstrap(parent_sentinel)<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/multiprocessing\/process.py\u201d, line 333, in _bootstrap<br>\nthreading._shutdown()<br>\nFile \u201c\/opt\/conda\/lib\/python3.8\/threading.py\u201d, line 1388, in _shutdown<br>\nlock.acquire()<br>\nKeyboardInterrupt<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Set y ranges in Parallel Coordinates plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/set-y-ranges-in-parallel-coordinates-plot\/3745",
        "Question_created_time":"2023-01-25T10:48:15.926Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":199,
        "Question_body":"<p>I want to compare many runs through a parallel coordinates plot and I need to evaluate them in terms of different metrics.<br>\nWhat I get by default when creating it manually is the following (where the various kinds of AUC scores is what I am interested in):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8.png\" data-download-href=\"\/uploads\/short-url\/iwiKWiM6XBlEBWoJ1rFVitBIl5e.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_690x205.png\" alt=\"image\" data-base62-sha1=\"iwiKWiM6XBlEBWoJ1rFVitBIl5e\" width=\"690\" height=\"205\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_690x205.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_1035x307.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_1380x410.png 2x\" data-dominant-color=\"FCFAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1772\u00d7527 130 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>However, as you can see the AUCs columns have different yticks and range depending on the corresponding values, which makes it impossible to interpret them intuitively. Is it possible to set column ranges manually?<\/p>\n<p><strong>More context:<\/strong> I think this is related to <a href=\"https:\/\/community.wandb.ai\/t\/scaling-in-the-parelles-coordinates-plot\/3274\">another question<\/a> on this blog. The reason why this would be convenient is when you want to compare different metrics or the same metric for different models.<br>\nIn particular, I want to compare the performance of a baseline solution (<code>Cumulative AUC (MELD)<\/code> ) VS my model (<code>Cumulative AUC<\/code>). So intuitively I would see whether the lines go up passing from one column to the other to determin whether the second column shows better performance. Unfortunately, that is misleading if I the two columns have different ranges.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Different run sets within a panel grid",
        "Question_link":"https:\/\/community.wandb.ai\/t\/different-run-sets-within-a-panel-grid\/3721",
        "Question_created_time":"2023-01-19T12:16:22.264Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":210,
        "Question_body":"<p>Hello, I want to create a grid panel containing several linecharts but the selected runs are different.<br>\nTo elaborate on my need: I have several algorithms, evaluated across timesteps on several environments. I want one line chart per environment. To illustrate, my final requirement is to get something that looks like this:<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/f2059dafd12562e424e2b66a3e2aabb2b4e1b204.png\" alt=\"Screenshot from 2023-01-19 13-12-26\" data-base62-sha1=\"yx1zXviDcru4wcBIHNfwKEhCyFK\" width=\"435\" height=\"213\"><\/p>\n<p>How would you do that?<\/p>",
        "Question_closed_time":"2023-01-20T18:42:33.197Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/qgallouedec\">@qgallouedec<\/a>, thanks for writing in! As you\u2019d like to have a figure with independent charts inside, one option would be to use <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/custom-charts\">custom charts<\/a>. I let you <a href=\"https:\/\/vega.github.io\/vega\/examples\/barley-trellis-plot\/\" rel=\"noopener nofollow ugc\">here<\/a> and <a href=\"https:\/\/vega.github.io\/vega\/examples\/brushing-scatter-plots\/\" rel=\"noopener nofollow ugc\">here<\/a> two Vega examples that may be useful in order to build your figure. Other way I can think of for this is rendering the chart through <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots#matplotlib-and-plotly-plots\">Plotly\/Matplotlib<\/a> and then log it. Please let me know if any of these would be useful!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"My wandb page is extremely slow",
        "Question_link":"https:\/\/community.wandb.ai\/t\/my-wandb-page-is-extremely-slow\/3784",
        "Question_created_time":"2023-01-31T02:03:32.553Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_body":"<p>when i try to look at evaluation graph, it loads extremely slowly for some reason.<\/p>\n<p>Is  there anythin i can do to speed up this process?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using WandB in Visual Studio Code",
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-wandb-in-visual-studio-code\/3752",
        "Question_created_time":"2023-01-25T23:44:11.711Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":127,
        "Question_body":"<p>Dear community,<\/p>\n<p>I want to use WandB locally in my VSCode project, but my Ipython kernel keeps dying. After restarting the kernel it always prints out the errore message: \u201cFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u201d and \u201cwandb: Currently logged in as: XXX. Use <code>wandb login --relogin<\/code> to force relogin\u201d<\/p>\n<p>I already tried to import os, as well as setting the environment variabele to my local notebook, but this didnt change a thing. I am using python 3.9.12<\/p>\n<p>I hope you can help me in this matter<\/p>",
        "Question_closed_time":"2023-01-30T18:51:36.691Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/martin-woschitz\">@martin-woschitz<\/a> thank you for reporting this issue. This first message is just a warning so it shouldn\u2019t cause any issues running your code, also the second message  is an informatio output about the user account that you\u2019ve logged in. When does the Ipython kernel stops working, is it when you\u2019re running a python script? would it be possible to make a new virtual environment and install <code>wandb<\/code> only there to test if that\u2019s what\u2019s causing the issue for you?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Define_metric parameter 'hidden' not working?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/define-metric-parameter-hidden-not-working\/3748",
        "Question_created_time":"2023-01-25T15:38:05.424Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":91,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m new to W&amp;B and was setting up my metrics like this:<\/p>\n<pre><code class=\"lang-auto\"># define x-axes\nwandb.define_metric(\"batch#\", hidden=True)   # \"hidden\" not working\nwandb.define_metric(\"epoch#\", hidden=True)\n# define metrics and match to x-axis\nwandb.define_metric(\"loss\", step_metric=\"#batch#\")\nwandb.define_metric(\"f1\", step_metric=\"epoch#\")\n<\/code><\/pre>\n<p>I want graphs of loss\/batch# and f1\/epoch# on my dashboard, but not graphs of batch#\/step or epoch#\/step. Therefore, I set the function parameter \u2018hidden\u2019 to True for these. It does not work, I still get automatically generated panels of them. Any advice?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Control knobs for sending commands back to the running job \/ controlling live variables from the das",
        "Question_link":"https:\/\/community.wandb.ai\/t\/control-knobs-for-sending-commands-back-to-the-running-job-controlling-live-variables-from-the-das\/3710",
        "Question_created_time":"2023-01-18T12:57:43.876Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":125,
        "Question_body":"<h2>\n<a name=\"feature-1\" class=\"anchor\" href=\"#feature-1\"><\/a><img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/rocket.png?v=12\" title=\":rocket:\" class=\"emoji\" alt=\":rocket:\" loading=\"lazy\" width=\"20\" height=\"20\"> Feature<\/h2>\n<p>There should be a way to attach variables to the logger, that you can modify live from from controls in the dashboard.<\/p>\n<h3>\n<a name=\"motivation-2\" class=\"anchor\" href=\"#motivation-2\"><\/a>Motivation<\/h3>\n<p>When you have a running job and are monitoring the progress, you sometimes want to adjust the learning rate or other hyperparameter (should we switch to fine-tuning mode, etc.).<\/p>\n<h3>\n<a name=\"pitch-3\" class=\"anchor\" href=\"#pitch-3\"><\/a>Pitch<\/h3>\n<p>This is a bit of a unspoken black-magic deep learning technique. However, if you read papers from Meta, etc. or talk to hardcore old-school practitioners, they have these super long-running difficult optimization problems, and say something like: \u201cWell we trained the generator for X thousand epochs, then we enabled the discriminator, then Y thousand epochs later we dropped the learning rate, etc.\u201d This is ideally done by monitoring a live, running job and modifying the variables in situ.<\/p>\n<h3>\n<a name=\"alternatives-4\" class=\"anchor\" href=\"#alternatives-4\"><\/a>Alternatives<\/h3>\n<ul>\n<li>The non-agile way to do this is let your run go for a while, decide afterwards that you should have changed something at some point in time, code that, run it again and cross your fingers. This is obviously pretty slow and requires luck.<\/li>\n<li>A hacky way to do this is to create a DSL with sentinel files that the running job reads and applies. However, the workflow is useful enough that there should be a common way to do this.<\/li>\n<\/ul>\n<h3>\n<a name=\"additional-context-5\" class=\"anchor\" href=\"#additional-context-5\"><\/a>Additional context<\/h3>\n<p>I\u2019m not aware of any logging library that does this. So it would make great blog posts to show off and attract more users.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to initialise wandb on Colab even after setting up login and project name",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-initialise-wandb-on-colab-even-after-setting-up-login-and-project-name\/3740",
        "Question_created_time":"2023-01-24T04:15:26.372Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":134,
        "Question_body":"<p>On python3.8 , and using wandb==0.9.7, on google Colab<br>\nI am getting this error<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1105, in init\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 167, in setup\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 307, in setup\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 302, in _setup\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 288, in __init__\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 106, in __init__\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 234, in _setup\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 262, in _setup_manager\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_manager.py\", line 112, in __init__\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/service\/service.py\", line 137, in start\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/service\/service.py\", line 132, in _launch_server\nAssertionError\nwandb: ERROR Abnormal program exit\nproc exited with 1\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best Practices for WandB Artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/best-practices-for-wandb-artifacts\/3536",
        "Question_created_time":"2022-12-12T14:10:19.554Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":170,
        "Question_body":"<p>Hi there, I am currently exploring a best practices for wandb artifacts.  Can anybody let me know there best way to create artifacts rather than saving each runs as artifacts<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"API and Website out of sync",
        "Question_link":"https:\/\/community.wandb.ai\/t\/api-and-website-out-of-sync\/3730",
        "Question_created_time":"2023-01-21T00:39:32.135Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":88,
        "Question_body":"<p>Hi, I ran a sweep and I\u2019m finding the API (using python) and the website dashboard report different data regarding the runs. For example, the API says that the sweep contains a different number of runs than the website dashboard says. Also, the status for certain runs is also out of sync (e.g. according to API the run is still \u201crunning\u201d but according website the run finished 4hrs ago). I\u2019m wondering why the two are so out of sync? Is there anything I can do to sync them? I\u2019ve deleted all the run files locally so I assume both would be calling the same backend\u2026 It\u2019s also been several hours so I don\u2019t think it\u2019s just a momentary lapse.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb to download models to a container",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-to-download-models-to-a-container\/3738",
        "Question_created_time":"2023-01-23T23:43:33.620Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":86,
        "Question_body":"<p>We want to containerize our models using a CI\/CD pipeline in bitbucket.  This means i need to install and run wandb in a temporary\/interim container just long enough to download several models.  Then the models can be copied into a container using a DockerFile.  Is there a recommended method for setting up wandb for this scenario?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run.history(keys=key_list) returns empty history",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-history-keys-key-list-returns-empty-history\/3746",
        "Question_created_time":"2023-01-25T13:16:39.969Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":114,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>when calling <code>run.history(keys=key_list)<\/code> with a <code>key_list<\/code> that contains more than one key with a \u2018\/\u2019 character in it,  an empty history is returned:<\/p>\n<pre><code class=\"lang-auto\">history = run.history(keys=[\"hierarchy_1\/metric_1\", \"hierarchy_1\/metric_2\"], samples=n_samples)\nprint(history)\n<\/code><\/pre>\n<p>yields this output:<\/p>\n<pre><code class=\"lang-auto\">Empty DataFrame\nColumns: []\nIndex: []\n<\/code><\/pre>\n<p>However, calling it with only one key in the list yields the full history:<\/p>\n<pre><code class=\"lang-auto\">history_metric_1 = run.history(keys=[\"hierarchy_1\/metric_1\"], samples=n_samples)\nhistory_metric_2 = run.history(keys=[\"hierarchy_1\/metric_2\"], samples=n_samples)\n<\/code><\/pre>\n<p>both work and return <code>n_samples<\/code> steps of the run history.<\/p>\n<p>Calling <code>run.history()<\/code> without any keys and extracting them afterwards is not an option for me due to another bug in the API, discussed <a href=\"https:\/\/community.wandb.ai\/t\/calling-run-history-samples-n-samples-returns-a-sample-size-different-from-n-samples\/3414\">here<\/a>.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Renaming columns in the runs table?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/renaming-columns-in-the-runs-table\/3592",
        "Question_created_time":"2022-12-23T14:16:46.773Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":370,
        "Question_body":"<p>Hello!<\/p>\n<p>I\u2019ve got a large nested config file that I usually log with each runs. The problem is that I only see the beginning of each of the path of the hyperparameters, which isn\u2019t so useful.<\/p>\n<p>See this picture:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/4feef90ca3c84455b4d4181120295a389faca498.png\" data-download-href=\"\/uploads\/short-url\/bp7IsEY9jp884hM6YlobtiDLMyA.png?dl=1\" title=\"Screenshot from 2022-12-23 15-15-24\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4feef90ca3c84455b4d4181120295a389faca498_2_690x157.png\" alt=\"Screenshot from 2022-12-23 15-15-24\" data-base62-sha1=\"bp7IsEY9jp884hM6YlobtiDLMyA\" width=\"690\" height=\"157\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4feef90ca3c84455b4d4181120295a389faca498_2_690x157.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4feef90ca3c84455b4d4181120295a389faca498_2_1035x235.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4feef90ca3c84455b4d4181120295a389faca498_2_1380x314.png 2x\" data-dominant-color=\"F9FAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-12-23 15-15-24<\/span><span class=\"informations\">4268\u00d7976 309 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Is there a way to automatically rename every columns so that only the last word in the hyperparameter path is displayed?<\/p>\n<p>Like if my hyperparameter path is something like:<br>\nconfig.model.autoencoder.layer I want to only see layer<\/p>\n<p>Best,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log images during mmdetection training",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-images-during-mmdetection-training\/3606",
        "Question_created_time":"2022-12-27T14:23:26.556Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":130,
        "Question_body":"<p>I am using the mmdetection platform.<br>\nFor training I am using a .py config file that contains the log configuration from W&amp;B documentation:<br>\nlog_config = dict(<br>\nhooks = [<br>\ndict(type=\u2018TextLoggerHook\u2019),<br>\ndict(type=\u2018MMDetWandbHook\u2019,<br>\ninit_kwargs={\u2018project\u2019: \u2018\u2026\u2019, \u2018entity\u2019: \u2018\u2026\u2019, \u2018name\u2019: \u2018\u2026\u2019},<br>\ninterval=10,<br>\nlog_checkpoint=True,<br>\nlog_checkpoint_metadata=True,<br>\nnum_eval_images=200,<br>\nbbox_score_thr=0.3)]<br>\n)<br>\nFor some reason, I can\u2019t log images of the train, validation, and their ground truth and predictions during training.<br>\nDid someone do it and can give me a good tip for that?<br>\nThanks,<br>\nZiv<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problems about Error Run when using wandb.agent",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problems-about-error-run-when-using-wandb-agent\/3718",
        "Question_created_time":"2023-01-19T08:23:59.129Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":187,
        "Question_body":"<p>Hello, I have some problems when reproducing the results using code here: <a href=\"https:\/\/github.com\/oscarclivio\/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">oscarclivio (Oscar Clivio) \u00b7 GitHub<\/a> neuralscorematching.<br>\nWhen I run the file: sweep_config.py, I get the error like: ERROR Run ur2vuu27 errored: FileNotFoundError(2, \u2018No such file or directory\u2019)<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/3471020e22eb5bc852365c5bbca143f9f7a2dcd5.png\" data-download-href=\"\/uploads\/short-url\/7tUWIrQKbqa3T8bEGfIXUjbnBhb.png?dl=1\" title=\"problem\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_690x303.png\" alt=\"problem\" data-base62-sha1=\"7tUWIrQKbqa3T8bEGfIXUjbnBhb\" width=\"690\" height=\"303\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_690x303.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_1035x454.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_1380x606.png 2x\" data-dominant-color=\"272728\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">problem<\/span><span class=\"informations\">1485\u00d7653 64.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nI ran the codes via vscode and using one cloud service autodl considering the hardware of my computer.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logs disappeared from table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logs-disappeared-from-table\/3732",
        "Question_created_time":"2023-01-21T23:31:18.113Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":182,
        "Question_body":"<p>Hello,<\/p>\n<p>The table section of a new project has changed. I usually run experiments where a log a lot of metrics at every epochs (a few hundreds). They still appear in workspace\/chart. However the table only show the very very basic options of eachs runs ( State. Notes, User, Tags, Created, Runtime, Sweep). This is annoying given that:<\/p>\n<ul>\n<li>I don t see the configs of each run.<\/li>\n<li>I was used to export my final results to CSV from this table section.<\/li>\n<\/ul>\n<p>Is it a bug ? or an intentional change in the interface ? Or did I do something wrong ?<\/p>\n<p>best<\/p>\n<p>Barthelemy<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log custom metrics for a run outside of the training loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-custom-metrics-for-a-run-outside-of-the-training-loop\/3696",
        "Question_created_time":"2023-01-13T12:46:10.984Z",
        "Question_answer_count":10,
        "Question_score_count":1,
        "Question_view_count":249,
        "Question_body":"<p>Hi,<br>\nI\u2019m currently working on a self-supervised representation learning project, and to evaluate the quality of my models I train a linear classifier on the outputs of my (frozen) trained encoder and look at the downstream classification accuracy.<\/p>\n<p>This evaluation procedure is done separately from the training of the encoder, however is there still a way to add the metrics computed during this evaluation phase to the standard metrics I log during the training phase, in the same run panel?<\/p>\n<p>More generally, can I add metrics to a run that is already finished?<\/p>\n<p>Thanks a lot!<\/p>",
        "Question_closed_time":"2023-01-19T00:18:59.911Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ari0u\">@ari0u<\/a> , appreciate your your additional feedback.<\/p>\n<p>This approach of first logging , <code>loss<\/code>, to a run, then revisiting\/resuming a run to log different metric, <code>accuracy<\/code>, starting from <strong>step zero<\/strong> again is not supported. The wandb logging step must be monotonically increasing in each call, otherwise the <code>step<\/code> value is ignored during your call to <code>log()<\/code>. Now if you are not interested in logging accuracy at step 0, you <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#resuming-guidance\">could resume<\/a> the previously finished run using its un id and log additional metrics to the run. this however is problematic as the new metric is logged starting at the last known\/registered step for the run.<\/p>\n<p>One approach to get around the issue you are running into  is to assign each of the runs to a <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/grouping\">specific group<\/a>. Example set <code>group = version_0<\/code> for any runs that logs metrics for this specific version of the model. You could then set grouping in the workspace to help with tracking  the different metrics for each experiment, <a href=\"https:\/\/wandb.ai\/mohammadbakir\/Group-Viz-Test\/groups\/L2\/workspace?workspace=user-mohammadbakir\">see this example workspace<\/a>.<\/p>\n<p>Hope this helps and please let us know if you have additional questions.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Academic email not registered anymore?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/academic-email-not-registered-anymore\/3706",
        "Question_created_time":"2023-01-17T12:04:00.347Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":120,
        "Question_body":"<p>Hey!<\/p>\n<p>I cannot create an academic team anymore (last year, it worked, but I just deleted the group). In my email settings, there is no academic tag. If I try to upgrade my plan to academic again, I\u2019m forwarded to my project page. Am I missing something here? Thanks <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to override existing statistics in plot when resuming from a checkpoint?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-override-existing-statistics-in-plot-when-resuming-from-a-checkpoint\/3737",
        "Question_created_time":"2023-01-23T11:33:23.626Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":61,
        "Question_body":"<p>Hello all! I\u2019m trying to set up proper training checkpointing and resuming for my code and thus far I\u2019ve gotten things to work but there is still one thing I am trying to figure out, which is how to get the logs in wandb to get overwritten\/replaced after I load a checkpoint.<\/p>\n<p>For instance, right now in my code if I save a checkpoint at 5000 timesteps, let training run for a few more thousand timesteps, cancel it, and then load and resume training from that 5000 step checkpoint, a training plot will look like this:<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/0fd7c64199202e092516ae6671d3a7ffad419c7f.png\" alt=\"image\" data-base62-sha1=\"2g9sjoDhJ11TQUKPD8Ox6R0RONx\" width=\"481\" height=\"393\"><\/p>\n<p>This is because the built-in Wandb Step value didn\u2019t also reset back to 5k for when I restarted training from the 5k checkpoint, it just kept going. What I would instead like to have happen is that the Step value is synced with when I save the checkpoint so that when I resume, the existing plot is <strong>overridden<\/strong>, rather than continued. Is it possible to do this? Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Yolov5 creates wandb run with vscode jupyter notebook, but not with same nb in jupyterlab",
        "Question_link":"https:\/\/community.wandb.ai\/t\/yolov5-creates-wandb-run-with-vscode-jupyter-notebook-but-not-with-same-nb-in-jupyterlab\/3716",
        "Question_created_time":"2023-01-19T02:28:37.761Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":287,
        "Question_body":"<p>When I run the same notebook with the same jupyter kernel (custom conda env) in vscode and in jupyterlab, it only creates a wandb run in vscode, but not in jupyterlab.<\/p>\n<p>Output in jupyterlab (no output from wandb):<\/p>\n<pre><code class=\"lang-auto\">Training with yolov5: yolov5_model_size: yolov5s batch size: 8 for 180 epochs\ntrain: weights=yolov5s.pt, cfg=, data=dataset\/yolov5_config.yml, hyp=yolov5\/data\/hyps\/hyp.scratch-low.yaml, epochs=180, batch_size=8, imgsz=1280, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\/runs\/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\ngithub: up to date with https:\/\/github.com\/ultralytics\/yolov5 \u2705\nYOLOv5 \ud83d\ude80 v7.0-71-gc442a2e Python-3.10.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1070 with Max-Q Design, 8120MiB)\n\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\nClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 \ud83d\ude80 in ClearML\nComet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 \ud83d\ude80 runs in Comet\nTensorBoard: Start with 'tensorboard --logdir yolov5\/runs\/train', view at http:\/\/localhost:6006\/\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments\n<\/code><\/pre>\n<p>Output in vscode jupyter notebook (shows output from wandb with link to run):<\/p>\n<pre><code class=\"lang-auto\">Output exceeds the size limit. Open the full output data in a text editor\nTraining with yolov5: yolov5_model_size: yolov5s batch size: 8 for 180 epochs\nwandb: Currently logged in as: tleyden (eyepi). Use `wandb login --relogin` to force relogin\ntrain: weights=yolov5s.pt, cfg=, data=dataset\/yolov5_config.yml, hyp=yolov5\/data\/hyps\/hyp.scratch-low.yaml, epochs=180, batch_size=8, imgsz=1280, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\/runs\/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\ngithub: up to date with https:\/\/github.com\/ultralytics\/yolov5 \u2705\nYOLOv5 \ud83d\ude80 v7.0-71-gc442a2e Python-3.10.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1070 with Max-Q Design, 8120MiB)\n\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\nClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 \ud83d\ude80 in ClearML\nComet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 \ud83d\ude80 runs in Comet\nTensorBoard: Start with 'tensorboard --logdir yolov5\/runs\/train', view at http:\/\/localhost:6006\/\nwandb: Tracking run with wandb version 0.13.9\nwandb: Run data is saved locally in \/home\/tleyden\/Development\/seal-face-detection\/wandb\/run-20230118_182447-02ee6gxj\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run kind-meadow-202\nwandb: \u2b50\ufe0f View project at https:\/\/wandb.ai\/&lt;projectname&gt;\/train\nwandb: \ud83d\ude80 View run at https:\/\/wandb.ai\/&lt;projectname&gt;\/train\/runs\/02ee6gxj\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments         \n<\/code><\/pre>\n<p>Is there anything I can try in jupyterlab to get it to work?  If needed, I don\u2019t mind running it only in jupyterlab if it\u2019s not possible to switch back and forth between the two editing environments.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log two variables at different increments of timesteps?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-two-variables-at-different-increments-of-timesteps\/3674",
        "Question_created_time":"2023-01-10T14:49:39.466Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":150,
        "Question_body":"<p>Hi there! I was wondering, how do I deal with having multiple variables to log, but one of those variables I only want to log every 100 timesteps? The wandb docs seem to suggest that I need to collect all my metrics into one log function call, but in my scenario above where I want to track one variable every step and another variable every 100 steps, I would need multiple log calls. I saw the docs for the define metrics function, but I\u2019m not quite sure if that\u2019s the way to handle this. How do I approach this in PyTorch? Thanks!<\/p>\n<p>As an example, I currently have this Tensorboard logging that I\u2019m trying to convert to wandb:<\/p>\n<pre><code class=\"lang-auto\">print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\nwriter.add_scalar(\"charts\/episodic_return\", info[\"episode\"][\"r\"], global_step)\n\nif global_step % 100 == 0:\n    writer.add_scalar(\n        \"losses\/qf1_values\", qf1_a_values.mean().item(), global_step\n    )\n<\/code><\/pre>",
        "Question_closed_time":"2023-01-13T00:29:00.549Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/chulabhaya\">@chulabhaya<\/a> , happy to help. The approach you are considering is correct. You can set a check in place and log a dictionary with the values you want and set the step value.<\/p>\n<pre><code class=\"lang-auto\">for i in range (300):\n    if i%100==0:\n        wandb.log({\"value\": i, \"value\": 100}, step =i)\n    else:\n        wandb.log({\"value\": 100})\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log#customize-axes-and-summaries-with-define_metric\">defined metric<\/a> function allows you to have more control over the representation of your x axis and also how that axes is incremented. There are a few examples listed in the linked doc on how it functions. Please let me know if you have any questions.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Artifact download link",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifact-download-link\/3676",
        "Question_created_time":"2023-01-10T16:06:30.878Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":202,
        "Question_body":"<p>Hello everyone,<\/p>\n<p>In <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> for every created project, there is an Artifacts page. There we have a toolbar with the options: \u201cOverview\u201d, \u201cMetadata\u201d, \u201cUsage\u201d, \u201cFiles\u201d and \u201cLineage\u201d. In the Files section, there are downloadable links for every file that make part of a given artifact.<br>\nIs it possible to get through wandb package this downloadable Artifact URL link?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Changing files after starting a long sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/changing-files-after-starting-a-long-sweep\/3727",
        "Question_created_time":"2023-01-20T18:35:33.147Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":159,
        "Question_body":"<p>Hey,<\/p>\n<p>I think it\u2019s okay, but I just want to make sure. Say that I start a long hyperparameter sweep with many options, is it okay to change the code files after the sweep has started? or it might break something?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Page scrolls when moving panels in the web UI",
        "Question_link":"https:\/\/community.wandb.ai\/t\/page-scrolls-when-moving-panels-in-the-web-ui\/3672",
        "Question_created_time":"2023-01-10T14:45:04.230Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":133,
        "Question_body":"<p>Hello !<\/p>\n<p>When dragging panels within sections or from one section to another, the webpage scrolls back to the top. This makes it impossible to move panels around.<\/p>\n<p>Can this bug be fixed?<br>\nThank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to filter out sweep runs from UI",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-filter-out-sweep-runs-from-ui\/3725",
        "Question_created_time":"2023-01-20T07:58:45.952Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":178,
        "Question_body":"<p>I run several experiments, both singularly and using sweeps. Now I want to look at the results from the UI and I want to filter out runs that came from a sweep.<\/p>\n<p>I tried to filter out by name, but I can\u2019t get it to work. I manage to match all the sweep runs with the regex <code>.*sweep*<\/code>, but I don\u2019t know how to get the opposite. Any suggestion would be much appreciated, thanks! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":"2023-01-20T11:28:55.865Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/lclissa\">@lclissa<\/a> thanks for your question! You can go to the runs Table view and then perform the following actions: <code>Filter<\/code> &gt; <code>Add Filter<\/code> &gt; <code>Sweeps in \"&lt;null&gt;\"<\/code> as in the attached screenshot below.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/ef99184af5047a63dcc478a1480f31d9bcebc6ce.png\" data-download-href=\"\/uploads\/short-url\/ybA7qg4vIknsHb3jlIldWMRDplY.png?dl=1\" title=\"Screenshot 2023-01-20 at 11.25.10\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_690x244.png\" alt=\"Screenshot 2023-01-20 at 11.25.10\" data-base62-sha1=\"ybA7qg4vIknsHb3jlIldWMRDplY\" width=\"690\" height=\"244\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_690x244.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_1035x366.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_1380x488.png 2x\" data-dominant-color=\"262728\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-01-20 at 11.25.10<\/span><span class=\"informations\">1836\u00d7651 72.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>In this way you will end up with the runs that weren\u2019t part of the Sweeps. Would this work for you?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Is it possible to continue training with additional epochs? Also where can I find logs in local?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-continue-training-with-additional-epochs-also-where-can-i-find-logs-in-local\/3667",
        "Question_created_time":"2023-01-10T13:08:13.482Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":176,
        "Question_body":"<p>Dear wandb team,<\/p>\n<p>I currently start using pytorch-lightning combining with wandb, so I will use WandbLogger. (Due to link limits, I didn\u2019t put url for the documentation.)<\/p>\n<p>Suppose I had trained a model, let\u2019s say for 10 epochs. The <em>project<\/em> is <strong>wandb_toy<\/strong>,  and the <em>name or ID<\/em> is <strong>toy<\/strong>. After training, it will automatically create two folders under <code>.\/<\/code>, i.e., <code>.\/wandb<\/code> and <code>.\/wandb_toy<\/code>. I know that the checkpoints will be saved in <code>wandb_toy\/toy\/checkpoints<\/code>. Also there will be a new run folder in <code>.\/wandb<\/code>, let\u2019s say <code>.\/wandb\/run-20230101_102000<\/code>.<\/p>\n<p>Now if I want to continue the training from <em>epochs=10<\/em> to <em>epochs=20<\/em>, I know I can load the model state with adding <em>ckpt_path<\/em> during <em>trainer.fit()<\/em>, also update the config with <em>allow_val_change<\/em> setting to <em>True<\/em>. However, there is still a new additional run folder created, e.g., <code>.\/wandb\/run-20230202_104000<\/code>.<\/p>\n<hr>\n<p><strong>My questions are:<\/strong><\/p>\n<ul>\n<li>I want to keep saving or update things in the original run folder <code>.\/wandb\/run-20230101_102000<\/code>.<\/li>\n<li>Also is there any way to name the run folder, for example, change  <code>.\/wandb\/run-20230101_102000<\/code> to  <code>.\/wandb\/my_toy_run<\/code>. I have tried keywords like <em>dir<\/em> or <em>save_dir<\/em> already, but seems not right.<\/li>\n<li>If I delete the project in wandb ai (without delete folders in <code>.\/wandb<\/code>), then continue training from <em>epoch=10<\/em> to <em>epoch=20<\/em>, It will log only from epoch=10~20. Is there any way to still get the previous log from epoch=0~10? I have tried to look up <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/save-restore#examples-of-wandb.restore\"> Save &amp; Restore Files<\/a> or <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming\">Resume Runs<\/a>, but unfortunately I couldn\u2019t figure it out.<\/li>\n<li>If I want to see each epochs log (e.g., accuracy and loss) in  my local, which file should I look for?<\/li>\n<\/ul>\n<p>Thanks for reading and I apologize if I couldn\u2019t make things clear.<\/p>\n<p>Best wishes,<br>\nYian<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Waiting for wandb.init",
        "Question_link":"https:\/\/community.wandb.ai\/t\/waiting-for-wandb-init\/3658",
        "Question_created_time":"2023-01-09T18:43:24.453Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":682,
        "Question_body":"<p>Hi, the code ran 3 days agoand it worked, but after I changed some variables and it failed with: \u201cwandb: W&amp;B API key is configured. Use <code>wandb login --relogin<\/code> to force relogin wandb: - Waiting for wandb.init()\u2026wandb: \\ Waiting for wandb.init()\u2026wandb: | Waiting for wandb.init()\u2026wandb: \/ Waiting for wandb.init()\u2026wandb: - Waiting for wandb.init()\u2026Traceback (most recent call last):\u201d. Now after I changed it back the error persists.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Alpha channel of standard deviation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/alpha-channel-of-standard-deviation\/3681",
        "Question_created_time":"2023-01-11T14:04:08.149Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":145,
        "Question_body":"<p>Hello,<br>\ncan I change the alpha channel for an area of standard deviation around the line chart? Now it\u2019s not contrasting for me. I cannot recognise well the background and generated an area of stddev. Thanks a lot.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/32a3a3152fa5af0639ab0307252f741fd6e98d66.jpeg\" alt=\"image\" data-base62-sha1=\"7dYsME5bMAybvxWbkjJ2F0gbUHQ\" width=\"482\" height=\"253\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resume run not working for sweep run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/resume-run-not-working-for-sweep-run\/3690",
        "Question_created_time":"2023-01-12T17:47:46.357Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":365,
        "Question_body":"<p>I am looking to resume some runs that crashed due to a timeout on a slurm cluster. I am doing this by supplying <code>wandb.init<\/code> with <code>id=run_id<\/code> and <code>resume=\"must\"<\/code>, however it is unable to resume as it seemingly is not finding the run or something like that.<\/p>\n<p>My resume code is as follows:<\/p>\n<pre data-code-wrap=\"py\"><code class=\"lang-plaintext\">            init_args = {}\n            if args.run_id is not None:\n                init_args['id'] = args.run_id\n                init_args['resume'] = 'must'\n                init_args['project'] = wandb_project\n            with wandb.init(**init_args):\n                # training code here (including loading the checkpoint in the case of resume)\n<\/code><\/pre>\n<p>When I run this it logs the following:<\/p>\n<pre><code class=\"lang-auto\">wandb: Sweep Agent: Waiting for job.\nwandb: Sweep Agent: Exiting.\n<\/code><\/pre>\n<p>and then sets the online Sweep State to finished. I am doing a grid search, and every parameter combination has a run associated with it, however some crashed due to the timeout. I am passing the IDs for these runs to my program (i.e. args.run_id contains the run ID of a crashed run), yet this happens.<\/p>\n<p>Is there anything I am missing?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to log confidence intervals?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-log-confidence-intervals\/3684",
        "Question_created_time":"2023-01-11T17:59:27.645Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":223,
        "Question_body":"<p>I log model scores by steps and at every step I have metric value, confidence interval lower bound, confidence interval upper bound. Is it possible to log confidence intervals (on one graph) and show the confidence interval using different color?<\/p>",
        "Question_closed_time":"2023-01-18T07:44:32.136Z",
        "Answer_body":"<p>Thank you so much for the example! This helps a whole lot. Currently this isn\u2019t a feature we have in our product, but I\u2019ll create a feature request for this and our team will reach out to you once there are any updates on this ticket.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Runs table expand view",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runs-table-expand-view\/3633",
        "Question_created_time":"2023-01-04T00:48:13.930Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":178,
        "Question_body":"<p>Hi,<\/p>\n<p>When I access to Runs Table, I found myself expanding the Runs table every single time.<br>\nIs there a way to set the expanded Runs table as default?<\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Images are not saved\/logged",
        "Question_link":"https:\/\/community.wandb.ai\/t\/images-are-not-saved-logged\/3697",
        "Question_created_time":"2023-01-13T20:51:05.557Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":163,
        "Question_body":"<p>Hi all,<\/p>\n<p>I am using pytorch_lightning.loggers.WandbLogger to log some intermediate results of my preprocessing but nothing (i.e. plots and images) are logged, except the key name.<\/p>\n<p>Below is what I did:<\/p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(..)\nrunner = Trainer(logger=wandb_logger,..)\ndata = VAEDataset(.., logger=runner.logger,..) # LightningDataModule\ndata.setup()\n\n# in Dataset (in some preprocessing steps)\nplt.figure(figsize=(10, 30))\nplt.subplot(131), plt.imshow(orig_spec.detach(), cmap='gray')\nplt.title('Input'), plt.xticks([]), plt.yticks([])\nplt.subplot(132), plt.imshow(filtered_spec.squeeze().detach(), cmap='gray')\nplt.title('FilteredSpec'), plt.xticks([]), plt.yticks([])\nplt.subplot(133), plt.imshow(magnitude_spec.detach(), cmap='gray')\nplt.title('MagnitudeSpec'), plt.xticks([]), plt.yticks([])\nself.logger.experiment.log(\n        {\"HPFilter\/Input_Filtered-_Magnitude-Spec\": plt}\n        )\n\n# alternatively, I used wandb directly\nwandb.log(\n            {\"HPFilter\/FilteredSpec\": wandb.Image(torch.flipud(filtered_spec).detach(), caption=\"FilteredSpec.png\")}\n        )\n<\/code><\/pre>\n<p>Both gave such empty panels:.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac.png\" data-download-href=\"\/uploads\/short-url\/vCtIR0dL0KQ5J70c9oMVxBaaXq4.png?dl=1\" title=\"wandb\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_690x229.png\" alt=\"wandb\" data-base62-sha1=\"vCtIR0dL0KQ5J70c9oMVxBaaXq4\" width=\"690\" height=\"229\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_690x229.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_1035x343.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac.png 2x\" data-dominant-color=\"FDFDFD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb<\/span><span class=\"informations\">1171\u00d7389 13.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>There is no subdir called \u201cHPFilter\u201d under \u201cmedia\u201d but when I checked <code>wandb-summary.json<\/code>:<\/p>\n<pre><code class=\"lang-auto\">..., \"HPFilter\/FilteredSpec\": {\"_type\": \"image-file\", \"sha256\": \"92bd05772ad44d6be9ef9fed80df00ff649e378abbcbb34f73d4082aceacedb0\", \"size\": 86404, \"path\": \"media\/images\/HPFilter\/FilteredSpec_2_92bd05772ad44d6be9ef.png\", \"format\": \"png\", \"width\": 128, \"height\": 256, \"caption\": \"FilteredSpec_33150.png\"}, ...\n<\/code><\/pre>\n<p><strong>Added:<\/strong><br>\nTo eliminate that the problem lies in my actual data, I tried the below to replace my intended logging:<\/p>\n<pre><code class=\"lang-auto\">    arr = torch.rand(256, 128)\n    wandb.log(\n            {\"HPFilter\/FilteredSpec\": wandb.Image(torch.flipud(arr).detach().cpu().numpy(), caption=f\"FilteredSpec.png\")}\n        )\n<\/code><\/pre>\n<p>It still behaved the same.<\/p>\n<p>Many thanks in advance for any hints!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to stop weights & biases (wandb) from creating random tmp files?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files\/3460",
        "Question_created_time":"2022-11-24T22:13:29.419Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":655,
        "Question_body":"<p>I have a million tmp files due to wandb on my home folder. I don\u2019t know why. Why are they being created &amp; how do I stop it?<\/p>\n<pre><code class=\"lang-auto\">anaconda\t\t\t\t\t   tmpa0wf77f_wandb-artifacts  tmpmv2ewoi1wandb-media\nanaconda.sh\t\t\t\t\t   tmpa3t655lewandb-media      tmpmvhp3i6ewandb-media\ndata\t\t\t\t\t\t   tmpa6roiz80wandb\t       tmpmwszwea4\ndebug-cli.brando9.log\t\t\t\t   tmpal7kticfwandb-artifacts  tmpn0p49w1hwandb-media\ndiversity-for-predictive-success-of-meta-learning  tmpalsnd4g1wandb-media      tmpnbxtnojbwandb-artifacts\ndiv_install_miniconda\t\t\t\t   tmpambb3rm9wandb-artifacts  tmpngpy96dawandb-artifacts\ndiv_install.out\t\t\t\t\t   tmpapco0xetwandb-media      tmpnqezeggnwandb-media\niit-term-synthesis\t\t\t\t   tmpaqf80v_hwandb-media      tmpo3cug5nzwandb-media\nmain.sh.e449240\t\t\t\t\t   tmpaqigpze6wandb-artifacts  tmpoc4x6l22wandb\nmain.sh.e457075\t\t\t\t\t   tmpaw1kvgtgwandb-media      tmpofql583uwandb-media\nmain.sh.e760266\t\t\t\t\t   tmpay63rbxgwandb-media      tmponqiggzswandb-artifacts\nmain.sh.err748250\t\t\t\t   tmpb2clycf5\t\t       tmpoqem6uclwandb-media\nmain.sh.err849450\t\t\t\t   tmpbbrfn_kmwandb-artifacts  tmpoqth0mgpwandb-media\nmain.sh.err923818\t\t\t\t   tmpbcxatqdiwandb-artifacts  tmppbd5bfm_wandb\nmain.sh.err962904\t\t\t\t   tmpbgewkz10wandb\t       tmppbnpm41gwandb-media\nmain.sh.o449240\t\t\t\t\t   tmpbsd96o99wandb-media      tmppwxmebn1\nmain.sh.o457075\t\t\t\t\t   tmpbtlp8zomwandb\t       tmpq396kfo1wandb-artifacts\nmain.sh.o748250\t\t\t\t\t   tmpby3a9u8ywandb\t       tmpq8jryat0wandb-media\nmain.sh.o760266\t\t\t\t\t   tmpc45e2nlxwandb-media      tmpqc65bfs0wandb\nmain.sh.o849450\t\t\t\t\t   tmpc4m5b21_\t\t       tmpqexdhp6gwandb-artifacts\nmain.sh.o923818\t\t\t\t\t   tmpcap20jmdwandb-media      tmpqh3uu7v2wandb-media\nmain.sh.o950686\t\t\t\t\t   tmpcl2sb6j_wandb\t       tmpqh99a72vwandb-media\nmain.sh.o962904\t\t\t\t\t   tmpcsncx8x4wandb-media      tmpqmim4sxywandb\nminiconda\t\t\t\t\t   tmpd7dhluxmwandb\t       tmpqpfcq9uwwandb\nminiconda.sh\t\t\t\t\t   tmpdbbb3hw_wandb-artifacts  tmpqtds4jdiwandb-artifacts\nnohup.out\t\t\t\t\t   tmpdfrjyk90wandb-media      tmp_qz8pu0xwandb-artifacts\nnohup.out449240\t\t\t\t\t   tmpdhqwaxygwandb\t       tmpr98qj7auwandb\nnohup.out457075\t\t\t\t\t   tmpdpj3bfz0wandb-artifacts  tmprfwooa22wandb-artifacts\nnohup.out760266\t\t\t\t\t   tmpdqzzy7v3\t\t       tmpri9xu8i_wandb-media\npycoq\t\t\t\t\t\t   tmpdr6fbpctwandb\t       tmprj4g0kkhwandb\ntest.py\t\t\t\t\t\t   tmpejwo7axlwandb\t       tmp_rla0cb9wandb-media\ntmp\t\t\t\t\t\t   tmpekqp7b2dwandb-media      tmprmrasn0fwandb-media\ntmp03kmjan0wandb\t\t\t\t   tmpf3pk0_3t\t\t       tmpr_yrhzj_wandb\ntmp07zhon11wandb-media\t\t\t\t   tmpf4w8yhsswandb-media      tmprzxltg0lwandb\ntmp0pkwjwg8wandb\t\t\t\t   tmpf_6vd6hkwandb-media      tmps0beul64wandb-media\ntmp0ypuhnktwandb-media\t\t\t\t   tmpf7vuwlipwandb\t       tmps5qf0_w0wandb\ntmp0zk3_ok1wandb\t\t\t\t   tmpfc8ltujrwandb-media      tmpsp2djjg6wandb-artifacts\ntmp14xa24j_wandb\t\t\t\t   tmpfmcmwgb8\t\t       tmpsqe0vylnwandb\ntmp1f3gqdq1wandb-media\t\t\t\t   tmpfqhl6c9vwandb\t       tmpstniop3twandb-media\ntmp1hmrx3xnwandb\t\t\t\t   tmpfvkvyklpwandb-media      tmpsv3n4fi7wandb-media\ntmp1nxq8dmowandb\t\t\t\t   tmpfxuc2zwjwandb-artifacts  tmp_t3mkuy4\ntmp1r2xah97wandb-media\t\t\t\t   tmpg051c49z\t\t       tmptb0urf26wandb\ntmp1sdb3vnqwandb-media\t\t\t\t   tmpg16e6zpxwandb-media      tmptgq1h308wandb-media\ntmp1wq9i7tmwandb-media\t\t\t\t   tmpg2qfjo5pwandb-artifacts  tmpthtghn1wwandb-media\ntmp27k3evykwandb-artifacts\t\t\t   tmpg34wt2g1wandb-media      tmptkp9qpgxwandb-media\ntmp2ncmg9jmwandb-media\t\t\t\t   tmpggaltim9wandb-media      tmptqn9w7rawandb-artifacts\ntmp2qxmugpjwandb-media\t\t\t\t   tmpgj6gyqw6wandb-media      tmptsqb0lwrwandb\ntmp2w92xlzowandb\t\t\t\t   tmpgpv_1hxk\t\t       tmptub9i1zzwandb-media\ntmp39lds7tywandb-media\t\t\t\t   tmpgswv7jpn\t\t       tmpu0k6cuycwandb-media\ntmp3ncj9tdewandb-artifacts\t\t\t   tmpgvz0_o1h\t\t       tmpu6uv_y0pwandb\ntmp3qlpfrylwandb-media\t\t\t\t   tmpgyarr2jxwandb\t       tmpumz7hmaiwandb-artifacts\ntmp3snbanfnwandb\t\t\t\t   tmph6m9dpa_wandb\t       tmpun08cdmwwandb-artifacts\ntmp3xrxd920wandb-artifacts\t\t\t   tmph8n3b36swandb-media      tmp_uqnbz5n\ntmp3zmnx6jxwandb-artifacts\t\t\t   tmphddkq3_3wandb\t       tmpurv7_fe2wandb\ntmp4103eum2wandb\t\t\t\t   tmphmva83y4wandb\t       tmpuwoxzzfvwandb-media\ntmp421qmhu3wandb\t\t\t\t   tmphs6erdxrwandb-media      tmpvb5bk2js\ntmp48khxd0nwandb-artifacts\t\t\t   tmphshrf9juwandb-artifacts  tmpvd_wklrtwandb\ntmp49fv73y2wandb-media\t\t\t\t   tmpi31q87a0wandb-artifacts  tmpvg_71vtdwandb-media\ntmp49sad_g1wandb-artifacts\t\t\t   tmpiu05wr2_wandb\t       tmpvlxyr3eawandb-media\ntmp4c4800_xwandb-media\t\t\t\t   tmpivnhmojfwandb\t       tmpvqmyjo4pwandb-media\ntmp4clbe6xvwandb-media\t\t\t\t   tmpj16iv0rbwandb-media      tmpw10pvrxxwandb-media\ntmp4nuizjduwandb-media\t\t\t\t   tmpj4nmef2_wandb-media      tmpw8eaus7xwandb-media\ntmp5aiik94rwandb-media\t\t\t\t   tmpj6k4pajlwandb-artifacts  tmpw97zp6pqwandb-media\ntmp5jusc1czwandb-media\t\t\t\t   tmpjetcrm92wandb-media      tmpwkzzglljwandb-media\ntmp5ks7vxpqwandb\t\t\t\t   tmp_jfnbfwcwandb-artifacts  tmpwlpoppuwwandb-media\ntmp5ss5gfoqwandb-media\t\t\t\t   tmpjhcfo3sjwandb-media      tmpwok9yxtqwandb-media\ntmp61l257guwandb-media\t\t\t\t   tmpjhkja0n4wandb-media      tmpwqbb7793wandb\ntmp66a_30crwandb\t\t\t\t   tmpjq3bc0iywandb-media      tmpwu7oid1swandb-media\ntmp6_95ss09\t\t\t\t\t   tmpjseq6pjrwandb\t       tmpwwmlqm3gwandb-artifacts\ntmp6eb3e1v_wandb-artifacts\t\t\t   tmpjywyihxswandb\t       tmpwys0txyz\ntmp6ev3bw0kwandb-media\t\t\t\t   tmpk7eb9cxxwandb-artifacts  tmpx0i8_uxdwandb-media\ntmp6j_pagmjwandb-media\t\t\t\t   tmpki8mvo7pwandb\t       tmpxby6g44swandb-media\ntmp6uz84wzpwandb\t\t\t\t   tmpkiqc2rxywandb-media      tmpxdsg3tk8wandb-artifacts\ntmp7dmpqrecwandb\t\t\t\t   tmpklsmildcwandb-media      tmpxm2j1915wandb\ntmp7fzpg3pjwandb-artifacts\t\t\t   tmpkvhsusnzwandb-artifacts  tmp_xmydpcnwandb-media\ntmp7iafm3cywandb-media\t\t\t\t   tmpkvt13pjiwandb\t       tmpxpj1qkhnwandb-media\ntmp7m0tkcx7wandb\t\t\t\t   tmpkxhoutmnwandb\t       tmpxqnwoio_wandb-media\ntmp7p7ko5c1\t\t\t\t\t   tmpl32i_q8cwandb-artifacts  tmpy3sbukw0wandb-artifacts\ntmp7xmnpnjxwandb-media\t\t\t\t   tmpldwit_dswandb-media      tmpy4tqgd9q\ntmp80lef2dvwandb\t\t\t\t   tmplf9oolt5wandb\t       tmpy5mlqvf2\ntmp89e0j4bjwandb-artifacts\t\t\t   tmplgmiofgnwandb-artifacts  tmpy5y0mxbrwandb\ntmp8h7rchd9wandb-artifacts\t\t\t   tmplw1n5b69wandb-media      tmpydoskv75wandb\ntmp8l4njuz2\t\t\t\t\t   tmplx9285iywandb\t       tmpyx791iakwandb-media\ntmp8lxb4u_0wandb\t\t\t\t   tmp_lzx3b9dwandb-media      tmpyy2hv95pwandb-artifacts\ntmp8lyo8smzwandb\t\t\t\t   tmpm1c4zy4twandb-artifacts  tmpz0gx4ikiwandb-media\ntmp8q4h8lu7wandb-artifacts\t\t\t   tmpm2755ginwandb-artifacts  tmpz26cajmh\ntmp_8uvnuf2wandb\t\t\t\t   tmpm56u1aa5wandb-media      tmpz5s198hnwandb-artifacts\ntmp96o0qfii\t\t\t\t\t   tmpm9gk_r6swandb-media      tmpz6oxqu4vwandb-media\ntmp974f9ciawandb-media\t\t\t\t   tmpm_9gv20owandb-media      tmpzgz2lbnmwandb\ntmp98ec7tz8wandb-media\t\t\t\t   tmpmdak3eqkwandb-media      tmpzyqel_hcwandb-artifacts\ntmp9i4bx28vwandb\t\t\t\t   tmpmekovp_5wandb-artifacts  tmpzzjlqqh8wandb-media\ntmp9l8xrnlqwandb-media\t\t\t\t   tmp_mpucxdiwandb-artifacts  ultimate-utils\ntmp9y_56adfwandb-media\t\t\t\t   tmpmsn3sy8mwandb-artifacts  wandb\n<\/code><\/pre>\n<h3>\n<a name=\"additional-files-1\" class=\"anchor\" href=\"#additional-files-1\"><\/a>Additional Files<\/h3>\n<p><em>No response<\/em><\/p>\n<h3>\n<a name=\"environment-2\" class=\"anchor\" href=\"#environment-2\"><\/a>Environment<\/h3>\n<p>WandB version:<br>\n(metalearning_gpu) brando9~ $ python<br>\nPython 3.9.13 (main, Oct 13 2022, 21:15:33)<br>\n[GCC 11.2.0] :: Anaconda, Inc. on linux<br>\nType \u201chelp\u201d, \u201ccopyright\u201d, \u201ccredits\u201d or \u201clicense\u201d for more information.<\/p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import wandb<br>\nwandb.<strong>version<\/strong><br>\n\u20180.13.5\u2019<\/p>\n<\/blockquote>\n<\/blockquote>\n<\/blockquote>\n<p>OS: ubuntu\/linux<\/p>\n<p>(metalearning_gpu) brando9~ $ cat \/etc\/os-release<br>\nNAME=\u201cUbuntu\u201d<br>\nVERSION=\u201c16.04.7 LTS (Xenial Xerus)\u201d<br>\nID=ubuntu<br>\nID_LIKE=debian<br>\nPRETTY_NAME=\u201cUbuntu 16.04.7 LTS\u201d<br>\nVERSION_ID=\u201c16.04\u201d<br>\nHOME_URL=\u201c<a href=\"http:\/\/www.ubuntu.com\/\" rel=\"noopener nofollow ugc\">http:\/\/www.ubuntu.com\/<\/a>\u201d<br>\nSUPPORT_URL=\u201c<a href=\"http:\/\/help.ubuntu.com\/\" rel=\"noopener nofollow ugc\">http:\/\/help.ubuntu.com\/<\/a>\u201d<br>\nBUG_REPORT_URL=\u201c<a href=\"http:\/\/bugs.launchpad.net\/ubuntu\/\" rel=\"noopener nofollow ugc\">http:\/\/bugs.launchpad.net\/ubuntu\/<\/a>\u201d<br>\nVERSION_CODENAME=xenial<br>\nUBUNTU_CODENAME=xenial<\/p>\n<p>Python version: 3.9.13<\/p>\n<p>Versions of relevant libraries:<\/p>\n<hr>\n<p>related:<\/p>\n<ul>\n<li>cross: <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4535\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Random tmp files being made -- why? \u00b7 Issue #4535 \u00b7 wandb\/wandb \u00b7 GitHub<\/a>\n<\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/74566670\/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">machine learning - How to stop weights &amp; biases (wandb) from creating random tmp files? - Stack Overflow<\/a><\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Easy integration with yolov8?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/easy-integration-with-yolov8\/3694",
        "Question_created_time":"2023-01-13T10:50:17.251Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":117,
        "Question_body":"<p>I tried the Pytorch integration and it doesn\u2019t work:<\/p>\n<pre><code class=\"lang-auto\">from ultralytics import YOLO\n\nimport wandb\nwandb.init()\n\n# Load a model\nmodel = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n\n# Magic\nwandb.watch(model, log_freq=100)\n\nmodel.train()\nfor batch_idx, (data, target) in enumerate(train_loader):\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    if batch_idx % args.log_interval == 0:\n        wandb.log({\"loss\": loss})\n\n\n# Use the model\nresults = model.train(data=\"coco128.yaml\", epochs=3, batch = 2)  # train the model\n<\/code><\/pre>\n<p>I get the following:<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"train.py\", line 10, in &lt;module&gt;\n    wandb.watch(model, log_freq=100)\n  File \"\/home\/henry\/.local\/bin\/.virtualenvs\/ultralytics\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_watch.py\", line 71, in watch\n    raise ValueError(\nValueError: Expected a pytorch model (torch.nn.Module). Received &lt;class 'ultralytics.yolo.engine.model.YOLO'&gt;\n\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"OSError: Input\/output error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/oserror-input-output-error\/3693",
        "Question_created_time":"2023-01-13T10:47:31.697Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":244,
        "Question_body":"<p>Hi everyone,<br>\nwhile using wandb to log the metrics of my model (written using PyTorch), I randomly get an exception during the training phase. It is still unclear to me why and when this happens, but it causes my runs to stop which is quite annoying.<\/p>\n<p>Any ideas? I really appreciate any help you can provide!<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/logging\/__init__.py\", line 1085, in emit\n    self.flush()\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/logging\/__init__.py\", line 1065, in flush\n    self.stream.flush()\nOSError: [Errno 5] Input\/output error\nCall stack:\nException in thread OutRawRd-stderr:\nTraceback (most recent call last):\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/threading.py\", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 1027, in _output_raw_reader_thread\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 1042, in _output_raw_flush\n    self._output_raw_file.write(data.encode(\"utf-8\"))\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/filesystem.py\", line 64, in write\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/threading.py\", line 890, in _bootstrap\n    self._bootstrap_inner()\n  File \"\/usr\/local\/anaconda3\/lib\/python3.8\/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 49, in run\n    self._run()\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 264, in _process\n    self._hm.handle(record)\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 131, in handle\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 139, in handle_request\nMessage: 'handle_request: partial_history'\nArguments: ()\n    super().write(b\"\\n\".join(ret) + b\"\\n\")\n  File \"\/homes\/llumetti\/alveolar_canal_base\/venv\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/filesystem.py\", line 31, in write\n    self.f.flush()\nOSError: [Errno 5] Input\/output error\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wrong result after wandb sync",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wrong-result-after-wandb-sync\/3570",
        "Question_created_time":"2022-12-19T10:50:43.749Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":315,
        "Question_body":"<p>Hi everyone. I have a problem related to the sync of multiple offline runs: when syncing older runs are always overwritten with the latest run. The yellow and pink runs are represented only by the second run, while the first ones (from epoch 0 to nearly 100) have disappeared. Syncing only the first run makes the latter disappear. Runs were synced with the command<\/p>\n<pre><code class=\"lang-auto\">wandb sync --sync-all \"wandb\"\n<\/code><\/pre>\n<p>The blue run was an example of a complete online run on a different platform but with the same code.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/1459cc50f81ec38d21c64bc20597919c19713c54.png\" data-download-href=\"\/uploads\/short-url\/2U1Wl6jhdLxDHIIQSfDpdpo7IA4.png?dl=1\" title=\"wandb-error\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1459cc50f81ec38d21c64bc20597919c19713c54_2_690x260.png\" alt=\"wandb-error\" data-base62-sha1=\"2U1Wl6jhdLxDHIIQSfDpdpo7IA4\" width=\"690\" height=\"260\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1459cc50f81ec38d21c64bc20597919c19713c54_2_690x260.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1459cc50f81ec38d21c64bc20597919c19713c54_2_1035x390.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1459cc50f81ec38d21c64bc20597919c19713c54_2_1380x520.png 2x\" data-dominant-color=\"FEFEFE\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb-error<\/span><span class=\"informations\">1801\u00d7680 29.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Does someone know how to fix this?<\/p>",
        "Question_closed_time":"2022-12-21T20:03:42.985Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/lorenzo_b\">@lorenzo_b<\/a>, are these runs using the same run_id? If two runs have the same run_id then the second one will overwrite the first when it gets synced.<\/p>\n<p>One option is to specify a new run_id with <code>wandb sync &lt;run_folder&gt; --id &lt;new_run_id&gt;<\/code>. This won\u2019t work with <code>--sync-all<\/code> but you can write a quick for loop to iterate over each run folder and sync the runs individually.<\/p>\n<p>Let me know if this helps!<br>\n-Nate<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Multi-run confusion matrix is missing class",
        "Question_link":"https:\/\/community.wandb.ai\/t\/multi-run-confusion-matrix-is-missing-class\/3691",
        "Question_created_time":"2023-01-12T20:27:54.420Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":79,
        "Question_body":"<p>I  am working on a 3 classes classification problem and my confusion matrix is getting messed up. It does not show class 1.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/db00d90402775cbd38aa10db03d568c86fe1b6b1.png\" data-download-href=\"\/uploads\/short-url\/vfonHnXSPR6s8bDCiSBgLDe4P17.png?dl=1\" title=\"multi-run_confusion_matrix\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/db00d90402775cbd38aa10db03d568c86fe1b6b1.png\" alt=\"multi-run_confusion_matrix\" data-base62-sha1=\"vfonHnXSPR6s8bDCiSBgLDe4P17\" width=\"690\" height=\"445\" data-dominant-color=\"F9F6F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">multi-run_confusion_matrix<\/span><span class=\"informations\">1016\u00d7656 12.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The test accuracy for all three classes is 95% and all three classes are actually in the dataset.<\/p>\n<pre><code class=\"lang-auto\">        # log data for the confusion matrix\n        wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n                        y_true=y_test_true, preds=y_test_pred,\n                        class_names=labels)})\n<\/code><\/pre>\n<p>Any idea how to solve this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Gradients Panel Management",
        "Question_link":"https:\/\/community.wandb.ai\/t\/gradients-panel-management\/3688",
        "Question_created_time":"2023-01-12T11:45:04.026Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":78,
        "Question_body":"<p>Hi there!<br>\nI ran a sweep logging the gradients and they showed up in the Dashboard, but they don\u2019t follow the graph model (also logged in the <code>Model<\/code> section of the dashboard), hence it is difficult to see the gradient evolution from \u201cinit to final\u201d.<br>\nAlso, I can\u2019t setup a custom layout since they\u2019re more than 50\u2026<\/p>\n<p>Thanks in advance for your help!<\/p>\n<p>Mattia<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Join over different tables in a run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/join-over-different-tables-in-a-run\/3670",
        "Question_created_time":"2023-01-10T14:34:42.853Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":173,
        "Question_body":"<p>Hello,<\/p>\n<p>I am looking at <a href=\"https:\/\/wandb.ai\/stacey\/mnist-viz\/reports\/Visualize-Predictions-over-Time--Vmlldzo1OTQxMTk\">this example<\/a> where at each epoch a table is generated to represent a dataset (images, ground truth) along with the model prediction and is then logged to be able to visualize the model prediction at every epoch.<\/p>\n<p>It looks redundant and bandwidth-hungry to log the images at every epoch. I would like to have a way to log the dataset as a table only once with the columns (id, image, ground truth), then at every epoch log only a  table with the model predictions i.e. with columns (id, prediction), then on the UI join the two tables on the \u201cid\u201d key.<\/p>\n<p>This does not seem to be possible at the moment. Has anyone tried something similar? Is it really standard to log a whole dataset at every evaluation step?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Storing the files to AWS S3",
        "Question_link":"https:\/\/community.wandb.ai\/t\/storing-the-files-to-aws-s3\/3679",
        "Question_created_time":"2023-01-11T12:41:11.244Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_body":"<p>Is there a way we can save the tables to our own AWS S3 bucket ratherthan using W&amp;B storage.<br>\nCan we save all the .ckpt, .wand files that wandb logs to our AWS cloud storage.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb does not log all .py files",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-does-not-log-all-py-files\/3602",
        "Question_created_time":"2022-12-26T11:09:24.621Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":298,
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019m having an issue with logging code using wandb.run.log_code(\u201c.\u201d). While there are other .py files present in my directory, wandb only seems to log the script that called wandb.init(). This is frustrating, as I want to see all of the code that was used in my run. I\u2019ve even tried stepping through with a debugger, and it looks like wandb is looping over those .py files, but for some reason they aren\u2019t being logged on the run page in the code section.<\/p>\n<p>Has anyone else experienced this issue, or have any suggestions for how to resolve it?<\/p>\n<p>Thanks in advance for any help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Advanced legend doesn't display properly or displays [Object Object]",
        "Question_link":"https:\/\/community.wandb.ai\/t\/advanced-legend-doesnt-display-properly-or-displays-object-object\/3638",
        "Question_created_time":"2023-01-04T16:20:20.018Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":156,
        "Question_body":"<p>I am trying to customize the legend on plots using the Advanced Legend syntax. But have a couple of problems there. Here is the workspace\/plot: <a href=\"https:\/\/wandb.ai\/gat\/wandb-debug5?workspace=user-wjgat\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>I am using the following string in the advanced legend: <code>A=(${config:spec.url}) B=(${config:url}) C=${config:spec_name}<\/code><\/p>\n<p>This should render as `A=(http:\\google.com\/) B=(http:\\google.com\/) C=(google) but:<\/p>\n<ol>\n<li>It renders as <code>A=( ) B=(http:\\\\google.com) C=google<\/code>\n<\/li>\n<li>The \u201con hover\u201d legend renders as <code>A=( ) B=([Object Object]) C=google<\/code>\n<\/li>\n<\/ol>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/339707641144d812c66bf80fbc18a6b6f79de511.png\" data-download-href=\"\/uploads\/short-url\/7mnVAwnMPAidW9iqjOHkGnGgI6J.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/339707641144d812c66bf80fbc18a6b6f79de511_2_690x420.png\" alt=\"image\" data-base62-sha1=\"7mnVAwnMPAidW9iqjOHkGnGgI6J\" width=\"690\" height=\"420\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/339707641144d812c66bf80fbc18a6b6f79de511_2_690x420.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/339707641144d812c66bf80fbc18a6b6f79de511_2_1035x630.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/339707641144d812c66bf80fbc18a6b6f79de511.png 2x\" data-dominant-color=\"F4F6FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1190\u00d7726 100 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Are those bugs in wandb or I don\u2019t get sth?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Matplotlib Plot throws an error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/matplotlib-plot-throws-an-error\/3654",
        "Question_created_time":"2023-01-09T11:59:32.634Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":232,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m trying to log a matplotlib graph on Wandb and it throws the following error.<\/p>\n<pre><code class=\"lang-bash\">AttributeError: 'XAxis' object has no attribute '_gridOnMajor'\n<\/code><\/pre>\n<p>Steps to reproduce:<br>\nFollowing example: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots#matplotlib-and-plotly-plots\" class=\"inline-onebox\">Log Plots - Documentation<\/a><\/p>\n<h2>\n<a name=\"exact-steps-1\" class=\"anchor\" href=\"#exact-steps-1\"><\/a>Exact steps:<\/h2>\n<h3>\n<a name=\"imports-2\" class=\"anchor\" href=\"#imports-2\"><\/a>imports<\/h3>\n<pre><code class=\"lang-python\">import wandb\nimport random\nimport math\n<\/code><\/pre>\n<h3>\n<a name=\"login-3\" class=\"anchor\" href=\"#login-3\"><\/a>Login:<\/h3>\n<pre><code class=\"lang-python\">wandb.login()\n<\/code><\/pre>\n<h3>\n<a name=\"create-and-upload-graph-4\" class=\"anchor\" href=\"#create-and-upload-graph-4\"><\/a>Create and upload graph<\/h3>\n<pre><code class=\"lang-auto\"># Start a new run\nrun = wandb.init(project='custom-charts')\noffset = random.random()\n\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel(\"some interesting numbers\")\nwandb.log({\"chart\": plt})\n\n# Finally, end the run. We only need this ine in Jupyter notebooks.\nrun.finish()\n<\/code><\/pre>\n<h3>\n<a name=\"summary-error-message-5\" class=\"anchor\" href=\"#summary-error-message-5\"><\/a>Summary error message:<\/h3>\n<pre><code class=\"lang-auto\">AttributeError                            Traceback (most recent call last)\n\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb Cell 4 in &lt;cell line: 9&gt;()\n      7 plt.plot([1, 2, 3, 4])\n      8 plt.ylabel(\"some interesting numbers\")\n----&gt; 9 wandb.log({\"chart\": plt})\n     11 # Finally, end the run. We only need this ine in Jupyter notebooks.\n     12 run.finish()\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:256, in _run_decorator._noop.&lt;locals&gt;.wrapper(self, *args, **kwargs)\n    253         wandb.termwarn(message, repeat=False)\n    254         return cls.Dummy()\n--&gt; 256 return func(self, *args, **kwargs)\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:222, in _run_decorator._attach.&lt;locals&gt;.wrapper(self, *args, **kwargs)\n    220         raise e\n    221     cls._is_attaching = \"\"\n--&gt; 222 return func(self, *args, **kwargs)\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1548, in Run.log(self, data, step, commit, sync)\n   1541 if sync is not None:\n   1542     deprecate.deprecate(\n   1543         field_name=deprecate.Deprecated.run__log_sync,\n   1544         warning_message=(\n   1545             \"`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\"\n   1546         ),\n   1547     )\n-&gt; 1548 self._log(data=data, step=step, commit=commit)\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1339, in Run._log(self, data, step, commit)\n   1336 if any(not isinstance(key, str) for key in data.keys()):\n   1337     raise ValueError(\"Key values passed to `wandb.log` must be strings.\")\n-&gt; 1339 self._partial_history_callback(data, step, commit)\n   1341 if step is not None:\n   1342     if os.getpid() != self._init_pid or self._is_attached:\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1228, in Run._partial_history_callback(self, row, step, commit)\n   1225 if self._backend and self._backend.interface:\n   1226     not_using_tensorboard = len(wandb.patched[\"tensorboard\"]) == 0\n-&gt; 1228     self._backend.interface.publish_partial_history(\n   1229         row,\n   1230         user_step=self._step,\n   1231         step=step,\n   1232         flush=commit,\n   1233         publish_step=not_using_tensorboard,\n   1234     )\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/interface\/interface.py:541, in InterfaceBase.publish_partial_history(self, data, user_step, step, flush, publish_step, run)\n    530 def publish_partial_history(\n    531     self,\n    532     data: dict,\n   (...)\n    537     run: Optional[\"Run\"] = None,\n    538 ) -&gt; None:\n    539     run = run or self._run\n--&gt; 541     data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n    542     data.pop(\"_step\", None)\n    544     partial_history = pb.PartialHistoryRequest()\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/utils.py:54, in history_dict_to_json(run, payload, step, ignore_copy_err)\n     50         payload[key] = history_dict_to_json(\n     51             run, val, step=step, ignore_copy_err=ignore_copy_err\n     52         )\n     53     else:\n---&gt; 54         payload[key] = val_to_json(\n     55             run, key, val, namespace=step, ignore_copy_err=ignore_copy_err\n     56         )\n     58 return payload\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/utils.py:82, in val_to_json(run, key, val, namespace, ignore_copy_err)\n     79     val = wandb.Table(dataframe=val)\n     81 elif util.is_matplotlib_typename(typename) or util.is_plotly_typename(typename):\n---&gt; 82     val = Plotly.make_plot_media(val)\n     83 elif isinstance(val, Sequence) and all(isinstance(v, WBValue) for v in val):\n     84     assert run\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/plotly.py:48, in Plotly.make_plot_media(cls, val)\n     46     if util.matplotlib_contains_images(val):\n     47         return Image(val)\n---&gt; 48     val = util.matplotlib_to_plotly(val)\n     49 return cls(val)\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/util.py:565, in matplotlib_to_plotly(obj)\n    557 obj = ensure_matplotlib_figure(obj)\n    558 tools = get_module(\n    559     \"plotly.tools\",\n    560     required=(\n   (...)\n    563     ),\n    564 )\n--&gt; 565 return tools.mpl_to_plotly(obj)\n\nFile ~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/tools.py:112, in mpl_to_plotly(fig, resize, strip_style, verbose)\n    110 if matplotlylib:\n    111     renderer = matplotlylib.PlotlyRenderer()\n...\n--&gt; 246     if axis._gridOnMajor and len(gridlines) &gt; 0:\n    247         color = export_color(gridlines[0].get_color())\n    248         alpha = gridlines[0].get_alpha()\n\nAttributeError: 'XAxis' object has no attribute '_gridOnMajor'\n<\/code><\/pre>\n<h3>\n<a name=\"full-error-message-6\" class=\"anchor\" href=\"#full-error-message-6\"><\/a>Full Error message:<\/h3>\n<pre><code class=\"lang-bash\">{\n\t\"name\": \"AttributeError\",\n\t\"message\": \"'XAxis' object has no attribute '_gridOnMajor'\",\n\t\"stack\": \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\\n\\u001b[0;31mAttributeError\\u001b[0m                            Traceback (most recent call last)\\n\\u001b[1;32m\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb Cell 4\\u001b[0m in \\u001b[0;36m&lt;cell line: 9&gt;\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m      &lt;a href='vscode-notebook-cell:\/\/ssh-remote%2Bai_training_g5\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'&gt;7&lt;\/a&gt;\\u001b[0m plt\\u001b[39m.\\u001b[39mplot([\\u001b[39m1\\u001b[39m, \\u001b[39m2\\u001b[39m, \\u001b[39m3\\u001b[39m, \\u001b[39m4\\u001b[39m])\\n\\u001b[1;32m      &lt;a href='vscode-notebook-cell:\/\/ssh-remote%2Bai_training_g5\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'&gt;8&lt;\/a&gt;\\u001b[0m plt\\u001b[39m.\\u001b[39mylabel(\\u001b[39m\\\"\\u001b[39m\\u001b[39msome interesting numbers\\u001b[39m\\u001b[39m\\\"\\u001b[39m)\\n\\u001b[0;32m----&gt; &lt;a href='vscode-notebook-cell:\/\/ssh-remote%2Bai_training_g5\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'&gt;9&lt;\/a&gt;\\u001b[0m wandb\\u001b[39m.\\u001b[39;49mlog({\\u001b[39m\\\"\\u001b[39;49m\\u001b[39mchart\\u001b[39;49m\\u001b[39m\\\"\\u001b[39;49m: plt})\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:\/\/ssh-remote%2Bai_training_g5\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'&gt;11&lt;\/a&gt;\\u001b[0m \\u001b[39m# Finally, end the run. We only need this ine in Jupyter notebooks.\\u001b[39;00m\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:\/\/ssh-remote%2Bai_training_g5\/home\/ubuntu\/src\/workspace\/py-vision\/src\/research\/nbs\/automated_inventory_analysis\/aia_africaai_baseline\/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'&gt;12&lt;\/a&gt;\\u001b[0m run\\u001b[39m.\\u001b[39mfinish()\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:256\\u001b[0m, in \\u001b[0;36m_run_decorator._noop.&lt;locals&gt;.wrapper\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    253\\u001b[0m         wandb\\u001b[39m.\\u001b[39mtermwarn(message, repeat\\u001b[39m=\\u001b[39m\\u001b[39mFalse\\u001b[39;00m)\\n\\u001b[1;32m    254\\u001b[0m         \\u001b[39mreturn\\u001b[39;00m \\u001b[39mcls\\u001b[39m\\u001b[39m.\\u001b[39mDummy()\\n\\u001b[0;32m--&gt; 256\\u001b[0m \\u001b[39mreturn\\u001b[39;00m func(\\u001b[39mself\\u001b[39;49m, \\u001b[39m*\\u001b[39;49margs, \\u001b[39m*\\u001b[39;49m\\u001b[39m*\\u001b[39;49mkwargs)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:222\\u001b[0m, in \\u001b[0;36m_run_decorator._attach.&lt;locals&gt;.wrapper\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    220\\u001b[0m         \\u001b[39mraise\\u001b[39;00m e\\n\\u001b[1;32m    221\\u001b[0m     \\u001b[39mcls\\u001b[39m\\u001b[39m.\\u001b[39m_is_attaching \\u001b[39m=\\u001b[39m \\u001b[39m\\\"\\u001b[39m\\u001b[39m\\\"\\u001b[39m\\n\\u001b[0;32m--&gt; 222\\u001b[0m \\u001b[39mreturn\\u001b[39;00m func(\\u001b[39mself\\u001b[39;49m, \\u001b[39m*\\u001b[39;49margs, \\u001b[39m*\\u001b[39;49m\\u001b[39m*\\u001b[39;49mkwargs)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1548\\u001b[0m, in \\u001b[0;36mRun.log\\u001b[0;34m(self, data, step, commit, sync)\\u001b[0m\\n\\u001b[1;32m   1541\\u001b[0m \\u001b[39mif\\u001b[39;00m sync \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m   1542\\u001b[0m     deprecate\\u001b[39m.\\u001b[39mdeprecate(\\n\\u001b[1;32m   1543\\u001b[0m         field_name\\u001b[39m=\\u001b[39mdeprecate\\u001b[39m.\\u001b[39mDeprecated\\u001b[39m.\\u001b[39mrun__log_sync,\\n\\u001b[1;32m   1544\\u001b[0m         warning_message\\u001b[39m=\\u001b[39m(\\n\\u001b[1;32m   1545\\u001b[0m             \\u001b[39m\\\"\\u001b[39m\\u001b[39m`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\\u001b[39m\\u001b[39m\\\"\\u001b[39m\\n\\u001b[1;32m   1546\\u001b[0m         ),\\n\\u001b[1;32m   1547\\u001b[0m     )\\n\\u001b[0;32m-&gt; 1548\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_log(data\\u001b[39m=\\u001b[39;49mdata, step\\u001b[39m=\\u001b[39;49mstep, commit\\u001b[39m=\\u001b[39;49mcommit)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1339\\u001b[0m, in \\u001b[0;36mRun._log\\u001b[0;34m(self, data, step, commit)\\u001b[0m\\n\\u001b[1;32m   1336\\u001b[0m \\u001b[39mif\\u001b[39;00m \\u001b[39many\\u001b[39m(\\u001b[39mnot\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(key, \\u001b[39mstr\\u001b[39m) \\u001b[39mfor\\u001b[39;00m key \\u001b[39min\\u001b[39;00m data\\u001b[39m.\\u001b[39mkeys()):\\n\\u001b[1;32m   1337\\u001b[0m     \\u001b[39mraise\\u001b[39;00m \\u001b[39mValueError\\u001b[39;00m(\\u001b[39m\\\"\\u001b[39m\\u001b[39mKey values passed to `wandb.log` must be strings.\\u001b[39m\\u001b[39m\\\"\\u001b[39m)\\n\\u001b[0;32m-&gt; 1339\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_partial_history_callback(data, step, commit)\\n\\u001b[1;32m   1341\\u001b[0m \\u001b[39mif\\u001b[39;00m step \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m   1342\\u001b[0m     \\u001b[39mif\\u001b[39;00m os\\u001b[39m.\\u001b[39mgetpid() \\u001b[39m!=\\u001b[39m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_init_pid \\u001b[39mor\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_is_attached:\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_run.py:1228\\u001b[0m, in \\u001b[0;36mRun._partial_history_callback\\u001b[0;34m(self, row, step, commit)\\u001b[0m\\n\\u001b[1;32m   1225\\u001b[0m \\u001b[39mif\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_backend \\u001b[39mand\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_backend\\u001b[39m.\\u001b[39minterface:\\n\\u001b[1;32m   1226\\u001b[0m     not_using_tensorboard \\u001b[39m=\\u001b[39m \\u001b[39mlen\\u001b[39m(wandb\\u001b[39m.\\u001b[39mpatched[\\u001b[39m\\\"\\u001b[39m\\u001b[39mtensorboard\\u001b[39m\\u001b[39m\\\"\\u001b[39m]) \\u001b[39m==\\u001b[39m \\u001b[39m0\\u001b[39m\\n\\u001b[0;32m-&gt; 1228\\u001b[0m     \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_backend\\u001b[39m.\\u001b[39;49minterface\\u001b[39m.\\u001b[39;49mpublish_partial_history(\\n\\u001b[1;32m   1229\\u001b[0m         row,\\n\\u001b[1;32m   1230\\u001b[0m         user_step\\u001b[39m=\\u001b[39;49m\\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_step,\\n\\u001b[1;32m   1231\\u001b[0m         step\\u001b[39m=\\u001b[39;49mstep,\\n\\u001b[1;32m   1232\\u001b[0m         flush\\u001b[39m=\\u001b[39;49mcommit,\\n\\u001b[1;32m   1233\\u001b[0m         publish_step\\u001b[39m=\\u001b[39;49mnot_using_tensorboard,\\n\\u001b[1;32m   1234\\u001b[0m     )\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/interface\/interface.py:541\\u001b[0m, in \\u001b[0;36mInterfaceBase.publish_partial_history\\u001b[0;34m(self, data, user_step, step, flush, publish_step, run)\\u001b[0m\\n\\u001b[1;32m    530\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mpublish_partial_history\\u001b[39m(\\n\\u001b[1;32m    531\\u001b[0m     \\u001b[39mself\\u001b[39m,\\n\\u001b[1;32m    532\\u001b[0m     data: \\u001b[39mdict\\u001b[39m,\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    537\\u001b[0m     run: Optional[\\u001b[39m\\\"\\u001b[39m\\u001b[39mRun\\u001b[39m\\u001b[39m\\\"\\u001b[39m] \\u001b[39m=\\u001b[39m \\u001b[39mNone\\u001b[39;00m,\\n\\u001b[1;32m    538\\u001b[0m ) \\u001b[39m-\\u001b[39m\\u001b[39m&gt;\\u001b[39m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    539\\u001b[0m     run \\u001b[39m=\\u001b[39m run \\u001b[39mor\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_run\\n\\u001b[0;32m--&gt; 541\\u001b[0m     data \\u001b[39m=\\u001b[39m history_dict_to_json(run, data, step\\u001b[39m=\\u001b[39;49muser_step, ignore_copy_err\\u001b[39m=\\u001b[39;49m\\u001b[39mTrue\\u001b[39;49;00m)\\n\\u001b[1;32m    542\\u001b[0m     data\\u001b[39m.\\u001b[39mpop(\\u001b[39m\\\"\\u001b[39m\\u001b[39m_step\\u001b[39m\\u001b[39m\\\"\\u001b[39m, \\u001b[39mNone\\u001b[39;00m)\\n\\u001b[1;32m    544\\u001b[0m     partial_history \\u001b[39m=\\u001b[39m pb\\u001b[39m.\\u001b[39mPartialHistoryRequest()\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/utils.py:54\\u001b[0m, in \\u001b[0;36mhistory_dict_to_json\\u001b[0;34m(run, payload, step, ignore_copy_err)\\u001b[0m\\n\\u001b[1;32m     50\\u001b[0m         payload[key] \\u001b[39m=\\u001b[39m history_dict_to_json(\\n\\u001b[1;32m     51\\u001b[0m             run, val, step\\u001b[39m=\\u001b[39mstep, ignore_copy_err\\u001b[39m=\\u001b[39mignore_copy_err\\n\\u001b[1;32m     52\\u001b[0m         )\\n\\u001b[1;32m     53\\u001b[0m     \\u001b[39melse\\u001b[39;00m:\\n\\u001b[0;32m---&gt; 54\\u001b[0m         payload[key] \\u001b[39m=\\u001b[39m val_to_json(\\n\\u001b[1;32m     55\\u001b[0m             run, key, val, namespace\\u001b[39m=\\u001b[39;49mstep, ignore_copy_err\\u001b[39m=\\u001b[39;49mignore_copy_err\\n\\u001b[1;32m     56\\u001b[0m         )\\n\\u001b[1;32m     58\\u001b[0m \\u001b[39mreturn\\u001b[39;00m payload\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/utils.py:82\\u001b[0m, in \\u001b[0;36mval_to_json\\u001b[0;34m(run, key, val, namespace, ignore_copy_err)\\u001b[0m\\n\\u001b[1;32m     79\\u001b[0m     val \\u001b[39m=\\u001b[39m wandb\\u001b[39m.\\u001b[39mTable(dataframe\\u001b[39m=\\u001b[39mval)\\n\\u001b[1;32m     81\\u001b[0m \\u001b[39melif\\u001b[39;00m util\\u001b[39m.\\u001b[39mis_matplotlib_typename(typename) \\u001b[39mor\\u001b[39;00m util\\u001b[39m.\\u001b[39mis_plotly_typename(typename):\\n\\u001b[0;32m---&gt; 82\\u001b[0m     val \\u001b[39m=\\u001b[39m Plotly\\u001b[39m.\\u001b[39;49mmake_plot_media(val)\\n\\u001b[1;32m     83\\u001b[0m \\u001b[39melif\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(val, Sequence) \\u001b[39mand\\u001b[39;00m \\u001b[39mall\\u001b[39m(\\u001b[39misinstance\\u001b[39m(v, WBValue) \\u001b[39mfor\\u001b[39;00m v \\u001b[39min\\u001b[39;00m val):\\n\\u001b[1;32m     84\\u001b[0m     \\u001b[39massert\\u001b[39;00m run\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/sdk\/data_types\/plotly.py:48\\u001b[0m, in \\u001b[0;36mPlotly.make_plot_media\\u001b[0;34m(cls, val)\\u001b[0m\\n\\u001b[1;32m     46\\u001b[0m     \\u001b[39mif\\u001b[39;00m util\\u001b[39m.\\u001b[39mmatplotlib_contains_images(val):\\n\\u001b[1;32m     47\\u001b[0m         \\u001b[39mreturn\\u001b[39;00m Image(val)\\n\\u001b[0;32m---&gt; 48\\u001b[0m     val \\u001b[39m=\\u001b[39m util\\u001b[39m.\\u001b[39;49mmatplotlib_to_plotly(val)\\n\\u001b[1;32m     49\\u001b[0m \\u001b[39mreturn\\u001b[39;00m \\u001b[39mcls\\u001b[39m(val)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/wandb\/util.py:565\\u001b[0m, in \\u001b[0;36mmatplotlib_to_plotly\\u001b[0;34m(obj)\\u001b[0m\\n\\u001b[1;32m    557\\u001b[0m obj \\u001b[39m=\\u001b[39m ensure_matplotlib_figure(obj)\\n\\u001b[1;32m    558\\u001b[0m tools \\u001b[39m=\\u001b[39m get_module(\\n\\u001b[1;32m    559\\u001b[0m     \\u001b[39m\\\"\\u001b[39m\\u001b[39mplotly.tools\\u001b[39m\\u001b[39m\\\"\\u001b[39m,\\n\\u001b[1;32m    560\\u001b[0m     required\\u001b[39m=\\u001b[39m(\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    563\\u001b[0m     ),\\n\\u001b[1;32m    564\\u001b[0m )\\n\\u001b[0;32m--&gt; 565\\u001b[0m \\u001b[39mreturn\\u001b[39;00m tools\\u001b[39m.\\u001b[39;49mmpl_to_plotly(obj)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/tools.py:112\\u001b[0m, in \\u001b[0;36mmpl_to_plotly\\u001b[0;34m(fig, resize, strip_style, verbose)\\u001b[0m\\n\\u001b[1;32m    110\\u001b[0m \\u001b[39mif\\u001b[39;00m matplotlylib:\\n\\u001b[1;32m    111\\u001b[0m     renderer \\u001b[39m=\\u001b[39m matplotlylib\\u001b[39m.\\u001b[39mPlotlyRenderer()\\n\\u001b[0;32m--&gt; 112\\u001b[0m     matplotlylib\\u001b[39m.\\u001b[39;49mExporter(renderer)\\u001b[39m.\\u001b[39;49mrun(fig)\\n\\u001b[1;32m    113\\u001b[0m     \\u001b[39mif\\u001b[39;00m resize:\\n\\u001b[1;32m    114\\u001b[0m         renderer\\u001b[39m.\\u001b[39mresize()\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py:51\\u001b[0m, in \\u001b[0;36mExporter.run\\u001b[0;34m(self, fig)\\u001b[0m\\n\\u001b[1;32m     49\\u001b[0m     \\u001b[39mimport\\u001b[39;00m \\u001b[39mmatplotlib\\u001b[39;00m\\u001b[39m.\\u001b[39;00m\\u001b[39mpyplot\\u001b[39;00m \\u001b[39mas\\u001b[39;00m \\u001b[39mplt\\u001b[39;00m\\n\\u001b[1;32m     50\\u001b[0m     plt\\u001b[39m.\\u001b[39mclose(fig)\\n\\u001b[0;32m---&gt; 51\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49mcrawl_fig(fig)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py:118\\u001b[0m, in \\u001b[0;36mExporter.crawl_fig\\u001b[0;34m(self, fig)\\u001b[0m\\n\\u001b[1;32m    115\\u001b[0m \\u001b[39mwith\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mrenderer\\u001b[39m.\\u001b[39mdraw_figure(fig\\u001b[39m=\\u001b[39mfig,\\n\\u001b[1;32m    116\\u001b[0m                                props\\u001b[39m=\\u001b[39mutils\\u001b[39m.\\u001b[39mget_figure_properties(fig)):\\n\\u001b[1;32m    117\\u001b[0m     \\u001b[39mfor\\u001b[39;00m ax \\u001b[39min\\u001b[39;00m fig\\u001b[39m.\\u001b[39maxes:\\n\\u001b[0;32m--&gt; 118\\u001b[0m         \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49mcrawl_ax(ax)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py:123\\u001b[0m, in \\u001b[0;36mExporter.crawl_ax\\u001b[0;34m(self, ax)\\u001b[0m\\n\\u001b[1;32m    120\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mcrawl_ax\\u001b[39m(\\u001b[39mself\\u001b[39m, ax):\\n\\u001b[1;32m    121\\u001b[0m     \\u001b[39m\\\"\\\"\\\"Crawl the axes and process all elements within\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    122\\u001b[0m     \\u001b[39mwith\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mrenderer\\u001b[39m.\\u001b[39mdraw_axes(ax\\u001b[39m=\\u001b[39max,\\n\\u001b[0;32m--&gt; 123\\u001b[0m                                  props\\u001b[39m=\\u001b[39mutils\\u001b[39m.\\u001b[39;49mget_axes_properties(ax)):\\n\\u001b[1;32m    124\\u001b[0m         \\u001b[39mfor\\u001b[39;00m line \\u001b[39min\\u001b[39;00m ax\\u001b[39m.\\u001b[39mlines:\\n\\u001b[1;32m    125\\u001b[0m             \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mdraw_line(ax, line)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/utils.py:272\\u001b[0m, in \\u001b[0;36mget_axes_properties\\u001b[0;34m(ax)\\u001b[0m\\n\\u001b[1;32m    264\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mget_axes_properties\\u001b[39m(ax):\\n\\u001b[1;32m    265\\u001b[0m     props \\u001b[39m=\\u001b[39m {\\u001b[39m'\\u001b[39m\\u001b[39maxesbg\\u001b[39m\\u001b[39m'\\u001b[39m: export_color(ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_facecolor()),\\n\\u001b[1;32m    266\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxesbgalpha\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_alpha(),\\n\\u001b[1;32m    267\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mbounds\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_position()\\u001b[39m.\\u001b[39mbounds,\\n\\u001b[1;32m    268\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mdynamic\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_navigate(),\\n\\u001b[1;32m    269\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxison\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39maxison,\\n\\u001b[1;32m    270\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mframe_on\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_frame_on(),\\n\\u001b[1;32m    271\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mpatch_visible\\u001b[39m\\u001b[39m'\\u001b[39m:ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_visible(),\\n\\u001b[0;32m--&gt; 272\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxes\\u001b[39m\\u001b[39m'\\u001b[39m: [get_axis_properties(ax\\u001b[39m.\\u001b[39;49mxaxis),\\n\\u001b[1;32m    273\\u001b[0m                       get_axis_properties(ax\\u001b[39m.\\u001b[39myaxis)]}\\n\\u001b[1;32m    275\\u001b[0m     \\u001b[39mfor\\u001b[39;00m axname \\u001b[39min\\u001b[39;00m [\\u001b[39m'\\u001b[39m\\u001b[39mx\\u001b[39m\\u001b[39m'\\u001b[39m, \\u001b[39m'\\u001b[39m\\u001b[39my\\u001b[39m\\u001b[39m'\\u001b[39m]:\\n\\u001b[1;32m    276\\u001b[0m         axis \\u001b[39m=\\u001b[39m \\u001b[39mgetattr\\u001b[39m(ax, axname \\u001b[39m+\\u001b[39m \\u001b[39m'\\u001b[39m\\u001b[39maxis\\u001b[39m\\u001b[39m'\\u001b[39m)\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/utils.py:236\\u001b[0m, in \\u001b[0;36mget_axis_properties\\u001b[0;34m(axis)\\u001b[0m\\n\\u001b[1;32m    233\\u001b[0m     props[\\u001b[39m'\\u001b[39m\\u001b[39mfontsize\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m \\u001b[39mNone\\u001b[39;00m\\n\\u001b[1;32m    235\\u001b[0m \\u001b[39m# Get associated grid\\u001b[39;00m\\n\\u001b[0;32m--&gt; 236\\u001b[0m props[\\u001b[39m'\\u001b[39m\\u001b[39mgrid\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m get_grid_style(axis)\\n\\u001b[1;32m    238\\u001b[0m \\u001b[39m# get axis visibility\\u001b[39;00m\\n\\u001b[1;32m    239\\u001b[0m props[\\u001b[39m'\\u001b[39m\\u001b[39mvisible\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m axis\\u001b[39m.\\u001b[39mget_visible()\\n\\nFile \\u001b[0;32m~\/anaconda3\/envs\/cyberhawk_ai\/lib\/python3.10\/site-packages\/plotly\/matplotlylib\/mplexporter\/utils.py:246\\u001b[0m, in \\u001b[0;36mget_grid_style\\u001b[0;34m(axis)\\u001b[0m\\n\\u001b[1;32m    244\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mget_grid_style\\u001b[39m(axis):\\n\\u001b[1;32m    245\\u001b[0m     gridlines \\u001b[39m=\\u001b[39m axis\\u001b[39m.\\u001b[39mget_gridlines()\\n\\u001b[0;32m--&gt; 246\\u001b[0m     \\u001b[39mif\\u001b[39;00m axis\\u001b[39m.\\u001b[39;49m_gridOnMajor \\u001b[39mand\\u001b[39;00m \\u001b[39mlen\\u001b[39m(gridlines) \\u001b[39m&gt;\\u001b[39m \\u001b[39m0\\u001b[39m:\\n\\u001b[1;32m    247\\u001b[0m         color \\u001b[39m=\\u001b[39m export_color(gridlines[\\u001b[39m0\\u001b[39m]\\u001b[39m.\\u001b[39mget_color())\\n\\u001b[1;32m    248\\u001b[0m         alpha \\u001b[39m=\\u001b[39m gridlines[\\u001b[39m0\\u001b[39m]\\u001b[39m.\\u001b[39mget_alpha()\\n\\n\\u001b[0;31mAttributeError\\u001b[0m: 'XAxis' object has no attribute '_gridOnMajor'\"\n}\n<\/code><\/pre>\n<p>Any suggestions are welcomed,<br>\nThanks <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb truncates stdout in run logs?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-truncates-stdout-in-run-logs\/3661",
        "Question_created_time":"2023-01-09T20:10:45.945Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":86,
        "Question_body":"<p>I\u2019m running a personal wandb server using Docker.  I have a script that prints to stdout:<\/p>\n<pre><code class=\"lang-auto\">Loaded 5000 training images.\nLoaded 1000 test images.\n59.3% of training images contain cats.\n57.7% of test images contain cats.\n***********************************************\nepoch: 0\n<\/code><\/pre>\n<p>\u2026 and-so-on.  However, when I view the run logs in wandb, I get the following:<\/p>\n<pre><code class=\"lang-auto\">5000 training images.\n1000 test images.\nof training images contain cats.\nof test images contain cats.\n***********************************************\n0\n<\/code><\/pre>\n<p>At first, I thought the output was being \u201ccovered\u201d by the sidebar, but a quick inspection of the page source shows that this is really what\u2019s being captured.  Any thoughts?  Is wandb looking for some kind of formatted log output?<\/p>\n<p>Thanks in advance,<br>\nTim<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Line chart with config item on x-axis, multiple runs per line",
        "Question_link":"https:\/\/community.wandb.ai\/t\/line-chart-with-config-item-on-x-axis-multiple-runs-per-line\/3548",
        "Question_created_time":"2022-12-14T16:50:43.610Z",
        "Question_answer_count":11,
        "Question_score_count":0,
        "Question_view_count":304,
        "Question_body":"<p>I have several finetuning runs evaluating checkpoints of other pretraining runs. Pretraining run A creates checkpoints A-1 and A-2 in epochs 1 and 2. Now I have a finetuning run for each checkpoint of A. I would like to create a chart with on the X-axis the pretraining epoch (I can get this from a config file), not the finetuning epoch, and on the Y-axis a test metric I compute once at the end of every finetuning run. The above is easy to get with a scatter plot, but I would like to be able to group finetuning runs by the pretraining run (so A, that has a number of separate finetuning runs associated with it, not the pretraining checkpoint A-1 for which there is 1 finetuning run)(I have this info also in a config file), so that each line in the resulting line chart has points from different finetuning runs corresponding to different epochs of the same pretraining runs. Is that possible, to group runs in a line chart?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tensorboard not logged correctly on wandb run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorboard-not-logged-correctly-on-wandb-run\/3652",
        "Question_created_time":"2023-01-09T10:46:58.845Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":76,
        "Question_body":"<p>Hello,<br>\nI have been using wandb for a while now, but since last week  the training runs on W&amp;B  only show the validation losses and not the training losses. If I open tensorboard from the W&amp;B run page, I also can only see the validation stats, but if I open tensoboard from terminal independently from W&amp;B  the both training and validation stats are shown correctly.<br>\nI am not sure of what\u2019s going on, as I haven\u2019t changed my workflow at all, and since I don\u2019t get any error message I am not sure of how to debug the problem.<br>\nIf it helps, the folder structure of my project looks like this:<\/p>\n<pre><code class=\"lang-auto\">-main_folder\n    -training_notebook\n    -output     (folder)\n        -run_name_folder\n        -events.out.tfevents.1673259721.ip-.....   (tensorboard file for training)\n        -validation     (folder)\n            -events.out.tfevents.1673259726.ip-.... (tensorboard file for validation)\n<\/code><\/pre>\n<p>and I run the training with the following code:<\/p>\n<pre><code class=\"lang-auto\">with wandb.init(name=run_name,\n                project=project_name, \n                id=run_id,\n                job_type=\"training_job\",\n                sync_tensorboard=True) as run:\n<\/code><\/pre>\n<p>Any idea of why only the validation losses are logged on W&amp;B?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to get the sequential id for the experiment",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-get-the-sequential-id-for-the-experiment\/3619",
        "Question_created_time":"2022-12-29T20:08:11.999Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":315,
        "Question_body":"<p>Hi I am trying to name the experiment as per my project as well as a sequential id, for example my Project name is Semantic Segmentation and I have 3 runs, I want to name them something like SEM-1,SEM-2 and so on,<br>\nEssentially I need to log the new experiment by getting the previous experiment id and incrementing it by 1, if it is the first experiment then just start by first three letters of project and then append 1 and so on<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb sweeep training error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sweeep-training-error\/3636",
        "Question_created_time":"2023-01-04T05:02:23.979Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":130,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b2b7478189f41aaca4f1c7ba31c9ab544d26e8e9.png\" data-download-href=\"\/uploads\/short-url\/puZF9VtzGIPQ8W24OigDTk9RKiJ.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b2b7478189f41aaca4f1c7ba31c9ab544d26e8e9.png\" alt=\"image\" data-base62-sha1=\"puZF9VtzGIPQ8W24OigDTk9RKiJ\" width=\"690\" height=\"413\" data-dominant-color=\"262727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1010\u00d7605 29.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>this error happened while I was training and I know nothing about this. Help me on this :))<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb sweep & Hydra",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sweep-hydra\/3637",
        "Question_created_time":"2023-01-04T15:41:24.792Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":157,
        "Question_body":"<p>Hi All,<\/p>\n<p>How are you?<\/p>\n<p>My colleague Soumik Rakshit directed me to you for help. I\u2019m trying to launch a sweep with hydra in which I would like to control two parameters which are already included in the yml file.<\/p>\n<p>I tried to follow <a href=\"https:\/\/wandb.ai\/adrishd\/hydra-example\/reports\/Configuring-W-B-Projects-with-Hydra--VmlldzoxNTA2MzQw\">this tutorial<\/a> but without success. What I\u2019m trying to do is to be able to both pass arg parse arguments using \u201c\u2013\u201d in addition to config parameters editing.<\/p>\n<p>Can we schedule a quick session for support?<\/p>\n<p>Cheers,<\/p>\n<p>Aviv<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export grouped runs individually as CSV",
        "Question_link":"https:\/\/community.wandb.ai\/t\/export-grouped-runs-individually-as-csv\/3571",
        "Question_created_time":"2022-12-19T14:21:28.409Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":347,
        "Question_body":"<p>Hi,<\/p>\n<p>I am new to using wandb. I have a project that contain many groups, each group has multiple runs. I want to export the metrics of each single run in a group to a CSV file but it only allows me to export the statistics of  the group.<\/p>\n<p>How can export each run from a group to CSV?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Account Storage and Artifacts not being freed",
        "Question_link":"https:\/\/community.wandb.ai\/t\/account-storage-and-artifacts-not-being-freed\/3624",
        "Question_created_time":"2022-12-31T11:17:51.417Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":168,
        "Question_body":"<p>Hi!<\/p>\n<p>I have the same issue - <a href=\"https:\/\/community.wandb.ai\/t\/account-storage-not-being-freed\/1375\" class=\"inline-onebox\">Account storage not being freed?<\/a>.<\/p>\n<p>Is this bug still present?<\/p>\n<p>profile - <a href=\"https:\/\/wandb.ai\/ramang\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Failure to upload data after run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/failure-to-upload-data-after-run\/3612",
        "Question_created_time":"2022-12-28T11:16:48.345Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":273,
        "Question_body":"<p>Hi,<\/p>\n<p>I have several runs that upon termination are getting stuck on the following error (unable to copy as text due to the rotating \u201c|\u201d sign):<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae27b992b80ee351ee93649b5d64e097b02af05a.png\" data-download-href=\"\/uploads\/short-url\/oQEbMyZj2EOLrZlOJ30i5nPRdlE.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae27b992b80ee351ee93649b5d64e097b02af05a_2_690x53.png\" alt=\"image\" data-base62-sha1=\"oQEbMyZj2EOLrZlOJ30i5nPRdlE\" width=\"690\" height=\"53\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae27b992b80ee351ee93649b5d64e097b02af05a_2_690x53.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae27b992b80ee351ee93649b5d64e097b02af05a.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae27b992b80ee351ee93649b5d64e097b02af05a.png 2x\" data-dominant-color=\"1A2015\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">843\u00d765 14 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any ideas on how to fix without stopping my run?<\/p>\n<p>Edit: I checked the <code>debug-internal.log<\/code> and it seems the below error message pops up.<br>\nAdditional details -<br>\n(1) The server uploading the data is in a private network (.technion.ac.il)<br>\n(2) Unlike other runs that do succeed in the meantime, here I upload a video using:<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\"video\": wandb.Video(all_images, fps=4, format=\"mp4\")})\n<\/code><\/pre>\n<p>Error:<\/p>\n<p>2022-12-28 13:30:28,582 ERROR   Thread-17 :3928098 [internal_api.py:upload_file():1875] upload_file exception <a href=\"https:\/\/storage.googleapis.com\/wandb-production.appspot.com\/tomjur\/\" rel=\"noopener nofollow ugc\">https:\/\/storage.googleapis.com\/wandb-production.appspot.com\/tomjur\/<\/a>[my proj]\/[current run]\/wandb-metadata.json?Expires=1672313428&amp;GoogleAccessId=wandb-production%<a href=\"http:\/\/40appspot.gserviceaccount.com\" rel=\"noopener nofollow ugc\">40appspot.gserviceaccount.com<\/a>&amp;Signature=UKkwGiiPdbchVt3D9Np7HXU91ioIwnWZa5EqapeDR0UFZbjElm2TU5XOF93P2z7%2BnvCTcAEeSkV0tVg3ln0aMTUw%2BYTVSiyBBHncYCZkJcHWS2MDgcA5v9LzjnQ3c5kJoUA5dJwMWNVLebZ8LWkUDKdBSeafEfogP3xE%2FLIDdPtHolpISNJIvEY3JDPOrTJUh9Ge%2Bw3%2BgLgvep9LbG2qEtmj%2FIeeW%2FXqi9wIpfWdDjZ6ZlkGkohYjJPdSGA6GM9RLrglaDVnwmJQXTgyLEIpD9%2FsuKJeBN3U0v6qz1aE2OBoDCK%2Fs4lDEspXy%2FgOqVS6FEHrwQ813rkabFR6dvC1tA%3D%3D: HTTPSConnectionPool(host=\u2018<a href=\"http:\/\/storage.googleapis.com\" rel=\"noopener nofollow ugc\">storage.googleapis.com<\/a>\u2019, port=443): Max retries exceeded with url: \/wandb-production.appspot.com\/tomjur\/[my proj]\/[current run]\/wandb-metadata.json?Expires=1672313428&amp;GoogleAccessId=wandb-production%<a href=\"http:\/\/40appspot.gserviceaccount.com\" rel=\"noopener nofollow ugc\">40appspot.gserviceaccount.com<\/a>&amp;Signature=UKkwGiiPdbchVt3D9Np7HXU91ioIwnWZa5EqapeDR0UFZbjElm2TU5XOF93P2z7%2BnvCTcAEeSkV0tVg3ln0aMTUw%2BYTVSiyBBHncYCZkJcHWS2MDgcA5v9LzjnQ3c5kJoUA5dJwMWNVLebZ8LWkUDKdBSeafEfogP3xE%2FLIDdPtHolpISNJIvEY3JDPOrTJUh9Ge%2Bw3%2BgLgvep9LbG2qEtmj%2FIeeW%2FXqi9wIpfWdDjZ6ZlkGkohYjJPdSGA6GM9RLrglaDVnwmJQXTgyLEIpD9%2FsuKJeBN3U0v6qz1aE2OBoDCK%2Fs4lDEspXy%2FgOqVS6FEHrwQ813rkabFR6dvC1tA%3D%3D (Caused by SSLError(CertificateError(\u201chostname \u2018<a href=\"http:\/\/storage.googleapis.com\" rel=\"noopener nofollow ugc\">storage.googleapis.com<\/a>\u2019 doesn\u2019t match either of \u2018*.technion.ac.il\u2019, \u2018technion.ac.il\u2019\u201d)))<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Waiting for W&B process to finish... (success)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/waiting-for-w-b-process-to-finish-success\/3511",
        "Question_created_time":"2022-12-07T20:22:44.138Z",
        "Question_answer_count":12,
        "Question_score_count":1,
        "Question_view_count":1922,
        "Question_body":"<p>I am using wandb to log Tensorflow model training. Unfortunately the runs keep on running forever even though the training has finished minutes before.<\/p>\n<p>I am receiving a lot of the following debug messages in debug-internals.log:<\/p>\n<pre><code class=\"lang-auto\">2022-12-07 21:19:47,595 DEBUG   HandlerThread:796 [handler.py:handle_request():139] handle_request: keepalive\n```\n\ndebug.log  is already finished with the following last messages:\n```\n2022-12-07 21:09:05,301 INFO    MainThread:12168 [wandb_run.py:_config_callback():1163] config_cb ('_wandb', 'session_history') code\\_session_history.ipynb None\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [jupyter.py:_save_ipynb():389] looking for notebook: None\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [wandb_init.py:_jupyter_teardown():408] cleaning up jupyter logic\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [wandb_run.py:_atexit_cleanup():1955] got exitcode: 0\n2022-12-07 21:09:05,324 INFO    MainThread:12168 [wandb_run.py:_restore():1938] restore\n2022-12-07 21:09:05,325 INFO    MainThread:12168 [wandb_run.py:_restore():1944] restore done\n```\n\nI have already updated to wandb-013.6 but this did not solve the issues.<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Boxplots do not show values if there is only a single point",
        "Question_link":"https:\/\/community.wandb.ai\/t\/boxplots-do-not-show-values-if-there-is-only-a-single-point\/3528",
        "Question_created_time":"2022-12-10T21:34:45.943Z",
        "Question_answer_count":10,
        "Question_score_count":0,
        "Question_view_count":243,
        "Question_body":"<p>E.g.,<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png\" data-download-href=\"\/uploads\/short-url\/49H8dJRF7TWhHGd2OSIh5IiqgRb.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1_2_634x500.png\" alt=\"image\" data-base62-sha1=\"49H8dJRF7TWhHGd2OSIh5IiqgRb\" width=\"634\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/1\/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1_2_634x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/1\/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png 2x\" data-dominant-color=\"FBFAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">774\u00d7610 23 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I would use barplot but I bar plot stacks the data over instead of computing means and do not see any possibility to compute means using weave.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The debug-internal.log file is too large (>500MB)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/the-debug-internal-log-file-is-too-large-500mb\/3589",
        "Question_created_time":"2022-12-23T04:23:12.303Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":223,
        "Question_body":"<p>Because of network problem. The local <code>debug-internal.log<\/code> files of some runs are too large (more than 500MB). To save the disk space, is there any way to avoid the generation of these log files?<\/p>",
        "Question_closed_time":"2022-12-28T01:24:27.021Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> , thank you for writing in and happy to look into this for you.  <code>debug-internal.log<\/code> files are automatically generated and cannot be disabled by the user.  Please see this github issue thread that was raised about this issue were a user provided <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4223#issuecomment-1236304565\" rel=\"noopener nofollow ugc\">workaround<\/a> solution to address this . Do let me know if this reference helps.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Cannot login after passing a wrong secret key",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-login-after-passing-a-wrong-secret-key\/3546",
        "Question_created_time":"2022-12-14T15:22:27.089Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":226,
        "Question_body":"<p>After passing a wrong key value and initiating a run like below:<\/p>\n<blockquote>\n<p>wandb.login(key=&lt;wrong_key&gt; relogin=True)<br>\nrun = wandb.init(entity=&lt;entity_name&gt;, project=&lt;project_name&gt;)<\/p>\n<\/blockquote>\n<p>I can\u2019t use the same kernel session to initialize a new run even passing the right key value. I\u2019ve tried to remove all the wandb related lines of ~\/.netrc (as subprocess) and even remove and reinstall wandb in the same kernel.<\/p>\n<p>Has someone faced the same issue and might know how to fix it during without restarting the kernel?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: WARNING Invalid value for property root_dir",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-warning-invalid-value-for-property-root-dir\/3505",
        "Question_created_time":"2022-12-06T20:36:23.881Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":263,
        "Question_body":"<p>Hello,<\/p>\n<p>I defined wandb_log_dir to be another directory than where my code resides and received the following warning: \u201cwandb: WARNING Invalid value for property root_dir: \/home\/xx\/xxx\/experiments. This will raise an error in the future.\u201d<\/p>\n<p>Normally I am not particularly concerned about warnings. But because it said \u201cThis will raise an error in the future\u201d, I would like to know what is considered a valid value for property root_dir (and why)? If defining it the way I did, why will it raise an error done the road?<\/p>\n<p>Many thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is the wandb.ai server down?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-the-wandb-ai-server-down\/3611",
        "Question_created_time":"2022-12-28T05:54:47.228Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":229,
        "Question_body":"<p>Hi, it seems that the <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> server is currently down in my area.<\/p>\n<p>I live in Seoul, and can confirm access to <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> is down on my phone, computer, and server. All with different internet providers.<\/p>\n<p>I was wondering if this was a worldwide issue.<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: Network error (ProxyError), entering retry loop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-network-error-proxyerror-entering-retry-loop\/3567",
        "Question_created_time":"2022-12-19T03:36:10.418Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":462,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/c\/c33f553564ce1498375ecc989c07f1d676c8d9be.png\" data-download-href=\"\/uploads\/short-url\/rReNoE5gMy7hPVhQcXSs2fKrewu.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/c\/c33f553564ce1498375ecc989c07f1d676c8d9be_2_690x191.png\" alt=\"image\" data-base62-sha1=\"rReNoE5gMy7hPVhQcXSs2fKrewu\" width=\"690\" height=\"191\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/c\/c33f553564ce1498375ecc989c07f1d676c8d9be_2_690x191.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/c\/c33f553564ce1498375ecc989c07f1d676c8d9be_2_1035x286.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/c\/c33f553564ce1498375ecc989c07f1d676c8d9be_2_1380x382.png 2x\" data-dominant-color=\"152130\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1738\u00d7483 72.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>i run wandb in offline mode, and want to update to wandb server, it shows these error? i can ping to <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> but wandb sync is not ok, why?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Download logged table in run locally",
        "Question_link":"https:\/\/community.wandb.ai\/t\/download-logged-table-in-run-locally\/3507",
        "Question_created_time":"2022-12-07T03:42:36.861Z",
        "Question_answer_count":10,
        "Question_score_count":4,
        "Question_view_count":516,
        "Question_body":"<p>Hi all,<\/p>\n<p>I have been trying to download and open Wandb table locally. I have managed to get the corresponding table and its id, however, I cannot find way to download the table and open it as CSV for example.<\/p>\n<pre><code class=\"lang-auto\">runs[0].summary['avg_results'].keys()\ndict_keys(['_type', 'ncols', 'nrows', 'sha256', 'artifact_path', '_latest_artifact_path', 'path', 'size'])```\n\nAbove is a snippet of what I have managed to reach, how can I go from this point to get the table file and read it as cdv<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Trying to log wandb.Object3D object, getting exception \"unhashable type> 'Object3D'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/trying-to-log-wandb-object3d-object-getting-exception-unhashable-type-object3d\/3586",
        "Question_created_time":"2022-12-22T13:38:04.101Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":238,
        "Question_body":"<p>Hey guys and gals,<br>\nI am currently trying to log an Object3D object but it wont let me stating that the object is unhashable\u2026<\/p>\n<p>minimal example:<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport numpy as np\n\nobj = wandb.Object3D(np.array([[0,1,2,100,200,50],[1,2,0,50,0,100]]))\nwandb.log({\"3dtest\",obj})\n\n<\/code><\/pre>\n<p>results in:<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: unhashable type: 'Object3D'\n\n<\/code><\/pre>\n<p>Any advice would be nice (:<\/p>\n<p>Ps: format r,g,b,c leads to the same outcome<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Grouping runs decreases the granularity of the plots",
        "Question_link":"https:\/\/community.wandb.ai\/t\/grouping-runs-decreases-the-granularity-of-the-plots\/3532",
        "Question_created_time":"2022-12-11T22:03:21.528Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":146,
        "Question_body":"<p>See the attached image with grouped runs and range set to samples. The actual plots (faint lines) have a much higher granularity then the grouped plot. This decrease in granularity is particularly visible when x-axis is set to log-scale.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e.jpeg\" data-download-href=\"\/uploads\/short-url\/vxWxi1IA9sZR2hhpUslBXc37Mxo.jpeg?dl=1\" title=\"Screenshot 2022-12-11 at 5.03.49 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg\" alt=\"Screenshot 2022-12-11 at 5.03.49 PM\" data-base62-sha1=\"vxWxi1IA9sZR2hhpUslBXc37Mxo\" width=\"690\" height=\"235\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1035x352.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1380x470.jpeg 2x\" data-dominant-color=\"FAFAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-12-11 at 5.03.49 PM<\/span><span class=\"informations\">2801\u00d7957 152 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"K-fold cross validation in one run?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/k-fold-cross-validation-in-one-run\/3560",
        "Question_created_time":"2022-12-16T14:14:26.196Z",
        "Question_answer_count":7,
        "Question_score_count":5,
        "Question_view_count":339,
        "Question_body":"<p>Hello,<br>\nI have set a run with a model to execute k-fold  cross validation. When  the axis of the AUC or loss plot is steps , all the folds are shown but when I select the axis to be equal to epochs, then only one run is shown. Which is this run? The last one, the average of all the runs or the best one?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/5\/5f9d03b825103840e76e8a66e4499ab603ea22e9.png\" data-download-href=\"\/uploads\/short-url\/dDPLeeNKtZZqmBfzeeUj5hKYAMp.png?dl=1\" title=\"W&amp;amp;B Chart 12_16_2022, 3_12_11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_690x362.png\" alt=\"W&amp;B Chart 12_16_2022, 3_12_11 PM\" data-base62-sha1=\"dDPLeeNKtZZqmBfzeeUj5hKYAMp\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/5\/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_1380x724.png 2x\" data-dominant-color=\"FBFAFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 12_16_2022, 3_12_11 PM<\/span><span class=\"informations\">2780\u00d71460 356 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nThanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to manage columns in project run table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-manage-columns-in-project-run-table\/3551",
        "Question_created_time":"2022-12-14T19:24:08.938Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":430,
        "Question_body":"<p>Hello,<\/p>\n<p>I just started a new project and recorded my first runs. Unfortunately, I am unable to add the \u201caccuracy\u201d, \u201closs\u201d, \u201cval_accuracy\u201d and \u201cval_loss\u201d columns to the visible columns.  When I try to drag them to the visible columns they remain in the hidden columns.<\/p>\n<p>Thanks for your support.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"All my plots start at epoch 2",
        "Question_link":"https:\/\/community.wandb.ai\/t\/all-my-plots-start-at-epoch-2\/3593",
        "Question_created_time":"2022-12-23T21:50:17.765Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":336,
        "Question_body":"<p>See screenshots below. Each model has been trained for 3 epochs so far. They all started from 0, and the info panel shows that the most recent epoch was 2 and \u201cbest\u201d is 0. Looking at the plots though, it looks like all the plots cover epochs 2 through 4.<\/p>\n<p>I\u2019m calling keras <code>model.fit<\/code> with <code>from_epoch=0<\/code>. I\u2019m running inside a <code>ray<\/code> worker so maybe that\u2019s causing some problems?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png\" data-download-href=\"\/uploads\/short-url\/eJUS1BdlLEVdGhqEUtHrBXnO9Q2.png?dl=1\" title=\"Screenshot 2022-12-24 at 8.45.46 am\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png\" alt=\"Screenshot 2022-12-24 at 8.45.46 am\" data-base62-sha1=\"eJUS1BdlLEVdGhqEUtHrBXnO9Q2\" width=\"690\" height=\"288\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png 2x\" data-dominant-color=\"202121\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-12-24 at 8.45.46 am<\/span><span class=\"informations\">788\u00d7329 16.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b82b054b707b56a829f444969855ec256c85aee5.png\" alt=\"Screenshot 2022-12-24 at 8.44.29 am\" data-base62-sha1=\"qhe1BKuwPFD8WbPpt39n8Mz0TKR\" width=\"456\" height=\"269\"><\/p>",
        "Question_closed_time":"2022-12-27T11:41:57.164Z",
        "Answer_body":"<p>Hi Tom,<\/p>\n<p>Thanks for writing in! So the step is calculated every time there is a call to <code>wandb.log(<\/code>, you can see more details in our docs. If you click on the Edit panel button (a pencil) in the top right corner of the chart, you can select the epoch as X axis. I just checked in your project and it starts in 0. Please let me know if I can help you in any other way!<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Cache image in the wandb board?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cache-image-in-the-wandb-board\/3510",
        "Question_created_time":"2022-12-07T16:18:22.330Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":347,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m running a ML project where I need to log images every 10 epochs or so. Since I run for a large number of epochs, I often end up with a lot of images.<\/p>\n<p>I would like to get a sense of how the image quality improves overtime, however it is difficult to do so when the images have to load every time. Is there a way to cache the images in the board somehow?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while using W&B on Vertex AI GCP",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-while-using-w-b-on-vertex-ai-gcp\/3583",
        "Question_created_time":"2022-12-22T12:23:27.808Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":153,
        "Question_body":"<p>Hi,<br>\nRecently I switched from AWS to GCP, and when I try to run wandb.init() it keeps raising the following error<\/p>\n<pre><code class=\"lang-auto\">wandb: Network error (ConnectTimeout), entering retry loop.\nwandb: Network error (ConnectTimeout), entering retry loop.\nwandb: ERROR Error communicating with wandb process\nProblem at: \/tmp\/ipykernel_1\/1411081884.py 2 &lt;module&gt;\nUsageError: Error communicating with wandb process\n<\/code><\/pre>\n<p>It seems that the notebook has some restrictions on connecting with the web, is there anything I can do to overcome this error?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Team Permission Issues",
        "Question_link":"https:\/\/community.wandb.ai\/t\/team-permission-issues\/3579",
        "Question_created_time":"2022-12-21T19:12:13.537Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":134,
        "Question_body":"<p>I\u2019m having issues with a team I created. Despite me creating the team I somehow am not the admin. In fact, nobody is an admin. I have been trying to delete some sweeps that I set up incorrectly and it\u2019s not letting me do this. If I go to organization settings I am the admin. I\u2019m not sure how to fix this and would appreciate some help<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retrieve all the sweeps in a team project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/retrieve-all-the-sweeps-in-a-team-project\/3534",
        "Question_created_time":"2022-12-12T08:49:21.489Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":142,
        "Question_body":"<p>I was trying to retrieve all the sweeps in a project, I did the following:<\/p>\n<pre><code class=\"lang-auto\">sweeps = wandb.Api().project(&lt;project_name&gt;, entity=&lt;team_name&gt;).sweeps()\n<\/code><\/pre>\n<p>However, I got the error that Project object has no attribute sweeps.<\/p>\n<p>Can you please help with it?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Disable : \"Showing a bar chart instead of a line chart because all logged values are length one.\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/disable-showing-a-bar-chart-instead-of-a-line-chart-because-all-logged-values-are-length-one\/3562",
        "Question_created_time":"2022-12-16T17:52:21.382Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":172,
        "Question_body":"<p>Hello,<\/p>\n<p>Is there a way to disable bar chart conversion of line charts that only have a single x value?<br>\nI have a chart that changed to a bar chart but no option to change it back to a line chart<br>\n<em>Showing a bar chart instead of a line chart because all logged values are length one.<\/em><\/p>\n<p>The issue is that the bar chart does not show a relation between the different runs.<br>\nMy variable logs the final accuracy but because it is bar chart that is simply ordered by experiment execution order it is very hard to assess the ranking of all runs.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/fe84452d092f2dc117b94f1a3a8bc9d34e01c9f9.png\" data-download-href=\"\/uploads\/short-url\/AjyFeL7Tw01SYLTbfpy80ZtLF2x.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/fe84452d092f2dc117b94f1a3a8bc9d34e01c9f9.png\" alt=\"image\" data-base62-sha1=\"AjyFeL7Tw01SYLTbfpy80ZtLF2x\" width=\"690\" height=\"294\" data-dominant-color=\"DACFD5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">700\u00d7299 2.39 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nI would rather see the a line chart with a single x step<\/p>\n<p>Kind regards,<br>\nMaxim<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature Request: Nested Tags",
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-nested-tags\/3574",
        "Question_created_time":"2022-12-19T16:37:37.068Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":262,
        "Question_body":"<p>Tags are a very powerful feature for organising experiment runs - it would be nice to have the ability to use nested tags as well, for instance:<\/p>\n<pre><code class=\"lang-auto\">#tag1\n#tag1\/feature1\n#tag1\/feature2\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding Image() to a Report programatically",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-image-to-a-report-programatically\/3266",
        "Question_created_time":"2022-10-17T06:03:20.457Z",
        "Question_answer_count":14,
        "Question_score_count":0,
        "Question_view_count":356,
        "Question_body":"<p>Hello,<br>\nI am experimenting with programmatic report generation using Python.<br>\nI understand that reports are a beta feature.<br>\nI would like to add an Image object to a report.  The image was generated in MatPlotLib and rendered using PIL.  I\u2019ve read the documentation but there is little if any mention of how to handle <code>Image<\/code> objects, other than a brief mention that they are supported.<\/p>\n<p>I am getting the following error:<\/p>\n<pre><code class=\"lang-auto\">TypeError: url object must be of type (&lt;class 'str'&gt;,) (got &lt;class 'PIL.PngImagePlugin.PngImageFile'&gt;)\n<\/code><\/pre>\n<p>The generating code for the report looks like:<\/p>\n<pre><code class=\"lang-auto\">blocks  = []\nblocks += [wr.MarkdownBlock(text=\"Markdown cell with *italics* and **bold** and $e=mc^2$\")]\nfor result in results:\n    if result:\n        blocks += wr.PanelGrid(panels=[wr.Image(result['image'], caption=f\"Subject={result['subject']}\")])\nreport.blocks = blocks\nreport.save()<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to customize Advanced Legend to display a string",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-customize-advanced-legend-to-display-a-string\/3498",
        "Question_created_time":"2022-12-05T05:35:29.261Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":340,
        "Question_body":"<p>Hello W&amp;B community!<br>\nFor a custom project within our company, we attempt to compare various models across a list of category.<br>\nWe therefore want to visualize, for each version of our model:<\/p>\n<ul>\n<li>for each category (a string)<\/li>\n<li>a score (float in 0,1).<\/li>\n<\/ul>\n<p>Here is how we log scores in W&amp;B (simplified for easy understanding):<\/p>\n<pre><code class=\"lang-auto\">    scores = [0.3, 0.5, 0.6, ...]\n    categories = ['dog', 'cat', 'fish', ...]\n    for k, (val, name) in enumerate(zip(scores, categories)):\n        wandb.log({\n                    f\"score\": val,\n                    f\"category\": name,\n                    f\"id\": k\n                })\n<\/code><\/pre>\n<p>Here is the graph associated with this code:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d.jpeg\" data-download-href=\"\/uploads\/short-url\/xDQmaIYqXkpCtcwGLMp3ch9QtmR.jpeg?dl=1\" title=\"Screenshot from 2022-12-05 14-29-41\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg\" alt=\"Screenshot from 2022-12-05 14-29-41\" data-base62-sha1=\"xDQmaIYqXkpCtcwGLMp3ch9QtmR\" width=\"690\" height=\"373\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1035x559.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1380x746.jpeg 2x\" data-dominant-color=\"F6F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-12-05 14-29-41<\/span><span class=\"informations\">1389\u00d7751 103 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Now as you can see in the picture: For each version (td_ver), we display the \u201cscore\u201d (y) for each \u201cid\u201d (x). When we hover over the score itself, we do not want to show the \u201cid\u201d, but the \u201cname\u201d<br>\n(In the image, instead of displaying \u201c25\u201d highlighted in red, we want to display \u201cfish\u201d.<\/p>\n<p>I assume this change needs to happen in the \u201cAdvanced Legend\u201d section, but I could not find the correct spelling for that formula.<\/p>\n<pre><code class=\"lang-auto\">original:\n [[ ${x}: ${y} (${original})]] ${run:displayName}\n\nnew:\n???\n<\/code><\/pre>\n<p>Thanks a lot for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run Time is inaccurate because of including upload time",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-time-is-inaccurate-because-of-including-upload-time\/3499",
        "Question_created_time":"2022-12-05T14:04:58.960Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":153,
        "Question_body":"<p>Some runs will spend minutes because of my terrible network:<\/p>\n<pre><code class=\"lang-shell\">wandb: Waiting for W&amp;B process to finish... (success).\n<\/code><\/pre>\n<p>I find the Run Time column in UI will also contain the uploading time (by comparing with other runs\u2019 Run Time).<\/p>\n<p>My script is organized as follow:<\/p>\n<pre><code class=\"lang-python\">def main(config):\n    ...\n    wandb.init(wandb_config)\n    ...\n\nif __name__ == '__main__':\n    config = blabla\n    for p in [p1, p2, p3]:  # for loop to tune hyperparameters\n        config.param = p\n        main(config)\n<\/code><\/pre>\n<p>To fix this issue, should I use <code>wandb.finish<\/code> in the end of the <code>main()<\/code> function? As the <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/finish\">doc<\/a> of <code>wandb.finish<\/code> lists:<\/p>\n<blockquote>\n<p>Marks a run as finished, and finishes uploading all data.<\/p>\n<\/blockquote>\n<p>I worry about whether this func will kill my slow data uploading worker.<\/p>\n<p>Or any other solutions?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Every wandb command yields \"An error occured in MPI_Init_thread\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/every-wandb-command-yields-an-error-occured-in-mpi-init-thread\/3422",
        "Question_created_time":"2022-11-15T23:40:42.183Z",
        "Question_answer_count":10,
        "Question_score_count":1,
        "Question_view_count":565,
        "Question_body":"<p>I have a user on a multi-user server whose wandb installation appears to be broken. I have forced him to reinstall with<\/p>\n<pre><code class=\"lang-auto\">python3 -m pip install --upgrade pip\npython3 -m pip install --upgrade --force-reinstall wandb\n<\/code><\/pre>\n<p>after which he has wandb-0.13.5.<\/p>\n<p>But this error persists; even the simplest <code>wandb<\/code> command yields an <code>MPI_Init_thread<\/code> error:<\/p>\n<pre><code class=\"lang-auto\">$ wandb --version\n*** An error occurred in MPI_Init_thread\n*** on a NULL communicator\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\n***    and potentially your MPI job)\n[xhostnamex:1359609] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\n<\/code><\/pre>\n<p>On the same machine, my <code>wandb<\/code> installation works fine:<\/p>\n<pre><code class=\"lang-auto\">$ wandb --version\nwandb, version 0.13.5\n<\/code><\/pre>\n<p>Apologies if this is a duplicate, but I could not find this exact problem documented anywhere.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to make the Model Registry public?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-make-the-model-registry-public\/3489",
        "Question_created_time":"2022-12-02T15:08:26.271Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":643,
        "Question_body":"<p>I am currently trying to figure out how the Model Registry can be accessed by people not logged into WandB \/ not member of our developement team. Background is, that we link models that performed well in our private projects, to the Model Registry for reproducability, s.t. other researchers can access these models.<\/p>\n<p>Right now I managed to make the model-registry project public which enabled not logged in users to see the models in the model registry. However, I am still unable to download the visible modle version artifacts as the download buttons are not visible on the web UI.<\/p>\n<p>I am not sure if this is a bug or intendet behaviour as the entire experience of accessing a public model registry as a not logged in user is somehow very buggy with versions appearing and disappearing at random.<\/p>\n<p>Does anyone have any insights on this?<\/p>\n<p>Regards,<br>\nSnagnar<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to jump the W&B upload process when the network is not so good?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-jump-the-w-b-upload-process-when-the-network-is-not-so-good\/3487",
        "Question_created_time":"2022-12-02T11:57:42.570Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":400,
        "Question_body":"<p>My training process unsuccessfully ended, because of the failure of the uploading process for W&amp;B.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/dbd70f7322f4960651abd3f6fae4f09d756e5380.png\" data-download-href=\"\/uploads\/short-url\/vmNkve8jMTMA4YvuwSOc4NGUodW.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_690x160.png\" alt=\"image\" data-base62-sha1=\"vmNkve8jMTMA4YvuwSOc4NGUodW\" width=\"690\" height=\"160\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_690x160.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_1035x240.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_1380x320.png 2x\" data-dominant-color=\"F2EEDD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1742\u00d7404 78.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nI often use a script file to run multiple experiments at once. When one of it is tucked, others cannot be run.<br>\nHow to jump this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Artefact upload very slow",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artefact-upload-very-slow\/3488",
        "Question_created_time":"2022-12-02T14:44:28.287Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":880,
        "Question_body":"<p>I\u2019m encountering a similar issue to the one reported here: <a href=\"https:\/\/community.wandb.ai\/t\/programmatically-accessing-artifact-object-very-slow-for-first-call-for-large-artifacts\/1158\" class=\"inline-onebox\">Programmatically accessing artifact object very slow for first call for large artifacts<\/a><\/p>\n<p>I\u2019ve found artefacts to be an excellent way for storing the full outputs of my models for later debugging. However , as I\u2019m training information retrieval models my artefacts are rather large (~300MB). I\u2019m only storing titles of my documents but even with that each evaluation example has around 300 titles as an output.<\/p>\n<p>At the end of each WANDB run it takes a couple of hours for the run to sync. I\u2019m running the experiments on GCP VMs so internet speed should not be an issue.<\/p>\n<p>Do you have any ideas on how I could speed up the sync time?<\/p>\n<p>As I\u2019m running multiple experiments sequentially, atm the experiments are blocked by WANDB upload time. I\u2019m thinking as a quick workaround to disable automatic syncing from my scripts and run a <code>wandb sync; sleep<\/code> loop on a parallel process in the same directory. Does that sound like a reasonable way to go forward?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to check if a secret key corresponds to an entity?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-check-if-a-secret-key-corresponds-to-an-entity\/3541",
        "Question_created_time":"2022-12-13T20:28:48.878Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":132,
        "Question_body":"<p>I am trying to create a wandb run.<\/p>\n<pre><code class=\"lang-auto\">wandb.login(key=wandb_secret_key, relogin=True)\ntry:\n    run = wandb.init(\n        entity=wandb_entity_name,\n        project=wandb_project,\n        name=wandb_run_name,\n        notes=wandb_experiment_description,\n        config=wandb_configs,\n    )\nexcept Exception:\n    raise InvalidWanbInfoConfigurationsExeption(f\"wandb_secret_key({wandb_secret_key}) is not associated with wandb_entity_name ({wandb_entity_name})\")\n\n<\/code><\/pre>\n<p>I can exception handle like I did, but the subsequent runs are crashing even if wandb_secret_key and wandb_entity_name correspond.<\/p>\n<pre><code class=\"lang-auto\">---------------------------------------------------------------------------\nBrokenPipeError                           Traceback (most recent call last)\n~\/.virtualenvs\/tfpipeline\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1077         try:\n-&gt; 1078             run = wi.init()\n   1079             except_exit = wi.settings._except_exit\n\n~\/.virtualenvs\/tfpipeline\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py in init(self)\n    573             logger.info(\"setting up manager\")\n--&gt; 574             manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n    575 \n\n~\/.virtualenvs\/tfpipeline\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_manager.py in _inform_init(self, settings, run_id)\n    169         svc_iface = self._get_service_interface()\n--&gt; 170         svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n    171 \n\n~\/.virtualenvs\/tfpipeline\/lib\/python3.8\/site-packages\/wandb\/sdk\/service\/service_sock.py in _svc_inform_init(self, settings, run_id)\n     37         assert self._sock_client\n---&gt; 38         self._sock_client.send(inform_init=inform_init)\n     39 \n\n~\/.virtualenvs\/tfpipeline\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py in send(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\n    210             raise Exception(\"unmatched\")\n--&gt; 211         self.send_server_request(server_req)\n...\n   1115                 os._exit(-1)\n-&gt; 1116             raise Exception(\"problem\") from error_seen\n   1117     return run\n<\/code><\/pre>\n<p>Is there a wat to check if they correspond without creating the run?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot access run data via run.history()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-access-run-data-via-run-history\/3530",
        "Question_created_time":"2022-12-11T19:02:41.235Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":131,
        "Question_body":"<p>Hi,<\/p>\n<p>I am having trouble accessing run data keys in several of my runs. Specifically, I have logged a metric in my code, the metric is tracked in the online wandb UI, but when I try accessing the data using the following code<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nrun = api.run(\"xxxxxx\")\nrun.history()[['_step', 'metric_name']]\n<\/code><\/pre>\n<p>It throws a <code>KeyError: \"['metric_name'] not in index\"<\/code>.<\/p>\n<p>When I print out <code>run.history()<\/code> in table format, it does show \u2018metric_name\u2019 as one of the columns; \u2018metric_name\u2019 also appears as a key in <code>run.summary<\/code>. I wonder what is the issue here?<\/p>\n<p>Would appreciate any help. Thank you!<\/p>",
        "Question_closed_time":"2022-12-13T14:56:59.675Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/toruowo\">@toruowo<\/a> thank you for writing in! Can you please change your last line to:<\/p>\n<pre><code class=\"lang-auto\">run.history(keys=['_step', 'metric_name'])\n<\/code><\/pre>\n<p>Would this work for you?  Please let me know if you have any further issues or questions. You may also find some more <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#public-api-examples\">API examples here<\/a> if that helps.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb Resume Logging",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-resume-logging\/3543",
        "Question_created_time":"2022-12-14T01:34:28.598Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":608,
        "Question_body":"<p>Hello,<\/p>\n<p>I was trying to resume my run after a crash, but got confused about some points.<br>\nThe questions would mainly be about the <strong>resume<\/strong> and <strong>id<\/strong> argument in wandb.init().<\/p>\n<p>I have read the <strong>Resume Runs<\/strong> docs and followed thing mentioned in it.<br>\nPrecisely I have initialized my run as follows.<\/p>\n<pre><code class=\"lang-auto\">my_project_name = \"tmp\"\nmy_id = \"1r0f3yu4\"\nwandb.init(project=my_project_name, id=my_id, resume=\"must\") \n<\/code><\/pre>\n<p>where I have found <strong>my_id<\/strong> in  <strong>wandb\/run-20221214_011018-1r0f3yu4<\/strong> which is a directory that was automatically generated from the crashed run. I have also double checked that <strong>my_project_name<\/strong> is also same as the crashed run.<\/p>\n<p>However,<br>\nProblem 1) I <strong>can<\/strong> see that the <strong>State<\/strong> in my Weight and Biases Workspace has change to \u201crunning\u201d again, but cannot see any plots or logging information updated in the dashboard (which worked fine for the crashed run).<\/p>\n<p>Problem 2) Instead of re-using the previous directory <strong>wandb\/run-20221214_011018-1r0f3yu4<\/strong>, it generates a new directory <strong>wandb\/run-anotherYYYYMMDD_anotherHHMMSS-1r0f3yu4<\/strong>. Is this the proper way it should work, or am I doing something wrong?<br>\n(Is it because of <strong><a href=\"https:\/\/github.com\/wandb\/wandb\/blob\/main\/wandb\/sdk\/wandb_init.py\/\" rel=\"noopener nofollow ugc\">https:\/\/github.com\/wandb\/wandb\/blob\/main\/wandb\/sdk\/wandb_init.py\/<\/a><\/strong> line299?)<\/p>\n<p>Finally, my questions would be<br>\nQuestion 1) How should I resume my run? I want to continue logging my training stats on the same dashboard. (I am already saving my checkpoint for training with torch.load\/torch.save function. Thus, I just wand to know how to resume my \u201clogging\u201d in my Weight and Biases workspace  online.)<\/p>\n<p>Question 2) Is Problem2 the proper way it should work? or am I doing something wrong?<\/p>\n<p>I\u2019m not a very good English speaker, please let me know if anything sounds unclear.<\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging volumetric data?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-volumetric-data\/3476",
        "Question_created_time":"2022-11-28T15:15:25.050Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":208,
        "Question_body":"<p>Hi,<\/p>\n<p>I was wondering if there was any tools that could be of use to log volumetric data? My data are essentially 3-d tensor where each values represent the density of a volume. Currently I use some third party tools to visualize them, but it would be nice to have everything in the wandb UI.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hp-sweep with function with arguments",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hp-sweep-with-function-with-arguments\/3539",
        "Question_created_time":"2022-12-13T12:26:40.394Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":423,
        "Question_body":"<p>Hi<\/p>\n<p>Im wondering if its possible to have hp-sweep and instantiating wandb agent (using wandb.agent api) , such that the function will have arguments, in all of the example I\u2019ve seen that the passed functions to wandb.agent has no args at all.<\/p>\n<p>My training script looks as follows<\/p>\n<pre><code class=\"lang-auto\">\ndef trainer(input1, input2, input3):\n  # construct cfg file given the inputs\n  # passing the cfg file to wandb.init() \n  # receiving the returned config from wandb.config (with the decided params by the wandb Params controler)\n  # Continue training as usual, given the latest cfg.\n<\/code><\/pre>\n<p>I will be happy to get some inspiration about other ways to implement this<br>\nHope this is helpful<\/p>\n<p>Dor<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Calling run.history(samples=n_samples) returns a sample size different from n_samples",
        "Question_link":"https:\/\/community.wandb.ai\/t\/calling-run-history-samples-n-samples-returns-a-sample-size-different-from-n-samples\/3414",
        "Question_created_time":"2022-11-14T14:27:22.567Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":207,
        "Question_body":"<p>Hi everyone!<\/p>\n<p>I am experiencing weird behaviour of the run.history() function in Python:<\/p>\n<p>Calling <code>run.history(samples = 100)<\/code> gives me sample sizes different to 100 and the sample size varies for each call. E.g. executing it 5 times gave me sample sizes 98, 90, 88, 110, 104.<br>\nHowever, when I execute <code>run.history(keys=['my_key'], samples=100)<\/code>, I get a sample size of exactly 100 for every call. Why is this the case?<\/p>\n<p>After investigating this further, I found more strange behaviour: Calling <code>run.history(keys=['my_key'], samples=n_samples)<\/code> yields a sample size of exactly n_samples, as long as n_samples &lt;= 12493 (at least for my test run). If n_samples &gt; 12493, smaller sample sizes (varying roughly  between 12400 and 12490) are returned.<\/p>\n<p>Am I understanding something wrong or are these functions behaving in a way that they shouldn\u2019t?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"CPU Temperature Metrics",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cpu-temperature-metrics\/3538",
        "Question_created_time":"2022-12-12T16:49:01.942Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":244,
        "Question_body":"<p>Is there a way to measure CPU temperature? I am able to see GPU temps but it would be nice if there is a way to see CPU temps as well.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rate Limit Exceeded wandb increase rate limit",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rate-limit-exceeded-wandb-increase-rate-limit\/3522",
        "Question_created_time":"2022-12-10T05:27:46.619Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":194,
        "Question_body":"<p>Hi all, I get the following error in my logs:<\/p>\n<pre><code class=\"lang-auto\">^[[34m^[[1mwandb^[[0m: Network error (HTTPError), entering retry loop.^M                                                                                                                               \n306 ^[[34m^[[1mwandb^[[0m: 429 encountered (Filestream rate limit exceeded, retrying in 36.30758655296977 seconds), retrying request^M    \n<\/code><\/pre>\n<p>It appears i am sending too many requests. would it be possible to increase my rate limit?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Revert wandb server upgrade?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/revert-wandb-server-upgrade\/3518",
        "Question_created_time":"2022-12-09T17:38:12.654Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":253,
        "Question_body":"<p>Hi,<\/p>\n<p>When I start the wandb server locally, I got a notification to upgrade, so I upgraded the version. But now I couldn\u2019t access my runs and I run into this error whenever I run a training script:<\/p>\n<p><code>wandb: Network error (TransientError), entering retry loop.<\/code><\/p>\n<p>It also does not seem to log images anymore.<\/p>\n<p>I removed wandb from pip and reinstalled it at the version that still worked but the error still persists.<\/p>\n<p>Any ideas?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permanently delete Artifact Versions",
        "Question_link":"https:\/\/community.wandb.ai\/t\/permanently-delete-artifact-versions\/3065",
        "Question_created_time":"2022-09-05T08:28:26.516Z",
        "Question_answer_count":7,
        "Question_score_count":2,
        "Question_view_count":467,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to delete Artifact Versions using the API, for instance with something like this:<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api(overrides={\"entity\": entity, \"project\": project})\nartifact = api.artifact(name, type)\nartifact.delete()\n<\/code><\/pre>\n<p>The artifact is indeed deleted from the web UI, but then when I call <code>api.artifact_versions(type, name)<\/code> it is still present in the iterator.<\/p>\n<p>So, in order to get the list of all available artifacts, what I\u2019m currently doing is call the <code>api.artifact_versions()<\/code> method and then check if a specific version really exists by usiing <code>api.artifact<\/code> inside a try\/except clause (if the artifact was deleted, it will raise a <code>wandb.CommError<\/code> exception), but of course this solution is more expensive.<\/p>\n<p>My question is: is there a way to permanently delete artifact versions so that they are not shown in <code>api.artifact_versions()<\/code> anymore? This would also help keep the version number from growing too high<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Images logged using W&B logger bloats up \/tmp",
        "Question_link":"https:\/\/community.wandb.ai\/t\/images-logged-using-w-b-logger-bloats-up-tmp\/3450",
        "Question_created_time":"2022-11-23T02:06:16.532Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":625,
        "Question_body":"<p>In my code, I have the following  statement called at the end of every epoch as part of validation<\/p>\n<pre><code class=\"lang-auto\">wandb_logger.experiment.log({'test': wandb.Image(img)}, commit=commit)\n<\/code><\/pre>\n<p>where <code>img<\/code> is an image of type numpy array.<\/p>\n<p>I have noticed that  W&amp;B logger writes the image to a directory inside <code>\/tmp<\/code>,  and this directory is only cleared at the  end of the run.<\/p>\n<p>I have limited space in <code>\/tmp<\/code> and this leads to my training run crashing. I have tried saving the image to disk and then calling W&amp;B log on the path, this skips saving to <code>\/tmp<\/code> but doesn\u2019t really work well with distributed training (deadlock issues).<\/p>\n<p>Expected behavior:<br>\nThe user should be able to configure the temporary directory where intermediary media is stored.<\/p>\n<p>Kindly let me know if there\u2019s any other workaround.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"KeyError: 'fasterrcnn_resnet50'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/keyerror-fasterrcnn-resnet50\/3474",
        "Question_created_time":"2022-11-28T11:44:37.740Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":564,
        "Question_body":"<p>I am trying to run this GitHub repository <a href=\"https:\/\/github.com\/sovit-123\/fasterrcnn-pytorch-training-pipeline#Train-on-Custom-Dataset\" rel=\"noopener nofollow ugc\">faster rcnn-pytorch-custom-dataset<\/a> but I got this error.<\/p>\n<pre><code class=\"lang-auto\">Building model from scratch...\nTraceback (most recent call last):\n  File \"train.py\", line 491, in &lt;module&gt;\n    main(args)\n  File \"train.py\", line 248, in main\n    build_model = create_model[args['model']]\nKeyError: 'fasterrcnn_resnet50'\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced smoke_training: https:\/\/wandb.ai\/samahwa\/fastercnn-pytorch-training-pipeline\/runs\/ejy5jyw8\nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\/wandb\/run-20221128_113545-ejy5jyw8\/logs\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resuming sweep runs on a cluster with job time limits",
        "Question_link":"https:\/\/community.wandb.ai\/t\/resuming-sweep-runs-on-a-cluster-with-job-time-limits\/3333",
        "Question_created_time":"2022-10-27T18:44:38.337Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":476,
        "Question_body":"<p>Many users (including myself) on our compute cluster use wandb Sweeps, but a current pain point is our cluster admins limit each job length to 6 hours. For some applications this is not enough time to train Sweep trial configs to convergence, so they get cut off. I see in the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming\">docs<\/a> we have \u201cresuming a run which was executed as part of a Sweep is not supported.\u201d <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>However the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#preemptible-sweeps\">pre-emptible sweeps<\/a> section also mentions it can be possible to mark runs as being pre-empted, and \u201cresume logging at the step where it was interrupted\u201d. Sounds great, but there are a couple concerns:<\/p>\n<ol>\n<li>How can I ensure this resuming will actually resume properly, i.e. pick up model weights where they left off and so on? If I save model weights, optimizer state, etc with <code>wandb.save()<\/code>, will they be automatically pulled in when doing <code>wandb.init(resume=True)<\/code>? Or do I need to explicitly use <code>wandb.restore()<\/code>?<\/li>\n<li>More importantly, I\u2019m not sure how to actually implement this for our system. The current workflow is to generate the sweep config and sweep id, then submit a bunch of jobs (one job per trial) to the cluster with the appropriate sweep id. Each of these uses <code>wandb.agent<\/code> followed by <code>wandb.init<\/code> to get a sweep trial config and run it. However then presumably I\u2019d also have to launch some jobs with <code>wandb.init(resume=True)<\/code> to pick up the runs that don\u2019t finish in time (the number of which I won\u2019t know a priori), and these will clog up the queue. I guess this would all have to be manual \u2013 I\u2019d go and find all the runs which didn\u2019t finish and launch a corresponding number of jobs to complete them?<\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Warning: \"Failed to detect the name of this notebook\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/warning-failed-to-detect-the-name-of-this-notebook\/3491",
        "Question_created_time":"2022-12-03T09:45:31.457Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":785,
        "Question_body":"<p>I\u2019m not sure why this started happening, but WB is now giving us this error message:<\/p>\n<p><code>Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.<\/code><\/p>\n<p>We do not use notebooks and so there is no reason for us to set the above mentioned environment variable.  How can we make this stop?  And why is WB pushing us to set an optional parameter?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature request: adding tags to a report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-adding-tags-to-a-report\/3496",
        "Question_created_time":"2022-12-04T21:16:40.450Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":166,
        "Question_body":"<p>We\u2019ve generated a number of iterations of a report programmatically and it would be nice to be able to Tag the reports to indicate which is the best version.  We made use of the little heart icon to upvote a report, but it would also be nice to apply (and remove) a tag as new better versions of the report becomes available.  Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get stuck at uploading at the end",
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-stuck-at-uploading-at-the-end\/3453",
        "Question_created_time":"2022-11-24T01:37:20.661Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":822,
        "Question_body":"<p>My program finished before a few hours, but wandb get stuck at uploading files until now. I asked my friend and he said he had the same problem. So there are any problem for wandb server in the past  few hours and how to fix it?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf.jpeg\" data-download-href=\"\/uploads\/short-url\/kwlk7giIWlj5N5PsCmnxPYQd8d1.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg\" alt=\"image\" data-base62-sha1=\"kwlk7giIWlj5N5PsCmnxPYQd8d1\" width=\"690\" height=\"83\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1035x124.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1380x166.jpeg 2x\" data-dominant-color=\"181717\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2122\u00d7256 120 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Upload and Syncing of Artifacts are too slow using WSL - MainThread and HandlerThread hanging",
        "Question_link":"https:\/\/community.wandb.ai\/t\/upload-and-syncing-of-artifacts-are-too-slow-using-wsl-mainthread-and-handlerthread-hanging\/3068",
        "Question_created_time":"2022-09-05T12:33:19.984Z",
        "Question_answer_count":10,
        "Question_score_count":0,
        "Question_view_count":581,
        "Question_body":"<p>Hello everyone, hope you can help me with this issue.<\/p>\n<p>I am very new to the W&amp;B interface and python library. I am tryingo to incorporate the dataset versioning and experiment tracking issues into my training procedure for now.<\/p>\n<p>In the dataset versioning section of my code, I am logging the raw dataset and the cleaned ones via wandb.Artifact \u2192 wandb.add_file \u2192 wandb.log_artifact workflow, as show in documentation.<\/p>\n<p>The problem is that a simple <strong>upload and syncing takes around 10 minutes to finish!<\/strong> The datasets sizes are small (approx. 2MB) and I don\u2019t have any connection constraints or issues that I\u2019m aware of.<br>\nI\u2019m using a JupyterNotebook in a WSL2 environment (distro Ubuntu 20.04)<\/p>\n<p>The output of code shows: <code>Wating for W&amp;B process to finish (sucess) ...<\/code> for the whole time, and the upload and syncing bar stucks during the whole time of waiting.<\/p>\n<p>The debug log for the <code>latest-run<\/code> show this over and over:<\/p>\n<pre><code class=\"lang-auto\">2022-09-05 01:29:54.344 INFO    MainThread:10293 [jupyter.py:save_history():447] not saving jupyter history\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [jupyter.py:save_ipynb():377] not saving jupyter notebook\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_init.py:_jupyter_teardown():393] cleaning up jupyter logic\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_run.py:_atexit_cleanup():1931] got exitcode: 0\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_run.py:_restore():1914] restore\n2022-09-05 01:29:54.345 INFO    MainThread:10293 [wandb_run.py:_restore():1920] restore done\n...\n2022-09-05 01:29:57.481 INFO    MainThread:10293 [wandb_run.py:_on_finish():2221] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 397\n  total_bytes: 4431\n}\n<\/code><\/pre>\n<p>And the <code>debug-intenal<\/code> log shows the following:<\/p>\n<pre><code class=\"lang-auto\">2022-09-05 01:29:57.789 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:29:57.892 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:29:57.892 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:29:57.993 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:29:57.994 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n<\/code><\/pre>\n<p>And in the end of the running cell, the <code>debug-internal<\/code> log shows (sensible info omitted):<\/p>\n<pre><code class=\"lang-auto\">2022-09-05 01:33:09,176 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:33:09,176 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:33:10,268 INFO    WriterThread:10324 [datastore.py:close():279] close [...]\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [sender.py:finish():1312] shutting down sender\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [file_pusher.py:finish():171] shutting down file pusher\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [file_pusher.py:join():176] waiting for file pusher\n<\/code><\/pre>\n<p>I tried setting <code>WANDB_START_METHOD=thread<\/code> as mentioned in a Github issue, but didn\u2019t reduce overall time that the cell takes to finish. I have made the login through CLI and the cell recognizes my user.<\/p>\n<p>The raw data are in JSON format, and the cleaned data is a Pandas dataframe where of 30-60 rows, where each row contains an array of data (temporal analysis) around 2000 items.<\/p>\n<p><strong>Is there something I forgot  to setup? Is this the average time taken to upload files, even when they are small? I am missing something in the code workflow?<\/strong><\/p>\n<p>Any help would be much appreciated!<\/p>\n<p>Regards<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Settings defined in wandb.config dictionary not shown at the Overview page",
        "Question_link":"https:\/\/community.wandb.ai\/t\/settings-defined-in-wandb-config-dictionary-not-shown-at-the-overview-page\/3452",
        "Question_created_time":"2022-11-23T16:21:59.458Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":559,
        "Question_body":"<p>Why settings specified in the wandb config dictionary (see the code below), are not shown in my W.&amp;B\u2019s Overview page?<br>\nWhen the init_wandb() method is called, all the parameter values are already known. I can see the logged information and charts in my W&amp;B\u2019s Workspace page but I can\u2019t see the settings in my Overview page.<\/p>\n<p>Any suggestions?<br>\nKind regards,<br>\nH.<\/p>\n<p>def init_wandb(self) \u2192 None:<\/p>\n<pre><code>    wandb.login(key=key_value)\n\n    my_params = {\n                 'architecture': self.model_name,\n                 'learning_rate': self.learning_rate,\n                 'epochs': self.epochs,\n                 'batch_size': self.batch_size,\n                 'dataset': self.dataset\n                 }\n\n    wandb.init(config=my_params,\n               project=self.project_name,\n               notes=self.dataset + '_' + self.date_now,\n               name=self.project_code\n               )\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dataset selection for hyperparameter optimization and training",
        "Question_link":"https:\/\/community.wandb.ai\/t\/dataset-selection-for-hyperparameter-optimization-and-training\/3455",
        "Question_created_time":"2022-11-24T07:50:35.658Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":103,
        "Question_body":"<p>Hi,<br>\ni want to make a multiclass classifier using a bert model. For this i would like to compare the performance of (at least) two domain specific bert models. But  before i compare the model performance i would like to find the best hyperparameters using wandb sweeps und the simpletransformers api (the simpletransformers api, has an easy integration with wandb).<\/p>\n<p>Currently i\u2019m a bit confused how to select a good dataset for<\/p>\n<ol>\n<li>the hyperparameter optimization<\/li>\n<li>the training with the best hyperparams.<\/li>\n<\/ol>\n<p>So for the hyperparams, should i create n cross-validation sets and then run a training cycle with the current selected hyperparams for every m in n dataset?<br>\nE.g. i created 2 train\/test sets and i only want to find the best n of episodes out of [1,2]:<br>\nFor both train\/test sets, the training is done for 1 episode and in the nex cycle for 2 episodes?<\/p>\n<p>And if i found the best hyperparameters, should i train the final model afterwards using my full dataset?<\/p>\n<p>Hope my questions are kind of clear<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"About Network error (TransientError)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/about-network-error-transienterror\/3462",
        "Question_created_time":"2022-11-25T14:20:11.119Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":874,
        "Question_body":"<p>I get below error message when starting a new run:<\/p>\n<pre><code class=\"lang-shell\">wandb: Network error (TransientError), entering retry loop.\n<\/code><\/pre>\n<p>Some metrics can be uploaded successfully, but some metrics are not (cannot be found in the UI).<\/p>\n<p>I have determined that it is an internet connection problem because this problem is solved when I change WIFI connection from A to B.<\/p>\n<p>I would like to know if there is any way to guide the network operator to fix the network A. Is <code>ping<\/code> command can help (should try to decrease the packet loss)?<\/p>\n<pre><code class=\"lang-shell\">PING www.wandb.ai (151.101.1.195): 56 data bytes\n64 bytes from 151.101.1.195: icmp_seq=0 ttl=42 time=258.594 ms\n64 bytes from 151.101.1.195: icmp_seq=1 ttl=42 time=188.247 ms\n64 bytes from 151.101.1.195: icmp_seq=2 ttl=42 time=186.654 ms\n64 bytes from 151.101.1.195: icmp_seq=3 ttl=42 time=189.388 ms\n64 bytes from 151.101.1.195: icmp_seq=4 ttl=42 time=228.432 ms\n64 bytes from 151.101.1.195: icmp_seq=5 ttl=42 time=280.176 ms\n64 bytes from 151.101.1.195: icmp_seq=6 ttl=42 time=324.054 ms\n64 bytes from 151.101.1.195: icmp_seq=7 ttl=42 time=215.211 ms\n64 bytes from 151.101.1.195: icmp_seq=8 ttl=42 time=224.348 ms\nRequest timeout for icmp_seq 9\n64 bytes from 151.101.1.195: icmp_seq=10 ttl=42 time=311.803 ms\n64 bytes from 151.101.1.195: icmp_seq=11 ttl=42 time=187.057 ms\n64 bytes from 151.101.1.195: icmp_seq=12 ttl=42 time=189.397 ms\n64 bytes from 151.101.1.195: icmp_seq=13 ttl=42 time=196.487 ms\n64 bytes from 151.101.1.195: icmp_seq=14 ttl=42 time=195.504 ms\n64 bytes from 151.101.1.195: icmp_seq=15 ttl=42 time=194.557 ms\n64 bytes from 151.101.1.195: icmp_seq=16 ttl=42 time=189.196 ms\n64 bytes from 151.101.1.195: icmp_seq=17 ttl=42 time=185.882 ms\n^C\n--- www.wandb.ai ping statistics ---\n19 packets transmitted, 17 packets received, 10.5% packet loss\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ERROR: Project does not contain artifact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-project-does-not-contain-artifact\/3314",
        "Question_created_time":"2022-10-24T20:50:40.009Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":551,
        "Question_body":"<p>I\u2019m running the following code to initialize a run and use my dataset as an artifact:<\/p>\n<pre><code class=\"lang-auto\">    run = wandb.init(name=job_name, project=wandb_project_name, config=vars(args), save_code=True, job_type=\"training\")\n    wandb.run.log_code(\".\")\n    print(wandb_dataset_name)\n    dataset = run.use_artifact(wandb_dataset_name)\n<\/code><\/pre>\n<p>This code is in a Sagemaker script and when I run, everything works as expected. However, when I run the same exact script in a Sagemaker hyper parameter tuning job instead of a single training job, I get the following error:<\/p>\n<blockquote>\n<p>wandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\ndistributedspectrum\/RadioML-Experimentation\/RadioML_tfrecords:v0<br>\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\nwandb: ERROR Project distributedspectrum\/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d<br>\nTraceback (most recent call last):<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\u201d, line 26, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 937, in artifact<br>\nartifact = Artifact(self.client, entity, project, artifact_name)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 4151, in <strong>init<\/strong><br>\nself._load()<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 4735, in _load<br>\nraise ValueError(<br>\nValueError: Project distributedspectrum\/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d<br>\nDuring handling of the above exception, another exception occurred:<br>\nTraceback (most recent call last):<br>\nFile \u201cradioml-training.py\u201d, line 306, in <br>\nmain(args)<br>\nFile \u201cradioml-training.py\u201d, line 175, in main<br>\ndataset = run.use_artifact(wandb_database_name)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\u201d, line 255, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\u201d, line 2575, in use_artifact<br>\nartifact = public_api.artifact(type=type, name=name)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\u201d, line 62, in wrapper<br>\nraise CommError(message, err).with_traceback(sys.exc_info()[2])<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\u201d, line 26, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 937, in artifact<br>\nartifact = Artifact(self.client, entity, project, artifact_name)<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 4151, in <strong>init<\/strong><br>\nself._load()<br>\nFile \u201c\/usr\/local\/lib\/python3.8\/site-packages\/wandb\/apis\/public.py\u201d, line 4735, in _load<br>\nraise ValueError(<br>\nwandb.errors.CommError: Project distributedspectrum\/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d<\/p>\n<\/blockquote>\n<p>Literally everything is exactly the same but I suddenly get this error. I\u2019m also not sure why the warnings about wandb.login() appear as well. They don\u2019t appear in the single training job and I don\u2019t ever call wandb.login() in my code.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Digest mismatch error when trying to download model artifact from S3",
        "Question_link":"https:\/\/community.wandb.ai\/t\/digest-mismatch-error-when-trying-to-download-model-artifact-from-s3\/3269",
        "Question_created_time":"2022-10-18T00:11:32.610Z",
        "Question_answer_count":7,
        "Question_score_count":2,
        "Question_view_count":308,
        "Question_body":"<p>I\u2019m using AWS Sagemaker to train a Keras model with the Wandb callback. In my Sagemaker script, I save checkpoints to <code>'\/opt\/ml\/checkpoints\/'<\/code> which it redirects to an s3 bucket continuously. After the model has finished training, I create my artifact and add a reference to that bucket.<\/p>\n<p>Later, if I try to download the model with:<\/p>\n<pre><code class=\"lang-auto\">model_path = run.use_artifact(...)\nmodel_path.download()\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<blockquote>\n<p>ValueError: Digest mismatch for object s3:\/\/\u2026\/variables\/variables.data-00000-of-00001: expected 4f8d37a52a3e87f1f0ee2d3101688848-3 but found 8ad5ef5242d547d7edaa76f620597b60-3<\/p>\n<\/blockquote>\n<p>My guess is that I\u2019ve added the reference to the artifact before Sagemaker has pushed the final model from the local directory to S3. I\u2019m not sure how to get around this, is there a better way to have my Artifacts be linked to an S3 bucket?<\/p>",
        "Question_closed_time":"2022-10-27T17:31:38.081Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dspectrum\">@dspectrum<\/a>,<\/p>\n<p>Looking at your error and tracing back through our code - looks like versioning is not enabled on your S3 bucket, which means the artifact is changing the file itself, leading to different hashes. I would suggest turning on versioning on your S3 bucket and letting me know if you still run into the same error.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Init and config in different files",
        "Question_link":"https:\/\/community.wandb.ai\/t\/init-and-config-in-different-files\/3439",
        "Question_created_time":"2022-11-18T10:52:38.344Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":200,
        "Question_body":"<p>Hi all,<br>\nI want to seperate the wandb.config from wandb.init in my training script. Howerever I cant seem to get around a circular import when trying to do this. I had a workaround where I use .init(mode=\u201coffline\u201d), so I can use wandb.config() afterwards and then call init() again in the training script. However this does not seem to work with sweeps.<\/p>\n<ol>\n<li>In settings.py: Run wandb.config()<\/li>\n<li>In training.py: From settings import config<br>\nRun wandb.init() in training.py<\/li>\n<\/ol>\n<p>I feel like there is an obvious solution, but I cant seem to find it.<br>\nThanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hypyerparameter optimization with k folds on each iteration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hypyerparameter-optimization-with-k-folds-on-each-iteration\/3429",
        "Question_created_time":"2022-11-16T15:55:13.531Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":198,
        "Question_body":"<p>I am trying to perform hyperparameter optimization with wandb and for each iteration I would like to get the average performance across 3 different folds of my dataset.<\/p>\n<p>I have defined a function optimize that i pass to wandb.agent:<\/p>\n<pre><code class=\"lang-auto\">def optimize(config):\n    for fold in range(1, 4):    \n        dataset_artifact = f'fold-{fold}:latest'\n        config['dataset_artifact'] = dataset_artifact \n        with wandb.init(config=config, group=group_name, job_type=f'train-fold-{fold}', name=f'train-fold-{fold}', reinit=True) as run:   \n            train_and_log(config, run)  \n            run.finish()\n<\/code><\/pre>\n<p>I would expect this to creat a seperate run for each fold (since I have specified a different job type and run name as well as passing init=True) so that I would end up with:<\/p>\n<p>Group: param_combo_1<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-1<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-1<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-2<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-2<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-3<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-3<\/p>\n<p>However each run for a given hyperparameter iteration overwrites the previous fold so I in fact end up with<\/p>\n<p>Group: param_combo_1<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-3<\/p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-3<\/p>\n<p>How can I resolve this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run to Run Logging",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-to-run-logging\/3353",
        "Question_created_time":"2022-11-01T06:23:49.357Z",
        "Question_answer_count":11,
        "Question_score_count":0,
        "Question_view_count":720,
        "Question_body":"<p>We are interested in using WandB to track monitoring statistics for a Model that is going into production.  We have a process that runs known data against the model and records results to confirm operation and timing.<br>\nWe would like to show the statistics in a lineplot over many iterations from these regular monitoring runs.  Its important to be able see a plot tracking the values over time.<br>\nWhat is the recommended way to log run-to-run values?<br>\nOptions:<\/p>\n<ol>\n<li>Use the <code>resume<\/code> command to continue a RunID repeatedly for every monitoring run.<br>\n<code>wand.init(project=\"name\",id=\"my_run_id\", resume=True)<\/code><br>\nThis seems to work, but I have found that I can\u2019t look at old values. Only the most recent values are shown under the <code>Summary<\/code> panel.  It would be helpful to see a Table of all recorded values over time.<\/li>\n<li>Somehow use a Table, but can\u2019t find a way to tack on data to a table from a previous run<\/li>\n<li>Use a separate Run for each test, but find some way to track statistics across runs.  I\u2019ve tried to search on this, but can\u2019t find a way to do this across dozens to hundreds of runs.<br>\nThanks for the help.<\/li>\n<\/ol>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Forcing Pre-emption in a sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/forcing-pre-emption-in-a-sweep\/3391",
        "Question_created_time":"2022-11-08T17:39:54.104Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":407,
        "Question_body":"<p>This is a bit of a weird one\u2026<br>\nMy lab has a cluster that usually runs using slurm, but slurm is down (and may be not up for a while). We would like to still use wandb and still maintain the priority levels that slurm gives (i.e. we want to make sure if there is some critical jobs that need to get run, we can easily pre-empt existing jobs that are running in sweeps and still get them to requeue later when the critical jobs are over (essentially we are trying to do manual pre-emption)<\/p>\n<p>I have been trying to set this up with a dummy sweep that just sends a single \u201cmagic number\u201d to each run, however no matter what I do I cannot seem to get the run to be pre-empted. If I try killing via <code>ctrl+C<\/code>, the wandb process shuts down normally and it marks the run as finished. Is there any way I can get around this to force the pre-emption? Thank you so much for your help!<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport time\nfrom random import randint\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nwandb.init()\nmagic_number = wandb.config.magic_number\ntry:\n    print(f'Hello, world! Magic number is {magic_number}')\n    print('My PID is', os.getpid())\n    size = 1_000_000_000\n    for count in tqdm(range(size)):\n        if count % (size \/\/ 10) == 0:\n            print(f'On count {count}')\nexcept (Exception, KeyboardInterrupt, SystemExit) as e:\n    print('Keyboard interrupt!')\n    # I cannot reach this piece of code no matter when I do\n    # I have tried ctrl+c, killing the process corresponding to this python script, killing the wandb agent process\n    wandb.mark_preempting()\n    print('Preempted!')\n    sys.exit(999)\nprint('Done!')\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"extraKeys don't show up in historyTable",
        "Question_link":"https:\/\/community.wandb.ai\/t\/extrakeys-dont-show-up-in-historytable\/3416",
        "Question_created_time":"2022-11-14T15:29:54.076Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":565,
        "Question_body":"<p>Hey everyone,<\/p>\n<p>I\u2019m trying to visualize some ROC curves for different epochs, and what I would like to do is add a slider with the epoch number to see how it evolves. I found this <a href=\"https:\/\/wandb.ai\/stacey\/presets\/reports\/PR-Curve-Slider-Example--Vmlldzo2NjE5ODk\">example<\/a>, but I am having an issue with the <code>extraKeys<\/code> parameter. No option shows up when I click on it\u2026 (I would like to use the <code>t_epoch<\/code> field that I correctly log (cf screenshots). Am I doing something wrong?<\/p>\n<p>Many thanks for considering my request.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/f\/fcc44be61b70a4aae43f6fea3fa466fe0beaa409.png\" data-download-href=\"\/uploads\/short-url\/A44SV67K2WiCfegtX5Wv8Yt9khj.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/f\/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_690x279.png\" alt=\"image\" data-base62-sha1=\"A44SV67K2WiCfegtX5Wv8Yt9khj\" width=\"690\" height=\"279\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/f\/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_690x279.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/f\/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_1035x418.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/f\/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_1380x558.png 2x\" data-dominant-color=\"F0F1F2\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1412\u00d7572 65.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ERROR Abnormal program exit",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-abnormal-program-exit\/3448",
        "Question_created_time":"2022-11-22T04:32:51.015Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":972,
        "Question_body":"<p>I am using wandb version 0.13.5 on python 3.6.9 (Linux kernel version: 4.14.281-212.502.amzn2.x86_64). I have a problem running <code>wandb.init()<\/code> with the following error.<\/p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_init.py\u201d, line 1075, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_init.py\u201d, line 165, in setup<br>\nself._wl = wandb_setup.setup()<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 312, in setup<br>\nret = _setup(settings=settings)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 307, in _setup<br>\nwl = _WandbSetup(settings=settings)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 293, in <strong>init<\/strong><br>\n_WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 106, in <strong>init<\/strong><br>\nself._setup()<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 234, in _setup<br>\nself._setup_manager()<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py\u201d, line 266, in _setup_manager<br>\n_use_grpc=use_grpc, settings=self._settings<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_manager.py\u201d, line 108, in <strong>init<\/strong><br>\nself._service.start()<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/service\/service.py\u201d, line 112, in start<br>\nself._launch_server()<br>\nFile \u201c\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/service\/service.py\u201d, line 108, in _launch_server<br>\nassert ports_found<br>\nAssertionError<br>\nwandb: ERROR Abnormal program exit<br>\nproc exited with 1<\/p>\n<\/blockquote>\n<blockquote>\n<hr>\n<p>AssertionError                            Traceback (most recent call last)<br>\n\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)<br>\n1074         wi = _WandbInit()<br>\n \u2192 1075         wi.setup(kwargs)<br>\n1076         except_exit = wi.settings._except_exit<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_init.py in setup(self, kwargs)<br>\n164<br>\n \u2192 165         self._wl = wandb_setup.setup()<br>\n166         # Make sure we have a logger setup (might be an early logger)<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in setup(settings)<br>\n311 def setup(settings=None) \u2192 Optional[\u201c_WandbSetup\u201d]:<br>\n \u2192 312     ret = _setup(settings=settings)<br>\n313     return ret<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in _setup(settings, _reset)<br>\n306         return<br>\n \u2192 307     wl = _WandbSetup(settings=settings)<br>\n308     return wl<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in <strong>init<\/strong>(self, settings)<br>\n292             return<br>\n \u2192 293         _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)<br>\n294<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in <strong>init<\/strong>(self, pid, settings, environ)<br>\n105         self._check()<br>\n \u2192 106         self._setup()<br>\n107<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in _setup(self)<br>\n233     def _setup(self):<br>\n \u2192 234         self._setup_manager()<br>\n235<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_setup.py in _setup_manager(self)<br>\n265         self._manager = wandb_manager._Manager(<br>\n \u2192 266             _use_grpc=use_grpc, settings=self._settings<br>\n267         )<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_manager.py in <strong>init<\/strong>(self, settings, _use_grpc)<br>\n107         if not token:<br>\n \u2192 108             self._service.start()<br>\n109             host = \u201clocalhost\u201d<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/service\/service.py in start(self)<br>\n111     def start(self) \u2192 None:<br>\n \u2192 112         self._launch_server()<br>\n113<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/service\/service.py in _launch_server(self)<br>\n107             ports_found = self._wait_for_ports(fname, proc=internal_proc)<br>\n \u2192 108             assert ports_found<br>\n109             self._internal_proc = internal_proc<\/p>\n<p>AssertionError:<\/p>\n<p>The above exception was the direct cause of the following exception:<\/p>\n<p>Exception                                 Traceback (most recent call last)<br>\n in <br>\n1 import wandb<br>\n----&gt; 2 wandb.init()<\/p>\n<p>\/usr\/local\/lib\/python3.6\/dist-packages\/wandb\/sdk\/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)<br>\n1114             if except_exit:<br>\n1115                 os._exit(-1)<br>\n \u2192 1116             raise Exception(\u201cproblem\u201d) from error_seen<br>\n1117     return run<\/p>\n<p>Exception: problem<\/p>\n<\/blockquote>\n<p>I tried downgrading the wandb version to 0.9.7 but the problem still the same. Could you please help me solve this error?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Select the metrics according to different step thresholds in the Runs Table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/select-the-metrics-according-to-different-step-thresholds-in-the-runs-table\/3403",
        "Question_created_time":"2022-11-10T08:26:29.469Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":93,
        "Question_body":"<p>Take the following as an example. We train a model with different configurations  for 1000 steps. Then, the Runs Table only shows the final values of the logged metrics. In some cases, we might want to compare different runs within 500 steps. Can we add support for this functionality?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"More on Bayes method",
        "Question_link":"https:\/\/community.wandb.ai\/t\/more-on-bayes-method\/3355",
        "Question_created_time":"2022-11-01T10:36:20.752Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":183,
        "Question_body":"<p>is there a more detailed explanation on the use of bayes in hyperparameter search? For example, if it uses GP regression, what are the default kernel and parameters, and how to change them, etc.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to log each run when using pytorch lightning integration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-log-each-run-when-using-pytorch-lightning-integration\/3443",
        "Question_created_time":"2022-11-18T22:42:35.261Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":445,
        "Question_body":"<p>I\u2019m able to log a training run with pytorch lightning + wandb based on <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/lightning\">these instructions<\/a> in google colab.  Here\u2019s a snippet of code I\u2019m running:<\/p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\ntrainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n<\/code><\/pre>\n<p>it outputs the link to the run and I can see all of the stats etc.<\/p>\n<p>However, how can I retrain?  If I try re-training with:<\/p>\n<pre><code class=\"lang-auto\">trainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n<\/code><\/pre>\n<p>It doesn\u2019t seem to log a new run.  It looks like it doesn\u2019t even log the data to the existing run, it is just completely lost.<\/p>\n<p>If I try to create a new wandb logger before the re-training:<\/p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\ntrainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n<\/code><\/pre>\n<p>it times out after 1 minute with this error:<\/p>\n<pre><code class=\"lang-auto\">andb: ERROR Error communicating with wandb process\nwandb: ERROR For more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\nProblem at: \/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/wandb.py 406 experiment\n---------------------------------------------------------------------------\nUsageError                                Traceback (most recent call last)\n&lt;ipython-input-44-6016437e3426&gt; in &lt;module&gt;\n----&gt; 1 wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\n\n6 frames\n\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/wandb_init.py in init(self)\n    717                     backend.cleanup()\n    718                     self.teardown()\n--&gt; 719                 raise UsageError(error_message)\n    720             assert run_result and run_result.run\n    721             if run_result.run.resumed:\n\nUsageError: Error communicating with wandb process\nFor more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error```\n\nAm I using wandb + pytorch lightning the correct way?  What is the expected lifecycle of the wandb logger in relation to the pl training object?<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to set the environment variable WANDB_IGNORE_GLOBS correctly?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-set-the-environment-variable-wandb-ignore-globs-correctly\/3423",
        "Question_created_time":"2022-11-16T07:04:43.551Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":142,
        "Question_body":"<p>The usage in the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/environment-variables#optional-environment-variables\">Docs<\/a> is:<\/p>\n<blockquote>\n<p>Set this to a comma separated list of file globs to ignore. These files will not be synced to the cloud<\/p>\n<\/blockquote>\n<p>So, is the below code correct?<\/p>\n<pre><code class=\"lang-python\">os.environ['WANDB_IGNORE_GLOBS'] = '[*.pth, *.npy]'\n<\/code><\/pre>",
        "Question_closed_time":"2022-11-17T15:17:40.971Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> thank you for writing in! Could you please check if the following would work for you?<\/p>\n<pre><code class=\"lang-auto\">os.environ['WANDB_IGNORE_GLOBS'] = '*.pth,*.npy'\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Manually ask sweep agents to start new run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/manually-ask-sweep-agents-to-start-new-run\/3441",
        "Question_created_time":"2022-11-18T14:53:29.156Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":245,
        "Question_body":"<p>Sorry, it may be easy question or I was unable to find the answer \u2013 how do I manually ask one (or more) agents of a running sweep to stop the current run and move to a new one ?<\/p>\n<p>I am running a sweep with 48 possible configurations with 10 agents. I noticed (from sweep dashboard) some of configurations are poor from the very beginning. So I would like to terminate them and explore the unexplored configurations. The poor ones are just wasting my resources. I don\u2019t want to terminate all since some of them are doing quite good,<\/p>\n<p>How do we do this is wandb ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"(Windows 11) `wandb.sweep()` gives ConnectionResetError: [WinError 10054]",
        "Question_link":"https:\/\/community.wandb.ai\/t\/windows-11-wandb-sweep-gives-connectionreseterror-winerror-10054\/3217",
        "Question_created_time":"2022-10-04T20:26:49.749Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":564,
        "Question_body":"<p>Hello, sort of new to wandb. I\u2019m trying sweeps for the first time - I had no problem creating and running a sweep from the web UI, then copy-pasting the command to start an agent from bash. However, starting it using <code>wandb.agent()<\/code> keeps giving me problems. It starts training, but I keep running into two problems:<\/p>\n<ol>\n<li>I keep getting the error below each time a new run starts - it seems to be originating from another thread created by wandb, so I\u2019m not sure what to do about it. Also, the runs get logged in the sweep page, but none of them have the data I\u2019ve logged (and each run has the \u201cactive\u201d dot even once the script ends).<\/li>\n<li>I can\u2019t figure out what wandb calls to make, and in what order, to get the agent to populate its randomized values into <code>wandb.config<\/code>. I would like to set some default config values (which are not specified by my <code>sweep_config<\/code> dict), but have the sweep agent update <code>wandb.config<\/code> with the randomized values created from the <code>sweep_config<\/code> dict (it seems like this is what happens when I run from bash). In the traceback below, you can see I print <code>wandb.config<\/code> right before the model is trained, and it simply uses the <code>config<\/code> dict I specified when calling <code>wandb.init<\/code> (it is not updated\/overwritten by the agent).<\/li>\n<\/ol>\n<p>Below is the full traceback. Thanks in advance for any ideas.<\/p>\n<pre><code class=\"lang-auto\">C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\python.exe C:\\Users\\jacks\\ml-project\\training_script.py \nUsing device: cuda\nwandb: Currently logged in as: jacksth22. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.13.3\nwandb: Run data is saved locally in C:\\Users\\jacks\\ml-project\\wandb\\run-20221004_162225-1aj4c6jt\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run restful-dew-107\nwandb:  View project at https:\/\/wandb.ai\/jacksth22\/&lt;project&gt;\nwandb:  View run at https:\/\/wandb.ai\/jacksth22\/&lt;project&gt;\/runs\/1aj4c6jt\nLoading data...done (elapsed=1.49s).\nConverting data to tensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500\/500 [00:03&lt;00:00, 164.20it\/s]\ndone (elapsed=3.05s).\nCreate sweep with ID: plq6uobc\nSweep URL: https:\/\/wandb.ai\/jacksth22\/uncategorized\/sweeps\/plq6uobc\n=== Starting sweep agent ===\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.\nwandb: Waiting for W&amp;B process to finish... (success).\nwandb:                                                                                \nwandb: Synced restful-dew-107: https:\/\/wandb.ai\/jacksth22\/&lt;project&gt;\/runs\/1aj4c6jt\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\\wandb\\run-20221004_162225-1aj4c6jt\\logs\nwandb: Agent Starting Run: 1bqu30r5 with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 2\nwandb: \tdense_width: 64\nwandb: \tdepth: 6\nwandb: \tdropout: 0.25778082906860794\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 4\nwandb: \tlr: 0.0008418633888555167\nwandb: \tlr_warmup: 1960\nwandb: \tmax_seq_len: 64\nwandb: \toptimizer: AdamW\nwandb: \tuse_max_pool: False\nModel created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml\/logs\/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1\/3:   0%|          | 0\/22 [00:00&lt;?, ?it\/s]Exception in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 190, in check_status\n    status_response = self._interface.communicate_stop_status()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 128, in communicate_stop_status\n    resp = self._communicate_stop_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 69, in _communicate_stop_status\n    data = super()._communicate_stop_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 399, in _communicate_stop_status\n    resp = self._communicate(req, local=True)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 230, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router_sock.py\", line 35, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 172, in check_network_status\n    status_response = self._interface.communicate_network_status()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 139, in communicate_network_status\n    resp = self._communicate_network_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 82, in _communicate_network_status\n    data = super()._communicate_network_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 409, in _communicate_network_status\n    resp = self._communicate(req, local=True)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 230, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router_sock.py\", line 35, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nTraining epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:06&lt;00:00,  3.32it\/s]\nTesting epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 20.42it\/s]\nTraining epoch 2\/3:   0%|          | 0\/22 [00:00&lt;?, ?it\/s]Train: acc =    9.43% | loss = 260.72%\nTest:  acc =   16.67% | loss = 225.52%\nTraining epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.70it\/s]\nTesting epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.73it\/s]\nTraining epoch 3\/3:   0%|          | 0\/22 [00:00&lt;?, ?it\/s]Train: acc =   11.60% | loss = 221.38%\nTest:  acc =   13.33% | loss = 218.46%\nTraining epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.84it\/s]\nTesting epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.05it\/s]\nTrain: acc =   12.40% | loss = 218.99%\nTest:  acc =   13.33% | loss = 235.97%\nException in thread Thread-14:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nwandb: Agent Starting Run: ly4ox06s with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 4\nwandb: \tdense_width: 128\nwandb: \tdepth: 10\nwandb: \tdropout: 0.3449039365016265\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 6\nwandb: \tlr: 0.0007649760799562746\nwandb: \tlr_warmup: 1057\nwandb: \tmax_seq_len: 64\nwandb: \toptimizer: AdamW\nwandb: \tuse_max_pool: False\nModel created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml\/logs\/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.86it\/s]\nTesting epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.62it\/s]\nTrain: acc =   10.57% | loss = 247.77%\nTest:  acc =   10.00% | loss = 227.83%\nTraining epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.84it\/s]\nTesting epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.09it\/s]\nTraining epoch 3\/3:   0%|          | 0\/22 [00:00&lt;?, ?it\/s]Train: acc =   10.60% | loss = 236.37%\nTest:  acc =   10.00% | loss = 231.93%\nTraining epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.83it\/s]\nTesting epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.15it\/s]\nException in thread Thread-15:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\nTrain: acc =   10.40% | loss = 233.15%\nTest:  acc =   13.33% | loss = 230.50%\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nwandb: Agent Starting Run: viajyjrk with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 4\nwandb: \tdense_width: 128\nwandb: \tdepth: 8\nwandb: \tdropout: 0.06200113164824134\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 6\nwandb: \tlr: 0.0006929869499125819\nwandb: \tlr_warmup: 2917\nwandb: \tmax_seq_len: 512\nwandb: \toptimizer: SGD\nwandb: \tuse_max_pool: False\nTraining epoch 1\/3:   0%|          | 0\/22 [00:00&lt;?, ?it\/s]Model created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml\/logs\/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.65it\/s]\nTesting epoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.07it\/s]\nTrain: acc =    9.43% | loss = 262.65%\nTest:  acc =   10.00% | loss = 221.72%\nTraining epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.86it\/s]\nTesting epoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 21.02it\/s]\nTrain: acc =   11.60% | loss = 236.80%\nTest:  acc =   10.00% | loss = 234.05%\nTraining epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22\/22 [00:03&lt;00:00,  5.81it\/s]\nTesting epoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10\/10 [00:00&lt;00:00, 20.80it\/s]\nException in thread Thread-16:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\nTrain: acc =   11.00% | loss = 226.62%\nTest:  acc =    9.33% | loss = 221.71%\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nProcess finished with exit code 0\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Training hangs with GPU Utilization 100% and wandb trying to sync",
        "Question_link":"https:\/\/community.wandb.ai\/t\/training-hangs-with-gpu-utilization-100-and-wandb-trying-to-sync\/3376",
        "Question_created_time":"2022-11-03T23:12:28.231Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":240,
        "Question_body":"<p>I\u2019ve been trying to get wandb to work with pytorch lightning on multiple gpus, it works fine, in the sense that the model is being trained, and metrics are being reported properly to the dashboard; however, only after a couple of hours and sometimes 20 mins, the system is maxed to use all the resources, causing the whole training process to freeze without any progress. I used <code>py-spy<\/code> to generate the following dumps<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b7f9aeb6b00a64f0949160291dd29702c3f2a805.png\" data-download-href=\"\/uploads\/short-url\/qfwjNuMRxJcCiiUOe6uuHTM1BLT.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_690x260.png\" alt=\"image\" data-base62-sha1=\"qfwjNuMRxJcCiiUOe6uuHTM1BLT\" width=\"690\" height=\"260\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_690x260.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_1035x390.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b7f9aeb6b00a64f0949160291dd29702c3f2a805.png 2x\" data-dominant-color=\"EAE7D7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1282\u00d7484 70.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Hopefully, they\u2019d be helpful to figure out where is the issue.<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Group by multiple variables in charts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/group-by-multiple-variables-in-charts\/3435",
        "Question_created_time":"2022-11-17T15:03:50.270Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":168,
        "Question_body":"<p>I have some variables in my sweeps that i want to be able to group by at the same time in my charts.<\/p>\n<p>In this specific case it\u2019s 3 hyperparameters of the architecture: \u201clevels\u201d, \u201cconvolutions per level\u201d and \u201cstarting features\u201d.<\/p>\n<p>I can have multiple charts, grouping by one at a time, and see how each individual variable affects the runs, but it would be much more beneficial to see the effects of all three together.<\/p>\n<p>The \u201ccustom chart\u201d seemed the way to go, but i couldn\u2019t make it work so far. Any help would be really appreciated!<\/p>",
        "Question_closed_time":"2022-11-17T15:30:23.534Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/mateoballa\">@mateoballa<\/a> thank you for writing in! In the Project level, you can group your Runs by all these three hyperparameters from the Group button as in the attachment.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/40fde472a1d51962372411528e99e65a7c90656d.png\" alt=\"Screenshot 2022-11-17 at 15.26.35\" data-base62-sha1=\"9gWweVkvwN7ym0GpqkZ8aunFcq9\" width=\"596\" height=\"303\"><\/p>\n<p>Then the Charts will adjust to this grouping. Would this help, or you wanted something different to achieve? Could you share a screenshot of your current custom chart?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Set random seed for sweep initialization",
        "Question_link":"https:\/\/community.wandb.ai\/t\/set-random-seed-for-sweep-initialization\/3418",
        "Question_created_time":"2022-11-15T19:43:01.663Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":195,
        "Question_body":"<p>Hi,<\/p>\n<p>is there a way to set the initial random seed for a random or bayesian hyperparameter sweep  so that  it goes through a reproducible  sequence of hyperparameter configurations?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: ERROR Failed to sample metric: psutil.NoSuchProcess process no longer exists (pid=453)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-failed-to-sample-metric-psutil-nosuchprocess-process-no-longer-exists-pid-453\/3393",
        "Question_created_time":"2022-11-08T21:06:52.934Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":583,
        "Question_body":"<p>I am running some NLP models and simply using wandb to log the errors during these modelings. I am receiving  the following error while logging:<\/p>\n<p><code>wandb: ERROR Failed to sample metric: psutil.NoSuchProcess process no longer exists (pid=453)<\/code><\/p>\n<p>I appreciate your help in fixing it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Undelete runs no longer available?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/undelete-runs-no-longer-available\/3420",
        "Question_created_time":"2022-11-15T22:02:39.237Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":329,
        "Question_body":"<p>Hi,<br>\nI deleted a run by accident and tried to recover it. However, I noticed there is undelete all runs option available from the dot menu on the overview page of the project.<br>\nIs there a way to recover a deleted run?<br>\nThank you.<\/p>",
        "Question_closed_time":"2022-11-16T12:05:29.286Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/summer5e\">@summer5e<\/a> thank you for reporting this. The option to undelete runs should be available when you go to the Project\u2019s overview page, and not in the Runs overview level. I have attached a screenshot of an example, the option can be found when you click on the three vertical dots:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b4766106065aa247f2d9930f131e3dab402136a6.png\" data-download-href=\"\/uploads\/short-url\/pKrzn3Dflv0FWE8GGBfCE4JTMhM.png?dl=1\" title=\"Screenshot 2022-11-16 at 12.02.29\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b4766106065aa247f2d9930f131e3dab402136a6_2_690x174.png\" alt=\"Screenshot 2022-11-16 at 12.02.29\" data-base62-sha1=\"pKrzn3Dflv0FWE8GGBfCE4JTMhM\" width=\"690\" height=\"174\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b4766106065aa247f2d9930f131e3dab402136a6_2_690x174.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b4766106065aa247f2d9930f131e3dab402136a6_2_1035x261.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/b\/b4766106065aa247f2d9930f131e3dab402136a6_2_1380x348.png 2x\" data-dominant-color=\"212122\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-11-16 at 12.02.29<\/span><span class=\"informations\">2845\u00d7719 123 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Could you please let me know the name of your project to look further into this?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Nested Sweep Configuration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/nested-sweep-configuration\/3369",
        "Question_created_time":"2022-11-02T17:13:09.376Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":762,
        "Question_body":"<p>I have been attempting to use <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/other\/hydra\">Hydra configuration<\/a> with a wandb sweeps. I have nested hierarchy of configuration. When defining the parameters I want to sweep over  I would like to something like the following:<\/p>\n<pre><code class=\"lang-auto\">optimizer:\n    parameters:\n        learning_rate:\n            values: [0.01, 0.001]\n        momentum:\n            value: 0.9\n<\/code><\/pre>\n<p>Source: <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/define-sweep-configuration\">Sweep Configuration<\/a><br>\nWhen I attempt this, I get a <code>CommError<\/code> with a message that  <code>sweep config must have a parameters section <\/code>. I do not get this error if <code>parameters<\/code> is at the top level of the hierarchy, but then the configs are not read in properly.  If I were to modify the above example to the following (only swapped <code>parameters<\/code> with <code>optimizer<\/code>):<\/p>\n<pre><code class=\"lang-auto\">parameters:\n    optimizer:\n        learning_rate:\n            values: [0.01, 0.001]\n        momentum:\n            value: 0.9\n<\/code><\/pre>\n<p>I would get a <code>CommError<\/code> with message <code>Invalid sweep config: invalid hyperparameter configuration: optimizer<\/code>. I would like to keep the hierarchical structure of the YAML base config but add <code>parameters<\/code> which will indicate which parameters to sweep over. Any recommendation? or resources? A code example using a nested <code>sweep.yaml<\/code> would be ideal.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Filtering runs by job_type using API is not working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/filtering-runs-by-job-type-using-api-is-not-working\/3390",
        "Question_created_time":"2022-11-08T15:39:19.400Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":183,
        "Question_body":"<p>Hi everyone!<\/p>\n<p>I am trying to retrieve  filtered runs from a project using the WandB API and a filter dictionary.<\/p>\n<p>I try to do the following:<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nfilter_dict = {\"job_type\":  \"my_job_type\"}\nruns = api.runs(\"my_entity\/my_project\", filters=filter_dict)\nfor run in runs:\n    print(run)\n<\/code><\/pre>\n<p>When I do this, I get the following error message:<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 980, in __next__\n    if not self._load_page():\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 965, in _load_page\n    self.last_response = self.client.execute(\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\retry.py\", line 168, in wrapped_fn\n    return retrier(*args, **kargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\retry.py\", line 108, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 207, in execute\n    return self._client.execute(*args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\client.py\", line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\client.py\", line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\transport\\requests.py\", line 39, in execute\n    request.raise_for_status()\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https:\/\/api.wandb.ai\/graphql\n<\/code><\/pre>\n<p>However, other filters do work. For example I can do the above described procedure with<\/p>\n<pre><code class=\"lang-auto\">filter_dict = {\"group\":  \"my_group\"}\n<\/code><\/pre>\n<p>and it yields the correctly filtered jobs.<\/p>\n<p>What I am currently doing as a workaround is this:<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nruns = api.runs(\"my_entity\/my_project\")\nfor run in runs:\n    if run.job_type == \"my_job_type\":\n        print(run)\n<\/code><\/pre>\n<p>However, I would prefer to directly filter the runs with the API call. Any idea what I am doing wrong?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":"2022-11-08T16:25:24.247Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kolja\">@kolja<\/a> thank you for writing in! Could you please try if the following would work for you?<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nfilter_dict = {\"jobType\":  \"my_job_type\"}\nruns = api.runs(\"my_entity\/my_project\", filters=filter_dict)\nfor run in runs:\n    print(run)\n<\/code><\/pre>\n<p>The queries in <code>filters<\/code> are using the MongoDB query language. Hope this helps!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Cannot connect to Amazon S3 from self hosted wandb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-connect-to-amazon-s3-from-self-hosted-wandb\/3399",
        "Question_created_time":"2022-11-09T21:12:49.307Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":124,
        "Question_body":"<p>I\u2019m trying to setup a self hosted wandb on k8s using helm charts. Unfortunately, I am not able to connect to my Amazon S3.<\/p>\n<p>I tried two ways:<\/p>\n<ol>\n<li>\n<p>Based on the example here <a href=\"https:\/\/docs.wandb.ai\/guides\/self-hosted\/setup\/on-premise-baremetal\" class=\"inline-onebox\">On Prem \/ Baremetal - Documentation<\/a>, I used the format:<br>\ns3:\/\/myaccess:myseceret@s3.amazonaws.com\/ofer-bucket-1<br>\nHowever when the wandb pod starts, it says that the URL is not valid, as \u201c:mysecret\u201d is not a valid port.<br>\nFor some reason it considers the secret to indicate URL port and not secret<\/p>\n<\/li>\n<li>\n<p>I also tried changing my bucket to public,  but wandb pod failed to initialize again, this time with error 403 access denied.<\/p>\n<\/li>\n<\/ol>\n<p>Anyone has an example for the correct format of the BUCKET value or can explain how it should be structured? I prefer to have it with access\/secret key. But I\u2019m ok with public as well.<\/p>",
        "Question_closed_time":"2022-11-13T05:04:58.264Z",
        "Answer_body":"<p>I\u2019ll post the reply of Chris Van Pelt from WandB support, to assist anyone who encounters this:<br>\nThe correct format is indeed s3:\/\/access:secret@host\/bucket<br>\nHowever, each component (access, secret, etc) needs to be url encoded as special characters within them can interfere with the parsing.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Rename username",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rename-username\/3409",
        "Question_created_time":"2022-11-11T04:34:38.790Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":312,
        "Question_body":"<p>Hello to all,<\/p>\n<p>I am new here. I thought I can change my username whenever I want when I signed up, so my username was informal. However, I couldn\u2019t find the place where I can change my username. I can only change my real name, institution, location, etc.<\/p>\n<p>Thank you very much<br>\nBest regards<br>\nJellerode<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delete account?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-account\/3412",
        "Question_created_time":"2022-11-12T00:00:11.695Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":421,
        "Question_body":"<p>Hi, I want my account deleted as I want to be removed from all teams I am currently in (changed jobs). I cannot delete my account since I\u2019m a billing user for some reason (I don\u2019t get charged at all by wandb so not sure why?) My username is aharakeh. Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Detectron2 sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/detectron2-sweeps\/3351",
        "Question_created_time":"2022-10-31T18:10:51.410Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":219,
        "Question_body":"<p>Hello<\/p>\n<p>I\u2019m a CV engineer and I\u2019m trying to make sweeps using w&amp;b, the issue is that I use detectron2 framework, thus I use config files to build the model, solver, etc\u2026<br>\nThe config files are usually nested if its important<br>\nI\u2019m intrested to initialize the agent using SDK properly, but in contrast to the example in the documentation, I cant just assign all the parameters (like \u2018a\u2019 here) to wandb.config.a<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/0b77bb2ed35e6a9e13a69a44c28a0901046c6ea2.png\" alt=\"image\" data-base62-sha1=\"1DrM3iAAJsTbiAW3aq7KKi7FbFw\" width=\"620\" height=\"314\"><br>\nIs there a way to assign the determined parameters efficiently?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"CI Credentials Not Tied to User",
        "Question_link":"https:\/\/community.wandb.ai\/t\/ci-credentials-not-tied-to-user\/3388",
        "Question_created_time":"2022-11-08T14:37:29.037Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":243,
        "Question_body":"<p>Hi there.<\/p>\n<p>We currently use wandb artifacts for model versioning during experiments. We\u2019d also like to integrate this into our production pipeline so that we can automatically pull specific model versions during builds.<\/p>\n<p>I am wondering if it\u2019s possible to get credentials that are not tied to a specific wandb user so that they don\u2019t expire if the team member that implements this happens to leave our company.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":"2022-11-08T15:54:30.258Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/willjstone\">@willjstone<\/a> thank you for writing in! You can do this using a <code>service account<\/code>, the steps to add this account type to your team are explained in our documentation <a href=\"https:\/\/docs.wandb.ai\/guides\/technical-faq\/general#what-is-a-service-account-and-why-is-it-useful\">here<\/a>. Would this work for your use case?<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Easiest way to load the best model checkpoint after training w\/ pytorch lightning",
        "Question_link":"https:\/\/community.wandb.ai\/t\/easiest-way-to-load-the-best-model-checkpoint-after-training-w-pytorch-lightning\/3365",
        "Question_created_time":"2022-11-02T00:15:43.889Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":1455,
        "Question_body":"<p>I have a notebook based on <a href=\"http:\/\/wandb.me\/lit-colab\" rel=\"noopener nofollow ugc\"> Supercharge your Training with PyTorch Lightning + Weights &amp; Biases<\/a> and I\u2019m wondering what the easiest approach to load a model with the best checkpoint after training finishes.<\/p>\n<p>I\u2019m assuming that after training the \u201cmodel\u201d instance will just have the weights of the most recent epoch, which might not be the most accurate model (in case it started overfitting etc).<\/p>\n<p>Specifically I was looking for an easy way to get the directory where the checkpoints artifacts are stored, which in my case look like this: <code>.\/MnistKaggle\/1vzsgin6\/checkpoints<\/code>, where <code>1vzsgin6<\/code> is the run id auto-generated by wandb.<\/p>\n<p>One (clunky) way to do it would be:<\/p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"MnistKaggle\")\ncheckpoint_dir_path = None\n\ndef my_after_save_checkpoint(checkpoint):\n  checkpoint_dir_path = checkpoint.dirpath\n\nwandb_logger.after_save_checkpoint = my_after_save_checkpoint\n\n# Now find the checkpoint file in the checkpoint_dir_path directory and load the model from that.\n<\/code><\/pre>\n<p>Is there an easier way?  I was sorta expecting the <code>WandbLogger<\/code> object to have an easy method like <code>get_save_checkpoint_dirpath()<\/code>, but I\u2019m not seeing anything.<\/p>\n<p>Thanks in advance for any help!<\/p>",
        "Question_closed_time":"2022-11-02T23:00:11.968Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/tleyden\">@tleyden<\/a> , happy to help. Please review the following <a href=\"https:\/\/pytorch-lightning.readthedocs.io\/en\/stable\/extensions\/generated\/pytorch_lightning.loggers.WandbLogger.html#:~:text=(model)-,Log%20model%20checkpoints,-Log%20model%20checkpoints\" rel=\"noopener nofollow ugc\">resource<\/a> on model checkpointing and retrieval.<\/p>\n<p>A common flow would be to log a model checkpoint as in the example then to also log a \u201cbest model\u201d artifact. Since artifacts are versioned you don\u2019t have to worry about renaming the new \u201cbest model\u201d artifact. Then at the end of your run you not only have an artifact history of your model at each of the checkpoints but also a versioned history of all the best models.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Training crashes on 2nd epoch with ValueError: not enough image data",
        "Question_link":"https:\/\/community.wandb.ai\/t\/training-crashes-on-2nd-epoch-with-valueerror-not-enough-image-data\/3341",
        "Question_created_time":"2022-10-28T19:46:50.551Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":197,
        "Question_body":"<p>I am trying to train a model but on the second epoch training crashes with the following error that is raised inside the wandb site-package:<\/p>\n<pre><code class=\"lang-auto\">----&gt; 1 history, model = train_model()\n\nCell In [11], line 54, in train_model()\n     51 early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3)\n     53 checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n---&gt; 54 history = model.fit(train_dataset,\n     55         epochs=config.epochs, \n     56         validation_data=val_dataset, \n     57         callbacks=[tensorboard_callback, wandb_callback, checkpoint, early_stopping])\n     59 wandb.finish()\n     60 return history, model\n\nFile d:\\Miniconda\\envs\\tiny_cnn\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174, in patch_tf_keras.&lt;locals&gt;.new_v2(*args, **kwargs)\n    172     for cbk in cbks:\n    173         set_wandb_attrs(cbk, val_data)\n--&gt; 174 return old_v2(*args, **kwargs)\n\nFile d:\\Miniconda\\envs\\tiny_cnn\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174, in patch_tf_keras.&lt;locals&gt;.new_v2(*args, **kwargs)\n    172     for cbk in cbks:\n    173         set_wandb_attrs(cbk, val_data)\n--&gt; 174 return old_v2(*args, **kwargs)\n...\n--&gt; 798     raise ValueError(\"not enough image data\")\n    799 if s[1] != 0:\n    800     raise ValueError(\"cannot decode image data\")\n\nValueError: not enough image data\n<\/code><\/pre>\n<p>Any idea on what needs to be fixed? Thanks for your support.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Uploadding seems never stop",
        "Question_link":"https:\/\/community.wandb.ai\/t\/uploadding-seems-never-stop\/3379",
        "Question_created_time":"2022-11-04T10:50:12.707Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":178,
        "Question_body":"<p>When I finished my code or shut it by ctrl+c,The terminal will prompt that the upload is in progress, but it will last for a long time, as if it will not end.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/343b92e6ac8a17b1091ce6676845df22dffecfca.png\" data-download-href=\"\/uploads\/short-url\/7s4sOJkQ3ydppUBxeHzteVX9AVA.png?dl=1\" title=\"1667558977574\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/343b92e6ac8a17b1091ce6676845df22dffecfca.png\" alt=\"1667558977574\" data-base62-sha1=\"7s4sOJkQ3ydppUBxeHzteVX9AVA\" width=\"690\" height=\"72\" data-dominant-color=\"E4DDCE\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">1667558977574<\/span><span class=\"informations\">1005\u00d7105 14.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log_code not working with hydra",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-code-not-working-with-hydra\/3276",
        "Question_created_time":"2022-10-18T11:07:01.890Z",
        "Question_answer_count":14,
        "Question_score_count":0,
        "Question_view_count":971,
        "Question_body":"<p>Hello to all,<\/p>\n<p>I am new here.  I would like to  save my files to the wandb experiment .<br>\nThis was also working before I used hydra. Since Hydra is changing the run dir.<br>\nI also adapted the  wandb.run.log_code(root=) to the where files are.<br>\nStill not working.<br>\nHas someone an Idea How to fix it<\/p>\n<p>Thank you very much<br>\nBest regards<br>\nChris<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Experiment tracking for multiple ML models using mlflow in a single main evaluation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/experiment-tracking-for-multiple-ml-models-using-mlflow-in-a-single-main-evaluation\/3340",
        "Question_created_time":"2022-10-28T13:58:30.304Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":355,
        "Question_body":"<p>Could you, in your experience, show an article or an experiment tracking example and only version \u201cMulti-independent models, but one input-&gt; multiple models-&gt; one output\u201d to get a single main score and conveniently compare sub-scores? see an example project in the diagram:<\/p>\n<p><strong><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2d4287f78a095ed787cb30539b2a40edaf8c7aaa.png\" data-download-href=\"\/uploads\/short-url\/6so1LjTa7qTKo5LoyNfMyNuc6vM.png?dl=1\" title=\"\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_602x227.png\" alt=\"\" data-base62-sha1=\"6so1LjTa7qTKo5LoyNfMyNuc6vM\" width=\"602\" height=\"227\" role=\"presentation\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_602x227.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_903x340.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_1204x454.png 2x\" data-dominant-color=\"EBD6DA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\"><\/span><span class=\"informations\">1600\u00d7604 213 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/strong><\/p>\n<p>I understand and tried to use W&amp;B, MLFlow, DVC,  Neptune. ai, DagsHub for only one model, but I\u2019m not sure one is convenient to use for multi-independent models. I also did not find it in Google for the approximate phrase \u201cML tracking experiment and management for multi models\u201d<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding tags cause internal server error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-tags-cause-internal-server-error\/3363",
        "Question_created_time":"2022-11-01T21:33:23.355Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":246,
        "Question_body":"<p>Adding tags to any project in my account will cause an internal server error. Is there an outage or it\u2019s something specific to my account?<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/cchi\/tags_test_project\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/cchi\/tags_test_project\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/7\/7e3d01bfbb9f37b8c9af3076e9688c9bef1b6347.png\" class=\"thumbnail onebox-avatar\" width=\"120\" height=\"120\">\n\n<h3><a href=\"https:\/\/wandb.ai\/cchi\/tags_test_project\" target=\"_blank\" rel=\"noopener\">cchi<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/a924869568d0c7ad73ea9c46361492d6a4827051.png\" data-download-href=\"\/uploads\/short-url\/o8iWO0KA8b01xdqNjqP8vCU1eUh.png?dl=1\" title=\"Screen Shot 2022-11-01 at 5.32.04 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/a924869568d0c7ad73ea9c46361492d6a4827051_2_690x258.png\" alt=\"Screen Shot 2022-11-01 at 5.32.04 PM\" data-base62-sha1=\"o8iWO0KA8b01xdqNjqP8vCU1eUh\" width=\"690\" height=\"258\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/a924869568d0c7ad73ea9c46361492d6a4827051_2_690x258.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/a924869568d0c7ad73ea9c46361492d6a4827051.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/a924869568d0c7ad73ea9c46361492d6a4827051.png 2x\" data-dominant-color=\"FBF3F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-11-01 at 5.32.04 PM<\/span><span class=\"informations\">789\u00d7296 13.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2022-11-02T04:20:49.066Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/cchi\">@cchi<\/a>,<\/p>\n<p>Could you try adding your tags once again? We were running into some site issues earlier today but they should be resolved now.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"W&B Outage? 11\/1\/2022",
        "Question_link":"https:\/\/community.wandb.ai\/t\/w-b-outage-11-1-2022\/3360",
        "Question_created_time":"2022-11-01T20:15:54.242Z",
        "Question_answer_count":7,
        "Question_score_count":3,
        "Question_view_count":110,
        "Question_body":"<p>Hello,<\/p>\n<p>I was wondering if anybody from the W&amp;B team can confirm that there is an outage at the moment.<\/p>\n<p>I\u2019ve been having issues starting runs and it seems like other folks are having issues syncing runs with a network time out error (<a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4424\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: canno't sync my runs \u00b7 Issue #4424 \u00b7 wandb\/wandb \u00b7 GitHub<\/a>). It\u2019s been ongoing for about 2 hours now.<\/p>\n<p>The status page is saying everything is fine - <a href=\"https:\/\/status.wandb.com\" rel=\"noopener nofollow ugc\">https:\/\/status.wandb.com<\/a><\/p>\n<p>All the best,<br>\nAlexey<\/p>",
        "Question_closed_time":"2022-11-01T22:51:30.214Z",
        "Answer_body":"<p>Thank you for your patience! Our engineers were able to push a fix for this. There\u2019s still currently an issue regarding batch moving runs, but for the most part this issue has been resolved.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"InitStartError: Error communicating with wandb process",
        "Question_link":"https:\/\/community.wandb.ai\/t\/initstarterror-error-communicating-with-wandb-process\/3015",
        "Question_created_time":"2022-08-27T12:03:04.434Z",
        "Question_answer_count":33,
        "Question_score_count":0,
        "Question_view_count":756,
        "Question_body":"<p>My code run well on wandb 0.12.21, but after I upgrade to the latest version, my code gave me this error <code>InitStartError: Error communicating with wandb process<\/code>. I tried the solution in the document but it doesn\u2019t work. Code is as shown below.<\/p>\n<pre><code class=\"lang-python\">def k_fold(config, log_folder=None, log_init_info=None):\n    \"\"\"\n    Performs a  k-fold cross validation.\n\n    Args:\n        config (Config): Parameters.\n        log_folder (None or str, optional): Folder to logs results to. Defaults to None.\n        log_init_info (None or dict, optional): Dictionary to init wandb logging.\n    \"\"\"\n    scores = []\n    nb_folds = 5\n\n    # Data preparation\n    print(\"Creating in-memory dataset ...\")\n\n    start_time = time.time()\n\n    in_mem_dataset = InMemoryTrainDataset(\n        train_tile_size=config.tile_size,\n        reduce_factor=config.reduce_factor,\n        train_transfo=HE_preprocess(size=config.tile_size),\n        valid_transfo=HE_preprocess(augment=False, size=config.tile_size),\n        train_path=config.train_path,\n        iter_per_epoch=config.iter_per_epoch,\n        on_spot_sampling=config.on_spot_sampling,\n        pl_path=config.pl_path,\n        use_pl=config.use_pl,\n        test_path=config.test_path,\n    )\n    print(f\"Done in {time.time() - start_time :.0f} seconds.\")\n\n    for i in config.selected_folds:\n        print(f\"\\n-------------   Fold {i + 1} \/ {nb_folds}  -------------\\n\")\n\n        # Init logging\n        if not DEBUG:\n            print(f\"    -&gt; Init wandb logging with name {log_init_info['name_head']}_fold{i + 1} ...\")\n            wandb.init(\n                project=PROJECT_NAME,\n                name=f\"{log_init_info['name_head']}_fold{i + 1}\",\n                config=log_init_info['config'],\n            )\n\n        meter, history, model = train(config, in_mem_dataset, i, log_folder=log_folder)\n\n        print(\"\\n    -&gt; Validating \\n\")\n\n        val_images = in_mem_dataset.valid_set\n        scores += validate(model, config, val_images)\n\n        if log_folder is not None:\n            history.to_csv(log_folder + f\"history_{i}.csv\", index=False)\n\n        if log_folder is None or len(config.selected_folds) == 1:\n            return meter\n\n        if not DEBUG:\n            wandb.finish()\n\n        # Garbage collect\n        del meter\n        del model\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(f\"\\n\\n  -&gt;  Dice CV : {np.mean(scores) :.3f}  +\/- {np.std(scores) :.3f}\")\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WandB and AWS Lambda",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-and-aws-lambda\/3354",
        "Question_created_time":"2022-11-01T07:47:58.824Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":575,
        "Question_body":"<p>We\u2019re trying to run WandB (0.13.4) in an AWS Lambda with Python 3.9.  We have set an environment variable for our API Key.  But we are getting this error message from Lambda:<\/p>\n<pre><code class=\"lang-auto\">{\n  \"errorMessage\": \"Error communicating with wandb process\",\n  \"errorType\": \"UsageError\",\n  \"requestId\": \"0b6c4576-adbe-4182-826a-eca4dd06bc6f\",\n  \"stackTrace\": [\n    \"  File \\\"\/var\/task\/lambda_monitor.py\\\", line 73, in test_harness\\n    run  = wandb.init(project= WB_PROJECT,\\n\",\n    \"  File \\\"\/var\/task\/wandb\/sdk\/wandb_init.py\\\", line 1078, in init\\n    run = wi.init()\\n\",\n    \"  File \\\"\/var\/task\/wandb\/sdk\/wandb_init.py\\\", line 719, in init\\n    raise UsageError(error_message)\\n\"\n  ]\n}\n<\/code><\/pre>\n<p>The calling code is this:<\/p>\n<pre><code class=\"lang-auto\">    run  = wandb.init(project= WB_PROJECT,\n                      id     = WB_RUN_ID,  # We force the run to continue with the specific monitoring Run ID\n                      resume = True,\n                      settings=wandb.Settings(start_method=\"fork\"))\n<\/code><\/pre>\n<p>And this error message from CloudWatch:<\/p>\n<pre><code class=\"lang-auto\">wandb: WARNING Path \/var\/task\/wandb\/ wasn't writable, using system temp directory.\nOpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k\nwandb: WARNING Path \/var\/task\/wandb\/ wasn't writable, using system temp directory\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nTraceback (most recent call last):\nFile \"\/var\/lang\/lib\/python3.9\/runpy.py\", line 197, in _run_module_as_main\nreturn _run_code(code, main_globals, None,\nFile \"\/var\/lang\/lib\/python3.9\/runpy.py\", line 87, in _run_code\nexec(code, run_globals)\nFile \"\/var\/task\/wandb\/__main__.py\", line 3, in &lt;module&gt;\ncli.cli(prog_name=\"python -m wandb\")\nFile \"\/var\/task\/click\/core.py\", line 1130, in __call__\nreturn self.main(*args, **kwargs)\nFile \"\/var\/task\/click\/core.py\", line 1055, in main\nrv = self.invoke(ctx)\nFile \"\/var\/task\/click\/core.py\", line 1657, in invoke\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\nFile \"\/var\/task\/click\/core.py\", line 1404, in invoke\nreturn ctx.invoke(self.callback, **ctx.params)\nFile \"\/var\/task\/click\/core.py\", line 760, in invoke\nreturn __callback(*args, **kwargs)\nFile \"\/var\/task\/wandb\/cli\/cli.py\", line 97, in wrapper\nreturn func(*args, **kwargs)\nFile \"\/var\/task\/wandb\/cli\/cli.py\", line 282, in service\nserver.serve()\nFile \"\/var\/task\/wandb\/sdk\/service\/server.py\", line 142, in serve\nmux.loop()\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 394, in loop\nraise e\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 392, in loop\nself._loop()\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 385, in _loop\nself._process_action(action)\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 350, in _process_action\nself._process_add(action)\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 203, in _process_add\nstream = StreamRecord(action._data, mailbox=self._mailbox)\nFile \"\/var\/task\/wandb\/sdk\/service\/streams.py\", line 61, in __init__\nself._record_q = multiprocessing.Queue()\nFile \"\/var\/lang\/lib\/python3.9\/multiprocessing\/context.py\", line 103, in Queue\nreturn Queue(maxsize, ctx=self.get_context())\nFile \"\/var\/lang\/lib\/python3.9\/multiprocessing\/queues.py\", line 43, in __init__\nself._rlock = ctx.Lock()\nFile \"\/var\/lang\/lib\/python3.9\/multiprocessing\/context.py\", line 68, in Lock\nreturn Lock(ctx=self.get_context())\nFile \"\/var\/lang\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 162, in __init__\nSemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\nFile \"\/var\/lang\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 57, in __init__\nsl = self._semlock = _multiprocessing.SemLock(\nOSError: [Errno 38] Function not implemented\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: \/ Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log configs except for configs that need to be tuned in w&b when I use ray tune for tuning",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-configs-except-for-configs-that-need-to-be-tuned-in-w-b-when-i-use-ray-tune-for-tuning\/3076",
        "Question_created_time":"2022-09-06T19:14:51.603Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":175,
        "Question_body":"<p>Hallo! I want to log some configs that are not for tuning, for example, the name for datasets, and the name for different losses. When I call WandbLoggerCallback in tune.Tuner,  it turns out that only the hyperparameters that it tuned are logged, other configs are not there, even though I have called wandb.config[\u201clossfn\u201d] = \"cross_entropy \" at the beginning.<\/p>\n<p>for example, as you see that there is nothing in the columns dataset and lossfn.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1.jpeg\" data-download-href=\"\/uploads\/short-url\/2KUKjJmSyAImPaso4ffQ0ZnBcsh.jpeg?dl=1\" title=\"Screenshot 2022-09-06 at 21.14.38\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_690x336.jpeg\" alt=\"Screenshot 2022-09-06 at 21.14.38\" data-base62-sha1=\"2KUKjJmSyAImPaso4ffQ0ZnBcsh\" width=\"690\" height=\"336\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_690x336.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_1035x504.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_1380x672.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-09-06 at 21.14.38<\/span><span class=\"informations\">1920\u00d7936 85.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best practice to store data artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/best-practice-to-store-data-artifacts\/3326",
        "Question_created_time":"2022-10-26T06:34:29.132Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":299,
        "Question_body":"<p>What\u2019s best practice for storing data artifacts? Currently we store them as csvs but I was wondering if pickling them makes more sense or if anyone has any experience with the pros and cons of doing that.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Modeling stochastic dorminance",
        "Question_link":"https:\/\/community.wandb.ai\/t\/modeling-stochastic-dorminance\/3324",
        "Question_created_time":"2022-10-26T04:38:29.539Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":79,
        "Question_body":"<p>Modeling stochastic dorminance<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hyperparameter search for RL(stable baseline3)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hyperparameter-search-for-rl-stable-baseline3\/3349",
        "Question_created_time":"2022-10-31T08:26:21.913Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":341,
        "Question_body":"<p>It seems the hyperparameter search guide in documentation is catered for supervised setting. Is there any guide on adapting it to reinforcement learning setting, specifically stable baseline3?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"BUG: Parallel coordinates Panel in Sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-parallel-coordinates-panel-in-sweep\/3318",
        "Question_created_time":"2022-10-25T01:37:25.342Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":294,
        "Question_body":"<p>My Sweep config looks like this:<\/p>\n<pre><code class=\"lang-yaml\">parameters:\n  pretraining_run_name:\n    values: [ns4bedao, 6cnr8gb9, lo4f6pma, qiha6oci]\n<\/code><\/pre>\n<p>As you can see, some of their names start with decimal.<br>\nThis makes the Parallel coordinates Panel broken.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/671538bef4b0651502815871345bf48d5af62323.png\" data-download-href=\"\/uploads\/short-url\/eHUE5Lsun9I9dgN8ekmT7ipoEvN.png?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/671538bef4b0651502815871345bf48d5af62323_2_176x500.png\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11\" data-base62-sha1=\"eHUE5Lsun9I9dgN8ekmT7ipoEvN\" width=\"176\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/671538bef4b0651502815871345bf48d5af62323_2_176x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/671538bef4b0651502815871345bf48d5af62323_2_264x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/671538bef4b0651502815871345bf48d5af62323.png 2x\" data-dominant-color=\"FAF9FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11<\/span><span class=\"informations\">320\u00d7906 34.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Is there any workaround that I can do immediately?<br>\nOr not, I wish this would be fixed as soon as possible.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pattern in semantic mask logging above size (100, 100)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/pattern-in-semantic-mask-logging-above-size-100-100\/3248",
        "Question_created_time":"2022-10-13T10:38:11.125Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":310,
        "Question_body":"<p>When attempting to log masks above size 100 x 100, the masks display a strange pattern. What is the cause of this and is there a way to ensure the pattern does not appear?<\/p>\n<p>Here is a toy example comparing two random images of size (100,100) and (200,200), each with two masks of all 0s and all 1s. This is logged as:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142.jpeg\" data-download-href=\"\/uploads\/short-url\/97K3axa7Ka7PdrF85pXm22No2rw.jpeg?dl=1\" title=\"Screenshot 2022-10-13 at 03.30.15\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_690x414.jpeg\" alt=\"Screenshot 2022-10-13 at 03.30.15\" data-base62-sha1=\"97K3axa7Ka7PdrF85pXm22No2rw\" width=\"690\" height=\"414\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_690x414.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_1035x621.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/3\/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_1380x828.jpeg 2x\" data-dominant-color=\"DBD3DA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-10-13 at 03.30.15<\/span><span class=\"informations\">1920\u00d71152 209 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>These images were generated by the following:<\/p>\n<pre><code class=\"lang-auto\">import numpy as np\nimport wandb\n\nwandb.init()\nsizes = [100,200]\n\nfor size in sizes:\n    name = str(size)\n    image = np.random.randint(low=0, high=256, size=(size, size, 3), dtype=np.uint8)\n    predicted_mask = np.ones((size, size), dtype=np.uint8)\n    ground_truth_mask = np.zeros((size, size), dtype=np.uint8)\n    class_labels = {\n        0: \"class 0\",\n        1: \"class 1\",\n    }\n\n    masked_image = wandb.Image(image, masks={\n        \"predictions\": {\n            \"mask_data\": predicted_mask,\n            \"class_labels\": class_labels\n        },\n        \"ground_truth\": {\n            \"mask_data\": ground_truth_mask,\n            \"class_labels\": class_labels\n        }\n    })\n\n    wandb.log({name : masked_image})\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging with Tensorboard",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-with-tensorboard\/3265",
        "Question_created_time":"2022-10-16T18:59:17.447Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":213,
        "Question_body":"<p>I am trying to run the demo code from <a href=\"https:\/\/colab.research.google.com\/gist\/sayakpaul\/5b31ed03725cc6ae2af41848d4acee45\/demo_tensorboard.ipynb\" rel=\"noopener nofollow ugc\">Demo_tensorboard.ipynb<\/a> so that I can learn more about the use of Tensorboard in combination with W&amp;B. Unfortunately this code throws this warning:<\/p>\n<p>WARNING When using several event log directories, please call <code>wandb.tensorboard.patch(root_logdir=\"...\")<\/code> before <code>wandb.init<\/code><\/p>\n<p>When I implement the suggested change with:<\/p>\n<p><code>wandb.tensorboard.patch(root_logdir=\".\/logs\/debug\")<\/code><\/p>\n<p>I get the following warning:<br>\nFound log directory outside of given root_logdir, dropping given root_logdir for event file in i:\\tinyml\\tiny_cnn\\wandb\\run-20221016_205607-22b9tlzf\\files\\train<\/p>\n<p>So my questions is: What is a suitable root_logdir for Tensorboard?<\/p>\n<p>Thanks for your support.<\/p>",
        "Question_closed_time":"2022-10-17T13:16:21.990Z",
        "Answer_body":"<p>Hi Susanne,<\/p>\n<p>Thanks for writing in! The <code>root_logdir<\/code>argument is the path to the root of all tfevent files, so you can use the wandb project folder (in this case I think it is <code>I:\/tinyml\/tiny_cnn<\/code>). Could you try if setting this solves the issue?<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Workflow for running an ensemble of experiments with different initial conditions",
        "Question_link":"https:\/\/community.wandb.ai\/t\/workflow-for-running-an-ensemble-of-experiments-with-different-initial-conditions\/3074",
        "Question_created_time":"2022-09-06T18:49:16.459Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":207,
        "Question_body":"<p>Any ideas on the right workflow to run sweeps\/groups with a whole bunch of different variations on initial conditions to see an ensemble of results?  I think that the  <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/grouping\" class=\"inline-onebox\">Group Runs - Documentation<\/a>  seems a natural candidate for this but I am not sure the right approach or how it overlays with sweeps in this sort of usecase.<\/p>\n<p>To setup the scenario I have in mind: I have a script  I want to run hundred times on my local machine with pretty much all parameters fixed except the neural network initial conditions.  I can control that by doing things like incrementing a <code>--seed<\/code> argument  or just not establishing a default seed.  After running those experiments, it is nice to see pretty pictures of distribtions in wandb but I also want to be able to later collect the results\/assets as a group. and do things like plot a histogram of <code>val_loss<\/code> to put in a research paper.<\/p>\n<p>Is the way to do this with a combination of sweeps and run_groups?  Forr example, can I run a bunch of these in a sweep with after setting the <code>WANDB_RUN_GROUP<\/code> environment variable?  For example, maybe setup a sweep file like<\/p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">program: train.py\nmethod: grid\nparameters:\n  seed:\n    min: 2\n    max: 102\n<\/code><\/pre>\n<p>Where <code>--seed<\/code> is used internally to set the seed for the experiment?  Any better approaches<\/p>\n<p>If that works, ,  then do I just need to set <code>WANDB_RUN_GROUP<\/code> environment variable on every machine that I will run an agent on and then it can be grouped?  Then I can pull down all of the assets for these with the <code>WAND_RUN_GROUP<\/code>?  I couldn\u2019t figure it out from the docs how to get all of the logged results (and the artifacts if there are any) for a group.<\/p>",
        "Question_closed_time":"2022-09-22T12:46:48.295Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jlperla\">@jlperla<\/a> thank you for the detailed information, and great to hear that the grouping issue has been now resolved. Regarding your question using the API to filter runs, you could do that indeed with the following command:<br>\n<code>runs = api.runs(\"entity\/project\", filters={\"sweep\": \"sweep_id\"})<\/code><br>\nAlternatively you can use <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/tags#how-to-add-tags\">API to tag all your runs<\/a> based on <code>my_sweep_name<\/code> identifier and then query runs as follows:<br>\n<code>runs = api.runs(\"entity\/project\", filters={\"tags\": \"my_sweep_name\"})<\/code><br>\nIs my_sweep_name defined in your config? In that case you could do <code>filters={\"config.sweep_name\": \"my_sweep_name\"}<\/code>.<\/p>\n<p>Would any of these work for you? Please let me know if you have any further questions or issues with this!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Sweep error - AttributeError: 'SettingsStatic' object has no attribute 'git_root'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-error-attributeerror-settingsstatic-object-has-no-attribute-git-root\/3335",
        "Question_created_time":"2022-10-27T21:19:53.478Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":170,
        "Question_body":"<p>When trying to make a new sweep I get the following error<br>\n<code>AttributeError: 'SettingsStatic' object has no attribute 'git_root'<\/code><\/p>\n<p>Seems to be repeated no matter what I try.<br>\nThe full log from <code>debug-internal.log<\/code><\/p>\n<pre><code class=\"lang-bash\">2022-10-27 21:15:00,236 INFO    StreamThr :3165542 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 3165542, started at: 2022-10-27 21:15:00.235637\n2022-10-27 21:15:00,237 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: status\n2022-10-27 21:15:00,374 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: status\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: header\n2022-10-27 21:15:00,376 INFO    WriterThread:3165542 [datastore.py:open_for_write():75] open: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/run-xj06c5a6.wandb\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: run\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [dir_watcher.py:__init__():216] watching files in: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_start_run_threads():928] run started: xj06c5a6 with start time 1666905300.0\n2022-10-27 21:15:00,760 DEBUG   SenderThread:3165542 [sender.py:send():303] send: summary\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_save_file():1171] saving file wandb-summary.json with policy end\n2022-10-27 21:15:00,761 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: check_version\n2022-10-27 21:15:00,761 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: check_version\n2022-10-27 21:15:01,040 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: run_start\n2022-10-27 21:15:01,044 DEBUG   HandlerThread:3165542 [meta.py:__init__():34] meta init\n2022-10-27 21:15:01,381 INFO    WriterThread:3165542 [datastore.py:close():279] close: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/run-xj06c5a6.wandb\n2022-10-27 21:15:01,761 INFO    Thread-14 :3165542 [dir_watcher.py:_on_file_created():275] file\/dir created: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [sender.py:finish():1331] shutting down sender\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [dir_watcher.py:finish():362] shutting down directory watcher\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():392] scan: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json wandb-summary.json\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/config.yaml config.yaml\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [file_pusher.py:finish():168] shutting down file pusher\n2022-10-27 21:15:02,764 INFO    SenderThread:3165542 [file_pusher.py:join():173] waiting for file pusher\n2022-10-27 21:15:04,333 INFO    Thread-19 :3165542 [upload_job.py:push():143] Uploaded file \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/config.yaml\n2022-10-27 21:15:04,349 INFO    Thread-18 :3165542 [upload_job.py:push():143] Uploaded file \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json\n2022-10-27 21:15:04,954 ERROR   StreamThr :3165542 [internal.py:wandb_internal():163] Thread HandlerThread:\nTraceback (most recent call last):\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 130, in handle\n    handler(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 140, in handle_request\n    handler(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 672, in handle_request_run_start\n    run_meta = meta.Meta(settings=self._settings, interface=self._interface)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/meta.py\", line 40, in __init__\n    root=self._settings.git_root,\nAttributeError: 'SettingsStatic' object has no attribute 'git_root'\n<\/code><\/pre>",
        "Question_closed_time":"2022-10-28T07:32:33.022Z",
        "Answer_body":"<p>Hi Leslie,<\/p>\n<p>Found the issue! I was even though I had the correct conda env activated running the <code>wandb sweep<\/code> command with my local new version of wandb while the python code and env where running with and old 12.XX version.<\/p>\n<p>I changed it to use the same install for both and now it works.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Image resolution with log()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/image-resolution-with-log\/3289",
        "Question_created_time":"2022-10-19T17:35:22.619Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":482,
        "Question_body":"<p>We are generating some intricate images and using log() to store those with the run (not to mention trying to add them to a Report).  It has recently become apparent that WandB is downscaling the images when they are logged.  For example, our images are 200DPI, but on viewing them after logging they are 72DPI.<br>\nIs there a way to override this?  I have checked the source for <code>wandb.Image()<\/code> but there is no mention of DPI or resolution.  Its not clear if this is being done by <code>log()<\/code> or by <code>Image()<\/code>.<br>\nThank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Exporting graphs gives different graph datapoints",
        "Question_link":"https:\/\/community.wandb.ai\/t\/exporting-graphs-gives-different-graph-datapoints\/3294",
        "Question_created_time":"2022-10-20T13:16:56.925Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":118,
        "Question_body":"<p>When exporting a line graph to png or svg gives a figure that is different than the actual graph. The final points of each graph should be located at the end of the line of that graph. However, the final points are placed much farther to the right.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The wandb.log function does not treat nested dict as it describes in the document",
        "Question_link":"https:\/\/community.wandb.ai\/t\/the-wandb-log-function-does-not-treat-nested-dict-as-it-describes-in-the-document\/3330",
        "Question_created_time":"2022-10-27T00:42:51.509Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":110,
        "Question_body":"<p>Hi,<\/p>\n<p>I find that using the <code>wandb.log()<\/code> does not work like it describe in the document that<\/p>\n<blockquote>\n<p>Logging nested metrics is encouraged and is supported in the W&amp;B UI. If you log with a nested dictionary like <code>wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}})<\/code> , the metrics will be organized into <code>train<\/code> and <code>val<\/code> sections in the W&amp;B UI.<\/p>\n<\/blockquote>\n<p>Instead, it seems like it will create separate plots with a dot to make different names. In the above sample, it would show me<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/7\/77fb781483d08f4abf148a2abd22caa5c42a5d2b.png\" data-download-href=\"\/uploads\/short-url\/h7pAvZ8ws18O7lJwodYZ0CdnF6X.png?dl=1\" title=\"img1\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/7\/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_690x237.png\" alt=\"img1\" data-base62-sha1=\"h7pAvZ8ws18O7lJwodYZ0CdnF6X\" width=\"690\" height=\"237\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/7\/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_690x237.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/7\/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_1035x355.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/7\/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_1380x474.png 2x\" data-dominant-color=\"FDFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">img1<\/span><span class=\"informations\">2136\u00d7736 31.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nHowever, what I expect is the UI should show me two sections (train and val) and separate \u201cacc\u201d named plots inside. BTW, I know if I use <code>wandb.log({\"train\/acc\": 0.9, \"val\/acc\": 0.9})<\/code> can achieve this functionality.<\/p>\n<p>Any helps would be appreciated!<br>\nThank you!<br>\nDylan<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Stored artifact is not h5 file",
        "Question_link":"https:\/\/community.wandb.ai\/t\/stored-artifact-is-not-h5-file\/3322",
        "Question_created_time":"2022-10-25T14:07:27.698Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":565,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using tensorflow with the python callback. The callback stores several files automatically for each run:<\/p>\n<ul>\n<li>saved_model.pb<\/li>\n<li>keras_metadata.pb<\/li>\n<\/ul>\n<p>I would like to automatically store the weights h5 file as well. Is there an option for this? Do I have to do it manually?<br>\nNote that I can find best-model.h5 in the wand folder of each run, but for some reason it is not uploaded to the server.<\/p>\n<p>Thank you,<br>\nArnaud<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to stop logging locally but only save to wandb's servers and have wandb work using soft links?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links\/3305",
        "Question_created_time":"2022-10-23T23:03:31.012Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":406,
        "Question_body":"<p>I am having a weird issue where I change the location of all my code &amp; data to a different location with more disk space, then I soft link my projects &amp; data to those locations with more space. I assume there must be some file handle issue because wandb\u2019s logger is throwing me issues. So my questions:<\/p>\n<ol>\n<li>how do I have wandb only log  online and not locally? (e.g. stop trying to log anything to <code>.\/wandb<\/code>[or any secret place it might be logging to]  since it\u2019s creating issues). Note my code was running fine after I  stopped logging to wandb so I assume that was the issue. note that the <code>dir=None<\/code> is the default to wandb\u2019s param.<\/li>\n<li>how do I resolve this issue entirely so that it works seemlessly with all my projects softlinked somewhere else?<\/li>\n<\/ol>\n<hr>\n<h1>\n<a name=\"more-details-on-the-error-1\" class=\"anchor\" href=\"#more-details-on-the-error-1\"><\/a>More details on the error<\/h1>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/vendor\/watchdog\/observers\/api.py\", line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/vendor\/watchdog\/observers\/api.py\", line 368, in dispatch_events\n    handler.dispatch(event)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/vendor\/watchdog\/events.py\", line 454, in dispatch\n    _method_map[event_type](event)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/filesync\/dir_watcher.py\", line 275, in _on_file_created\n    logger.info(\"file\/dir created: %s\", event.src_path)\nMessage: 'file\/dir created: %s'\nArguments: ('\/shared\/rsaas\/miranda9\/diversity-for-predictive-success-of-meta-learning\/wandb\/run-20221023_170722-1tfzh49r\/files\/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 130, in handle\n    handler(record)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 138, in handle_request\n    logger.debug(f\"handle_request: {request_type}\")\nMessage: 'handle_request: stop_status'\nArguments: ()\nN\/A% (0 of 100000) |      | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s\/it\n\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_dist_maml_l2l.py\", line 1814, in &lt;module&gt;\n    main()\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_dist_maml_l2l.py\", line 1747, in main\n    train(args=args)\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_dist_maml_l2l.py\", line 1794, in train\n    meta_train_iterations_ala_l2l(args, args.agent, args.opt, args.scheduler)\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/torch_uu\/training\/meta_training.py\", line 167, in meta_train_iterations_ala_l2l\n    log_zeroth_step(args, meta_learner)\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/meta_learning.py\", line 92, in log_zeroth_step\n    log_train_val_stats(args, args.it, step_name, train_loss, train_acc, training=True)\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/supervised_learning.py\", line 55, in log_train_val_stats\n    _log_train_val_stats(args=args,\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/supervised_learning.py\", line 116, in _log_train_val_stats\n    args.logger.log('\\n')\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logger.py\", line 89, in log\n    print(msg, flush=flush)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/redirect.py\", line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced vit_mi Adam_rfs_cifarfs Adam_cosine_scheduler_rfs_cifarfs 0.001: args.jobid=101161: https:\/\/wandb.ai\/brando\/entire-diversity-spectrum\/runs\/1tfzh49r\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\/wandb\/run-20221023_170722-1tfzh49r\/logs\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/router_sock.py\", line 27, in _read_message\n    resp = self._sock_client.read_server_response(timeout=1)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 283, in read_server_response\n    data = self._read_packet_bytes(timeout=timeout)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 269, in _read_packet_bytes\n    raise SockClientClosedError()\nwandb.sdk.lib.sock_client.SockClientClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/router.py\", line 70, in message_loop\n    msg = self._read_message()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/router_sock.py\", line 29, in _read_message\n    raise MessageRouterClosedError\nwandb.sdk.interface.router.MessageRouterClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/logging\/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/threading.py\", line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/router.py\", line 77, in message_loop\n    logger.warning(\"message_loop has been closed\")\nMessage: 'message_loop has been closed'\nArguments: ()\n\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '\/srv\/condor\/execute\/dir_27749\/tmpmvf78q6owandb'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '\/srv\/condor\/execute\/dir_27749\/tmpt5etqpw_wandb-artifacts'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '\/srv\/condor\/execute\/dir_27749\/tmp55lzwviywandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n\/home\/miranda9\/miniconda3\/envs\/metalearning_gpu\/lib\/python3.9\/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '\/srv\/condor\/execute\/dir_27749\/tmprmk7lnx4wandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n<\/code><\/pre>\n<p>cross: <a href=\"https:\/\/stackoverflow.com\/questions\/74175401\/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How to stop logging locally but only save to wandb's servers and have wandb work using soft links? - Stack Overflow<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[Q] Pyinstaller not fetching wandb_gql",
        "Question_link":"https:\/\/community.wandb.ai\/t\/q-pyinstaller-not-fetching-wandb-gql\/3309",
        "Question_created_time":"2022-10-24T05:03:03.585Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":439,
        "Question_body":"<p>I\u2019m checking if pyinstaller package works to binarize a project and to test it, and I\u2019m currently using pieces of code that contain the main functionality and package dependencies to the main project.<\/p>\n<p>To decode into binary through pyinstaller I\u2019m running:<\/p>\n<pre><code class=\"lang-bash\">pyinstaller pyinst_test.py\n<\/code><\/pre>\n<p>And to execute the generated binary:<\/p>\n<pre><code class=\"lang-bash\">$ .\/dist\/pyinst_test\/pyinst_test \n<\/code><\/pre>\n<p>The output of the binary is the following execution error:<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"pyinst_test.py\", line 3, in &lt;module&gt;\n    import wandb\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/__init__.py\", line 26, in &lt;module&gt;\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/sdk\/__init__.py\", line 7, in &lt;module&gt;\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/sdk\/wandb_artifacts.py\", line 30, in &lt;module&gt;\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/apis\/__init__.py\", line 31, in &lt;module&gt;\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/apis\/internal.py\", line 1, in &lt;module&gt;\n  File \"PyInstaller\/loader\/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb\/sdk\/internal\/internal_api.py\", line 1, in &lt;module&gt;\nModuleNotFoundError: No module named 'wandb_gql'\n<\/code><\/pre>\n<p>Is there anyway to use pyinstaller and wandb? Or is recommended another solution to encode wandb code dependencies as binary?<\/p>\n<hr>\n<p><strong>Issue description and steps:<\/strong><\/p>\n<p>tensorflow==2.10.0<br>\nwandb==0.12.20<\/p>\n<p>The baseline code (pyinst_test.py):<\/p>\n<pre><code class=\"lang-python\">import os\nfrom tempfile import mkdtemp\nimport wandb\nimport tensorflow as tf\n\nclass Test:\n    def __init__(self) -&gt; None:\n        wandb_secret_key = \"&lt;wandb_secret_key&gt;\"\n        wandb_entity = \"&lt;wandb_entity&gt;\"\n        wandb_project = \"&lt;wandb_project&gt;\"\n        artifact_name = \"&lt;artifact_name&gt;\"\n        artifact_version = \"&lt;artifact_version&gt;\"\n\n        model_full_path = self._download_artifact(\n            wandb_secret_key = wandb_secret_key,\n            wandb_entity = wandb_entity,\n            wandb_project = wandb_project,\n            artifact_name = artifact_name,\n            artifact_version = artifact_version    \n        )\n        print(f\"[INFO] Model Artifact Directory: {model_full_path}\")\n        model = self._load_tf_model(model_full_path)\n        self._print_model_summary(model)\n\n    def _download_artifact(\n        self,\n        wandb_entity: str,\n        wandb_project: str,\n        artifact_name: str,\n        artifact_version: str):\n\n        api = wandb.Api()\n        artifact = api.artifact(f\"{wandb_entity}\/{wandb_project}\/{artifact_name}:{artifact_version}\")\n        local_download_folder = mkdtemp()\n\n        artifact_dir = artifact.download(local_download_folder)\n        model_full_path = os.path.join(local_download_folder, artifact_dir)\n        return model_full_path\n\n    \n    def _load_tf_model(self, model_path: str):\n        model = tf.keras.models.load_model(model_path)\n        return model\n\n    def _print_model_summary(self, model: tf.keras.models.Model):\n        model.summary()\n\nif __name__ == \"__main__\":\n    test = Test()\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add alias to artifacts linked to a registered model\/collection",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-alias-to-artifacts-linked-to-a-registered-model-collection\/3237",
        "Question_created_time":"2022-10-11T02:16:27.885Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":141,
        "Question_body":"<p>I can update the aliases of an artifact that is not linked to a registered model in the following manner:<\/p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity\/project\/artifact:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>However, I  cannot update an artifact linked to a registered model\/collection.<\/p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity\/project\/collection:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code class=\"lang-auto\">File \"\/usr\/local\/lib\/python3.8\/dist-packages\/requests\/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https:\/\/api.wandb.ai\/graphql\n<\/code><\/pre>\n<p>The only way to do it is by using the UI and manually adding an alias.<br>\nIs there a way to programmatically update the alias of an artifact in a collection\/registered model?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding Confusion Matrix to report programatically",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-confusion-matrix-to-report-programatically\/3267",
        "Question_created_time":"2022-10-17T06:22:44.533Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":140,
        "Question_body":"<p>We are experimenting with programmatic report generation with WandB.<br>\nI would like to be able to add a Confusion Matrix to a report, but this is not one of the base types (as far as I can tell). Is there a good way to do this?<br>\nI could generate a PNG\/Image and insert it, but I can\u2019t figure out how to add an Image to a report yet (see recent question).  Are there other ways?<br>\nThanks.<\/p>",
        "Question_closed_time":"2022-10-17T14:06:09.169Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kevinashaw\">@kevinashaw<\/a> I am also posting here <a href=\"https:\/\/colab.research.google.com\/drive\/1Fepp-JLFvK-wLL2BZ_BnkCG_fAC6HFbo#scrollTo=An_example_with_all_of_the_blocks_and_panels\" rel=\"noopener nofollow ugc\">this Colab<\/a> and the Python SDK commands of our <a href=\"https:\/\/docs.wandb.ai\/guides\/reports\/edit-a-report#add-plots\">Reports reference docs<\/a> which may be helpful.<\/p>\n<p>The confusion matrix isn\u2019t <a href=\"https:\/\/github.com\/wandb\/wandb\/blob\/main\/wandb\/apis\/reports\/panels.py\" rel=\"noopener nofollow ugc\">currently exposed<\/a> but I have increased this feature requests for our engineering team. We will reach out to you once this is implemented. I hope this helps, please let me know if you have any further questions or issues with the Reports API.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Sweep agents sometimes become extremely slow",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-agents-sometimes-become-extremely-slow\/3171",
        "Question_created_time":"2022-09-22T08:07:59.543Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":542,
        "Question_body":"<p>Hello,<\/p>\n<p>I am running a hyperparameter grid search using sweeps. I launched 4 agents on the same machine but I noticed that after completing one run, one of the agents is struggling with the next run.<\/p>\n<p>This agent seems to be still communicating with <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a>, the updated variable is regularly updated to the current time on the active run, and the agent itself has the same heartbeat as the others.<\/p>\n<p>The agent should be in its 8th run by now, but is only at the second one and only computed two epochs. All runs should take the same amount of time as they have the same number of epochs and model architecture.<\/p>\n<p>The \u201cLogs\u201d panel is also completely blank for this agent. And now that I\u2019m writing this, it seems another agent is starting to slow down.<\/p>\n<p>Also, I had the same issue in the previous sweep, this is the second time I run it with the same configuration. Previously, the issue appeared in the first few runs so I quickly stopped it and ran everything again.<\/p>\n<p>Is it most likely an issue with the CPU resources being not well distributed (all threads are at 100% usage), or could it be a network issue? How can I investigate what\u2019s happening?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Confusion matrix not generating \"Custom chart\" entry",
        "Question_link":"https:\/\/community.wandb.ai\/t\/confusion-matrix-not-generating-custom-chart-entry\/3181",
        "Question_created_time":"2022-09-25T06:38:12.866Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":442,
        "Question_body":"<p>I\u2019m using the following code (based on <code>wandb.plot.confusion_matrix<\/code> because I accumulate my own confusion matrix per step using <code>tf.math.confusion_matrix<\/code>) to log a confusion matrix:<\/p>\n<pre><code class=\"lang-auto\"> data = []\n for i in range(n_classes):\n     for j in range(n_classes):\n         data.append([class_names[i], class_names[j], value[i, j]])\n\n fields = {\n     \"Actual\": \"Actual\",\n     \"Predicted\": \"Predicted\",\n     \"nPredictions\": \"nPredictions\",\n }\n return wandb.plot_table(\n     \"wandb\/confusion_matrix\/v1\",\n     wandb.Table(columns=[\"Actual\", \"Predicted\", \"nPredictions\"], data=data),\n     fields,\n     {\"title\": title},\n )\n<\/code><\/pre>\n<p>On one run I did get the custom chart, but the \u201cActual\u201d labels (on the Y-axis) were horribly laid out so I tweaked the code to generate different labels and now I don\u2019t see the custom chart. I tried to create my own custom chart cloning the settings from the other confusion matrix, but the \u201cOK\u201d button is grayed out.<\/p>\n<p>Are there some extra checks somewhere that decide whether or not to generate a confusion matrix report?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" data-download-href=\"\/uploads\/short-url\/uvRybQw5OBb0uSf32Wb66ffRbFV.png?dl=1\" title=\"Screen Shot 2022-09-25 at 4.30.45 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" alt=\"Screen Shot 2022-09-25 at 4.30.45 pm\" data-base62-sha1=\"uvRybQw5OBb0uSf32Wb66ffRbFV\" width=\"183\" height=\"500\" data-dominant-color=\"272727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.30.45 pm<\/span><span class=\"informations\">268\u00d7732 9.57 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d.jpeg\" data-download-href=\"\/uploads\/short-url\/12g1yYFJCC60Ln7oWdZARFbh57v.jpeg?dl=1\" title=\"Screen Shot 2022-09-25 at 4.34.29 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg\" alt=\"Screen Shot 2022-09-25 at 4.34.29 pm\" data-base62-sha1=\"12g1yYFJCC60Ln7oWdZARFbh57v\" width=\"690\" height=\"333\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1035x499.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1380x666.jpeg 2x\" data-dominant-color=\"252525\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.34.29 pm<\/span><span class=\"informations\">2934\u00d71418 140 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pulling artifact metadata into report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/pulling-artifact-metadata-into-report\/3201",
        "Question_created_time":"2022-09-29T19:01:58.863Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":619,
        "Question_body":"<p>Is there a way to pull artifact metadata into reports? Here is my use case:<\/p>\n<p>I have several datasets that I use for evaluation of my model. They are stored as input artifacts and have metadata associated with them for example data type, source, and size. I would like to put a table in my report which outlines the size and type of each dataset, and ideally, could perform excel-like operations on the table (e.g. to sum the sizes of each dataset to create a total, or to get a label distribution).<\/p>\n<p>Right now I build these tables manually but it is error prone and time consuming. Here is an example:<\/p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>Dataset<\/th>\n<th>Size<\/th>\n<th>Sources<\/th>\n<th>% Positive Class<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>A<\/td>\n<td>1333<\/td>\n<td>[\u2018type-1\u2019 \u2018type-2\u2019]<\/td>\n<td>0.63<\/td>\n<\/tr>\n<tr>\n<td>B<\/td>\n<td>13308<\/td>\n<td>[\u2018type-1\u2019 \u2018type-2\u2019 \u2018type-3\u2019]<\/td>\n<td>0.63<\/td>\n<\/tr>\n<tr>\n<td>C<\/td>\n<td>1153<\/td>\n<td>[\u2018type-2\u2019 \u2018type-3\u2019]<\/td>\n<td>0.61<\/td>\n<\/tr>\n<tr>\n<td>D<\/td>\n<td>273<\/td>\n<td>[\u2018type-1\u2019]<\/td>\n<td>0.66<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div><p>Is there any existing way to do this? Or a hack to get something like it?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem of not seeing all the images in media,",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problem-of-not-seeing-all-the-images-in-media\/3292",
        "Question_created_time":"2022-10-20T12:02:26.925Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":587,
        "Question_body":"<p>In the workspace\/images, i am only seeing 30 images, when with oldest images getting deleted every time. Is there any limits that this images slot can show? If yes, is there any way that i can see more images that is saved on locally saved log folder??<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.Html() not displaying",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-html-not-displaying\/3271",
        "Question_created_time":"2022-10-18T04:55:19.749Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":309,
        "Question_body":"<p>I\u2019m trying to display a block of text (a confusion matrix actually, since they do not display in WB) using HTML.<br>\nThe code runs but it will not show up on run panel.  How can i see it?  It seems only images will display.<\/p>\n<pre><code class=\"lang-auto\">wandb.log({f\"ConfMatrix\" : wandb.Html(\"&lt;tt&gt;\"+my_confusion_matrix.ai2_confusion_matrix(y_true, y_pred...).replace(\"\\n\", \"&lt;P&gt;\").replace(\" \", \"&amp;nbsp;\"))})\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Support for ComplexFloat",
        "Question_link":"https:\/\/community.wandb.ai\/t\/support-for-complexfloat\/3279",
        "Question_created_time":"2022-10-18T17:44:07.645Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":133,
        "Question_body":"<p>Python 3.9.7<br>\nWandb 0.13.4<br>\nPytorch 1.12.0+cu116<\/p>\n<p>I am running a neural network over complex valued data and getting the following error:<\/p>\n<pre><code class=\"lang-python\">Traceback (most recent call last):\n  File \"\/home\/aclifton\/rf_fp\/run_training_w_evaluate.py\", line 523, in &lt;module&gt;\n    run_training_pipeline(tmp_dict)\n  File \"\/home\/aclifton\/rf_fp\/run_training_w_evaluate.py\", line 229, in run_training_pipeline\n    outputs = rffp_model(**batch)\n  File \"\/home\/aclifton\/anaconda3\/envs\/rffp\/lib\/python3.9\/site-packages\/torch\/nn\/modules\/module.py\", line 1151, in _call_impl\n    hook_result = hook(self, input, result)\n  File \"\/home\/aclifton\/anaconda3\/envs\/rffp\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 110, in &lt;lambda&gt;\n    lambda mod, inp, outp: parameter_log_hook(\n  File \"\/home\/aclifton\/anaconda3\/envs\/rffp\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 105, in parameter_log_hook\n    self.log_tensor_stats(data.cpu(), \"parameters\/\" + prefix + name)\n  File \"\/home\/aclifton\/anaconda3\/envs\/rffp\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 221, in log_tensor_stats\n    tmin = flat.min().item()\nRuntimeError: \"min_all\" not implemented for 'ComplexFloat'\n<\/code><\/pre>\n<p>I\u2019m not quite sure what to make of it and was wondering if anyone could offer some advice? Thanks in advance for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Confusion Matrix generates report not plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/confusion-matrix-generates-report-not-plot\/3270",
        "Question_created_time":"2022-10-18T03:50:14.660Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":442,
        "Question_body":"<p>I\u2019ve recently attempted to build a Confusion Matrix using the <code>wandb.plot.confusion_matrix()<\/code> command.<br>\nMuch to my surprise, I get a Table object, not a plot.<br>\nImagine my surprise when I discovered a comment (<a href=\"https:\/\/community.wandb.ai\/t\/wandb-plot-confusion-matrix-just-show-a-table\/1744\">here<\/a>) saying \u201cLogging the Table also is expected behaviour\u201d.<br>\nReally?  If I wanted a Table, i would call <code>wand.table.confusion_matrix()<\/code>, not the <code>plot<\/code> command.<br>\nI really do want a plot and and do NOT want to \u201cinteractively explore\u201d it.  I want to see it along with the twenty other plots that I generate with this run.  Clicking each and every CM to view it kinda defeats the purpose.<br>\nI would like to recommend that this choice be rethought, or at least put in the <code>table<\/code> namespace.<br>\nIs there a way to generate a real CM plot?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"There is not history when logging wandb.plot.bar?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/there-is-not-history-when-logging-wandb-plot-bar\/3203",
        "Question_created_time":"2022-09-30T05:19:45.654Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":223,
        "Question_body":"<p>Hi,<br>\nI want to use wandb.plot.bar to log a bar chart, with below code<\/p>\n<pre><code class=\"lang-auto\">    table_data = some_function_to_get_data()\n    table = wandb.Table([\"label\", \"value\"], table_data)\n    wandb.log(\n        {\"a_bar_chart\": wandb.plot.bar(table, \"label\", \"value\")}, step=global_step,\n    )\n<\/code><\/pre>\n<p>There are two problems:<\/p>\n<ol>\n<li>there is no bar plot shown in browser, I need to create the a chart and custom it to bar, this is a little weird in the sense that I already told wandb to log a bar, but it does not do it by default<\/li>\n<li>there is no history of the bar chart, only the current bar chart, as we are <strong>logging<\/strong> the bar chart, I suppose I can see the history of bar chart, that\u2019s how we call it a log right?  So we should able to see the history of both table and bar chart during training.<\/li>\n<\/ol>\n<p>Maybe I did something wrong?<br>\nBTW, I know I can achieve what I want by using matplotlib and log the figure, but I prefer using wandb.pot, as this allows to free of worrying about create and delete the figure object.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scaling in the parelles coordinates plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/scaling-in-the-parelles-coordinates-plot\/3274",
        "Question_created_time":"2022-10-18T08:54:08.386Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":331,
        "Question_body":"<p>Hi,<\/p>\n<p>I want to have custom value ranges for my hyperparameters, for example, for all GCN layers, I want it to range from 0 to 500.  I also want accuracy to range from 0-100. Would this be possible in the plot?<\/p>\n<p>Thanks.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/2fa3a6c300fee74cd3820b8960ba4c2c662641ce.jpeg\" data-download-href=\"\/uploads\/short-url\/6Nr3SOp7uDdsYf6W6V2DDTkiMsS.jpeg?dl=1\" title=\"Screen Shot 2022-10-18 at 7.52.00 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_690x224.jpeg\" alt=\"Screen Shot 2022-10-18 at 7.52.00 pm\" data-base62-sha1=\"6Nr3SOp7uDdsYf6W6V2DDTkiMsS\" width=\"690\" height=\"224\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_690x224.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_1035x336.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_1380x448.jpeg 2x\" data-dominant-color=\"EABFC3\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-10-18 at 7.52.00 pm<\/span><span class=\"informations\">1574\u00d7512 141 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem with Sweep; how to use run.finish() and log without error + Question about defined metric",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problem-with-sweep-how-to-use-run-finish-and-log-without-error-question-about-defined-metric\/3260",
        "Question_created_time":"2022-10-16T05:44:58.604Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":520,
        "Question_body":"<p>Hi all,<\/p>\n<p>Nice to meet you!<\/p>\n<p>Currently I\u2019m not understanding how to use run.finish() and wandb.init for logging correctly. I\u2019m constantly getting an error when the wandb.agent sweeps to another model configuration. It\u2019s successfully doing the K-fold split, I dont see any errors. But it\u2019s right after the K-fold split  when the now model configuration is applied by the sweep.<\/p>\n<p><strong>Information about my code:<\/strong><br>\nMy code is a bit messy. I think there is no way to use K cross validation from scikitlearn. I\u2019ve tried it many times, but my input and output are (with N = number of datasets):<\/p>\n<p>Input 1: N datasets of 1000 numbers (x-axis)<br>\nInput2 : N datasets of 1000 numbers (y-axis)<br>\nOutput1: 1 number for each N\u2019th dataset<br>\nOutput2: 1 number for each N\u2019th dataset<\/p>\n<p>Input 1 and 2 are concatenated to produce 2 outputs. Lets say N is 300 and split is 0.2 then:<br>\nOutput1.shape, Output2.shape, Output1_test.shape, Output2_test.shape, X.shape, Y.shape, X_test.shape, Y_test.shape<\/p>\n<p>In the same order, their shapes: ((240,), (240,), (60,), (60,), (240, 1000), (240, 1000), (60, 1000), (60, 1000))<br>\nI think there is just no way I can define the cross validation with sklearn with this type of data I think\u2026<\/p>\n<p><strong>Error<\/strong><br>\nI\u2019ve introduced to save to model each time it\u2019s configured. Then load the model in each for loop with zero weigths. This way may cross validation succeeds. However, I\u2019m not sure how to correctly log my files. This code is doing bad at producing the groups I want them to be in; it\u2019s just overwriting them. Also, and as I mentioned; every time when a new model is initiated by the sweep, I get and error:<\/p>\n<p><strong>display<\/strong><\/p>\n<pre><code class=\"lang-auto\">wandb: Sweep Agent: Waiting for job.\nwandb: Job received.\nwandb: While tearing down the service manager. The following error has occured: [WinError 10054] De externe host heeft een verbinding verbroken\nwandb: Agent Starting Run: ekc1s4gm with config:\nwandb: \tbatch_size: 6\nwandb: \tdense_units: 63.48472025895866\nwandb: \tdense_units2: 81.47931201263756\nwandb: \tlearning_rate: 0.0007466619646085462\nwandb: \tnum_layers: 10\nwandb: \toptimizer: Adam\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\n\nException in thread ChkStopThr: \n.....\nSome file information\n.....\n\nException in thread NetStatThr::\n.....\nSome file information\n.....\n\nEnding in: \n\nConnectionResetError: [WinError 10054] De externe host heeft een verbinding verbroken\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] De externe host heeft een verbinding verbroken\n<\/code><\/pre>\n<p>So when this error occurs, it just continues right after  it created the new model configuration. The last time this error occurs is when the last loop and last model gets evaluated.  Also this error occurs every loop<\/p>\n<blockquote>\n<p>wandb: WARNING Ignored wandb.init() arg project when running a sweep.<\/p>\n<\/blockquote>\n<p>I think it definitely has to do something with the Groups I want certain logs to be in and therefore also my run.finish() command (<strong>The error does not error without any wandb.init()!!! The error also occurs with just the wandb.init() in the for loop, also if I add this, each sweep is overwritten by the other sweep so it\u2019s not creating groups aswell!!<\/strong>.  I\u2019m unsure if I placed them correctly.  it sounded logical to me to define run just once and to have to others as just wandb.init()\u2026  (see me code). I just don\u2019t understand how to use it in this case\u2026  I hope you do ? <strong>How can I group my folds and my validation seperately without  using wandb.init()<\/strong> ? Any recommendations on this would be very welcome!<\/p>\n<p><strong>My code<\/strong><br>\nHere is my code\u2026 A little messy, sorry.<\/p>\n<pre><code class=\"lang-auto\">def seed_all(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">def build_model(config):\n  \n    activ = config.activation   \n    dense_units = config.dense_units  \n    dense_units2 = config.dense_units2\n    num_layers = config.num_layers\n    batch_size = config.batch_size\n    batch_norm = False\n    optimizer = config.optimizer\n    learning_rate = config.learning_rate\n    \n    x = tf.keras.layers.Concatenate()([input1, input2])\n                   \n        #input_layer = Input(shape=(len(norm_train_X .columns), len(norm_train_X.iloc[0][0]))\n    x = Dense(units=dense_units, activation=activ)(x)\n        \n    for _ in range(num_layers):\n        x = Dense(units=dense_units, activation=activ)(x)\n        \n        \n    x1 = Dense(units=dense_units2, activation=activ)(x)\n    \n        # Y1 output will be fed directly from the second dense\n    \n    y1_output = Dense(units='1', name='y1_output')(x1)\n\n    third_dense = Dense(units=dense_units2, activation=activ)(x1)\n\n         # Y2 output will come via the third dense\n    y2_output = Dense(units='1', name='y2_output')(third_dense)\n        \n    model = Model(inputs=[input1, input2], outputs=[y1_output, y2_output])\n    print(model.summary())   \n    model.save_weights('model.h5', overwrite = True)\n    return model\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">def train():\n    test_loss_sum =np.array([0])\n    Hp_loss_sum = np.array([0])\n    MDp_loss_sum = np.array([0])\n    Hp_rmse_sum = np.array([0])\n    MDp_rmse_sum = np.array([0])\n    loss_sum = np.array([0])\n    loss_sum_tot =0 \n    Hp_R2_append = []\n    test_loss_sum_tot =0\n    hp_append = []\n    MDp_append = []\n    hp_pred_append = []\n    MDp_R2_append = []\n    MDp_sum = 0\n    Hp_sum = 0\n    test_loss_mean = 0 \n    hp_pred_append = []\n    MDp_pred_append = []\n    Hp_loss_sum_tot = 0\n    MDp_loss_sum_tot =0\n    Hp_rmse_sum_tot =0\n    MDp_rmse_sum_tot=0\n    \n    X = np.vstack(np.asarray(norm1.numpy()[:]))\n    Y = np.vstack(np.asarray(norm2.numpy()[:]))\n    max_trials = 2\n    epochs = 100\n    test_loss_sum = np.array([0])\n    Hp = train_Y_1_t\n    MDp = train_Y_2_t\n    Hp_test = test_Y_1_t\n    MDp_test = test_Y_2_t\n    hyperparams = dict(\n        lr = 0.0001,\n        optimizer = 'Adam',\n        dense_units = 256,\n        batch_size = 64,\n        epochs = 1,        \n        ense_units2 = 64,\n        activation = 'relu',)\n    \n    cb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor = \"val_loss\",\n        mode = 'auto',\n        factor = 0.1,\n        patience = 20,\n        min_delta = 1e-04, #default\n        min_lr = 1e-07,\n        verbose = 1)\n\n    cb_earlystop= tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"auto\",\n        min_delta = 0,\n        patience=25,\n        verbose=1)\n    \n    run = wandb.init(project=\"custom-charts\", config=hyperparams, reinit = True) #Note the Reinit here!\n    config = wandb.config\n    \n    Wandcalback = WandbCallback(monitor='val_loss')\n    \n    model =  build_model(config=config)\n    \n    LR = config.learning_rate     # 0.001\n    \n    if config.optimizer=='Adam':\n        optimizer = tf.keras.optimizers.Adam(lr = LR)\n    elif config.optimizer=='RMSprop':\n        optimizer = tf.keras.optimizers.RMSprop(lr=LR, rho=0.9, epsilon=1e-08, decay=0.0)\n    else: \n        raise\n    \n    # Compile the model\n    model.compile(optimizer=optimizer,\n    loss={'y1_output': 'mse', 'y2_output': 'mse'},\n    metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError(),'y2_output': tf.keras.metrics.RootMeanSquaredError()})\n   \n    n_splits = 4\n    skf = KFold(n_splits, shuffle = True)\n    skf.get_n_splits(X, Y)\n    i=0\n    vall_loss = []\n    for train_index, test_index in skf.split(X, Y):\n        \n        wandb.init(project=\"custom-charts\", group = \"folds_experiment\", job_type = \"fold{}\".format(i)) \n        model.load_weights('model.h5')\n        \n        train_index = train_index.astype(int)\n        test_index = test_index.astype(int)\n        X = np.array(X)\n        Y = np.array(Y)\n        Hp = np.array(Hp)\n        MDp = np.array(MDp)\n        X_train, X_test = X[train_index], X[test_index]\n        Y_train, Y_test = Y[train_index], Y[test_index]\n        Hp_train, Hp_test = Hp[train_index], Hp[test_index]\n        MDp_train, MDp_test = MDp[train_index],MDp[test_index]      \n        \n        history = model.fit([tf.convert_to_tensor(X), tf.convert_to_tensor(Y)], [Hp, MDp], validation_data = ([tf.convert_to_tensor(X_test), tf.convert_to_tensor(Y_test)], [Hp_test, MDp_test]), \n                     batch_size=config.batch_size,    \n                     epochs=2,             \n                     callbacks=[Wandcalback,cb_earlystop,cb_reducelr],\n                     verbose=1)\n        \n        loss_sum = pd.DataFrame(history.history)['loss'].iloc[-1]  + loss_sum\n        test_loss_sum = pd.DataFrame(history.history)['val_loss'].iloc[-1]  + test_loss_sum\n        Hp_loss_sum = pd.DataFrame(history.history)['val_y1_output_loss'].iloc[-1]  + Hp_loss_sum\n        MDp_loss_sum = pd.DataFrame(history.history)['val_y2_output_loss'].iloc[-1]  + MDp_loss_sum\n        Hp_rmse_sum = pd.DataFrame(history.history)['val_y1_output_root_mean_squared_error'].iloc[-1]  + Hp_rmse_sum\n        MDp_rmse_sum = pd.DataFrame(history.history)['val_y2_output_root_mean_squared_error'].iloc[-1]  + MDp_rmse_sum\n            \n        loss_sum_tot = pd.DataFrame(history.history)['loss']  + loss_sum_tot\n        test_loss_sum_tot = pd.DataFrame(history.history)['val_loss']  + test_loss_sum_tot\n        Hp_loss_sum_tot = pd.DataFrame(history.history)['val_y1_output_loss'] +  Hp_loss_sum_tot\n        MDp_loss_sum_tot = pd.DataFrame(history.history)['val_y2_output_loss']  + MDp_loss_sum_tot\n        Hp_rmse_sum_tot = pd.DataFrame(history.history)['val_y1_output_root_mean_squared_error']  +  Hp_rmse_sum_tot\n        MDp_rmse_sum_tot = pd.DataFrame(history.history)['val_y2_output_root_mean_squared_error']  +  MDp_rmse_sum_tot   \n\n        Y_pred = model.predict([tf.convert_to_tensor(X_test), tf.convert_to_tensor(Y_test)])\n        metric = tfa.metrics.r_square.RSquare()\n            \n        metric.update_state(Hp_test, Y_pred[0].flatten())\n        result = metric.result()\n        R_2_Hp = result.numpy()\n        Hp_R2_append.append(R_2_Hp)\n           \n        metric.update_state(MDp_test, Y_pred[1].flatten())\n        result = metric.result()\n        R_2_MDp = result.numpy()\n        MDp_R2_append.append(R_2_MDp)\n        \n        hp_append.append(Hp_test)\n        MDp_append.append(MDp_test)\n        hp_pred_append.append(Y_pred[0])\n        MDp_pred_append.append(Y_pred[1])\n        MDp_sum = MDp_sum + Y_pred[1]\n        Hp_sum = Hp_sum + Y_pred[0]\n        i = i + 1 \n    \n    test_loss_mean = test_loss_sum\/n_splits\n    loss_sum_mean = loss_sum\/n_splits\n    test_loss_sum_mean =  test_loss_sum\/n_splits\n    Hp_loss_sum_mean = Hp_loss_sum\/n_splits\n    MDp_loss_sum_mean = MDp_loss_sum\/n_splits\n    Hp_rmse_sum_mean = Hp_rmse_sum\/n_splits\n    MDp_rmse_sum_mean = MDp_rmse_sum\/n_splits\n         \n    test_MDp_R2 = np.mean(MDp_R2_append)\n    test_Hp_R2 = np.mean(Hp_R2_append)\n                \n        \n    Hp_mean = Hp_sum\/n_splits\n    MDp_mean = MDp_sum\/n_splits    \n        # wandb.init(project= \"sweep &amp; optimalisation RandomSearch\", group=\"experimentfold{}\".format(i), job_type=\"validation\")\n    wandb.init(project=\"custom-charts\", group =\"folds_experiment\", job_type = \"validation\")\n    for val_los in range(len(test_loss_sum_tot)):\n        wandb.log({\"val_loss_mean\" : test_loss_sum_tot[val_los]\/n_splits})\n    for loss in range(len(loss_sum_tot)):\n        wandb.log({\"loss_mean\": loss_sum_tot[loss]\/n_splits})\n    for val_MDp_los in range(len(test_loss_sum_tot)):\n        wandb.log({\"val_MDp_loss_mean\" : test_loss_sum_tot[val_MDp_los]\/n_splits})\n    for val_hp_los in range(len( Hp_loss_sum_tot)):\n        wandb.log({\"val_hp_loss_mean\": Hp_loss_sum_tot[val_hp_los]\/n_splits})\n    for val_MDp_rmse in range(len(MDp_rmse_sum_tot)):\n        wandb.log({\"val_MDp_rmse_mean\" : MDp_loss_sum_tot[val_MDp_rmse]\/n_splits})\n    for val_hp_rmse in range(len(Hp_rmse_sum_tot)):\n        wandb.log({\"val_MDp_rmse_mean\": Hp_rmse_sum_tot[val_hp_rmse]\/n_splits})\n       \n    hp_append = np.concatenate(hp_append)\n    MDp_append = np.concatenate(MDp_append)\n    hp_pred_append = np.concatenate(hp_pred_append)\n    MDp_pred_append = np.concatenate(MDp_pred_append)\n            \n    Hp_score = np.sqrt(mean_squared_error(hp_pred_append,hp_append))\n    MDp_score = np.sqrt(mean_squared_error(MDp_pred_append,MDp_append))  \n    test_MDp_R2 = np.mean(MDp_R2_append)\n    test_Hp_R2 = np.mean(Hp_R2_append)\n        \n    wandb.log({\"R2_score_hp\":Hp_score, \"R2_score_MDp\":MDp_score, \"R2_hp\":test_Hp_R2, \"R2_MDp\":test_MDp_R2})\n    Hp = np.asarray(Hp_mean.flatten())\n    MDp = np.asarray(MDp_mean.flatten())\n    Hp_testt = np.asarray(Hp_test.flatten())\n    MDp_testt = np.asarray(MDp_test.flatten())\n        \n        \n    fd = pd.DataFrame({\"pred\": Hp,\"actual\":Hp_testt})\n    print(fd)\n    table = wandb.Table(dataframe=fd)\n    wandb.log({'scatter-plot1': wandb.plot.scatter(table, \"pred\", \"actual\")})\n        \n    fd2 = pd.DataFrame({\"pred\": MDp,\"actual\":MDp_testt})\n    print(fd2)\n    table2 = wandb.Table(dataframe=fd2)\n    wandb.log({'scatter-plot2': wandb.plot.scatter(table2, \"pred\", \"actual\")})\n        \n    predictions_h = [s for s in Hp_mean]\n    predictions_h\n    table2 = wandb.Table(data=predictions_h, columns=[\"h_predictions\"])\n    wandb.log({'my_histogramM': wandb.plot.histogram(table2, \"h_predictions\",\n    title=\"Prediction Score Distribution Hubble Parameter\")})\n        # hist = np.histogram(predictions_h)\n        # wandb.log({'Hubble parameter': wandb.plot.histogram(hist)})\n        \n        \n    predictions_hh = [ s for s in MDp_mean]\n    predictions_hh\n    table3 = wandb.Table(data=predictions_hh, columns=[\"h_predictions\"])\n    wandb.log({'my_histogram': wandb.plot.histogram(table3, \"h_predictions\",\n    title=\"Prediction Score Distribution Mass Density\")})\n        # hist = np.histogram(predictions_hh)\n        # wandb.log({'Mass Density parameter': wandb.plot.histogram(hist)})\n    run.finish()\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">sweep_config = {\n    'method': 'random',         \n    'metric': {\n        'name': 'test_loss_mean',     \n        'goal': 'minimize'      \n    },\n    'parameters': {\n        'dense_units': {\n            'distribution': 'log_uniform_values',\n            'min': 32,\n            'max': 256\n        },\n        'learning_rate': {\n            'distribution': 'log_uniform_values',\n            'min': 0.0000001,\n            'max': 0.1\n        },\n        'dense_units2': {\n            'distribution': 'log_uniform_values',\n            'min': 32,\n            'max': 256\n        },\n        'batch_size': {\n            #Integers between 32 and 256 \n            # with evenly distributed logarithms\n            'values': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n               \n        },\n        'optimizer': {\n            'values': ['Adam', 'RMSprop']\n        },\n        'num_layers': {\n            'values': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n        }\n\n    }\n}\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep_config, entity=\"stijnvdbosch\", project=\"custom-charts\")\nwandb.agent(sweep_id, function=train, count=2, project=\"custom-charts\")\n<\/code><\/pre>\n<p>You can also see i\u2019m updating my own <strong>defined metric<\/strong> (not from model.fit) called <strong>test_loss_mean<\/strong>. I suppose I did that correct?<br>\nIf there is any more information you need to help me, then, please, send  me a message and I will reply in a blink. <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/blush.png?v=12\" title=\":blush:\" class=\"emoji\" alt=\":blush:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Very Slow UI - How to bulk delete charts?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/very-slow-ui-how-to-bulk-delete-charts\/3183",
        "Question_created_time":"2022-09-25T22:14:37.344Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":1007,
        "Question_body":"<p>I\u2019ve been using W&amp;B for 1.5 years and this is the first time I am running into a problem. This problem is very serious and I can\u2019t access any of my runs.<\/p>\n<p>The UI is very slow because there are 129 charts that were created automatically in my charts section of my project.<\/p>\n<p>I am confused because I did not manually create these 129 charts, they were automatically created when I completed my run.<\/p>\n<p>It takes over 5 minutes to open a run from the table, then when I go to the charts section, it takes almost 10 minutes to delete 1 of the 129 charts.<\/p>\n<p>The whole entire UI is completely freezing and slow because of this. When I delete the charts section, all 129 charts go to the Hidden Charts section, and I cant delete that section at all.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Some clarification about W&B starter-plan pricing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/some-clarification-about-w-b-starter-plan-pricing\/3227",
        "Question_created_time":"2022-10-07T16:51:21.915Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":182,
        "Question_body":"<p>Hello everyone! I\u2019m currently evaluating W&amp;B as experiment tracking solution for the company I\u2019m currently working. So far, we found that W&amp;B cover all our basic needs so we would like to buy a starter plan. However before to move on,  I need some clarifications about the pricing that are not so clear from the info available on the website:<\/p>\n<ul>\n<li>\n<p>Tracked Hours:  for tier 1 plan there are 250 to 5000 cumulative tracked hours. These are counted per-user or shared by all the user of the team? In other words, can each user track up to 5000 hours of experiments each month? It seems to be a little bit confusing since the the bill is specified per user.<\/p>\n<\/li>\n<li>\n<p><a href=\"https:\/\/wandb.ai\/site\/pricing#lineage-tracking\">Storage\/Artifacts<\/a>: these 100GB of storage should be intended as shared between Storage &amp; Artifacts or there are a total of 200gb (100+100) of storage for each objects category. By the way, what is considered \u201cfiles saved to W&amp;B\u201d? Tracked metrics\/distributions\/parameters are included in this category?<\/p>\n<\/li>\n<\/ul>\n<p>Sorry for the silly questions but we want to be extra sure before to buy a license <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AttributeError with sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/attributeerror-with-sweep\/3221",
        "Question_created_time":"2022-10-05T11:21:21.823Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":305,
        "Question_body":"<p>When I activated my sweep agent, I got AttributeError as following:<\/p>\n<p>Thread HandlerThread:<br>\nTraceback (most recent call last):<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\u201d, line 50, in run<br>\nself._run()<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\u201d, line 101, in _run<br>\nself._process(record)<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal.py\u201d, line 263, in _process<br>\nself._hm.handle(record)<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\u201d, line 130, in handle<br>\nhandler(record)<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\u201d, line 140, in handle_request<br>\nhandler(record)<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\u201d, line 666, in handle_request_run_start<br>\nself._system_stats = stats.SystemStats(<br>\nFile \u201c\/home1\/prof\/jeon\/anaconda3\/envs\/deep\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/stats.py\u201d, line 76, in <strong>init<\/strong><br>\nself._pid = settings._stats_pid<br>\nAttributeError: \u2018SettingsStatic\u2019 object has no attribute \u2018_stats_pid\u2019<\/p>\n<p>However, the code \u2018main.py\u2019 is ran correctly without sweep\u2026<br>\nHow can I fix this issue so I can use sweep agent?<br>\nI do really appreciate your help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ConnectionResetError appearing while i am training due to wandb run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/connectionreseterror-appearing-while-i-am-training-due-to-wandb-run\/3210",
        "Question_created_time":"2022-10-01T22:14:58.353Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":169,
        "Question_body":"<p>Hi all,<br>\nI am facing a problem while I am training my model.<br>\nthe training crashed due to wandb run.<br>\ncould anyone explain why this error happened and how can I avoid it.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/0169513adb7250af5ca174ac97243b8fdc0e5c6a.jpeg\" alt=\"Capture.PNG\" data-base62-sha1=\"cu7muubyTNVdJjnHUpHxiUChdM\" width=\"690\" height=\"360\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Deleting data from self-hosted server",
        "Question_link":"https:\/\/community.wandb.ai\/t\/deleting-data-from-self-hosted-server\/2613",
        "Question_created_time":"2022-06-15T14:29:55.067Z",
        "Question_answer_count":13,
        "Question_score_count":3,
        "Question_view_count":1260,
        "Question_body":"<p>I saw <a href=\"https:\/\/community.wandb.ai\/t\/delete-files-from-a-run\/1031\">this<\/a> post, but it doesn\u2019t answer my question. We are running a self-hosted wandb instance. We have somewhat limited space, though we\u2019ve been good about deleting old runs through the interface.<\/p>\n<p>We thought deleting from the interface would also delete the physical files from the hard disk, but that doesn\u2019t appear to be the case. For example, going into the minio folder on the server shows a particular project taking up 130 GB of space, while wandb reports 30 GB. That\u2019s a big difference!<\/p>\n<p>How do we really really delete files from minio that wandb no longer knows anything about?<\/p>\n<p>Suggestion: please have a central <code>\/usage\/<\/code> URL for admins to look through usage from all teams and users rather than having to go through each one individually!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Continuing an artifact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/continuing-an-artifact\/3198",
        "Question_created_time":"2022-09-29T04:28:27.593Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":795,
        "Question_body":"<p>We are running long data preparation run (30+ hours) to pre-build source files for training.  However, part of the dataset was not ready and was excluding from the current run (which is 20+ hours into the run).  I would like to process the remaining data and ADD it to this current artifact.<br>\nI note that whenever I run this code is creates a new version of the artifact.<br>\nHow can I append new data to an existing artifact?<\/p>\n<p>Second question: Can I add new data in-parallel with the original job.  That is, can two different processes add data to the same artifact at the same time?<\/p>",
        "Question_closed_time":"2022-09-30T19:32:06.301Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kevinashaw\">@kevinashaw<\/a><\/p>\n<p>After speaking with the the team, you have options via our wandb artifact upsert calls to append to a non-finalized artifact as output of a run, see <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/run#upsert_artifact\">here<\/a>.However, we highly recommend you utilize S3 URI reference instead as it would be the more straightforward approach. Add all data to the S3 bucket <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/track-external-files#amazon-s3-gcs-references\">then setup reference URI<\/a> to generate the new artifact with all your processed data. If you run into any issues, please let me know.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Histogram across steps with in a run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/histogram-across-steps-with-in-a-run\/3219",
        "Question_created_time":"2022-10-05T05:03:14.952Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":224,
        "Question_body":"<p>As we prepare our datasets we are using WandB to track results of different runs.  These data-prep runs last several days across 10M+ frames and we would like to log the ongoing results to histograms.  For example, we want to generate histograms of statistics metrics across all data frames.<br>\nThe simplest technique would seem to be to log each parameter step-by-step for each frame using <code>wandb.log()<\/code>.  But the workspace Panel (\u201cAdd Panel\u201d) does not not support histograms.<br>\nI\u2019ve read the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/media#histograms\">section on histograms<\/a> repeatedly and I can\u2019t help but conclude that continuous tracking of histograms is not supported.  Which seems odd.<br>\nThe documentation suggests that I should accumulate the elements in a local list, generate a histogram with each frame (locally) and to then log the histogram to WandB. Basically we are just plotting the histogram locally and pushing a figure. This seems inefficient for large data sets.<br>\nWandB would seem to be well suited for tracking statistics across steps and runs using histograms.<br>\nBut perhaps I have not yet found it in the documentation.  Can you provide some guidance?<\/p>\n<p>To reiterate, I want to log a several statistics every step across many (millions) of steps.  I wish to plot a histogram of these values across all steps.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Strategy for adding referenced files to an artifact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/strategy-for-adding-referenced-files-to-an-artifact\/3094",
        "Question_created_time":"2022-09-11T05:29:45.197Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":238,
        "Question_body":"<p>We are new to WandB and working out best-practices for using referenced-artifacts.<br>\nWe have an S3 bucket were we keep our data corpus, so that it can be shared between machines.<br>\nWe want to use WandB to track these files and to use it to download\/synchronize copies of the datasets to local machines.<br>\nThere seem to be two ways to add files to an artifact:<\/p>\n<ol>\n<li>By-Group: Create the file locally and put it to S3. Repeat with all other data files until done.  Then use the <code>artifact.add_reference()<\/code> command and point it to the S3 prefix\/directory for the files.  This will add the directory and its files to the artifact.  The artifact will report that only a single \u201cfile\u201d exists (since we only added the directory) \u2013 which I think is weird, by the way \u2013 but all the files seem to be there.<\/li>\n<li>One-by-one: create the file locally, put it to S3 and immediately add the S3 file to the artifact.  Repeat until all files are done and then close the artifact and the run.  The artifact will now properly note that n-files have been added.<\/li>\n<\/ol>\n<p>The real question is, when I later execute a <code>download(root=my-local-path)<\/code> operation, will I be able to cleanly load the files from the artifact to my local directory.  That is, without having to fight a path mismatch between the S3 paths and my local paths.<br>\nThat is, if the S3 path is: \/really\/deep\/s3\/path\/to\/my\/dataset\/files<br>\nAnd my local path is: \/Users\/user\/<br>\nCan the files end up here: \/Users\/user\/dataset\/files<\/p>\n<p>Thank you,<br>\nKevin<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"MatPlotLib into WandB",
        "Question_link":"https:\/\/community.wandb.ai\/t\/matplotlib-into-wandb\/3212",
        "Question_created_time":"2022-10-03T04:23:09.932Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":817,
        "Question_body":"<p>I need to import MatPlotLib images into WandB.  On the surface, this seems simple, since the documentation clearly shows how to ingest a <code>plt<\/code> or <code>fig<\/code> object.  However, WandB is making a mess of the plots and I don\u2019t want to recode them in plotly.<br>\nSo I next want to use MatPlotLib to save a PNG and ingest that.  Again seems easy, but I would prefer to do it using an in-memory buffer object (this avoids messing with local paths and temp directories on various instances).  Apparently I\u2019m not the first one to do this either (<a href=\"https:\/\/stackoverflow.com\/questions\/35999020\/convert-pyplot-figure-into-wand-image-image\" rel=\"noopener nofollow ugc\">link<\/a>). The instructions are clear and show someone has already done this.  But it fails when I try it:<\/p>\n<pre><code class=\"lang-auto\">fig, (ax1, ax2) = plt.subplots(2, 1, dpi=300, figsize=(10, 5))\n...\nbuf = io.BytesIO()\nplt.savefig(buf, format='png')\nbuf.seek(0)\nwandb.log(({\"chart\": wandb.Image(file=buf)}))\n<\/code><\/pre>\n<p>The error seems to be with <code>wandb.Image()<\/code>.  It returns:<br>\n<code>{TypeError}__init__() got an unexpected keyword argument 'file'<\/code><\/p>\n<p>I can remove the <code>file=<\/code> parameter so that the command is:<\/p>\n<pre><code class=\"lang-auto\">wandb.Image(buf)\n<\/code><\/pre>\n<p>And I get: <code>{AttributeError}'_io.BytesIO' object has no attribute 'ndim'<\/code><\/p>\n<p>Any recommendations?<\/p>",
        "Question_closed_time":"2022-10-03T17:26:35.860Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kevinashaw\">@kevinashaw<\/a>!<\/p>\n<p>The <code>BytesIO<\/code> type is not supported by <code>wandb.Image<\/code> which is why you are running into this issue. Here are a few options that would work instead:<\/p>\n<ul>\n<li><code>wandb.log({ 'chart' : wandb.Image(Image.open(buf)) })<\/code><\/li>\n<li><code>wandb.log({ 'chart' : wandb.Image(fig) })<\/code><\/li>\n<li>\n<code>wandb.log({ 'chart' : fig })<\/code> (Please note that this does not actually save an image but an interactable Plotly chart on your workspace<\/li>\n<\/ul>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Report page often crashes when I collapse a section of the report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/report-page-often-crashes-when-i-collapse-a-section-of-the-report\/3115",
        "Question_created_time":"2022-09-14T12:29:47.156Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":96,
        "Question_body":"<p>report page often crashes when I collapse a section of the report.<br>\nHere is one of the reports that crash: <a href=\"https:\/\/wandb.ai\/dc914337\/nri\/reports\/Generalizing-movement--VmlldzoyNjMyMTUx\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>How to reproduce:<\/p>\n<ol>\n<li>click \u201cedit\u201d report<\/li>\n<li>collapse and open different sections until you see<\/li>\n<\/ol>\n<blockquote>\n<p>Oops, something went wrong.<\/p>\n<p>If this keeps happening, email us at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a> with this page link.<\/p>\n<\/blockquote>\n<p>Emailing the address doesn\u2019t work as well. Google says group doesn\u2019t exist<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Storage limit under free plan: How long until freed space is recognised?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/storage-limit-under-free-plan-how-long-until-freed-space-is-recognised\/3179",
        "Question_created_time":"2022-09-23T09:26:47.434Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":194,
        "Question_body":"<p>I had exceeded the 100GB storage limit available for the free plan yesterday and accordingly deleted a lot of sweeps and artifacts right away. In the usage dashboard, it says that I\u2019m taking up 104GB. However, when I click the project to see a more detailed view, I only see artfiacts\/ with 20GB and runs\/ with 16GB. It seems that the 104GB are not updated to the current state.<\/p>\n<p>Is this a caching issue? Are my runs in danger of not being able to save their data?<\/p>\n<p>My user name is sgerard, in case you want to look into this more closely.<\/p>\n<p>Best regards<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Labels of x and y axis is not clearly seen?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/labels-of-x-and-y-axis-is-not-clearly-seen\/3177",
        "Question_created_time":"2022-09-23T00:50:31.656Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":236,
        "Question_body":"<p>Dears, I am new to use wandb. Currently when I plot a curve by creating a link between my experiment and wandb, the labels of x and y axis is inside of the graph grid itself making it invisible as you see in the picture below. How can I fix this issue so I can make labels out of the grid of the graph?<br>\nI do really appreciate your help.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/2\/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da.jpeg\" data-download-href=\"\/uploads\/short-url\/4X2VldFgZ2NNZmAaZXvucjxWrTY.jpeg?dl=1\" title=\"convergence curve11\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_690x362.jpeg\" alt=\"convergence curve11\" data-base62-sha1=\"4X2VldFgZ2NNZmAaZXvucjxWrTY\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_690x362.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_1035x543.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/2\/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_1380x724.jpeg 2x\" data-dominant-color=\"F8F9FA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">convergence curve11<\/span><span class=\"informations\">2528\u00d71328 179 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to save\/log PipFile",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-save-log-pipfile\/3150",
        "Question_created_time":"2022-09-19T04:33:50.701Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":175,
        "Question_body":"<p>I understand that WandB stores the <code>requirements.txt<\/code> as part of its logging for every experiment.<br>\nSince i use <code>pipenv<\/code> I would also like to log the <code>PipFile<\/code>.  However this file is at the path-level as <code>requirements.txt<\/code> and I am prohibited from saving this file.  I get the error message: <code>globs can't walk above base_path<\/code>.  Is there a way to log this file?<\/p>\n<p>Edit: I\u2019ve discovered that I can use <code>wandb.init(dir=\"my\/project\/root\/dir\")<\/code> and can then use <code>wandb.save(\"Pipfile\")<\/code>.  Now I dont have an error, but the file also is NOT being added to the files logged by the experiment.  I\u2019m guessing that I instead need to copy the <code>Pipfile<\/code> into the local wandb temp directory.  Perhaps that is enough.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add row to table replaces existing rows",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-row-to-table-replaces-existing-rows\/3205",
        "Question_created_time":"2022-09-30T12:00:24.075Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":1700,
        "Question_body":"<p>Hi,<\/p>\n<p>I want to add a row to a table in each epoch.  But it overrides existing data each time a new row is added (or at least there is always only 1 row shown in the dashboard. Ive tried different options when to create the table using <em>wandb.Table<\/em>, use <em>table.add_row<\/em> and when to use <em>run.log<\/em>.  The problem is always the same.<\/p>\n<p>In the dashboard <em>runs.summary[\u201cimage_table\u201d]<\/em> is used to show the table.<\/p>\n<p>What might be the problem here? Shouldnt I create the wandb.Table once and then  add_row and log for each epoch? Is there an option to show the full table in dashboard correctly?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Training yoloX",
        "Question_link":"https:\/\/community.wandb.ai\/t\/training-yolox\/2825",
        "Question_created_time":"2022-07-29T10:14:10.950Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":151,
        "Question_body":"<p>hi,<br>\ni am trying to enable logging for yolox nano, but when i start training i get this error :<\/p>\n<p>File \u201c\/content\/YOLOX\/yolox\/utils\/logger.py\u201d, line 206, in <strong>init<\/strong><br>\nself.cats = val_dataset.cats<br>\n\u2502           \u2514 &lt;yolox.data.datasets.voc.VOCDetection object at 0x7f6f1d379e10&gt;<br>\n\u2514 &lt;yolox.utils.logger.WandbLogger object at 0x7f6f1e77ed10&gt;<\/p>\n<p>AttributeError: \u2018VOCDetection\u2019 object has no attribute \u2018cats\u2019<\/p>\n<p>also this is my colab code:<br>\n!python tools\/train.py -f exps\/example\/yolox_voc\/yolox_voc_nano.py -d 1 -b 16 --fp16 -o --logger wandb wandb-project object-detectiontemp -c weights\/yolox_nano.pth<\/p>\n<p>could you please guide me or give me some hints on what should i do ?<br>\nbecause as i see there is a val_dataset variable, but i have no idea how do you fill that .<\/p>\n<p>thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ConnectionRefusedError",
        "Question_link":"https:\/\/community.wandb.ai\/t\/connectionrefusederror\/3200",
        "Question_created_time":"2022-09-29T14:10:02.042Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":390,
        "Question_body":"<p>Hi,<br>\nI used colab to run the code,  it succeeded the first time, but failed the third time, why did it like this? what should I do? Thanks!<br>\nException has occurred: ConnectionRefusedError<br>\n[Errno 111] Connection refused<br>\nFile \u201c\/content\/OPTIM\/0_template_graph_node_classify copy\/agent_sweep.py\u201d, line 75, in <br>\nsweep_id = wandb.sweep(sweep_config, project=\u201cvscode_debug\u201d)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can a same combinasion happened twice with bayesian optimisation?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/can-a-same-combinasion-happened-twice-with-bayesian-optimisation\/3172",
        "Question_created_time":"2022-09-22T08:54:57.751Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":145,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using sweeps with bayesian optimisation, and i have a limited number of possible combinations between the hyperparameters I\u2019m trying to optimise (16 possible combinations) .<\/p>\n<p>In a test, I tried to run 16 runs with bayesian optimisation in the same sweep expecting to have all 16 possible hyperparameter combinations, but only 12 of the possible combinations were selected.<\/p>\n<p>Is this behavior normal?<\/p>\n<p>In an other test a same combination appeared 4 times.<\/p>\n<p>Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Barchart Grouping by Time\/Step\/Count",
        "Question_link":"https:\/\/community.wandb.ai\/t\/barchart-grouping-by-time-step-count\/3157",
        "Question_created_time":"2022-09-19T16:32:16.917Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":803,
        "Question_body":"<p>Dear W&amp;B Community,<\/p>\n<p>I have system metrics logged like the \u201c<em>time per step<\/em>\u201d or \u201c<em>time per backward pass<\/em>\u201d for a model.<br>\nWhen doing this on different hardware, I would like to compare the effect this has on these metrics.<br>\nIn the following examples, I profile the basic Torch CIFAR10 model on a 1,2,4,8,16 and 32 CPU VM.<\/p>\n<p>When looking at a <code>Linechart<\/code>, the full history of these metrics is visible, however, it is very hard to compare them due to the overlapping and oscillation:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351.png\" data-download-href=\"\/uploads\/short-url\/zZROm2jlGDN4WUrxx2lQXAA8jYZ.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_22_16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_22_16 PM\" data-base62-sha1=\"zZROm2jlGDN4WUrxx2lQXAA8jYZ\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1380x724.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_22_16 PM<\/span><span class=\"informations\">3539\u00d71859 509 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>When using a <code>Barchart<\/code>, only the last value is visualized:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/48a4597177e867b3eb511112ad23b561f18f1137.png\" data-download-href=\"\/uploads\/short-url\/amCuG3pzRgnimYoyoJeru5muDMH.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_20_31 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_20_31 PM\" data-base62-sha1=\"amCuG3pzRgnimYoyoJeru5muDMH\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_1380x724.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_20_31 PM<\/span><span class=\"informations\">3539\u00d71859 251 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The functionality that would be nice is to group values based on their count or occurrence, as grouping by runs already works perfectly. Here\u2019s the same data but run through <code>seaborn.barplot<\/code>:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479.png\" data-download-href=\"\/uploads\/short-url\/7VTQur5SLq8cPHTQtTqGrDuwPRn.png?dl=1\" title=\"download\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png\" alt=\"download\" data-base62-sha1=\"7VTQur5SLq8cPHTQtTqGrDuwPRn\" width=\"690\" height=\"427\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1035x640.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1380x854.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">download<\/span><span class=\"informations\">3777\u00d72341 159 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Would this be possible to implement? Or does anybody know a way to get that functionality?<\/p>\n<p>My current workaround is to download the data manually and run it through seaborn. Unfortunately, I did not understand the errors I\u2019ve gotten with the <code>Custom Chart<\/code> functionality when trying to port Vega examples to use wandb as a data basis.<\/p>\n<p>I\u2019d be very glad if anybody can point me to a tutorial on how to migrate existing Vega examples to be used with wandb (and the common problems, like differences between v3\/v4\/v5, as these seemed to be an issue for me).<\/p>",
        "Question_closed_time":"2022-09-27T10:20:24.356Z",
        "Answer_body":"<p>Hi Alexander,<\/p>\n<p>Thanks for sending this detailed explanation! I have been exploring it and I think that the issue here is that, in lines 22, 29 and 43 you have \u201cdata\u201d: \u201ctable\u201d but as the name has been changed to \u201cwandb\u201d, then you should have \u201cdata\u201d: \u201cwandb\u201d. To solve the error between lines 4 and 6, you can use <span class=\"chcklst-box fa fa-square-o fa-fw\"><\/span> and it is solved, but it seems that it is not affecting to the chart.<\/p>\n<pre><code>\"data\": [{ \"name\": \"wandb\" }]\n<\/code><\/pre>\n<p>Please let me know if this would be useful for you!<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Upload a series of time sequence (ecg curve) with each corresponding heart rate into a table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/upload-a-series-of-time-sequence-ecg-curve-with-each-corresponding-heart-rate-into-a-table\/3072",
        "Question_created_time":"2022-09-06T12:16:11.195Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":153,
        "Question_body":"<p>Dear friends,<br>\nI\u2019m a new wandb. My task is to predict a time sequence and its heart rate. Therefore, I want to visualize each result by uploading it to a table. Is there any data format similar to the image? I want to achieve a table like below:<br>\npredicted time sequence(1D point), heart rate(single value), the ground truth time sequence (also a 1D point)<br>\nEach column represents a different data type.<br>\nHow to achieve it?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Metric data exceeds maximum size",
        "Question_link":"https:\/\/community.wandb.ai\/t\/metric-data-exceeds-maximum-size\/3082",
        "Question_created_time":"2022-09-08T07:30:16.472Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":667,
        "Question_body":"<p>When I use wandb.log online, the following error will be reported: \u201cMetric data exceeds maximum size of 10.4MB\u201d. Now if I don\u2019t want to run again, how can I fix this mistake?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Remove from a team",
        "Question_link":"https:\/\/community.wandb.ai\/t\/remove-from-a-team\/3193",
        "Question_created_time":"2022-09-27T08:25:18.870Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":439,
        "Question_body":"<p>Hi,<\/p>\n<p>I would like to remove myself from a tesm. How can I do it?<\/p>\n<p>Thanks,<br>\nP<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb generates all the files in the root path of my project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-generates-all-the-files-in-the-root-path-of-my-project\/3132",
        "Question_created_time":"2022-09-17T09:05:12.983Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":128,
        "Question_body":"<p>Hi there. I am faced with a issue here. You see when my experiments begin wandb creates all the files right in my project root path, just like below<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc.png\" data-download-href=\"\/uploads\/short-url\/l41fn57sn746ESH9dhIVvNNmgt6.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc.png\" alt=\"image\" data-base62-sha1=\"l41fn57sn746ESH9dhIVvNNmgt6\" width=\"525\" height=\"500\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">708\u00d7674 13.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Filter GPU curves in the system panel",
        "Question_link":"https:\/\/community.wandb.ai\/t\/filter-gpu-curves-in-the-system-panel\/3152",
        "Question_created_time":"2022-09-19T05:45:41.242Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":196,
        "Question_body":"<p>Hi,<br>\nMe and a colleague are sharing a remote server with 8 GPUs. We split them, 4 GPUs each. In the system panel at the WANDB page I currently see data of all 8 GPUs. Is it possible to filter some of those curves, so I\u2019ll only see the GPUs I\u2019m using?<\/p>\n<p>Many thanks<\/p>",
        "Question_closed_time":"2022-09-20T15:55:12.779Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/yonatan-shimoni\">@yonatan-shimoni<\/a> thank you for writing in! Just to clarify here, is this for the System view that you can access from the left panel of an individual Run, or is it at the System panels section in your Project\u2019s Workspace? You can select which GPUs to visualise there by editing the Chart (pencil icon) as in the attached screenshot. Would this help?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818.png\" data-download-href=\"\/uploads\/short-url\/uFNI8njAc6A8srPIjwcR86x4AZi.png?dl=1\" title=\"Screenshot 2022-09-20 at 16.50.40\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_476x500.png\" alt=\"Screenshot 2022-09-20 at 16.50.40\" data-base62-sha1=\"uFNI8njAc6A8srPIjwcR86x4AZi\" width=\"476\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_476x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_714x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_952x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-09-20 at 16.50.40<\/span><span class=\"informations\">1098\u00d71153 76.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Rate Limit Exceeded",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rate-limit-exceeded\/753",
        "Question_created_time":"2021-09-23T13:29:47.148Z",
        "Question_answer_count":12,
        "Question_score_count":4,
        "Question_view_count":1965,
        "Question_body":"<p>Hello,<\/p>\n<p>Since recently, I have been getting this error when browsing the runs\/workspace of my latest project.<\/p>\n<p>For info, it is a segmentation tasks trained in pytorch using fastai callback.<\/p>\n<p>My log looks like this:<\/p>\n<pre><code class=\"lang-auto\">\n0: *Quadro RTX 8000,         48.6GB, tensor_cores=72\n1: GeForce RTX 2070 SUPER,   8.0GB, tensor_cores=40\n Selecting GPU : Quadro RTX 8000\nException ignored in: &lt;function _releaseLock at 0x7f3232131ee0&gt;\nTraceback (most recent call last):\n  File \"\/home\/tcapelle\/miniconda3\/envs\/pytorch_18\/lib\/python3.8\/logging\/__init__.py\", line 227, in _releaseLock\n    def _releaseLock():\nKeyboardInterrupt:\nWandbCallback requires use of \"SaveModelCallback\" to log best model\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:08.499452, resuming normal operation.\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:09.337473, resuming normal operation.\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:08.679539, resuming normal operation.\n<\/code><\/pre>\n<p>this happens in the training notebooks and in the wandb page afterwards.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Limiting the number of runs for a sweep of method 'bayes'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/limiting-the-number-of-runs-for-a-sweep-of-method-bayes\/3137",
        "Question_created_time":"2022-09-18T07:52:40.972Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":163,
        "Question_body":"<p>Hi,<\/p>\n<p>Is there a way to limit in advance the number of configs a sweep is going to use?<br>\nCurrently, I need to follow the progress and stop the sweep manually.<\/p>\n<p>Moreover, if there is such a setting, could it also be configured dynamically on-the-fly?<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep, how is the optimisation metric selected in bayesian optimisation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-how-is-the-optimisation-metric-selected-in-bayesian-optimisation\/3126",
        "Question_created_time":"2022-09-16T13:48:14.344Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":111,
        "Question_body":"<p>Hi every one,<\/p>\n<p>When using a sweep, the selection of a metric that need to beoptimized is required when using bayesian optimisation.<\/p>\n<p>I wanted to know if for the selection of the next critierion for the next runs, the bayesian optimisation is based on the value of that metric at the end of the run (last epoch) or on the highest value reached by the metric during the run ?<\/p>\n<p>Because in the first case, if I choose a metric calculated over my validation dataset, it performance may decrease during the training because of overfitting, then the value of my metric at the end would not reflect the best performance of my model.<\/p>\n<p>Thanks for your help<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Recording videos of custom gym environments",
        "Question_link":"https:\/\/community.wandb.ai\/t\/recording-videos-of-custom-gym-environments\/3110",
        "Question_created_time":"2022-09-13T21:49:41.075Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":1031,
        "Question_body":"<p>Hi, I am try to use VecVideoRecorder to log videos of my custom environment. The observation come from a camera, though I don\u2019t think that is the issue.  The error is:<\/p>\n<p>AttributeError(\u201c\u2018VideoRecorder\u2019 object has no attribute \u2018path\u2019\u201d)<\/p>\n<p>I\u2019m not directly setting nor accessing an attribute \u2018path\u2019 so I\u2019m having identifying where this is coming from. My code looks like this:<\/p>\n<pre><code>def make_env():\n    env = DummyVecEnv([lambda:    Monitor(ReacherFiveJointsImageSpace(random_start=wandb.config.random_start,\n                                                        log_state_actions=True,\n                                                        shape_reward=wandb.config.shape_reward,\n                                                        file_name_prefix=wandb.config.rl_name,\n                                                        env_type=wandb.config.env_type,\n                                                        seed=(wandb.config.seed+wandb.config.run)),\n                                       log_dir)])\n    env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=5.)\n    env = VecVideoRecorder(env, video_folder=log_dir,\n                           record_video_trigger=lambda x: x % 100 == 0, video_length=10)  # record videos\n    stats_path = os.path.join(log_dir,\n                              \"run\" + str(wandb.config.run) + \"_vec_normalize_\" + run.id + \".pkl\")\n    env.save(stats_path)\n    return env\n<\/code><\/pre>\n<p>Can anyone point me in the right direction?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Traceback error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/traceback-error\/3008",
        "Question_created_time":"2022-08-25T22:14:17.943Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":2107,
        "Question_body":"<p>Hey guys,<\/p>\n<p>I am totally new to W&amp;B. I am getting a Traceback error when I want to run \u201cwandb.init(project=\u201d\u2026\u201c)\u201d. Last week it still did work. Any tips what to do?? Thank you so much.<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/wandb_init.py\", line 651, in init\n    backend.cleanup()\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/backend\/backend.py\", line 246, in cleanup\n    self.interface.join()\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 475, in join\n    super().join()\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 666, in join\n    _ = self._communicate_shutdown()\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 472, in _communicate_shutdown\n    _ = self._communicate(record)\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 226, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"\/home\/p\/pthielge\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 231, in _communicate_async\n    raise Exception(\"The wandb backend process has shutdown\")\nException: The wandb backend process has shutdown\nwandb: ERROR Abnormal program exit\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n    998         try:\n--&gt; 999             run = wi.init()\n   1000             except_exit = wi.settings._except_exit\n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/wandb_init.py in init(self)\n    650                     # we don't need to do console cleanup at this point\n--&gt; 651                     backend.cleanup()\n    652                     self.teardown()\n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/backend\/backend.py in cleanup(self)\n    245         if self.interface:\n--&gt; 246             self.interface.join()\n    247         if self.wandb_process:\n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py in join(self)\n    474     def join(self) -&gt; None:\n--&gt; 475         super().join()\n    476 \n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface.py in join(self)\n    665             return\n--&gt; 666         _ = self._communicate_shutdown()\n    667 \n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py in _communicate_shutdown(self)\n    471         record = self._make_record(request=request)\n--&gt; 472         _ = self._communicate(record)\n    473 \n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py in _communicate(self, rec, timeout, local)\n    225     ) -&gt; Optional[pb.Result]:\n--&gt; 226         return self._communicate_async(rec, local=local).get(timeout=timeout)\n    227 \n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/interface\/interface_shared.py in _communicate_async(self, rec, local)\n    230         if self._process_check and self._process and not self._process.is_alive():\n--&gt; 231             raise Exception(\"The wandb backend process has shutdown\")\n    232         future = self._router.send_and_receive(rec, local=local)\n\nException: The wandb backend process has shutdown\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\n&lt;ipython-input-49-e3734aa09c65&gt; in &lt;module&gt;\n      1 #Login to wandb\n      2 # #! wandb login config_dict[\"wandb_key\"]\n----&gt; 3 wandb.init()\n      4 #run_name = wandb.run.name\n\n~\/.local\/lib\/python3.6\/site-packages\/wandb\/sdk\/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1035             if except_exit:\n   1036                 os._exit(-1)\n-&gt; 1037             raise Exception(\"problem\") from error_seen\n   1038     return run\n\nException: problem\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to ignore NaNs in x-axis scaling?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-ignore-nans-in-x-axis-scaling\/3021",
        "Question_created_time":"2022-08-29T11:37:10.331Z",
        "Question_answer_count":17,
        "Question_score_count":0,
        "Question_view_count":211,
        "Question_body":"<p>Hi!<\/p>\n<p>I\u2019m trying to plot some results from Ray, but due to the presence of NaNs, my X axis is scaled very weirdly. Is there any way to ignore NaNs?<\/p>\n<p>My issue is very similar to this one: <a href=\"https:\/\/community.wandb.ai\/t\/nan-loss-causes-incorrect-x-axis-time-scale\/2410\" class=\"inline-onebox\">NaN loss causes incorrect X axis time scale<\/a><\/p>\n<p>This is the way it looks now:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a.png\" data-download-href=\"\/uploads\/short-url\/ocEjriMibztw54CCD86LMzxWCaS.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a_2_690x248.png\" alt=\"image\" data-base62-sha1=\"ocEjriMibztw54CCD86LMzxWCaS\" width=\"690\" height=\"248\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a_2_690x248.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a_2_1035x372.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a_2_1380x496.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a9a2403dfe2030c681662aac536bfb6938af619a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1501\u00d7540 35.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Runs in parrallel with bayesian optimisation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runs-in-parrallel-with-bayesian-optimisation\/3127",
        "Question_created_time":"2022-09-16T14:00:06.094Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":110,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I started to use sweeps with bayesian optimisation. The idea is that the selected criterion in the futur runs will be impacted by the past runs.<\/p>\n<p>But if a run starts when the last run isn\u2019t over yet, will the last run results (which is not completed yet) have an impact over the selected criterion on the run which is up to start  or will the selection of the parameters for the new run be only based on the runs that are  already over  ?<\/p>\n<p>Thanks for your time.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to download the learning curves of grouped runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-download-the-learning-curves-of-grouped-runs\/3010",
        "Question_created_time":"2022-08-26T16:25:47.920Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":138,
        "Question_body":"<p>Hi,<\/p>\n<p>Is there a way to download the learning curves of grouped runs? For grouped runs, the learning curves have shaded area. Does that represent the standard deviation or the 95% confidence interval? And can we download them (the grouped curve, not the individual ones) in a python script so that we can customize the plot with matplotlib or seaborn? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot add new members to a team I created",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-add-new-members-to-a-team-i-created\/3156",
        "Question_created_time":"2022-09-19T09:42:08.669Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":136,
        "Question_body":"<p>Hi there,<br>\nI created a team, but apparently I\u2019m not an admin (and neither is anyone else for that matter).<br>\nSo we\u2019re all simple members and cannot add new ppl to our team.<\/p>\n<p>Any solutions?<br>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb has no attribute login error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-has-no-attribute-login-error\/3146",
        "Question_created_time":"2022-09-19T00:40:44.682Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":389,
        "Question_body":"<p>For some reason, I\u2019m getting an error when I run wandb in a notebook that used to run fine. My error is:<\/p>\n<p>AttributeError                            Traceback (most recent call last)<br>\nInput In [11], in &lt;cell line: 1&gt;()<br>\n----&gt; 1 wandb.login(key=\u2018xxx\u2019)<\/p>\n<p>AttributeError: module \u2018wandb\u2019 has no attribute \u2018login\u2019<\/p>\n<p>Has anyone else encountered this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add_reference() with nested folders",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-reference-with-nested-folders\/3092",
        "Question_created_time":"2022-09-10T16:36:30.113Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":450,
        "Question_body":"<p>We need to set a dataset folder in S3 as an artifact.  The folder has many sub-directories (only one layer though).<br>\nWhen I use the a <code>add_reference()<\/code> command it only stores the directory names of the top-level.<br>\nOf course, I could loop across it, but I\u2019m wondering if there is a command option to make the operation recursive?<\/p>\n<pre><code class=\"lang-auto\">run  = wandb.init(project=WB_PROJECT)\nart = wandb.Artifact(WB_ENTITY, type=WB_DATASET)\nart.add_reference(s3_full, max_objects=WB_MAX_OBJECTS_TO_UPLOAD)\nrun.log_artifact(art)\nwandb.finish()\n<\/code><\/pre>\n<p>EDIT 1: I conclude that the all files are not being added because the <code>Num Files<\/code> in the Artifact Overview shows only <code>5<\/code>.  If I click on the directories, it seems I can see the files, but I assume they are not actually there because of the <code>5<\/code> being reported for the number of files.<\/p>",
        "Question_closed_time":"2022-09-21T11:32:02.548Z",
        "Answer_body":"<p>Hi Kevin,<\/p>\n<p>Thanks for the detailed explanation! I see your issue, I will create a request for this feature, thanks for reporting it! May I help you with any other issue?<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Multi-level nesting in yaml for sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/multi-level-nesting-in-yaml-for-sweeps\/3108",
        "Question_created_time":"2022-09-13T19:43:49.093Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":1087,
        "Question_body":"<p>I am trying to start a sweep using this yaml file.<\/p>\n<p>sweep.yaml<\/p>\n<pre><code class=\"lang-auto\">method: bayes\nmetric:\n  goal: maximize\n  name: val_f1_score\nparameters:\n  notes:\n    value: \"\"\n  seed:\n    value: 42\n  lr:\n    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n  epochs:\n    value: 30\n  augmentation:\n    value: True\n  class_weights:\n    value: True\n  optimizer:\n    value: adam\n  loss:\n    value: categorical_crossentropy\n  metrics:\n    value: [\"accuracy\"]\n  batch_size:\n    value: 64\n  num_classes:\n    value: 7\n  paths:\n    - \n      data:\n        value: ${hydra:runtime.cwd}\/data\/4_tfds_dataset\/\n\nwandb:\n  -\n    use:\n      value: True\n    project:\n      value: Whats-this-rock\n\ndataset:\n  -\n    id:\n      value: [1, 2, 3, 4]\n    dir:\n      value: data\/3_consume\/\n    image:\n      size:\n        value: 124\n      channels:\n        value: 3\n    classes:\n      value: 10\n    sampling:\n      value: None\n\nmodel:\n  -\n    backbone:\n      value: efficientnetv2m\n    use_pretrained_weights:\n      value: True\n    trainable:\n      value: True\n    preprocess:\n      value: True\n    dropout_rate:\n      value: 0.3\n\ncallback:\n  -\n    monitor:\n      value: \"val_f1_score\"\n    earlystopping:\n      patience:\n        value: 10\n    reduce_lr:\n      factor:\n        values: [.9, .7, .5]\n      min_lr: 0.00001\n      patience:\n        values: [1, 2, 3, 4]\n    save_model:\n      status:\n        value: True\n      best_only:\n        value: True\n\nprogram: src\/models\/train.py\n\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">Error: Invalid sweep config: invalid hyperparameter configuration: paths\n<\/code><\/pre>\n<p>Here\u2019s the full traceback of the error:-<\/p>\n<pre><code class=\"lang-auto\">During handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/cli\/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/cli\/cli.py\", line 942, in sweep\n    launch_scheduler=_launch_scheduler_spec,\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/apis\/internal.py\", line 102, in upsert_sweep\n    return self.api.upsert_sweep(*args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/apis\/normalize.py\", line 62, in wrapper\n    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/apis\/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2178, in upsert_sweep\n    raise e\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2175, in upsert_sweep\n    check_retry_fn=no_retry_4xx,\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/lib\/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/internal\/internal_api.py\", line 2153, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.CommError: Invalid sweep config: invalid hyperparameter configuration: paths\n<\/code><\/pre>\n<p>I am using hydra and trying to replicate a config.yaml for wandb sweeps<\/p>\n<p>config.yaml<\/p>\n<pre><code class=\"lang-auto\">notes: \"\"\nseed: 42\nlr: 0.001\nepochs: 30\naugmentation: True\nclass_weights: True\noptimizer: adam\nloss: categorical_crossentropy\nmetrics: [\"accuracy\"]\nbatch_size: 64\nnum_classes: 7\n\npaths:\n  data: ${hydra:runtime.cwd}\/data\/4_tfds_dataset\/\n\nwandb:\n  use: True\n  project: Whats-this-rock\n\ndataset:\n  id: [1, 2, 3, 4]\n  dir: data\/3_consume\/\n  image:\n    size: 124\n    channels: 3\n  classes: 10\n  sampling: None\n\nmodel:\n  backbone: efficientnetv2m\n  use_pretrained_weights: True\n  trainable: True\n  preprocess: True\n  dropout_rate: 0.3\n\ncallback:\n  monitor: \"val_f1_score\"\n  earlystopping:\n    patience: 10\n  reduce_lr:\n    factor: 0.4\n    min_lr: 0.00001\n    patience: 2\n  save_model:\n    status: True\n    best_only: True\n\n<\/code><\/pre>",
        "Question_closed_time":"2022-09-18T15:44:40.848Z",
        "Answer_body":"<p>The solution is to use dot notation instead of nested parameters as wandb (v0.13.3) sweeps doesn\u2019t support nested parameters.<\/p>\n<pre><code class=\"lang-auto\">sweep.yaml\n\nmethod: bayes\nmetric:\n  goal: maximize\n  name: val_accuracy\nparameters:\n  notes:\n    value: \"\"\n  seed:\n    values: [1, 42, 100]\n  lr:\n    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n  epochs:\n    value: 100\n  augmentation:\n    value: True\n  class_weights:\n    value: True\n  optimizer:\n    values: [adam, adamax]\n  loss:\n    value: categorical_crossentropy\n  metrics:\n    value: [\"accuracy\"]\n  batch_size:\n    value: 64\n  num_classes:\n    value: 7\n  train_split:\n    values:\n      - 0.70\n      - 0.75\n      - 0.80\n  data_path:\n    value: data\/4_tfds_dataset\/\n  wandb.use:\n    value: True\n  wandb.mode:\n    value: online\n  wandb.project:\n    value: Whats-this-rockv3\n  dataset_id:\n    values:\n      - [1]\n  image_size:\n    value: 224\n  image_channels:\n    value: 3\n  sampling:\n    values: [None, oversampling, undersampling]\n  backbone:\n    values:\n      [\n        efficientnetv2m,\n        efficientnetv2,\n        resnet,\n        mobilenetv2,\n        inceptionresnetv2,\n        xception,\n      ]\n  use_pretrained_weights:\n    values: [True]\n  trainable:\n    values: [True, False]\n  preprocess:\n    value: True\n  dropout_rate:\n    values: [0.3]\n  monitor:\n    value: \"val_accuracy\"\n  earlystopping.use:\n    value: True\n  earlystopping.patience:\n    values: [10]\n  reduce_lr.use:\n    values: [True]\n  reduce_lr.factor:\n    values: [.9, .7, .5, .3]\n  reduce_lr.patience:\n    values: [1, 3, 5, 7, 13]\n  reduce_lr.min_lr:\n    value: 1e-5\n  save_model:\n    value: False\n\nprogram: src\/models\/train.py\ncommand:\n  - ${env}\n  - python\n  - ${program}\n  - ${args_no_hyphens}\n\n<\/code><\/pre>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Wandb automatically logeed into the wrong user -- why?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-automatically-logeed-into-the-wrong-user-why\/2916",
        "Question_created_time":"2022-08-12T14:33:18.111Z",
        "Question_answer_count":14,
        "Question_score_count":2,
        "Question_view_count":1783,
        "Question_body":"<p>I followed the usual instructions:<\/p>\n<pre><code class=\"lang-auto\">pip install wandb\nwandb login\n<\/code><\/pre>\n<p>but then it never asked me for the user and thus when I pasted my key into the terminal when asked it was there in the <code>.netrc<\/code> file but it was all wrong:<\/p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~ \u276f\n(iit_term_synthesis) brandomiranda~ \u276f wandb login\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\n(iit_term_synthesis) brandomiranda~ \u276f wandb login --relogin\nwandb: Logging into wandb.ai. (Learn how to deploy a W&amp;B server locally: https:\/\/wandb.me\/wandb-server)\nwandb: You can find your API key in your browser here: https:\/\/wandb.ai\/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\nwandb: Appending key for api.wandb.ai to your netrc file: \/Users\/brandomiranda\/.netrc\n(iit_term_synthesis) brandomiranda~ \u276f cat \/Users\/brandomiranda\/.netrc\nmachine api.wandb.ai\n  login user\n  password djkfhkjsdhfkjshdkfj...SECRET...sdhjfjhsdjkfhsdjf\n<\/code><\/pre>\n<p>how to fix this?<\/p>\n<aside class=\"onebox stackexchange\" data-onebox-src=\"https:\/\/stackoverflow.com\/questions\/73335735\/wandb-automatically-logeed-into-the-wrong-user-why\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/stackoverflow.com\/questions\/73335735\/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">stackoverflow.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https:\/\/stackoverflow.com\/users\/1601580\/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img alt=\"Charlie Parker\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5e9c0a0caedbda92f5ad9bc087e52e143936f9f5.png\" class=\"thumbnail onebox-avatar\" width=\"256\" height=\"256\">\n  <\/a>\n\n<h4>\n  <a href=\"https:\/\/stackoverflow.com\/questions\/73335735\/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">Wandb automatically logeed into the wrong user -- why?<\/a>\n<\/h4>\n\n<div class=\"tags\">\n  <strong>wand<\/strong>\n<\/div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https:\/\/stackoverflow.com\/users\/1601580\/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    Charlie Parker\n  <\/a>\n  on <a href=\"https:\/\/stackoverflow.com\/questions\/73335735\/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">02:32PM - 12 Aug 22 UTC<\/a>\n<\/div>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":"2022-08-12T15:49:49.713Z",
        "Answer_body":"<aside class=\"quote no-group\" data-username=\"brando\" data-post=\"9\" data-topic=\"2916\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/sea2.discourse-cdn.com\/business7\/user_avatar\/community.wandb.ai\/brando\/40\/199_2.png\" class=\"avatar\"> brando:<\/div>\n<blockquote>\n<p>But that is weird, I\u2019ve ran it from pycharm debugger before\u2026<img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<\/blockquote>\n<\/aside>\n<p>First make sure your <code>.netrc<\/code> file looks right. Login in as instructed in wandb and its fine to relogin. Make sure it still looks fine. Make sure you update wandb with pip. You can set the env variable with your key too. Update pycharm. Remove all the .idea folders in your projects and start from scratch. Make sure your pycharm projs have the right path to the python interpreter form pycharm. Thats I think what worked\u2026<\/p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~\/iit-term-synthesis \u276f rm -rf ..\/ultimate-utils\/.idea\n(iit_term_synthesis) brandomiranda~\/iit-term-synthesis \u276f rm -rf ..\/iit-term-synthesis\/.idea\n(iit_term_synthesis) brandomiranda~\/iit-term-synthesis \u276f rm -rf ..\/pycoq\/.idea\n(iit_term_synthesis) brandomiranda~\/iit-term-synthesis \u276f rm -rf ..\/data\/.idea\n(iit_term_synthesis) brandomiranda~\/iit-term-synthesis \u276f rm -rf ..\/proverbot\/.idea\n<\/code><\/pre>\n<p>this was useful:<\/p>\n<pre><code class=\"lang-auto\">run_bash_command('pip install wandb --upgrade')\ncat_file('~\/.zshrc')\ncat_file('~\/.netrc')\n\nwandb.init(project=\"proof-term-synthesis\", entity=\"brando\", name='run_name', group='expt_name')\n\nprint('success!\\a')\n\n<\/code><\/pre>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"The group you tried to contact (support) may not exist",
        "Question_link":"https:\/\/community.wandb.ai\/t\/the-group-you-tried-to-contact-support-may-not-exist\/3114",
        "Question_created_time":"2022-09-14T12:24:07.836Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":110,
        "Question_body":"<blockquote>\n<p>We\u2019re writing to let you know that the group you tried to contact (support) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren\u2019t able to post:<\/p>\n<ul>\n<li>You might have spelled or formatted the group name incorrectly.<\/li>\n<li>The owner of the group may have removed this group.<\/li>\n<li>You may need to join the group before receiving permission to post.<\/li>\n<li>This group may not be open to posting.<\/li>\n<\/ul>\n<\/blockquote>\n<p>The email I was using is: <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a><br>\nIt is displayed when my page crashes and I just wanted to report it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to retrieve the `group` and `job_type` of a resumed run?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-retrieve-the-group-and-job-type-of-a-resumed-run\/3031",
        "Question_created_time":"2022-08-30T15:53:04.218Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":115,
        "Question_body":"<p>I am inspecting and analysing my best runs. I expected that <code>group<\/code> and <code>job_type<\/code> would be populated with the resumed run\u2019s values after running the code below.<\/p>\n<pre><code class=\"lang-python\">run_id = input(\"id=\")\nwith wandb.init(entity=wandb_entity, project=wandb_project, id=run_id, resume=\"must\") as wandb_r:\n    config = wandb_r.config\n    group = wandb_r.group\n    job_type = wandb_r.job_type\n<\/code><\/pre>\n<p>Even though <code>config<\/code> is successfully recovered, <code>group<\/code> and <code>job_type<\/code> are just empty strings. How do I retrieve group and job_type values from WandB? Thanks.<\/p>",
        "Question_closed_time":"2022-09-02T14:18:38.611Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/avm21\">@avm21<\/a>, it looks like we don\u2019t download these on resumed runs but rather we don\u2019t update them unless you explicitly change them on a resumed run. If you need to get group\/job_type you can use the public API like this to access anything you may need:<\/p>\n<pre><code class=\"lang-auto\">import wandb\nfrom wandb import Api\n\napi = Api()\n\nwith wandb.init(entity=wandb_entity, project=wandb_project, id=run_id, resume=\"must\") as wandb_r:\n    config = wandb_r.config\n\n    # A resumed run will still have the path attribute which can be used to access the run via the API\n    api_run = api.run(wandb_r.path)\n\n    # This will correctly print the group of the run\n    print(api_run.group)\n<\/code><\/pre>\n<p>Let me know if you have any questions around this.<\/p>\n<p>Thank you,<br>\nNate<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Lighting: Checkpoints silently fail to save",
        "Question_link":"https:\/\/community.wandb.ai\/t\/lighting-checkpoints-silently-fail-to-save\/3048",
        "Question_created_time":"2022-09-01T23:10:02.656Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":116,
        "Question_body":"<p>Every couple of hours I silently get this error during training then checkpoints silently fail to save from then on. I\u2019ve now lost &gt;30 hrs of training because of this weird issue. Does anyone know what\u2019s causing this and how to fix it?<\/p>\n<p>for future searchers:<br>\n<code>NVMLError_OperatingSystem: The operating system has blocked the request.<\/code><\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/40594953988cd414c66052042a88418ba4eda5a4.jpeg\" data-download-href=\"\/uploads\/short-url\/9bfQUuHL4Ek3Qjo5EjzA1z8ucRK.jpeg?dl=1\" title=\"IMG_0367\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg\" alt=\"IMG_0367\" data-base62-sha1=\"9bfQUuHL4Ek3Qjo5EjzA1z8ucRK\" width=\"690\" height=\"497\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_1035x745.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/40594953988cd414c66052042a88418ba4eda5a4.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">IMG_0367<\/span><span class=\"informations\">1284\u00d7925 205 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Support@wandb.com doesn't work",
        "Question_link":"https:\/\/community.wandb.ai\/t\/support-wandb-com-doesnt-work\/3122",
        "Question_created_time":"2022-09-16T05:37:48.094Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_body":"<p>I emailed <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a> following instructions from <a href=\"https:\/\/docs.wandb.ai\/company\/getting-help\">Support - Documentation<\/a><\/p>\n<p>However, my email doesn\u2019t go through and I get the following automated reply:<\/p>\n<blockquote>\n<p>We\u2019re writing to let you know that the group you tried to contact (support) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren\u2019t able to post:<\/p>\n<ul>\n<li>You might have spelled or formatted the group name incorrectly.<\/li>\n<li>The owner of the group may have removed this group.<\/li>\n<li>You may need to join the group before receiving permission to post.<\/li>\n<li>This group may not be open to posting.<\/li>\n<\/ul>\n<\/blockquote>\n<p>I also can\u2019t seem to access the Zendesk chat widget, even with ad blockers and all extensions removed.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to install wandb on a docker image for arm?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-install-wandb-on-a-docker-image-for-arm\/3080",
        "Question_created_time":"2022-09-08T00:09:22.611Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":951,
        "Question_body":"<p>My docker building failed at the <code>RUN <\/code><\/p>\n<p>with:<\/p>\n<pre><code class=\"lang-auto\">(meta_learning) brandomiranda~ \u276f docker build -f ~\/iit-term-synthesis\/Dockerfile_arm -t brandojazz\/iit-term-synthesis:test_arm ~\/iit-term-synthesis\/\n\n[+] Building 184.7s (20\/28)\n =&gt; [internal] load build definition from Dockerfile_arm                                                                                           0.0s\n =&gt; =&gt; transferring dockerfile: 41B                                                                                                                0.0s\n =&gt; [internal] load .dockerignore                                                                                                                  0.0s\n =&gt; =&gt; transferring context: 2B                                                                                                                    0.0s\n =&gt; [internal] load metadata for docker.io\/continuumio\/miniconda3:latest                                                                           0.0s\n =&gt; [ 1\/24] FROM docker.io\/continuumio\/miniconda3                                                                                                  0.0s\n =&gt; https:\/\/api.github.com\/repos\/IBM\/pycoq\/git\/refs\/heads\/main                                                                                     0.3s\n =&gt; CACHED [ 2\/24] RUN apt-get update   &amp;&amp; apt-get install -y --no-install-recommends     ssh     git     m4     libgmp-dev     opam     wget      0.0s\n =&gt; CACHED [ 3\/24] RUN useradd -m bot                                                                                                              0.0s\n =&gt; CACHED [ 4\/24] WORKDIR \/home\/bot                                                                                                               0.0s\n =&gt; CACHED [ 5\/24] ADD https:\/\/api.github.com\/repos\/IBM\/pycoq\/git\/refs\/heads\/main version.json                                                     0.0s\n =&gt; CACHED [ 6\/24] RUN opam init --disable-sandboxing                                                                                              0.0s\n =&gt; CACHED [ 7\/24] RUN opam switch create ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1 ocaml-variants.4.07.1+flambda                     0.0s\n =&gt; CACHED [ 8\/24] RUN opam switch ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1                                                          0.0s\n =&gt; CACHED [ 9\/24] RUN eval $(opam env)                                                                                                            0.0s\n =&gt; CACHED [10\/24] RUN opam repo add coq-released https:\/\/coq.inria.fr\/opam\/released                                                               0.0s\n =&gt; CACHED [11\/24] RUN opam repo --all-switches add --set-default coq-released https:\/\/coq.inria.fr\/opam\/released                                  0.0s\n =&gt; CACHED [12\/24] RUN opam update --all                                                                                                           0.0s\n =&gt; CACHED [13\/24] RUN opam pin add -y coq 8.11.0                                                                                                  0.0s\n =&gt; [14\/24] RUN opam install -y coq-serapi                                                                                                       176.3s\n =&gt; [15\/24] RUN eval $(opam env)                                                                                                                   0.2s\n =&gt; ERROR [16\/24] RUN pip install wandb --upgrade                                                                                                  8.0s\n------\n &gt; [16\/24] RUN pip install wandb --upgrade:\n#20 0.351 Defaulting to user installation because normal site-packages is not writeable\n#20 0.637 Collecting wandb\n#20 0.986   Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n#20 1.365 Requirement already satisfied: setuptools in \/opt\/conda\/lib\/python3.9\/site-packages (from wandb) (61.2.0)\n#20 1.366 Requirement already satisfied: six&gt;=1.13.0 in \/opt\/conda\/lib\/python3.9\/site-packages (from wandb) (1.16.0)\n#20 1.409 Collecting promise&lt;3,&gt;=2.0\n#20 1.472   Downloading promise-2.3.tar.gz (19 kB)\n#20 2.087 Collecting PyYAML\n#20 2.154   Downloading PyYAML-6.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (731 kB)\n#20 2.431 Collecting protobuf&lt;4.0dev,&gt;=3.12.0\n#20 2.492   Downloading protobuf-3.20.1-cp39-cp39-manylinux2014_aarch64.whl (917 kB)\n#20 2.648 Collecting setproctitle\n#20 2.706   Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (30 kB)\n#20 2.763 Collecting Click!=8.0.0,&gt;=7.0\n#20 2.818   Downloading click-8.1.3-py3-none-any.whl (96 kB)\n#20 2.902 Collecting sentry-sdk&gt;=1.0.0\n#20 2.962   Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n#20 3.112 Collecting psutil&gt;=5.0.0\n#20 3.172   Downloading psutil-5.9.2.tar.gz (479 kB)\n#20 3.871 Collecting pathtools\n#20 3.937   Downloading pathtools-0.1.2.tar.gz (11 kB)\n#20 4.431 Collecting shortuuid&gt;=0.5.0\n#20 4.509   Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n#20 4.512 Requirement already satisfied: requests&lt;3,&gt;=2.0.0 in \/opt\/conda\/lib\/python3.9\/site-packages (from wandb) (2.27.1)\n#20 4.568 Collecting docker-pycreds&gt;=0.4.0\n#20 4.636   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n#20 4.695 Collecting GitPython&gt;=1.0.0\n#20 4.781   Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n#20 4.834 Collecting gitdb&lt;5,&gt;=4.0.1\n#20 4.892   Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n#20 4.934 Collecting smmap&lt;6,&gt;=3.0.1\n#20 4.992   Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n#20 5.005 Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in \/opt\/conda\/lib\/python3.9\/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (1.26.8)\n#20 5.005 Requirement already satisfied: certifi&gt;=2017.4.17 in \/opt\/conda\/lib\/python3.9\/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2021.10.8)\n#20 5.006 Requirement already satisfied: idna&lt;4,&gt;=2.5 in \/opt\/conda\/lib\/python3.9\/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.3)\n#20 5.006 Requirement already satisfied: charset-normalizer~=2.0.0 in \/opt\/conda\/lib\/python3.9\/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.0.4)\n#20 5.075 Collecting urllib3&lt;1.27,&gt;=1.21.1\n#20 5.135   Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n#20 5.172 Building wheels for collected packages: promise, psutil, pathtools\n#20 5.172   Building wheel for promise (setup.py): started\n#20 5.851   Building wheel for promise (setup.py): finished with status 'done'\n#20 5.852   Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=6de0373376d2a8e995959e6173507e13cba502c79b648b5884b1eac45d1ec9ae\n#20 5.852   Stored in directory: \/home\/bot\/.cache\/pip\/wheels\/e1\/e8\/83\/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n#20 5.854   Building wheel for psutil (setup.py): started\n#20 6.226   Building wheel for psutil (setup.py): finished with status 'error'\n#20 6.226   ERROR: Command errored out with exit status 1:\n#20 6.226    command: \/opt\/conda\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d \/tmp\/pip-wheel-4y62c4eb\n#20 6.226        cwd: \/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/\n#20 6.226   Complete output (45 lines):\n#20 6.226   running bdist_wheel\n#20 6.226   running build\n#20 6.226   running build_py\n#20 6.226   creating build\n#20 6.226   creating build\/lib.linux-aarch64-3.9\n#20 6.226   creating build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_psosx.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_psbsd.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_common.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_pswindows.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_psposix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/__init__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_compat.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_pslinux.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_pssunos.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   copying psutil\/_psaix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 6.226   creating build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/__main__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_process.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_aix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_misc.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_bsd.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_linux.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/runner.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/__init__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_connections.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_unicode.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_windows.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_contracts.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_sunos.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_testutils.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_osx.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_memleaks.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_posix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   copying psutil\/tests\/test_system.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 6.226   running build_ext\n#20 6.226   building 'psutil._psutil_linux' extension\n#20 6.226   creating build\/temp.linux-aarch64-3.9\n#20 6.226   creating build\/temp.linux-aarch64-3.9\/psutil\n#20 6.226   gcc -pthread -B \/opt\/conda\/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem \/opt\/conda\/include -I\/opt\/conda\/include -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem \/opt\/conda\/include -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=592 -DPSUTIL_LINUX=1 -I\/opt\/conda\/include\/python3.9 -c psutil\/_psutil_common.c -o build\/temp.linux-aarch64-3.9\/psutil\/_psutil_common.o\n#20 6.226   gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 6.226   gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 6.226   gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 6.226   gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 6.226   error: command '\/usr\/bin\/gcc' failed with exit code 1\n#20 6.226   ----------------------------------------\n#20 6.226   ERROR: Failed building wheel for psutil\n#20 6.226   Running setup.py clean for psutil\n#20 6.550   Building wheel for pathtools (setup.py): started\n#20 7.135   Building wheel for pathtools (setup.py): finished with status 'done'\n#20 7.135   Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=8e205a0f68c9c7a3c0107d1cc40d94f1d2843c78270217378dcbe98212958b82\n#20 7.135   Stored in directory: \/home\/bot\/.cache\/pip\/wheels\/b7\/0a\/67\/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n#20 7.136 Successfully built promise pathtools\n#20 7.136 Failed to build psutil\n#20 7.195 Installing collected packages: smmap, urllib3, gitdb, shortuuid, setproctitle, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, Click, wandb\n#20 7.262   WARNING: The script shortuuid is installed in '\/home\/bot\/.local\/bin' which is not on PATH.\n#20 7.262   Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n#20 7.345     Running setup.py install for psutil: started\n#20 7.727     Running setup.py install for psutil: finished with status 'error'\n#20 7.727     ERROR: Command errored out with exit status 1:\n#20 7.727      command: \/opt\/conda\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-gb2y421d\/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers \/home\/bot\/.local\/include\/python3.9\/psutil\n#20 7.727          cwd: \/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/\n#20 7.727     Complete output (47 lines):\n#20 7.727     running install\n#20 7.727     \/opt\/conda\/lib\/python3.9\/site-packages\/setuptools\/command\/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n#20 7.727       warnings.warn(\n#20 7.727     running build\n#20 7.727     running build_py\n#20 7.727     creating build\n#20 7.727     creating build\/lib.linux-aarch64-3.9\n#20 7.727     creating build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_psosx.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_psbsd.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_common.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_pswindows.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_psposix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/__init__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_compat.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_pslinux.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_pssunos.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     copying psutil\/_psaix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\n#20 7.727     creating build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/__main__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_process.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_aix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_misc.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_bsd.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_linux.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/runner.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/__init__.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_connections.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_unicode.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_windows.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_contracts.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_sunos.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_testutils.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_osx.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_memleaks.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_posix.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     copying psutil\/tests\/test_system.py -&gt; build\/lib.linux-aarch64-3.9\/psutil\/tests\n#20 7.727     running build_ext\n#20 7.727     building 'psutil._psutil_linux' extension\n#20 7.727     creating build\/temp.linux-aarch64-3.9\n#20 7.727     creating build\/temp.linux-aarch64-3.9\/psutil\n#20 7.727     gcc -pthread -B \/opt\/conda\/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem \/opt\/conda\/include -I\/opt\/conda\/include -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem \/opt\/conda\/include -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=592 -DPSUTIL_LINUX=1 -I\/opt\/conda\/include\/python3.9 -c psutil\/_psutil_common.c -o build\/temp.linux-aarch64-3.9\/psutil\/_psutil_common.o\n#20 7.727     gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 7.727     gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 7.727     gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 7.727     gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 7.727     error: command '\/usr\/bin\/gcc' failed with exit code 1\n#20 7.727     ----------------------------------------\n#20 7.728 ERROR: Command errored out with exit status 1: \/opt\/conda\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-vgietl2j\/psutil_c905945489d349018aaad0a17600df0b\/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-gb2y421d\/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers \/home\/bot\/.local\/include\/python3.9\/psutil Check the logs for full command output.\n------\nexecutor failed running [\/bin\/sh -c pip install wandb --upgrade]: exit code: 1\n<\/code><\/pre>\n<p>why?<\/p>\n<p>Docker file so far:<\/p>\n<pre><code class=\"lang-auto\">FROM continuumio\/miniconda3\n\nRUN apt-get update \\\n  &amp;&amp; apt-get install -y --no-install-recommends \\\n    ssh \\\n    git \\\n    m4 \\\n    libgmp-dev \\\n    opam \\\n    wget \\\n    ca-certificates \\\n    rsync \\\n    strace\n\nRUN useradd -m bot\nWORKDIR \/home\/bot\nUSER bot\n\n## https:\/\/stackoverflow.com\/questions\/73642349\/how-to-have-miniconda-work-properly-with-docker-especially-naming-my-conda-en\n#RUN wget https:\/\/repo.anaconda.com\/miniconda\/Miniconda3-latest-Linux-x86_64.sh  \\\n#    &amp;&amp; bash Miniconda3-latest-Linux-x86_64.sh -b -f\n#ENV PATH=\"\/home\/bot\/miniconda3\/bin:${PATH}\"\n#RUN conda create -n pycoq python=3.9 -y\n## somehow this \"works\" but conda isn't fully aware of this. Fix later?\n#ENV PATH=\"\/home\/bot\/miniconda3\/envs\/pycoq\/bin:${PATH}\"\n\nADD https:\/\/api.github.com\/repos\/IBM\/pycoq\/git\/refs\/heads\/main version.json\n\n# -- setup opam like VP's PyCoq\nRUN opam init --disable-sandboxing\n# compiler + '_' + coq_serapi + '.' + coq_serapi_pin\nRUN opam switch create ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1 ocaml-variants.4.07.1+flambda\nRUN opam switch ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1\nRUN eval $(opam env)\n\nRUN opam repo add coq-released https:\/\/coq.inria.fr\/opam\/released\n# RUN opam pin add -y coq 8.11.0\n# ['opam', 'repo', '--all-switches', 'add', '--set-default', 'coq-released', 'https:\/\/coq.inria.fr\/opam\/released']\nRUN opam repo --all-switches add --set-default coq-released https:\/\/coq.inria.fr\/opam\/released\nRUN opam update --all\nRUN opam pin add -y coq 8.11.0\n\n#RUN opam install -y --switch ocaml-variants.4.07.1+flambda_coq-serapi_coq-serapi_8.11.0+0.11.1 coq-serapi 8.11.0+0.11.1\nRUN opam install -y coq-serapi\n\nRUN eval $(opam env)\n\n# makes sure depedencies for pycoq are installed once already in the docker image\nENV WANDB_API_KEY=\"SECRET\"\nRUN pip install wandb --upgrade\n<\/code><\/pre>\n<aside class=\"onebox stackexchange\" data-onebox-src=\"https:\/\/stackoverflow.com\/questions\/73642527\/how-to-install-wandb-on-a-docker-image-for-arm\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/stackoverflow.com\/questions\/73642527\/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">stackoverflow.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https:\/\/stackoverflow.com\/users\/1601580\/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img alt=\"Charlie Parker\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5e9c0a0caedbda92f5ad9bc087e52e143936f9f5.png\" class=\"thumbnail onebox-avatar\" width=\"256\" height=\"256\">\n  <\/a>\n\n<h4>\n  <a href=\"https:\/\/stackoverflow.com\/questions\/73642527\/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">How to install wandb on a docker image for arm?<\/a>\n<\/h4>\n\n<div class=\"tags\">\n  <strong>python, linux, docker, anaconda<\/strong>\n<\/div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https:\/\/stackoverflow.com\/users\/1601580\/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    Charlie Parker\n  <\/a>\n  on <a href=\"https:\/\/stackoverflow.com\/questions\/73642527\/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">12:07AM - 08 Sep 22 UTC<\/a>\n<\/div>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Running wandb server behind a jupyterhub proxy",
        "Question_link":"https:\/\/community.wandb.ai\/t\/running-wandb-server-behind-a-jupyterhub-proxy\/2930",
        "Question_created_time":"2022-08-15T00:54:18.007Z",
        "Question_answer_count":13,
        "Question_score_count":0,
        "Question_view_count":252,
        "Question_body":"<p>i\u2019m trying to proxy the wandb \u201clocal\u201d server that runs under docker behind jupyterhub. (Playing with an on-prem install to do labs in the new full stack-dl course). Jupyterhub has a proxy server which lets one obtain an app at an arbitrary port show up at a given url.  The wandb server wants a particular url, but to be behind jupyterhub i need the base url for the wandb server to be something like <a href=\"http:\/\/hostname\/hub\/user-redirect\/proxy\/8080\" rel=\"noopener nofollow ugc\">http:\/\/hostname\/hub\/user-redirect\/proxy\/8080<\/a>. Is it possible to set a base url as an option in the docker container\/arguments to the local web server in the container there?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Force Bayesian sweep to run certain variable tests",
        "Question_link":"https:\/\/community.wandb.ai\/t\/force-bayesian-sweep-to-run-certain-variable-tests\/3098",
        "Question_created_time":"2022-09-12T08:09:38.525Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":138,
        "Question_body":"<p>Hi!<br>\nI want to run a bayesian HP sweep with 5-fold CV. In other words I want the bayesian sweep to decide upon a configuration, run 5 runs with that configuration and log each run. The easiest way to do this would be to have a variable in the sweep, called e.g. fold_id which simply can take the values 1,2,3,4,5 and force the agent to always test all the fold_ids per configuration.<\/p>\n<p>Is there any way to make this possible? I.e force the sweep agent to always test a variable, even though running a bayesian sweep. In a way it would be like running a grid sweep over a bayesian sweep.<\/p>\n<p>One way I\u2019ve thought of is by making all parameters nested inside the fold_id variable but it still won\u2019t probably do what I\u2019m after.<\/p>\n<p>I\u2019ve seen the k-fold CV example code, but it\u2019s quite advanced and does not seem to work when running on CUDA and my understanding of multiprocessing is limited.<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":"2022-09-15T16:51:08.921Z",
        "Answer_body":"<p>You can create a nested sweep where each fold could be a list and then you can then iterate over those values.  Make sure that the run name changes per run so that way the runs don\u2019t overwrite one another.<\/p>\n<p>Here\u2019s an example config of a nested sweep:<\/p>\n<pre><code class=\"lang-auto\">command:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nmethod: random\nparameters:\n  MULTI_STAGE_TRAINING:\n    value:\n      DEPTH_SCALE:\n        - 100\n        - 100\n      HEAD:\n        - OBJECT_DETECTION\n      NETWORK:\n        - net_a\n        - net_b\n        - net_c\n      NUM_EPOCHS_IN_EACH_STAGE:\n        - 0\n        - 1\n        - 2\n        - 3\n      NUM_STAGES:\n        - 0\n        - 1\n        - 2\n        - 3\n        - 4\n        - 5\n        - 6\n        - 7\n        - 8\n        - 9\n      OPTIMIZER_PARAMS_PER_STAGE:\n        lr:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        momentum:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        weight_decay:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n  epochs:\n    value: 10\nprogram: script.py\n<\/code><\/pre>\n<p>And here\u2019s a script that is able to run it:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\u200b\ndef create_sweep(\n    sweep_config:dict,\n    update:bool,\n    project:str,\n    entity:str):\n    \n    parameters_dict = {'MULTI_STAGE_TRAINING':\n                   {'value':\n                    {'NUM_STAGES':list(range(10)),\n                     'OPTIMIZER_PARAMS_PER_STAGE':\n                     {'lr':list(range(10)),'momentum': list(range(10)),'weight_decay':list(range(10))},\n                     'NUM_EPOCHS_IN_EACH_STAGE':list(range(4)),\n                     'NETWORK':['net_a','net_b','net_c'],\n                     'HEAD':['OBJECT_DETECTION'],\n                     'DEPTH_SCALE': [100,100]\n                     }\n                    }\n                   }\n    sweep_config['parameters'] = parameters_dict\n    \n    parameters_dict.update({\n    'epochs': {\n        'value': 10}\n    })\n    return wandb.sweep(sweep_config,entity=entity,project=project)\n\u200b\nif __name__ == '__main__':\n\u200b\n    SWEEP_CONFIG = {\n    'method': 'random',\n    'program':'script.py',\n    'command':['${env}', 'python3', '${program}','${args}']\n    }\n    ENTITY = 'demonstrations'\n    PROJECT = 'sweep_gm'\n    UPDATE = True\n\u200b\n    sweep = create_sweep(\n        sweep_config=SWEEP_CONFIG,\n        entity=ENTITY,\n        project=PROJECT,\n        update=UPDATE)\n<\/code><\/pre>\n<p>Let me know if you need any further help with this!<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Parallel coordinate plot doesn't work with nested groupings",
        "Question_link":"https:\/\/community.wandb.ai\/t\/parallel-coordinate-plot-doesnt-work-with-nested-groupings\/3102",
        "Question_created_time":"2022-09-13T08:51:19.631Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":132,
        "Question_body":"<p>Hi!<\/p>\n<p>I have tried to use a parallel coordinate plot with a nested group, and it only shows the top-level group, whereas line plots correctly show multiple level groups. See screenshot below for example\u2014there are 3 lines on the parallel coordinates, but 6 on the line plot. Is this correct behaviour?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda.png\" data-download-href=\"\/uploads\/short-url\/oRjaIBHNsSCjMDTUurlQOHfluci.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_503x500.png\" alt=\"image\" data-base62-sha1=\"oRjaIBHNsSCjMDTUurlQOHfluci\" width=\"503\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_503x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_754x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_1006x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1042\u00d71034 127 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to do \"Pnael Export\", I found no button of it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-do-pnael-export-i-found-no-button-of-it\/2991",
        "Question_created_time":"2022-08-25T04:13:05.513Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":207,
        "Question_body":"<p>I want to export all log from cloud like this \" <a href=\"https:\/\/wandb.ai\/site\/articles\/export-data-from-wb\">Export Your Data from W&amp;B on Weights &amp; Biases (wandb.ai)<\/a>\". However, there  is no option for \u201cPanel Export\u201d now. How should I do?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting `AttributeError : 'NoneType' object has no attribute '_log' `when trying to run test set",
        "Question_link":"https:\/\/community.wandb.ai\/t\/getting-attributeerror-nonetype-object-has-no-attribute-log-when-trying-to-run-test-set\/3090",
        "Question_created_time":"2022-09-09T17:52:20.278Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":1200,
        "Question_body":"<p><strong>Framework: Pytorch<\/strong><br>\n<strong>wandb version : 0.13.3<\/strong><br>\n<strong>workspace: Google colab<\/strong><\/p>\n<pre><code class=\"lang-python\">config = dict(\n    dropout = 0.4,\n    train_batch = 3,\n    val_batch = 1,\n    test_batch = 1,\n    learning_rate = 0.001,\n    epochs = 5,\n    architecture = \"CNN\",\n    model_name = \"efficientnet-b0\",\n    infra = \"Colab\",\n    dataset=\"dysphagia_dataset2\"\n    )\n\n<\/code><\/pre>\n<p>My test function<\/p>\n<pre><code class=\"lang-auto\">def test_model():\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.append(labels.item())\n            outputs = model_ft(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            pred_labels.append(preds.item())\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n        acc = running_correct\/running_total\n    return (true_labels, pred_labels, running_correct, running_total, acc)\n\n\ntrue_labels, pred_labels, running_correct, running_total, acc = test_model()\n\n<\/code><\/pre>\n<p><strong>Error<\/strong><\/p>\n<pre><code class=\"lang-bash\">AttributeError                            Traceback (most recent call last)\n\n&lt;ipython-input-26-b7dbeaddcbbb&gt; in &lt;module&gt;\n----&gt; 1 true_labels, pred_labels, running_correct, running_total, acc = test_model()\n      2 \n\n4 frames\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    254             bins = torch.Tensor(bins_np)\n    255 \n--&gt; 256         wandb.run._log(\n    257             {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n    258             commit=False,\n\nAttributeError: 'NoneType' object has no attribute '_log'\n<\/code><\/pre>\n<p>This is how i initialize training:<\/p>\n<pre><code class=\"lang-python\">model_ft = train_model(model_ft, \n                       criterion, \n                       optimizer_ft,\n                       config\n                       )\n<\/code><\/pre>\n<p>my wandb init:<\/p>\n<pre><code class=\"lang-python\">wandb.init(config=config,\n           name='efficientnet0+albumentions',\n           group='pytorch-efficientnet-baseline', \n           project='dysphagia_image_classification',\n           job_type='train')\nconfig = wandb.config\n\n<\/code><\/pre>",
        "Question_closed_time":"2022-09-09T19:44:50.228Z",
        "Answer_body":"<p>Finally caught my mistake <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slightly_smiling_face.png?v=12\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<pre><code class=\"lang-auto\">model_ft._fc = nn.Sequential(\n    nn.BatchNorm1d(num_features=num_ftrs),    \n    nn.Linear(num_ftrs, 512),\n    nn.ReLU(),\n    nn.BatchNorm1d(512),\n    nn.Linear(512, 128),\n    nn.ReLU(),\n    nn.BatchNorm1d(num_features=128),\n    nn.Dropout(p=config.dropout), # Error due to this\n    nn.Linear(128, 2),\n    )\n\nmodel_ft = model_ft.to(device)\n\n<\/code><\/pre>\n<p>I was calling my test function outside of  wandb(only used wandb for training)and wandb must have call <code>.finish<\/code> so, it must have set the my config dict:-&gt; None  as I was passing it to wandb.config.<\/p>\n<p>Now , my model class use one of the config (dropout) but I passed my config file into wandb config so, it set it to None after my model finish training. So, when my def test function use my model, the dropout hyparameter value is None now!<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Invited to org, the login is broken",
        "Question_link":"https:\/\/community.wandb.ai\/t\/invited-to-org-the-login-is-broken\/3070",
        "Question_created_time":"2022-09-05T13:43:12.872Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":78,
        "Question_body":"<p>I was invited to an org, logged in and when I try to accept the invite I receive a page saying:<\/p>\n<p>\"XXX is an invite-only team.<\/p>\n<p>Received an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\"<\/p>\n<p>the thing is I am logged in with the mail I was invited by, suggestions?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Interprete gradient graphs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/interprete-gradient-graphs\/3052",
        "Question_created_time":"2022-09-02T13:25:01.171Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":312,
        "Question_body":"<p>Hi everyone,<br>\nAttached is the gradient histograms of my training. It seems that the gradient for lin1.weight and line2.weight are mostly zero everywhere.  Does it mean that the model doesn\u2019t learn anything from these parameters and should I exclude them my optimizer?<\/p>\n<p>Thank you very much<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367.png\" data-download-href=\"\/uploads\/short-url\/uhFmZAeJe0w8aS6Cbez7CQKl5j1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png\" alt=\"image\" data-base62-sha1=\"uhFmZAeJe0w8aS6Cbez7CQKl5j1\" width=\"690\" height=\"238\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1035x357.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1380x476.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1808\u00d7624 111 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to reenable automatic synchronisation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-reenable-automatic-synchronisation\/3061",
        "Question_created_time":"2022-09-04T01:29:31.968Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":161,
        "Question_body":"<p>I made a change to my script and now I have to manually synchronise my runs, my script contains<\/p>\n<pre><code>if args.dry_run:\n    os.environ['WANDB_MODE'] = 'dryrun'\n\nwandb.init(project=args.project_name, notes=args.notes)\n\n# log all experimental args to wandb\nwandb.config.update(args)\n<\/code><\/pre>\n<p>The change I made was the first line, setting <code>WANDB_MODE=dryrun<\/code>. From that point on I cannot re-enable automatic synchronisation.<\/p>\n<p>I\u2019ve run <code>wandb online<\/code> and run my script with <code>dryrun=False<\/code>. I also realised that this doesn\u2019t unset WANDB_MODE so I tried setting it to \u2018online\u2019 when <code>dryrun==False<\/code>. But it always ends up logging to <code>wandb\/offline-run-*<\/code> and I have to manually sync it.<\/p>\n<p>Is there another step to re-enable sync\u2019ing?<\/p>",
        "Question_closed_time":"2022-09-05T05:21:29.729Z",
        "Answer_body":"<p>I\u2019ve found a way around this - I\u2019m not really sure why it\u2019s happening but I noticed that the huggingface trainer logs the metrics at the end of training as follows:<\/p>\n<pre><code>                if not args.load_best_model_at_end\n                else {\n                    f\"eval\/{args.metric_for_best_model}\": state.best_metric,\n                    \"train\/total_floss\": state.total_flos,\n                }\n<\/code><\/pre>\n<p>Meaning it logs the validation loss, but only if you train with <code>load_best_model_at_end=True<\/code> and set <code>save_strategy==evaluation_strategy<\/code> (epoch or steps) and <code>save_steps=eval_steps<\/code>.<\/p>\n<p>Doing this means I didn\u2019t need to perform the separate eval step since it\u2019s already logged the evaluation loss from the best model during training.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"How to keep only last checkpoint artifact?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-keep-only-last-checkpoint-artifact\/3014",
        "Question_created_time":"2022-08-27T08:35:42.720Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":724,
        "Question_body":"<p>How do I keep only the last checkpoint artifact in wandb?<\/p>\n<p>I am using lightning\u2019s ModelCheckpoint to periodically save my checkpoint artifact to wandb. However, these artifacts are really large. If I keep multiple checkpoint artifact versions on wandb, they get big really quickly.<\/p>\n<p>However, I can\u2019t just checkpoint at the end of training. My GPUs occasionally terminate, so I need to checkpoint periodically.<\/p>\n<p>How do I make sure that only the last checkpoint artifact is kept on wandb?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Showing total loss in distributed computing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/showing-total-loss-in-distributed-computing\/2923",
        "Question_created_time":"2022-08-13T22:40:05.468Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":418,
        "Question_body":"<p>Hello,<\/p>\n<p>I am trying to use wandb to monitor my loss functions and I am running my code on multiple GPU nodes. When logging my loss function I can see 4 different links for each node. However, I would like to see the total loss and have one process reporting that through wandb. How should I take care of this?<\/p>\n<p>I would appreciate any feedback as I am totally new to this community,<br>\nThanks,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plot overlay obscures most of plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plot-overlay-obscures-most-of-plot\/3044",
        "Question_created_time":"2022-09-01T04:34:45.138Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":83,
        "Question_body":"<p>See screenshot, when I mouse over the plot showing the value of a metric across multiple runs, the acutal shape of the plot is obscured by the detail view almost all of the time. This makes it almost impossible to visually compare runs while also seeing precise values at certain points.<\/p>\n<p>Additionally, assuming this gets fixed by moving the detail view to the lower-right portion of the plot (or even outside the bounds of the plot entirely), it would be really nice to see a horizontal guide in addition to a vertical guide, so I can visually tell  how the peaks of a given run compare to the peaks of other runs a different points in time (I\u2019m using <code>tfa.optimizers.CyclicalLearningRate<\/code> so my metrics have a rather spiky nature).<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2590f8667fb82a696da92b44e20ea000587efde7.png\" alt=\"Screen Shot 2022-09-01 at 2.24.01 pm\" data-base62-sha1=\"5mkgmk48PEjHXdWpVtiAwgVAwZN\" width=\"477\" height=\"277\"><\/p>\n<p>Screenshot showing spiky nature of metric plot:<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f72adaf4477903b571813ced8457fdf9cdab5c34.png\" alt=\"Screen Shot 2022-09-01 at 2.31.11 pm\" data-base62-sha1=\"zgxKDAV5kmh1mT2P88Unv5CvThO\" width=\"422\" height=\"151\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb login issue",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-login-issue\/3023",
        "Question_created_time":"2022-08-29T11:52:50.926Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":1317,
        "Question_body":"<p>Hi, everytime I run my experiment in kubernetes, wandb is asking for options wandb:<br>\n(1) Create a W&amp;B account<br>\nwandb: (2) Use an existing W&amp;B account<br>\nwandb: (3) Don\u2019t visualize my results<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Code Comparer can only show the difference of main training file",
        "Question_link":"https:\/\/community.wandb.ai\/t\/code-comparer-can-only-show-the-difference-of-main-training-file\/3020",
        "Question_created_time":"2022-08-29T11:36:01.165Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":160,
        "Question_body":"<p>If I call <code>wandb.run.log_code(\".\")<\/code>, all python source code files in the current directory are saved in W&amp;B cloud. That\u2019s what I want.<\/p>\n<p>However, only changes in main training file where I call <code>wandb.init()<\/code> can be shown in <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/panels\/code#code-comparer\">Code Comparer<\/a>. The change in other file (like <code>helper_funcs.py<\/code>) will not appear in code panel. Do you have any suggestions about it?<\/p>",
        "Question_closed_time":"2022-08-31T14:14:44.028Z",
        "Answer_body":"<p>Hi Yao, thanks for writing in! As you have said, you can\u2019t compare in the panel other files than the one where you call <code>wandb.init()<\/code>, but you can compare them in the artefacts tab. I send you a video on how to do this. Please let me know if this would work for you.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Feature Request: Embed only a table\/report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-embed-only-a-table-report\/3037",
        "Question_created_time":"2022-08-30T23:42:17.612Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":246,
        "Question_body":"<p>I intend to do a series of blog posts which use W&amp;B reports like this one:<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/31da22c8b3786e20cdf0326872a564cdf70efa6d.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\" target=\"_blank\" rel=\"noopener nofollow ugc\">write.farook.org<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/199;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg\" class=\"thumbnail\" width=\"690\" height=\"199\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_1035x298.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_1380x398.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\" target=\"_blank\" rel=\"noopener nofollow ugc\">Stable Diffusion Parameter Variations \u2013 Meandering Musings<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>As you\u2019ll notice, I have multiple reports in the blog post. The current embed with an IFRAME takes up way too much space because of the header and the footer where you can comment etc. I\u2019d prefer to have the ability to just embed a table (or preferably) the content section of a report.<\/p>\n<p>Does this ability currently exist? I checked the documentation but couldn\u2019t find anything like that.<\/p>\n<p>If the functionality does not exist, being able to do so in future would be a great help for me and probably for others too.<\/p>\n<p>I currently take screenshots of the relevant part of the report and then link to the full report on W&amp;B. But I hope you\u2019d agree that having the interactivity of the W&amp;B report in the post itself would be much more preferable <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NotFoundError()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/notfounderror\/3006",
        "Question_created_time":"2022-08-25T16:42:15.566Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":309,
        "Question_body":"<p>Hi,<\/p>\n<p>I was wondering if you have any suggestions on what could be causing the following error:<\/p>\n<p>wandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)<br>\nwandb: Find logs at: .\/wandb\/run-20220825_163228-73lfow6y\/logs<br>\nRun 73lfow6y errored: NotFoundError()<br>\nwandb: ERROR Run 73lfow6y errored: NotFoundError()<\/p>\n<p>Please note, I am using:<br>\nPython 3.7.12<br>\nwandb, version 0.13.2<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Local controller seems block",
        "Question_link":"https:\/\/community.wandb.ai\/t\/local-controller-seems-block\/2955",
        "Question_created_time":"2022-08-18T06:17:13.186Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":346,
        "Question_body":"<p>I make the following sweep (yaml) file:<\/p>\n<pre><code class=\"lang-auto\">program: train_mnist.py\nmethod: grid\nparameters:\n  lr_schedule:\n    values: [ step, cyclic ]\n  epoch_total:\n    values: [ 2, 4 ]\nmetric:\n  goal: maximize\n  name: test-result\/accuracy\nproject: my-mnist-test-project\nname: MNIST-Sweep-Test\ndescription: test sweep demo\n<\/code><\/pre>\n<p>and I use <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/advanced-sweeps\/local-controller#running-the-local-controller-from-the-command-line\">local controller<\/a> to perform sweep locally. However, it seems block here:<\/p>\n<pre><code class=\"lang-auto\">(pytorch) geyao@geyaodeMacBook-Air wandb_test % wandb sweep --controller sweep_config.yaml\nwandb: Creating sweep from: sweep_config.yaml\nwandb: Created sweep with ID: o2mzl569\nwandb: View sweep at: https:\/\/wandb.ai\/geyao\/my-mnist-test-project\/sweeps\/o2mzl569\nwandb: Run sweep agent with: wandb agent geyao\/my-mnist-test-project\/o2mzl569\nwandb: Starting wandb controller...\nSweep: o2mzl569 (grid) | Runs: 0\n\n# ------blocked here!------\n<\/code><\/pre>\n<p>When I turn off the network, it will be:<\/p>\n<pre data-code-wrap=\"shell\"><code class=\"lang-nohighlight\">(pytorch) geyao@geyaodeMacBook-Air wandb_test % wandb sweep --controller sweep_config.yaml\nwandb: Creating sweep from: sweep_config.yaml\nwandb: Network error (ConnectionError), entering retry loop.\n<\/code><\/pre>\n<p>Why local controller tries to connect the network? How can I perform local sweep with\/without network in the right way?<\/p>",
        "Question_closed_time":"2022-09-01T00:39:13.334Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> , the local controller doesn\u2019t have the full functionality of W&amp;B cloud, and is not intended for actual hyperparameter optimization workloads. It\u2019s intended for development and debugging of new algorithms for the Sweeps tool. You don\u2019t need to connect to W&amp;B cloud service to use the controller.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Legend ordering",
        "Question_link":"https:\/\/community.wandb.ai\/t\/legend-ordering\/3041",
        "Question_created_time":"2022-08-31T23:35:30.181Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":170,
        "Question_body":"<p>Hey all,<br>\nI was just wondering if its possible to rearrange\/order elements in the legend of a chart? I have different data series that each go by a number and right now, the legend displays these numbers in random order\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rate limit exceeded wandb website",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rate-limit-exceeded-wandb-website\/3001",
        "Question_created_time":"2022-08-25T06:55:37.930Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":159,
        "Question_body":"<p>Help! I can\u2019t log in to my wandb on the web. It returns Rate limit exceed error. It\u2019s been like this for hours @@.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb docker-run fails to detect image argument",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-docker-run-fails-to-detect-image-argument\/3033",
        "Question_created_time":"2022-08-30T18:09:27.257Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":83,
        "Question_body":"<p>Trying to set up wandb, I get the following error when running<\/p>\n<pre><code class=\"lang-auto\">wandb docker-run [docker run options] [IMAGE] bash\n<\/code><\/pre>\n<p>wandb: Couldn\u2019t detect image argument, running command without the WANDB_DOCKER env variable<\/p>\n<p>The image loads as usual but I cannot access wandb.<\/p>\n<p>Error presents even after deleting all docker run options.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Getting KeyError: tensor([0]) while plotting wandb's confusion matrix",
        "Question_link":"https:\/\/community.wandb.ai\/t\/getting-keyerror-tensor-0-while-plotting-wandbs-confusion-matrix\/2974",
        "Question_created_time":"2022-08-22T16:46:51.132Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":337,
        "Question_body":"<p>Hi,<br>\nI am trying to plot confusion matrix using wandb\u2019s API.<br>\nBut I am getting<\/p>\n<pre><code class=\"lang-auto\">  File \"\/home\/ubuntu\/anaconda3\/envs\/pytorch_p38\/lib\/python3.8\/site-packages\/wandb\/plot\/confusion_matrix.py\", line 72, in confusion_matrix\n    counts[class_mapping[y_true[i]], class_mapping[preds[i]]] += 1\nKeyError: tensor([0])\n<\/code><\/pre>\n<p>My validation loops like below -<\/p>\n<pre><code class=\"lang-auto\">for batch_idx, (data, target) in enumerate(loader['valid']):\n     output = model(data)\n     preds = torch.max(output, dim=1, keepdim=True)[1]\n     wandb.log({\"conf_mat\": wandb.plot.confusion_matrix(y_true=target, preds=preds, # noqa\n                       class_names=class_names)})\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parameter importance for categorical variables",
        "Question_link":"https:\/\/community.wandb.ai\/t\/parameter-importance-for-categorical-variables\/2966",
        "Question_created_time":"2022-08-22T07:13:28.896Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":223,
        "Question_body":"<p>Hi!<\/p>\n<p>I have a conditional variable (True\/False) in my sweep for freezing a layer or not. It gets quite high importance and a high positive correlation. How do I know if the \u201cTrue\u201d or the \u201cFalse\u201d is the \u201chigher\u201d value? In other words, how do I know which to set it to? Is it based on the order specified in the sweep-config? Unfortunately I cannot see any clear pattern in the runs due to a lot of other parameters also being varied at the time in my Bayesian sweep.<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Login error! init error + broken pipeline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/login-error-init-error-broken-pipeline\/2926",
        "Question_created_time":"2022-08-14T16:35:44.419Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":185,
        "Question_body":"<p>Hi there, I am facing this issue while using wandb.init().<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4de690d919b9d13b072bd6968c7c5a6d8c4061af.png\" data-download-href=\"\/uploads\/short-url\/b78KvLFKhAaWKkyNhJ2WPEjnkBN.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4de690d919b9d13b072bd6968c7c5a6d8c4061af.png\" alt=\"image\" data-base62-sha1=\"b78KvLFKhAaWKkyNhJ2WPEjnkBN\" width=\"690\" height=\"364\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/4de690d919b9d13b072bd6968c7c5a6d8c4061af_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1211\u00d7640 24.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I tried running following instructions:<\/p>\n<pre><code class=\"lang-auto\">wandb.init(settings=wandb.Settings(start_method='fork'))\nor\nwandb.init(settings=wandb.Settings(start_method='thread'))\n<\/code><\/pre>\n<p>is not working.<\/p>\n<p>Help would be appreciated, thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"xAxis settings for line plot over different runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/xaxis-settings-for-line-plot-over-different-runs\/2894",
        "Question_created_time":"2022-08-10T19:48:28.832Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":82,
        "Question_body":"<p>I have developed a script to estimate some hardware evaluations for running my neural network. As parameter for this script the number of layers can be defined. This parameter is also passed to Wand.config.<br>\nThen the network trains over several epochs and evaluates the hardware. The results are all logged. At the end I would like to have a line chart with the number of layers as xaxis and for example the energy consumption on the yaxis. However, it is not possible to select the num_layers parameter in the menu.<br>\nMy guess is that line charts can only be plotted across a run and not as in my case where per value of the xaxis (num_layers) a different run specifies the value.<\/p>\n<p>Is there any way to implement my plan in Wandb in an automated way? Otherwise I would have to export the data and plot it with matplotlib etc.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging multiline plots",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-multiline-plots\/3025",
        "Question_created_time":"2022-08-29T15:12:03.618Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":90,
        "Question_body":"<p>I\u2019m looking for an elegant way to log multiline plots (e.g. showing AUROC and AUPRC on one plot) whilst training, and using the wandb.log() function. As far as I can tell, the only way is to keep track of the values from the start of training up until the current iteration, then log a wandb.plot.line (according to <a href=\"https:\/\/wandb.ai\/wandb\/plots\/reports\/Custom-Line-Plots--VmlldzoyNjk5NTA\" class=\"inline-onebox\">Weights &amp; Biases<\/a>), however this is a different interface from the standard use of wandb.log(), wherein you only give the latest value.<\/p>\n<p>Is there some way to do what I\u2019m looking for (multiline plots that update each iteration of training, and only need to be given the latest value for each variable)?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb takes too much time after each run ends",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-takes-too-much-time-after-each-run-ends\/2947",
        "Question_created_time":"2022-08-16T21:43:49.100Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":288,
        "Question_body":"<p>I\u2019ve been using wandb sweeps and I found that after each run is finished, the following message shows up<\/p>\n<blockquote>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success)<\/p>\n<\/blockquote>\n<p>but then 10 minutes pass with nothing happening.<br>\nOnly after this long time wandb shows the run history and summary and starts a new run.<br>\nI\u2019m using wandb in a Gradient Paperspace notebook, running it from the terminal.<\/p>\n<p>I\u2019ve found anyone else with this issue, so it may be something wrong at my side.<br>\nDo you have any idea of what the problem might be?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plotting confusion matrix",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plotting-confusion-matrix\/2902",
        "Question_created_time":"2022-08-11T12:31:44.757Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":174,
        "Question_body":"<p>I\u2019m training a model and I\u2019m trying to add a confusion matrix, which would be displayed in my wandb, but got lost a bit. Basically, the matrix works, I can print it, but it\u2019s not loaded into wandb. Everything should be ok, except it\u2019s not. Can you please help me? I\u2019m new to all this. Thanks a lot!<\/p>\n<pre><code class=\"lang-auto\">                nb_classes = 7\n\n                confusion_matrix = torch.zeros(nb_classes, nb_classes)\n                with torch.no_grad():\n                    for i, (inputs, classes) in enumerate(dataloaders['val']):\n                        inputs = inputs.to(device)\n                        classes = classes.to(device)\n                        outputs = model_ft(inputs)\n                        _, preds = torch.max(outputs, 1)\n                    \n                    for t, p in zip(classes.view(-1), preds.view(-1)):\n                        confusion_matrix[t.long(), p.long()] += 1\n              wandb.log({'matrix' : confusion_matrix})\n                           \n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"All records are lost in a project without any action",
        "Question_link":"https:\/\/community.wandb.ai\/t\/all-records-are-lost-in-a-project-without-any-action\/2993",
        "Question_created_time":"2022-08-25T04:55:18.517Z",
        "Question_answer_count":13,
        "Question_score_count":5,
        "Question_view_count":297,
        "Question_body":"<p>Dear Sir or Madam,<\/p>\n<p>Sorry for bothering you, I think there is an error in one of my wandb projects and the records of all runs were lost. The account is nbower0707, email 1155156871@link.cuhk.edu.hk, and the project name is ocp22.<\/p>\n<p>Everything worked fine before today, and I did a lot of experiments on this project. I\u2019m uploading records of my metric around every 5000 steps, and the result validation metric plot should be something like  figure 1 shows(continuous lines of records, with multiple data points) I\u2019m uploading the corresponding metrics every 2500 steps, and wandb displayed all results fine yesterday (either undergoing or finished runs)<\/p>\n<p>However, when I check the plot today, the record of metric in all runs were (completely or partly) lost, except for some small isolated data points left (as figure 2 and 3 shows).<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d.jpeg\" data-download-href=\"\/uploads\/short-url\/n0TMrYL9SyvpaH1YKsBmceDhhRb.jpeg?dl=1\" title=\"Picture 1\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg\" alt=\"Picture 1\" data-base62-sha1=\"n0TMrYL9SyvpaH1YKsBmceDhhRb\" width=\"414\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_621x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_828x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Picture 1<\/span><span class=\"informations\">2337\u00d72818 348 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I tried to use <strong>wandb sync<\/strong> from the local file, and upload the runs to a new project, the result is still the same.<\/p>\n<p>I didn\u2019t do any specific operations regarding wandb logging process or on the website. The project consist of runs uploaded from different machines, therefore it wouldn\u2019t be mistakenly deletion\/ false operation offline. And the phenomenon of lost of data also occurs on old runs that finished weeks ago.<\/p>\n<p>Please let me know if you have any suggestions on this error, and if the records could be recovered.<\/p>\n<p>Your time and patience are sincerely appreciated.<\/p>\n<p>Bowen Wang<\/p>",
        "Question_closed_time":"2022-08-25T21:07:26.293Z",
        "Answer_body":"<p>Hey all,<\/p>\n<p>Our engineering team looked into this and rolled back some changes, everything should be working fine now.<\/p>\n<p>Please let us know if this issue persists.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Can I resume the sweep using python code instead of command?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/can-i-resume-the-sweep-using-python-code-instead-of-command\/2976",
        "Question_created_time":"2022-08-23T04:25:44.841Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":123,
        "Question_body":"<p>I meet the <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/3344\" rel=\"noopener nofollow ugc\">bug<\/a> when I try to resume the sweep through command. I want to know if there exists the way to resume the sweep using python code.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Please delete my account",
        "Question_link":"https:\/\/community.wandb.ai\/t\/please-delete-my-account\/2978",
        "Question_created_time":"2022-08-23T10:37:26.876Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":118,
        "Question_body":"<p>Can you please delete this account (gws-flux). Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot find a specific column in sweep -> sweep table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-find-a-specific-column-in-sweep-sweep-table\/2925",
        "Question_created_time":"2022-08-14T04:00:40.995Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":147,
        "Question_body":"<p>When searching, I first hide all the columns (because in total there are more than 500 entries, which cannot be fully visible), and then I search for my intended column, but I find that I cannot find it. What\u2019s weird is that I didn\u2019t change my code and i am pretty sure I can see them before. Also, I can see that entry (i.e., a bleu result) in the charts. What\u2019s happening?<\/p>\n<p>Actually, I can see that entry appears for a millisecond, and then disappears. So, I guess that the table can only show arguments instead of result from now on?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use GPU with Keras - Colab File Missing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/use-gpu-with-keras-colab-file-missing\/2879",
        "Question_created_time":"2022-08-09T23:00:55.369Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":92,
        "Question_body":"<p>Link: <a href=\"https:\/\/wandb.ai\/authors\/ayusht\/reports\/Use-GPUs-with-Keras--VmlldzoxNjEyNjE?_gl=1%2A1uwdrw1%2A_ga%2AMTA2NjE2OTcwOC4xNjYwMDgxMDY1%2A_ga_JH1SJHJQXJ%2AMTY2MDA4MTA2NC4xLjEuMTY2MDA4NTg2MC41Mg\" class=\"inline-onebox\">Weights &amp; Biases<\/a>\u2026<\/p>\n<h1>\n<a name=\"using-gpus-with-keras-a-tutorial-with-code-1\" class=\"anchor\" href=\"#using-gpus-with-keras-a-tutorial-with-code-1\"><\/a>Using GPUs With Keras: A Tutorial With Code<\/h1>\n<p>I am following this article to Monitor GPU and CPU performances but Colab file is missing. I wish to see this tutorial Can you help in this regard<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Show only columns with different values in experiments table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/show-only-columns-with-different-values-in-experiments-table\/2972",
        "Question_created_time":"2022-08-22T15:58:05.637Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":109,
        "Question_body":"<p>In the table view of a project, is it possible to show only the columns that have different values among runs? This would be very useful to quickly explore how changing parameters affect the model.<\/p>",
        "Question_closed_time":"2022-08-24T23:22:17.881Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/enajx\">@enajx<\/a> , would the run comparer table work for your use case, see <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/panels\/run-comparer\">here<\/a>.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Is parameter importance affected by the number of runs in bayesian sweep?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-parameter-importance-affected-by-the-number-of-runs-in-bayesian-sweep\/2965",
        "Question_created_time":"2022-08-22T06:57:27.397Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":132,
        "Question_body":"<p>Hi!<\/p>\n<p>I have used wandb for a while now and since this is my first post here I must begin by extending my thanks to the team for making a great product! To my question:<\/p>\n<p>I have just started using Bayesian sweeps instead of grid based. I have a question about the parameter importance chart that you may add. If I understand it correctly, the bayesian sweep runs a couple of runs to build a probability model for e.g. the validation loss based on tweeking the given parameters inside their span. So in other words if permitted to run for say 100 runs, there will be many more runs inside the parameter-span where the probability of getting a low validation loss is highest than the opposite. This also means that some parameter configurations will be vastly overrepresented.<\/p>\n<p>Does it matter that there is a big inbalance in the tested parameter configurations when making the \u201cParameter Importance\u201d chart\/panel? I don\u2019t know much about how the RF importance parameter is achieved, but for the Correlation it seems to me that this would be affected. Now I don\u2019t if that would be a bad thing, since I guess it should reflect the probability model but I would just like to hear someone else\u2019s opinion on the matter <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Embed Plotly Graphs in HTML",
        "Question_link":"https:\/\/community.wandb.ai\/t\/embed-plotly-graphs-in-html\/2986",
        "Question_created_time":"2022-08-24T15:07:20.713Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":208,
        "Question_body":"<p>I would like to use some of my wandb plots to <a href=\"https:\/\/plotly.com\/python\/embedding-plotly-graphs-in-HTML\/\" rel=\"noopener nofollow ugc\">Embed Plotly Graphs in HTML<\/a>. Is there anyway to get similar functionality? If it cannot be done directly on wandb I see the other option as downloading the graphs, and uploading them to Plotly Chart Studio where they can then be embedded in HTML.<\/p>\n<p>I do like reports, but this would allow for the inclusion of plots in a wider scope of documents. For example, papers for publication, books, or even a dissertation.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scores of BoundingBoxes2D object now showing in workspace",
        "Question_link":"https:\/\/community.wandb.ai\/t\/scores-of-boundingboxes2d-object-now-showing-in-workspace\/2891",
        "Question_created_time":"2022-08-10T16:21:23.491Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":82,
        "Question_body":"<p>Hey, I\u2019m using <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/data-types\/boundingboxes2d\">boundingboxes2d<\/a> to save my detection predictions, which include keys like <code>position<\/code> and <code>scores<\/code>.<\/p>\n<p>The <code>media\/metadata\/boxes2D\/*.json<\/code> files show that I successfully logged what I want. However, in the workspace, where can I get a visual of the scores?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251.jpeg\" data-download-href=\"\/uploads\/short-url\/fCmX7d0Pk78vObXQyale8gQ6yQx.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_690x457.jpeg\" alt=\"image\" data-base62-sha1=\"fCmX7d0Pk78vObXQyale8gQ6yQx\" width=\"690\" height=\"457\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_690x457.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_1035x685.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_1380x914.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1920\u00d71272 120 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Besides, can I sort the results based on scores?<\/p>\n<p>Thanks for your time!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rate limited exceeded",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rate-limited-exceeded\/2981",
        "Question_created_time":"2022-08-24T04:37:38.978Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":516,
        "Question_body":"<p>Hi, I ran a few distributed training runs with 12 parallel processes. I now have problems accessing the web interface, with the error message \u201crate limit exceeded\u201d showing. Please help!<\/p>\n<p>Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plotly aspect ratio",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plotly-aspect-ratio\/2848",
        "Question_created_time":"2022-08-03T19:43:18.584Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":168,
        "Question_body":"<p>I am creating plots on my mac notebook and logging them to wandb, and this works. However, wandb displays these plots in a fixed aspect ratio, which only includes a subset of the axis range. I must scroll to see the entire plot, which is inconvenient. The default aspect ratio seems to be chosen to display a nice layout together with other logged items. My question is whether it is possible to specify the aspect ratio for specific logged variables and plotly plots. Thank you. Gordon.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to export data from local run files?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-export-data-from-local-run-files\/2959",
        "Question_created_time":"2022-08-19T03:24:43.281Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":227,
        "Question_body":"<p>The doc <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide\">Import &amp; Export Data<\/a> gives the way how to export data from cloud. Can I use api to export data from local run files? I tried use path to local run directory instread of <code>&lt;entity&gt;\/&lt;project&gt;\/&lt;run_id&gt;<\/code>, but it doesn\u2019t work.<\/p>",
        "Question_closed_time":"2022-08-22T23:35:26.167Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> , this is currently not an available option. This functionality will be revisited in the future for consideration. Our API only works with runs logged to the cloud.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Description field",
        "Question_link":"https:\/\/community.wandb.ai\/t\/description-field\/2881",
        "Question_created_time":"2022-08-10T00:50:58.434Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":131,
        "Question_body":"<p>I am loving <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> and all it can do for me. I have a question whose answer I cannot find anywhere.<br>\nAmong the various fields in the wandb.config file are a few that wandb generates automatically. One of them is <code>Description<\/code>. I tried setting it from a Python program via my configuration file, but to no avail. So I am wondering how to set the Description field programmatically. This will allow me to \u201cdescribe\u201d several hundred simulations for easy retrieval. Thanks,<\/p>",
        "Question_closed_time":"2022-08-18T22:05:26.461Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/erlebacher\">@erlebacher<\/a> , It\u2019s pretty expensive to do pattern filtering in MySQL, especially on a large column like <code>notes<\/code> . The engineering team decided this feature will not be implemented. I will mark this resolved but please let me know if there is anything else I can answer for you.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Access sweep_id and run_id within train() function for local weight storage",
        "Question_link":"https:\/\/community.wandb.ai\/t\/access-sweep-id-and-run-id-within-train-function-for-local-weight-storage\/2948",
        "Question_created_time":"2022-08-17T07:01:45.149Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":146,
        "Question_body":"<p>Hello,<\/p>\n<p>As I cannot simply upload infinitely many weights using artifacts, I also want to store some locally.<br>\nFor naming, I would like to use the sweep id and\/or the run id.<\/p>\n<p>Can I access that somehow in the train function I hand over to the agent?<\/p>\n<p>Thanks<\/p>\n<p>Markus<\/p>",
        "Question_closed_time":"2022-08-18T22:04:29.034Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/markuskarner\">@markuskarner<\/a>!<\/p>\n<p>The <code>wandb.Run<\/code> object that is returned from <code>wandb.init<\/code> contains this information as properties. You should be able to access <code>run.id<\/code> and <code>run.sweep_id<\/code> in the train function after calling <code>run = wandb.init(...)<\/code>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb dashboard\/report table - rotate column names",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-dashboard-report-table-rotate-column-names\/2889",
        "Question_created_time":"2022-08-10T14:09:19.235Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":108,
        "Question_body":"<p>Hi wandb Team,<\/p>\n<p>I just recently started to use your tool and I already really like it! It\u2019s integration is very easy and helps to decouple the monitoring of my experiments from my own computer.<\/p>\n<p>I have a question regarding the table visualizations in the dashboard or as part of a report. I am wondering whether it is possible to rotate the column names by 90\u00b0 so that I can use the available space more efficiently because I am tracking a lot of metrics, which I would like to compare.<\/p>\n<p>If this is not possible at the moment, I would really appreciate such a feature!<br>\nMy workaround will be now to use abbreviations for the metrics.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retrieving sweep id when starting sweep from CL",
        "Question_link":"https:\/\/community.wandb.ai\/t\/retrieving-sweep-id-when-starting-sweep-from-cl\/2921",
        "Question_created_time":"2022-08-13T13:58:59.209Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":223,
        "Question_body":"<p>I start a sweep from the command line (<code>wandb sweep config.yaml<\/code>). The sweep ID is now displayed (<code>wandb: Created sweep with ID: 6bb3459a<\/code>), but I would like to get it programatically, such that I can later start agents automatically without copy-pasting the ID.<\/p>\n<p>Is there a way to achieve this?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Subset of list of values as hyperparameters",
        "Question_link":"https:\/\/community.wandb.ai\/t\/subset-of-list-of-values-as-hyperparameters\/2934",
        "Question_created_time":"2022-08-15T13:46:08.207Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":405,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m currently training a object detection model and wanted to use sweeps to do some hyperparameter optimization. A few of the hyperparameters are in the form of lists. E.g: data_preprocessors: [\u201crandom-flip\u201d, \u201crandom-crop\u201d, \u201crandom-expand\u201d, etc.]<\/p>\n<p>I would like sweep to take a subset from these values and pass them to my training script. However I could not find how to do this easily without a lot of custom wrapping code.<br>\nMy current solution would be to have each value as a boolean and add some custom logic to convert that to the list I want, however this is not easily expandable\/reusable. Is there something I am missing?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Multiple tables",
        "Question_link":"https:\/\/community.wandb.ai\/t\/multiple-tables\/2856",
        "Question_created_time":"2022-08-06T00:09:11.959Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":236,
        "Question_body":"<p>I know how to create a table with a data frame programmatically. However, I have two data frames, and they have different number of rows, so I cannot combine them into a single data frame. How do I upload two different tables to a Weights&amp;Biases project? Somehow, I suspect that the following is not the correct approach:<\/p>\n<pre><code class=\"lang-python\">    train_df = pd.DataFrame({\n        'tx':train_x,\n        'ty':train_y,\n    })\n    valid_df = pd.DataFrame({\n        'vx':valid_x,\n        'vy':valid_y\n    })\n\n    # How to add multiple tables\n\n    wandb.log({\"table\": train_df}, commit=False)\n    wandb.log({\"table\": valid_df}, commit=False)\n<\/code><\/pre>\n<p>Any help is greatly appreciated.<\/p>",
        "Question_closed_time":"2022-08-10T21:27:09.977Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/erlebacher\">@erlebacher<\/a> , see <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/log-tables#create-tables\">this document<\/a> on how to create tables from dataframes and please let me know if you have any questions.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Graphs out of sync with each other",
        "Question_link":"https:\/\/community.wandb.ai\/t\/graphs-out-of-sync-with-each-other\/2803",
        "Question_created_time":"2022-07-26T19:42:09.811Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":212,
        "Question_body":"<p>This happens to multiple users on other projects as well, not just me. If you look at the graphs here, as an example (<a href=\"https:\/\/wandb.ai\/kaiyotech\/KaiBumBot?workspace=user-kaiyotech\" class=\"inline-onebox\">Weights &amp; Biases<\/a>) you can see that if you move your mouse to the right side of the graph, they show different steps, so they\u2019re not in sync with each other. This makes it really complicated to actually nicely figure out what\u2019s happening with a run, and makes some graphs out of date with others. Occasionally the screen will refresh and some graphs will change to be more in date and others will move out of date, it seems random.<\/p>\n<p>Is there something I can do about this?<\/p>\n<p>Thanks,<br>\nKai<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb Sweep running bash scripts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sweep-running-bash-scripts\/2895",
        "Question_created_time":"2022-08-10T21:12:38.652Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":102,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019d like to use Wandb sweep but running different parameter settings with bash. Is it possible?<br>\nOr I have to have a python file as entry point to parse the parameters and execute bash from python.<\/p>\n<p>Thanks,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save multiindex dataframes",
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-multiindex-dataframes\/2913",
        "Question_created_time":"2022-08-12T09:22:03.520Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":281,
        "Question_body":"<p>Is it possible to log a multiindex pandas dataframe?<\/p>\n<p>In addition, is it possible to save a pandas dataframe with the names of the rows? Even though my dataframe has names in the rows, in the UI I see a linear index.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Taking a long time to download artifact of only 300mb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/taking-a-long-time-to-download-artifact-of-only-300mb\/2909",
        "Question_created_time":"2022-08-11T15:18:52.264Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":67,
        "Question_body":"<p>Its taking ages to download an artifact of only 300mb. Its there anyway to enable parallel download ? add multiprocessing ?<\/p>\n<p>wandb: Downloading large artifact Data-Split-802020:v0, 303.21MB. 148470 files\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to invert the logged images?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-invert-the-logged-images\/2907",
        "Question_created_time":"2022-08-11T13:18:47.393Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":135,
        "Question_body":"<p>Hi,<\/p>\n<p>is it possible to invert my logged images ? Or is there maybe a way to do that in pytorch ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to login using wandb local",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-login-using-wandb-local\/2868",
        "Question_created_time":"2022-08-09T15:41:53.918Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":190,
        "Question_body":"<p>Python: 3.9.7<br>\nwandb: 0.12.17<br>\nOS: Ubuntu 20.04.4 LTS<\/p>\n<p>Yesterday (08 Aug) I was able to login and view my training artifacts using <code>wandb local<\/code>. However, today I am unable to do so. Here are the commands I run:<\/p>\n<pre><code class=\"lang-auto\">conda activate my_env\nwandb local\n<\/code><\/pre>\n<p>I then navigate in my browser to <code>localhost:8080<\/code>. I\u2019m taken to a page that says \u201cDeveloper Tools for Deep Learning\u201d and click the Login button in the upper right corner. The url is redirected to <code>http:\/\/localhost:8080\/login?local=true<\/code> and I am presented with the login fields. I login using the same credentials I used yesterday (and the same ones that gave me access to the wandb forum and the ability to make this post), but  get an error saying \u201cInvalid password\u201d.<\/p>\n<p>I tried resetting the password but I get another error that says \u201cError while trying to reset password\u201d.<\/p>\n<p>Any thoughts about what might be going on? If need be, I\u2019m fine with completely wiping the user account and starting over as I don\u2019t have anything of real value uploaded. Thanks in advance for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I move a run from one project to another?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-move-a-run-from-one-project-to-another\/2900",
        "Question_created_time":"2022-08-11T07:15:21.472Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":135,
        "Question_body":"<p>The runs on two projects share all the same parameters, I maybe accidently create two projects, now I want to aggregate the two projects to one, is there any way I can do this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Axis scales",
        "Question_link":"https:\/\/community.wandb.ai\/t\/axis-scales\/2892",
        "Question_created_time":"2022-08-10T17:44:01.068Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":66,
        "Question_body":"<p>I have created 100 runs, and would like to make two scatter plots. The first scatter plot involves the first 50 simulations, with axis limits [0,10] in both directions. The second scatter plot uses simulations 51 to 100, with different axis limits, say [10,20]. So far, I created a new panel, for both these plots. But wandb does not like that. Whatever I set the axis limits will be the same for both subsets (1-50, and 51-100). What is the recommended approach to have a plot for each of the data subsets? Must I create two different panels? If so, that means that one panel 2 might have to be turned off for the first batch of data experiments, and panel 1 would be turned off for the second batch of experiments. Is this the recommended approach? Thanks.<\/p>",
        "Question_closed_time":"2022-08-12T22:11:24.524Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/erlebacher\">@erlebacher<\/a>,<\/p>\n<p>Have you tried creating reports with different panel plots? They should work here.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb sweep project always getting created in a specific team",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sweep-project-always-getting-created-in-a-specific-team\/2887",
        "Question_created_time":"2022-08-10T12:26:32.672Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":155,
        "Question_body":"<p>Following is my simple Python code along with the sweep.yaml file I am using:<\/p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.init(\n    entity=\"kanishkanarch\", \n    project=\"wandb-sweep-testing\", \n    name=\"my_first_sweep\"\n)\nconfig = wandb.config\nseed = config.seed\nsum = 0 \nsum += seed\n<\/code><\/pre>\n<pre><code class=\"lang-auto\">program: testing.py\nmethod: random\nmetric:\n  name: sum \n  goal: maximize\nparameters:\n  seed:\n    min: 1\n    max: 10\n<\/code><\/pre>\n<p>I created a public project on my personal wandb page by the name <code>wandb-sweep-testing<\/code> but whenever I run <code>wandb sweep sweep.yaml<\/code> file it shows that the project is getting created in another team that I am part of.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b.png\" data-download-href=\"\/uploads\/short-url\/Av9VD7f5wslMTylimEN27Ms3Qsb.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_690x74.png\" alt=\"image\" data-base62-sha1=\"Av9VD7f5wslMTylimEN27Ms3Qsb\" width=\"690\" height=\"74\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_690x74.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_1035x111.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1115\u00d7120 62.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>How can I make a project on my personal profile not on my team\u2019s profile?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Key Error in wandb.config when using wandb.sweep in pytorch",
        "Question_link":"https:\/\/community.wandb.ai\/t\/key-error-in-wandb-config-when-using-wandb-sweep-in-pytorch\/2898",
        "Question_created_time":"2022-08-11T05:43:04.671Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":165,
        "Question_body":"<p>I am trying to run this codebase <a href=\"https:\/\/github.com\/devzhk\/LMCTS\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - devzhk\/LMCTS<\/a>. To run hyperparameter sweep, I ran the following:<\/p>\n<pre><code class=\"lang-auto\">wandb sweep sweep\/simulation\/linear-lmcts.yaml\nwandb agent [agent id]\n<\/code><\/pre>\n<p><a href=\"https:\/\/github.com\/devzhk\/LMCTS\/blob\/master\/sweep\/simulation\/linear-lmcts.yaml\" rel=\"noopener nofollow ugc\">The config file<\/a> seems to have the same style as the sweep tutorial in W&amp;B website has. However, when I run sweep command as above, I get the following error<\/p>\n<pre><code class=\"lang-auto\">2022-08-10 02:12:55,113 - wandb.wandb_agent - INFO - Running runs: []\n2022-08-10 02:12:55,352 - wandb.wandb_agent - INFO - Agent received command: run\n2022-08-10 02:12:55,362 - wandb.wandb_agent - INFO - Agent starting run with config:\n\tT: 10000\n\talgo: LMCTS\n\tbeta_inv: 0.0001\n\tdatapath: data\/gaussian50-20-1-1.pt\n\tdim_context: 20\n\tfunc: linear\n\tlr: 0.1\n\tmodel: linear\n\tnum_arm: 50\n\tnum_iter: 70\n\tsigma: 0.5\n2022-08-10 02:12:55,372 - wandb.wandb_agent - INFO - About to run command: \/usr\/bin\/env python3 run_simulation.py\n2022-08-10 02:13:00,385 - wandb.wandb_agent - INFO - Running runs: ['ngxmksza']\n\/home\/mila\/i\/ishfaqha\/code\/LMCTS\/LCMTS\/lib\/python3.7\/site-packages\/sklearn\/feature_extraction\/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https:\/\/numpy.org\/devdocs\/release\/1.20.0-notes.html#deprecations\n  dtype=np.int):\nRandom seed: 720\nTraceback (most recent call last):\n  File \"run_simulation.py\", line 107, in &lt;module&gt;\n    run(config, args)\n  File \"run_simulation.py\", line 41, in run\n    data = torch.load(config['datapath'])\nKeyError: 'datapath'\n\n<\/code><\/pre>\n<p>Shouldn\u2019t it automatically parse the config?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot join team via invite",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-join-team-via-invite\/2905",
        "Question_created_time":"2022-08-11T13:10:58.030Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":68,
        "Question_body":"<p>Hi!<\/p>\n<p>I can\u2019t join team after accepting the invite, only receive message \u201cReceived an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\u201d, but I already logged with that email.<\/p>\n<p>Best regards,<br>\nBohdan<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Multiple teams",
        "Question_link":"https:\/\/community.wandb.ai\/t\/multiple-teams\/2903",
        "Question_created_time":"2022-08-11T13:00:38.615Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":79,
        "Question_body":"<p>I could not find the answer to the following question. I work in an academic environment and have a single use free W&amp;B account. I would like to create multiple teams. Is this possible? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Duplicating a project?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/duplicating-a-project\/2866",
        "Question_created_time":"2022-08-09T11:23:56.077Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":65,
        "Question_body":"<p>Hello,<\/p>\n<p>It would be super useful to be able to  duplicate a project, in order to have a \u2018benchmark\/control project\u2019 on top of which I can do experiments.<\/p>\n<p>Is this possible?<\/p>\n<p>Many thanks<br>\nHarry<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.log inconsistent behavior with step parameter",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-log-inconsistent-behavior-with-step-parameter\/2771",
        "Question_created_time":"2022-07-19T02:13:54.539Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":196,
        "Question_body":"<p>Why does these code snippets produce different results?<\/p>\n<pre><code class=\"lang-auto\">for i in range(100):\n    wandb.log({\"train\/loss\": i}, step=i)\n    \nfor i in range(100):\n    wandb.log({\"val\/loss\": i**2}, step=i)\n<\/code><\/pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/ioofli05?workspace=user-dminn\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/ioofli05?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/626b9c1d1ceb6cb5d3bb90cf6ab8d2894a6b8b14.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n\n<h3><a href=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/ioofli05?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">dminn<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<pre><code class=\"lang-auto\">for i in range(100):\n    wandb.log({\"train\/loss\": i}, step=i)\n    wandb.log({\"val\/loss\": i**2}, step=i)\n<\/code><\/pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/146hdnar?workspace=user-dminn\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/146hdnar?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/626b9c1d1ceb6cb5d3bb90cf6ab8d2894a6b8b14.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n\n<h3><a href=\"https:\/\/wandb.ai\/dminn\/WandbHelp\/runs\/146hdnar?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">dminn<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":"2022-07-21T13:55:33.624Z",
        "Answer_body":"<p>As far as I understand the step variable, once the step is incremented, the value is stored immutably. So, if chronologically, you execute:<\/p>\n<pre><code class=\"lang-python\">\nwandb.log({'potato': 1}, step=0}\nwandb.log({'tomato': 1}, step=0}\nwandb.log({'potato': 2}, step=1}\nwandb.log({'tomato': 2}, step=1}\n\n<\/code><\/pre>\n<p>It\u2019ll be fine but instead if you execute:<\/p>\n<pre><code class=\"lang-python\">\nwandb.log({'potato': 1}, step=0}\nwandb.log({'potato': 2}, step=1}\nwandb.log({'tomato': 1}, step=0}\nwandb.log({'tomato': 2}, step=1}\n\n<\/code><\/pre>\n<p>the third command (tomato = 1, step 0) will not be executed since the logger has already moved past step 0.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to start? No knowledge no skill in AI or ML",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-start-no-knowledge-no-skill-in-ai-or-ml\/2876",
        "Question_created_time":"2022-08-09T21:27:28.945Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":258,
        "Question_body":"<p>Hi every one, i am a pure pure beginner in AI  and this forum can you tell me where should i go to learn basics of ML?<br>\nBecause i saw 2min Paper  telling the audience that People like me are welcomed!<br>\nThank you very much!<br>\nEro<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Boolean variables",
        "Question_link":"https:\/\/community.wandb.ai\/t\/boolean-variables\/2874",
        "Question_created_time":"2022-08-09T20:25:47.423Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":76,
        "Question_body":"<p>I am performing a hyperparameter sweep, and all is going well, except for an issue involving Boolean variables.<br>\nVariables that are True or False, do not appear as such in the run tables. Here are some images to demonstrate.<br>\nInstead, there are little horizontal dashes. So my question is whether one can include \u201cTrue\/False\u201d values for variables in configurations, and if so, how do they appear in the run tables displayed on <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a>?  Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Reverse deleted projects",
        "Question_link":"https:\/\/community.wandb.ai\/t\/reverse-deleted-projects\/2872",
        "Question_created_time":"2022-08-09T18:27:47.533Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":297,
        "Question_body":"<p>Hey,<br>\nWondering is there anyway to restore deleted projects with artifacts ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"White screen crash",
        "Question_link":"https:\/\/community.wandb.ai\/t\/white-screen-crash\/2862",
        "Question_created_time":"2022-08-09T04:48:35.949Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":67,
        "Question_body":"<p>If I login <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a>, the website does not respond and just show white screen\u2026<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f.png\" data-download-href=\"\/uploads\/short-url\/2g1cHYijVLuymAZWY8CC8f6Kqon.png?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_690x388.png\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50\" data-base62-sha1=\"2g1cHYijVLuymAZWY8CC8f6Kqon\" width=\"690\" height=\"388\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_690x388.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_1035x582.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_1380x776.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50<\/span><span class=\"informations\">5120\u00d72880 363 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any help is greatly appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add a default sweep plot?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-a-default-sweep-plot\/2854",
        "Question_created_time":"2022-08-05T00:22:26.380Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":245,
        "Question_body":"<p><strong>Context<\/strong>: In my project, I am performing benchmarking on a lot of datasets and therefore need to perform a lot of sweeps.<\/p>\n<p><strong>Problem<\/strong>:  I have some custom metrics that I wish to plot together to quickly review the performance of the different runs in the sweep in a specific way. This means for each sweep I need to recreate the plot which is frustrating.<\/p>\n<p><strong>Question<\/strong>: Is there a way of adding a custom default plot setup in the sweep workspace?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question regarding W&B server quick start",
        "Question_link":"https:\/\/community.wandb.ai\/t\/question-regarding-w-b-server-quick-start\/2755",
        "Question_created_time":"2022-07-15T01:59:48.717Z",
        "Question_answer_count":16,
        "Question_score_count":0,
        "Question_view_count":802,
        "Question_body":"<p>hi folks, when I was trying to follow the instructions listed in this page (<a href=\"https:\/\/docs.wandb.ai\/guides\/self-hosted\">https:\/\/docs.wandb.ai\/guides\/self-hosted<\/a>), I encountered an issue.  I successfully finished step1 and step 2 under section \u201cW&amp;B server quick start\u201d, however, when I was trying to do step3, it always asked me to create a new account and even I click the button \u201clog in with another account\u201d, it will directly forward me to the signup page again. So there is no chance for me to follow the instruction in step3.<br>\nAnyone encountered this issue before? Can you pls share how you fixed this issue ?<\/p>\n<p>Thank you !<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Mutually exclusive parameters for sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/mutually-exclusive-parameters-for-sweeps\/2808",
        "Question_created_time":"2022-07-27T22:35:38.889Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":229,
        "Question_body":"<p>Can I pass exclusive parameters for a sweep? E.g. for a particular pre-trained model, I want to try learning rate values of [0.1, 0.2]. For another model I want to use [0.3, 0.4].  if I use the sweep configuration below, then grid search will try all the four learning rate values for each model. However, for model 1 - I want to use a learning rate of 0.1, 0.2 whereas, for model2, I want to use 0.3, 0.4.<\/p>\n<p>project: my_project<br>\nprogram: main.py<br>\nname: grid_search<br>\nmethod: grid<br>\nparameters:<br>\nlearning_rate:<br>\nvalues: [0.1, 0.2, 0.3, 0.4]<br>\narch:<br>\nvalues: [\u2018model1\u2019, \u2018model2\u2019]<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Combining multiple sweeps with the same name",
        "Question_link":"https:\/\/community.wandb.ai\/t\/combining-multiple-sweeps-with-the-same-name\/2846",
        "Question_created_time":"2022-08-03T14:20:58.411Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":412,
        "Question_body":"<p>I have figured out how to do hyperparameter sweeps, and I am pleased. However, I would like to combine sweep results from multiple sweeps with the same name, and this does not appear to be possible without rerunning the simulations. If it not possible, I would like to know why not since all the information necessary to combine them is available. The runs from these multiple sweeps are all available in a single table. Thanks. Gordon.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hypersweep metric with a dictionary hierarchy",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hypersweep-metric-with-a-dictionary-hierarchy\/2839",
        "Question_created_time":"2022-08-02T18:54:35.629Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":87,
        "Question_body":"<p>I am creating hyper parameter sweeps of a linear regression problem, which has gone without a hitch so far. However, I am working to improve my skills with wand. In particular, I logged dictionaries of dictionaries. Here is an example:<\/p>\n<pre><code class=\"lang-python\"> wandb.log({\n    'epoch': epoch,     \n    'train':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch},                  \n    'valid':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch}\n  } , step=epoch, commit=True)\n<\/code><\/pre>\n<p>The metric should be the training loss. How does one specify it when using dictionary hierarchies? Have I done it correctly below?<\/p>\n<pre><code class=\"lang-python\"># docs: https:\/\/docs.wandb.ai\/guides\/sweeps\/configuration\nsweep_config3 = {\n    'name' : 'broad_sweep', \n    'method' : 'random',\n    'metric' : {\n                'name': {'train': 'loss'},\n                'goal': 'minimize',\n               },\n    'parameters' : {\n        'lr' : {\n            'distribution': 'log_uniform_values',\n            'min': 1.e-3, \n            'max': 1.e-1},\n        'batch_size' : { 'value': 32 },\n        'optim' : { 'value': 'adamw' },\n        'nb_layers' : { 'values': [0, 2, 4] },\n        'pts_layer': { 'values': [5, 10, 30] },\n        'nb_epochs': { 'value': 200},\n    }\n}\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cant see the team after accepting invite",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cant-see-the-team-after-accepting-invite\/2823",
        "Question_created_time":"2022-07-29T09:49:38.684Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":734,
        "Question_body":"<p>Hi! I can\u2019t see my team after accepting the invite, it says \u201cReceived an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\u201d but it does not tell you what to do when this is already checked <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/stuck_out_tongue.png?v=12\" title=\":stuck_out_tongue:\" class=\"emoji\" alt=\":stuck_out_tongue:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>regards<br>\nR<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Chat Application Integration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-chat-application-integration\/2844",
        "Question_created_time":"2022-08-03T12:21:13.332Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":139,
        "Question_body":"<p>I would like to get some references to integrate wandb alert to a custom chat application(discord bot or other slack like app for example). how do i go about achieving that?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Understanding define_metric parameters",
        "Question_link":"https:\/\/community.wandb.ai\/t\/understanding-define-metric-parameters\/2836",
        "Question_created_time":"2022-08-02T13:30:36.761Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":79,
        "Question_body":"<p>I would like to understand the difference between those two function calls:<\/p>\n<p>I am referring to the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log#customize-the-summary\">documentation of define_metric<\/a>:<\/p>\n<pre data-code-wrap=\"py\"><code class=\"lang-nohighlight\">wandb.define_metric(\"acc\", summary=\"max\")\nwandb.define_metric(\"acc\", summary=\"best\", objective=\"maximize\")\n<\/code><\/pre>\n<p>Is it the \u201cbest\u201d accuracy ever measured (during training) versus the accuracy of the \u201cbest\u201d (validation) model? I understand that wandb does not care what metric I log, but what is the intended use?<\/p>\n<p>Thank you for clarification.<\/p>",
        "Question_closed_time":"2022-08-02T14:00:10.923Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/hogru\">@hogru<\/a>,<\/p>\n<p>For each metric logged, there is a summary metric that\u2019ll summarize the logged values as <em>one<\/em> value for each run. By default, W&amp;B uses the <em>latest<\/em> value, but you can update it with <code>wandb.summary['acc'] = best_acc<\/code> or using the two <code>define_metric<\/code> calls you show.<\/p>\n<p>This is then used to decide which value is displayed in plots that only use one value for each run (e.g. Scatter plots).<\/p>\n<pre><code class=\"lang-auto\">wandb.define_metric(\"acc\", summary=\"max\")\nwandb.define_metric(\"acc\", summary=\"best\", objective=\"maximize\")\n<\/code><\/pre>\n<p>These two calls are both functionally the same, one will show <code>acc.best<\/code> and one will show as <code>acc.max<\/code> in the summary metrics of your run. Both will be the maximum value that you log for <code>acc<\/code> like <code>wandb.log('acc':acc)<\/code> during a run.<\/p>\n<p>You can see the summary metrics of each run by clicking the <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/information_source.png?v=12\" title=\":information_source:\" class=\"emoji\" alt=\":information_source:\" loading=\"lazy\" width=\"20\" height=\"20\"> icon in the top left nav bar in a run.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Artifacts logged with run_id",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifacts-logged-with-run-id\/2759",
        "Question_created_time":"2022-07-16T15:11:27.757Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":497,
        "Question_body":"<p>Hello everyone,<br>\nI am new to w&amp;b, so this might be a beginner question, but I was wondering why when I run<br>\n<code> wandb.log_artifact(file_path, name='dataset', type='dataset')<\/code><br>\nI am able to log artifacts correctly without many issues,  whereas if I use the example provided <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/wandb-artifacts\/Pipeline_Versioning_with_W%26B_Artifacts.ipynb#scrollTo=Mb8GiolzPgUU\" rel=\"noopener nofollow ugc\">here<\/a><\/p>\n<pre><code class=\"lang-auto\">def load_and_log():\n\n    # \ud83d\ude80 start a run, with a type to label it and a project it can call home\n    with wandb.init(project=\"artifacts-example\", job_type=\"load-data\") as run:\n        \n        datasets = load()  # separate code for loading the datasets\n        names = [\"training\", \"validation\", \"test\"]\n\n        # \ud83c\udffa create our Artifact\n        raw_data = wandb.Artifact(\n            \"mnist-raw\", type=\"dataset\",\n            description=\"Raw MNIST dataset, split into train\/val\/test\",\n            metadata={\"source\": \"torchvision.datasets.MNIST\",\n                      \"sizes\": [len(dataset) for dataset in datasets]})\n\n        for name, data in zip(names, datasets):\n            # \ud83d\udc23 Store a new file in the artifact, and write something into its contents.\n            with raw_data.new_file(name + \".pt\", mode=\"wb\") as file:\n                x, y = data.tensors\n                torch.save((x, y), file)\n\n        # \u270d\ufe0f Save the artifact to W&amp;B.\n        run.log_artifact(raw_data)\n\nload_and_log()\n<\/code><\/pre>\n<p>I get the artifacts stored in a run_table, and it makes versioning impossible.<br>\nAm I doing something wrong? Below you can find the same function as I modified it for my project, in case I might have missed something<\/p>\n<pre><code class=\"lang-auto\">from wandb.sdk import wandb_init\ndef load_and_log():\n\n    # \ud83d\ude80 start a run, with a type to label it and a project it can call home\n    with wandb.init(project=\"project\", job_type=\"load-data\", resume=\"allow\") as run:\n        \n        dataset = my_function(dir_path + '\/datas', MAX_SAMPLES, MAX_LENGTH) #returns a tuple of lists\n        datasets = dataset.load()  # separate code for loading the datasets\n        names = [\"questions\", \"answers\"]\n\n        # \ud83c\udffa create our Artifact\n        raw_data = wandb.Artifact(\n            \"dataset\", type=\"dataset\",\n            description=\"json of the preprocessed dataset - not split\",\n            metadata={\"source\": \"https:\/\/source.php\",\n                      \"sizes\": [len(dataset) for dataset in datasets]})\n\n        # transfer lists into table\n        table = wandb.Table(columns=[], data=[])\n        for name, dataset in zip(names, datasets):\n          table.add_column(name=f\"{name}\", data=dataset)\n\n        # \u270d\ufe0f Save the artifact to W&amp;B.\n        wandb.log({f\"dataset_{MAX_SAMPLES}_{MAX_LENGTH}\": table})\n\nload_and_log()\n<\/code><\/pre>\n<p>Thank you in advance if you have an answer!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Update offline run before syncing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/update-offline-run-before-syncing\/2794",
        "Question_created_time":"2022-07-25T09:29:20.433Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":149,
        "Question_body":"<p>Hi! During training, my script crashed unexpectedly and did not save the latest epoch information.  I restarted training without being aware of it, and now my epochs are offset by a large number.<\/p>\n<p>Is it possible to edit the epoch number (index) and add a certain value to each entry? I have tried opening the \u201crun_name.wandb\u201d file and I can already see the \u2018_step\u2019 variable for each entry, but I was wondering if there is a cleaner way to perform such an update.<\/p>\n<p>Thank you in advance for your help!<\/p>",
        "Question_closed_time":"2022-07-28T22:36:27.071Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/vandrew\">@vandrew<\/a> , I understand what you are attempting to achieve now. At this time our API doesn\u2019t support offline mode to access local log files. We do have this planned as a future feature but I can\u2019t speak to a specific timeline. At this time you will have to sync your runs first in online mode, then update metrics using the API.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"RuntimeError: max must be larger than min SCALER",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runtimeerror-max-must-be-larger-than-min-scaler\/2796",
        "Question_created_time":"2022-07-25T11:16:28.348Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":116,
        "Question_body":"<p>Hi all,<br>\nI have this weird Runtime error during training @ epoch 129.<\/p>\n<p>Traceback (most recent call last):<br>\nFile \u201c\/home\/anton\/Documents\/GitHub\/horse2depth_Pix2Pix\/train_depth_loss.py\u201d, line 715, in <br>\nFile \u201c\/home\/anton\/Documents\/GitHub\/horse2depth_Pix2Pix\/train_depth_loss.py\u201d, line 630, in main<br>\nFile \u201c\/home\/anton\/Documents\/GitHub\/horse2depth_Pix2Pix\/train_depth_loss.py\u201d, line 315, in train_fn<br>\n# g_scaler.scale(G_loss).backward()<br>\nFile \u201c\/usr\/anaconda3\/envs\/CGAN\/lib\/python3.10\/site-packages\/torch\/_tensor.py\u201d, line 396, in backward<br>\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)<br>\nFile \u201c\/usr\/anaconda3\/envs\/CGAN\/lib\/python3.10\/site-packages\/torch\/autograd\/<strong>init<\/strong>.py\u201d, line 173, in backward<br>\nVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass<br>\nFile \u201c\/usr\/anaconda3\/envs\/CGAN\/lib\/python3.10\/site-packages\/wandb\/wandb_torch.py\u201d, line 264, in <br>\nhandle = var.register_hook(lambda grad: _callback(grad, log_track))<br>\nFile \u201c\/usr\/anaconda3\/envs\/CGAN\/lib\/python3.10\/site-packages\/wandb\/wandb_torch.py\u201d, line 262, in _callback<br>\nself.log_tensor_stats(grad.data, name)<br>\nFile \u201c\/usr\/anaconda3\/envs\/CGAN\/lib\/python3.10\/site-packages\/wandb\/wandb_torch.py\u201d, line 213, in log_tensor_stats<br>\ntensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)<br>\nRuntimeError: max must be larger than min<\/p>\n<p>First time it happened.<\/p>\n<p>Any help?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can't associate sweeps with project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cant-associate-sweeps-with-project\/2636",
        "Question_created_time":"2022-06-19T18:57:34.170Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":828,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using wandb (great product!!!) and have been able to set up projects, do runs and am now working with sweeps (FANTASTIC!). However I can\u2019t figure out how to associate my sweeps with a project.<\/p>\n<p>I have:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\nsweep_config = {\n  \"project\" : \"HDBSCAN_Clustering\",\n  \"method\" : \"random\",\n  \"parameters\" : {\n    \"min_cluster_size\" :{\n      \"values\": [*range(20,500)]\n    },\n    \"min_sample_pct\" :{\n      \"values\": [.25, .5, .75, 1.0]\n    }\n  }\n}\n<\/code><\/pre>\n<p>Then when I:<\/p>\n<p>sweep_id = wandb.sweep(sweep_config)<\/p>\n<p>I get<\/p>\n<p><code>Sweep URL: https:\/\/wandb.ai\/teamberkeley\/uncategorized\/sweeps\/jk9c1l8q<\/code><\/p>\n<p>Note:  teamberkeley\/<em>uncategorized<\/em>\/sweeps<\/p>\n<p>They are of course uncategorized in the projects interface as well.<\/p>\n<p>No luck with running wandb.init beforehand either thusly:<\/p>\n<p>wandb.init(project=\u2018HDBSCAN_Clustering\u2019)<\/p>\n<p>Same result (despite the fact that at this point if I do \u2018runs\u2019 with wandb they are attached to the correct project after this init). Please let me know what I\u2019m doing wrong!<\/p>",
        "Question_closed_time":"2022-06-30T02:42:41.635Z",
        "Answer_body":"<p>Ahhh fixed.  The entity is \u2018drob707\u2019, not \u2018drob\u2019.  Thanks!<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Waiting for W&B process to finish (success)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/waiting-for-w-b-process-to-finish-success\/2818",
        "Question_created_time":"2022-07-28T18:54:55.533Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":684,
        "Question_body":"<p>When using wandb I don\u2019t have any runs at the moment however it won\u2019t let me start any new runs. When the python script is run the bellow message is shown and the run is \u2018synced\u2019 doesn\u2019t appear to be running on the PC. I have checked the system processes and there is no instance of a wandb script running. On my wandb profile, all runs appear to be failed, finished or killed.<br>\nIs there a way to manually override this? I have tried running in offline mode and it still has no effect and I cannot test the changes to my code.<\/p>\n<p>EDIT: Elaborated description and provided console output:<\/p>\n<p>wandb: Currently logged in as: username. Use <code>wandb login --relogin<\/code> to force relogin<\/p>\n<p>wandb: Tracking run with wandb version 0.12.19<\/p>\n<p>wandb: Run data is saved locally in \/tmp\/tmpjjlzygaw\/wandb\/run-<br>\n20220627_121802-X_training18<\/p>\n<p>wandb: Run <code>wandb offline<\/code> to turn off syncing.<\/p>\n<p>wandb: Syncing run 88_DCAC_training18<br>\nwandb: <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/star.png?v=12\" title=\":star:\" class=\"emoji\" alt=\":star:\" loading=\"lazy\" width=\"20\" height=\"20\"> View project at <a href=\"https:\/\/wandb.ai\/username\/X\" class=\"inline-onebox\">Weights &amp; Biases<\/a><br>\nwandb: <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/rocket.png?v=12\" title=\":rocket:\" class=\"emoji\" alt=\":rocket:\" loading=\"lazy\" width=\"20\" height=\"20\"> View run at <a href=\"https:\/\/wandb.ai\/username\/X\/runs\/X_training18\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>continuing\u2026<\/p>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success).<br>\nwandb:<br>\nwandb: Synced X_training18: <a href=\"https:\/\/wandb.ai\/lucmc\/DCAC%20L-Reacher\/runs\/X_training18\" class=\"inline-onebox\">Weights &amp; Biases<\/a><br>\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)<br>\nwandb: Find logs at: \/tmp\/tmpjjlzygaw\/wandb\/run-20220627_121802-X_training18\/logs<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What are your requirements for a cloud server?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-are-your-requirements-for-a-cloud-server\/2816",
        "Question_created_time":"2022-07-28T18:54:52.111Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":193,
        "Question_body":"<p>Amazon Web Services (AWS) presently services over 7,500 government entities and 5000 educational institutions.<\/p>\n<p>If that isn\u2019t an endorsement, we don\u2019t know what is! AWS, known as one of the world\u2019s premier IT corporations, is now one of the top four public cloud computing companies in the world.<\/p>\n<p>Source : <a href=\"https:\/\/www.sevenmentor.com\/amazon-web-services-training-institute-in-pune.php\" rel=\"noopener nofollow ugc\">AWS Course In Pune<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integration of Wandb with AWS Lambda",
        "Question_link":"https:\/\/community.wandb.ai\/t\/integration-of-wandb-with-aws-lambda\/2280",
        "Question_created_time":"2022-04-20T19:19:11.842Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":755,
        "Question_body":"<p>Hi Community,<\/p>\n<p>I was trying to integrate the WandB inside the AWS lambda. The code was deployed successfully but during testing I am facing an issue with WandB.<\/p>\n<p>OSError: [Errno 38] Function not implemented<\/p>\n<p>This error is being raised by the WandB library inside the  AWS lambda. This is probably because of multiprocessing utilized by WandB.  Below are more details about the Lambda configuration and env variables:<\/p>\n<p><strong>CONFIGURATION:<\/strong><br>\nPython Version= 3.7<br>\nArchitecture = x86_64<\/p>\n<p><strong>ENV VARIABLES<\/strong><br>\nWANDB_API_KEY = Key<br>\nWANDB_CACHE_DIR= \/tmp\/<br>\nWANDB_CONFIG_DIR=\/tmp\/<br>\nWANDB_DIR=\/tmp\/<br>\nWANDB_SILENT=true<\/p>\n<p>Is there any suggestion how to deal with this bug?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hide Command from Overview Run Page Bug - Reopen",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hide-command-from-overview-run-page-bug-reopen\/2802",
        "Question_created_time":"2022-07-26T19:38:34.475Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":218,
        "Question_body":"<aside class=\"quote\" data-post=\"1\" data-topic=\"2231\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/ed8c4c\/40.png\" class=\"avatar\">\n    <a href=\"https:\/\/community.wandb.ai\/t\/hide-command-from-overview-run-page\/2231\">Hide Command from Overview Run Page<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/w-b-support\/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP.\">W&amp;B Support<\/span><\/a>\n  <\/div>\n  <blockquote>\n    On the Run Page (<a href=\"https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page\">https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page<\/a>) it shows on the left incognito that it shouldn\u2019t show your command when the public is viewing your page. \nHowever, on my page, when public and I view as not-me, it still shows the command that launched it, and that includes my Windows username, which I\u2019d rather not. I can\u2019t find anything to override or hide this. What am I missing? \nThanks.\n  <\/blockquote>\n<\/aside>\n\n<p>Reopening the above, this still isn\u2019t fixed and it\u2019s still bothering me.<\/p>\n<p>Any updates?<\/p>\n<p><a class=\"mention\" href=\"\/u\/armanharutyunyan\">@armanharutyunyan<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to kill a specific agent using a command in terminal?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-kill-a-specific-agent-using-a-command-in-terminal\/2782",
        "Question_created_time":"2022-07-20T15:21:29.646Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":169,
        "Question_body":"<p>I run several agents in one sweep.<br>\nI want to stop a specific agent among them, but I don\u2019t know how to stop it.<\/p>",
        "Question_closed_time":"2022-07-22T06:22:37.452Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jeongwhanchoi\">@jeongwhanchoi<\/a> , please see this <a href=\"https:\/\/community.wandb.ai\/t\/hp-sweep-correct-way-to-stop-a-specific-agent-and-not-the-entire-sweep\/1173\">post<\/a> for stopping agents. Please let me know if you have additional questions.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Error while hyperparameter search",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-while-hyperparameter-search\/2751",
        "Question_created_time":"2022-07-14T17:30:42.704Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":306,
        "Question_body":"<p>When I try wandb.sweep, it gives following error:  wandb.errors.CommError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.<\/p>\n<p>Following this, is my sweep config<br>\n{\u2018method\u2019: \u2018random\u2019,<br>\n\u2018metric\u2019: {\u2018goal\u2019: \u2018minimize\u2019, \u2018name\u2019: \u2018loss\u2019},<br>\n\u2018parameters\u2019: {\u2018batch_size\u2019: {\u2018distribution\u2019: \u2018q_log_uniform_values\u2019,<br>\n\u2018max\u2019: 256,<br>\n\u2018min\u2019: 32,<br>\n\u2018q\u2019: 8},<br>\n\u2018epochs\u2019: {\u2018value\u2019: 10},<br>\n\u2018fc_layer_size\u2019: {\u2018values\u2019: [16, 32, 64]},<br>\n\u2018learning_rate\u2019: {\u2018distribution\u2019: \u2018uniform\u2019,<br>\n\u2018max\u2019: 0.1,<br>\n\u2018min\u2019: 0},<br>\n\u2018optimizer\u2019: {\u2018values\u2019: [\u2018adam\u2019, \u2018sgd\u2019]},<br>\n\u2018training_snr\u2019: {\u2018values\u2019: [0.3981071705534972,<br>\n0.44668359215096315,<br>\n0.5011872336272722,<br>\n0.5623413251903491,<br>\n0.6309573444801932,<br>\n0.7079457843841379,<br>\n0.7943282347242815,<br>\n0.8912509381337456,<br>\n1.0,<br>\n1.1220184543019633,<br>\n1.2589254117941673,<br>\n1.4125375446227544,<br>\n1.5848931924611136,<br>\n1.7782794100389228,<br>\n1.9952623149688795,<br>\n2.2387211385683394,<br>\n2.51188643150958,<br>\n2.8183829312644537,<br>\n3.1622776601683795,<br>\n3.548133892335755,<br>\n3.9810717055349722,<br>\n4.466835921509632,<br>\n5.011872336272722,<br>\n5.623413251903491,<br>\n6.309573444801933,<br>\n7.079457843841379,<br>\n7.943282347242816,<br>\n8.912509381337454,<br>\n10.0]}}}<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot compare artifcats anymore",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-compare-artifcats-anymore\/2800",
        "Question_created_time":"2022-07-26T15:51:53.295Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":353,
        "Question_body":"<p>Hello,<\/p>\n<p>I work a project using GANs to generate images. At each iteration I would log artifacts containing the generated images. Up until now I could visualize the generated images in a table and compare multiple artifact versions visually by joining the tables in the artifact view.<br>\nIt seems that view has been updated and this functionality does not exist anymore or is hidden. Could anyone help me find back this functionality in case it still exists. Thank you!<\/p>\n<p>Mahmoud<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question\uff1aCan I use multiple accounts (i.e. adopting multiple API keys) in one machine?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/question-can-i-use-multiple-accounts-i-e-adopting-multiple-api-keys-in-one-machine\/2397",
        "Question_created_time":"2022-05-10T14:29:14.062Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":1287,
        "Question_body":"<p>Can I use multiple accounts (i.e. adopting multiple API keys) in one machine?<br>\nAre there any ways I can do that?<br>\nLooking forward to helping! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Automatically repeating experiments and plots with error bars",
        "Question_link":"https:\/\/community.wandb.ai\/t\/automatically-repeating-experiments-and-plots-with-error-bars\/2791",
        "Question_created_time":"2022-07-22T11:34:38.841Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":117,
        "Question_body":"<p>Is it possible to use wandb to do repeats of certain machine learning experiments and automatically plot a learning curve with uncertainty regions?<\/p>\n<p>Something like this <a href=\"https:\/\/stackoverflow.com\/questions\/43064524\/plotting-shaded-uncertainty-region-in-line-plot-in-matplotlib-when-data-has-nans\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - Plotting shaded uncertainty region in line plot in matplotlib when data has NaNs - Stack Overflow<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"TypeError when uploading pixel value bounding box",
        "Question_link":"https:\/\/community.wandb.ai\/t\/typeerror-when-uploading-pixel-value-bounding-box\/2684",
        "Question_created_time":"2022-06-30T20:20:00.089Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":497,
        "Question_body":"<p>Hi,<br>\nI was just trying to log a 2D bounding box with pixel coordinates, but I keep on running into this error:<br>\n<code>TypeError: Object of type int is not JSON serializable<\/code><\/p>\n<p>The code I used:<\/p>\n<pre><code class=\"lang-auto\">box_data = []\n\nclass_labels = {\n    0: \"face\"\n}\n\nfor (x,y,w,h) in face_rects:\n    frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n\n    midX = int(x+w\/2)\n    midY = int(y+h\/2) \n    box = {\n                \"position\": {\n                    \"middle\": [midX, midY],\n                    \"width\": w,\n                    \"height\": h\n                },\n                \"domain\" : \"pixel\",\n                \"class_id\" : 0\n            }\n    box_data.append(box)\n\npredictions = {\"predictions\": {\n        \"box_data\": box_data,\n        \"class_labels\": class_labels\n    }\n    }\n\nimg = wandb.Image(frame, boxes=predictions)\n<\/code><\/pre>\n<p>It works when I\u2019m using the relational notation instead of pixel values, but I\u2019d rather keep the pixel values for simplicity in the code.<\/p>",
        "Question_closed_time":"2022-07-25T19:30:25.744Z",
        "Answer_body":"<p>Hey Mohammad,<br>\nactually today I came back to the project and found something interesting about the bounding box.<br>\nActually, it is not outside of the dimensions of the frame set and I can do a little trick to get the right size of the bounding box working:<\/p>\n<pre><code class=\"lang-auto\"> box = {\n                \"position\": {\n                    \"middle\": [midX, midY],\n                    \"width\": (w\/2)+(w\/2),\n                    \"height\": (h\/2)+(h\/2)\n                },\n\n<\/code><\/pre>\n<p>So what is the difference here? After dividing, the coordinates are <code>float<\/code> values and not <code>int<\/code> anymore and this makes it work(can also just cast them). Sounds like a bug and I just created an issue for it: <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/3982\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Logging bounding boxes only works with float dimensions, not int \u00b7 Issue #3982 \u00b7 wandb\/wandb \u00b7 GitHub<\/a><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Hello\uff0cI save my wandb offline, how can I upload it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hello-i-save-my-wandb-offline-how-can-i-upload-it\/2793",
        "Question_created_time":"2022-07-25T03:36:14.078Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":69,
        "Question_body":"<p>I save my wandb log offline but I can\u2019t upload it, No matter what code I try , it comes the error wandb: ERROR Nothing to sync. I want to know with my runs path(with each runs like offline-run-20220725_105335-3c4wo6kf),how to upload this run online. and how to upload a project?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to group runs (e.g., different random seeds) together on the wandb report function for plots?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-group-runs-e-g-different-random-seeds-together-on-the-wandb-report-function-for-plots\/2634",
        "Question_created_time":"2022-06-18T18:46:32.183Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":490,
        "Question_body":"<p>I am running some experiments where I have multiple random seeds per experiment setting, so I am trying to group the runs together to get their average and standard deviation (this is standard in reinforcement learning research these days). However, I can\u2019t seem to figure out how to get this to reliably work on wandb \u2013 sometimes it works and sometimes it doesn\u2019t.<\/p>\n<p>For reference, this is the kind of plot that I am trying to generate:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb.jpeg\" data-download-href=\"\/uploads\/short-url\/hYtsFlCoHHY8wJNPJseLDMnC29R.jpeg?dl=1\" title=\"Screen Shot 2022-06-18 at 2.32.22 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_565x500.jpeg\" alt=\"Screen Shot 2022-06-18 at 2.32.22 PM\" data-base62-sha1=\"hYtsFlCoHHY8wJNPJseLDMnC29R\" width=\"565\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_565x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_847x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-06-18 at 2.32.22 PM<\/span><span class=\"informations\">1070\u00d7946 97.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>There are two overall curves, but these are averaged among several runs, which is why you see a shaded region for standard deviation.<\/p>\n<p>I make this figure in a wandb report by going to the panel grid and assigning different runs together to a group manually. Here is a screen recording of the process of how I try to do this.<\/p>\n<aside class=\"onebox googledrive\" data-onebox-src=\"https:\/\/drive.google.com\/file\/d\/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a\/view?usp=sharing\">\n  <header class=\"source\">\n\n      <a href=\"https:\/\/drive.google.com\/file\/d\/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a\/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">drive.google.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https:\/\/drive.google.com\/file\/d\/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a\/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\"><span class=\"googledocs-onebox-logo g-drive-logo\"><\/span><\/a>\n\n\n\n<h3><a href=\"https:\/\/drive.google.com\/file\/d\/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a\/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">wandb_cannot_group.mov<\/a><\/h3>\n\n<p>Google Drive file.<\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Here, I\u2019m showing another set of runs that I\u2019m trying to group together (it\u2019s about 15 total individual runs, but in 3-4 groups, so I\u2019m trying to group the curves). However, clicking on the \u201cRuns\u201d button means nothing changes! This is strange since it\u2019s how I do this to create my other grouping plots. Sometimes it works, sometimes it does not. Does anyone have suggestions on how to make this function work more reliably? Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Select runs and parameters for Run Comparer",
        "Question_link":"https:\/\/community.wandb.ai\/t\/select-runs-and-parameters-for-run-comparer\/2787",
        "Question_created_time":"2022-07-21T10:19:36.489Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":131,
        "Question_body":"<p>I\u2019d like the idea of using the Run Comparer, but I can find a way to select which runs to display, nor which parameters I want to display. As I have 100 runs in my project, it seems to be selecting 10 runs at random, none of which are actually the ones I want to compare. There are also lots of parameters that I\u2019m not interested in for this particular evaluation. Unless I\u2019m missing something, I assume a feature would need to be added to allow the user the select the runs and parameters.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I do probabilistic logging?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-do-probabilistic-logging\/2747",
        "Question_created_time":"2022-07-13T23:09:41.053Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":90,
        "Question_body":"<p>I\u2019m currently doing all my logging like this:<\/p>\n<pre><code class=\"lang-auto\">wandb.log(\n{ \"loss\": loss, \"step\": step }, commit=should_commit())\n# step increments with each batch\n\ndef should_commit():\n    return random.randint(0, 100) == 0\n<\/code><\/pre>\n<p>The goal is to only sync metrics to the server once every 100 or so calls to log. I\u2019m doing this because otherwise my training speed is halved, if I just do the default.<\/p>\n<p>But, I notice this isn\u2019t working. My charts look very odd for some reason.<br>\nWhat is the correct way to only sync all my metrics every so often?<\/p>\n<p>To be clear, I want the end result to be such that all my metrics are on the server for every time-step, however, I want to do the syncing infrequently instead of every time I call <code>wandb.log<\/code>, because that\u2019s slow.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Class Label miscount while creating image masks for semantic segmentation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/class-label-miscount-while-creating-image-masks-for-semantic-segmentation\/2734",
        "Question_created_time":"2022-07-11T14:26:28.807Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":133,
        "Question_body":"<p>Hey all,<\/p>\n<p>When making a table of images with image masks, I realized wandb keeps the greatest amount of labels out of all the images as opposed to giving each image in a column its appropriate amount of labels. Ex: If I have 2 images, 1 with 5 labels and another with 11 labels, both image will have 11 labels as opposed to one with 5 and another with 11. I already debugged my code to make sure every time I created a dictionary with the appropriate amount of labels and passed it in as an argument, not sure why the final outcome in wandb still comes out with the wrong labels.<\/p>\n<p>Thanks!<br>\nUmama<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Population Based Training",
        "Question_link":"https:\/\/community.wandb.ai\/t\/population-based-training\/2773",
        "Question_created_time":"2022-07-19T05:18:05.013Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":216,
        "Question_body":"<p>I\u2019m interested in using population-based training as a WandB Sweep methodology as referenced in the article <a href=\"https:\/\/wandb.ai\/wandb\/DistHyperOpt\/reports\/Modern-Scalable-Hyperparameter-Tuning-Methods--VmlldzoyMTQxODM\">here<\/a>.<\/p>\n<p>However, I can\u2019t find any mention or tutorials for PBT with WandB outside of this article. I\u2019m interested in using PBT with a <a href=\"https:\/\/github.com\/spaceml-org\/Self-Supervised-Learner\" rel=\"noopener nofollow ugc\">self-supervised learner<\/a> and configuring the sweep in a YAML. Does anyone have any advice on how to go about this? I\u2019m familiar with configuring sweeps in a YAML or jupyter notebook but, I\u2019m unsure how to make the PBT scheduler and tuner (as outlined in the article) compatible with the SSL code I\u2019m using which is run from the command line.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Group runs from the UI after they all have finished",
        "Question_link":"https:\/\/community.wandb.ai\/t\/group-runs-from-the-ui-after-they-all-have-finished\/2785",
        "Question_created_time":"2022-07-21T08:54:33.471Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":80,
        "Question_body":"<p>Hi, I have some runs in my dashboard that I would like to group but I can\u2019t find a way to do it from the UI since from code is now impossible being them all finished. Is there a way to do it ?<br>\nThank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run crashed at end of epoch due to invalid name",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-crashed-at-end-of-epoch-due-to-invalid-name\/2776",
        "Question_created_time":"2022-07-19T12:34:33.854Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":161,
        "Question_body":"<p>I walked away from my run, only to come back and see it stopped after 1 epoch with:<\/p>\n<pre><code class=\"lang-auto\">  File \"\/home\/ubuntu\/src\/polez\/conda\/polez\/lib\/python3.9\/site-packages\/wandb\/integration\/keras\/keras.py\", line 1019, in _save_model_as_artifact\n    model_artifact = wandb.Artifact(f\"model-{wandb.run.name}\", type=\"model\")\n  File \"\/home\/ubuntu\/src\/polez\/conda\/polez\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_artifacts.py\", line 137, in __init__\n    raise ValueError(\nValueError: Artifact name may only contain alphanumeric characters, dashes, underscores, and dots. Invalid name: \"model-point-tall-fine,temp=0.2,batch=1024,custom_sched=false\"\n<\/code><\/pre>\n<p>I would much rather have found this out at the beginning when I called <code>wandb.init<\/code><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where is the confusion matrix saved on the dashboard?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/where-is-the-confusion-matrix-saved-on-the-dashboard\/2689",
        "Question_created_time":"2022-07-01T17:02:48.455Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_body":"<p>I\u2019ve logged a confusion matrix like the below but I cannot find it listed anywhere on the dashboard of my project for any run. Indeed, I logged this for every step of the training (not every epoch). So where is the confusion matrix stored?<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n                                y_true=target, preds=pred[0],\n                                class_names=class_names)})\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scatter plot instead of Line plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/scatter-plot-instead-of-line-plot\/2706",
        "Question_created_time":"2022-07-06T15:08:14.265Z",
        "Question_answer_count":7,
        "Question_score_count":3,
        "Question_view_count":245,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>regarding the different chart types, I am somehow missing the option \u2018<strong>Scatter plot<\/strong>\u2019 next to \u2018Line plot\u2019, \u2018Area plot\u2019, and \u2018Percent area plot\u2019. Would be great if you could add this feature in the future (or in case it can easily be done somehow else, please let me know how it works \u2013 I already tried custom scatter plots, but it seems as if they are meant for comparing different runs, not matrices from a single run).<\/p>\n<p>Thanks <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":"2022-07-14T20:45:41.559Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/aichberger\">@aichberger<\/a> ,<\/p>\n<p>You can create a line chart with a dotted non connected line through the legend category within chart edit.  I believe that is what you are looking for, see image below. In terms of modifying how a metric is being logged, can you expand on your meaning behind this? You can currently update metrics for a run, after it has finished., see <a href=\"https:\/\/wandb.ai\/mohammadbakir\/Finance-Prediction?workspace=user-mohammadbakir\">here<\/a>.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea.png\" data-download-href=\"\/uploads\/short-url\/wDbjAXgfUtaaLAXhq2VTVU9YU6C.png?dl=1\" title=\"DotChart\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_690x198.png\" alt=\"DotChart\" data-base62-sha1=\"wDbjAXgfUtaaLAXhq2VTVU9YU6C\" width=\"690\" height=\"198\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_690x198.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_1035x297.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_1380x396.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">DotChart<\/span><span class=\"informations\">1819\u00d7524 30 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Point Clouds no longer 3D-viewable?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/point-clouds-no-longer-3d-viewable\/2770",
        "Question_created_time":"2022-07-18T23:34:53.727Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":116,
        "Question_body":"<p>I\u2019ve been using the WandB 3D point cloud feature for a few months now to view my model\u2019s embeddings in 3D.  But recently my collaborators and I have notice that this feature seems to have been disabled\u2026?<br>\nNow when we mouse over a point cloud image, instead of getting the \u201cX\u201d in the top right in order to expand and going into 3D mode\u2026 nothing happens.<br>\n(How) Can we get 3D viz back for point clouds? This was an important feature.<\/p>\n<p>To reproduce: go to any WandB page for point cloud that used to be viewable in 3D, whether in documentation or in your own runs.  You will see that there is no longer a way to make it 3D.<\/p>\n<p>UPDATE: I notice that also <a href=\"https:\/\/wandb.ai\/stacey\/alphafold?workspace=user-stacey\">\u201c3D Molecules\u201d<\/a> are also no longer offered in 3D, rather only as static images.<\/p>\n<p>UPDATE 2: Yea I\u2019m thinking this is an unintentional bug.  Your <a href=\"https:\/\/wandb.ai\/nbaryd\/SparseConvNet-examples_3d_segmentation\/reports\/Point-Clouds--Vmlldzo4ODcyMA\">\u201c3D Objects Live Example\u201d<\/a> also no longer is 3D-viewable.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep on remote cluster GPUs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-on-remote-cluster-gpus\/2731",
        "Question_created_time":"2022-07-09T17:40:56.681Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":290,
        "Question_body":"<p>Hey. I\u2019m trying to run a sweep on a cluster GPUs by submitting it as a new job.<br>\nThe problem is that the job runs, but keep logging a network error:<\/p>\n<blockquote>\n<p>wandb: Network error (ConnectionError), entering retry loop.<\/p>\n<\/blockquote>\n<p>The script works fine if I\u2019m trying to run it \u201clocally\u201d in the cluster i.e. without submitting a GPU job.<br>\nMy intuition is that W&amp;B doesn\u2019t find my creds (.netrc file) on the node its running. So I was wondering if there is a way to directly pass my API key to the wandb.agent function, so that the script is independent of its execution environment?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WandbCallback of fastai crashing the colab session!",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandbcallback-of-fastai-crashing-the-colab-session\/2743",
        "Question_created_time":"2022-07-13T10:02:31.185Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":301,
        "Question_body":"<p>I am trying to fine-tune the ULMFit language model using fastai library.<\/p>\n<p>For logging, I want to use wandb.<\/p>\n<p>To implement wandb in the model, I used WandbCallback.<\/p>\n<p>But, it always crashes the colab session at the end of training of an epoch.<\/p>\n<p>Initially, I thought the session is getting crashed due to a memory issue but when I used the same model with the same data but without wandb callback, it ran successfully.<\/p>\n<p>Below is the code that I have used.<\/p>\n<pre><code class=\"lang-auto\">from fastai.text.all import *\n\nfiles = get_text_files('digital_marketing_data')\n# digital_marketing_data is a folder that contains text files.\n\n# Here's how we use TextBlock to create a language model, using fastai's defaults:\n\nget_db = partial(get_text_files)\n\ndls_lm = DataBlock(\n    blocks=TextBlock.from_folder('digital_marketing_data', is_lm=True),\n    get_items=get_db, splitter=RandomSplitter(0.1)\n).dataloaders('digital_marketing_data', path='digital_marketing_data', bs=64\/\/2, seq_len=100)\n\nimport wandb\nfrom fastai.callback.wandb import *\nimport os\n\nwandb.login()\n\n# Initializing a wandb run\nwandb.init(project='ulmfit_digital_marketing_finetune', name='Default Param with Minimum LR')\n\n# Model\ncp_name = 'model_with_minimum_lr'\nlearn = language_model_learner(\n    dls_lm, AWD_LSTM, drop_mult=0.3, cbs=[GradientAccumulation(n_acc=64),WandbCallback(),SaveModelCallback(fname=cp_name, every_epoch=True, with_opt=True)],\n    metrics=[accuracy, Perplexity()]).to_fp16()\n<\/code><\/pre>\n<p>When I ran the same code without WandbCallback(), then it ran successfully, but with WandbCallback() it always crashes the colab session.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Rendering confusion matrix from 2D array",
        "Question_link":"https:\/\/community.wandb.ai\/t\/rendering-confusion-matrix-from-2d-array\/2775",
        "Question_created_time":"2022-07-19T11:09:38.386Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":116,
        "Question_body":"<p>I have a ConfusionMatrix metric implemented as a subclass of tf.keras.metrics.Metric where the only value is a tf.Variable with shape=(13,13) and dtype=tf.uint32. In wandb UI this just shows up as a histogram, is there some way to reinterpret this as a multilabel confusion matrix?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png\" data-download-href=\"\/uploads\/short-url\/tqgId0mKmRahaQW7TqrvTeIns4Y.png?dl=1\" title=\"Screen Shot 2022-07-19 at 9.09.20 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_690x446.png\" alt=\"Screen Shot 2022-07-19 at 9.09.20 pm\" data-base62-sha1=\"tqgId0mKmRahaQW7TqrvTeIns4Y\" width=\"690\" height=\"446\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_690x446.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-07-19 at 9.09.20 pm<\/span><span class=\"informations\">874\u00d7566 16.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Track power\/energy consumption?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/track-power-energy-consumption\/2774",
        "Question_created_time":"2022-07-19T07:47:56.213Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":84,
        "Question_body":"<p>Hey all,<\/p>\n<p>I wondered if there was a way to track system power consumption caused by model development? I\u2019ve checked the W&amp;B docs and can\u2019t see anything.<br>\nIdeally I\u2019d love to be able to keep track of runs to see how much power is used by different runs but also the whole project.<\/p>\n<p>Elsewhere I\u2019ve seen packages such as <a href=\"https:\/\/pypi.org\/project\/energyusage\/\" rel=\"noopener nofollow ugc\">energyusage<\/a> but ideally would like to use something more integrated and could be aggregated across runs for whole projects.<br>\nIf something already exists I\u2019d love to hear about it, otherwise either if W&amp;B fancied adding this functionality that would be great or if it came to it if anyone would like to help me with this project.<\/p>\n<p>Thanks,<\/p>\n<p>Jeff.<\/p>",
        "Question_closed_time":"2022-07-19T08:08:15.949Z",
        "Answer_body":"<p>Hi,<br>\nWe have this example that shows how to do this with CodeCarbon.<br>\n<a href=\"https:\/\/wandb.ai\/amanarora\/codecarbon\/reports\/Tracking-CO2-Emissions-of-Your-Deep-Learning-Models-with-CodeCarbon-and-Weights-Biases--VmlldzoxMzM1NDg3\">https:\/\/wandb.ai\/amanarora\/codecarbon\/reports\/Tracking-CO2-Emissions-of-Your-Deep-Learning-Models-with-CodeCarbon-and-Weights-Biases\u2013VmlldzoxMzM1NDg3<\/a><\/p>\n<p>You would use that library and log the info yourself. I do appreciate the feature request to integrate these more tightly.<br>\nThanks, hope this helps<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"W&B Sweeps w\/ Self-Supervised Learning",
        "Question_link":"https:\/\/community.wandb.ai\/t\/w-b-sweeps-w-self-supervised-learning\/2579",
        "Question_created_time":"2022-06-08T20:21:31.416Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":578,
        "Question_body":"<p>I\u2019m reaching out to get some thoughts on integrating W&amp;B Sweeps with some of the code we\u2019re interested in using. An example of the code we\u2019re running is linked <a href=\"https:\/\/streaklinks.com\/BEDYVhxBgS02lmUdIwa1e2xV\/https%3A%2F%2Fgithub.com%2Fspaceml-org%2FSelf-Supervised-Learner%2Fblob%2Fmain%2Ftutorials%2FPythonColabTutorial_Merced.ipynb\" rel=\"noopener nofollow ugc\">here<\/a>. Note the 2 key sections \u2018Training Self-Supervised Learning Model\u2019 and \u2018Fine Tuning Model\u2019 which contain the !python commands we\u2019re interested in tuning (model, technique, learning rate, etc.)<\/p>\n<p>Based on <a href=\"https:\/\/streaklinks.com\/BEDYVh1Fxefx8VZVJQh5ZZi-\/https%3A%2F%2Fdocs.wandb.ai%2Fguides%2Fsweeps%2Fpython-api\" rel=\"noopener nofollow ugc\">this documentation<\/a>, I\u2019ve set up sweep_config but I\u2019m unsure how to incorporate the 2 !python commands in train() when running an agent. Do you have any input on how to integrate a wandb sweep with these 2 commands?<\/p>\n<p>An additional point I wanted to discuss was the strategy for a Sweep. The SSL code we\u2019re running requires training 2 sequential models (the SSL and the final classification Model) where the output SSL model is the input to the final classification model (see the linked code above). We\u2019re interested in doing hyperparameter tuning for both of the models - should we set up 2 independent sweeps for each? Or should we run a sweep on the first SSL model, pick the best performing model and use that as the input into the second classification model where we run a second sweep?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WandB icevision not showing prediction",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-icevision-not-showing-prediction\/2767",
        "Question_created_time":"2022-07-18T10:53:29.792Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":222,
        "Question_body":"<p>Hello everyone,<\/p>\n<p>I am using WanbB in IceVision through the fastai integration, you could have a look here for <a href=\"https:\/\/airctic.com\/0.12.0\/wandb_efficientdet\/\" rel=\"noopener nofollow ugc\">IceVision WandB<\/a> but i get the following message:<\/p>\n<pre><code class=\"lang-auto\">Could not gather input dimensions\nWandbCallback was not able to prepare a DataLoader for logging prediction samples -&gt; 'Dataset' object has no attribute 'items'\n<\/code><\/pre>\n<p>Any help appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Confusion with resume=true",
        "Question_link":"https:\/\/community.wandb.ai\/t\/confusion-with-resume-true\/2765",
        "Question_created_time":"2022-07-17T20:01:10.757Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":122,
        "Question_body":"<p>I just started using wandb,  and I wanted to train two models over the weekend on 1 GPU, but after a while one of them crashed due to lack of memory. I reduced the val batch size then added <code>resume=true<\/code> to the call to <code>wandb.init<\/code> and things started progressing. Checking in over the weekend I saw that only one run was \u201crunning\u201d, the other was \u201ccrashed\u201d. I went to look at the actual terminal session where I launched the jobs, and they were both still running.<\/p>\n<p>At this point I had 2 runs under my project, as I\u2019d deleted all the previous failed attempts. I assumed I\u2019d accidentally deleted the wrong run from the UI, but when I looked at the graphs I saw that training accuracy and loss went backwards at one epoch.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523.png\" data-download-href=\"\/uploads\/short-url\/5YiO2JPEIhGDLezHYJTY91QO9BV.png?dl=1\" title=\"Screen Shot 2022-07-18 at 5.28.13 am\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png\" alt=\"Screen Shot 2022-07-18 at 5.28.13 am\" data-base62-sha1=\"5YiO2JPEIhGDLezHYJTY91QO9BV\" width=\"381\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_571x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_762x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-07-18 at 5.28.13 am<\/span><span class=\"informations\">920\u00d71206 49.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>This shouldn\u2019t happen, so I went to look at the logs for the runs in MLFlow (still using it as I try out wandb) and the train accuracy for both runs was monotonically increasing. Looking closer at the actual values and the logs, I think both runs are submitting values to the same \u201crun\u201d. The graph was saying accuracy was 0.973 at epoch 6, and 0.9711 at epoch 7. Looking at my terminal logs for the most recent epoch for each run, I saw:<\/p>\n<p>point-tall-fine:  loss: 0.3797 - acc: 0.9730<br>\npoint-tall-baseline: loss: 0.3842 - acc: 0.9711<\/p>\n<p>Scrolling up to the top of each log, I see both are using <code>runs\/ajydp67n<\/code>. I\u2019m guessing  this is because I didn\u2019t specify anything other than config when calling init,  does wandb not disambiguate runs based on the value of <code>config<\/code>?<\/p>\n<p><code>wandb.init(config=wandb_args, resume=True)<\/code><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Runs log stops at 50",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runs-log-stops-at-50\/2696",
        "Question_created_time":"2022-07-04T12:02:27.013Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":224,
        "Question_body":"<p>Hello, i am running wandb locally in my computer. I start a sweep and it runs smoothly, but when it reaches 50 runs it stops. Although kernel seems to be running it does not show any runs in the wandb site nor locally files in my computer. Does anyone know what seems to be the problem? I can provide any logs if requested, i don\u2019t know what to post and be helpful.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep run not closing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-run-not-closing\/2639",
        "Question_created_time":"2022-06-21T22:07:39.393Z",
        "Question_answer_count":10,
        "Question_score_count":1,
        "Question_view_count":269,
        "Question_body":"<p>I am trying to run sweep for hyperparameter tuning. This was to get the best parameters according to val_loss and use those to retrain another model.<br>\nBut the problem is that when I implement both these steps instead of creating a separate run for the retraining of model it repeats the last run of sweep.<br>\nA template of my script<\/p>\n<pre><code class=\"lang-auto\">#Login into account\nwandb.login()\n\nsweep_config_up = {\n    'method': 'bayes',\n    'metric':{\n    'name': 'val_loss',\n    'goal': 'minimize'\n    },\n    'parameters': {\n        'dropout':{\n          'values':[0.2, 0.25]\n        },\n        'hidden_layer_size':{\n          'values':[128,256]\n        },\n        'layer_1_size':{\n          'values':[8,16,32]\n        },\n        'layer_2_size': {\n          'values': [32, 64, 96]\n      },\n          'decay':{\n            'values':[1e-6, 1e-5]\n          },\n          'momentum':{\n            'values':[0.85, 0.9]\n          },\n          'epoch': {\n            'values' : [5, 10]\n      },\n          'learn_rate': {\n        # a flat distribution between 0 and 0.1\n        'distribution': 'uniform',\n        'min': 0,\n        'max': 0.01\n        }\n    }\n}\n\ndef build_model(config, img_width, img_height, num_classes):\n  config = config\n  model = Sequential()\n  model.add(Conv2D(config.layer_1_size, (5, 5), activation='relu',\n                    input_shape=(img_width, img_height, 1)))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Conv2D(config.layer_2_size, (5, 5), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(config.dropout))\n  model.add(Flatten())\n  model.add(Dense(config.hidden_layer_size, activation='relu'))\n  model.add(Dense(num_classes, activation='softmax'))\n  return model\n\ndef load_data(width, height):\n  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n  labels = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n            \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n  img_width, img_height = width, height\n\n  X_train = X_train.astype('float32') \/ 255.\n  X_test = X_test.astype('float32') \/ 255.\n\n  # reshape input data -- add channel dimension\n  X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n  X_test = X_test.reshape(X_test.shape[0], img_width, img_height, 1)\n\n  # one hot encode outputs\n  y_train = np_utils.to_categorical(y_train)\n  y_test = np_utils.to_categorical(y_test)\n  num_classes = y_test.shape[1]\n  return X_train, y_train, X_test, y_test, num_classes, labels\n\ndef model_train():\n  #intialize the wandb\n  config_defaults = dict(\n    dropout=0.2,\n    hidden_layer_size=128,\n    layer_1_size=16,\n    layer_2_size=32,\n    learn_rate=0.01,\n    decay=1e-6,\n    momentum=0.9,\n    epoch=30,\n    )\n  run = wandb.init(reinit = True, config=config_defaults, magic=True, group='sweep_runings', job_type = 'training_new')\n  with run: \n    config = wandb.config\n    #specify height and width of the image\n    img_width, img_height = 28, 28\n    #load the data\n    X_train, y_train, X_test, y_test, num_classes, labels = load_data(img_width, img_height)\n    #build the model\n    model = build_model(config, img_width, img_height, num_classes)\n    #define the callbacks \n    callbacks = [WandbCallback(data_type=\"image\", labels=labels)]\n    #define the optimizer\n    sgd = SGD(learning_rate=config.learn_rate, decay=config.decay, momentum=config.momentum,\n            nesterov=True)\n    #compile and fit the model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    model.fit(X_train, y_train,  validation_data=(X_test, y_test),\n            epochs=config.epoch,\n            callbacks=callbacks\n            )\n\nsweep_id = wandb.sweep(sweep_config_up, project=\"sweeps\")\n\nwandb.agent(sweep_id, function = model_train, count=2)\n\nwandb.finish()\n\nprint('--------------------------------------------------------finish_train model-------------------------------------------------')\n\n\nprint('--------------------------------------------------------Retrain model-------------------------------------------------')\n\n#get best model paramaters\napi = wandb.Api()\napi_dir = 'some\/sweeps\/'\nsweep = api.sweep(os.path.join(api_dir,sweep_id))\n\n# Get best run parameters\nbest_run = sweep.best_run()\nbest_parameters = best_run.config\nprint(best_parameters)\n\nwandb.finish()\n\nmodel_path = os.getcwd()\nmodel_name = 'model.h5'\nprefix = 'cnn_model'\n\n#retrain the model and log weights \ndef retrain_model(best_parameters, model_path, model_name, prefix):\n  project_name = \"sweeps\"\n  run = wandb.init(reinit=True ,config=best_parameters, project = project_name, group='best_model', job_type = 'training_new_model' )\n  #specify height and width of the image\n  with run:\n    config = wandb.config\n    img_width, img_height = 28, 28\n    #load the data\n    X_train, y_train, X_test, y_test, num_classes, labels = load_data(img_width, img_height)\n    #build the model\n    model = build_model(config, img_width, img_height, num_classes)\n    #define the callbacks \n    callbacks = [WandbCallback(data_type=\"image\", labels=labels, log_weights=True)]\n    #define the optimizer\n    sgd = SGD(learning_rate=config.learn_rate, decay=config.decay, momentum=config.momentum,\n          nesterov=True)\n    #compile and fit the model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    model.fit(X_train, y_train,  validation_data=(X_test, y_test),\n          epochs=config.epoch,\n          callbacks=callbacks\n            )\n    model.save(model_name)\n\n    #weight model display structure\n    weight_at = \"_\".join([prefix, \"weights\"])\n    #create artifact\n    weight_model_at = wandb.Artifact(weight_at, type=\"model_weight\", metadata = best_parameters)            \n\n    # save trained model as artifact\n    weight_model_at.add_file(os.path.join(model_path, model_name))            \n                \n    # save artifact to W&amp;B\n    run.log_artifact(weight_model_at)\n\n    run.finish()\n\nretrain_model(best_parameters, model_path, model_name, prefix)\n\nprint('--------------------------------------------------------finish_Retrain model-------------------------------------------------')\n\n\n<\/code><\/pre>\n<p>Here is an image of the resulting runs<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png\" data-download-href=\"\/uploads\/short-url\/OB2tYgbhTKU83XM1uVZZrotC37.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_337x500.png\" alt=\"image\" data-base62-sha1=\"OB2tYgbhTKU83XM1uVZZrotC37\" width=\"337\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_337x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">489\u00d7724 21.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I would be extremely grateful if you can provide a suggestion or highlight the mistake. Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging Metrics for each sample per epoch",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-metrics-for-each-sample-per-epoch\/2678",
        "Question_created_time":"2022-06-29T20:28:00.479Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":267,
        "Question_body":"<p>Hey everyone,<br>\nLet\u2019s say that I have a dataset with 50000 samples and I am training my model for 10 epochs. Now, in each epoch, I am recording the <em>per sample loss<\/em> (i.e. loss of each sample - Not the average loss of all samples). This means that there are 50000 loss values per epoch. I want to log these values for <em>each epoch<\/em>, so that I can later perform some analysis on how the loss values for the samples change as training progresses (And, if possible, observe the loss values of a particular sample across epochs). For reference, <a href=\"https:\/\/proceedings.neurips.cc\/paper\/2020\/file\/62000dee5a05a6a71de3a6127a68778a-Paper.pdf\" rel=\"noopener nofollow ugc\">this<\/a> paper tracks such  statistics. Here are two ways I can think of doing this -<\/p>\n<ul>\n<li>A simple way to do this is to update the values in a 50000x10 array, then log the array as a table at the end of training (I would obviously need to track which indices belong to which samples). However, I need to wait for the training to end in this scenario.<\/li>\n<li>I can also log each sample\u2019s statistic with wandb.log (Maybe put them under \u201csample_statistics\/\u201d to pull them more easily). This ensures that the metrics are logged as and when they are observed, however, I am not sure if this is the most optimal solution.<\/li>\n<\/ul>\n<p>Is there any other way in which I can do this so that I can analyse the resulting data effectively? Open to all suggestions!<br>\nThank you!<\/p>",
        "Question_closed_time":"2022-07-01T23:32:44.004Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/tataganesh\">@tataganesh<\/a> ,<\/p>\n<p>Thank you for writing in with your question.   Ideally what would be best in your case here is to create an Empty table and log per sample loss values per epoch and be able to see your data live in the UI. However, we currently,  don\u2019t support adding new rows to existing tables that you\u2019ve already logged. We are working on adding this functionality.<\/p>\n<p>In the meantime here are two approaches<\/p>\n<ol>\n<li>Keep the wandb.Table locally holding all the data in memory and logging it once.<\/li>\n<li>Keep logging the same table at each step, and just add new rows to it. The final table you log will have all the rows you want, and you\u2019ll be able to see the latest table logged in the UI. This would be risky if you have large table sizes.<\/li>\n<\/ol>\n<p>Please Note: If you were to look through our docs and come across the<a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/log-tables#add-data\"> Add Data Incrementally<\/a> to  Tables doc, this functionality is currently broken and we are working on an active fix.  There is github issues thread <a href=\"https:\/\/github.com\/wandb\/client\/issues\/2981\" rel=\"noopener nofollow ugc\">here<\/a> where community members have posted workarounds for this, you may find it helpful.<\/p>\n<p>Please let me know if you have any questions.<\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Sweep command",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-command\/2749",
        "Question_created_time":"2022-07-14T10:06:58.155Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":191,
        "Question_body":"<p>Hi,<br>\nI am trying to create a sweep YAML config but the hp are not passed as cli args to my script.<\/p>\n<p>The yaml:<\/p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">\nprogram: src.stance_detection.bert.simpletransformers.sweep_tests\nmethod: grid\nmetric:\n  goal: minimize\n  name: loss\nparameters:\n  n:\n    values: [1, 2]\ncommand:\n  - ${env}\n  - ${interpreter}\n  - \"-m\"\n  - ${program}\n  - ${args_no_boolean_flags}\n<\/code><\/pre>\n<p>The script:<\/p>\n<pre><code class=\"lang-python\">import wandb\nfrom pprint import pprint\nimport sys\n\nif __name__ == \"__main__\":\n    pprint(sys.argv)\n    wandb.init()\n    wandb.log({\"loss\": 0})\n<\/code><\/pre>\n<p>I was expecting <code>sys.argv<\/code> to contain <code>--n=[value]<\/code>. What am I doing wrong?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Retrieving Models (Aliases) held in the Model Registry",
        "Question_link":"https:\/\/community.wandb.ai\/t\/retrieving-models-aliases-held-in-the-model-registry\/2700",
        "Question_created_time":"2022-07-05T08:51:11.943Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":146,
        "Question_body":"<p>I\u2019m trying a new model management set-up leveraging the model registry. My previous model management loop would go and check for any new aliases in a model which contained the word \u2018challenger\u2019, these models would then be pulled through to an evaluation job against the current \u2018champion\u2019 model to check whether any new challenger models should be staged for evaluation by a ML Eng to decide whether it should be promoted to production.<\/p>\n<p>The previous code used to do this was leveraging <code>api.artifact_versions<\/code>:<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api(overrides={\"project\": \"test-project\"})\nartifacts = api.artifact_versions(\"model\", \"model-name\")\n<\/code><\/pre>\n<p>This returns the different versions of that model which exist (with all the alias names) as a list of lists of aliases<\/p>\n<p>When applying this same logic against a model-registry (collection) the api no longer works \/ isn\u2019t able to resolve the items held in the model registry.<\/p>\n<p>Is there a different way to access the items held in the model registry?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Store trained models without wandb as artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/store-trained-models-without-wandb-as-artifacts\/2722",
        "Question_created_time":"2022-07-07T10:37:50.706Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":310,
        "Question_body":"<p>Hello wandb community!<\/p>\n<p>I have a large collection of trained models (with pytorch-lightning), but unfortunately without using wandb back then. So, I am wondering if there is a way to store them as artifacts in a model registry.<\/p>\n<p>Thanks in advance! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging a table from a list of python dicts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-a-table-from-a-list-of-python-dicts\/2701",
        "Question_created_time":"2022-07-05T16:18:18.222Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":186,
        "Question_body":"<p>Is it possible to log tables to WANDB from a list \/sequence of dicts where the keys are the column names and the values wandb.Images (for example)?<\/p>\n<p>Once the my tables are logged to WANDB, if they share a column, can I join them in the WANDB web GUI?<\/p>\n<p>Thanks  beforehand!<\/p>",
        "Question_closed_time":"2022-07-07T19:38:05.552Z",
        "Answer_body":"<p><a class=\"mention\" href=\"\/u\/fisikillo\">@fisikillo<\/a> ,<\/p>\n<p>Thanks for writing in. We support logging tables using list\/nested listed  with multiple images, see <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/log-tables#create-tables\">here.<\/a> You can also join tables directly from the web GUI.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"WandB doesn't track my metrics after a certain step onwards",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-doesnt-track-my-metrics-after-a-certain-step-onwards\/2709",
        "Question_created_time":"2022-07-06T16:14:43.051Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":100,
        "Question_body":"<p>Hi! My issue is that I can track the trend of my metrics in wandb panels till around 820 steps (or epochs, I run 250 epochs for each task of a Continual Learning scenario, and the tasks are 10, so in the end I should have around 2500 steps), then the panels don\u2019t show the metrics anymore. The experiment is running smoothly and I don\u2019t get any error in the terminal. Is there any kind of cap on the max steps? Do I have to set it? I just log 3 metrics.<br>\nThank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save long tensors using wandb.save OR wandb.log?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-long-tensors-using-wandb-save-or-wandb-log\/2737",
        "Question_created_time":"2022-07-11T18:27:04.663Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":264,
        "Question_body":"<p>Hi all,<br>\nIn my experimentation, I want to save some tensor_10k_size for a dataset which has 90k samples.  so that I can compare how the tensors look for different datasets. It\u2019s part of my thesis.<br>\nWhich is a better option to save tensors in my scripts using wandb.save(\u2018filename\u2019)<br>\nor<br>\nwandb.log(tensor)<\/p>\n<p>Thanks,<br>\nPrachi<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plot array, over time",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plot-array-over-time\/2690",
        "Question_created_time":"2022-07-01T20:44:41.950Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":103,
        "Question_body":"<p>Hi all,<\/p>\n<p>I have a simple 1D array (e.g. norm of each layer), that I want to plot over time (e.g. plot \u201cnorm against array index\u201d, each time step). Should I create a line plot? How can I overlay line plots as they are updated?<\/p>\n<p>Thanks! Carlos<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ValueError: Value out of range: 15263439326086220952",
        "Question_link":"https:\/\/community.wandb.ai\/t\/valueerror-value-out-of-range-15263439326086220952\/2729",
        "Question_created_time":"2022-07-08T14:08:59.847Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":143,
        "Question_body":"<p>I am trying sweep in a remote server,whose system is Centos 7.6.<br>\nAfter the first run ,it occered  an  ERROR as folow:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6a868c651662464dfba15f99745bf91fd688ff00.png\" data-download-href=\"\/uploads\/short-url\/fcmSAJb5vDbYn8vgBpfwfFB8mZO.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6a868c651662464dfba15f99745bf91fd688ff00.png\" alt=\"image\" data-base62-sha1=\"fcmSAJb5vDbYn8vgBpfwfFB8mZO\" width=\"690\" height=\"265\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6a868c651662464dfba15f99745bf91fd688ff00_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1134\u00d7436 19.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nAnd  the code is ok to run in my conputer.<br>\nwhen i remove all the sweep code,the code is able ro run successfully in the remote server too.<br>\nIs this error attributed to my remote server?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Compare different architectures for a same task",
        "Question_link":"https:\/\/community.wandb.ai\/t\/compare-different-architectures-for-a-same-task\/2724",
        "Question_created_time":"2022-07-07T13:53:24.620Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":510,
        "Question_body":"<p>Hey there.<\/p>\n<p>I discovered W&amp;B recently and decided to use it for my current research project. The thing is that I have a specific task to solve and would like to evaluate a bunch of completely different model architectures, having different sets of hyper-parameters.<\/p>\n<p>Most of the online resources and tutorials I\u2019ve found only shows examples of W&amp;B usage to evaluate different experiments with different params selections (e.g. optimized using sweeps). However none of the examples I found explained how to optimally organize a W&amp;B project including different architectures to solve the same task, and thus being able to compare in a glimpse the different performances in a single view \/ report.<\/p>\n<p>My idea was to make use of the job_type flag and group every architecture instances together under a same job_type flag. But still seems like not the best solution and was wondering if there is some special feature or built-in tool that I\u2019ve not noticed yet (or even good practices?).<\/p>\n<p>(Other than that, W&amp;B looks really insane).<\/p>\n<p>Many thanks <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/smile.png?v=12\" title=\":smile:\" class=\"emoji\" alt=\":smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log custom criterion function?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-custom-criterion-function\/2703",
        "Question_created_time":"2022-07-05T22:59:47.579Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":116,
        "Question_body":"<p>We can use <code>wandb.watch(model, criterion, ...)<\/code> in order to log a model + a loss function.<br>\nBut my loss function is not something simple like: <code>criterion = nn.CrossEntropyLoss()<\/code>.<\/p>\n<p>Rather, here\u2019s how I calculate my loss:<\/p>\n<pre><code class=\"lang-auto\">            # `set_to_none=True` boosts performance\n            optimizer.zero_grad(set_to_none=True)\n            masks_pred = model(imgs)\n\n            probs = F.softmax(masks_pred, dim=1).float()\n            ground_truth = F.one_hot(masks, model.n_classes).permute(0, 3, 1, 2).float()\n\n            loss = criterion(masks_pred, masks) + dice_loss(probs, ground_truth)\n            loss.backward()\n            optimizer.step()\n<\/code><\/pre>\n<p>As you can see, the loss is a composition of 2 functions: the criterion and the <code>dice_loss<\/code> function.<br>\nWhat should I pass to <code>wandb.watch<\/code> for the <code>criterion<\/code> argument?<\/p>",
        "Question_closed_time":"2022-07-08T18:53:54.861Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/vroomerify\">@vroomerify<\/a>,<\/p>\n<p>Thanks for reaching out. <code>wandb.watch<\/code> expects a torch function as a criterion parameter. You can set up a custom criterion function by subclassing <code>torch.nn.Module<\/code>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to automatically add new panel to group",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-automatically-add-new-panel-to-group\/2715",
        "Question_created_time":"2022-07-06T19:08:10.574Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":118,
        "Question_body":"<p>Hi,<\/p>\n<p>I create a group of runs, that is similar to parameter sweeping, and want to show the parallel coordinates panel. I can do that manually, but wonder how to programmatically add than when creating a group?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851.png\" data-download-href=\"\/uploads\/short-url\/4w8N8k8sYvcpJ5hhRM9TWr8fxK1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_690x304.png\" alt=\"image\" data-base62-sha1=\"4w8N8k8sYvcpJ5hhRM9TWr8fxK1\" width=\"690\" height=\"304\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_690x304.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_1035x456.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1377\u00d7608 84.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Analyzing hyperparameters without actualy performing a sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/analyzing-hyperparameters-without-actualy-performing-a-sweep\/2719",
        "Question_created_time":"2022-07-07T08:09:02.018Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":143,
        "Question_body":"<p>Hy, I\u2019m in love with wandb, but I have a problem\u2026<\/p>\n<p>I have a simple question\u2026<\/p>\n<p>How can I analyze hyperparameters\u2026As seen in this picture, without actually creating a sweep.<\/p>\n<p>In my own code\u2026<\/p>\n<p><img src=\"https:\/\/mail.google.com\/mail\/u\/0?ui=2&amp;ik=8824e8d63e&amp;attid=0.1&amp;permmsgid=msg-a:r-1242756300606160728&amp;th=181d7b1a169f2ed0&amp;view=fimg&amp;fur=ip&amp;sz=s0-l75-ft&amp;attbid=ANGjdJ9LbpPclu5VUg_KiYT_9MyY2AbgyxXn6tmqz8qoKH2kUghMnyxeJstBhkIK4wCOgqfFHueuZ6ul6juIl6zvWD3lcsPXIvZAnZatibVLxPjneVvO-xSUoWLyCpM&amp;disp=emb&amp;realattid=ii_l5aqmkag2\" alt=\"68747470733a2f2f692e696d6775722e636f6d2f5455333451465a2e706e67.png\" width=\"339\" height=\"205\"><\/p>\n<p>I\u2019m preforming learning and for every model i\u2019m sending config with hyperparams\u2026<\/p>\n<p>wandb.finish(quiet=True)<br>\nwandb.init(<br>\nentity=var.WANDB_ENTITY,<br>\nproject=f\u2019{var.version} | {var.INPUT_DATASET}',<br>\ndir=str(var.working_dir),<br>\nconfig=utils.keras.hyper_params(hp))<\/p>\n<p>But in dashboard I dont see hyperparameters dashboard\u2026 And this makes me really sad !<\/p>",
        "Question_closed_time":"2022-07-07T18:37:19.909Z",
        "Answer_body":"<p>I can\u2019t see the images above, but if you would like to create a <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/panels\/parallel-coordinates\">parallel coordinates plot<\/a>, you can do so using the UI by clicking \u201cadd panel\u201d in your workspace and choosing Parallel Coordinates.<\/p>\n<p>If you need to do this programmatically, one <em>very<\/em> recent feature would be to create a W&amp;B Report using our Api. You can programatically define what plots show up. It is a very new feature so it\u2019ll become better documented and more stable over time.<\/p>\n<p>Here\u2019s how you would create a Parallel Coordinates plot programmatically and save it in a report using Python.<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport wandb.apis.reports as wb\napi = wandb.Api()\nproject = 'pytorch-sweeps-demo'\nwandb.require('report-editing') # this is needed as of version 0.12.21 but will likely not be needed in future.\nreport = wb.Report(\n    project=project,\n    title='Sweep Results',\n    blocks=[\n            wb.PanelGrid(panels=[\n                 wb.ParallelCoordinatesPlot(\n                     columns=[wb.reports.PCColumn('batch_size'), wb.reports.PCColumn('epoch'), wb.reports.PCColumn('loss')])\n            ], runsets=[wb.RunSet(project=project)]),\n    ]\n)\nreport.save()\n<\/code><\/pre>\n<p>This will then show up in the Reports tab on your project.<br>\nAs this is a very fresh API, there may be issues or features that are not supported yet. I do apologise if that happens to you, I\u2019ll be happy to follow up and provide help.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Benchmarking function calls using python decorators",
        "Question_link":"https:\/\/community.wandb.ai\/t\/benchmarking-function-calls-using-python-decorators\/2713",
        "Question_created_time":"2022-07-06T18:49:13.203Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":150,
        "Question_body":"<p>To visualize performance bottlenecks, we want to know execution times for functions calls<br>\nUsing  <code>time.time()<\/code>  makes the code ugly<br>\nCan we write a python decorator for this so that users only need to decorate their definitions<\/p>\n<pre><code class=\"lang-python\">@wandb.timeit\ndef my_function(args)\n    pass<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging values to ongoing run from a different process",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-values-to-ongoing-run-from-a-different-process\/2671",
        "Question_created_time":"2022-06-28T04:42:52.182Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":88,
        "Question_body":"<p>Hi there!<br>\nIn my use case I\u2019m running a training loop and storing a model at a regular interval. During training, I also want to evaluate metrics such as the CIDEr score for image captioning. The problem is, computing these metrics takes a lot of time (~40 minutes), and the training is running on a cluster where I can\u2019t evaluate the metrics for several reasons.<\/p>\n<p>So my plan is to load the stored models on a separate machine after every update, and evaluate the metrics there. Once done, I would like to log the metrics to the ongoing training runs, with a step parameter set to the time when the model was stored. So by the time the evaluation is finished, the training runs will have progressed in steps.<\/p>\n<p>Is this possible using the wandb api, without getting concurrency problems?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to make parametric plots?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-make-parametric-plots\/2662",
        "Question_created_time":"2022-06-27T07:58:30.393Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":244,
        "Question_body":"<p>Hello, I would like to make plots such as the ones that can be seen in this video at this timestamp (59:59): <a href=\"https:\/\/youtu.be\/XL07WEc2TRI?t=3599\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Stanford Seminar - Information Theory of Deep Learning - YouTube<\/a><\/p>\n<p>Basically, I have two variables (let\u2019s say X and Y) that are measured at each layer and epoch, and I would like to have a unified plot where each layer is represented as a parametric curve. Connecting points in a same epoch by neighboring layers would be a plus but that\u2019s optional.<br>\nSo for each epoch and layer, I would like to plot a point at coordinates (X,Y) connected to the corresponding previous point of the previous epoch. If possible, I would like to color each point according to the epoch so that we can see the progression.<\/p>\n<p>I tried to plot a line series like this:<\/p>\n<pre><code class=\"lang-python\">wandb.log({\"XY\": wandb.plot.line_series(self.layers_x, self.layers_y, self.layer_names,\n                                        \"XY by layer and epoch\", \"X\")}, step=step)\n<\/code><\/pre>\n<p>But there are three issues with this:<\/p>\n<ol>\n<li>The points of the curves aren\u2019t connected in the correct order, it seems they are implicitly connected according to their sorted X values. So the resulting curves are incorrect, even if I can guess the true shapes they should have.<\/li>\n<li>I haven\u2019t managed to get point coloring according to the epoch number, and I had to manually modify the plot in the dashboard so that I had all curves correctly displayed in the same plot. I had to use custom plots but I am not familiar with these. I also don\u2019t know how to set the display name of the y axis which is \u201cy\u201d by default.<\/li>\n<li>I have to manually keep track of the table values, if possible I would like to log the values for each step normally, like any other value like the accuracy at each epoch.<\/li>\n<\/ol>\n<p>So, is it possible to make such plots? Thank you.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Which stream is captured on Run Log page?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/which-stream-is-captured-on-run-log-page\/2669",
        "Question_created_time":"2022-06-27T15:36:52.897Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":89,
        "Question_body":"<p>Hi,<\/p>\n<p>I noticed that there is a log page for each run. Which stream does the log page capture? In my case it seems only capture stderr but no stdout<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Runs not listed in workspace",
        "Question_link":"https:\/\/community.wandb.ai\/t\/runs-not-listed-in-workspace\/2593",
        "Question_created_time":"2022-06-10T13:21:04.003Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_body":"<p>In my workspace (on the left) runs are not listed, although they appear in the plots.<\/p>\n<p>I tried turning filters on and off but this didn\u2019t change anything.<\/p>\n<p>When I switch to the table view all the runs are there.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8.jpeg\" data-download-href=\"\/uploads\/short-url\/eJF0nB5WgI7JkvFgmKGP6rnRJ6.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_690x268.jpeg\" alt=\"image\" data-base62-sha1=\"eJF0nB5WgI7JkvFgmKGP6rnRJ6\" width=\"690\" height=\"268\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_690x268.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_1035x402.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_1380x536.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1920\u00d7746 70.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run sweep on cluster",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-sweep-on-cluster\/2629",
        "Question_created_time":"2022-06-17T09:06:42.852Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":434,
        "Question_body":"<p>I want to run a sweep on a cluster, say I want to use just 1\/4th of a node which has 32 cpus (It\u2019s an RNN so cpus are fine and cheaper). One cpu has enough memory to do a run, but of course I want to use all, so ideally I\u2019d want to do 32 training loops in parallel.<\/p>\n<p>How do I get this to work?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I create a custom metric for bayesian sweeps?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-create-a-custom-metric-for-bayesian-sweeps\/2622",
        "Question_created_time":"2022-06-15T22:53:31.703Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":300,
        "Question_body":"<p>I am trying to figure out how to integrate a custom metric for sweeps. It should be a composite of the number of clusters created as well as the number of outliers. I\u2019m just getting started and the answer doesn\u2019t jump out from the documentation. Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Empty group name",
        "Question_link":"https:\/\/community.wandb.ai\/t\/empty-group-name\/2452",
        "Question_created_time":"2022-05-19T23:45:21.104Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":139,
        "Question_body":"<p>By my mistake, group name is changed to empty.<br>\nWhen I click the group with empty name, it always redirect to project workspace.<br>\nI can\u2019t find any options make me enable to change the empty group name.<br>\nHow can I change the empty group name.<br>\nIt\u2019s so inconvenient.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Overlaying two point clouds",
        "Question_link":"https:\/\/community.wandb.ai\/t\/overlaying-two-point-clouds\/2676",
        "Question_created_time":"2022-06-29T16:14:14.609Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":75,
        "Question_body":"<p>Is it possible to visualize two point clouds on top of each other with different colors to differentiate them? So far I\u2019ve been using the following format to visualize only one point cloud:<\/p>\n<pre><code class=\"lang-auto\">points = np.random.uniform(size=(250, 3))\nwandb.log(\n        {\n            \"point_scene\": wandb.Object3D(\n                {   \"type\": \"lidar\/beta\",\n                    \"points\": points\n                }\n            )\n        }\n    )\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Strange message when running wandb sync from commandline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/strange-message-when-running-wandb-sync-from-commandline\/2657",
        "Question_created_time":"2022-06-24T00:36:07.764Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":76,
        "Question_body":"<p>I\u2019m running wandb sync from the command line for offline runs in a cluster, and recently whenever I run it I get the message<\/p>\n<p><code>Seen metric with glob (shouldnt happen)<\/code><\/p>\n<p>being output in the console hundreds of times. It doesn\u2019t affect anything; I can still see the runs synced to my account, but I don\u2019t think this message should appear, given that it says \u201cshouldnt happen\u201d in the log line.<\/p>\n<p>My wandb library version is 0.11.2 and my python version is 3.9.6, both installed via conda. I had the same version for quite a while and I didn\u2019t run into this until a few months ago.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to compare (parameter & gradient) histograms from different runs?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-compare-parameter-gradient-histograms-from-different-runs\/2660",
        "Question_created_time":"2022-06-26T09:09:35.899Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":128,
        "Question_body":"<p>Usually when logging a metric from different runs wandb will plot the results in the same graph (for different runs).<\/p>\n<p>This is not the case for histograms, is there a way to compare the histograms from different runs other than manually switching between tabs that contain the histogram plots for different runs?<\/p>\n<p>In general I\u2019m curious what the best way to compare gradients between different runs is. Maybe just tracking the magnitude is enough and one doesn\u2019t need histograms (I presume in this case, since the logging value is just a scalar the graphs from different runs would end up in the same plot)? Curious whether other engineers may have found this to be the case.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging linear evaluation results asynchronously in SimCLR",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-linear-evaluation-results-asynchronously-in-simclr\/2646",
        "Question_created_time":"2022-06-22T17:37:05.378Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":83,
        "Question_body":"<p>Hello! I\u2019m currently investigating SimCLR, which consists of a pretraining and fine-tuning\/linear evaluation step. I can log pretraining loss and linear eval accuracy metrics in the same W&amp;B run by running eval after every pretraining epoch, but the pretraining script has to wait until eval is done before continuing with the next epoch. Is there any way to run linear eval <em>after<\/em> pretraining is done (e.g., in a separate <code>eval.py<\/code> script, and log the results to the same run_id?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d.png\" data-download-href=\"\/uploads\/short-url\/gNLp9XWDciUbXa3tmRjGtU7axqZ.png?dl=1\" title=\"wandb_fig\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_690x456.png\" alt=\"wandb_fig\" data-base62-sha1=\"gNLp9XWDciUbXa3tmRjGtU7axqZ\" width=\"690\" height=\"456\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_690x456.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb_fig<\/span><span class=\"informations\">835\u00d7553 56.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"BUG: Sweep in Jupyter makes new runs impossible to start",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-sweep-in-jupyter-makes-new-runs-impossible-to-start\/2645",
        "Question_created_time":"2022-06-22T08:32:54.292Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":80,
        "Question_body":"<p>Let\u2019s say I\u2019m working on a jupyter notebook and I run a sweep<\/p>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep_config, entity=WANDB_ENTITY, project=WANDB_PROJECT, )\nwandb_agent = wandb.agent(sweep_id, project=WANDB_PROJECT, function=pipeline)\n<\/code><\/pre>\n<p>After an hour I\u2019m happy with the sweep results and I stop execution, not here\u2019s the bug, I CANNOT start a new run manually. Here\u2019s what happens when I run the following code<\/p>\n<blockquote>\n<p>run = wandb.init()<br>\nprint(\u201c------ RUN NAME ------\u201d, run.name)<br>\nrun.finish()<\/p>\n<p>run = wandb.init()<br>\nprint(\u201c------ RUN NAME ------\u201d, run.name)<br>\nrun.finish()<\/p>\n<\/blockquote>\n<p>Output:<\/p>\n<pre><code class=\"lang-auto\">\nChanges to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to the W&amp;B docs.\nFinishing last run (ID:ln732mvm) before initializing another...\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https:\/\/wandb.ai\/arkareem\/test\/runs\/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: .\/wandb\/run-20220622_111904-ln732mvm\/logs\nSuccessfully finished last run (ID:ln732mvm). Initializing new run:\nTracking run with wandb version 0.12.18\nRun data is saved locally in \/mnt\/m\/MyFiles\/Classes\/wandb\/run-20220622_112014-ln732mvm\nSyncing run fresh-sweep-32 to Weights &amp; Biases (docs)\nSweep page: https:\/\/wandb.ai\/arkareem\/test\/sweeps\/9t3sbtv5\n------ RUN NAME ------ fresh-sweep-32\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https:\/\/wandb.ai\/arkareem\/test\/runs\/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: .\/wandb\/run-20220622_112014-ln732mvm\/logs\nChanges to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to the W&amp;B docs.\nTracking run with wandb version 0.12.18\nRun data is saved locally in \/mnt\/m\/MyFiles\/Classes\/wandb\/run-20220622_112037-ln732mvm\nSyncing run fresh-sweep-32 to Weights &amp; Biases (docs)\nSweep page: https:\/\/wandb.ai\/arkareem\/test\/sweeps\/9t3sbtv5\n------ RUN NAME ------ fresh-sweep-32\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https:\/\/wandb.ai\/arkareem\/test\/runs\/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: .\/wandb\/run-20220622_112037-ln732mvm\/logs\n\n<\/code><\/pre>\n<p>How do I start a new run without restarting the notebook and starting everything from scratch???<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error while calling W&B API iinternal database error (<Response [500]>)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-while-calling-w-b-api-iinternal-database-error-response-500\/2624",
        "Question_created_time":"2022-06-16T06:31:15.016Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":1069,
        "Question_body":"<p>I am running four experiments from the same system (a google cloud VM) and while one is running fine: three have frozen (no progress but program still active\/has not errored out). Curious if anyone knows how to fix this?<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/19876a837127852045cb70c484da66f5a3c28d52.png\" alt=\"image\" data-base62-sha1=\"3DQ3Zmd1Ly9oF4hn1gpJ6jJ9bB8\" width=\"681\" height=\"130\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Coordinate wandb local across two laptops",
        "Question_link":"https:\/\/community.wandb.ai\/t\/coordinate-wandb-local-across-two-laptops\/2620",
        "Question_created_time":"2022-06-15T21:07:48.687Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":171,
        "Question_body":"<p>Hi Wandb Community!<\/p>\n<p>I have a laptop in my office that I am able to run <code>wandb local<\/code> on and sync my ML experiments to my account email address. My company gave me another laptop to work from on the road and I would like to set up <code>wandb local<\/code> on that laptop to streamline ML experiments I do in office and on the road.<\/p>\n<p>On my laptop, I have <code>wandb<\/code> and <code>docker<\/code> installed successfully. I can also run <code>wandb local<\/code> successfully. However, I\u2019m not sure if I need to copy the same api key and license over for the single account to work on both machines. Is there a smart way to do this?<\/p>\n<p>Thanks in advance!<\/p>\n<p>wand: 0.12.18<br>\nOS: Ubuntu 22.04<br>\ndocker: 20.10.17<\/p>",
        "Question_closed_time":"2022-06-17T20:51:46.274Z",
        "Answer_body":"<p><a class=\"mention\" href=\"\/u\/aclifton314\">@aclifton314<\/a> ,<\/p>\n<p>Thank you for writing in with your question. Local is explicitly an \u201con-device\u201d service.If you want to share data across devices,  you would want to host you instance on a server to be able to reach it from anywhere, otherwise your two laptops wont share data. You can however still use the individual machine to sync data back\/forth to W&amp;B cloud,  pull experiments\/runs\/metrics\/ ect. to the individual machines. If this is your intended approach then you can copy the same API and Local License key to both machines.  <a href=\"https:\/\/docs.wandb.ai\/guides\/self-hosted\/local#login\">Here<\/a> is a quick reference on how to switch between a private instance and the wandb cloud when you need to sync the data. Please let us know if you have additional questions.<\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to deal with artifact.wait() when running in mode \"DISABLED\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-deal-with-artifact-wait-when-running-in-mode-disabled\/2607",
        "Question_created_time":"2022-06-13T15:18:04.499Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":121,
        "Question_body":"<p>During the preparation for a training (in <code>prepare_data<\/code> in pytorch lightning) I either create or update local data (download, prepare different encodings). I then create a W&amp;B artifact and wait for the upload to be complete. Later in the code (in <code>setup()<\/code> in pytorch lightning) I use the data. Strictly speaking, this is not necessary, because I have the files locally, but I want to track the usage of the data (and the IDs of the data used for training, validation, \u2026). I added the <code>wait()<\/code> statement, because wandb would download the previous version (v=n-1) of the data \/without the enoding just added). In mode <code>ONLINE<\/code> this works nicely. However, in mode <code>DISABLED<\/code> I get this error: <code>ValueError: Cannot call wait on an artifact before it has been logged or in offline mode<\/code>. How am I supposed to handle <code>wait()<\/code>in order to have it work in all modes? (it would be nice if <code>wait()<\/code> would do it).<\/p>\n<p>This is the sample code:<\/p>\n<pre><code class=\"lang-python\"># Upload the data\nartifact = wandb.Artifact(name=..., type=...)\nartifact.description = ...\nartifact.metadata = ...\nartifact.add_file(local_path=...)\nwandb.run.log_artifact(artifact)\nartifact.save()  # I think I don't need this, playing around because of this issue\nartifact.wait()\n<\/code><\/pre>\n<pre><code class=\"lang-python\"># Use (Download) the data\nartifact = wandb.run.use_artifact(artifact_or_name=... + \":latest\")\nartifact_entry = artifact.get_path(...)\nartifact_entry.download(root=...)\n<\/code><\/pre>",
        "Question_closed_time":"2022-06-17T10:48:43.780Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/hogru\">@hogru<\/a>, sorry about the late response. Runs have a <code>disabled<\/code> attribute. Here is a code snippet you can use:<\/p>\n<pre><code class=\"lang-auto\">run = wandb.init(mode=\"disabled\")\nif run.disabled:\n    \/\/ your code\n<\/code><\/pre>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Config and summary logs gone after initialising a run again",
        "Question_link":"https:\/\/community.wandb.ai\/t\/config-and-summary-logs-gone-after-initialising-a-run-again\/2556",
        "Question_created_time":"2022-06-05T03:16:54.146Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":160,
        "Question_body":"<p>After I finished a training run I wanted to upload a file, like shown here <a href=\"https:\/\/community.wandb.ai\/t\/add-files-to-run\/1066\/2\" class=\"inline-onebox\">Add files to run - #2 by _scott<\/a><br>\nThis worked fine, but after that all the config and summary logs were gone.<\/p>\n<p>Is there a way to restore them?<\/p>\n<p>If no, how can I save this file without loosing the logs?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep creation down? (Resolved)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-creation-down-resolved\/2615",
        "Question_created_time":"2022-06-15T19:28:54.078Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":156,
        "Question_body":"<p>Hello, I thought you\u2019d like to know that creating a sweep seems to be broken for me. I get a new sweep ID, but going to the URL in question gets a 404, and it doesn\u2019t appear in the sweep list either. I\u2019ve tried via CLI and browser.<\/p>\n<p>Edit: Seems to be back up!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Upload model weights to the Artifacts of a finished run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/upload-model-weights-to-the-artifacts-of-a-finished-run\/2540",
        "Question_created_time":"2022-06-03T00:26:07.487Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":235,
        "Question_body":"<p>I was training a yolov5 model, using the pre-configured wandb settings. But the weights weren\u2019t uploaded because the session was killed. I tried <code>wandb sync path\/to\/run<\/code> but the model file didn\u2019t get synced.<\/p>\n<p>I want to upload the resulting <code>best.pt<\/code> file to the artifacts regardless without messing up with the current summary and results of the finished run. I looked up in the documentation and tried multiple guides but couldn\u2019t manage to do that.<\/p>\n<p>TL;DR: I have a finished run and a weights file. I need to upload the weights file as a model artifact to that finished run using the run path.<\/p>",
        "Question_closed_time":"2022-06-07T07:41:19.840Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/alyetama\">@alyetama<\/a>, here is a code snippet you can use: <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/artifacts-faqs#how-do-i-log-an-artifact-to-an-existing-run\">https:\/\/docs.wandb.ai\/guides\/artifacts\/artifacts-faqs#how-do-i-log-an-artifact-to-an-existing-run<\/a><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to save configs?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-save-configs\/2587",
        "Question_created_time":"2022-06-09T17:16:40.865Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":97,
        "Question_body":"<p>I can\u2019t figure out how to save configurations.<\/p>\n<p>After initilization I do <code>wandb.config.update(model_config)<\/code> where <code>model_config<\/code> is a dict.<\/p>\n<p>However, it does not sync with the user interface, that\u2019s still true after calling <code>wandb.finish()<\/code>.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1.png\" data-download-href=\"\/uploads\/short-url\/q76xEv6yugWsGPOs0ho5RCULGGl.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1_2_690x271.png\" alt=\"image\" data-base62-sha1=\"q76xEv6yugWsGPOs0ho5RCULGGl\" width=\"690\" height=\"271\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1_2_690x271.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1_2_1035x406.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b7062521caebaa48838e51e3df8a358947ae83f1_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1245\u00d7490 30.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb in academic work as a PhD student with industry collaborations\/internship)?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-in-academic-work-as-a-phd-student-with-industry-collaborations-internship\/2529",
        "Question_created_time":"2022-06-01T20:09:38.109Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":170,
        "Question_body":"<p>Hi,<\/p>\n<p>I was wondering on a use case most graduate students (PhD) in machine learning often come across and thought it would be better to open it up. We often do <strong>academic research<\/strong> (not for commercial) while doing an internship at a company while still affiliated to our university institution.<\/p>\n<p>In that case is it ok to use the academic teams we usually use during the semester for our internship?<\/p>\n<p>Does that fall this use:<\/p>\n<blockquote>\n<p>And guess what? W&amp;B is free for personal and academic use. (The latter is especially important for students and academics and something we\u2019ve championed since we started the company).<\/p>\n<\/blockquote>\n<p>from this site: <a href=\"https:\/\/wandb.ai\/ivangoncharov\/wandb-teams-for-students\/reports\/How-to-Use-W-B-Teams-For-Your-University-Machine-Learning-Projects-For-Free---VmlldzoxMjk1Mjkx\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>PS: I thought I had asked this already\u2026if yes link the question if it has an answer and my apologies before hand. If not I will remove this ps later.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sagemaker blazingtext logging loss and accuracy",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sagemaker-blazingtext-logging-loss-and-accuracy\/2542",
        "Question_created_time":"2022-06-03T00:42:06.810Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":99,
        "Question_body":"<p>Hello! I have recently trained a sagemaker estimator called blazingtext  for text classification. I am struggling on how to log the accuracy and loss with wandb.log(). Would love some help with this. Thanks a ton!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add run to existing sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-run-to-existing-sweep\/2604",
        "Question_created_time":"2022-06-12T17:46:28.205Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":84,
        "Question_body":"<p>The last run of my sweep crashed, so I run the last one again, but now it\u2019s not in the sweep. Can I add this run to the sweep somehow?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is only the final logged value counted towards min or max of a metric?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-is-only-the-final-logged-value-counted-towards-min-or-max-of-a-metric\/2601",
        "Question_created_time":"2022-06-11T15:06:07.646Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":108,
        "Question_body":"<p>I wanted to find the run with the best validation accuracy, however, I noticed that to calculate the maximum only the  last logged values are used.<\/p>\n<p>You can see this on the screenshot below - it says the run with the maximum validation accuracy is run \u201821-\u2026\u2019 (the one that stopped earlier), even though run \u201818-\u2026\u2019 had a higher value one epoch after the other ones end. The problem is that one epoch later run 18 dropped in accuracy again, so it doesn\u2019t have \u2018final maximum\u2019 accuracy\u2026<\/p>\n<p>This is a bit problematic for me - I\u2019m saving my models after each epoch, so I don\u2019t really care only about the last model - precisely to prevent such a problem where the accuracy would suddenly drop at the end.<\/p>\n<p>I think this is a bit similar to this post: <a href=\"https:\/\/community.wandb.ai\/t\/can-i-plot-the-value-of-a-metric-at-a-single-step\/1971\" class=\"inline-onebox\">Can I plot the value of a metric at a single step?<\/a><\/p>\n<p>Is this a feature, or is this a bug?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff.png\" data-download-href=\"\/uploads\/short-url\/s9uTwyqB1GUIxqL7kJT4rjYgf8P.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_478x500.png\" alt=\"image\" data-base62-sha1=\"s9uTwyqB1GUIxqL7kJT4rjYgf8P\" width=\"478\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_478x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_717x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_956x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1094\u00d71144 56.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Keras tuner integration with WandB",
        "Question_link":"https:\/\/community.wandb.ai\/t\/keras-tuner-integration-with-wandb\/2538",
        "Question_created_time":"2022-06-02T17:09:15.046Z",
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":160,
        "Question_body":"<p>Hi, I\u2019m a new WandB user and I\u2019m trying to integrate WandB with my keras tuner in order to keep track of my hyper parameter tunning.<\/p>\n<p>I tried to follow an online guide I found but I\u2019m getting errors when I try to load the models with the tuner.get_best_models() function<\/p>\n<p><strong>NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for DAM_Aggr_tuning_129_cc\/DAM_Aggr_tuning_129_cc_project\/trial_2\/checkpoint<\/strong><\/p>\n<p>Here I leave a link to my colab notebook, anyone that can help it would be really appreciated, I feel stuck\u2026<\/p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/colab.research.google.com\/drive\/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/15b193ca15faf45091ba185f7b8a62df5d7d3566.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https:\/\/colab.research.google.com\/drive\/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https:\/\/colab.research.google.com\/drive\/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Bug report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-report\/2566",
        "Question_created_time":"2022-06-07T08:33:23.112Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":125,
        "Question_body":"<p>Hi<br>\nwhen trying to  export panel with multiple groups to PDF\/PNG much of the information being cut (even for maximal height and width).<br>\nwhen trying to CSV the plot it seems to be ignoring the grouping .<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Resuming run\/training",
        "Question_link":"https:\/\/community.wandb.ai\/t\/resuming-run-training\/2487",
        "Question_created_time":"2022-05-23T22:28:02.230Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":1567,
        "Question_body":"<p>Hi (Please note the codes are in italic),<br>\nI created a new run using code below:<\/p>\n<p><em>id = wandb.util.generate_id()<\/em><br>\n<em>run = wandb.init(project=\u2018checkpoint\u2019,  name=\u2018new_load\u2019,  id=id, config=configs)<\/em><\/p>\n<p>and the results (lets say for 10 epochs) were stored in my account as expected. I also saved the last model in the run using <em>wandb.save(\u2018last_model.h5\u2019)<\/em>.  Now, I want to continue learning from epoch 10 for 10 more epochs till epoch 20 for the last_model. So, I first restore the model using the code below:<\/p>\n<p><em>restored_model = wandb.restore(\u2018last_model.h5\u2019,  run_path=\"\u2026\/checkpoint\/id\")<\/em><\/p>\n<p>then, I load the weights from restored_model to the model:<\/p>\n<p><em>model = build_model()<\/em><br>\n<em>model.load_weights(restored_model.name)<\/em><\/p>\n<p>and then I compiled the model. However, when I execute <em>model.fit()<\/em>, nothing happens, that is the code is executed without any error but there is no training and no epoch just like executing an empty cell.<\/p>\n<p><em>num_epoch = config.epochs - wandb.run.step<\/em><br>\n<em>model.fit(x_train, y_train, batch_size=config.batch_size, verbose=1, epochs=num_epoch, validation_data=(x_valid, y_valid), shuffle=False,  initial_epoch=wandb.run.step, callbacks=[ WandbCallback(training_data=(x_train, y_train),  validation_data=(x_valid, y_valid))])<\/em><\/p>\n<p>I really appreciate any help as I am so in need of resuming training.<\/p>\n<p>By the way, I have been wondering why in the example below which is in the resume documentation you use model.compile() while  loading the entire model. You won\u2019t need compile the model when you load the entire model. I believe it is not correct and you need to edit the code:<br>\nimport keras<br>\nimport numpy as np<br>\nimport wandb<br>\nfrom wandb.keras import WandbCallback<\/p>\n<p>wandb.init(project=\u201cpreemptible\u201d, resume=True)<\/p>\n<p>if wandb.run.resumed:<br>\n# restore the best model<br>\n<strong>model = keras.models.load_model(wandb.restore(\u201cmodel-best.h5\u201d).name)<\/strong><br>\nelse:<br>\na = keras.layers.Input(shape=(32,))<br>\nb = keras.layers.Dense(10)(a)<br>\nmodel = keras.models.Model(input=a, output=b)<\/p>\n<p><strong>model.compile(\u201cadam\u201d, loss=\u201cmse\u201d)<\/strong><br>\nmodel.fit(np.random.rand(100, 32), np.random.rand(100, 10),<br>\n# set the resumed epoch<br>\ninitial_epoch=wandb.run.step, epochs=300,<br>\n# save the best model if it improved each epoch<br>\ncallbacks=[WandbCallback(save_model=True, monitor=\u201closs\u201d)])<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can I manually cancel a run in a sweep?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/can-i-manually-cancel-a-run-in-a-sweep\/2583",
        "Question_created_time":"2022-06-09T17:08:32.062Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":172,
        "Question_body":"<p>Can I manually stop a run in a sweep so that the sweep agent will just continue with the next run?<\/p>",
        "Question_closed_time":"2022-06-10T02:59:49.273Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/fryderykkogl\">@fryderykkogl<\/a> ,<\/p>\n<p>Yes, you can manually stop runs directly from the webUI. In the sweeps run table, select the options menu for the run you want to stop, and select  <code>stop run<\/code>. The sweep will continue to the next run configuration. See this image for reference. Please let us know if you have any followup questions.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc.png\" data-download-href=\"\/uploads\/short-url\/bC6fK8EPrbIPohDGGY4pPBG24Ec.png?dl=1\" title=\"Screen Shot 2022-06-09 at 7.57.28 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc_2_394x500.png\" alt=\"Screen Shot 2022-06-09 at 7.57.28 PM\" data-base62-sha1=\"bC6fK8EPrbIPohDGGY4pPBG24Ec\" width=\"394\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc_2_394x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc_2_591x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc_2_788x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/51667cd84dc068e0d2d43d2997688afbb76431fc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-06-09 at 7.57.28 PM<\/span><span class=\"informations\">952\u00d71206 94.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb.watch with PyTorch Lightning not logging",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-watch-with-pytorch-lightning-not-logging\/2589",
        "Question_created_time":"2022-06-09T22:56:34.134Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":316,
        "Question_body":"<p>Hi,<\/p>\n<p>I moved all of my calls to wandb  from the training loop to PyTorch Lightning (PL)'s <code>Callback<\/code> module. All of my <code>wandb.log()<\/code> calls are working properly, but the gradients and parameter tabs in my wandb dashboard are empty.  I checked two threads:<\/p>\n<ul>\n<li>Wandb.watch with pytorch not logging anything<\/li>\n<li>When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?<\/li>\n<\/ul>\n<p>For the first thread, the link to the run has expired and I don\u2019t fully understand the context of the solution \"\u2026 was using <code>forward()<\/code> instead of <code>__call__()<\/code>\".<\/p>\n<p>For the second thread, <code>wandb.log<\/code> is getting called after PL\u2019s Callback hook <a href=\"https:\/\/pytorch-lightning.readthedocs.io\/en\/latest\/extensions\/callbacks.html#on-train-batch-end\" rel=\"noopener nofollow ugc\"><code>on_train_batch_end<\/code><\/a>, so <code>wandb.log<\/code> should be getting called after a backward pass.<\/p>\n<p>Below is a portion of the code defined in the Callback Module. At the start of training (<code>on_fit_start<\/code>) I initialize the wandb run and call <code>wandb.watch<\/code>.  And after a batch is completed, (<code>on_train_batch_end<\/code>) I log all the metrics.<\/p>\n<pre><code class=\"lang-auto\">Class PatentLoggerCallback(Callback):\n \n   # Omitted non-relevant code \n\n    def on_fit_start(self, trainer, pl_module):\n        wandb.init(project=self.project,\n                   config=pl_module.hparams,\n                   dir=self.save_dir)\n\n        wandb.watch(pl_module,\n                    criterion=torch.nn.functional.binary_cross_entropy_with_logits,\n                    log='all',\n                    log_freq=10,\n                    log_graph=True)\n\n    def on_train_batch_end(\n        self,\n        trainer: Trainer,\n        pl_module: LightningModule,\n        outputs: Sequence,\n        batch: Sequence,\n        batch_idx: int,\n        dataloader_idx: int,\n    ) -&gt; None:\n\n        metrics = outputs['metrics']\n        for metric, value in metrics.items():\n            wandb.log({f'train\/{metric}': value})\n<\/code><\/pre>\n<p>I would like to have produced a google collab for reproducibility, but there is a lot of code involved. The next best thing I can offer is this <a href=\"https:\/\/github.com\/DennisMinn\/patent-phrase-matching\/blob\/nakama\/Workspace.ipynb\" rel=\"noopener nofollow ugc\">Jupyter Notebook<\/a> that runs through my entire code.  I\u2019m not expecting you to clone to repository, but if you do make sure you\u2019re on the \u201cnakama\u201d branch.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[fixed] Cannot use Sweeps - metric value [null]",
        "Question_link":"https:\/\/community.wandb.ai\/t\/fixed-cannot-use-sweeps-metric-value-null\/2576",
        "Question_created_time":"2022-06-08T17:41:48.211Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":369,
        "Question_body":"<p>Hi! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>I am using <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/boosting\/Using_W%26B_Sweeps_with_XGBoost.ipynb#scrollTo=VCRlDRL6_5aA\" rel=\"noopener nofollow ugc\">this notebook<\/a> as a tutorial to log sweeps into <a href=\"https:\/\/wandb.ai\/andrada\/AI4Code?workspace=user-andrada\">my Dashboard<\/a>.<\/p>\n<p>Everything works very well besides the Metric, which loggs with the value Null (<a href=\"https:\/\/wandb.ai\/andrada\/AI4Code\/sweeps\/6831zeoz?workspace=user-andrada\">see this run for details<\/a>)<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2.png\" data-download-href=\"\/uploads\/short-url\/8XMAnSbrBXqOrZuGJcQDg6tQrGq.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_690x249.png\" alt=\"image\" data-base62-sha1=\"8XMAnSbrBXqOrZuGJcQDg6tQrGq\" width=\"690\" height=\"249\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_690x249.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_1035x373.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_1380x498.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1471\u00d7532 98.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>My process is as follows:<\/p>\n<p><strong>Create a train function<\/strong><\/p>\n<pre><code class=\"lang-auto\">def train_XGBRanker(config_defaults):\n    \n    # \ud83d\udc1d W&amp;B Experiment\n    config_defaults.update(CONFIG)\n    run = wandb.init(project='AI4Code', name='xgbRanker', config=config_defaults)\n    config = wandb.config\n    \n    # Initiate the model\n    model = XGBRanker(tree_method = config.tree_method,\n                      booster=config.booster,\n                      objective=config.objective,\n                      random_state=config.random_state, \n                      learning_rate=config.learning_rate,\n                      colsample_bytree=config.colsample_bytree, \n                      eta=config.eta, \n                      max_depth=config.max_depth, \n                      n_estimators=config.n_estimators, \n                      subsample=config.subsample,\n                      min_child_weight=config.min_child_weight)\n\n    # Train the model\n    model.fit(X_train, y_train, group=groups, verbose=True)\n\n    # Create df containing the cell_id and the prediction\n    predict = pd.DataFrame({\"cell_id\" : df_valid[\"cell_id\"],\n                            \"pred\" : model.predict(X_valid)}, index = df_valid.index)\n\n    # Sort (using the predicted rank) and then group\n    predict = predict.sort_values(by = ['id', 'pred'], ascending = [False, True])\\\n                        .groupby('id')['cell_id'].apply(list)\n\n    # Create the same but for actual data\n    actual = df_valid.sort_values(by = ['id', 'rank'], ascending = [False, True])\\\n                            .groupby('id')['cell_id'].apply(list)\n\n    # Kendall Metric\n    metric = kendall_tau(actual, predict)\n    print(clr.S+\"Kendall Tau\"+clr.E, metric)\n    wandb.log({\"kendall_tau\": np.float(metric)})\n<\/code><\/pre>\n<p><strong>try a first baseline experiment<\/strong><\/p>\n<pre><code class=\"lang-auto\">config_defaults = {\"tree_method\":'hist',\n                   \"booster\":'gbtree',\n                   \"objective\":'rank:pairwise',\n                   \"random_state\":24, \n                   \"learning_rate\":0.1,\n                   \"colsample_bytree\":0.9, \n                   \"eta\":0.05, \n                   \"max_depth\":6, \n                   \"n_estimators\":110, \n                   \"subsample\":0.75,\n                   \"min_child_weight\":10}\n\ntrain_XGBRanker(config_defaults)\n<\/code><\/pre>\n<p>which returns a <code>kendall_tau<\/code> of 0.5479588742699661 (so the metric isn\u2019t null).<\/p>\n<p><strong>and then I am running the Sweeps as follows:<\/strong><\/p>\n<pre><code class=\"lang-auto\"># Sweep Config\nsweep_config = {\n    \"method\": \"random\", # grid for all\n    \"metric\": {\n      \"name\": \"kendall_tau\",\n      \"goal\": \"maximize\"   \n    },\n    \"parameters\": {\n        \"booster\": {\n            \"values\": [\"gbtree\",\"gblinear\"]\n        },\n        \"max_depth\": {\n            \"values\": [3, 6, 9, 12]\n        },\n        \"learning_rate\": {\n            \"values\": [0.1, 0.05, 0.2]\n        },\n        \"subsample\": {\n            \"values\": [1, 0.5, 0.3]\n        }\n    }\n}\n\n# Sweep ID\nsweep_id = wandb.sweep(sweep_config, project=\"AI4Code\")\n\n# \ud83d\udc1d RUN SWEEPS\nconfig_defaults = {\"tree_method\":'hist',\n                   \"booster\":'gbtree',\n                   \"objective\":'rank:pairwise',\n                   \"random_state\":24, \n                   \"learning_rate\":0.1,\n                   \"colsample_bytree\":0.9, \n                   \"eta\":0.05, \n                   \"max_depth\":6, \n                   \"n_estimators\":110, \n                   \"subsample\":0.75,\n                   \"min_child_weight\":10}\n\n# count = the number of trials to run\nwandb.agent(sweep_id, train_XGBRanker(config_defaults), count=8)\n<\/code><\/pre>\n<p>Could you please advise? I don\u2019t know if this is related, but I also can\u2019t run the sweeps for more than a <code>count=5<\/code> as I get the following error:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/88e725be8086de062b815ebe6c25710b0ba23b89.png\" data-download-href=\"\/uploads\/short-url\/jx6amgBaQRJiD3N6IIcvKyT4sNH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/88e725be8086de062b815ebe6c25710b0ba23b89.png\" alt=\"image\" data-base62-sha1=\"jx6amgBaQRJiD3N6IIcvKyT4sNH\" width=\"690\" height=\"487\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/88e725be8086de062b815ebe6c25710b0ba23b89_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">922\u00d7652 21.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thank you lots!<br>\nAndrada<\/p>\n<p>UPDATE:<\/p>\n<p>The issue was from the fact that I was having arguments within the <code>train_XGBRanker()<\/code> - moving <code>config_defaults<\/code> from outside the function to in the function an then passing it to <code>wandb.agent(sweep_id, train_XGBRanker, count=20)<\/code> did the job.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to early stop bad runs in sweeps to save time",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-early-stop-bad-runs-in-sweeps-to-save-time\/2563",
        "Question_created_time":"2022-06-07T06:44:10.764Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":663,
        "Question_body":"<p>Hello,<br>\nthat\u2019s my first topic in the community, so I hope I am posting that in the correct category <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>I started exploring sweeps last week for a university project, and it is incredible! As we also got a new PyTorch version with support for the new apple silicon, I wanted to try that on my M1 Pro. As this is not as powerful as, for example, using GoogleColab for a fraction of the time, I wanted to ask if it is somehow possible to stop bad runs after a few epochs.<\/p>\n<p>As you can see in the report linked below, the run hopeful-sweep-2 does not look promising. It would be nice to cancel that run and start a new one instead.<\/p>\n<p>Thanks,<br>\nMarkus<\/p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_750x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_10x10.png\">\n\n<h3><a href=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">Weights &amp; Biases<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":"2022-06-07T18:41:53.182Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/markuskarner\">@markuskarner<\/a> ,<\/p>\n<p>Thank you for writing in with your question. We do support early termination of sweeps, this reference <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/configuration#early_terminate\">doc<\/a> covers this. When the early stopping is triggered, the agent stops the current run and gets the next set of hyperparameters to try. Here is a <a href=\"https:\/\/github.com\/wandb\/examples\/blob\/master\/examples\/keras\/keras-cnn-fashion\/sweep-bayes-hyperband.yaml\" rel=\"noopener nofollow ugc\">link<\/a> to an example sweep configuration for reference. If after setting up your configuration and your require review \/ feedback. Please do write back in this thread and we can review your work more closely.<\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to visualize model graph in weights and biases",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-visualize-model-graph-in-weights-and-biases\/2547",
        "Question_created_time":"2022-06-03T12:47:19.117Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":605,
        "Question_body":"<p>Hi,<\/p>\n<p>I have been trying to find an example on how to write a model graph in weights and biases just like we can do in Tensorboard using  writer.add_graph() similar to as given <a href=\"https:\/\/www.tensorflow.org\/tensorboard\/graphs\" rel=\"noopener nofollow ugc\">here<\/a>.<br>\nI am working with Pytorch lightning.<\/p>\n<p>If someone can please refer me to a correct documentation or an example.<\/p>\n<p>Thanks in advance.<br>\nNikhil<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Summarize Complex Configuration Dictionaries",
        "Question_link":"https:\/\/community.wandb.ai\/t\/summarize-complex-configuration-dictionaries\/2481",
        "Question_created_time":"2022-05-23T07:33:54.729Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":187,
        "Question_body":"<p>Hello,<br>\nIs there a way I can access the nested dictionaries in the <code>run.config<\/code> object for custom panels, weaves and reports. Apart from sweeps, I am manipulating a variable space and logging them as an array to the config as below:<\/p>\n<pre><code class=\"lang-python\">wandb.config.update({'observation\/experiment': AN_ARRAY })\n<\/code><\/pre>\n<p>I would like to access and visualize\/summarize this variable in text or weave form. However when I call <code>run.config<\/code> in a weave, this variable doesn\u2019t show up even though I can see it in the run overview.<br>\nThank you for your support!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Visual Bug in Documentation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/visual-bug-in-documentation\/2572",
        "Question_created_time":"2022-06-08T07:12:19.920Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":180,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/fd0f258d7049524defde72d94701022480abd440.png\" data-download-href=\"\/uploads\/short-url\/A6FfBmGoIRNds6FR4YCdptOz7Fe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd0f258d7049524defde72d94701022480abd440_2_690x264.png\" alt=\"image\" data-base62-sha1=\"A6FfBmGoIRNds6FR4YCdptOz7Fe\" width=\"690\" height=\"264\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd0f258d7049524defde72d94701022480abd440_2_690x264.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd0f258d7049524defde72d94701022480abd440_2_1035x396.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd0f258d7049524defde72d94701022480abd440_2_1380x528.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd0f258d7049524defde72d94701022480abd440_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2560\u00d7981 120 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I think there is a missing ``` to finish the code block<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to compute FID score for different checkpoints",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-compute-fid-score-for-different-checkpoints\/2506",
        "Question_created_time":"2022-05-29T05:01:02.853Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":192,
        "Question_body":"<p>I have a hyper spectral image of 170 bands.  I have used auto-encoder to reconstruct the image. Now I want to plot the FID score for 100 epochs like we can do for MSE plot.<\/p>\n<p>like we do for MSE polt:<\/p>\n<p>model.compile(optimizer=\u2018adam\u2019, loss=\u2018mean_absolute_error\u2019, metrics=[\u2018accuracy\u2019])<\/p>\n<p>history = model.fit(img, img,<br>\nepochs=100, batch_size=1, verbose=1,<br>\nvalidation_split=0.33, shuffle=True)<\/p>\n<h1>\n<a name=\"list-all-data-in-history-1\" class=\"anchor\" href=\"#list-all-data-in-history-1\"><\/a>list all data in history<\/h1>\n<p>print(history.history.keys())<\/p>\n<h1>\n<a name=\"summarize-history-for-accuracy-2\" class=\"anchor\" href=\"#summarize-history-for-accuracy-2\"><\/a>summarize history for accuracy<\/h1>\n<p>plt.plot(history.history[\u2018accuracy\u2019])<br>\nplt.plot(history.history[\u2018val_accuracy\u2019])<br>\nplt.title(\u2018model accuracy\u2019)<br>\nplt.ylabel(\u2018accuracy\u2019)<br>\nplt.xlabel(\u2018epoch\u2019)<br>\nplt.legend([\u2018train\u2019, \u2018test\u2019], loc=\u2018upper left\u2019)<br>\nplt.show()<\/p>\n<p>Is there a simple way to do that? If so can anyone assist me with a demo code is possible\u2026<\/p>\n<p>Thanks in advance\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem loading code",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problem-loading-code\/2470",
        "Question_created_time":"2022-05-21T05:46:18.658Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":414,
        "Question_body":"<p>Hi, I\u2019m new to W&amp;B and already liked it a lot. But found some unexpected behavior: I want to compare two .py files when receiving the error in my Dashboard panel:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9ac14983e976292bdc26420fa959598cb2e12855.png\" data-download-href=\"\/uploads\/short-url\/m51E4n99eRFPkiAvGeuLOAGTLWB.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9ac14983e976292bdc26420fa959598cb2e12855_2_690x258.png\" alt=\"image\" data-base62-sha1=\"m51E4n99eRFPkiAvGeuLOAGTLWB\" width=\"690\" height=\"258\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9ac14983e976292bdc26420fa959598cb2e12855_2_690x258.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9ac14983e976292bdc26420fa959598cb2e12855.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9ac14983e976292bdc26420fa959598cb2e12855.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9ac14983e976292bdc26420fa959598cb2e12855_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">940\u00d7352 11.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I logout of my account?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-logout-of-my-account\/2531",
        "Question_created_time":"2022-06-01T21:44:26.279Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":321,
        "Question_body":"<p>There\u2019s a <code>wandb login<\/code> command, but I couldn\u2019t find any way to log out.  How does one logout?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to sync name on wandb web with images saved on the disk",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-sync-name-on-wandb-web-with-images-saved-on-the-disk\/2392",
        "Question_created_time":"2022-05-10T09:55:58.669Z",
        "Question_answer_count":12,
        "Question_score_count":0,
        "Question_view_count":388,
        "Question_body":"<p>I use pytotch-lightning and wandb. After using wandblogger, the image with a name like \u2018bird 1\u2019 on the web shows correct. But the image saved  on disk with a name like \u2018test_image_21_0\u2019, which is quite different from my name \u2018bird 1\u2019. This also happens in other frameworks.<br>\nWhat should I do to keep the name of images shown on the web the same as the image names saved on the disk?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hide projects on googling",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hide-projects-on-googling\/2388",
        "Question_created_time":"2022-05-10T08:11:18.096Z",
        "Question_answer_count":10,
        "Question_score_count":0,
        "Question_view_count":249,
        "Question_body":"<p>Hi, I\u2019m a user of wandb.<br>\nI\u2019m in several projects now, but others can search some of them on google despite I already locked them.<br>\nHow to prevent it to come out?<\/p>\n<p>Sincerely<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to delete files like images and tables logged in the Files section",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-delete-files-like-images-and-tables-logged-in-the-files-section\/2552",
        "Question_created_time":"2022-06-04T15:34:19.657Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":398,
        "Question_body":"<p>Hey all,<br>\nHope everyone is doing well.<br>\nI was wondering if it\u2019s possible to delete files saved in the Files section of a run. It seems that the only option available is to download them locally.<br>\nI\u2019ve already checked out the docs and other posts here in the forum, but the few things I found referred specifically to artifacts like model checkpoints, whereas I\u2019m looking for a way to remove unwanted media files like images, tables and so on.<\/p>\n<p>Thanks in advance for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"After 429 encountered (Filestream rate limit exceeded, it takes three days since I click stopping",
        "Question_link":"https:\/\/community.wandb.ai\/t\/after-429-encountered-filestream-rate-limit-exceeded-it-takes-three-days-since-i-click-stopping\/2534",
        "Question_created_time":"2022-06-02T01:42:46.004Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":530,
        "Question_body":"<p>Hello!<\/p>\n<p>The same code runs successfully and in a normal speed before, but last week, I have met the problem like: wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441980818670473 seconds), retrying request.  After that, it runs extremely slower than before. Some runs does not report this issue in the logs runs much slower too(running the same code) .<\/p>\n<p>I tried to use \u2018wandb init\u2019 , start a new project, kill the processes and only keep &lt;10 runs running\u2026 but it does not solve this problem.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090.jpeg\" data-download-href=\"\/uploads\/short-url\/9fu7XzbPdtOV1epkLvmcIVx1CcE.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090_2_150x499.jpeg\" alt=\"image\" data-base62-sha1=\"9fu7XzbPdtOV1epkLvmcIVx1CcE\" width=\"150\" height=\"499\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090_2_150x499.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090_2_225x748.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090_2_300x998.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40d3b3d032c52de4a182712ae8d41119c90f1090_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1822\u00d76042 2.05 MB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Meanwhile, some runs take&gt;3days to stop. It is stopping currently.<\/p>\n<p>Could you help me, please? Thank you very much~!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb: ERROR Error while calling W&B API: (<Response [500]>)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-error-while-calling-w-b-api-response-500\/2509",
        "Question_created_time":"2022-05-30T14:51:15.888Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":145,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019ve just started to use <strong>wandb<\/strong> and I love it.  I use v 0.12.17 and the code below to log from a json file that contains my key, because I don\u2019t want to expose it to the public (I have my script in Github)<\/p>\n<pre><code class=\"lang-auto\">wandb_path = Path('~\/.wandb\/wandb.json').expanduser()\nwith open(wandb_path) as fp:\n    mykey = json.load(fp)['key']\nwandb.login(key = mykey)\n<\/code><\/pre>\n<p>I\u2019m able to login, but after a few seconds, I get the following error message:<\/p>\n<blockquote>\n<p>wandb: ERROR Error while calling W&amp;B API: json: cannot unmarshal array into Go value of type map[string]interface {} (&lt;Response [500]&gt;)<\/p>\n<\/blockquote>\n<p>Any ideas on how to solve it?<\/p>\n<p>Thanks<\/p>\n<p>Jose<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Grouping and comparing across two dimensions",
        "Question_link":"https:\/\/community.wandb.ai\/t\/grouping-and-comparing-across-two-dimensions\/2525",
        "Question_created_time":"2022-06-01T13:53:31.752Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":95,
        "Question_body":"<p>I have two hyperparameters, lets say p1 with values {A, B,C} and p2 with values {0, 1} and a metric I want to compare. Now I want to  group my runs to visualize how p2 affects the metric for each value of p1 separately. Something like on the image below.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6fc197c9a83f96d5196805c315c0edb402521d2d.png\" alt=\"wandb_classes\" data-base62-sha1=\"fWDLKpRDMuRYnyft4eMiPsGXkbH\" width=\"371\" height=\"250\"><\/p>\n<p>When I group my runs by both p1 and p2 and do a bar plot I lose the information which pairs of bars I want to compare. Is there any way to achieve what I want on a report?<br>\nThe best I could think of is to have separate sets of runs each filtered on A, B, C and then do multiple plots with just the two bars. But I\u2019d much rather have all the information together.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweeps while using MPI and SLURM",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweeps-while-using-mpi-and-slurm\/2427",
        "Question_created_time":"2022-05-16T10:04:13.529Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":753,
        "Question_body":"<p>Hello! I am attempting to perform a hyperparameter search on my project, which uses MPI under the hood to aggregate the results of multiple agents. I have 63 agents that run an episode, returning a total reward at the end. At the end, each worker node sends their results to the main node, which logs the total reward of every 5th training run.<\/p>\n<p>I have tried to create a sweep with a custom command to use <code>mpirun<\/code>(as seen below) and running <code>wandb agent sweepid --count 1<\/code> in the SLURM script.  This results in using all the cores of the machine to start a sweep, effectively blocking my other agents from training.<\/p>\n<pre><code class=\"lang-auto\">program: src.sweep_mpi \ncommand:\n  - mpirun\n  - \"--mca\" \n  - opal_warn_on_missing_libcuda\n  - 0\n  - python\n  - \"-m\"\n  - ${program}\n  - ${args}\n<\/code><\/pre>\n<p>Next, I have tried setting up the sweeping agent inside the python code with a local controller, but this also led to issues regarding the parallelization. Currently, I need to initialize wandb using <code>settings=wandb.Settings(start_method=\"fork\")<\/code>, but I cannot find any way to specify this as a sweep parameter. Therefore, each  run crashes since it is not using the correct parallelization procedure.<\/p>\n<p>Is there anything I can do in this case? Or should I implement my own parameter search?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integration for spacy v2",
        "Question_link":"https:\/\/community.wandb.ai\/t\/integration-for-spacy-v2\/2536",
        "Question_created_time":"2022-06-02T06:35:54.004Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":126,
        "Question_body":"<p>Is the way to integrate wandb with spacy v2 documented somewhere?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I make a generated project sweep work with a jupyter notebook?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-make-a-generated-project-sweep-work-with-a-jupyter-notebook\/2472",
        "Question_created_time":"2022-05-21T20:14:55.287Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":137,
        "Question_body":"<p>I really like that in my project  the config was automatically generated. So I would like to use that for running from jupyter notebook. All the examples I have seen are that you make the config file within the jupyter notebook and then also make the sweep in the same cell as your function. Is there anyway to use the auto-generated project config for my jupyter notebook in colab.<\/p>\n<p>I tried something like this, but it did not work:<\/p>\n<p>import sweep <span class=\"hashtag\">#trying<\/span> to import sweep.yaml file<\/p>\n<p>sweep_id=wandb.sweep(sweep)<\/p>\n<p>count = 1 # number of runs to execute<\/p>\n<p>wandb.agent(sweep_id, function=train_model, count=count)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Value Error: Instances of wandb.Artifact and wandb.apis.public.Artifact can only be top level keys i",
        "Question_link":"https:\/\/community.wandb.ai\/t\/value-error-instances-of-wandb-artifact-and-wandb-apis-public-artifact-can-only-be-top-level-keys-i\/2500",
        "Question_created_time":"2022-05-27T15:35:02.174Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":150,
        "Question_body":"<p>Hello, sorry for the bad english. I\u2019m using for a personal project wandb to train Yolov5 in a kaggle environment. Im getting this type of error:<\/p>\n<p>Traceback (most recent call last):<br>\nFile \u201ctrain.py\u201d, line 643, in<br>\nmain(opt)<br>\nFile \u201ctrain.py\u201d, line 539, in main<br>\ntrain(opt.hyp, opt, device, callbacks)<br>\nFile \u201ctrain.py\u201d, line 95, in train<br>\nloggers = Loggers(save_dir, weights, opt, hyp, LOGGER) # loggers instance<br>\nFile \u201c\/content\/yolov5\/utils\/loggers\/ <strong>init<\/strong> .py\u201d, line 73, in <strong>init<\/strong><br>\nself.wandb = WandbLogger(self.opt, run_id)<br>\nFile \u201c\/content\/yolov5\/utils\/loggers\/wandb\/wandb_utils.py\u201d, line 185, in <strong>init<\/strong><br>\nallow_val_change=True)<br>\nFile \u201c\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/wandb_config.py\u201d, line 181, in update<br>\nsanitized = self._update(d, allow_val_change)<br>\nFile \u201c\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/wandb_config.py\u201d, line 175, in _update<br>\nparsed_dict, allow_val_change, ignore_keys=locked_keys<br>\nFile \u201c\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/wandb_config.py\u201d, line 227, in _sanitize_dict<br>\nself._raise_value_error_on_nested_artifact(config_dict)<br>\nFile \u201c\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/sdk\/wandb_config.py\u201d, line 266, in _raise_value_error_on_nested_artifact<br>\n\u201cInstances of wandb.Artifact and wandb.apis.public.Artifact\u201d<br>\nValueError: Instances of wandb.Artifact and wandb.apis.public.Artifact can only be top level keys in wandb.config<\/p>\n<p>Here the debug log:<\/p>\n<p><a href=\"https:\/\/github.com\/wandb\/client\/files\/8171769\/debug.log\" rel=\"noopener nofollow ugc\">debug.log<\/a><br>\n<a href=\"https:\/\/github.com\/wandb\/client\/files\/8171770\/debug-internal.log\" rel=\"noopener nofollow ugc\">debug-internal.log<\/a><\/p>\n<p>With a dowgrade to version 0.12.10 just work.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accessing logged values in a callback during run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/accessing-logged-values-in-a-callback-during-run\/2527",
        "Question_created_time":"2022-06-01T18:26:21.576Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":81,
        "Question_body":"<p>Hi-<\/p>\n<p>I\u2019m trying  to access a logged value during a run (in a callback). When I examine <code>run.summary<\/code> it does not seem to have any of the values logged by <code>self.log<\/code> in either <code>train_step()<\/code> or <code>validation_step()<\/code>. Is there a correct pattern for accessing logged values during a run.<\/p>\n<p>My use case is trying to keep track of the minimum of a metric. I already use <code>define_metric<\/code>, but I want to see the minimum as a plot over <code>step<\/code> or <code>epoch<\/code> as opposed to just in the summary. Essentially trying to call <code>torchmetrics.MinMetric<\/code> in the <code>on_validation_epoch_end()<\/code> callback - but to update that metric I need to feed it the previously logged value for another metric.<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save_format of shared layers",
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-format-of-shared-layers\/2463",
        "Question_created_time":"2022-05-20T10:22:21.698Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":167,
        "Question_body":"<p>Hi, I am running a model which uses the same embedding layer (and variables)  several places in the model. During training, I use the standard WandbCallback() with no additional parameters, however, I get this warning from TensorFlow:<\/p>\n<blockquote>\n<p>WARNING:tensorflow:Found duplicated <code>Variable<\/code>s in Model\u2019s <code>weights<\/code>. This is usually caused by <code>Variable<\/code>s being shared by Layers in the Model. These <code>Variable<\/code>s will be treated as separate <code>Variable<\/code>s when the Model is restored. To avoid this, please save with <code>save_format=\"tf\"<\/code>.<\/p>\n<\/blockquote>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"NaN loss causes incorrect X axis time scale",
        "Question_link":"https:\/\/community.wandb.ai\/t\/nan-loss-causes-incorrect-x-axis-time-scale\/2410",
        "Question_created_time":"2022-05-12T08:39:53.002Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":109,
        "Question_body":"<p>NaN values are displayed with incorrect X axis values when \u201cRelative Time\u201d is selected.<\/p>\n<p>To reproduce, go to a plot with NaN values and select \u201cRelative Time (Wall)\u201d as unit for the X axis. The NaN values are still displayed by step number and not  by relative time:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2dda6900e0c1e9986663091725820304b26465c4.png\" data-download-href=\"\/uploads\/short-url\/6xDqwsQGPqpl4IB1TEP2WAgfX9y.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2dda6900e0c1e9986663091725820304b26465c4_2_345x244.png\" alt=\"image\" data-base62-sha1=\"6xDqwsQGPqpl4IB1TEP2WAgfX9y\" width=\"345\" height=\"244\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2dda6900e0c1e9986663091725820304b26465c4_2_345x244.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2dda6900e0c1e9986663091725820304b26465c4_2_517x366.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2dda6900e0c1e9986663091725820304b26465c4_2_690x488.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2dda6900e0c1e9986663091725820304b26465c4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">888\u00d7630 14.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nThe screenshot is from a run that was only running for 160 minutes.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run.history() returns different values on almost each call",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-history-returns-different-values-on-almost-each-call\/2431",
        "Question_created_time":"2022-05-16T15:00:29.122Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":866,
        "Question_body":"<p>I recently started using the <code>wandb.Api()<\/code> in order not to manually download all the Charts in <code>.csv<\/code> format.<\/p>\n<p>The problem is that I cannot get consistent results, most of the times that I call the API  in a jupyter-notebook I get different results.<\/p>\n<p>I have made public one of my dashboards to tackle this issue. Here is a screenshot with a reproducible example:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" data-download-href=\"\/uploads\/short-url\/8x7Rm9lNkSyg4pi6edKG0wNOxgE.png?dl=1\" title=\"2022-05-16-165542_647x517_scrot\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" alt=\"2022-05-16-165542_647x517_scrot\" data-base62-sha1=\"8x7Rm9lNkSyg4pi6edKG0wNOxgE\" width=\"625\" height=\"500\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">2022-05-16-165542_647x517_scrot<\/span><span class=\"informations\">647\u00d7517 50.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>In order to obtain the <code>csv_val_f1<\/code> variable one just needs to download the <code>Val F1<\/code> chart. Two things can be seen here:<\/p>\n<ol>\n<li>Multiple runs of the same code produce different results<\/li>\n<li>The maximum value obtained by the API differs from the maximum value obtained by manually downloading the <code>.csv<\/code> version of the Chart.<\/li>\n<\/ol>\n<p>Any ideas on what I\u2019m missing?<\/p>",
        "Question_closed_time":"2022-05-27T16:47:31.375Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jaeheelee\">@jaeheelee<\/a> and <a class=\"mention\" href=\"\/u\/carloshernandezp\">@carloshernandezp<\/a>,<br>\nI believe you are seeing this because we sample the data points when you call <code>run.history()<\/code>. You can use <code>run.scan_history()<\/code> if you would like to have the entire history returned. <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#sampling\">Here<\/a> is some more information on this.<\/p>\n<p>Let me know if this solves the issue for you.<\/p>\n<p>Thank you,<br>\nNate<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Modify code during sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/modify-code-during-sweep\/2484",
        "Question_created_time":"2022-05-23T13:43:17.712Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":80,
        "Question_body":"<p>If I run a sweep, and while the sweep is running I modify code that gets called during the sweep, will it affect the sweep or does it save the state of the code when the sweep starts?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Instant crash",
        "Question_link":"https:\/\/community.wandb.ai\/t\/instant-crash\/2468",
        "Question_created_time":"2022-05-20T21:24:25.643Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":81,
        "Question_body":"<p>Hey Guys, if i wand.init my pc instantly blue screens after inpputing my Key. I have no idea how to figure out what the issue is here and if some of you have any idea please let me know.<br>\nThanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using wandb sweep with torch.distributed.launch",
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-wandb-sweep-with-torch-distributed-launch\/2483",
        "Question_created_time":"2022-05-23T12:30:50.747Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":249,
        "Question_body":"<p>Hello<\/p>\n<p>I am using wandb sweep to perform hyperparameter tuning.<\/p>\n<p>Basically when I launch wandb agent with \u201cwandb agent &lt;USERNAME\/PROJECTNAME\/SWEEPID&gt;\u201d,<\/p>\n<p>It will automatically run  \u201c\/usr\/bin\/env python train.py --param1=value1 --param2=value2\u201d according to the configurations.<\/p>\n<p>However my code is based on torch distributed data parallel and it has to be launched with torch.distributed.launch   train.py  rather than just  python train.py.<\/p>\n<p>How can I tackle this problem?<\/p>\n<p>Many thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Show baseline score in plots",
        "Question_link":"https:\/\/community.wandb.ai\/t\/show-baseline-score-in-plots\/2492",
        "Question_created_time":"2022-05-25T10:55:26.544Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":192,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m training N models and I\u2019m plotting on wandb their evaluation score. This results in having a run group where each panel has N plots, like in the figure below.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6bfd099e64d3d1327f97778eb9b5fd37605c3674.png\" alt=\"Screenshot from 2022-05-25 12-49-24\" data-base62-sha1=\"fpjdD3BHyP6hIa3uCWJUY9ZbVKk\" width=\"441\" height=\"210\"><\/p>\n<p>I want to also show a horizontal line that represents the baseline score that my model needs to beat. At the moment I\u2019m doing that manually by adding an expression like <code>baseline_value + 0 * ${evaluation}<\/code>. However, this is ugly since N lines will be created with the same name as the model runs.<\/p>\n<p>Is there a way to automate this, and only produce one line with a different name (e.g. <code>'baseline'<\/code>)?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom Radar Plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-radar-plot\/2455",
        "Question_created_time":"2022-05-20T02:52:37.992Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":87,
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019ve been trying to set up a radar plot using the custom charts feature, but I\u2019m stuck!<\/p>\n<p>Ideally, I want to be able to display seven different summary metrics on the radar plot, and overlay multiple runs.<br>\nI\u2019ve found an example vega chart that would work perfectly (<a href=\"https:\/\/vega.github.io\/vega\/examples\/radar-chart\/\" rel=\"noopener nofollow ugc\">https:\/\/vega.github.io\/vega\/examples\/radar-chart\/<\/a>), however I cannot figure out how to integrate the summary metrics into it.<\/p>\n<p>I\u2019m sure this is just coming from a lack of experience, so any help would be much appreciated!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"No config file and system plots for offline runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/no-config-file-and-system-plots-for-offline-runs\/2337",
        "Question_created_time":"2022-04-28T08:48:39.417Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":745,
        "Question_body":"<p>When uploading offline runs, there is no config shown in the dashboard.<br>\nAdditionally, there are also no system plots.<\/p>\n<p>Is there any way to fix this issue?<\/p>\n<p>Thank you very much for your help!<br>\nCedric<\/p>",
        "Question_closed_time":"2022-05-23T05:29:29.317Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/nathank\">@nathank<\/a>,<\/p>\n<p>sorry for my late reply and  thank you very much for your help. <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nWe\u2019gve managed to get the config displayed in the dashboard.<\/p>\n<p>Unfortunately, we specified the wrong path for the upload, i.e., the experiment folder.<br>\nThe config is uploaded and displayed correctly when we specify offline run folder.<\/p>\n<p>Example<br>\nold : wandb sync \u2026\/experiment_name<br>\nnew : wandb sync \u2026\/experiment_name\/wandb\/offline-run-20220515_002356-jdlxek9r<\/p>\n<p>Apparently, now, we get a new error:<\/p>\n<p>.wandb: ERROR Metric data exceeds maximum size of 10.4MB (12.4MB)<br>\nwandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.<br>\ndone.<\/p>\n<p>However, the configuration is displayed correctly on the website.<br>\nThanks again for your help and if we can\u2019t get the new error under control, we\u2019ll  ask in a new issue.<\/p>\n<p>Bests,<br>\nCedric and Jannis<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"404 response executing GraphQL",
        "Question_link":"https:\/\/community.wandb.ai\/t\/404-response-executing-graphql\/2418",
        "Question_created_time":"2022-05-13T23:17:09.957Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":1017,
        "Question_body":"<p>When I execute wandb.login() in pycharm or jupyter notebook, I got the error below:<br>\n404 response executing GraphQL<br>\n404 page not found<\/p>\n<p>and then True is printed. However, when I run wandb.restored(\u2026), I get the error below:<br>\nCommError: Permission denied, ask the project owner to grant you access<\/p>\n<p>It works well in colab. What is the issue?<br>\nI am using Win11 with the latest version of wandb<\/p>\n<p>I should add that I could log in to my wandb account without issue, but recently I get the errors mentioned.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Log multiple variables at the same plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/log-multiple-variables-at-the-same-plot\/2474",
        "Question_created_time":"2022-05-22T02:05:44.304Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":135,
        "Question_body":"<p>Hello there, I would like to log two different variables to show up on the same chart. I use the following:<\/p>\n<pre><code class=\"lang-auto\">for I in range(100):\n    var1 = something\n    var2 = something_else\n\n    wandb.log({\"var1\":something, \"var2\":something_else})\n<\/code><\/pre>\n<p>but for some reason, the dashboard shows it as two separate plots. I went through the documentation I see this:<br>\nMultiple metrics on one chart: Log multiple metrics in the same call to wandb.log, like this:<\/p>\n<p><code>wandb.log({\"acc'\": 0.9, \"loss\": 0.1})<\/code><\/p>\n<p>and they will both be available to plot against in the UI.<\/p>\n<p>Can anyone help me on this? I tried many hacks like insertring a list in the place of the variable, or a dict of dicts, etc\u2026<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Question on using ax.vspan when plotting",
        "Question_link":"https:\/\/community.wandb.ai\/t\/question-on-using-ax-vspan-when-plotting\/2355",
        "Question_created_time":"2022-05-02T12:58:56.203Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":118,
        "Question_body":"<p>Hi!<\/p>\n<p>Does wandb plotting support the use of matplotlib\u2019s <a href=\"https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.axes.Axes.axvspan.html?highlight=axvspan#matplotlib.axes.Axes.axvspan\" rel=\"noopener nofollow ugc\">axvspan<\/a>? I\u2019m trying to shade an area and it works locally, but it doesn\u2019t pop up in my plot in wandb.<\/p>\n<pre><code class=\"lang-auto\">    fig, ax = plt.subplots()\n    ax.plot(x_train, y_train, 'ro', label='data')\n\n    if len(x_test) &gt; 0:\n        ax.plot(x_test, y_test, 'bo', label='unseen data')\n        ax.axvspan(np.min(x_test), np.max(x_test), alpha=0.3, color='blue')\n    wandb.log({\"plot\": plt})\n<\/code><\/pre>\n<p>Thanks,<br>\nAndrei<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Workspace configuration gone",
        "Question_link":"https:\/\/community.wandb.ai\/t\/workspace-configuration-gone\/2130",
        "Question_created_time":"2022-03-22T09:08:02.726Z",
        "Question_answer_count":12,
        "Question_score_count":0,
        "Question_view_count":267,
        "Question_body":"<p>I spent many hours designing the workspace I wanted (columns, graphs, \u2026). Worked nicely (beside a bug that I reported before). Now I run the first experiment on a more powerful machine and\u2026 ALL configuration is gone, I am presented with the initial\/standard graphs. Please tell me that there is a way to get my designs back. This way I can\u2019t use it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save_code in Google Colab",
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-code-in-google-colab\/2439",
        "Question_created_time":"2022-05-18T08:08:04.020Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":109,
        "Question_body":"<p>I tried saving code using <code>save_code=True<\/code> in wandb.init() running on Google Colab, but can\u2019t see any code files in the run dashboard (there is no code section).<br>\nTaking a look in the debug log, I see \"\u2026Unable to probe notebook: \u2018NoneType\u2019 object has no attribute \u2018get\u2019 \" - can I assume save_code doesn\u2019t work on Google colab?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is prediction speed of YOLOv5 recorded somewhere as part of the integration?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-prediction-speed-of-yolov5-recorded-somewhere-as-part-of-the-integration\/2419",
        "Question_created_time":"2022-05-14T01:03:03.869Z",
        "Question_answer_count":8,
        "Question_score_count":2,
        "Question_view_count":116,
        "Question_body":"<p>Hello!<br>\nI\u2019ve been training YOLOv5 models using wandb, and I\u2019ve been amazed at how much is natively built in with just a few command-line arguments. One thing I\u2019m lacking - is there any recording of the speed at which it makes predictions? I don\u2019t particularly care if it\u2019s on the training or test sets, I\u2019m just looking for any record of the speed at which the model makes predictions.<\/p>\n<p>Thanks!<br>\nIan<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Acoount Deletion",
        "Question_link":"https:\/\/community.wandb.ai\/t\/acoount-deletion\/2456",
        "Question_created_time":"2022-05-20T02:54:48.831Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":71,
        "Question_body":"<p>I no more use W&amp;B. Could you delete my account please?<br>\nmy username is code4bw<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Want to log Inference Progress",
        "Question_link":"https:\/\/community.wandb.ai\/t\/want-to-log-inference-progress\/2459",
        "Question_created_time":"2022-05-20T06:28:20.295Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":226,
        "Question_body":"<p>Hi Wandb,<br>\nI am running an Inference script on a huge corpus for a wav2vec ASR model. I want to log the progress on wandb (% of files completed) either as a progress bar or a changing label so that I can peacefully close the sagemaker notebook window and make sure the notebook still runs fine. How can I log the percentage completion (maybe like tqdm)?<br>\nAny help is appreciated, thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Permission Error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/permission-error\/2444",
        "Question_created_time":"2022-05-18T23:15:19.749Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":180,
        "Question_body":"<p>Hi all,<br>\nI am totally new to wandb and when running my code I get the following error:<br>\nTraceback (most recent call last):<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 996, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 237, in setup<br>\nwandb_login._login(<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 297, in _login<br>\nwlogin.prompt_api_key()<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 220, in prompt_api_key<br>\nkey, status = self._prompt_api_key()<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 197, in _prompt_api_key<br>\napi = Api(self._settings)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\u201d, line 74, in <strong>init<\/strong><br>\nself._settings = Settings(<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/old\/settings.py\u201d, line 23, in <strong>init<\/strong><br>\nself._global_settings.read([Settings._global_path()])<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/old\/settings.py\u201d, line 110, in _global_path<br>\nutil.mkdir_exists_ok(config_dir)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/util.py\u201d, line 854, in mkdir_exists_ok<br>\nos.makedirs(path)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 223, in makedirs<br>\nmkdir(name, mode)<br>\nPermissionError: [Errno 13] Permission denied: \u2018\/home\/mahzad-khosh\u2019<br>\nwandb: ERROR Abnormal program exitTraceback (most recent call last):<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 996, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\u201d, line 237, in setup<br>\nwandb_login._login(<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 297, in _login<br>\nwlogin.prompt_api_key()<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 220, in prompt_api_key<br>\nkey, status = self._prompt_api_key()<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_login.py\u201d, line 197, in _prompt_api_key<br>\napi = Api(self._settings)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\u201d, line 74, in <strong>init<\/strong><br>\nself._settings = Settings(<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/old\/settings.py\u201d, line 23, in <strong>init<\/strong><br>\nself._global_settings.read([Settings._global_path()])<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/old\/settings.py\u201d, line 110, in _global_path<br>\nutil.mkdir_exists_ok(config_dir)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/site-packages\/wandb\/util.py\u201d, line 854, in mkdir_exists_ok<br>\nos.makedirs(path)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c\/z\/home\/mahzad-khosh\/env\/romp2\/lib\/python3.8\/os.py\u201d, line 223, in makedirs<br>\nmkdir(name, mode)<br>\nPermissionError: [Errno 13] Permission denied: \u2018\/home\/mahzad-khosh\u2019<br>\nwandb: ERROR Abnormal program exit<\/p>\n<p>When initializing wandb I set the dir to path = \u201c\/z\/home\/mahzad-khosh\/Human_object_transform\/wandb\u201d which I am sure has permission to write.<br>\nAlso I do<br>\nexport WANDB_DIR=\/z\/home\/mahzad-khosh\/Human_object_transform\/wandb<br>\nin my submit script.<br>\nAny tip on how I can avoid this error?<\/p>\n<p>Thanks,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb integration using class and sweep running twice under the same name",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-integration-using-class-and-sweep-running-twice-under-the-same-name\/2433",
        "Question_created_time":"2022-05-16T16:44:47.380Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":320,
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019m implementing W&amp;B into an existing project in which Agent, Model creation and Environment are constructed in classes. The code structure in the Python file (<code>AIAgent.py<\/code>) looks like this:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\nconfig = {\n    'layer_sizes': [17, 16, 12, 4],\n    'batch_minsize': 32,\n    'max_memory': 100_000,\n    'episodes': 2,\n    'epsilon': 1.0,\n    'epsilon_decay': 0.998,\n    'epsilon_min': 0.01,\n    'gamma': 0.9,\n    'learning_rate': 0.001,\n    'weight_decay': 0,\n    'optimizer': 'sgd',\n    'activation': 'relu',\n    'loss_function': 'mse'\n}\n\nclass AIAgent:\n    def __init__(self):\n        self.config = config\n        self.pipeline(self.config)\n\n\n    def pipeline(self, config):\n        wandb.init()\n        config = wandb.config\n\n        model, criterion, optimizer = self.make(config)\n        self.train(model, criterion, optimizer, config) \n\n\n    def make(self, config):\n        model = LinearQNet(config).to(device)\n\n        if config['loss_function'] == 'mse':\n            criterion = nn.MSELoss()\n\n        if config['optimizer'] == 'adam':\n            optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], betas=(0.9, 0.999), eps=1e-08, weight_decay=config['weight_decay'], amsgrad=False)\n \n        wandb.watch(model, criterion, log='all', log_freq=1)\n        summary(model)\n\n        return model, criterion, optimizer\n\n\n    def train(self, model, criterion, optimizer, config):\n        for episode in range(1, config['episodes'] + 1):\n            while True:\n                # Where the training is performed\n\n                if done:\n                    if (episode % 1) == 0:\n                        wandb.log({'episode': episode, 'epsilon': epsilon, 'score': score, 'loss': loss_mean, 'reward': reward_mean, 'score_mean': score_mean, 'images': [wandb.Image(img) for img in env_images]}, step=episode})\n                    break\n\n            if episode &lt; config['episodes']:\n                game.game_reset()\n            else:\n                wandb.finish()\n                break\n\n\nclass LinearQNet(nn.Module):\n    def __init__(self, config):\n        super(LinearQNet, self).__init__()\n        self.config = config\n        # Where the NN is configured\n\n\nif __name__ == '__main__':\n    AIAgent.__init__(AIAgent())\n<\/code><\/pre>\n<p>I\u2019m currently initializing the sweep configuration via a .yaml file calling  <code>wandb sweep sweep.yaml<\/code>. The sweep.yaml file looks like this:<\/p>\n<pre><code class=\"lang-auto\">program: AIAgent.py\nproject: evaluation-sweep-1\nmethod: random\nmetric:\n  name: score_mean\n  goal: maximize\ncommand:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nparameters:\n  layer_sizes:\n    distribution: constant\n    value: [17, 16, 512, 4]\n  batch_minsize:\n    distribution: int_uniform\n    max: 1024\n    min: 32\n  max_memory:\n    distribution: constant\n    value: 100_000\n  episodes:\n    distribution: constant\n    value: 50\n  epsilon:\n    distribution: constant\n    value: 1.0\n  epsilon_decay:\n    distribution: constant\n    value: 0.995\n  epsilon_min:\n    distribution: constant\n    value: 0.01\n  gamma:\n    distribution: uniform\n    max: 0.99\n    min: 0.8\n  learning_rate:\n    distribution: uniform\n    max: 0.1\n    min: 0.0001  \n  weight_decay:\n    distribution: constant\n    value: 0\n  optimizer:\n    distribution: categorical\n    values: ['sgd', 'adam', 'adamw']\n  activation:\n    distribution: categorical\n    values: ['relu', 'sigmoid', 'tanh', 'leakyrelu']\n  loss_function:\n    distribution: constant\n    value: 'mse'\nearly_terminate:\n  type: hyperband\n  min_iter: 5\n<\/code><\/pre>\n<p>Besides general feedback on the implementation I\u2019m a bit dumbfounded with a current bug. The sweeps run fine and show up in the W&amp;B interface but every sweep is performed twice under the same name of which only the loffing of the first is displayed and the second runs \u2018silently\u2019 in the environment without update of wandb.log. Does anybody have an idea what the reason for this might be?<\/p>\n<p>Thanks,<br>\nTobias<\/p>",
        "Question_closed_time":"2022-05-18T14:52:27.134Z",
        "Answer_body":"<p>Hi Tobias,<\/p>\n<p>Looks like the source of this bug is this line: <code>AIAgent.__init__(AIAgent())<\/code> which is calling 2 constructors: 1 from <code>AIAgent.__init__()<\/code> and 1 from <code>AIAgent()<\/code>. This, in turn calls <code>pipeline<\/code> twice, which ends up meaning 2 calls to <code>wandb.init()<\/code> and therefore you see 2 runs.<\/p>\n<p>I would suggest changing that line to just <code>AIAgent<\/code> to prevent this error.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Copy instead of moving runs to team",
        "Question_link":"https:\/\/community.wandb.ai\/t\/copy-instead-of-moving-runs-to-team\/2442",
        "Question_created_time":"2022-05-18T16:20:34.786Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":85,
        "Question_body":"<p>Hello,<\/p>\n<p>I know how to move runs to a team, but my problem is that the runs are then removed from my profile.<\/p>\n<p>Is there a way to copy the runs, keeping them in my profile and in the team ?<\/p>\n<p>A better solution would be to link them to a team project and if we add things to the run in the user project the changes should  also be  reported in the team project. Basically, both projects would point to the same unique run and if a user deletes a run in his project the run would still be present in team\u2019s project (only the link would be removed). If a run as no links attached to it, it should be erased.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Remove multiple runs at the same time",
        "Question_link":"https:\/\/community.wandb.ai\/t\/remove-multiple-runs-at-the-same-time\/2435",
        "Question_created_time":"2022-05-17T08:39:36.526Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":249,
        "Question_body":"<p>Hello,<\/p>\n<p>I think it would be beneficial to select and delete several experiments at the same time.<br>\nNow I have to delete one by one and it is very time consuming.<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":"2022-05-18T11:54:10.582Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/lucasventura\">@lucasventura<\/a>, you can do it like <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/runs-table#filter-and-delete-unwanted-runs\">this<\/a>.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Comparing different artifact versions visually",
        "Question_link":"https:\/\/community.wandb.ai\/t\/comparing-different-artifact-versions-visually\/2394",
        "Question_created_time":"2022-05-10T11:56:16.601Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":406,
        "Question_body":"<p>I am running an image generative model and logging the generated images at each step as a new version of the same artifact. I would like to compare the generated images over time. I was able to compare two versions of the same artifact using \u201ccompare\u201d in the artifact view (and doing an inner join between the tables containing the images). However I was not able to compare more than two versions. I have tried using weave in a reportbut it seems to be very buggy.<br>\nAny ideas how I can compare multiple versions of an artifact (to view the improvement in image generation over time).<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Run best model off sweep?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/run-best-model-off-sweep\/2423",
        "Question_created_time":"2022-05-16T03:38:22.869Z",
        "Question_answer_count":6,
        "Question_score_count":2,
        "Question_view_count":593,
        "Question_body":"<p>Hi,<br>\nI am using Sweeps to run through different configuration models and I was told by the wandb chat support that to run the best model configuration off sweeps is to create a new sweep with the best performing parameter set and running off it.<\/p>\n<p>But this is lot of tedious work, is there any other elegant way of quering wandb project for the best model configuration and running off it?<\/p>\n<p>tldr: I run a sweep with different configuration, would like to run predictions off a specific set of parameters (or best performing set of parameters). How  to do it with the sweep API?<\/p>",
        "Question_closed_time":"2022-05-16T10:11:09.278Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/cyrilw\">@cyrilw<\/a><\/p>\n<p>Thanks for persisting with this and posting it here, here is how you do it with the Api.<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\napi = wandb.Api()\nsweep = api.sweep(f\"_scott\/project-name\/sweeps\/qwbwbwbz\")\n\n# Get best run parameters\nbest_run = sweep.best_run(order='validation\/accuracy')\nbest_parameters = best_run.config\nprint(best_parameters)\n<\/code><\/pre>\n<p>Hope this helps <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/magic_wand.png?v=12\" title=\":magic_wand:\" class=\"emoji\" alt=\":magic_wand:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Additional System Metrics From e.g., `dstat`",
        "Question_link":"https:\/\/community.wandb.ai\/t\/additional-system-metrics-from-e-g-dstat\/2333",
        "Question_created_time":"2022-04-27T17:16:16.562Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":173,
        "Question_body":"<p>Hi W&amp;B Community,<\/p>\n<p>Is there a possibility to get additional live system metrics like the network read\/write rates, disk read\/write rates, virtual memory major\/minor page faults, filesystem inodes, and system context switches?<\/p>\n<p>Basically, most of the metrics that dstat provides with the following flags:<\/p>\n<ul>\n<li>\u2013disk<\/li>\n<li>\u2013mem (memory)<\/li>\n<li>\u2013net (network)<\/li>\n<li>\u2013sys (system)<\/li>\n<li>\u2013fs (filesystem)<\/li>\n<li>\u2013vm (virtual memory)<\/li>\n<\/ul>\n<p>I\u2019m deep into pipeline profiling and found that having these helps a lot when looking for performance tuning opportunities. Also, allowing to add to the system metric log might be helpful generally to have everything related to actual ML in one log, and everything related to system metrics in another.<\/p>\n<p>I saw that the <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/system-metrics\">current documentation<\/a> suggests that you use this script - github(.)com\/nicolargo\/nvidia-ml-py3\/blob\/master\/pynvml.py - to get the GPU metrics, however, I did not find the system metrics there.<\/p>\n<p>The first workaround for me would be to run  <code>dstat<\/code> in parallel to the process, save the profiling log,<br>\ndownload your system metrics and join over the <code>_timestamp<\/code>. This, however, would negate your wonderful automatic visualization.<\/p>\n<p>The other solution would be to use some system monitoring library and add manually via <code>wandb.log({'my_metric': x})<\/code> to the \u201cML\u201d-log. This would show the metric in your visualization but not at the correct place and would not be easily compared to the other system metrics. I do not know how well this would work in practice as there would need to be additions to this log ideally every (few) seconds. This would be an asynchronous running thread that is not inside of the training loop. <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/logging-faqs#what-if-i-want-to-log-some-metrics-on-batches-and-some-metrics-only-on-epochs\">The solution proposed here<\/a>  seems like it could work if I use \u201ctimestamps\u201d as the X-axis? This still does not seem like a clean solution.<\/p>\n<p>What are your thoughts on this proposed feature? I\u2019m very much a novice regarding your service so I might not know the in\u2019s and out\u2019s, maybe I have overlooked some trivial solution.<\/p>",
        "Question_closed_time":"2022-05-03T23:23:48.352Z",
        "Answer_body":"<p>Hi Alex,<\/p>\n<p>Thank you for that very detailed and insightful response regarding your request! I definitely see why this could be useful for optimizing features now, I had never considered how the rate of context switches could have a performance impact on the performance of an ML pipeline.<\/p>\n<p>I\u2019ll definitely go ahead and make a feature request for this, and I\u2019ll keep you updated on the status of this request.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Custom settings for wandb.Object3D",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-settings-for-wandb-object3d\/2351",
        "Question_created_time":"2022-05-02T02:39:24.070Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":252,
        "Question_body":"<p>I wonder if <a class=\"mention-group notify\" href=\"\/groups\/team\">@team<\/a> can add some custom seetings for wandb.Object3D.<br>\nAf first I tried to use Plotly to achieve custom 3D point cloud visualization, but I saw team says Plotly is not supported now in github issue.<br>\nFor example, point size, backgorund color, etc.<br>\nIt would be really nice for 3D task.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[Solved] How to create model comparison table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/solved-how-to-create-model-comparison-table\/2416",
        "Question_created_time":"2022-05-13T14:04:44.607Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":316,
        "Question_body":"<p>Hi all! In the YOLOv5 tutorial there is an excellent table comparing the model runs side by side. I\u2019m not sure how to create it - can anyone give any advice? The tutorial is located here:  <a href=\"https:\/\/wandb.ai\/glenn-jocher\/yolov5_tutorial\/reports\/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>\n<p>and the table I\u2019m looking to recreate is this:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda.jpeg\" data-download-href=\"\/uploads\/short-url\/1EdKVW3ukTzAAcyxW6wBQuGijvY.jpeg?dl=1\" title=\"demo-model-comparison\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_690x365.jpeg\" alt=\"demo-model-comparison\" data-base62-sha1=\"1EdKVW3ukTzAAcyxW6wBQuGijvY\" width=\"690\" height=\"365\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_690x365.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_1035x547.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_1380x730.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">demo-model-comparison<\/span><span class=\"informations\">3062\u00d71624 365 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thanks for the help!!<\/p>\n<p>EDIT: Figured it out by searching for the term \u201cdiff only\u201d that appears in the top left. If anyone is wondering, you create a new panel and select \u201cRun Comparer\u201d. Leaving this up in case anyone has the same question <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to draw many images with a bar",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-draw-many-images-with-a-bar\/2391",
        "Question_created_time":"2022-05-10T09:42:20.664Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":186,
        "Question_body":"<p>I can only draw image with [wandb.Image(Numpy.array()),] like this<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b48aa9bfc94603e638f56ff8452ed88b900f00db.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\" title=\"11:54AM - 20 November 2020\">AIcrowd Forum \u2013 20 Nov 20<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:600\/325;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/e05a631c976b165047261523c356b3fa7e5eab41.gif\" class=\"thumbnail animated\" width=\"600\" height=\"325\"><\/div>\n\n<h3><a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\">MaskRCNN integrated with WandB and DIRECT SUBMIT FROM COLAB!<\/a><\/h3>\n\n  <p>Hi everyone!    @rohitmidha23 and me have been following this challenge for quite a while. We have written a starter notebook using MaskRCNN. We further integrate MaskRCNN with WandB which really helps to keep track of the various experiments that...<\/p>\n\n  <p>\n    <span class=\"label1\">Reading time: 1 mins \ud83d\udd51<\/span>\n      <span class=\"label2\">Likes: 17 \u2764<\/span>\n  <\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<p>\nBut how can I draw many images with a bar like this<br>\n<a href=\"https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/wandb_image.webp\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/wandb_image.webp<\/a><\/p>",
        "Question_closed_time":"2022-05-13T09:03:54.120Z",
        "Answer_body":"<p>Oh\uff0cyes! I got it ,the step slider.<br>\nIt\u2019s on the left top of my panel. Thanks!<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7477d027660f227b355c1b7090095a0ca0e72264.png\" alt=\"FireShot Capture 043 - warm-sea-50 - deepfillv2_512x512_dv5_0pv8_1 \u2013 Weights &amp; Biases_ - 192.168.23.40\" data-base62-sha1=\"gCk5gzKgcCCqUAxrDVgTMn9CtF2\" width=\"274\" height=\"249\"><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Mean of two different groups on the same plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/mean-of-two-different-groups-on-the-same-plot\/2407",
        "Question_created_time":"2022-05-11T21:16:21.483Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":94,
        "Question_body":"<p>Hi,<\/p>\n<p>I have multiple replicates of two algorithms running. I\u2019d like to group by the algorithm and then plot the resulting mean accuracy over time. This should lead to two lines for the two different groups. What\u2019s the best way to do this? I played around with the group variables without too much success.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log absolutely everything on the console?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-absolutely-everything-on-the-console\/1896",
        "Question_created_time":"2022-02-10T21:02:27.078Z",
        "Question_answer_count":4,
        "Question_score_count":3,
        "Question_view_count":330,
        "Question_body":"<p>I\u2019ve had a few jobs die without any information on my wandb log of what happened. I wonder if there is some logging level that is implicitly set that doesn\u2019t allow me to see why it ended at X epochs randomly rather than the end.<\/p>\n<p>Is there a way to set it to print everything?<\/p>\n<ul>\n<li>perhaps there is a way to debug this with the extra system stuff wandb already logs?<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Weird login error with wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/weird-login-error-with-wandb\/2379",
        "Question_created_time":"2022-05-07T17:17:43.759Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":184,
        "Question_body":"<p>Error<\/p>\n<pre><code class=\"lang-auto\">---- Running your python main ----\nwandb=&lt;module 'wandb' from '\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/__init__.py'&gt;\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nwandb: Network error (ReadTimeout), entering retry loop.\nwandb: Network error (ReadTimeout), entering retry loop.\nProblem at: \/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/common.py 25 setup_wand\nwandb: ERROR Error communicating with wandb process\nwandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))\nwandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))\nwandb: ERROR For more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 323, in &lt;module&gt;\n    main()\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 254, in main\n    args: Namespace = load_args()\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 247, in load_args\n    setup_wand(args)\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/common.py\", line 25, in setup_wand\n    wandb.init(project=args.wandb_project,\n  File \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 653, in init\n    raise UsageError(error_message)\nwandb.errors.UsageError: Error communicating with wandb process\ntry: wandb.init(settings=wandb.Settings(start_method='fork'))\nor:  wandb.init(settings=wandb.Settings(start_method='thread'))\nFor more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\n<\/code><\/pre>\n<p>Why is this happening and what is the solution?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Recreating wandb plots with matplotlib\/seaborn",
        "Question_link":"https:\/\/community.wandb.ai\/t\/recreating-wandb-plots-with-matplotlib-seaborn\/2303",
        "Question_created_time":"2022-04-22T11:08:05.152Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":906,
        "Question_body":"<p>I have been using w&amp;b for a few months and have had a great experience with it. However, I have had some trouble with including the diagram in my report. Under *more actions &gt; export panel \u2026 * there exist options for exporting the panel to PNG, SVG, PDF, and CSV. I want to export the panel to PDF with vectorized graphics and text but the PDF export seems to simply render the panel to PNG.<\/p>\n<p>What I have tried:<\/p>\n<ul>\n<li>exporting to SVG, but I was not able to convert this format to pdf or any other format suitable for my LaTeX report. I have been unable to use SVG files in my LaTeX report directly.<\/li>\n<li>creating a report of the panel and downloading the report as LaTeX, but again it renders the plots as PNG which is not desired in my case.<\/li>\n<\/ul>\n<p>Perhaps I am missing something, but as a final resort I have tried recreating the plots in wandb with the Export API in the following code snippet:<\/p>\n<pre><code class=\"lang-python\">import wandb\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\napi = wandb.Api()\n\n# Project is specified by &lt;entity\/project-name&gt;\nruns = api.runs(\"&lt;wandb-id&gt;\/&lt;entity-project-name&gt;\")\nhist_list = [] \nfor run in runs: \n    if not 'val\/loss' in run.summary:\n        continue\n\n    name = run.config['model']['_target_'].split('.')[-1]\n    hist = run.history(keys=['epoch', 'val\/loss'])\n    hist['name'] = name\n    hist_list.append(hist)\n\ndf = pd.concat(hist_list, ignore_index=True)\ndf = df.query(\"`val\/loss` != 'NaN'\")\n\nsns.lineplot(x=\"epoch\", y=\"val\/loss\", hue=\"name\", data=df)\nplt.show()\n<\/code><\/pre>\n<p>The script takes a long time to run (10 seconds) and comparing the output with the panel in the w&amp;b dashboard we have the following two plots<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a.png\" data-download-href=\"\/uploads\/short-url\/lxcb3jp5qj9Tu3wiJDqNxbIHY1Q.png?dl=1\" title=\"my fig\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_690x343.png\" alt=\"my fig\" data-base62-sha1=\"lxcb3jp5qj9Tu3wiJDqNxbIHY1Q\" width=\"690\" height=\"343\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_690x343.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">my fig<\/span><span class=\"informations\">964\u00d7480 40.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa.png\" data-download-href=\"\/uploads\/short-url\/bxWxmqbCJuvxst6H9WgGcA170lY.png?dl=1\" title=\"wandb fig\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_690x263.png\" alt=\"wandb fig\" data-base62-sha1=\"bxWxmqbCJuvxst6H9WgGcA170lY\" width=\"690\" height=\"263\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_690x263.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_1035x394.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_1380x526.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb fig<\/span><span class=\"informations\">1516\u00d7580 69 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The two plots have a noticeable difference. So I have two questions:<\/p>\n<ul>\n<li>Is it possible to export a panel to pdf with selectable text?<\/li>\n<li>If not, is there any reference for recreating the plots in wandb?<\/li>\n<\/ul>\n<p>Any help is appreciated <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p><strong>EDIT<\/strong><\/p>\n<p>I found a github thread that explains my problem a bit better: <a href=\"https:\/\/github.com\/wandb\/client\/issues\/1446#issuecomment-1029293004\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Custom Charts: Export Panel Feature \u00b7 Issue #1446 \u00b7 wandb\/client \u00b7 GitHub<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Account deletion",
        "Question_link":"https:\/\/community.wandb.ai\/t\/account-deletion\/2386",
        "Question_created_time":"2022-05-10T07:31:42.800Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":265,
        "Question_body":"<p>Hi,<br>\nI created two accounts by accident. Would you please delete this account (kaminski)?<br>\nIs there a cool-down to use the email address bound to this account again? Because I would like to add it, my academic address, as the primary address to my main account (jkaminski).<\/p>\n<p>Cheers<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one save a plot in wandb with wandb.log?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-save-a-plot-in-wandb-with-wandb-log\/2373",
        "Question_created_time":"2022-05-05T22:15:27.254Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_body":"<p>I\u2019m trying to save a plot with wandb.log. Their <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots\">docs<\/a> say to do:<\/p>\n<pre><code class=\"lang-auto\">    wandb.log({\"chart\": plt})\n<\/code><\/pre>\n<p>but this fails for me.<\/p>\n<p>I get two errors, 1st error (when I do NOT do <code>plt.show()<\/code> before trying to do wand.log):<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/Applications\/PyCharm.app\/Contents\/plugins\/python\/helpers\/pydev\/_pydevd_bundle\/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 124, in crawl_fig\n    self.crawl_ax(ax)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 146, in crawl_ax\n    self.draw_collection(ax, collection)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 289, in draw_collection\n    offset_order = offset_dict[collection.get_offset_position()]\nAttributeError: 'LineCollection' object has no attribute 'get_offset_position'\n<\/code><\/pre>\n<p>I get two errors, 2nd error (when I DO <code>plt.show()<\/code> before trying to do wand.log):<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/Applications\/PyCharm.app\/Contents\/plugins\/python\/helpers\/pydev\/_pydevd_bundle\/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 122, in crawl_fig\n    with self.renderer.draw_figure(fig=fig, props=utils.get_figure_properties(fig)):\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/contextlib.py\", line 119, in __enter__\n    return next(self.gen)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/renderers\/base.py\", line 45, in draw_figure\n    self.open_figure(fig=fig, props=props)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/renderer.py\", line 90, in open_figure\n    self.mpl_x_bounds, self.mpl_y_bounds = mpltools.get_axes_bounds(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mpltools.py\", line 265, in get_axes_bounds\n    x_min, y_min, x_max, y_max = min(x_min), min(y_min), max(x_max), max(y_max)\nValueError: min() arg is an empty sequence\n<\/code><\/pre>\n<p>Note that their trivial example DOES work:<\/p>\n<pre><code class=\"lang-auto\">import matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel(\"some interesting numbers\")\nwandb.log({\"chart\": plt})\n<\/code><\/pre>\n<p>for me.<\/p>\n<hr>\n<p>cross posted: <a href=\"https:\/\/stackoverflow.com\/questions\/72134168\/how-does-one-save-a-plot-in-wandb-with-wandb-log\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How does one save a plot in wandb with wandb.log? - Stack Overflow<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accessing a run that was saved offline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/accessing-a-run-that-was-saved-offline\/2372",
        "Question_created_time":"2022-05-05T18:33:56.353Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":444,
        "Question_body":"<p>I\u2019m running experiments on an environment with no internet connection, and I have some issues running wand locally. I can save the run in offline mode.<\/p>\n<p>I\u2019d like to access the logs\/artifacts\/tables using the public API (I have that already implemented), but by giving a path to the relevant experiment\u2019s wandb directory (and not with the <code>entity\/project\/run_id<\/code> run_id format)?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Azure Artifact Referencing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/azure-artifact-referencing\/2376",
        "Question_created_time":"2022-05-06T19:10:51.629Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":108,
        "Question_body":"<p>Following doesn\u2019t work for us. Is their any way to solve the following problems for Artifact reference with  <strong>Azure Blob Storage<\/strong>:<\/p>\n<ol>\n<li>\n<p>How should we pass credentials to wandb ? As for Amazon S3 and GCS the priority and env variables are mentioned in docs.<\/p>\n<\/li>\n<li>\n<p>It was recommended that by passing <strong>az:\/\/<\/strong> as prefix will work similar to whats done s3 bucket and gcs.  However I didn\u2019t see any storage handler in wandb code for azure. I wonder how would it work just by passing a prefix ? Furthermore, unlike boto for s3 and google-cloud-storage sdk for gcs. I don\u2019t see any requirement of azure-storage in requirements.txt. Is their any Microsoft Azure Storage SDK for Python somewhere in code that I can not find ??<\/p>\n<\/li>\n<li>\n<p>Although it doesn\u2019t make any sense still I gave it a try, and as expected. Following are the results.<\/p>\n<\/li>\n<\/ol>\n<pre><code class=\"lang-auto\">run = wandb.init(project=\"Dummy_Training\", job_type=\"upload\")\nbucket = 'az:\/\/azurestorage.blob.core.windows.net\/container_name'\ndataset_at = wandb.Artifact('sample',type=\"raw_data\")\n\ndataset_at.add_reference(bucket)\nrun.log_artifact(dataset_at)\nrun.finish()\n<\/code><\/pre>\n<p>And I get the following Error<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/d74321689bbd477953afb77691a5b5ee70505085.jpeg\" data-download-href=\"\/uploads\/short-url\/uIitV3rWGuO3hAvgAkyuvwPTnF3.jpeg?dl=1\" title=\"6853D58492F2404D8EAC586087E55373\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d74321689bbd477953afb77691a5b5ee70505085_2_682x500.jpeg\" alt=\"6853D58492F2404D8EAC586087E55373\" data-base62-sha1=\"uIitV3rWGuO3hAvgAkyuvwPTnF3\" width=\"682\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d74321689bbd477953afb77691a5b5ee70505085_2_682x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d74321689bbd477953afb77691a5b5ee70505085_2_1023x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/d74321689bbd477953afb77691a5b5ee70505085.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d74321689bbd477953afb77691a5b5ee70505085_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">6853D58492F2404D8EAC586087E55373<\/span><span class=\"informations\">1202\u00d7881 264 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<ol start=\"4\">\n<li>Do I need to pass something in name parameter? What would be the entry name for azure?<br>\nSeems like az:\/\/ is defiantly not in your known handlers<\/li>\n<\/ol>\n<p><strong>Is their any way for Azure Artifact Referencing (azure blob storage) to work. And please let me know if their is any thing that I am missing. Any example for the resolution of this problem will be much appreciated.<\/strong><\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"About hyperparameters sweeping for DDP program",
        "Question_link":"https:\/\/community.wandb.ai\/t\/about-hyperparameters-sweeping-for-ddp-program\/2384",
        "Question_created_time":"2022-05-09T15:16:25.291Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":165,
        "Question_body":"<p>Hi, I have a program which needs multiple GPUs to run at the same time, currently I use DDP to launch the program. I wonder how can I do the sweeping , the program will still be launched  in DDP mode (using all GPUs) at each trial. Thanks!<\/p>\n<p>Best<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging Date Objects",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-date-objects\/2263",
        "Question_created_time":"2022-04-19T17:00:30.533Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":468,
        "Question_body":"<p>Hey everyone!<\/p>\n<p>I\u2019m looking for a way to log Dates. I want to show the evolution of our labeled data over time over non-uniform time steps. To make it more clear, let\u2019s say I want to display the amount of data on arbitrary days. If I ran my W&amp;B run on those days, I could distinguish them by <code>run:createdAt<\/code>. The plots could display them as dates as one would expect and everything is fine.  Now, this fails as soon as I want to have a starting date AND an end date. Therefore I\u2019m looking to log date data.<\/p>\n<p>The functionality should be there, as it is for <code>createdAt<\/code>,  but I can\u2019t figure out how to log my own. I couldn\u2019t find a suitable object in the docs and neither POSIX timestamp nor iso format\/datetime objects work out of the box.<\/p>\n<p>Is there no way to do this, or did I overlook something?<\/p>\n<p>As a workaround I could just use the POSIX timestamp as scale, but I guess we all agree that\u2019s a little unwieldy.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I query whether a run object is disabled (`RunDisabled`)?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-query-whether-a-run-object-is-disabled-rundisabled\/2256",
        "Question_created_time":"2022-04-17T19:14:57.307Z",
        "Question_answer_count":9,
        "Question_score_count":2,
        "Question_view_count":213,
        "Question_body":"<p>Given a <code>run<\/code> object (such as the one retuned by <code>wandb.init()<\/code>, what\u2019s the right way to query its status?<br>\nE.g. `run.status == \u2018RunDisabled\u2019?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to build a sweeps model for different numbers of hidden layers?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-build-a-sweeps-model-for-different-numbers-of-hidden-layers\/2363",
        "Question_created_time":"2022-05-03T12:11:09.475Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":158,
        "Question_body":"<p>I am making a simple network in PyTorch with linear units as a practise project. I\u2019d like to use sweeps to find the best hyper parameters for the network. Some of these hyperparameters include batch_norm, dropout value, number of hidden layers, number of units in each hidden layer.<\/p>\n<p>I can\u2019t figure out how to set up the model and sweep config so that two different model structures can be swept without being confusing. For example, I want to use batch_norm OR have dropout values of <code>[0, 0.2, 0.4, 0.5]<\/code>. I never want <code>batch_norm<\/code> AND <code>dropout<\/code> to be used. If I use random search with wandb, it may choose both <code>0.4<\/code> dropout AND <code>batch_norm<\/code> which I don\u2019t want.<\/p>\n<p>I know how to set up the network class with simple if statements so it adds either <code>batch_norm<\/code> or <code>dropout<\/code>, but the <code>wandb.config<\/code> would still select a value for <code>dropout<\/code> and a boolean for <code>batch_norm<\/code>, and I don\u2019t want the sweep report to show both these parameters if the network only uses one.<\/p>\n<p>Another example is, I\u2019d like 2, 3, 4 or 5 hidden layers. I\u2019d also like each layer to have a randomly selected  number of neurons from the range <code>[64, 128, 256, 512]<\/code>.<\/p>\n<p>I can forsee a problem where wandb will select the model to have 3 hidden layers but also pick say, 256 neurons for the 4th or 5th layer which will be misleading on the sweep parameter graph.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb upload limit \/ request limit should not stop execution of script",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-upload-limit-request-limit-should-not-stop-execution-of-script\/2311",
        "Question_created_time":"2022-04-24T10:29:55.742Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":227,
        "Question_body":"<p>Hi,<\/p>\n<p>my scripts regularly slow down significantly because I run into the wandb upload limit\/ request limit.<br>\nE.g. getting <code>429 encountered (Filestream rate limit exceeded, retrying in 4.902817452929678 seconds), retrying request<\/code><\/p>\n<p>Is there a way to set wandb to \u201csoft uploads\u201d, i.e. uploading data whenever possible but never stopping\/pausing the execution of the main script?<\/p>\n<p>Thanks so much!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"(unsolved) How to set spacing between monitoring points(default 30s)?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unsolved-how-to-set-spacing-between-monitoring-points-default-30s\/1780",
        "Question_created_time":"2022-01-18T01:32:40.749Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":252,
        "Question_body":"<p>The default interval of monitoring points for GPU utilization is the 30s. How can I set this time?<\/p>\n<p>In my model, the latency of one batch is shorter than the 30s. So I don\u2019t think this interval is suitable.<br>\nCan I modify it by setting any variable?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom HTML with three.js for interactive 3D asset visualization",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-html-with-three-js-for-interactive-3d-asset-visualization\/2258",
        "Question_created_time":"2022-04-18T14:18:11.993Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":328,
        "Question_body":"<p>Hi, I am working on a 3D reconstruction task that returns multiple 3D meshes in my visualization. The custom W&amp;B 3D visualization is too bright and it is not helpful for tasks that require to visualize texture; also, it seems to reduce the triangle counts, but triangle counts are important for 3D vision.<\/p>\n<p>It seems that W&amp;B supports uploading custom HTML.  I am wondering if it is possible to:<\/p>\n<ol>\n<li>Upload my predicted 3D meshes for each step.<\/li>\n<li>Display my 3D meshes using a custom HTML that using <a href=\"https:\/\/threejs.org\/examples\/#webgl_animation_keyframes\" rel=\"noopener nofollow ugc\">three.js<\/a> to allow me interact with it.<\/li>\n<\/ol>\n<p>Potential blockers:<\/p>\n<ul>\n<li>I assume <code>wandb.Object3D<\/code> is used with <code>wandb.log<\/code> to upload my 3D prediction. In my HTML, how do I get access to the uploaded meshes?<\/li>\n<li>Similarly, how do I upload and get access to a js library in the HTML? (the paths)<\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I add a table to a run after it has completed via the API?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api\/2334",
        "Question_created_time":"2022-04-27T19:47:44.988Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":159,
        "Question_body":"<p>I would like to log a table to a wandb run, like shown here: <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/tables-quickstart\">https:\/\/docs.wandb.ai\/guides\/data-vis\/tables-quickstart<\/a><\/p>\n<p>The table will contain information about the performance of an RL agent in environments which differ from its training environment. I want to add the table to the wandb created during the training of the RL agent. Is this possible?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Local runs are not being updated to server",
        "Question_link":"https:\/\/community.wandb.ai\/t\/local-runs-are-not-being-updated-to-server\/2328",
        "Question_created_time":"2022-04-27T07:36:04.042Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":137,
        "Question_body":"<p>Nothing is being logged on <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a><br>\nSessions are being created but no graphs are being made and no codes are being saved.<\/p>\n<p>Are there issues with the server?<br>\nThis has been happening since yesterday and it\u2019s very frustrating since i can\u2019t see the graphs <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding values manually to run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-values-manually-to-run\/2146",
        "Question_created_time":"2022-03-23T16:26:50.276Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":508,
        "Question_body":"<p>Hey!<\/p>\n<p>I have some metrics which I cannot log during a run, but would like to attach to afterwards to also plot it. Is there a ways through the website or the CLI to manually attach a new value or metric?<\/p>\n<p>Greetings,<br>\nPatrick<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Account deletion request",
        "Question_link":"https:\/\/community.wandb.ai\/t\/account-deletion-request\/2322",
        "Question_created_time":"2022-04-26T14:28:16.869Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":96,
        "Question_body":"<p>Can you delete my account please? username realdionysus<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Suboptimal subsampling behavior",
        "Question_link":"https:\/\/community.wandb.ai\/t\/suboptimal-subsampling-behavior\/2320",
        "Question_created_time":"2022-04-26T12:57:37.791Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":175,
        "Question_body":"<p>I am trying to build a plot of \u201closs\/eval\u201d vs \u201ccompleted_steps\u201d. \u201closs\/eval\u201d is the validation loss and it is logged once in a while. \u201ccompleted_steps\u201d is logged at every step. I would like to see all datapoints where \u201closs\/eval\u201d is logged to be displayed in the plot, because there is not many of them (about 30 for each run). Instead I only see random ones because apparently the downsampling procedure is based on frequency of \u201ccompleted_steps\u201d logging. As a result the plots are not very informative;<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bf980db958e2b3207bbe7973f8a99a123bb9cb84.png\" alt=\"image\" data-base62-sha1=\"rkUY9uzfHFfCzy1pCZMz1zVMVSs\" width=\"649\" height=\"305\"><\/p>\n<p>I think a better behavior when plotting a metric X against metric Y would be to fetch all (X, Y) pairs first and then downsample if there is too many such pairs.<\/p>\n<p>Can I hope to see improvements in downsampling logic at some point?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Tracked hours difference in personal account vs team usage?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/tracked-hours-difference-in-personal-account-vs-team-usage\/2288",
        "Question_created_time":"2022-04-21T01:47:08.301Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":151,
        "Question_body":"<p>Thanks for a great resource. I have a quick question on pricing. I\u2019m on the personal (free) account and <a href=\"https:\/\/wandb.ai\/site\/pricing\">I see here<\/a> that I have unlimited tracking hours:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26.png\" data-download-href=\"\/uploads\/short-url\/mkA0xRHM7AOXolpoKtYl3ViLpNs.png?dl=1\" title=\"Screenshot from 2022-04-20 21-31-22\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26_2_208x500.png\" alt=\"Screenshot from 2022-04-20 21-31-22\" data-base62-sha1=\"mkA0xRHM7AOXolpoKtYl3ViLpNs\" width=\"208\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26_2_208x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26_2_312x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9c83666d152fcb77e5641a77a84886c46f328d26_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-04-20 21-31-22<\/span><span class=\"informations\">351\u00d7841 24.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>On the same page, it says for team management, a personal account has 250 tracked hours.<\/p>\n<p>To clarify, does this mean that if I am running wandb for a team, and hit my 250 tracked hours, if I want to remain in the free tier while using the team, I will need to move the experiments to my personal account? Will this \u201cremove\u201d the tracked hours or will the tracked hours continue to count against the 250?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[Feature Request] W&B badge or shield for GitHub repositories",
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-w-b-badge-or-shield-for-github-repositories\/2181",
        "Question_created_time":"2022-04-02T15:50:23.994Z",
        "Question_answer_count":4,
        "Question_score_count":4,
        "Question_view_count":291,
        "Question_body":"<p>I was wondering if it would be possible to have a simple W&amp;B\/wandb badge to display on GitHub repositories, meaning: \u201cThis repository supports experiment tracking with wandb\u201d.<\/p>\n<p>By badge, I mean like below. The official wandb client repository for example uses pypi, codecov and circleci badges.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png\" data-download-href=\"\/uploads\/short-url\/64tMj9Dw36m9P2OBKPlPRcyIuBq.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png\" alt=\"image\" data-base62-sha1=\"64tMj9Dw36m9P2OBKPlPRcyIuBq\" width=\"690\" height=\"151\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">775\u00d7170 36 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2022-04-22T21:46:15.454Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dealer56\">@dealer56<\/a>,<\/p>\n<p>I discussed this with some folks, and looks like we already have a <a href=\"https:\/\/img.shields.io\/badge\/Weights_&amp;_Biases-FFCC33?style=for-the-badge&amp;logo=WeightsAndBiases&amp;logoColor=black\" rel=\"noopener nofollow ugc\">badge<\/a> for something like this. You should also be able to generate such badges through <a href=\"http:\/\/shields.io\" rel=\"noopener nofollow ugc\">shields.io<\/a>, and we plan to have a tutorial in the future on how to use badges to present a metric on your repo.<\/p>\n<p>I\u2019ll link the tutorial once it is out.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"On premises W&B and inviting users to teams without email",
        "Question_link":"https:\/\/community.wandb.ai\/t\/on-premises-w-b-and-inviting-users-to-teams-without-email\/2191",
        "Question_created_time":"2022-04-06T16:34:08.750Z",
        "Question_answer_count":13,
        "Question_score_count":1,
        "Question_view_count":193,
        "Question_body":"<p>I\u2019m using an on-premises version of W&amp;B behind a corporate proxy. We\u2019re trying to create a team within our instance to collaborate on data. To do so, I go to the team settings (as the owner), and type in the username of the person I\u2019m trying to add. W&amp;B tries to send an email to the person. Because we\u2019re behind a SSL proxy, we get this error:<\/p>\n<pre><code class=\"lang-auto\">Something went wrong while trying to add the user &lt;USERNAME&gt;: Post \"https:\/\/api.sendgrid.com\/v3\/mail\/send\": x509: certificate signed by unknown authority\n<\/code><\/pre>\n<p>Is there an option (like with signing up new users) to just copy an invite link to the clipboard to send ourselves? There doesn\u2019t seem to be a \u2018backdoor\u2019 way to add a user to a team, like through python code or an API. Am I missing something?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use panels\/sections configured for one run for all runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-use-panels-sections-configured-for-one-run-for-all-runs\/2060",
        "Question_created_time":"2022-03-11T11:41:27.418Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":146,
        "Question_body":"<p>A couple of weeks ago I \u201clost\u201d the logged gradients in my wandb UI. Today I wanted to research why this might be the case (updated wandb to 0.12.11, changed <code>log-freq<\/code>, \u2026) but as it turns out (by chance) it is a visualisation issue. This is either a bug or a feature\/setting that I miss. It might also be related to a bug\/misunderstanding on my behalf that I have \u201clost\u201d sections\/panels configurations in the wandb UI.<\/p>\n<p>When I list a couple of (toy) runs with one run visible (\u201ceye open\u201d) I see a certain layout of sections\/panels. I have no gradients logged (see screenshot, section \u201cGradients\u201d. I have renamed it to uppercase and selected the option to also \u201cshow empty sections\u201d). That\u2019s what led me to believe that I have \u201clost\u201d the gradients.<\/p>\n<p>But when I select the run from above I can see both the run\u2019s gradient and the layout that I had changed.<\/p>\n<p>Can I somehow make the section\/panel configuration of this run the default for all runs? I already applied \u201cCopy to default workspace\u201d (which has a different intention I think, but it was worth a try).<\/p>\n<p>Do I miss a setting or behaviour?<\/p>\n<p>See the 2 screenshots in the PNG (had to combine them, only 1 upload allowed).<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1536b9c8180282ae0182c8834f883bea30622414.png\" data-download-href=\"\/uploads\/short-url\/31Fh7BjMnQAFkMRbuNmt9Zl6feQ.png?dl=1\" title=\"Screenshots\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png\" alt=\"Screenshots\" data-base62-sha1=\"31Fh7BjMnQAFkMRbuNmt9Zl6feQ\" width=\"594\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_891x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_1188x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshots<\/span><span class=\"informations\">1894\u00d71592 232 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Table artifact to pandas dataframe",
        "Question_link":"https:\/\/community.wandb.ai\/t\/table-artifact-to-pandas-dataframe\/2059",
        "Question_created_time":"2022-03-11T10:15:27.467Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":835,
        "Question_body":"<p>I logged a table artifact.<br>\nNow I want to analyze it using pd.DataFrame.<\/p>\n<p>I\u2019ve downloaded the artifact.<br>\nHowever, I don\u2019t mange to convert the json into dataframe.<br>\nIs there a method for doing so?<br>\nThanks<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport pandas as pd\nimport os.path as osp\n\nrun = wandb.init()\nartifact = run.use_artifact('PATH\/run-1n4emfxy-test_table:v19', type='run_table')\nartifact_dir = artifact.download()\npath_to_json = osp.join( next(iter(artifact._download_roots)), 'test_table.table.json')\npd.read_json(path_to_json)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Adding tfRecords files to artifacts doesn't work?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-tfrecords-files-to-artifacts-doesnt-work\/1948",
        "Question_created_time":"2022-02-18T16:05:59.797Z",
        "Question_answer_count":9,
        "Question_score_count":0,
        "Question_view_count":229,
        "Question_body":"<p>Hello,<\/p>\n<p>I am trying logging my tfRecords files to artefact, but it seems to not be working (I get an error: \u201cwandb: Network error (TransientError), entering retry loop.\u201d).<\/p>\n<p>I am providing the code I use below. I am pretty sure it is something regarding the tfRecords file since I tried changing the contents of my folders to contain only .csv and .paqruet and it worked nicely. Do you have any ideas what could be happening here?<\/p>\n<pre><code class=\"lang-auto\">with wandb.init(project=\"----\", entity='----', job_type='saving_processed_files') as run:\n    train_data_art = wandb.Artifact(\n        name='train_data',\n        type='train_data'  \n    )\n\n    files_train = os.listdir(final_path_train)\n    files_train=[x  for x in files_train if x[0]!='.']\n\n    for file in files_train:\n        file_path = os.path.join(final_path_train, file)\n        train_data_art.add_file(file_path, name=file)\n\n    run.log_artifact(train_data_art)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb Project table value select algorithm",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-project-table-value-select-algorithm\/2300",
        "Question_created_time":"2022-04-22T03:56:51.340Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":510,
        "Question_body":"<p>I have a wondering how to select value in project table.<br>\nWhat is algorithm in wandb project table to select values? In images, these values is not minimum in each models.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da.png\" data-download-href=\"\/uploads\/short-url\/bJn70ylkOmBrf45BJzAwLO3FLIe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png\" alt=\"image\" data-base62-sha1=\"bJn70ylkOmBrf45BJzAwLO3FLIe\" width=\"690\" height=\"99\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1035x148.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1380x198.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2478\u00d7358 42.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to distinguish resumed runs during sweeps?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-distinguish-resumed-runs-during-sweeps\/2091",
        "Question_created_time":"2022-03-16T09:10:01.021Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":237,
        "Question_body":"<p>I\u2019m looking into WandB\u2019s Sweep feature for my next project and am currently trying to implement the resume-mechanism.<\/p>\n<p>I use the following code to restore my model:<\/p>\n<pre><code class=\"lang-python\">wandb.init(resume=True)\n\nif wandb.run.resumed:\n    model = wandb.restore(\"last.ckpt\")\nelse:\n    model = ... # instantiate new model\n<\/code><\/pre>\n<p>However,  <code>wandb.run.resumed<\/code> is apparently always <code>True<\/code>, since the wandb agent sets the <code>WANDB_RUN_ID<\/code>-environment variable, so restore fails for new runs. What is a good way to handle this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb for Huggingface Trainer saves only first model",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-for-huggingface-trainer-saves-only-first-model\/2270",
        "Question_created_time":"2022-04-20T07:18:31.790Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":207,
        "Question_body":"<p>I am finetuning multiple models using for loop as follows.<\/p>\n<pre><code class=\"lang-auto\">for file in os.listdir(args.data_dir):\n    finetune(args, file)\n<\/code><\/pre>\n<p>BUT <code>wandb<\/code> shows logs only for the first file in <code>data_dir<\/code> although it is training and saving models for other files. It feels very strange behavior.<\/p>\n<pre><code class=\"lang-auto\">wandb: Synced bertweet-base-finetuned-file1: https:\/\/wandb.ai\/***\/huggingface\/runs\/***\n<\/code><\/pre>\n<p>This is a small snippet of <strong>finetuning<\/strong> code with Huggingface:<\/p>\n<pre><code class=\"lang-auto\">def finetune(args, file):\n    training_args = TrainingArguments(\n        output_dir=f'{model_name}-finetuned-{file}',\n        overwrite_output_dir=True,\n        evaluation_strategy='no',\n        num_train_epochs=args.epochs,\n        learning_rate=args.lr,\n        weight_decay=args.decay,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.batch_size,\n        fp16=True, # mixed-precision training to boost speed\n        save_strategy='no',\n        seed=args.seed,\n        dataloader_num_workers=4,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset['train'],\n        eval_dataset=None,\n        data_collator=data_collator,\n    )\n    trainer.train()\n    trainer.save_model()\n<\/code><\/pre>",
        "Question_closed_time":"2022-04-21T14:50:51.674Z",
        "Answer_body":"<p><code>wandb.init(reinit=True)<\/code> and <code>run.finish()<\/code> helped me to log the models <strong>separately<\/strong> on wandb website.<\/p>\n<p>The working code looks like below:<\/p>\n<pre><code class=\"lang-auto\">\nfor file in os.listdir(args.data_dir):\n    finetune(args, file)\n\nimport wandb\ndef finetune(args, file):\n    run = wandb.init(reinit=True)\n    ...\n    run.finish()\n<\/code><\/pre>\n<p>Reference: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/launch#how-do-i-launch-multiple-runs-from-one-script\" class=\"inline-onebox\">Launch Experiments with wandb.init - Documentation<\/a><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Visualizations, metrics, etc. keep randomly appearing and disappearing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/visualizations-metrics-etc-keep-randomly-appearing-and-disappearing\/2283",
        "Question_created_time":"2022-04-20T19:34:11.598Z",
        "Question_answer_count":9,
        "Question_score_count":4,
        "Question_view_count":187,
        "Question_body":"<p>This morning we were looking at the visualizations and charts on an active training run and everything was fine. After about 11am PDT, all of the visualizations started randomly disappearing. Sometimes only the loss charts would be visible, other times the losses and metrics and statistics would all be visible.<\/p>\n<p>The best I can tell is that the site is only showing charts for whatever things were in the most recent step. If you send some things less frequently, then their charts\/visualizations disappear until they\u2019re in the step data again.<\/p>",
        "Question_closed_time":"2022-04-20T22:33:58.572Z",
        "Answer_body":"<p><a class=\"mention\" href=\"\/u\/cogwheel\">@cogwheel<\/a> Could you possibly send me a link to your workspace?  If you don\u2019t want to share here you can also email <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a> and explain the issue and I can respond via email.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Sweep over pre-training, then sweep over finetuning",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-over-pre-training-then-sweep-over-finetuning\/2015",
        "Question_created_time":"2022-03-04T13:11:45.042Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":199,
        "Question_body":"<p>I\u2019d like to pre-train a model under several different conditions, then finetune each of those resulting models. The simple way to do this would be two separate sweeps. But then I need to manually start the second one. Is there a way to combine these into one single sweep?<\/p>\n<p>With a bash script, I can simply call pre-train and finetune in sequence, passing the respective arguments via a config file. Is it somehow possible to tell the respective scripts that they are part of the same sweep and should therefore use certain parameters?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Prevent wandb from eating output in distributed mode",
        "Question_link":"https:\/\/community.wandb.ai\/t\/prevent-wandb-from-eating-output-in-distributed-mode\/1931",
        "Question_created_time":"2022-02-15T16:45:50.264Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":136,
        "Question_body":"<p>Is there any way to stop wandb from gobbling up all the std out \/ logging output?<br>\nI\u2019m running wandb in distributed mode on rank=0 process, and wandb gobbles up all the output there.<br>\nHowever, rank=1 process still outputs stuff to stdout. So now if I want to see an error I have to look at both wandb logs and the server logs.<\/p>\n<p>I would like wandb to log its thing - but also leave the standard out where it was.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb login issue on git bash",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-login-issue-on-git-bash\/2000",
        "Question_created_time":"2022-03-02T06:51:27.453Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":478,
        "Question_body":"<p>In the login process, this error occurs. It  says install \u201cMkl-service\u201d but the service has already installed and I had tried to fix this error but I was unable to do so<\/p>\n<p>$ wandb login<br>\nc:\\users\\great\\anaconda3\\lib\\site-packages\\numpy_<em>init<\/em>_.py:143: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see <a href=\"http:\/\/github.com\/IntelPython\/mkl-service\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - IntelPython\/mkl-service: Python hooks for Intel(R) Math Kernel Library runtime control settings.<\/a><br>\nfrom . import _distributor_init<br>\nwandb: Appending key for <a href=\"http:\/\/api.wandb.ai\">api.wandb.ai<\/a> to your netrc file: C:\\Users\\great\/.netrc<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cumulative max (highwater mark) for distributed training and sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cumulative-max-highwater-mark-for-distributed-training-and-sweep\/2072",
        "Question_created_time":"2022-03-14T14:29:30.761Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":214,
        "Question_body":"<p>Hello everybody!<br>\nhave an algorithm that I run 10 times, and return the best run by a cumulative maximum - So for each run, I log the highest(cumulative) validation score of the entire run.<\/p>\n<p>I ran 7 of these, and grouped them together aggregating with maximum. However, since each experiment validates at different timestep, the resulting graph is not a cumulative maximum of the entire 7 runs. That happens because at each validation point, not all runs are present. What I got, with what I want to achieve marked in red:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wrlxx.png\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/60ed9165396ec6c81826b4ec1203340a9f898494.png\" alt=\"enter image description here\" data-base62-sha1=\"dPsP625Jbrr920C7eeCL3YtRJVG\" width=\"690\" height=\"368\"><\/a><\/p>\n<ol>\n<li>Is this achievable?<\/li>\n<li>How can I set a sweep that uses the cumulative validation of the entire experiment (the red line,  not a single trial)?<\/li>\n<\/ol>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I dont understand why my wandb_metadata.json file is showing this",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this\/2199",
        "Question_created_time":"2022-04-07T20:33:19.905Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":201,
        "Question_body":"<p>Hello, i am pretty new to this wandb function. I have been trying to run a program with it, but it shows an error of like this:<br>\nTraceback (most recent call last):<br>\nFile \u201cmain.py\u201d, line 105, in <br>\nmain()<br>\nFile \u201cmain.py\u201d, line 99, in main<br>\ntrainer.train(start_iteration=epoch)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/train.py\u201d, line 58, in train<br>\nloss = self.training_step(data, start_iteration)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/train.py\u201d, line 22, in training_step<br>\nloss, log = self.net.loss(data, epoch)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/model\/voxel2mesh.py\u201d, line 214, in loss<br>\npred_points = sample_points_from_meshes(pred_mesh, 3000)<br>\nFile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/sample_points_from_meshes.py\u201d, line 55, in sample_points_from_meshes<br>\nareas, _ = mesh_face_areas_normals(<br>\nFile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/mesh_face_areas_normals.py\u201d, line 44, in forward<br>\nareas, normals = _C.face_areas_normals_forward(verts, faces)<br>\nRuntimeError: Not compiled with GPU support. (FaceAreasNormalsForward at \/root\/project\/pytorch3d\/csrc\/face_areas_normals\/face_areas_normals.h:51)<\/p>\n<p>The preprocessing data job was done fine, but as I try to run the program with the preprocessed data, the upper error happens<\/p>\n<p>I checked the metadata.json file and realized the cuda was set as null even though i checked the cuda was there with nvcc --version. I am guessing the wandb not realizing the cuda is there seems to be an issue. Are there any methods of how i could solve this? Any advice is appreciated Thank you<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Export panel between sweeps",
        "Question_link":"https:\/\/community.wandb.ai\/t\/export-panel-between-sweeps\/2186",
        "Question_created_time":"2022-04-04T08:13:33.695Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":347,
        "Question_body":"<p>Hi,<\/p>\n<p>Is there a way to export custom plots I created in one sweep to the dashboard of another?<br>\nSpecifically, I used the \u201cadd section\u201d button to create a new section, and added custom plots to it. I would like to move this section \\ panel as a whole to another sweep.<\/p>\n<p>Is it possible somehow? It could save me a lot of time instead of setting it again and again for every sweep.<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Artifacts (local) caching - how does it really work?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifacts-local-caching-how-does-it-really-work\/2255",
        "Question_created_time":"2022-04-17T13:50:52.610Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":861,
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019m trying to figure out how does the caching  of artifacts work. Let\u2019s say I want to download a model artifact to run some evaluation on. I don\u2019t need the file on disk to persist rather I just want to load it into memory. What I do right now in my evaluation script is:<\/p>\n<pre><code class=\"lang-auto\">import tempfile\nimport wandb\n\nartifact = wandb.use_artifact(model_weights_uri)\nwith tempfile.TemporaryDirectory() as tmpdirname:\n    artifact.download(tmpdirname)\n    model_weights = load_pickle(os.path.join(tmpdirname, \"model_weights.pickle\"))\n<\/code><\/pre>\n<p>And from that point on I use the <code>model_weights<\/code> as it was loaded into memory.<\/p>\n<p>My first question is: if I run the code twice (on the same machine), <strong>will the model-weights be downloaded again<\/strong> or are they cached somewhere? assuming the logged artifact wasn\u2019t changed of course. And if they are cached, where are they cached?<br>\nI\u2019m also not clear about the <code>artifact<\/code> directory (which is used if I run <code>artifact.download()<\/code> without any argument). Does that directory serve as cache? if so, what does the <code>.cache<\/code> directory used for?<\/p>\n<p>I would appreciate answers to my questions and perhaps a  general explanation of the artifact caching mechanism &amp; best practices.<\/p>\n<p>Thanks!<br>\nRan<\/p>",
        "Question_closed_time":"2022-04-18T20:15:55.393Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ranshadmi-nexite\">@ranshadmi-nexite<\/a>,<\/p>\n<p>Thank you for your question. You are right, all Artifacts are cached on your system under <code>~\/.cache\/wandb\/artifacts<\/code> and organized by their checksum. So if you try to download a file with checksum <code>x<\/code> and that file has been logged in an Artifact from your machine or downloaded to your machine as part of an artifact before, we just pull it from the cache by checking if there is a cached Artifact file with checksum <code>x<\/code>.<\/p>\n<p>So, if you run the same code twice, assuming the version of the artifact you are trying to download has not changed, the artifact can simply be pickked up from your cache directory.<\/p>\n<p>Also, when calling <code>artifact.download()<\/code> without any arguments, the artifact is saved in the directory in which the code is running. This, however,  is not the directory that serves as a cache, that still remains <code>.cache<\/code> which acts as a central location to look for artifacts before fetching it.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Is there a way to change job_type?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-there-a-way-to-change-job-type\/2253",
        "Question_created_time":"2022-04-17T10:40:14.093Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":224,
        "Question_body":"<p>Hiya!<\/p>\n<p>Last night I ran an experiment and didn\u2019t bother to check the inputs to <code>wandb.init<\/code>. It turned out later that I mixed some things up and there was a mistake in <code>job_type<\/code> kwarg.  Now I am wondering is there a way to change this parameter (I really need it for grouping) through API or UI?<\/p>\n<p>Thanx<\/p>",
        "Question_closed_time":"2022-04-18T07:35:43.235Z",
        "Answer_body":"<p>Hey Ilya,<\/p>\n<p>At the moment, changing the job type is not possible. I\u2019ll file a ticket for this. As a workaround I\u2019d suggest tagging the runs using our Public API.<\/p>\n<p>Let me know if you have any questions.<\/p>\n<p>Best,<br>\nArman<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Show single lines in groups",
        "Question_link":"https:\/\/community.wandb.ai\/t\/show-single-lines-in-groups\/2245",
        "Question_created_time":"2022-04-14T20:29:45.659Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":85,
        "Question_body":"<p>Hello,<br>\nI want to have a way to organise my runs so that I can know some parameters of the runs already by the name. I can do that by using group_by and then I can see the different parameter for each run<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7aefbd3b28fbf0ac496352f40ceb75e0975e1f00.png\" alt=\"image\" data-base62-sha1=\"hxxTc29jObSNMn9oZg3e64ZOA4U\" width=\"269\" height=\"195\"><\/p>\n<p>But this also means all the runs inside a group, is it possible to group but still see the different runs (optionally all runs in a group with the same color?)<br>\nThanks,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Can you edit config of a run after it finishes?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/can-you-edit-config-of-a-run-after-it-finishes\/2247",
        "Question_created_time":"2022-04-15T20:22:38.436Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":155,
        "Question_body":"<p>A very bad practice, I know. But for a part of my experiment, the main file wasn\u2019t updated so it ignored some configs. Is it possible to manually add them into the runs, now that the runs are finished?<\/p>\n<p>If it helps, I don\u2019t need to add new entries to the config. I just need to add to an existing string in the config.<\/p>",
        "Question_closed_time":"2022-04-15T22:00:23.990Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/aceticia\">@aceticia<\/a>,<\/p>\n<p>This is absolutely possible! Here is an example in our docs on how to do this : <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#update-config-for-an-existing-run\">https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#update-config-for-an-existing-run<\/a><\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Configuration for the Replication for sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/configuration-for-the-replication-for-sweep\/2246",
        "Question_created_time":"2022-04-15T04:27:35.854Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":137,
        "Question_body":"<p>Is there a replication option for the sweep config?<br>\nI want to compare the average performance of my experiments more than one time due to variance in my experiments.<\/p>\n<p>Thaks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plot train and validation loss together by default?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plot-train-and-validation-loss-together-by-default\/2235",
        "Question_created_time":"2022-04-13T14:54:32.467Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":122,
        "Question_body":"<p>By default wandb plots the loss and the validation loss in separate plots. I know it is possible to add plots and modify those existing plots, but for each new run it will appear like the default again. Is there a way to change this default on a project or acount basis?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Passing arguments based on search parameters in sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/passing-arguments-based-on-search-parameters-in-sweep\/2221",
        "Question_created_time":"2022-04-12T08:53:36.910Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":194,
        "Question_body":"<p>I\u2019m running a grid-search sweep with a custom command of this sort:<\/p>\n<pre><code class=\"lang-auto\">project: my_project\nprogram: main.py\nname: grid_search\nmethod: grid\nmetric:\n  goal: maximize\n  name: eval_accuracy\nparameters:\n  learning_rate:\n    values: [1e-5, 5e-5, 1e-4]\n  batch_size:\n    values: [4, 8, 16]\ncommand:\n  - ${env}\n  - ${interpreter}\n  - ${program}\n  - \"--run_name\"\n  - \"${batch_size}_${learning_rate}\"\n  - ${args}\n<\/code><\/pre>\n<p>Note that when passing the <code>--run_name<\/code> argument I would like to condition it on the values of the search parameters <code>batch_size<\/code> &amp; <code>learning_rate<\/code>. I do not want to do this inside my code because the format might change between sweeps and I want my code to be generic.<\/p>\n<p>Is there a way to use the search parameters in other arguments? I tried using <code>${args_no_hyphens}<\/code> before my command so the variables would be defined but it didn\u2019t seem to work.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hide Command from Overview Run Page",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hide-command-from-overview-run-page\/2231",
        "Question_created_time":"2022-04-13T00:53:59.532Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":270,
        "Question_body":"<p>On the Run Page (<a href=\"https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page\">https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page<\/a>) it shows on the left incognito that it shouldn\u2019t show your command when the public is viewing your page.<\/p>\n<p>However, on my page, when public and I view as not-me, it still shows the command that launched it, and that includes my Windows username, which I\u2019d rather not. I can\u2019t find anything to override or hide this. What am I missing?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Information in tables disappearing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/information-in-tables-disappearing\/2215",
        "Question_created_time":"2022-04-11T05:26:21.916Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":287,
        "Question_body":"<p>Hello!<\/p>\n<p>I have 39 runs in an experiment, all correctly finished with the corresponding tables per run correctly uploaded and available (when clicking on the specific run).<\/p>\n<p>I have 4 different tables, and combine the runs depending on the table ID (runs .summary[\u201ca\u201d], runs .summary[\u201cb\u201d], \u2026).<\/p>\n<p>2 of the combined tables are correctly outputted, but in 1 of the tables there is half the data available, and in the other a message of \u201cno rows to display\u201d is shown. If I re-upload the data of the \u201cno rows to display\u201d table, it is shown properly, but another table becomes empty, with the \u201cno rows to display\u201d message.<\/p>\n<p>Probably is due to the amount of rows can be processed at the same time? The total number of rows per run is 42, so 39x42 = 1638, which shouldn\u2019t be that much?<\/p>\n<p>Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to continue a specific run after stopping?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-continue-a-specific-run-after-stopping\/2074",
        "Question_created_time":"2022-03-14T15:59:44.759Z",
        "Question_answer_count":7,
        "Question_score_count":1,
        "Question_view_count":2779,
        "Question_body":"<p>Hello, I am new to using wandb and I cant seem to wrap my head around how to continue a run after i stop it. I tried the wandb.restore and loading the weights from the \u201cwandb\\run-20220313_020710-18ws9vua\\files\u201d , but i seem to get the following error : \u201cwandb.errors.CommError: Could not find run\u201d .<br>\nIt seems that the run isn\u2019t unique? Do i need to set up something in the init ? Or am I just going about it all wrong?<br>\nThank you very much for your time !<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Invalid apollo response An application error occurred",
        "Question_link":"https:\/\/community.wandb.ai\/t\/invalid-apollo-response-an-application-error-occurred\/2228",
        "Question_created_time":"2022-04-12T19:42:36.780Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":160,
        "Question_body":"<p>I am getting \u201cinvalid apollo response An application error occurred.\u201d when accessing the any sweep via the UI. The rest seems to work, e.g. I can access all my runs in the UI. What is going on here, how can i fix this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb not logging git commit\/hash",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-not-logging-git-commit-hash\/2197",
        "Question_created_time":"2022-04-07T18:47:49.284Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":349,
        "Question_body":"<p>Hi,<\/p>\n<p>When I first used wandb, I did find that wandb automatically logs the git commit hash when I ran experiments. However, recently, I found that it stops doing so. Namely, I cannot find any git information on the \u201coverview\u201d page of each experiment. Does anyone have some guesses on what might be the cause? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Exporting GPU utilization, power usage data",
        "Question_link":"https:\/\/community.wandb.ai\/t\/exporting-gpu-utilization-power-usage-data\/2194",
        "Question_created_time":"2022-04-07T08:59:03.188Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":641,
        "Question_body":"<p>I\u2019ve been wanting to export the data on GPU usage for my algorithm, but when I export the CSV file there is a single line which does not contain all the data.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b17a445f7fc35f370a78c8a4d9ea242ef5797b42.png\" data-download-href=\"\/uploads\/short-url\/pk2t25q25HlYQzj2LOJ1W7xb1e2.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b17a445f7fc35f370a78c8a4d9ea242ef5797b42.png\" alt=\"image\" data-base62-sha1=\"pk2t25q25HlYQzj2LOJ1W7xb1e2\" width=\"690\" height=\"35\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b17a445f7fc35f370a78c8a4d9ea242ef5797b42_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1893\u00d797 7.21 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>For some reason all other data exports work, but any data which has to do with the GPU does not. I have 4 GPUs. The plot shows the right data:<\/p>\n<p>I could also not find the complete data using the API. Is this a bug?<\/p>\n<p>Best,<\/p>\n<p>Mario<\/p>",
        "Question_closed_time":"2022-04-07T20:15:51.468Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/meerio\">@meerio<\/a>,<\/p>\n<p>You should be able to retrieve your System Metrics history from the run using the following line of code:<\/p>\n<pre><code class=\"lang-python\">metrics = run.history(stream='events')\n<\/code><\/pre>\n<p>where <code>run<\/code> is a <code>Run<\/code> object accessed through the API. This should allow you to access all your system metrics data. Please let me know if this does not work for you or if you need any further assistance.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to remove myself from a team?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-remove-myself-from-a-team\/2201",
        "Question_created_time":"2022-04-08T12:50:46.846Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":115,
        "Question_body":"<p>I don\u2019t have admin access to a team and want to remove myself from the said team. There are other admin users, but say I can\u2019t communicate with them, how to remove myself?<\/p>",
        "Question_closed_time":"2022-04-08T13:28:00.723Z",
        "Answer_body":"<p><a class=\"mention\" href=\"\/u\/sai_prasanna\">@sai_prasanna<\/a> no problem! You\u2019ve been removed from \u201cagara\u201d. Is there anything else I can help with?<\/p>\n<p>Thank you,<br>\nNate<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb Comm Error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-comm-error\/2093",
        "Question_created_time":"2022-03-16T10:03:29.705Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_body":"<p>Hi I am facing below problem while trying to run sweeps using wandb.<\/p>\n<p>wandb: Program failed with code 1.  Press ctrl-c to abort syncing.<br>\nwandb: ERROR Error uploading \u201ccode\/wandb_hyperparameter.py\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cwandb-metadata.json\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cwandb-summary.json\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cconfig.yaml\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201crequirements.txt\u201d: CommError, &lt;Response [400]&gt;<\/p>\n<p>Please help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error in callback",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-in-callback\/2175",
        "Question_created_time":"2022-03-31T18:04:40.180Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":218,
        "Question_body":"<pre><code class=\"lang-auto\">Error in callback &lt;function _WandbInit._resume_backend at 0x7f84f11b49d0&gt; (for pre_run_cell):\n<\/code><\/pre>\n<p>If I stop a run in a Paperspace Gradient jupyter notebook and then try to execute any cell I receive the above error.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Will multiple runs in the same folder <del>sync<\/del>resume properly?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/will-multiple-runs-in-the-same-folder-del-sync-del-resume-properly\/2180",
        "Question_created_time":"2022-04-02T07:21:29.352Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":319,
        "Question_body":"<p>Edit: I think I did not express my problem correctly, I was concerned that if there are multiple runs in the same directory and some runs crashed, could wandb resume automatically if I pass the <code>resume=True<\/code> parameter to <code>wandb.init<\/code>.<\/p>\n<p>The answer is no, apparently.  I think either <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#automatic-and-controlled-resuming\">controlled resuming<\/a> or running from different working directories is mandatory in this case.<\/p>\n<hr>\n<p><del>Hi, I wonder if wandb can sync properly if I start multiple runs simultaneously in the same project root?<\/del><\/p>\n<p><del>I was using wandb with only 1 GPU and it worked splendidly, now I want to use the same codebase on a machine with 2 GPUs.  I have already started a run with <code>CUDA_VISIBLE_DEVICES=0<\/code>, now I want to start another run with <code>CUDA_VISIBLE_DEVICES=1<\/code> in a new shell session, but in the same directory as the first run.  I noticed that the <code>wandb\/<\/code> directory in the project root seems to track only the latest run (there is a symlink called <code>latest-run<\/code>), my question is, <strong>if I start another run in the same directory while the first one is running, will <code>wandb<\/code> mess it up<\/strong>?  If it does mess up, is cloning the codebase to another path and run there my best option?  Or if wandb can properly handle the situation mentioned above, is there any caveats I should be aware of?<\/del><\/p>\n<p>Thanks for reading through, any help would be greatly appreciated.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Has anyone used wandb sweeps and torch.distributed before?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/has-anyone-used-wandb-sweeps-and-torch-distributed-before\/2184",
        "Question_created_time":"2022-04-04T01:04:36.622Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":140,
        "Question_body":"<p>Hi! My first time posting here. One of my code bases uses torch.distributed for distributed training over different GPUs. Currently, I am writing .sh scripts to deal with hyperparameter sweeping. I was wondering if anyone had experience with using wandb sweep functionality to launch sweeps for torch.distributed training scripts.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to live log arbitrary line graph",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-live-log-arbitrary-line-graph\/2168",
        "Question_created_time":"2022-03-29T20:39:20.998Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":179,
        "Question_body":"<p>I\u2019m running active learning experiments where the result is some model performance metric against dataset size.  I\u2019ve seen the below code example:<\/p>\n<pre><code class=\"lang-auto\">data = [\ufeff[x, y] for (x, y) in zip\ufeff(x_values, y_values)\ufeff]\ntable = wandb.Table(data=data, columns = [\ufeff\"x\"\ufeff, \"y\"\ufeff]\ufeff)\nwandb.log(\ufeff{\ufeff\"my_custom_plot_id\" : wandb.plot.line(table,\n                                 \"x\"\ufeff, \"y\"\ufeff, title=\ufeff\"Custom Y vs X Line Plot\"\ufeff)\ufeff}\ufeff)\n<\/code><\/pre>\n<p>but this seems to be for static graph generation once you have access to all the data.<\/p>\n<p>How do I generate a live updating graph of model performance against dataset size?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best practice to efficiently log GPU PyTorch tensors to wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/best-practice-to-efficiently-log-gpu-pytorch-tensors-to-wandb\/2037",
        "Question_created_time":"2022-03-08T02:43:59.218Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":202,
        "Question_body":"<p>Hi there,<\/p>\n<p>I am using reinforcement learning and have quite a complicated training procedure. To make sure everything is working properly it is important to me to log as much as I can to my wandb dashboard. However most of these quantities are PyTorch tensors on GPU and the way I am logging seems quite inefficient.<\/p>\n<p>My current logging setup looks something like this<\/p>\n<pre><code class=\"lang-auto\">batch_d = dict()\nbatch_d['logp']        =           logp.detach().cpu().tolist()\nbatch_d['loss']        =           loss.detach().cpu().tolist()\nbatch_d['loss_sum']    =       loss_sum.detach().cpu().tolist()\nbatch_d['loss_batch']   =    loss_batch.detach().cpu().tolist()\n# ... ~10 other similar things tracked here too\n# ...convert quantities to wandb Histograms and similar\nwandb.log(batch_d)\n<\/code><\/pre>\n<p>However all this detaching and moving to cpu slows down performance (e.g. as mentioned by this <a href=\"https:\/\/towardsdatascience.com\/7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259\" rel=\"noopener nofollow ugc\">article<\/a> on PyTorch efficiency). Hence I was wondering if there was a better way I can log all these quantities.<\/p>\n<p>Thanks,<\/p>\n<p>Tom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Download Report as LaTeX not working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/download-report-as-latex-not-working\/2182",
        "Question_created_time":"2022-04-03T20:19:23.494Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":124,
        "Question_body":"<p>Hey,<\/p>\n<p>I\u2019m trying to download a <a href=\"https:\/\/wandb.ai\/dezzardhd\/eval_finals\/reports\/P1850-dim16--VmlldzoxNzc0NzA3?accessToken=7f0xyvcyq6j27xipyvuwhgbm9237uf2uft18zxt0kyhlutbg5b1ynodog330pqpa\">report<\/a> as LaTeX.<br>\nThe images and tables are not being downloaded. The folders contained in the zip archive are empty.<\/p>\n<p>That\u2019s a bug I guess.<\/p>\n<p>DezzardHD<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Agent bug? File not found error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/agent-bug-file-not-found-error\/2109",
        "Question_created_time":"2022-03-18T09:03:02.106Z",
        "Question_answer_count":11,
        "Question_score_count":2,
        "Question_view_count":3776,
        "Question_body":"<p>Hi I\u2019m using kaggle with Pytorch and W&amp;B<\/p>\n<ul>\n<li>Weights and Biases version: 0.12.11<\/li>\n<li>Python version: 3.7.12<br>\n<strong>Description:<\/strong><br>\nWhen using the attached notebook I get the following error:<br>\n[<a href=\"https:\/\/www.kaggle.com\/code\/wojtekddl\/license-plate-w-b\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">License-plate-w&amp;b | Kaggle<\/a>]<\/li>\n<\/ul>\n<pre><code class=\"lang-auto\">wandb: Agent Starting Run: 9uvr1lj3 with config:\nwandb: \tbatch_size: 64\nwandb: \tdropout: 0.2\nwandb: \tdropout_lstm: 0.1\nwandb: \tepochs: 8\nwandb: \thidden_size: 32\nwandb: \tlinear_output: 64\nwandb: \tmodels: PlateLUX_2GRU\nwandb: \toptimizer: RMSprop\nwandb: \tscheduler: ReduceLROnPlateau\nwandb: Currently logged in as: wualas (use `wandb login --relogin` to force relogin)\nTracking run with wandb version 0.12.11\nRun data is saved locally in \/kaggle\/working\/wandb\/run-20220318_082708-9uvr1lj3\nSyncing run winter-sweep-1 to Weights &amp; Biases (docs)\nSweep page: https:\/\/wandb.ai\/wualas\/pytorch-sweeps-rejestracje_last\/sweeps\/7ioy5yu1\n\nWaiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nSynced winter-sweep-1: https:\/\/wandb.ai\/wualas\/pytorch-sweeps-rejestracje_last\/runs\/9uvr1lj3\nSynced 4 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: .\/wandb\/run-20220318_082708-9uvr1lj3\/logs\nRun 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')\nwandb: ERROR Run 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')\n<\/code><\/pre>\n<p>train_function:<\/p>\n<pre><code class=\"lang-auto\">def train(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n        df = pd.read_csv('\/content\/OCRdataset\/annotations_CRNN.csv')\n        df['filename'] = '\/content\/OCRdataset\/images\/' + df['filename'].astype(str)\n        image_files = df['filename'].tolist()\n        targets_orig = df['label'].tolist()\n        targets = [[c for c in x] for x in targets_orig]\n        targets_flat = [c for clist in targets for c in clist]\n\n        lbl_enc = preprocessing.LabelEncoder()\n        lbl_enc.fit(targets_flat)\n        targets_enc = [lbl_enc.transform(x) for x in targets]\n        targets_enc = np.array(targets_enc)\n        targets_enc = targets_enc + 1\n\n        (\n        train_imgs,\n        test_imgs,\n        train_targets,\n        test_targets,\n        _,\n        test_targets_orig,\n        ) = model_selection.train_test_split(\n        image_files, targets_enc, targets_orig, test_size=0.1, random_state=42\n        )\n        num_chars=len(lbl_enc.classes_)\n        train_loader, test_loader = build_loader(train_imgs, train_targets, test_imgs, test_targets, config.batch_size)\n        model = build_network(config.models, num_chars, config.linear_output, config.hidden_size, config.dropout, config.dropout_lstm)\n        optimizer = build_optimizer(model, config.optimizer)\n        scheduler = build_scheduler(optimizer, config.scheduler)\n\n        train_loss_tab = []\n        test_loss_tab = []\n        accuracy_tab = []\n        best_test_loss = 100000000000000\n        for epoch in range(config.epochs):\n            train_loss = train_fn(model, train_loader, optimizer)\n            valid_preds, test_loss = eval_fn(model, test_loader)\n            valid_captcha_preds = []\n            for vp in valid_preds:\n                current_preds = decode_predictions(vp, lbl_enc)\n                valid_captcha_preds.extend(current_preds)\n            combined = list(zip(test_targets_orig, valid_captcha_preds))\n            print(combined)\n            test_dup_rem = [remove_duplicates(c) for c in test_targets_orig]\n            accuracy = metrics.accuracy_score(test_dup_rem, valid_captcha_preds)\n            print(\n              f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}\"\n            )\n            exloss = calculate_EXACTloss(combined)\n            scheduler.step(test_loss)\n            #torch.save(model.state_dict(), \"\/content\/epoch_save\/EPOCH_SAVER_CRNN_state_dict3{}.pt\".format(epoch))\n            # dopisac zapisywanie kazdego modelu\n            train_loss_tab.append(train_loss)\n            test_loss_tab.append(test_loss)\n            accuracy_tab.append(accuracy)\n            print(\"zapisuje\")\n            wandb.log({'epoch': epoch, 'loss_test': test_loss, 'loss_train': train_loss, 'accuracy': accuracy, 'EXACTacc' : exloss})\n<\/code><\/pre>\n<p>Is there an error how I\u2019m using wandb or is this a bug?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pytorch sync_tensorboard help",
        "Question_link":"https:\/\/community.wandb.ai\/t\/pytorch-sync-tensorboard-help\/1017",
        "Question_created_time":"2021-10-17T19:51:24.534Z",
        "Question_answer_count":8,
        "Question_score_count":1,
        "Question_view_count":802,
        "Question_body":"<p>I\u2019m having some issues getting W&amp;B to sync with Tensorboard in PyTorch. According to this <a href=\"https:\/\/github.com\/wandb\/client\/issues\/493\" rel=\"noopener nofollow ugc\">issue<\/a> and the docs, I should initializing <code>SummaryWriter<\/code> after W&amp;B  <code>init<\/code> possibly using <code>wandb.tensorboard.patch<\/code>. So far I haven\u2019t been able to get this to work with either <code>torch.utils.tensorboard<\/code> or <code>tensorboardX<\/code> and with or without the patch. Not sure if this is a bug or I\u2019m missing something. Thanks.<\/p>\n<p>Windows 11<br>\nPython 3.8.8<br>\nwandb 0.12.4<br>\ntorch 1.9.1<\/p>\n<pre><code class=\"lang-auto\"> wandb.tensorboard.patch(root_logdir=\"logs\")\n wandb.init(config=hyperparameter_defaults, project=f\"ppo_{env_name}_torch\", sync_tensorboard=True, save_code=True, name=run_name)\n config = wandb.config\n writer = SummaryWriter(f\"logs\")\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accidentally deleted user account in local - is there any way to recover user or projects?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/accidentally-deleted-user-account-in-local-is-there-any-way-to-recover-user-or-projects\/2163",
        "Question_created_time":"2022-03-28T13:37:08.027Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":119,
        "Question_body":"<p>While investigating an unrelated issue I incorrectly thought there was something wrong with the user as the local instance was having issues in the GUI. I tried a lot of troubleshooting steps, one of which I think included an attempt to recreate the account.<\/p>\n<p>Is there a way to recover the data associated with the old account or to recover the account itself? I tried to dig around myself and found entries relating to the old user in the mysql database and was hopeful there was a way I could recreate the account or recover the data to a new user in our local instance.  Is this at all possible?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Image plotting tells lies(samples are not from the same iteration when not trained)!",
        "Question_link":"https:\/\/community.wandb.ai\/t\/image-plotting-tells-lies-samples-are-not-from-the-same-iteration-when-not-trained\/2047",
        "Question_created_time":"2022-03-08T23:42:45.898Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":195,
        "Question_body":"<p>As you can see, when I push the image slider to 13500, while the red model is not trained yet to that iteration, the wandb shows a sample for it. I guess it is the last sample of the model, but wandb I guess at least show exactly from which iteration this image is coming from because I think this way is misleading. I mean, if someone does not pay attention they may think they are comparing the quality of the samples at the same number of iterations.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d.jpeg\" data-download-href=\"\/uploads\/short-url\/ySQOUszDVHpVqz8QnJLmnU2HItf.jpeg?dl=1\" title=\"Screen Shot 2022-03-08 at 6.27.10 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_690x447.jpeg\" alt=\"Screen Shot 2022-03-08 at 6.27.10 PM\" data-base62-sha1=\"ySQOUszDVHpVqz8QnJLmnU2HItf\" width=\"690\" height=\"447\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_690x447.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_1035x670.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_1380x894.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-03-08 at 6.27.10 PM<\/span><span class=\"informations\">2332\u00d71512 177 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Homogenizing x-axis among plots",
        "Question_link":"https:\/\/community.wandb.ai\/t\/homogenizing-x-axis-among-plots\/2132",
        "Question_created_time":"2022-03-22T12:47:39.189Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":195,
        "Question_body":"<p>Hello WandB community,<\/p>\n<p>I am having trouble doing something that I believe should be pretty straightforward. <a href=\"https:\/\/wandb.ai\/catai\/MIDL%2010%20splits?workspace=user-carloshernandezp\">Here is the link to the Dashboard<\/a><\/p>\n<p>I am training ten different splits on some data and I am logging some metrics, pretty standard stuff. Specifically I am logging some training and validation. Whenever the Validation Area Under Curve (<code>Val AUC<\/code>) surpasses the previous highest, I compute some metrics for the Test Set.  After the training script is done, I download all the information in <code>.csv<\/code> files<\/p>\n<p>The problem arises when comparing plots as the <code>X-axis<\/code> or <code>Step<\/code> is different for each one. For example: if we take a look at the run <code>Pleasant-elevator-24<\/code> the highest <code>Val AUC<\/code> happens at <code>Step<\/code> 530. But the logged value of  <code>Test auc<\/code> is at 530.<\/p>\n<p>What I would like to have the <code>X Steps<\/code> of all the plots synced.<\/p>\n<p>My code to plot this is the following:<\/p>\n<pre><code class=\"lang-auto\">if max_auc&lt;metrics[0] and epoch &gt;5:\n          max_auc = metrics[0]\n          torch.save(model.state_dict(), os.path.join(args.results_dir, \"s_{}_{}_checkpoint.pt\".format(round(metrics[0],3), cur)))\n          wandb.log({\"P-R curve\" : wandb.plot.pr_curve(metrics[1], metrics[2], labels=['Negative', 'Positive'])})     \n    \n          results_dict, test_error, test_auc, acc_logger, metrics_test = summary(model, test_loader, args.n_classes)    \n    \n          wandb.log({\"P-R curve test\" : wandb.plot.pr_curve(metrics_test[1], metrics_test[2], labels=['Negative', 'Positive'])})   \n          wandb.log({'Test auc' : metrics_test[0], \n                  'Test bal acc' : metrics_test[3],\n                  'Test sensitivity': metrics_test[4],\n                          'Test specificity': metrics_test[5]})\n<\/code><\/pre>\n<p>Is there a way in which I can solve this issue without having to re-run the experiments again?<\/p>\n<p>Maybe I am getting something wrong here, I appreciate all the help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logged value available in graph panel, but not in columns",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logged-value-available-in-graph-panel-but-not-in-columns\/2100",
        "Question_created_time":"2022-03-17T09:28:30.562Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":653,
        "Question_body":"<p>I log values which have names in the form of <code>test\/temp_top-k.---1<\/code> (I want the dashes for sorting reasons). I can create graph panels with these values, but they do not show up in the column view. When I <code>Manage Columns<\/code> they are not listed in the <code>Hidden Columns<\/code>. When I search for them, it gives me no (an empty) result. Even when I select <code>Show All<\/code> they don\u2019t show up in the column view. A bug?<\/p>",
        "Question_closed_time":"2022-03-22T21:38:19.859Z",
        "Answer_body":"<p>Hi Leslie,<\/p>\n<p>I apologize for not responding earlier. I assumed to be notified by e-mail when this thread is updated. Probably I need to check my settings, or \u201cwatch\u201d this thread.<\/p>\n<p>I log via Pytorch Lightning:<\/p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=settings.project_name, log_model=True)\nwandb_logger.watch(model, log='gradients', log_freq=50, log_graph=True)\n<\/code><\/pre>\n<p>The actual code for the logging is this:<\/p>\n<pre><code class=\"lang-auto\">temp_accs_top_k = {f'{k:-&gt;4d}': v for k, v in zip(settings.ks, temp_accs)}\nlightning_module.log(f'{split}\/temp_top-k', temp_accs_top_k, batch_size=lightning_module.batch_size)\n<\/code><\/pre>\n<p>That looks a bit odd I suppose. The code is in a function that I call from several different <code>pl.LightningModule<\/code>s. The variable <code>lightning_module<\/code> refers to that module. The parameter <code>temp_accs_top_k<\/code> evaluates to (straight from the debugger):<\/p>\n<p><code>{'---1': 0.00019996000628452748, '---2': 0.00019996000628452748, '---3': 0.00039992001256905496, '---5': 0.0005998800043016672, '--10': 0.0005998800043016672, '--20': 0.001399720087647438, '--50': 0.004199160262942314, '-100': 0.007598480209708214, '1000': 0.08318336308002472}<\/code><\/p>\n<p>Which is wrong. But I am seeing the values in the graph panels (see attached screenshot).<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ae06dc0b1399ce16eb917dfb94b60a5e0f77acd.png\" alt=\"Screen Shot 2022-03-22 at 21.52.37\" data-base62-sha1=\"8oQwPNwBrsRhQBp0p6SuZ6ht6NL\" width=\"412\" height=\"275\"><\/p>\n<p>I changed the code so that <code>temp_accs_top_k<\/code>now contains <code>{'test\/temp_top-k.---1': 0.2963850498199463, 'test\/temp_top-k.---2': 0.3962452709674835, 'test\/temp_top-k.---3': 0.44557619094848633, 'test\/temp_top-k.---5': 0.5052925944328308, 'test\/temp_top-k.--10': 0.5733972191810608, 'test\/temp_top-k.--20': 0.6277211904525757, 'test\/temp_top-k.--50': 0.6810465455055237, 'test\/temp_top-k.-100': 0.716596782207489, 'test\/temp_top-k.1000': 0.802676260471344}<\/code>.<\/p>\n<p>I log in a loop since Pytorch Lightning can\u2019t log a dict (I believe). I know that wandb does it, but I need the batch_size parameter (I have two dataloaders with different sizes\/lenghts and need to make sure that Pytorch Lightning does not get confused with steps\/epochs).<\/p>\n<pre><code class=\"lang-auto\">for k, v in temp_accs_top_k.items():\n    lightning_module.log(k, v, batch_size=lightning_module.batch_size)\n<\/code><\/pre>\n<p>Update: just realized that Pytorch Lightning has a <code>log_dict<\/code> function which lets me get rid of the awkward for loop.<\/p>\n<p>So the \u201cbug\u201d is more like \u201cwhy did it work in the first place (in the graph panels)?\u201d<\/p>\n<p>Hope that\u2019s not too much to digest and it is traceable.<\/p>\n<p>Best,<br>\nStephan<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Sweep - starting with a small project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-starting-with-a-small-project\/2075",
        "Question_created_time":"2022-03-14T16:04:43.323Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":144,
        "Question_body":"<p>Hi there,<br>\nI\u2019m new to W&amp;B and try to use sweep to find best parameters for MNIST with tf2.<\/p>\n<p>First, I ran sweep agent and I\u2019ve got this issue  that I don\u2019t understand where it comes from\u2026<br>\nAttributeError: module \u2018wandb\u2019 has no attribute \u2018init\u2019<br>\nIt doesn\u2019t appear when I 'm not using any agent.<\/p>\n<p>Second it\u2019s not clear to me if it\u2019s mandatory to put the hyperparameters as command line arguments. I\u2019m using a json file to fill the default values. I thought I would use this kind of file to configure the sweep.<\/p>\n<p>Where exactly do we have to run the agent? My script train.py is in a folder, source code in another, and my experiment in a third one. I would have like to put the sweep.yaml with my experiments.  Is there a way to put the script and the yaml file in a different folder?<\/p>\n<p>Thanks for your help<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Re run a previous config",
        "Question_link":"https:\/\/community.wandb.ai\/t\/re-run-a-previous-config\/2068",
        "Question_created_time":"2022-03-14T10:27:35.310Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":196,
        "Question_body":"<p>Hi,<\/p>\n<p>In my project lifetime I have many similar sweeps, such that each one is slightly different or even exactly like a previous sweep (for instance after a bug fix). In order to execute the same sweep again, I navigate to the previous sweep, copy the configuration, and paste that configuration in the new sweep. Is there a way to name and save a previous config and load it?<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delete my account",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-my-account\/2116",
        "Question_created_time":"2022-03-19T08:35:14.265Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":143,
        "Question_body":"<p>Can you delete my account please? Username is cengizk<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Averaging over runs with the same seed in a sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/averaging-over-runs-with-the-same-seed-in-a-sweep\/2110",
        "Question_created_time":"2022-03-18T09:49:35.964Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":180,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I am currently running a sweep to do hyperparameter search on a set of parameters and a seed. What I would like to do is have the results averaged over the different seeds, so that for each group of runs sharing the same hyperparameters but different seeds I only have one value.<br>\nI already tried grouping them by all the parameters except the seed in the GUI, but I obtain a hierarchical grouping (split over each hyparaparameter) which is not what I would expect.<br>\nI think that I will have to go through the API and add a new group to the runs with the same hyperparameters and then group by that group. Is there anything else I can do?<\/p>\n<p>Thank you in advance for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.watch with pytorch not logging anything",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-watch-with-pytorch-not-logging-anything\/2096",
        "Question_created_time":"2022-03-16T17:08:21.888Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":1548,
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use <code>wandb.watch<\/code> for a pytorch model, unfortunately without success. I checked the documentation and these two threads:<\/p>\n<ul>\n<li>Wandb.watch not logging parameters<\/li>\n<li>When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?<\/li>\n<\/ul>\n<p>But none of the suggested solutions solves my problem. I run in my environment the code from the colab notebook linked in <a href=\"https:\/\/community.wandb.ai\/t\/when-is-one-supposed-to-run-wandb-watch-so-that-weights-and-biases-tracks-params-and-gradients\/518\/3\">this post<\/a> (with <code>N, log_freq = 50, 2<\/code>) and still nothing is logged.<\/p>\n<p>Interestingly, if I set the <code>log_graph=True<\/code> there is a JSON file logged as a file, under <code>root \/ media \/ graph<\/code> in the files section. But I was expecting to get a result similar to <a href=\"https:\/\/wandb.ai\/ayush-thakur\/debug-neural-nets\/runs\/jh061uaf\/model\">this<\/a>.<\/p>\n<p>I am using wandb version 0.12.10.<\/p>\n<p>Kind regards,<br>\nMaciej<\/p>",
        "Question_closed_time":"2022-03-18T08:58:43.663Z",
        "Answer_body":"<p>Hi,<\/p>\n<p>Eureka! Everything was working correctly, but I always use <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> with project view or run groups view. When I opened the run view both the graph and gradient were there <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>However, there is one problem remaining: <code>parameters<\/code>. When running the colab notebook code with <code>wandb.watch(d, log_freq=log_freq, log=\"all\")<\/code> I still can see only gradients in the run view.<\/p>\n<p><a href=\"https:\/\/wandb.ai\/dmml-heg\/uncategorized\/runs\/2qovzwq9\">Link to run page<\/a>  executed with wandb version 0.12.11 in Google Colab.<\/p>\n<p>EDIT: I found it <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Code in the notebook was using <code>forward()<\/code> instead of <code>__call__()<\/code>. Forward hooks were not executed.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"No history data in custom charts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/no-history-data-in-custom-charts\/2087",
        "Question_created_time":"2022-03-15T14:03:29.602Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":366,
        "Question_body":"<p>Hi everyone,<br>\nI have been running a sweep with wandb and logged data (loss, accuracy, val_loss, val_accuracy) via wandb.keras.WandbCallback(). All plots over all epochs are plotted nicely in the main panel, but now I would like to create some custom charts. To be able to do that, I have tried to use the <code>history<\/code> field in the query but seems like it\u2019s empty. On the other hand, <code>summary<\/code> field seems okay (as can be seen in the screenshot).<br>\nHow do I get access to all these metrics logged in each epoch?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png\" data-download-href=\"\/uploads\/short-url\/2HpHLfFrQu2aAy7Cy1j9wzzaZQ2.png?dl=1\" title=\"Screenshot 2022-03-15 at 15.01.54\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_690x384.png\" alt=\"Screenshot 2022-03-15 at 15.01.54\" data-base62-sha1=\"2HpHLfFrQu2aAy7Cy1j9wzzaZQ2\" width=\"690\" height=\"384\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_690x384.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-03-15 at 15.01.54<\/span><span class=\"informations\">890\u00d7496 35.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Could wandb be used in the inference?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/could-wandb-be-used-in-the-inference\/2077",
        "Question_created_time":"2022-03-14T21:16:47.497Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":170,
        "Question_body":"<p>Could wandb be used in the inference stage? I\u2019m specifically interested in collecting system metrics during inference.  I\u2019m working with DeepSpeed and torch profile and would to know if wandb could be useful in the inference as well.<\/p>",
        "Question_closed_time":"2022-03-14T22:18:07.748Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/eneas-jr\">@eneas-jr<\/a>,<\/p>\n<p>Yes, wandb can definitely be used at inference time as well to record system metrics. <code>wandb<\/code> will record system metrics in between the calls to <code>wandb.init()<\/code> and <code>wandb.finish()<\/code>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to access the data of specific step in the dashboard of wandb.ai?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-access-the-data-of-specific-step-in-the-dashboard-of-wandb-ai\/2017",
        "Question_created_time":"2022-03-04T14:20:51.386Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":210,
        "Question_body":"<p>I am using the dashboard of wandb and want to access the specific step data. However, I can only obtain the metric throughout the whole training step. For example, I wanna get the best mAP in COCO evaluation, and corresponding AP50, AP70 and other evaluation metrics.<\/p>\n<p>Need help. Thanks for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging all summary metrics based on the max of one",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-all-summary-metrics-based-on-the-max-of-one\/1836",
        "Question_created_time":"2022-01-28T23:16:27.613Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":185,
        "Question_body":"<p>If you\u2019re doing something like early stopping, you might simply save the model with the best loss and let it run for 10 more epochs, but discard those model weights.  I see that for individual metrics I can tell it to store the \u201cmax\u201d or \u201cmin\u201d, but what if I want the entire summary to happen based on a single metric\u2019s max\/min?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Grouping custom metrics by configuration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/grouping-custom-metrics-by-configuration\/1995",
        "Question_created_time":"2022-03-01T13:09:53.637Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":390,
        "Question_body":"<p>Hi, I started using WandB today together with PyTorch Lightning.<\/p>\n<p>I am using a <code>LightningModule<\/code> which retrieves the input data and labels. I have also associated each input\/output pair with json configuration file which describes the capture environment (e.g., if it is multi host or single host, bandwidth, delay, BDP factor). I know how to log values such as F1 score and accuracy for each sample but I am confused how to associate each value with a configuration. Is there any guides available that addresses this or something similar?<\/p>\n<p>For instance, in <code>test_step<\/code> from the LightningModule I have<\/p>\n<pre><code class=\"lang-auto\">def test_step(self, batch, batch_idx):\n  x, y, config_file =  batch\n  y_pred = self.forward(x)\n  loss = self.loss(y_pred, y)\n  self.log(\"test\/loss\", loss)\n  return loss\n<\/code><\/pre>\n<p>I would like to do something like this:<\/p>\n<pre><code class=\"lang-auto\">def test_step(self, batch, batch_idx):\n  x, y, config_file =  batch\n  y_pred = self.forward(x)\n  loss = self.loss(y_pred, y)\n  self.log(\n    \"test\/loss\", \n    loss, \n    configuration = {\n      \"delay\": \"10ms\",\n      \"BDP\": 3,\n       # etc ...\n    }\n  )\n  return loss\n<\/code><\/pre>\n<p>The <code>config_file<\/code> is a json file with <code>configuration<\/code>.<\/p>\n<p>My guess is that I could probably change <code>\"test\/loss\"<\/code> to  <code>\"test\/loss\/10ms\/3\"<\/code>, but I am not sure if this is the best way to go about it, how would the charts look in the w&amp;b dashboard? I want to be able to compare different environment settings somehow.<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Loading a saved table to pandas dataframe",
        "Question_link":"https:\/\/community.wandb.ai\/t\/loading-a-saved-table-to-pandas-dataframe\/2063",
        "Question_created_time":"2022-03-11T22:29:56.200Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":446,
        "Question_body":"<p>Hi, I have been recently using wandb a lot in my projects and it is really helpful.<\/p>\n<p>my issue is that I an trying access the logged tables as a pandas dataframe in a program. I check the documentation and tried the solution mentioned in the <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/log-tables#access-tables-programmatically\">documentation here<\/a>.  Once I run this instead of getting the table it returns a dictionary like this<\/p>\n<pre><code class=\"lang-auto\">{'artifact_path': 'wandb-client-artifact:\/\/sx4urflmwtczzq7zf71hsfxkill8hqrnd8o4uirjbcswuuc29f0xxrq6nra7uo2kzsp8jmu4s2g53e7xl3xuyu4lfjiowz9v63r9fbn7d3r8ckmlz5lrkhncuyhr0e46:latest\/metrics.table.json', '_latest_artifact_path': 'wandb-client-artifact:\/\/sx4urflmwtczzq7zf71hsfxkill8hqrnd8o4uirjbcswuuc29f0xxrq6nra7uo2kzsp8jmu4s2g53e7xl3xuyu4lfjiowz9v63r9fbn7d3r8ckmlz5lrkhncuyhr0e46:latest\/metrics.table.json', 'path': 'media\/table\/metrics_2_491a3e34c6fcf4271cb2.table.json', 'size': 413, '_type': 'table-file', 'ncols': 9, 'nrows': 3, 'sha256': '491a3e34c6fcf4271cb2378f9a33ff5dc8c9cdb8268299b4f96b88151730ecad'}\n<\/code><\/pre>\n<p>It would be great if someone can help me to convert this to a table so that I can perform aggregations on the results.<\/p>\n<p>Thanks<br>\nPrateek<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Forgot password in local",
        "Question_link":"https:\/\/community.wandb.ai\/t\/forgot-password-in-local\/1959",
        "Question_created_time":"2022-02-21T12:53:45.579Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":286,
        "Question_body":"<p>What can I do when I forget my password in the local wandb?<br>\nIt seems that deleting or uninstalling  doesn\u2019t work.<\/p>",
        "Question_closed_time":"2022-03-09T00:10:28.353Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/nightmare4214\">@nightmare4214<\/a> ,<\/p>\n<p>Could you try the following steps?<\/p>\n<ul>\n<li>Log into the docker container using <code>docker exec -it wandb-local bash<\/code>\n<\/li>\n<li>Type <code>\/usr\/local\/bin\/local password EMAIL@ADDRESS.com<\/code> (where <code>EMAIL@ADDRESS.com<\/code> is your email)<\/li>\n<\/ul>\n<p>This should let you manually reset your password for the local instance and you should be able to log in through this. Please let me know if this does not work for you.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Can I plot the value of a metric at a single step?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/can-i-plot-the-value-of-a-metric-at-a-single-step\/1971",
        "Question_created_time":"2022-02-23T06:10:38.027Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":208,
        "Question_body":"<p>Typically, we can go to the table view to sort runs by their summary metrics. The summary metrics can simply be the last value logged, or it can be min\/max\/mean\/etc.<\/p>\n<p>However, say I have an evaluation process that runs over a number of steps\u2014say 600 steps. I\u2019d like to be able to figure out which run was the best after 10 steps, which was best after 100 steps, and so on. I can obviously log each of these as separate summary metrics. But is there a way to access these without knowing which steps I want ahead of time? Can I show them in either a table or a bar chart?<\/p>\n<p>Ideally, I\u2019d love to be able to slice into any line plot at a single point on the x-axis, and then just plot those points as a bar chart or table. Thanks for your help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb not compatible with Torch Script",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-not-compatible-with-torch-script\/1997",
        "Question_created_time":"2022-03-01T20:56:27.010Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":158,
        "Question_body":"<p>I\u2019m using wandb logging in conjunction with pytorch + pytorch lightning, and it seems like some of the code in wandb makes it so I cannot JIT my model into torchscript. Here\u2019s the error<\/p>\n<pre><code class=\"lang-auto\">torch.jit.frontend.UnsupportedNodeError: Set aren't supported:\n  File \"\/home\/peter\/catkin_ws\/src\/venv\/lib\/python3.8\/site-packages\/wandb\/wandb_torch.py\", line 355\n        \n            # hook has been processed\n            self._graph_hooks -= {id(module)}\n                                 ~ &lt;--- HERE\n        \n            if not self._graph_hooks:\n<\/code><\/pre>\n<p>is there a workaround for this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I get the version of an artifact?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-get-the-version-of-an-artifact\/2035",
        "Question_created_time":"2022-03-07T21:55:11.212Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":411,
        "Question_body":"<p>Hey,<br>\nI\u2019m trying to get the version of an artifact directly after logging my model (encoder) as an artifact to WandB.<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact)\nversion = artifact.version\n<\/code><\/pre>\n<p>Logging works so far, but\u2026<br>\nwhen trying to access the version of the artifact I get an error.<br>\n<strong>Error:<\/strong><\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/main.py\", line 48, in &lt;module&gt;\n    train_setups.start_training_sessions(project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/train_setups.py\", line 18, in start_training_sessions\n    model_pipeline(config, project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 84, in model_pipeline\n    save_model(model_ae=model, model_encoder=model_encoder, model_decoder=model_decoder)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 124, in save_model\n    version = artifact_enc.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_artifacts.py\", line 191, in version\n    return self._logged_artifact.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2899, in version\n    return self._assert_instance().version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2871, in _assert_instance\n    raise ValueError(\nValueError: Must call wait() before accessing logged artifact properties\n<\/code><\/pre>\n<p>What should I do now?<\/p>\n<p>For context:<br>\nI want to print out the version number with some other parameters so that I can easier start my evaluation process for certain runs.<\/p>\n<p>Best regards<br>\nDezzardHD<\/p>",
        "Question_closed_time":"2022-03-07T23:48:08.233Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dezzardhd\">@dezzardhd<\/a>,<\/p>\n<p>Could you try running your code as the following?<\/p>\n<pre><code class=\"lang-python\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact).wait()\nversion = artifact.version\n<\/code><\/pre>\n<p>Calling <code>wait()<\/code> after <code>log_artifact()<\/code> should resolve this for you.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Problems accessing web interface: \"rate limit exceeded\"",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problems-accessing-web-interface-rate-limit-exceeded\/2041",
        "Question_created_time":"2022-03-08T10:59:29.636Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":122,
        "Question_body":"<p>Hi,<\/p>\n<p>I am having trouble accessing the <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> web interface. I very often, yet not always, get error messages like \u201crate limit exceeded\u201d or \u201cThere was a problem rendering these panels\u201d.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b365941060b6ae0dc38310d95e97379e66323316.png\" data-download-href=\"\/uploads\/short-url\/pB164ekBeFRf2vXOzJZpRNGSnBQ.png?dl=1\" title=\"Screenshot_google-chrome_20220308104954_crop\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b365941060b6ae0dc38310d95e97379e66323316_2_690x254.png\" alt=\"Screenshot_google-chrome_20220308104954_crop\" data-base62-sha1=\"pB164ekBeFRf2vXOzJZpRNGSnBQ\" width=\"690\" height=\"254\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b365941060b6ae0dc38310d95e97379e66323316_2_690x254.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b365941060b6ae0dc38310d95e97379e66323316.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b365941060b6ae0dc38310d95e97379e66323316.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b365941060b6ae0dc38310d95e97379e66323316_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot_google-chrome_20220308104954_crop<\/span><span class=\"informations\">790\u00d7291 10.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Yesterday I had no problems at all. What\u2019s the issue?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Loading config values of a previous run to reproduce it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/loading-config-values-of-a-previous-run-to-reproduce-it\/1955",
        "Question_created_time":"2022-02-20T18:25:22.160Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":148,
        "Question_body":"<p>Hi all,<\/p>\n<p>Say I have a run that had a good result, and I want to re-run it. What would be the recommended way to do this? How can I download a previous run\u2019s config values to create a new run with the same config?<\/p>\n<p>Thanks, Carlos<\/p>",
        "Question_closed_time":"2022-02-22T14:39:05.458Z",
        "Answer_body":"<p>Hey Carlos, you can get the config by using our Public API. Here is a code snippet you can use:<\/p>\n<p>import wandb<br>\napi = wandb.Api()<\/p>\n<p>run = api.run(\"\/\/&lt;run_id&gt;\")<br>\nrun.file(\u201cconfig.yaml\u201d).download()<\/p>\n<p>You can also use the W&amp;B Launch feature which is in beta at the moment. Here is a <a href=\"https:\/\/docs.wandb.ai\/guides\/launch\">link<\/a> to the documentation.<\/p>\n<p>Best,<br>\nArman<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How does one \"migrate\" move a wandb repo from personal projects to school?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-migrate-move-a-wandb-repo-from-personal-projects-to-school\/1990",
        "Question_created_time":"2022-02-28T21:01:58.836Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":157,
        "Question_body":"<p>I\u2019ve been doing my experiments on my personal one by accident and wanted to move it\u2026to have everything centralized. How does one do it? What changes would I have to make to my script to push to the right places in wanbd? Other unexpected things I have to do?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Fail to show images when logging images in a project created in teams mode",
        "Question_link":"https:\/\/community.wandb.ai\/t\/fail-to-show-images-when-logging-images-in-a-project-created-in-teams-mode\/1936",
        "Question_created_time":"2022-02-16T09:50:03.760Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":180,
        "Question_body":"<p>We created a team and then added a project. while everything works when working with our personal space separately, in the project we created in the team space, images are not shown. Any ideas on how to fix it?<\/p>\n<p>please let me know what type of information I should provide here.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"AttributeError: 'EnumTypeWrapper' object has no attribute 'NOW'",
        "Question_link":"https:\/\/community.wandb.ai\/t\/attributeerror-enumtypewrapper-object-has-no-attribute-now\/1993",
        "Question_created_time":"2022-03-01T00:38:49.098Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":201,
        "Question_body":"<p>what I do can reslove this problem?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wanbd records wrong number of gpus and cpus when using a scheduler slurm or condor",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wanbd-records-wrong-number-of-gpus-and-cpus-when-using-a-scheduler-slurm-or-condor\/1982",
        "Question_created_time":"2022-02-25T19:20:25.884Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":147,
        "Question_body":"<p>I noticed it says there are 8 gpus and 24 cpus in the run but I scheduled a job with 1 gpu and 4 cpus. So I thought it would be good to report this since that seems like a bug. It should report\/record the actual amount is being used by my job. I assume the other plots graphs are wrong too\u2026if it says Iam not utilizing all the stuff is cuz I didn\u2019t ask for it\u2026<\/p>\n<p>Thought it would help to fix this eventually!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Constant Liar algorithm for sweeps?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/constant-liar-algorithm-for-sweeps\/1961",
        "Question_created_time":"2022-02-22T06:22:55.954Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":221,
        "Question_body":"<p>Hi,<\/p>\n<p>Just wondering if you have constant liar algorithm implemented internally for hyper-parameter suggestions in parallel. If I understand wandb API correctly, it is geared more for sequential suggestions, and considering our company can run pods in parallel, would be amazing if you guys can implement this on your end, rather than us hacking it on our end.<\/p>\n<p>The basic idea is that for the first pod (in a parllel set) it will suggest the hyper-parameters as usual, but for the 2nd and other pods starting now in parallel, it will send back the worst loss it has currently seen. The logic being that the next suggested hyper-parameters will be far away from ones suggested to first one. You could probably be smarter here since wandb has access to loss metrics as it trains, but that would be a side project.<\/p>\n<p>Here is a link with more depth: <a href=\"https:\/\/github.com\/microsoft\/nni\/blob\/98f66f76d310b0e0679823d966fdaa6adafb66c2\/docs\/en_US\/CommunitySharings\/ParallelizingTpeSearch.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">nni\/ParallelizingTpeSearch.md at 98f66f76d310b0e0679823d966fdaa6adafb66c2 \u00b7 microsoft\/nni \u00b7 GitHub<\/a><\/p>\n<p>Edit 1: follow up question, do you use anything more advanced than sklearn GPs for bayes search (basing my question on <a href=\"https:\/\/github.com\/wandb\/client\/blob\/master\/wandb\/sweeps\/bayes_search.py#L85\" rel=\"noopener nofollow ugc\">this<\/a>).<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error on torch.load for a run's saved file",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-on-torch-load-for-a-runs-saved-file\/1979",
        "Question_created_time":"2022-02-24T23:48:58.986Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":195,
        "Question_body":"<p>Hi,<br>\nI want to load a pt file of a run which is downloaded using  WandB api. but this error is raised:<br>\n<code>'utf-8' codec can't decode byte 0xaa in position 4: invalid start byte<\/code><\/p>\n<p>My code is:<\/p>\n<pre><code class=\"lang-python\">api = wandb.Api()\nruns = api.runs('USERNAME\/PROJ')\nmodel_path = list(list(runs)[0].files())[1].download()\nmodel = torch.load(model_path)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does wandb have a limit on how long it can be run and deadlocks?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/does-wandb-have-a-limit-on-how-long-it-can-be-run-and-deadlocks\/1933",
        "Question_created_time":"2022-02-15T19:50:41.495Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":154,
        "Question_body":"<p>I find that my scripts seem to halt on their own but they seem to deadlock or don\u2019t throw an error e.g. I was running a training script on my laptop but cuz it was on debug mode I was able to pause and it seemed to be stuck with some multiprocessing things and it seemed it was related to wandb\u2026<\/p>\n<pre><code class=\"lang-auto\">epoch_num=95: train_loss=1.861583555999555, train_acc=0.4987407624721527\nepoch_num=95: val_loss=tensor(7.3504), val_acc=tensor(0.)\n 16% (96 of 600) | | Elapsed Time: 7:47:13 | ETA:  1 day, 16:52:54 | 175.7 s\/it\nepoch_num=96: train_loss=1.8501708821246499, train_acc=0.5018503069877625\nepoch_num=96: val_loss=tensor(6.9187), val_acc=tensor(0.)\nException ignored in: &lt;Finalize object, dead&gt;\nTraceback (most recent call last):\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/multiprocessing\/util.py\", line 224, in __call__\n    res = self._callback(*self._args, **self._kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 88, in _cleanup\n    unregister(name, \"semaphore\")\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/multiprocessing\/resource_tracker.py\", line 151, in unregister\n    self._send('UNREGISTER', name, rtype)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/multiprocessing\/resource_tracker.py\", line 154, in _send\n    self.ensure_running()\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/multiprocessing\/resource_tracker.py\", line 75, in ensure_running\n    with self._lock:\nKeyboardInterrupt: \n<\/code><\/pre>\n<p>does wandb have some deadlock bug if it is ran for too long for a reallllyyyyyy long experiment?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a.jpeg\" data-download-href=\"\/uploads\/short-url\/hT5H9DiWLr9feqG3ZUqUHMsO3lE.jpeg?dl=1\" title=\"Screen Shot 2022-02-15 at 1.51.43 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_387x500.jpeg\" alt=\"Screen Shot 2022-02-15 at 1.51.43 PM\" data-base62-sha1=\"hT5H9DiWLr9feqG3ZUqUHMsO3lE\" width=\"387\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_387x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_580x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_774x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-02-15 at 1.51.43 PM<\/span><span class=\"informations\">1032\u00d71333 251 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add custom column in table reports the variance of a metric per group",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-custom-column-in-table-reports-the-variance-of-a-metric-per-group\/1938",
        "Question_created_time":"2022-02-16T11:07:25.094Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":144,
        "Question_body":"<p>Hello everyone,<\/p>\n<p>I\u2019 am using table view of wandb to compare different groups of multiple runs. Even thought table reports the mean of each group (e.x. training accuracy), do not reports the variance (std dev) of group\u2019s accuracies . Is there any way to add this per-group metric in my table view?<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I check whether an artifact is available?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-check-whether-an-artifact-is-available\/1826",
        "Question_created_time":"2022-01-27T16:18:12.817Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":229,
        "Question_body":"<p>Hi, just started to use W&amp;B and managed to refactor some code to use artifact versioning today. What I could not find is (and sorry if this is very basic): during the first run of the program I would like to check if there is already some artifact (raw data) f\u00fcr that project \/ artifact name \/ type available: If yes, use it. If no, prepare it (might take a while). I am looking for the equivalent of <code>&lt;filename&gt;.is_file()<\/code> but for artifacts. I could use\/download the artifact in a <code>try, except<\/code> clause but that\u2019s not very pretty (throwing errors on the console, not sure what the correct Exception is). The API does not seem to provide such a functionality?<\/p>",
        "Question_closed_time":"2022-02-09T18:16:35.263Z",
        "Answer_body":"<p>Hey Stephan,<\/p>\n<p>Thanks for your response. I think the code you have written is the best way to check if an artifact exists if you do not know a priori if it really exists.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Delete my user account",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-my-user-account\/1946",
        "Question_created_time":"2022-02-18T10:36:04.061Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":172,
        "Question_body":"<p>I would like to delete my account, please.<\/p>\n<p>My user name is yvanthiel<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to plot performance metrics against non-summary stats?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-plot-performance-metrics-against-non-summary-stats\/1891",
        "Question_created_time":"2022-02-10T18:57:27.197Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":229,
        "Question_body":"<p>How to plot performance metrics against non-summary stats?<\/p>\n<p>I am running sweeps over a few different datasets within the same job (each for a different location, it\u2019s a multi-task learning problem) and I am making wandb logging calls such as:<\/p>\n<pre><code class=\"lang-auto\">  wandb.log({\n    \"false_negative_rate\" : 0.043,\n    \"false_positive_rate\" : 0.261,\n    \"location\": \"Boston\",\n    \"number_training_instances\": 50\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.017,\n    \"false_positive_rate\" : 0.145,\n    \"location\": \"Boston\",\n    \"number_training_instances\": 100\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.076,\n    \"false_positive_rate\" : 0.334,\n    \"location\": \"Miami\",\n    \"number_training_instances\": 50\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.048,\n    \"false_positive_rate\" : 0.172,\n    \"location\": \"Miami\",\n    \"number_training_instances\": 100\n  })\n<\/code><\/pre>\n<p>After logging, I\u2019d like to be able to use the dashboard to create various scatter plots such as<\/p>\n<pre><code class=\"lang-auto\">Plot false_negative_rate versus false_positive_rate\n  where location == \"Boston\"\n    and number_training_instances == 50\n\nPlot false_negative_rate versus number_training_instances\n  where location == \"Washington\"\n\nPlot false_negative_positve_rate versus location\n  where number_training_instances == 100\n<\/code><\/pre>\n<p>However, the filters in the dashboard only provide me the ability to filter\/plot the last values logged (as opposed to any of the values logged). E.g., I can only filter on<\/p>\n<pre><code class=\"lang-auto\"> - number_training_instances == 100\n - location == \"Miami\"\n<\/code><\/pre>\n<p>because these were the last values logged for these attributes in each sweep.<\/p>\n<p>Is there a way to get the plotting flexibility I want using wandb\u2019s existing features?<br>\nCheers<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Example code for how to set up logging processes (cross validation folds) and grouping them?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/example-code-for-how-to-set-up-logging-processes-cross-validation-folds-and-grouping-them\/1908",
        "Question_created_time":"2022-02-12T15:37:40.014Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":197,
        "Question_body":"<p>Hi,<\/p>\n<p>I am new to wandb and I am trying to figure out how to set up logging processes (based on cross validation folds) and to group them. What I would like to do is to plot\/visualise performances for each fold in a cross validation scheme.<\/p>\n<p>In this Colab example notebook<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/scikit\/Simple_Scikit_Integration.ipynb\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9d23677f636eedb4d570ae645da788122519566f.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/scikit\/Simple_Scikit_Integration.ipynb\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/scikit\/Simple_Scikit_Integration.ipynb\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>at the very bottom the section \u201cBasic Setup\u201d says in point 2: \"Groups: For multiple processes or cross validation folds, log each process as a runs and group them together. <code>wandb.init(group='experiment-1')<\/code>\". I am not quite sure how to do this. I searched the documentation, but I was not successful. Can anyone point me to some example code how to do this?<\/p>\n<p>Basically, what I am interested in is to visualise ROC, etc. for each fold and compare how much they differ.<\/p>\n<p>Thanks in advance!<br>\nOliver<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Loading Keras model-best.h5 saved with W&B run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/loading-keras-model-best-h5-saved-with-w-b-run\/786",
        "Question_created_time":"2021-09-26T22:45:33.709Z",
        "Question_answer_count":5,
        "Question_score_count":6,
        "Question_view_count":1164,
        "Question_body":"<p>Hi,<\/p>\n<p>While using <code>wandb.keras.WandbCallback()<\/code> I noticed that W&amp;B saves a \u201c<code>model-best.h5<\/code>\u201d file at every run. However, I run into errors while trying to load this model. In contrast, the model saved by <code>tf.keras<\/code>\u2019 <code>ModelCheckpoint<\/code> callback works fine.<\/p>\n<p>Could this be an error due to <code>keras<\/code> vs. <code>tf.keras<\/code> protocols or clashing between different <code>tf.keras<\/code> versions? Would love to get more insight in how <code>wandb.keras.WandbCallback()<\/code> saves <code>model-best.h5<\/code>.<\/p>\n<p><strong>Error traceback:<\/strong><\/p>\n<pre data-code-wrap=\"---------------------------------------------------------------------------\"><code class=\"lang-nohighlight\">OSError                                   Traceback (most recent call last)\n\/tmp\/ipykernel_25\/1740475024.py in &lt;module&gt;\n      1 model = tf.keras.models.load_model(MODEL_PATH, \n      2                                    custom_objects={'FixedDropout': PermaDropout, \n----&gt; 3                                                    'rmse_tf': rmse_tf})\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/saving\/save.py in load_model(filepath, custom_objects, compile, options)\n    205           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n    206         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n--&gt; 207                                                 compile)\n    208 \n    209       filepath = path_to_string(filepath)\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/saving\/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\n    170   opened_new_file = not isinstance(filepath, h5py.File)\n    171   if opened_new_file:\n--&gt; 172     f = h5py.File(filepath, mode='r')\n    173   else:\n    174     f = filepath\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/h5py\/_hl\/files.py in __init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\n    406                 fid = make_fid(name, mode, userblock_size,\n    407                                fapl, fcpl=make_fcpl(track_order=track_order),\n--&gt; 408                                swmr=swmr)\n    409 \n    410             if isinstance(libver, tuple):\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/h5py\/_hl\/files.py in make_fid(name, mode, userblock_size, fapl, fcpl, swmr)\n    171         if swmr and swmr_support:\n    172             flags |= h5f.ACC_SWMR_READ\n--&gt; 173         fid = h5f.open(name, flags, fapl=fapl)\n    174     elif mode == 'r+':\n    175         fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n\nh5py\/_objects.pyx in h5py._objects.with_phil.wrapper()\n\nh5py\/_objects.pyx in h5py._objects.with_phil.wrapper()\n\nh5py\/h5f.pyx in h5py.h5f.open()\n\nOSError: Unable to open file (bad object header version number\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WandB login problem when i use the Huggingface accelerator on a TPU runtime",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-login-problem-when-i-use-the-huggingface-accelerator-on-a-tpu-runtime\/1886",
        "Question_created_time":"2022-02-09T12:30:36.875Z",
        "Question_answer_count":12,
        "Question_score_count":1,
        "Question_view_count":307,
        "Question_body":"<p>Hey Guys,<\/p>\n<p>I have been using WandB for a while now and everything is working fine but since I switched from a GPU runtime to a TPU runtime (8 cores) (Using the Huggingface accelerator on Google Colab) its not working anymore.<\/p>\n<p>The main process just never gets further than the code line with the WandB login while the other cores continue to work normally so i dont get any error message\u2026<\/p>\n<p>If i switch back to a GPU runtime afterwards, the same code runs without any problems.<\/p>\n<p>It is possible to login before using the notebook_launcher, but then of course I get an error message about different pids<\/p>\n<p>Im using the wandb version 0.12.10, torch-xla 1.9 and accelerate-0.5.1<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I upload code to WandB every time I run it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-upload-code-to-wandb-every-time-i-run-it\/1922",
        "Question_created_time":"2022-02-15T02:43:08.773Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":211,
        "Question_body":"<p>To back up the code, I want to upload my training code to Wandb every time I run it. Is this possible?<\/p>",
        "Question_closed_time":"2022-02-15T08:13:39.266Z",
        "Answer_body":"<p>No, wandb does not have an option to store code. Why do you want to save the code?<\/p>\n<ol>\n<li>\n<p>Are you changing the hparams in your code in every run?  - Then you could try using wandb.sweep() instead, as it visualizes your model\u2019s performance for different hparams<\/p>\n<\/li>\n<li>\n<p>Are you using different architectures while training? -   Wandb artifacts logs datasets and model\/training data. There are functions that track all your parameters (wandb. watch() iirc). This leads to an ONNX format of your model being saved.  This ONNX model can be visualized, and you could use that to see what model was trained. Or you could even save a string in your config file with details of the model you\u2019re training<\/p>\n<\/li>\n<\/ol>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Saving model's weights",
        "Question_link":"https:\/\/community.wandb.ai\/t\/saving-models-weights\/1924",
        "Question_created_time":"2022-02-15T07:44:25.288Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":119,
        "Question_body":"<p>Hi,<br>\nI\u2019m training a BERT model and I\u2019m trying to save the weights to wandb\u2019s files tab in the end of the training.<br>\nHow can I accomplish that?<br>\nAlso - how can I load the weights from wandb\u2019s files tab?<br>\nI\u2019m using this code:<br>\n<a href=\"https:\/\/wandb.ai\/cayush\/bert-finetuning\/reports\/Sentence-classification-with-Huggingface-BERT-and-W&amp;B--Vmlldzo4MDMwNA\">https:\/\/wandb.ai\/cayush\/bert-finetuning\/reports\/Sentence-classification-with-Huggingface-BERT-and-W&amp;B\u2013Vmlldzo4MDMwNA<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why is min and max causing errors when logging gradients for biases in model?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-is-min-and-max-causing-errors-when-logging-gradients-for-biases-in-model\/720",
        "Question_created_time":"2021-09-20T22:08:44.071Z",
        "Question_answer_count":5,
        "Question_score_count":3,
        "Question_view_count":670,
        "Question_body":"<p>Why is this error happening when wandb is logging the grad.data field?<\/p>\n<pre><code class=\"lang-auto\">  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/experiments\/meta_learning\/main_metalearning.py\", line 360, in &lt;module&gt;\n    main(args)\n  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/experiments\/meta_learning\/main_metalearning.py\", line 333, in main\n    meta_train_fixed_iterations_full_epoch_possible(args)\n  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/meta_learning\/training\/meta_training.py\", line 216, in meta_train_fixed_iterations_full_epoch_possible\n    log_train_val_stats(args, args.it, train_loss, train_acc, valid=meta_eval, bar=bar_it,\n  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/meta_learning\/training\/meta_training.py\", line 129, in log_train_val_stats\n    val_loss, val_acc = valid(args, save_val_ckpt=save_val_ckpt)\n  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/meta_learning\/training\/meta_training.py\", line 274, in meta_eval\n    eval_loss, eval_acc = args.meta_learner(spt_x, spt_y, qry_x, qry_y)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/torch\/nn\/modules\/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"\/home\/miranda9\/automl-meta-learning\/automl-proj-src\/meta_learning\/meta_learners\/maml_meta_learner.py\", line 159, in forward\n    (qry_loss_t \/ meta_batch_size).backward()  # note this is more memory efficient (as it removes intermediate data that used to be needed since backward has already been called)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/torch\/_tensor.py\", line 255, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/torch\/autograd\/__init__.py\", line 147, in backward\n    Variable._execution_engine.run_backward(\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 285, in &lt;lambda&gt;\n    handle = var.register_hook(lambda grad: _callback(grad, log_track))\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 283, in _callback\n    self.log_tensor_stats(grad.data, name)\n  File \"\/home\/miranda9\/miniconda3\/envs\/metalearning_cpu\/lib\/python3.9\/site-packages\/wandb\/wandb_torch.py\", line 235, in log_tensor_stats\n    tensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)\nRuntimeError: max must be larger than min\n<\/code><\/pre>\n<p>I am not doing anything myself so I am unsure how I can fix this\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Overriding logged media",
        "Question_link":"https:\/\/community.wandb.ai\/t\/overriding-logged-media\/1855",
        "Question_created_time":"2022-02-01T15:36:21.223Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":390,
        "Question_body":"<p>Hey there <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/raised_hand.png?v=12\" title=\":raised_hand:\" class=\"emoji\" alt=\":raised_hand:\"><\/p>\n<p>During my training I want to produce some visual outputs every epoch to monitor that the predictions make sense. I am logging a matplotlib figure with:<\/p>\n<pre><code class=\"lang-python\"> logger.log({'last epoch': fig})\n<\/code><\/pre>\n<p>The issue is that wandb is saving every figure that is produced instead of overwriting the last one. How can this be achieved?<\/p>\n<p>Thanks in advance<br>\nArturo<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"About manually assign weights & biases",
        "Question_link":"https:\/\/community.wandb.ai\/t\/about-manually-assign-weights-biases\/1884",
        "Question_created_time":"2022-02-08T23:40:01.355Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":137,
        "Question_body":"<p>How can we manually assign weights and biases rather than using randomly generated weights and biases at the beginning?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get a link to share project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-a-link-to-share-project\/1873",
        "Question_created_time":"2022-02-06T06:52:01.779Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":551,
        "Question_body":"<p>I have an existing project. I want to be able to make it public and share it to someone so that they can take a look at the graphs<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access to study group",
        "Question_link":"https:\/\/community.wandb.ai\/t\/access-to-study-group\/1850",
        "Question_created_time":"2022-01-31T09:11:41.251Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":163,
        "Question_body":"<p>Can you please help with content for hf-fastai2<\/p>",
        "Question_closed_time":"2022-02-06T02:30:59.106Z",
        "Answer_body":"<p>Slides can be found in fastai <a href=\"https:\/\/discord.com\/channels\/689892369998676007\/859175939368026162\/937472311836176425\" rel=\"noopener nofollow ugc\">discord.<\/a><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to visualize HTML run in Kubeflow Pipeline?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-visualize-html-run-in-kubeflow-pipeline\/1862",
        "Question_created_time":"2022-02-02T12:53:25.410Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":890,
        "Question_body":"<p>Hello,<\/p>\n<p>We use Pytorch Lightning for training and we use Kubeflow Pipelines and are thinking about using wandb to track and visualize the training and test metrics.<\/p>\n<p>Kubeflow pipelines offers the possibility to view a static html page (see <a href=\"https:\/\/www.kubeflow.org\/docs\/components\/pipelines\/sdk\/output-viewer\/#single-html-file\" rel=\"noopener nofollow ugc\">this link<\/a> ).<br>\nI was wondering if it would be possible via the wandb python sdk to get a read-only embeded code (iframe) that I could then simply pass to Kubeflow pipeline sdk to show the html ?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":"2022-02-03T23:26:27.864Z",
        "Answer_body":"<p>Ok I found the solution.<br>\nKubeflow Pipelines also support markdown visualization therefore instead of using kubeflow HTML output I used markdown and since markdown supports html inline I was able to directly use the wandb run html.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/21d1b9f84b7948659b75b981b04f21235e528615.png\" data-download-href=\"\/uploads\/short-url\/4Pb5MStVV77kGP5bCR1nBTvaK7H.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/21d1b9f84b7948659b75b981b04f21235e528615_2_690x333.png\" alt=\"image\" data-base62-sha1=\"4Pb5MStVV77kGP5bCR1nBTvaK7H\" width=\"690\" height=\"333\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/21d1b9f84b7948659b75b981b04f21235e528615_2_690x333.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/21d1b9f84b7948659b75b981b04f21235e528615_2_1035x499.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/21d1b9f84b7948659b75b981b04f21235e528615_2_1380x666.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/21d1b9f84b7948659b75b981b04f21235e528615_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1678\u00d7812 57.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Here is the code if someone is interested :<\/p>\n<pre><code class=\"lang-python\">import kfp\nfrom kfp.v2.dsl import component, Output, Markdown, pipeline\n\n@component(packages_to_install=['wandb'])\ndef wandb_visualization(markdown_artifact: Output[Markdown]):\n    import wandb\n    wandb.login(key=\"you_key\")\n\n    run = wandb.init(project=\"your-project\", entity=\"your-entity\")\n\n    wandb.log({\"train\/loss\" : 5.0})\n    wandb.log({\"train\/loss\" : 4.0})\n    wandb.log({\"train\/loss\" : 3.0})\n    wandb.log({\"train\/loss\" : 2.0})\n    wandb.log({\"train\/loss\" : 1.0})\n\n    wandb.finish()\n    with open(markdown_artifact.path, 'w') as f:\n        f.write(f\"&lt;iframe src=\\\"{run.get_url()}\\\" width=\\\"100%\\\" height=\\\"700\\\"\/&gt;\")\n<\/code><\/pre>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"[Potential Bugs] Issues with `wandb sync` after running `wandb artifact cache cleanup 10GB`",
        "Question_link":"https:\/\/community.wandb.ai\/t\/potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb\/1784",
        "Question_created_time":"2022-01-19T05:15:57.992Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":600,
        "Question_body":"<p>Hi,<\/p>\n<p>I am using the offline mode to train models and sync the wandb logs\/artifacts later using <code>wandb sync<\/code> command. As the number of artifact files get larger, I used <code>wandb artifact cache cleanup 10GB<\/code> to clean up some disk space. However, after running this command, I can no longer to <code>wandb sync<\/code> to upload the logs to the wandb online server.<\/p>\n<p>I got the following error when using <code>wandb sync<\/code> after running <code>wandb artifact cache cleanup 10GB<\/code>. There are many artifacts in this run, some of them might be deleted via the <code>cache cleanup<\/code> command. However, the logs (learning curves etc.) are all there,  but the following error prevents the logs being sync to the cloud server. Is there a way to still upload the logs?<\/p>\n<pre><code class=\"lang-auto\">FileNotFoundError, [Errno 2] No such file or directory: '\/home\/user\/.cache\/wandb\/artifacts\/obj\/md5\/93\/a2248a657e599da7c97f43d292b1c'\nwandb: ERROR Uploading artifact file failed. Artifact won't be committed.<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Problem with wandb.plot.pr_curve",
        "Question_link":"https:\/\/community.wandb.ai\/t\/problem-with-wandb-plot-pr-curve\/1857",
        "Question_created_time":"2022-02-01T17:33:32.021Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":112,
        "Question_body":"<p>Hello. My code for each training epoch:<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\n    \"PR_curve\":  wandb.plot.pr_curve(y_true, [(x, 1 - x) for x in y_predict])\n})\n<\/code><\/pre>\n<p>But I had plots like that(the left part):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5.jpeg\" data-download-href=\"\/uploads\/short-url\/9PhavrmCKrRlTKNxaRThfK8TGZv.jpeg?dl=1\" title=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg\" alt=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" data-base62-sha1=\"9PhavrmCKrRlTKNxaRThfK8TGZv\" width=\"690\" height=\"210\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1035x315.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1380x420.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">imgonline-com-ua-2to1-fyiDuqxQ397nx579<\/span><span class=\"informations\">1565\u00d7477 91.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nWhen I used pyplot I got the right part for some epoche:<br>\nAs I understand curve for class \u201c1\u201d must be equal to one of curves from second picture.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"A colleague accidentally deleted some projects, any chance to get them back?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/a-colleague-accidentally-deleted-some-projects-any-chance-to-get-them-back\/1774",
        "Question_created_time":"2022-01-17T17:30:42.480Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":151,
        "Question_body":"<p>Some of our teams projects were erroneously deleted by a colleague since he wanted to clean up his account and probably thought it were his own projects. Is there any chance to get the data back (I assume not, but worth a try\u2026)?<\/p>",
        "Question_closed_time":"2022-01-19T11:24:52.149Z",
        "Answer_body":"<p>Please check the names of the project. By username I meant the entity name where the projects were logged. If these were team projects then I need the team name.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Out of memory",
        "Question_link":"https:\/\/community.wandb.ai\/t\/out-of-memory\/1737",
        "Question_created_time":"2022-01-09T07:30:13.801Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":205,
        "Question_body":"<p>I have a question about how to free memory when integrating weights and biases  with yolox implementation?<br>\nAfter using weights and biases, my memory crashes before even completing the first epoch<br>\nI am using kaggle for yolox training<br>\nAny suggestions for this issue?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why are curves in different relative positions when zooming?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-are-curves-in-different-relative-positions-when-zooming\/1747",
        "Question_created_time":"2022-01-11T16:27:19.680Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":246,
        "Question_body":"<p>Hi team,<\/p>\n<p>Why am I seeing the green curve below the crimson curve in default view, but when I zoom into an x-range they overlap? FYI there is exponential avg smoothing with beta = 0.9<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/13ff04711b564d6fe57e7e360436af1cb51c0316.gif\" alt=\"curves_off\" data-base62-sha1=\"2QTrx5Mqnr4RbpOBcE5izW3FbXU\" width=\"690\" height=\"397\" class=\"animated\"><\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Decoding .wandb files?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/decoding-wandb-files\/1803",
        "Question_created_time":"2022-01-21T16:11:33.396Z",
        "Question_answer_count":9,
        "Question_score_count":1,
        "Question_view_count":228,
        "Question_body":"<p>I am hoping to inspect some thing in the .wandb file before I upload them (it is faster to get some quick results this way than to upload and then redownload data), but I am not sure what they are encoded in. Do you know if there are tools in the wandb library I can use to open these?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging temporal data \/ overriding single image",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-temporal-data-overriding-single-image\/1809",
        "Question_created_time":"2022-01-23T19:13:21.882Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":223,
        "Question_body":"<p>Hey, I have 1D data that I\u2019d like to show it at every step (think hidden state of a model) as a 2D image (x-axis would correspond to time\/epoch and y axis to # of neurons). Can I do this?<\/p>\n<p>If not, I can maintain the image myself and simply resend the data as an image, but then I\u2019d have to overwrite the image on the server. Can I do that?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb Local on Singularity?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-local-on-singularity\/1820",
        "Question_created_time":"2022-01-26T16:52:59.794Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":191,
        "Question_body":"<p>Has anyone found a good way to host wandb local on singularity rather than Docker? My understanding is that many institutions, mine included, do not allow use of docker because of security flaws within it.<\/p>",
        "Question_closed_time":"2022-01-26T20:02:14.985Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/evanv\">@evanv<\/a>,<\/p>\n<p>We do not have official support for singularity. You could, however, follow existing tutorials on running Docker containers with Singularity.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to make select group use a different x axis",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-make-select-group-use-a-different-x-axis\/1813",
        "Question_created_time":"2022-01-24T18:28:32.031Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":152,
        "Question_body":"<p>In my project, one of the network is larger than the others and has to use a smaller batch size. To keep the comparison fair, I used a 2x smaller batch size but accumulate gradients for 2 batches, which is theoretically the same amount of gradient updates as long as I keep the number of epochs 2x larger than the normal models. However, in the plots that are being tracked, the bigger model will look like it learns twice as slow as the normal model. This is expected, but to simulate the effect training with the same batch size, I need to shrink the x axis of the big model\u2019s learning curve.<\/p>\n<p>How would I do that? There is an expression column that I can use when editing the panels, but this seems to only work for all the curves in the plot, not selectively.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Where are artifacts stored locally?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/where-are-artifacts-stored-locally\/1733",
        "Question_created_time":"2022-01-08T20:46:19.166Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":491,
        "Question_body":"<p>Hi,<\/p>\n<p>As the title says, where are the artifacts stored locally when I save an artifact? How can I change its default location? It seems that changing <code>WANDB_DIR<\/code> does not change where artifacts are stored. On the other hand, I found many folders in <code>...\/wandb\/artifacts\/obj\/md5<\/code>,  what are these folders? Can I change its default saving location? Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Initiate Sweep Agent with Specific Hyperparameter Value",
        "Question_link":"https:\/\/community.wandb.ai\/t\/initiate-sweep-agent-with-specific-hyperparameter-value\/1789",
        "Question_created_time":"2022-01-19T22:12:32.515Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":167,
        "Question_body":"<p>I am running a sweep from several different machines. The machines have different GPU RAM, so I need to manually set the batch size on each machine. I would like to set batch size as a sweep parameter,  however, I can not figure out how to specify that certain agents use a specific value for a given hyperparameter, and randomly assign the rest.<\/p>\n<p>Thanks,<br>\nEdward<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Downloading best sweep model from python",
        "Question_link":"https:\/\/community.wandb.ai\/t\/downloading-best-sweep-model-from-python\/1781",
        "Question_created_time":"2022-01-18T01:44:14.498Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":293,
        "Question_body":"<p>I have run a few sweeps, and now I want to get the best models from any given sweeps. I follow the tutorial here: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide\">https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide<\/a> and run my code as following<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.sweep(f\"{team_name}\/{project_name}\/{sweep_id}\").runs\nrun = sorted(runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)[0]\nrun.file(f\"{path}{run.name}.h5\").download(replace=True)\n<\/code><\/pre>\n<p>And I get a \u201cPermission denied, ask the project owner to grant you access\u201d error on the run.file().download(), even though I followed the tutorial. I tried this in two different settings, (1) in a team where I am the admin and (2) on my personal account (note that these are the \u201cteam_name\u201d I am using in the api.sweep).<\/p>\n<p>It does find my sweep and the runs, I can also see the validation accuracies of all runs, it just doesn\u2019t allow me to download the files.<\/p>\n<p>Furthermore, and this might be unrelated, whenever I try to inspect the run elements in my pycharm, the debugger crashes. This has never happened before, but it\u2019s consistent on my machine, crashing my debugger every time<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Accesing wandb.ai takes too long",
        "Question_link":"https:\/\/community.wandb.ai\/t\/accesing-wandb-ai-takes-too-long\/1797",
        "Question_created_time":"2022-01-20T10:11:12.749Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":240,
        "Question_body":"<p>Hello!<\/p>\n<p>The time that takes to visit <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> is extremely long. I don\u2019t know what is happening. The problem is not that there is too much data\/graphs to load. Even when I have to go to <a href=\"https:\/\/wandb.ai\/authorize\" class=\"inline-onebox\">Weights &amp; Biases<\/a> I have to wait for about 10-20 seconds. That is really disappointing.<\/p>\n<p>My internet connection is about 10 Mbit\/s. It is not fast, but it is okay to view simple websites. I don\u2019t experience problems with other websites. LinkedIn, Facebook, Twitter, Netflix works fine.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Directly Querying Runs?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/directly-querying-runs\/1787",
        "Question_created_time":"2022-01-19T21:42:31.538Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":161,
        "Question_body":"<p>I have a project with a good number of runs (~30k). My overall goal is to find the best performing runs across a series of parameters specifying the data configuration (these parameters in my configs). Performance is measured as the maximum of the test accuracy obtained during training. This is relatively burdensome to do computationally if I read out each run individually. However it seems like something that any SQL-like database should be able to handle with ease (group by some parameters, measure maximums and sort, show only the top ones). Is this feasible with the wandb API?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Setting up a sweep using port forwarding?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/setting-up-a-sweep-using-port-forwarding\/1696",
        "Question_created_time":"2022-01-05T18:51:02.663Z",
        "Question_answer_count":6,
        "Question_score_count":1,
        "Question_view_count":241,
        "Question_body":"<p>I have a compute environment in which I have a university hosted cluster (so I am not admin) with a login node connected to the internet and not meant for compute jobs and several compute nodes which are connected to the login node but not to the internet. I would love to run a sweep in this environment but in the standard setup I would need my compute nodes to be connected to the internet. Is there a way I can setup port forwarding on the compute nodes so they can access the W&amp;B server via the login node? For reference, all environments are Ubuntu 18.04.6<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is it possible to override a Table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-override-a-table\/1776",
        "Question_created_time":"2022-01-17T20:25:01.000Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":334,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using a Table as it\u2019s the simplest to log text (Input output expected).<\/p>\n<p>However, I would like to keep only the last logged item in the Table, else I have thousand of rows or hundred of tables if I create a new table instead.<\/p>\n<p>Is there any fix for that ?<\/p>\n<p>Thanks in advance,<br>\nHave a great day <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=11\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Hiding runs in a sweep chart export",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hiding-runs-in-a-sweep-chart-export\/1778",
        "Question_created_time":"2022-01-18T01:04:26.195Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":235,
        "Question_body":"<p>Hello,<\/p>\n<p>I have a large sweep (~ 150 runs) and I want to hide some runs (these are not crashed runs) in the final sweep chart that I export. However, even if I turn off these runs in my visualization, I still see them with very faint lines (low opacity) in the chart that I see in my workspace and the PNG\/PDF that I export. Is there a way to completely turn off the visualization of completed runs in my sweep plots without deleting the runs? Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to show run name in repport Table",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-show-run-name-in-repport-table\/1775",
        "Question_created_time":"2022-01-17T18:32:35.909Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":361,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using Tables to log text (input, output, and expected) and I\u2019m showing it in a report.<\/p>\n<p>That\u2019s working perfectly, I changed \u201cMerged Table\u201d to \u201cList of tables\u201d to be able to change Run and see one table per run.<\/p>\n<p>However, it shows \u201c1 of 8\u201d so okay I need to open runs, check the first one, and get its name.<\/p>\n<p>Is there any way to show the run name instead of the little colors dot in the table ?<\/p>\n<p>Thanks in advance,<br>\nHave a great day <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=11\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Uploading basic data only once with wandb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/uploading-basic-data-only-once-with-wandb\/1770",
        "Question_created_time":"2022-01-17T09:12:11.020Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":142,
        "Question_body":"<p>Hi guys,<br>\nnot sure if this is the right place to ask, but i\u2019m trying to figure out how i can upload an \u201cartifact\u201d only once for my project.<br>\nI would like to upload a plot of my data to visualize some basic information. Adding it with wandb.log will upload this information on each run. Artifacts seem to be for data that should be versioned, which also doesn\u2019t seem to fit my usecase very well.<\/p>\n<p>I\u2019ve also tried uploading the dataset and then plotting it using the table information, but wandb seems to struggle with pandas datetimeindex, so i\u2019m not very happy with that solution either.<\/p>\n<p>Whats the proper way to go about doing this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error uploading dataset to colab",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-uploading-dataset-to-colab\/1728",
        "Question_created_time":"2022-01-08T12:42:36.058Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":252,
        "Question_body":"<p>I am having issues when I try to upload my dataset. I don\u00b4t know why but when I upload just one image and label in each folder(train and val) everything works perfectly, but when I try to upload more than one image I get the next error:<\/p>\n<p>Traceback (most recent call last):<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\log_dataset.py\u201d, line 27, in <br>\ncreate_dataset_artifact(opt)<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\log_dataset.py\u201d, line 11, in create_dataset_artifact<br>\nlogger = WandbLogger(opt, None, job_type=\u2018Dataset Creation\u2019)  # TODO: return value unused<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 190, in <em>init<\/em><br>\nself.data_dict = self.check_and_upload_dataset(opt)<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 203, in check_and_upload_dataset<br>\nconfig_path = self.log_dataset_artifact(opt.data,<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 345, in log_dataset_artifact<br>\nself.train_artifact = self.create_dataset_table(LoadImagesAndLabels(<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 428, in create_dataset_table<br>\nartifact.add(table, name)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 500, in add<br>\nval = obj.to_json(self)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\data_types.py\u201d, line 610, in to_json<br>\nmapped_row.append(_json_helper(v, artifact))<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\data_types.py\u201d, line 105, in _json_helper<br>\nreturn val.to_json(artifact)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u201d, line 2303, in to_json<br>\nclasses_entry = artifact.add(self._classes, class_name)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 520, in add<br>\nwith self.new_file(name) as f:<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\u201d, line 117, in <em>enter<\/em><br>\nreturn next(self.gen)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 359, in new_file<br>\nraise ValueError(<br>\nValueError: File with name \u201cmedia\\classes\\56699adf4321fa19e6264a528fad82c4_cls.classes.json\u201d already exists at \u201cC:\\Users\\Robcib\\AppData\\Local\\Temp\\tmph3c76g8x\\media\\classes\\56699adf4321fa19e6264a528fad82c4_cls.classes.json\u201d<\/p>\n<p>command line: C:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master&gt;python utils\/loggers\/wandb\/log_dataset.py --project custom_yolov5 --data data\/custom_dataset.yaml<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"YOLOv5 sweeps?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/yolov5-sweeps\/1735",
        "Question_created_time":"2022-01-09T02:44:07.744Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":255,
        "Question_body":"<p>Does anyone know if it\u2019s possible to use YOLOv5 train.py with sweeps?<\/p>\n<p>Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I make a Confusion Matrix that does not overlap?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-make-a-confusion-matrix-that-does-not-overlap\/1634",
        "Question_created_time":"2021-12-28T07:49:53.568Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":276,
        "Question_body":"<p>Hi,<br>\nI just made a confusion matrix in validation step, but it overlapped like this during training.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2.png\" data-download-href=\"\/uploads\/short-url\/xrqn87xjrMZ9EDb39gqB8tmMu6C.png?dl=1\" title=\"dd\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_690x70.png\" alt=\"dd\" data-base62-sha1=\"xrqn87xjrMZ9EDb39gqB8tmMu6C\" width=\"690\" height=\"70\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_690x70.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_1035x105.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_1380x140.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">dd<\/span><span class=\"informations\">2046\u00d7208 15.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I want to make a confusion matrix or table that can be seen by epoch.<\/p>\n<pre><code class=\"lang-auto\">            wandb.log({\n                \"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(\n                                                                y_true=targets,\n                                                                y_pred=outputs,\n                                                                labels=['Normal','COVID','Others']\n                                                                )\n            })\n<\/code><\/pre>\n<p>Is there any way to solve this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Table metrics are not logged when killing a wandb run early",
        "Question_link":"https:\/\/community.wandb.ai\/t\/table-metrics-are-not-logged-when-killing-a-wandb-run-early\/1694",
        "Question_created_time":"2022-01-05T16:55:39.311Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":170,
        "Question_body":"<p>Hi I have the following problem. I log several statistics, e.g. with<\/p>\n<pre><code>run.log({\"train-loss\": loss.item()}\nrun.summary[\"best_accuracy\"] =  best_acc1\n<\/code><\/pre>\n<p>and then I kill my wandb run early in the terminal. Unfortunately the metric \u201ctrain-loss\u201d and \u201cbest_accuracy\u201d is not logged in the table in wandb. The plots are available. It seems that summary metrics aren\u2019t.  Does anyone know how I can fix this? For early prototyping, I kill jobs quite often.<\/p>\n<p>Thanks and cheers!<\/p>\n<p>Stefan<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.plot.confusion_matrix() just show a Table!",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-plot-confusion-matrix-just-show-a-table\/1744",
        "Question_created_time":"2022-01-10T02:30:29.922Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":689,
        "Question_body":"<p>Hello,<\/p>\n<p>I used this code to create a confusion matrix:<\/p>\n<pre><code class=\"lang-auto\"># confusion matrix\n        wandb.log({\"confusion-matrix-test\": wandb.plot.confusion_matrix(\n            probs=None,\n            y_true=all_gt, preds=all_pre,\n            class_names=classes_names)})\n<\/code><\/pre>\n<p>However, Wanda\u2019s website only shows a table instead of the confusion matrix. This is a screenshot from the issue:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046.png\" data-download-href=\"\/uploads\/short-url\/8UGiFwpsOZ6Pivp7qmFXgL1OuvI.png?dl=1\" title=\"Screenshot from 2022-01-09 20-58-35\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_690x249.png\" alt=\"Screenshot from 2022-01-09 20-58-35\" data-base62-sha1=\"8UGiFwpsOZ6Pivp7qmFXgL1OuvI\" width=\"690\" height=\"249\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_690x249.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_1035x373.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_1380x498.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-01-09 20-58-35<\/span><span class=\"informations\">1741\u00d7629 29.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2022-01-10T10:12:33.312Z",
        "Answer_body":"<aside class=\"quote no-group\" data-username=\"fdaliran\" data-post=\"1\" data-topic=\"1744\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/f\/73ab20\/40.png\" class=\"avatar\"> fdaliran:<\/div>\n<blockquote>\n<pre><code class=\"lang-auto\">        wandb.log({\"confusion-matrix-test\": wandb.plot.confusion_matrix(\n            probs=None,\n            y_true=all_gt, preds=all_pre,\n            class_names=classes_names)})\n<\/code><\/pre>\n<\/blockquote>\n<\/aside>\n<p>If you click the section called \u201cCustom Charts\u201d above the Table, it\u2019ll show the line plot that you\u2019ve logged.<\/p>\n<p>Logging the Table also is expected behaviour because this will allow users to interactively explore the logged data in a W&amp;B Table after logging it.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Error with wandb on win10",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-with-wandb-on-win10\/1656",
        "Question_created_time":"2022-01-01T16:42:48.878Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":241,
        "Question_body":"<p>I got this on win10,it\u2019s stucked<br>\nthe enviornment is<\/p>\n<ul>\n<li>python3.7.10<\/li>\n<li>wandb 0.12.9<\/li>\n<\/ul>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" data-download-href=\"\/uploads\/short-url\/pvNysR6Ps6qxY0fl0Y5gjzfovBK.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" alt=\"image\" data-base62-sha1=\"pvNysR6Ps6qxY0fl0Y5gjzfovBK\" width=\"547\" height=\"500\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">686\u00d7626 26.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":"2022-01-09T01:03:19.763Z",
        "Answer_body":"<p>I\u2019ve deleted wandb in docker and pip ,then I reinstalled them.<br>\nAnd I got the right page after waiting about 5 or 6 minutes.<br>\nBut I don\u2019t know whtether the reason is the versions are different or something.<br>\nThis time I didn\u2019t set the LOCAL_RESOTRE var, I don\u2019t know whether the time will decrease.<br>\nAnd I notice that once I get the right page, the next time I can get in immediately.<br>\nThanks a lot.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Connecting to existing sweep from Python",
        "Question_link":"https:\/\/community.wandb.ai\/t\/connecting-to-existing-sweep-from-python\/1721",
        "Question_created_time":"2022-01-07T14:53:55.002Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":253,
        "Question_body":"<p>I have a few questions regarding the hyperparameter sweeps from Python.<br>\nI am wanting to essentially start a few tmux sessions on my server, and connect them all to the same sweep agent, but no keyword in the sweep_config (that i have found) allow me to connect to a specific sweep ID, and rather just a sweep name that doesnt connect to the same sweep, but just makes multiple sweeps of the same name.  If this possible or strongly advised against due to computational usage or similar?<\/p>\n<p>Furthermore, sweeps take up a great deal of storage requirements due to saving all the models, is it possible to store the model file from the best model only, while keeping the statistics from all the models for plots and interpretation? This would allow me to keep the great information gathered from sweeps, while not taking up 100+ GB from a single sweep.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":"2022-01-07T22:09:09.991Z",
        "Answer_body":"<p>I found the issue, i was trying to create a new wandb.sweep(config, project, entity) and pass the ID into the config dictionary, but instead i just needed to take the ID directly, and just do sweep_id = sweep_id_string which worked.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Help Adding To Tacotron Model",
        "Question_link":"https:\/\/community.wandb.ai\/t\/help-adding-to-tacotron-model\/1660",
        "Question_created_time":"2022-01-02T00:04:47.756Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":264,
        "Question_body":"<p><strong>Hello, can someone please help Me get this set up?<\/strong><br>\nI am running this in <strong>Google Colab<\/strong><\/p>\n<p>I am unable to get any data from my tacotron model.  I was able to login\/create multiple wandb runs and it tracks usage(log is connected, Utilization updates) but no data has been entered and the way it trains it runs one line forever so i dont even know how to begin.<\/p>\n<p>This is the Script that currently runs the training<\/p>\n<pre><code class=\"lang-auto\">print('FP16 Run:', hparams.fp16_run)\nprint('Dynamic Loss Scaling:', hparams.dynamic_loss_scaling)\nprint('Distributed Run:', hparams.distributed_run)\nprint('cuDNN Enabled:', hparams.cudnn_enabled)\nprint('cuDNN Benchmark:', hparams.cudnn_benchmark)\n\nfrom IPython.display import Javascript\ndisplay(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n#for i in range(200):\n#  print(i)\n\ntrain(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n\n<\/code><\/pre>\n<p><strong>I tried doing this but it didnt work either. here is my code to start the training with wandb<\/strong><\/p>\n<p>Install and login<\/p>\n<pre><code class=\"lang-auto\">#@markdown Login and start a new run\nprint('Installing wandb')\n!pip -q install wandb\nimport wandb\nprint('Login To wanb!!!\\n')\n!wandb login\n<\/code><\/pre>\n<p>Capture a dictionary of hyperparameters<\/p>\n<pre><code class=\"lang-auto\">#@markdown Capture a dictionary of hyperparameters\nwandb.config.p_attention_dropout=hparams.p_attention_dropout\nwandb.config.p_decoder_dropout=hparams.p_decoder_dropout\nwandb.config.decay_start=hparams.decay_start\nwandb.config.A_=hparams.A_\nwandb.config.B_=hparams.B_\nwandb.config.C_=hparams.C_\nwandb.config.min_learning_rate=hparams.min_learning_rate\nwandb.config.batch_size=hparams.batch_size\nwandb.config.epochs=hparams.epochs\nwandb.config.generate_mels=generate_mels\nwandb.config.show_alignments=hparams.show_alignments\nwandb.config.alignment_graph_height=alignment_graph_height\nwandb.config.alignment_graph_width=alignment_graph_width\nwandb.config.load_mel_from_disk=hparams.load_mel_from_disk\nwandb.config.ignore_layers=hparams.ignore_layers\nwandb.config.checkpoint_path=checkpoint_path\n<\/code><\/pre>\n<p>Start wanb and get runID<br>\n<code>wandb.init(project=\"tacotron\", entity=\"gmirsky2\")<\/code><\/p>\n<p><strong>start wandb run then Train<\/strong><\/p>\n<pre><code class=\"lang-auto\">#Run\napi = wandb.Api()\nrun = api.run(\"gmirsky2\/tacotron\/\" + wandb.run.id)\n\n#train\ntrain(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n\n# save the metrics for the run to a csv file\nmetrics_dataframe = run.history()\nmetrics_dataframe.to_csv(\"metrics.csv\")\n<\/code><\/pre>\n<p>When The Training Runs it Just goes to the train line and then never finishes.<br>\nI am looking for help with how to incorporate wandb with the tacotron train script\u2026<\/p>\n<pre><code class=\"lang-auto\">train(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n<\/code><\/pre>\n<p>I thought that was what the hyperparameters were for but i guess im wrong.<\/p>\n<p>Any help would be welcome. Thanks a bunch!<\/p>",
        "Question_closed_time":"2022-01-07T19:43:34.231Z",
        "Answer_body":"<p>I was able to get it working after blood\u2026 sweat\u2026 and time.<br>\nWell really it was just time.<\/p>\n<p>I ended up having to install then import it before Training and stop it after training\u2026 who would have thought. lol<\/p>\n<pre><code class=\"lang-auto\">#@markdown Install W&amp;B\n%%capture\n!pip install wandb --upgrade\n<\/code><\/pre>\n<p>wandb is super helpful and have a tf module: <em><strong>config=tf.flags.FLAGS<\/strong><\/em><\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport tensorflow as tf\nwandb.init(config=tf.flags.FLAGS, sync_tensorboard=True, project=model_filename)\n<\/code><\/pre>\n<p>Then after training is done Close the wandb connection<br>\n<code>wandb_run.finish(exit_code=0)<\/code><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"String bug in the parallel coordinates chart",
        "Question_link":"https:\/\/community.wandb.ai\/t\/string-bug-in-the-parallel-coordinates-chart\/1674",
        "Question_created_time":"2022-01-03T17:28:10.493Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":186,
        "Question_body":"<p>Hey Guys, i just started using wandb and so far everything is working pretty well, however I noticed that there seems to be a problem with strings as parameters in parallel coordinates chart<\/p>\n<p>Attached is a screenshot to illustrate the problem<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7.jpeg\" data-download-href=\"\/uploads\/short-url\/yfjVQxyNGXrfluwDks1707BnsO3.jpeg?dl=1\" title=\"wandb_string_problem\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_690x374.jpeg\" alt=\"wandb_string_problem\" data-base62-sha1=\"yfjVQxyNGXrfluwDks1707BnsO3\" width=\"690\" height=\"374\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_690x374.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_1035x561.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_1380x748.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb_string_problem<\/span><span class=\"informations\">1502\u00d7816 332 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>So now I wonder if I made a mistake or if I have to wait for a fix from you.<\/p>\n<p>Kind regards<br>\nChris<\/p>",
        "Question_closed_time":"2022-01-07T00:27:08.650Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/chrismartin\">@chrismartin<\/a>,<\/p>\n<p>This issue has been fixed. Parallel Coordinate charts  with strings should behave as expected now.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Invalid filename characters exception on uploading image",
        "Question_link":"https:\/\/community.wandb.ai\/t\/invalid-filename-characters-exception-on-uploading-image\/1711",
        "Question_created_time":"2022-01-06T15:24:48.588Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":251,
        "Question_body":"<p>Hi. I am using windows 10 &amp; venv &amp; python<br>\nthis is my code to upload image to wandb<\/p>\n<pre><code class=\"lang-auto\">wandb_log[\"Image\/train_image\"] = wandb.Image('tmp.jpg')\nwandb.log(wandb_log, step)\n<\/code><\/pre>\n<p>the full directory of image is \u201cC:\\Users\\\uc774\uc900\ud601\\Documents\\Github\\terenz\\tmp.jpg\u201d<br>\nHowever it creates this error<\/p>\n<pre><code class=\"lang-auto\">Media Image\/train_image is invalid. Please remove invalid filename characters\n<\/code><\/pre>\n<p>reinstalling wandb did not help to solve this problem.<br>\nwhat should I do?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Model stopped training once I introduced << report_to = 'wandb' >> in TrainingArguments",
        "Question_link":"https:\/\/community.wandb.ai\/t\/model-stopped-training-once-i-introduced-report-to-wandb-in-trainingarguments\/1712",
        "Question_created_time":"2022-01-06T15:31:50.793Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":418,
        "Question_body":"<p>I am downloading the model <a href=\"https:\/\/huggingface.co\/microsoft\/Multilingual-MiniLM-L12-H384\/tree\/main\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">microsoft\/Multilingual-MiniLM-L12-H384 at main<\/a> microsoft\/Multilingual-MiniLM-L12-H384 and then using it.<\/p>\n<p>Transformer Version: \u20184.11.3\u2019<\/p>\n<p>I have written the below code:<\/p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.login()\n%env WANDB_LOG_MODEL=true\n\nmodel = tr.BertForSequenceClassification.from_pretrained(\"\/home\/pc\/minilm_model\",num_labels=2)\nmodel.to(device)\n\nprint(\"hello\")\n\ntraining_args = tr.TrainingArguments(\nreport_to = 'wandb',\noutput_dir='\/home\/pc\/proj\/results2', # output directory\nnum_train_epochs=10, # total number of training epochs\nper_device_train_batch_size=16, # batch size per device during training\nper_device_eval_batch_size=32, # batch size for evaluation\nlearning_rate=2e-5,\nwarmup_steps=1000, # number of warmup steps for learning rate scheduler\nweight_decay=0.01, # strength of weight decay\nlogging_dir='.\/logs', # directory for storing logs\nlogging_steps=1000,\nevaluation_strategy=\"epoch\",\nsave_strategy=\"no\"\n)\n\nprint(\"hello\")\n\ntrainer = tr.Trainer(\nmodel=model, # the instantiated \ud83e\udd17 Transformers model to be trained\nargs=training_args, # training arguments, defined above\ntrain_dataset=train_data, # training dataset\neval_dataset=val_data, # evaluation dataset\ncompute_metrics=compute_metrics\n)\n\n<\/code><\/pre>\n<p>After Executing this:<\/p>\n<p>The model stuck at this point:<\/p>\n<p>***** Running training *****<\/p>\n<pre><code class=\"lang-auto\">Num examples = 12981\n Num Epochs = 20\n Instantaneous batch size per device = 16\n Total train batch size (w. parallel, distributed &amp; accumulation) = 32\n Gradient Accumulation steps = 1\n Total optimization steps = 8120\nAutomatic Weights &amp; Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\n<\/code><\/pre>\n<p><strong>What could be the possible solution?<\/strong><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep in DDP mode",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-in-ddp-mode\/1664",
        "Question_created_time":"2022-01-02T18:33:49.166Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":576,
        "Question_body":"<p>I wonder how Sweep works in multi-GPU mode? I want to initialize the parameters that need to be optimized in just one process, and then use Sweep for hyperparametric optimization. However, if I only initialize parameters in one process, other processes will report an error because they did not query parameters when loading the model. I didn\u2019t find the answer to using Sweep in multi-GPU mode, thanks for answering!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Saving Model Class Source, including forward() method",
        "Question_link":"https:\/\/community.wandb.ai\/t\/saving-model-class-source-including-forward-method\/1592",
        "Question_created_time":"2021-12-22T11:14:13.390Z",
        "Question_answer_count":5,
        "Question_score_count":6,
        "Question_view_count":231,
        "Question_body":"<p>Hey folks,<\/p>\n<p>I couldn\u2019t find the best practice when it comes to saving the model definition to <code>wandb<\/code>, including the forward call.<\/p>\n<p>Most of my research is done by changing the forward function, so it is an important piece of data I want to track.<\/p>\n<p>I tried using <code>inspect.getsource(class)<\/code> however, there seems to be an issue with using it in IPython.<\/p>\n<p>I am aware that I can save the whole notebook \/ file, but this means a lot of auxiliary information is also saved which makes it hard to compare just the models.<\/p>\n<p>Please let me know how you would approach this issue.<\/p>\n<p>thank you very much and enjoy life,<br>\nbatu<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Api key + entity verification",
        "Question_link":"https:\/\/community.wandb.ai\/t\/api-key-entity-verification\/1687",
        "Question_created_time":"2022-01-04T19:30:10.203Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":322,
        "Question_body":"<p>Hello Everyone,<\/p>\n<p>I\u2019ve been using this package for the past year to keep track of all my phd experiments (it is awesome!!!). I am in the process of developing an application (using streamlit) that makes use of my neural network framework more accessible to users.  For that reason, I want to provide users with the ability to use their wandb credentials to start logging results to their accounts. As far as I understand you need a valid API key and entity. Is there a way to verify that this API_key+entity combination exists?? Passing a random 40 character string in the key parameter of wandb.login() returns true, so I suspect that it only checks the length of the key and not if it actually exists. I guess I can try logging to a dummy project and then catch an exception (this means that the API key or the entity name is wrong) but I\u2019m looking for something more elegant.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to provide fold information in WandbCallback?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-provide-fold-information-in-wandbcallback\/1599",
        "Question_created_time":"2021-12-23T06:50:46.866Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":234,
        "Question_body":"<p>How to provide fold information in multi-fold training?<\/p>\n<p>I am trying to do something like this:<\/p>\n<pre><code class=\"lang-auto\">for fold in range(5):\nmodel.fit()\n<\/code><\/pre>\n<p>So it actually creates a single graph where steps are continued from the last executed step of previous epoch.<br>\nFor ref see below:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5.png\" data-download-href=\"\/uploads\/short-url\/bUQfG2SdqWgNhB5QoDwBGjbyy3P.png?dl=1\" title=\"Screenshot 2021-12-23 at 12.19.28 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_690x382.png\" alt=\"Screenshot 2021-12-23 at 12.19.28 PM\" data-base62-sha1=\"bUQfG2SdqWgNhB5QoDwBGjbyy3P\" width=\"690\" height=\"382\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_690x382.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_1035x573.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2021-12-23 at 12.19.28 PM<\/span><span class=\"informations\">1098\u00d7608 28.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to create a panel that reports number of successful runs per group",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-create-a-panel-that-reports-number-of-successful-runs-per-group\/1683",
        "Question_created_time":"2022-01-04T10:56:01.794Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":243,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m currently performing a hyperparameter search (I\u2019m not using wandb\u2019s sweeep feature for that) on a GPU cluster.  I group the runs into different categories, let\u2019s say that\u2019s simply \u201cGroup A\u201d, \u201cGroup B\u201d, etc.<\/p>\n<p>Now, since jobs can crash for various reasons, I would love to have a panel that reports the number of successful runs <em>for each group<\/em>, so I know how each group is doing (\u201cGroup A has 200 successful runs, while Group B only has 50, so I need to start some more jobs for Group B\u201d). I know I can get there by using the general filter and group feature in my project\u2019s run-table, but this is rather tedious and it would be more convenient for me to have it as a panel for quick access (e.g., inside a report).<\/p>\n<p>I\u2019ve fiddled around with the \u201cscalar chart\u201d and the \u201cweave\u201d panel, but without success \u2013 any ideas?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"The parallel coordinate panel seems to be inaccurate",
        "Question_link":"https:\/\/community.wandb.ai\/t\/the-parallel-coordinate-panel-seems-to-be-inaccurate\/1563",
        "Question_created_time":"2021-12-18T21:11:09.786Z",
        "Question_answer_count":8,
        "Question_score_count":0,
        "Question_view_count":233,
        "Question_body":"<p>I really love the parallel coordinate panel but something about it seemed off.  It turns out it\u2019s not consistent. I tried creating a new parallel coordinate panel once I saw the error but nothing changed.<\/p>\n<p>Here\u2019s an example. It says my out_activation for this run was tanh but the line goes through relu under out_activation.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7a3841626ef83df8db3398271d23de5997adfca2.jpeg\" data-download-href=\"\/uploads\/short-url\/hrcMePlFcUEqviIaQmCWRCSfYGu.jpeg?dl=1\" title=\"Screen Shot 2021-12-18 at 3.55.16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7a3841626ef83df8db3398271d23de5997adfca2_2_690x411.jpeg\" alt=\"Screen Shot 2021-12-18 at 3.55.16 PM\" data-base62-sha1=\"hrcMePlFcUEqviIaQmCWRCSfYGu\" width=\"690\" height=\"411\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7a3841626ef83df8db3398271d23de5997adfca2_2_690x411.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7a3841626ef83df8db3398271d23de5997adfca2_2_1035x616.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7a3841626ef83df8db3398271d23de5997adfca2.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/7a3841626ef83df8db3398271d23de5997adfca2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2021-12-18 at 3.55.16 PM<\/span><span class=\"informations\">1284\u00d7766 141 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb is doing the same possibility multiple times",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-is-doing-the-same-possibility-multiple-times\/1667",
        "Question_created_time":"2022-01-02T21:38:15.641Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":228,
        "Question_body":"<p>hi, i am working on private data with keras. I use different activation functions and optimization algorithms. I\u2019m doing this wandb sweep, but it trains one possibility more than once. example relu-lr=0.001-adam-batch_size=4 has trained probability more than 6 times. what is the reason of this. and I\u2019m not sure of the correctness of my code<\/p>\n<p>my code :<\/p>\n<pre><code class=\"lang-auto\">import tensorflow as tf\nimport numpy as np\nbase_dir=\"\/content\/f1\"\n\ntrain_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.1\n    )\n\ntest_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n     rescale=1.\/255,\n     validation_split=0.1\n)\n\ntrain_datagen=train_datagen.flow_from_directory(\n    base_dir,\n    target_size=(500,500),\n    subset='training',\n    batch_size=2\n)\n\ntest_datagen=test_datagen.flow_from_directory(\n    base_dir,\n    target_size=(500,500),\n    subset='validation',\n    batch_size=2\n)\nwandb.login()\nsweep_config = {\n    'method': 'random',\n    'metric': {\n      'name': 'accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs': {\n            'values': [2,4]\n        },\n        'learning_rate': {\n            'values': [0.01,0.001]\n        },\n        'optimizer': {\n            'values': ['adam','rmsprop']\n        },\n        'activation': {\n            'values': ['relu', 'elu', 'selu']\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config, entity=\"sdad\", project=\"func\")\ndef train():\n    config_defaults = {\n        'epochs': 2,\n        'batch_size': 2,\n        'learning_rate': 0.001,\n        'activation': 'relu',\n        'optimizer': 'adam',\n        'seed': 42\n    }\n\n    wandb.init(config=config_defaults)\n    \n    config = wandb.config\n    \n    model= Sequential()\n\n    model.add(layers.Conv2D(filters=4,activation=config.activation,kernel_size=(5,5),input_shape=(500,500,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=8,activation=config.activation,kernel_size=(3,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=16,activation=config.activation,kernel_size=(2,2)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=32,activation=config.activation,kernel_size=(2,2)))\n\n    model.add(layers.Flatten())\n\n    model.add(Dense(50,activation=config.activation))\n    model.add(Dense(100,activation=config.activation))\n    model.add(Dense(100,activation=config.activation))\n    model.add(Dense(50,activation=config.activation))\n    model.add(Dense(4,activation=\"softmax\"))\n\n  \n    model.compile(loss = \"categorical_crossentropy\", optimizer = config.optimizer, metrics=['accuracy'])\n\n    model.fit(train_datagen, batch_size=config.batch_size,\n              epochs=config.epochs,\n              validation_data=test_datagen,\n              callbacks=[WandbCallback(data_type=\"image\", validation_data=test_datagen)])\n<\/code><\/pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592.jpeg\" data-download-href=\"\/uploads\/short-url\/mvnzvxYGjBl6IgsCgOkOZueYeoa.jpeg?dl=1\" title=\"swepl\u0131nt\u0131s\u0131\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592_2_690x36.jpeg\" alt=\"swepl\u0131nt\u0131s\u0131\" data-base62-sha1=\"mvnzvxYGjBl6IgsCgOkOZueYeoa\" width=\"690\" height=\"36\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592_2_690x36.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592_2_1035x54.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592_2_1380x72.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9dbbeab2a807227267a91e6519a401beaaa15592_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">swepl\u0131nt\u0131s\u0131<\/span><span class=\"informations\">1780\u00d795 18.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Violin plots are inaccurate",
        "Question_link":"https:\/\/community.wandb.ai\/t\/violin-plots-are-inaccurate\/1644",
        "Question_created_time":"2021-12-30T08:43:55.684Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_body":"<p>I really like the violin plots but there is something strange in my plots.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a.png\" data-download-href=\"\/uploads\/short-url\/3F7Z1TdRo1hxg9aaZQGaFCcjA8i.png?dl=1\" title=\"screen_violin\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_690x358.png\" alt=\"screen_violin\" data-base62-sha1=\"3F7Z1TdRo1hxg9aaZQGaFCcjA8i\" width=\"690\" height=\"358\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_690x358.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_1035x537.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">screen_violin<\/span><span class=\"informations\">1062\u00d7552 21.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nAll of these distributions have the lower bound at 0.0, however they appear to be \u2018randomly\u2019 translated of some shift. Moreover, I have realized that the maximum value that you can estimate by looking at the extremum of the plot is clearly not corresponding with the maximum value you get from the tabular data.<br>\nIs this intended or not?<\/p>\n<p>Thanks in advance<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Pytorch sweep help",
        "Question_link":"https:\/\/community.wandb.ai\/t\/pytorch-sweep-help\/1669",
        "Question_created_time":"2022-01-03T12:10:16.566Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":225,
        "Question_body":"<p>Hi . I want to do a study in pytorch with wandb sweep. I want to try activation function optimization algorithm and lr value with various combinations. but I have no idea how to do this. I did it with keras but not in pytorch. can you help me<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Bug in WandB's Keras callback when specifying args",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-in-wandbs-keras-callback-when-specifying-args\/1651",
        "Question_created_time":"2021-12-31T19:27:08.765Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":276,
        "Question_body":"<p>Hi, I am using WandB\u2019s Keras callback in <code>autokeras<\/code> (which uses <code>keras-tuner<\/code> behind the scenes along with other modules). However, if I specify any args things immediately grind down to a halt.<\/p>\n<p>For reproduction, using the official <a href=\"https:\/\/autokeras.com\/tutorial\/image_regression\/\" rel=\"noopener nofollow ugc\">example<\/a> would be adequate.<\/p>\n<p>The problem for me is here,<\/p>\n<pre><code class=\"lang-auto\">WandbCB = WandbCallback(\n    monitor=\"val_loss\", verbose=0, mode=\"min\",\n    log_weights=(True), save_model=(True),\n    validation_data=validation,\n    predictions=5, generator=validation, input_type='images', output_type='images',\n    log_evaluation=(True), validation_steps=None, class_colors=None,\n)\n\nmodel.fit(x=training, validation_data=validation, batch_size=BATCH_SIZE, shuffle=True, callbacks=[WandCB, EStop])\n<\/code><\/pre>\n<p>However, if I specify WandB callback <em>without<\/em> any args,<\/p>\n<pre><code class=\"lang-auto\">model.fit(x=training, validation_data=validation, batch_size=BATCH_SIZE, shuffle=True, callbacks=[WandbCallback(), EStop])\n<\/code><\/pre>\n<p>it works very well.<\/p>\n<p>This is the error I am getting in the former case,<\/p>\n<pre><code class=\"lang-auto\">2021-12-31 19:18:38.582746: I tensorflow\/compiler\/mlir\/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n2021-12-31 19:18:38.583261: I tensorflow\/core\/platform\/profile_utils\/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\nTraceback (most recent call last):\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/site-packages\/keras_tuner\/engine\/tuner.py\", line 287, in _deepcopy_callbacks\n    callbacks = copy.deepcopy(callbacks)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 216, in _deepcopy_list\n    append(deepcopy(a, memo))\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/copy.py\", line 169, in deepcopy\n    rv = reductor(4)\nTypeError: can't pickle _thread.RLock objects\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"nas.py\", line 125, in &lt;module&gt;\n    log_evaluation=True, validation_steps=None, class_colors=None), EStop])\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/site-packages\/autokeras\/auto_model.py\", line 291, in fit\n    **kwargs\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/site-packages\/autokeras\/engine\/tuner.py\", line 175, in search\n    new_callbacks = self._deepcopy_callbacks(callbacks)\n  File \"\/usr\/local\/envs\/ak_env\/lib\/python3.7\/site-packages\/keras_tuner\/engine\/tuner.py\", line 293, in _deepcopy_callbacks\n    \"It is not possible to do `copy.deepcopy(%s)`\" % (callbacks,)\nValueError: All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([&lt;wandb.integration.keras.keras.WandbCallback object at 0x7f399310b690&gt;, &lt;tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39918b1710&gt;])`\n\nwandb: Waiting for W&amp;B process to finish, PID 6373... (failed 1). Press ctrl-c to abort syncing.\n<\/code><\/pre>\n<p>Does anyone have any idea?<\/p>\n<p><strong>EDIT-<\/strong> This is the <code>EarlyStopping<\/code> snippet<\/p>\n<pre><code class=\"lang-auto\">EStop = tf.keras.callbacks.EarlyStopping(\n    monitor='MAPEMetric', min_delta=2, patience=3, verbose=0, mode=\"min\", baseline=100, #baseline is 100\n    restore_best_weights=True)\n<\/code><\/pre>\n<p>The difference is perhaps the metrics being monitored in both - MAPEMetric is a simple custom TF metric that computes the \u201cMean Absolute Percentage Error\u201d;<\/p>\n<pre><code class=\"lang-auto\">def MAPEMetric(target, output):\n        return tf.math.reduce_mean(tf.math.abs((output - target) \/ output)) * 100   #100 for %\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to control grid sweep's parameters order?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-control-grid-sweeps-parameters-order\/1648",
        "Question_created_time":"2021-12-30T22:12:13.984Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":247,
        "Question_body":"<p>I have several parameters that I intend to grid sweep e.g. batch size, learning rate and optimizer. How can one specify the order in which the parameters are changed?<\/p>\n<p>For instance, suppose I think choice of optimizer will matter least and learning rate will matter most. I\u2019d like to try all possible learning rates on one optimizer before moving on to the next optimizer. How do I do this?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Custom sweep configuration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/custom-sweep-configuration\/1589",
        "Question_created_time":"2021-12-22T02:35:57.776Z",
        "Question_answer_count":2,
        "Question_score_count":3,
        "Question_view_count":321,
        "Question_body":"<p>How can I create more complex logic for defining the parameter space of a sweep? For example, for each model family, I\u2019d like to define a different set of parameters, or there a parameter that is a (variable) list of values.<\/p>\n<p>I can write code that generates all possible hyperparameter combinations by myself (as a list or as generator).<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Why can't I delete multiple runs in W&B at once",
        "Question_link":"https:\/\/community.wandb.ai\/t\/why-cant-i-delete-multiple-runs-in-w-b-at-once\/1585",
        "Question_created_time":"2021-12-21T22:57:53.795Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":239,
        "Question_body":"<p>As shown in the picture below, I selected multiple runs but still can\u2019t hit delete, which was ok before, did I set something wrong?<br>\nThank you for your help!<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe.jpeg\" data-download-href=\"\/uploads\/short-url\/1tihGWyfSAk2zp9Y2O4VmZiNf3g.jpeg?dl=1\" title=\"20211218195831\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_690x283.jpeg\" alt=\"20211218195831\" data-base62-sha1=\"1tihGWyfSAk2zp9Y2O4VmZiNf3g\" width=\"690\" height=\"283\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_690x283.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_1035x424.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">20211218195831<\/span><span class=\"informations\">1072\u00d7441 33.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep from existing runs not showing up in parallel coordinates, is this intended or a bug?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-from-existing-runs-not-showing-up-in-parallel-coordinates-is-this-intended-or-a-bug\/1601",
        "Question_created_time":"2021-12-23T07:47:19.181Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":261,
        "Question_body":"<p>Hi, I created a sweep from existing runs, but the panel Parallel Coordinates are empty, is this an intended behaviour or a bug?<\/p>\n<p>Here is what I did:<\/p>\n<ul>\n<li>populate projects with many runs (using ray\u2019s wandb_mixin)<\/li>\n<li>create a sweep following <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/existing-project#seed-a-new-sweep-with-existing-runs\">https:\/\/docs.wandb.ai\/guides\/sweeps\/existing-project#seed-a-new-sweep-with-existing-runs<\/a>\n<\/li>\n<li>the panel at \u201cSweeps &gt; [2]\u201d contains only 1 run, should contains all 42 runs.<\/li>\n<\/ul>\n<p>The sweep is at <a href=\"https:\/\/wandb.ai\/inc\/try_ray_tune\/sweeps\/smh3d0wg\" class=\"inline-onebox\">Weights &amp; Biases<\/a>, if any one is interested.<\/p>",
        "Question_closed_time":"2021-12-24T01:39:21.154Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/inc\">@inc<\/a>,<\/p>\n<p>You should be able to see all 42 runs on your parallel coordinates plot by ungrouping the runs. Grouping runs groups them for charts on your workspace as well.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Resources on how to use wandb docker",
        "Question_link":"https:\/\/community.wandb.ai\/t\/resources-on-how-to-use-wandb-docker\/1596",
        "Question_created_time":"2021-12-23T00:04:04.715Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":643,
        "Question_body":"<p>Greetings:<\/p>\n<p>After lots of research, I decided to go with wandb as the solution to several of the project management organization currently in place (or lack thereof).<\/p>\n<p>With that, I am looking to acquire the most effective workflow using <code>wandb docker<\/code> and <code>wandb local<\/code>.<\/p>\n<p>There is a page on this in the documents, and another in Github, but both are brief, and do not provide much information. All other documentation appears quite impressive (a major factor to me choosing this over the many other solutions). Whether featured by the company or a blog done by a third party, any good references to set up docker with wandb? Eventually, we will be spanning many parts of the data science pipeline (i.e., this is me doing a trial for a group at a company). So figured best practices and an efficient work environment should be set up first. Then, to start playing around with the outputs from the container runs to the project space (dashboard).<\/p>\n<p>Any pointers, references, samples projects, or any other material that might be out there?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I update custom plots in real-time?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-update-custom-plots-in-real-time\/1578",
        "Question_created_time":"2021-12-20T03:17:53.918Z",
        "Question_answer_count":6,
        "Question_score_count":2,
        "Question_view_count":825,
        "Question_body":"<p>I\u2019m currently using a custom line-plot to plot some metrics on one graph. Here\u2019s an example plot that tracks train and valid loss over a number of epochs:<\/p>\n<p><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3d95989b82878fed32b4b1ab123082013f3a229b.png\" alt=\"image\" data-base62-sha1=\"8MNDiL6poCrJxDhGbGFy3XTViGv\" width=\"566\" height=\"302\"><\/p>\n<p>Here\u2019s my current procedure to create this plot:<\/p>\n<ol>\n<li>First I create an empty W&amp;B Table (let\u2019s call it <code>loss_table<\/code>)<\/li>\n<li>At the end of each epoch, I calculate the train and valid loss and add it to the Table with the <code>loss_table.add_data()<\/code> method.<\/li>\n<li>Then at the end of training, I log <code>loss_table<\/code> to W&amp;B.<\/li>\n<li>Finally I create the chart from a vega spec <code>spec_name<\/code> with the command <code>chart = wandb.plot_table(vega_spec_name=spec_name, data_table=loss_table,...)<\/code> and log the chart with<br>\n<code>wandb.log({\"loss vs epoch\": chart})<\/code>\n<\/li>\n<\/ol>\n<p>This gives me the chart but doesn\u2019t let me see how the metrics change in real-time. Given that my training times are long (in the order of days and weeks) it is pretty important to me to see this real-time.<\/p>\n<p>My main problem is that W&amp;B doesn\u2019t support updating rows of a table, but instead supports only one upload of a table.  This prevents updating metrics and logging them to W&amp;B after each epoch, instead pushing for uploading the table only once training is finished.  There is an <a href=\"https:\/\/github.com\/wandb\/client\/issues\/1826\" rel=\"noopener nofollow ugc\">Github issue<\/a> that talks about this.<\/p>\n<p>Any suggestions would be welcomed.  Not sure how to get around this.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Only a subset of the artifacts exist issue",
        "Question_link":"https:\/\/community.wandb.ai\/t\/only-a-subset-of-the-artifacts-exist-issue\/1569",
        "Question_created_time":"2021-12-19T12:44:15.017Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":346,
        "Question_body":"<p>Hi,<br>\nI generated different 7 cells datasets.<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/chen-brestel\/cells_dataset\/runs\/z5lo24hn\/overview?workspace=user-chen-brestel\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/chen-brestel\/cells_dataset\/runs\/z5lo24hn\/overview?workspace=user-chen-brestel\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/s.gravatar.com\/avatar\/984d35ad02a6fb4388e6f91a95a0e805?s=480&amp;r=pg&amp;d=https%3A%2F%2Fcdn.auth0.com%2Favatars%2Fch.png\" class=\"thumbnail onebox-avatar\" width=\"120\" height=\"120\">\n\n<h3><a href=\"https:\/\/wandb.ai\/chen-brestel\/cells_dataset\/runs\/z5lo24hn\/overview?workspace=user-chen-brestel\" target=\"_blank\" rel=\"noopener\">chen-brestel<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>The pkl data of <em>all<\/em> the seven datasets do exist.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0.png\" data-download-href=\"\/uploads\/short-url\/o4SGcGfGg8KdPBsRnNdwBIRYPVC.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_690x487.png\" alt=\"image\" data-base62-sha1=\"o4SGcGfGg8KdPBsRnNdwBIRYPVC\" width=\"690\" height=\"487\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_690x487.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_1035x730.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_1380x974.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1389\u00d7981 52.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>However, There exist artifacts for <em>only<\/em> 3\/7.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787.png\" data-download-href=\"\/uploads\/short-url\/qIsbAXGhKr2J7Gt2hOwV2tE1l9J.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_690x489.png\" alt=\"image\" data-base62-sha1=\"qIsbAXGhKr2J7Gt2hOwV2tE1l9J\" width=\"690\" height=\"489\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_690x489.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_1035x733.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1360\u00d7965 59.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Screenshots attached.<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to plot multiline in one plot with smoothing features?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-plot-multiline-in-one-plot-with-smoothing-features\/1512",
        "Question_created_time":"2021-12-12T02:15:05.880Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":310,
        "Question_body":"<p>I\u2019m trying to plot the figure as in [W&amp;B Smoothing Features], but it didn\u2019t provide any code:<\/p>\n<p>                    <a href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9b0793db422eac619667bd11a7c56351d9d69149.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9b0793db422eac619667bd11a7c56351d9d69149.png\" width=\"690\" height=\"301\">\n          <\/a>\n\n<\/p>\n<p>Tutorials I could find by searching <code>wandb multiline in one plot<\/code> is [Custom Multi-Line Plots] which introduces <code>wandb.plot.line_series()<\/code>.  So I tried the code following<\/p>\n<pre><code class=\"lang-python\">import wandb\nimport numpy as np\n\n\nwandb.init(project=\"test\", entity=\"xxxx\")\n\nwandb.log({\"my_custom_id\":\n           wandb.plot.line_series(\n               xs=range(100),\n               ys=[range(100), np.random.randint(100, size=100)],\n               keys=[\"y1\", \"y2\"],\n               title=\"Multiline\",\n               xname=\"steps\"\n           )})\n<\/code><\/pre>\n<p>It gives me the following pic after choosing <code>Edit panel<\/code><\/p>\n<p>                    <a href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" width=\"690\" height=\"351\">\n          <\/a>\n\n<\/p>\n<p>Unlike the first picture:<\/p>\n<ol>\n<li>It <strong>doesn\u2019t<\/strong> have <code>Data<\/code>, <code>Group<\/code> etc tabs.<\/li>\n<li>There are <strong>two types<\/strong> of legend <code>name<\/code> and <code>lineKey<\/code> rather than one type.<\/li>\n<\/ol>\n<p>My question is how to plot exactly the same as the first picture with same function supported in wandb web?<\/p>",
        "Question_closed_time":"2021-12-15T00:32:50.761Z",
        "Answer_body":"<p>First I need to log the data I want<\/p>\n<pre><code class=\"lang-python\">import random\nimport wandb\n\nwandb.init(project=\"test\", entity=\"xxxx\")\nfor i in range(100):\n    wandb.log({\"y1\": random.random(), \"y2\": random.random(), \"x\": i})\n<\/code><\/pre>\n<p>Then, I need to mannually choosing y1 and y2 on Y Axis.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c.jpeg\" data-download-href=\"\/uploads\/short-url\/3mBq6eTgdFLO5BAFCPEQmOUHYoQ.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg\" alt=\"image\" data-base62-sha1=\"3mBq6eTgdFLO5BAFCPEQmOUHYoQ\" width=\"690\" height=\"262\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1035x393.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1380x524.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1807\u00d7687 214 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Download .html of plotly figures",
        "Question_link":"https:\/\/community.wandb.ai\/t\/download-html-of-plotly-figures\/1538",
        "Question_created_time":"2021-12-15T11:46:46.509Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":197,
        "Question_body":"<p>Can we download HTML figures from plotly exported to wandb?<br>\nI.e., I see in the media section the figure, but I wish to have the HTML plotly created to be used externally. The format by wandb not as reach as plotly\u2019s, as full-screen mode<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281.jpeg\" data-download-href=\"\/uploads\/short-url\/yhEMitSPZB9d8EKYfKmZE2SeJzz.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_690x263.jpeg\" alt=\"image\" data-base62-sha1=\"yhEMitSPZB9d8EKYfKmZE2SeJzz\" width=\"690\" height=\"263\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_690x263.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_1035x394.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_1380x526.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1920\u00d7732 89.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Workspace Bug",
        "Question_link":"https:\/\/community.wandb.ai\/t\/workspace-bug\/974",
        "Question_created_time":"2021-10-14T07:49:08.869Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":277,
        "Question_body":"<p>Dear WandB hello.<\/p>\n<p>When I\u2019m trying to work in my workspace and looking at the graph I could not see the model\u2019s menu, is there a way to fix it at my level?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Having problems with LaTeX reports",
        "Question_link":"https:\/\/community.wandb.ai\/t\/having-problems-with-latex-reports\/1514",
        "Question_created_time":"2021-12-12T10:46:53.787Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":206,
        "Question_body":"<p>When I try to download a LaTeX report the download spinning wheel starts, but never stops.<br>\nDoes it take so long or is this an issue with my setup?<\/p>\n<p>I\u2019m working on a MacBook accessing wandb from Apple Safari browser.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Does wandb charges for data transfer as s3 does(apart from data storage cost)?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/does-wandb-charges-for-data-transfer-as-s3-does-apart-from-data-storage-cost\/1487",
        "Question_created_time":"2021-12-08T11:22:03.480Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":321,
        "Question_body":"<p>The pricing on the wandb website states cost of data storage.Does wandb also charges downloading and uploading of artifacts like S3 does for data transfer?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plotting array-like values in a parallel coordinates plot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plotting-array-like-values-in-a-parallel-coordinates-plot\/1371",
        "Question_created_time":"2021-11-23T11:53:21.807Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":307,
        "Question_body":"<p>Hi,<\/p>\n<p>I have set up a sweep where one of the parameters possible values (arrays) are [0, 1, 3, 5], [0, 1, 5, 8], [0, 1, 8, 11], etc. The sweep is working fine and the model receives the correct value from the agent, but when visualizing the sweep using the parallel coordinates plot, every possible value of this hyperparameter is plotted at zero, since it is the first element of every array.<\/p>\n<p>I have thought of two solutions:<\/p>\n<ul>\n<li>Download all the data using the API, modify each value with an alias, and reupload the data.<\/li>\n<li>Write a custom plot to modify how that axe is plotted.<\/li>\n<\/ul>\n<p>However, I would like to know if there is a more straightforward solution so that each experiment line correctly passes through its value of this hyperparameter.<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Semi-transparent smoothing stopped working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/semi-transparent-smoothing-stopped-working\/1492",
        "Question_created_time":"2021-12-09T03:12:19.043Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":402,
        "Question_body":"<p>Smoothing suddenly stopped making the original graph semi-transparent.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e.png\" data-download-href=\"\/uploads\/short-url\/6HJfxA7ERNAiH7FwWeL8MzvFDIi.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e_2_512x500.png\" alt=\"image\" data-base62-sha1=\"6HJfxA7ERNAiH7FwWeL8MzvFDIi\" width=\"512\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e_2_512x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2efe82c897ae30783052f01c9383e9582d1f229e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">517\u00d7504 48.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any way your could rollback to the previous behavior? Some ETA for fixing this would be much appreciated, so our team could plan accordingly.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can use W&B locally and not publically?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-use-w-b-locally-and-not-publically\/1523",
        "Question_created_time":"2021-12-12T18:34:26.662Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":249,
        "Question_body":"<p>Hi<\/p>\n<p>I am trying to learn WB, I was wondering how can I use WB more like tensorboard locally and dont share my stuff on the cloud or publically?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What should the .gitignore file be when using wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-should-the-gitignore-file-be-when-using-wandb\/756",
        "Question_created_time":"2021-09-23T16:15:40.148Z",
        "Question_answer_count":6,
        "Question_score_count":2,
        "Question_view_count":425,
        "Question_body":"<p>I noticed that my pycharm suggests some wandb files that are created automatically\u2026to avoid pushing those (btw what are they?) what is the recommended .gitignore files contents?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Dataset artifact organization",
        "Question_link":"https:\/\/community.wandb.ai\/t\/dataset-artifact-organization\/1495",
        "Question_created_time":"2021-12-09T09:07:50.341Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":408,
        "Question_body":"<p>Typically pre wandb my approach to organizing dataset was to have lots of subfolders -<\/p>\n<pre><code class=\"lang-auto\">mnist\n     complete\n          augmented-mild\n          augmented-heavy\n     sampled-examples\n          mnist-1000\n               augmented-mild\n               augmented-heavy\n          mnist-10k\n              augmented-mild\n              augmented-heavy\n   sampled-class-examples\n        mnist-1000-5cls\n        mnist-10k-5cls\n\n<\/code><\/pre>\n<p>On going through wandb artifacts docs, it seems it is best to have a flattened structure for dataset versioning. How much flattening is ideal? A complete flattening would mean each of those above to have a different name and same type(say \u201cbalanced-dataset\u201d).Completely flattening dataset hierarchy seems to take away the \u201cversioning\u201d ability of wandb as now all of them are different artifacts.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Track train script version along with hyperaparams (ideally automated)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/track-train-script-version-along-with-hyperaparams-ideally-automated\/1479",
        "Question_created_time":"2021-12-06T23:02:22.465Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":234,
        "Question_body":"<p>I\u2019m just getting started with experiments, my goal is to ablation-study some potentially new methods for finetuning NLP models. I use HuggingFace trainer and the W&amp;B integration works flawlessly, so the hyperparams are super easy to track. I\u2019m going to be doing some experimentation within the training code though - is there an easy way to track the training script version\/content along with the experiments, ideally integrated with Github?  Thanks! Darek<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Best practices for many quick runs?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/best-practices-for-many-quick-runs\/1145",
        "Question_created_time":"2021-10-29T00:39:52.556Z",
        "Question_answer_count":13,
        "Question_score_count":4,
        "Question_view_count":595,
        "Question_body":"<p>I have a project where I am doing many, many runs across seeds none of which take a particularly long amount of time and for all of which I would like to log metrics (both the individual run metrics and the group metrics are relevant for me). Unfortunately my compute environment is such that I must run W&amp;B in offline mode (compute nodes are not connected to the internet), and as a result I have found sync to be an extreme bottleneck in my work. Has anyone encountered this kind of issue before and come up with a way to deal with it?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Handling imbalance dataset without altering the original dataset",
        "Question_link":"https:\/\/community.wandb.ai\/t\/handling-imbalance-dataset-without-altering-the-original-dataset\/1472",
        "Question_created_time":"2021-12-05T11:04:27.373Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":262,
        "Question_body":"<p>Hi,<\/p>\n<p>i tried several methods to handle imbalanced datasets<\/p>\n<p>i used a simple single neuron ANN as a logistic regression model and a churn dataset<\/p>\n<p>under- and oversampling worked well (especially SMOTE) but to get deeper understanding i wonder if there are even simpler ways to do than altering the original dataset?<\/p>\n<p>my questions (sorry, too many of them):<\/p>\n<ol>\n<li>\n<p>is changing the threshold value after training a model a usual and proper\/professional way to handle imbalance dataset classification problem?<\/p>\n<ul>\n<li>if so, how to do it? just run over the trained model and test data modifying threshold and calculating f1?<br>\nis the best threshold where F1 score is the highest?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>is it a good idea to try to find a model with best AUC score using wandb sweeps and then find the best threshold value of that model maximizing the F1 score?<\/p>\n<\/li>\n<li>\n<p>what if i train a model with a threshold value other than 0.5<\/p>\n<ul>\n<li>doing wandb sweeps finding the best AUC or f1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>applying class weights will help to improve recall but in return precision will decrease<\/p>\n<ul>\n<li>how to make it right? how to maximize F1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>does it improve my model if i add one or more hidden layers to it?<\/p>\n<\/li>\n<\/ol>\n<p>thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb.watch not logging parameters",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-watch-not-logging-parameters\/1197",
        "Question_created_time":"2021-11-02T14:31:07.980Z",
        "Question_answer_count":19,
        "Question_score_count":2,
        "Question_view_count":443,
        "Question_body":"<p>I just started to use w&amp;b to monitor the training of my few-shot learning NNs in Pytorch. I use wandb.watch(model, log=\u2018all\u2019) but it only logs the gradients. Any idea what could be causing this? Also, is there an easy way to log the activation histograms of the different layers for pytorch?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"App UI Bug: Can't see project's artifacts when it has no runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/app-ui-bug-cant-see-projects-artifacts-when-it-has-no-runs\/1461",
        "Question_created_time":"2021-12-02T19:23:43.932Z",
        "Question_answer_count":5,
        "Question_score_count":1,
        "Question_view_count":357,
        "Question_body":"<p>First, you may call it <em>a flaw<\/em> instead of <em>a bug<\/em> if you like. Second, I am not sure if this is a bug in the App UI or a flaw in your data model (I am new to WandB). Third, I am not sure if I am supposed to report bugs here, on github, or elsewhere. I could not find a non-public means of communicating this.<\/p>\n<p><strong>Expected behaviour.<\/strong><br>\nI should be able to see all artifacts created and\/or used within a given project via App UI (my browser) at all times. If the project has no artifacts, then I should see an explicit indication of that fact, just as on the first screenshot.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a.png\" data-download-href=\"\/uploads\/short-url\/AbdR0zySJTKb4nfew90jfroE6W6.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a_2_345x227.png\" alt=\"image\" data-base62-sha1=\"AbdR0zySJTKb4nfew90jfroE6W6\" width=\"345\" height=\"227\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a_2_345x227.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a_2_517x340.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a_2_690x454.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fd930d039ffbcbc6df6018430d9da2148658814a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">741\u00d7489 27.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p><strong>Observed behaviour.<\/strong><br>\nThe \u201cArtifacts\u201d icon on the side panel disappears when a project has no runs, <em>whether there are artifacts or not<\/em>.  As depicted on the second screenshot.<\/p>\n<p><strong>What I did.<\/strong><br>\nAll I did between the first and the second screenshots was deleting the only remaining (and empty) run within this project.<\/p>\n<p><strong>Why the observed behaviour is problematic:<\/strong><\/p>\n<ul>\n<li>If there are no artifacts in the project, I do not get an <em>explicit<\/em> confirmation of that.<\/li>\n<li>I cannot see the remaining artifacts if they still exist.<\/li>\n<li>Basically, you are forcing the user to keep a dummy run in a project, so that the bloody icon stays in place. (Figuratively speaking, because it\u2019s not just an icon issue: if you type the <code>\/entity\/project\/artifacts\/<\/code> in the address bar, you still can\u2019t get there)<\/li>\n<\/ul>\n<p>Now, you may argue that artifacts are attached to runs, and not to projects, therefore all artifacts created in a project that has become run-less are doomed to be orphaned (i.e., neither \u201cused\u201d, nor \u201clogged\u201d by any run), therefore they will be garbage-collected sooner or later, therefore there is no reason for the Artifacts tab. But this does not make sense for two reasons. First, why not keep the Artifact tab anyways? Second, if the user creates a dummy run so that the Artifact tab comes back, he\/she will be able to see the orphaned artifacts, as shown on the third screenshot.<br>\nHere\u2019s how I produced the third screenshot. I created a run and \u201cused\u201d a new artifact in this run, all via Python interface. Then I deleted the run, leaving the artifact orphaned. Then I created a new run within the same project, went back to the Artifact tab and found the orphaned artifact from the first run, as on the screenshot. If artifacts are attached to runs and not to projects, why does WandB show the orphaned artifact in this project\u2019s tab?<\/p>\n<hr>\n<p>P.S. Many thanks for all your work and, of course, for making your product available for free. But I can\u2019t help but point out that to facilitate neat and well-organised data science, WandB should be transparent, understandable, and predictable. So far, I have been having a hard time understanding your model and figuring out things like the unexpected difference between <code>wandb.sdk.wandb_run.Run<\/code> and <code>wandb.apis.public.Run<\/code>. I can\u2019t understand why any deviation from the simplest use cases and \u201cBest Practices\u201d must be so painful that it may be easier to re-run all experiments in order to correct how they are logged in WandB than to correct the record directly.<\/p>",
        "Question_closed_time":"2021-12-02T20:14:27.078Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/avm21\">@avm21<\/a>,<\/p>\n<p>Thanks for reporting this! It does indeed look like a bug on our end.  In general, I would start on GitHub for bug reporting, just to see if someone else has already filed the same bug; however, it is totally fine to post bugs and issues here as well. Alternatively if you want to get more direct support you can chat with the support team from our website 5am-5pm PST on Weekdays or email us at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a>.<\/p>\n<p>Circling back to your issue, I would log  a dummy run in the interim so you can see your artifacts in the UI; however, they should still be accessible via the public API and the <code>run.use_artifact()<\/code> method.<\/p>\n<p>I\u2019ll post back on this thread when I have an update on the bug fix.<\/p>\n<p>All the best,<\/p>\n<p>Aidan<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Local mirror of artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/local-mirror-of-artifacts\/1422",
        "Question_created_time":"2021-11-28T11:43:34.764Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":554,
        "Question_body":"<p>Hi<br>\nIs there an api to maintain a local mirror for artifacts?<\/p>\n<p>This way the artifact is downloaded only once (till it\u2019s remote update <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>For example:<\/p>\n<pre><code class=\"lang-auto\">artifact.download(mirror_dir=XXX)\nor\nrun.use(artifact, mirror_dir=XXX)\n<\/code><\/pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/api\">\n  <header class=\"source\">\n      \n\n      <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/api\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/362;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\/api\" target=\"_blank\" rel=\"noopener\">Artifacts Walkthrough<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Publishing Graphs\/Visualizations",
        "Question_link":"https:\/\/community.wandb.ai\/t\/publishing-graphs-visualizations\/1457",
        "Question_created_time":"2021-12-02T14:45:42.347Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":221,
        "Question_body":"<p>I\u2019m soon going to start implementing W&amp;B for my neural network\u2019s hyperparameter tuning. This is in preparation for an academic paper I\u2019m writing on the subject. The software seems very pragmatic and well-polished, so I\u2019m quite excited to get started.<\/p>\n<p>Its visualizations in particular seem to be of a very high quality. Some present sophisticated functionality that other experiment trackers can\u2019t touch. With proper citation, can these be included for publication?<\/p>",
        "Question_closed_time":"2021-12-02T17:40:47.308Z",
        "Answer_body":"<p>Hi Logan,<\/p>\n<p>I\u2019m so happy you\u2019re excited to use our product! Our engineers have worked very hard in order to get it to where it is today. We would love for you to use our graphs in your paper. We have a few examples of how to do so here (<a href=\"https:\/\/docs.wandb.ai\/company\/academics#cite-weights-and-biases\" class=\"inline-onebox-loading\">https:\/\/docs.wandb.ai\/company\/academics#cite-weights-and-biases<\/a>).<\/p>\n<p>Warmly,<br>\nLeslie<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"How to save\/restore model using artifact on servers that do not have internet access?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-save-restore-model-using-artifact-on-servers-that-do-not-have-internet-access\/1313",
        "Question_created_time":"2021-11-16T05:24:40.243Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":351,
        "Question_body":"<p>Hi,<\/p>\n<p>I just started using wandb tools. According to the instruction <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/save\">here<\/a>, it suggests using Artifact for new code to save models. And I am able to save the model in the offline mode. However, I wonder how to restore the model from an artifact with a particular version (e.g., v3, not necessarily the latest version of the artifact) if I want to resume the training after it\u2019s interrupted?<\/p>\n<p>I am running code on compute nodes that do not have access to internet, so I have to use the offline mode. And in offline mode, I cannot run <code>use_artifact<\/code> command as it only works in online mode. However, I think all the artifact data is already saved locally using <code>log_artifact<\/code> command. So in theory, I should be able to restore a particular version of the artifact? How can I get that? Even though I know the model file location, it is the latest model file, not a particular history version of the model file (that\u2019s the point of using Artifact to track the model?).<\/p>\n<pre><code class=\"lang-auto\">    run = wandb.init(mode='offline', project='test')\n    artifact = run.use_artifact('hello-world:v3')\n    artifact_dir = artifact.download(root=run.dir)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the best way to log multi-stage pipelines?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-is-the-best-way-to-log-multi-stage-pipelines\/1323",
        "Question_created_time":"2021-11-17T07:29:48.035Z",
        "Question_answer_count":5,
        "Question_score_count":4,
        "Question_view_count":415,
        "Question_body":"<p>Hi,<br>\nIn the project we have a multi-stage pipeline where each stage has a set of hyperparameters. It looks something like that:<br>\n<code>preprocesing -&gt; vectorization -&gt; clustering<\/code><\/p>\n<p>For sake of simplicity, let\u2019s assume that each stage has a single hyperparameter:<\/p>\n<pre><code class=\"lang-auto\">preprocesing: cutoff_threshold\nvectorizaiton: model_name\nclustering: num_clusters\n<\/code><\/pre>\n<p>Currently each stage logs everything in a separate run. All stages from a single run are grouped into a single group .<\/p>\n<p>At the moment we are doing hyperaparemeter sweep naively and we end up running whole pipeline 8 times (2x2x2) and using grouping feature we can nicely compare how changing hyperparameters of each stage affected end results.<\/p>\n<p>However preprocessing and vectorization steps are quite compute-intensive. In theory, in described setup we would only need to run preprocessing twice and vectorization 4 times (instead of 8 runs of each one). However then we can not (or at least i can\u2019t think of a way) group such runs so that we can get a nice sweep view. I.e. whe can not inform wandb which run of <code>clustering<\/code> was based on which run of <code>vectorization<\/code> and <code>preprocessing<\/code><\/p>\n<p>I wonder if what is the best way to setup such a pipeline in wandb?<\/p>\n<p>Thanks,<br>\nMicha\u0142<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How is one suppose to do custom logging in wandb especially with the x-axis?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-is-one-suppose-to-do-custom-logging-in-wandb-especially-with-the-x-axis\/1400",
        "Question_created_time":"2021-11-27T00:58:10.752Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":252,
        "Question_body":"<p>I feel I\u2019ve discussed this with someone somewhere (perhaps a gitissue\u2026can\u2019t find it!) but I can\u2019t find it and now I came back and can\u2019t figure out why my wandb command looks the way it does:<\/p>\n<pre><code class=\"lang-auto\">        # - log to wandb\n        if log_to_wandb:\n            if it == 0:\n                wandb.define_metric(\"train loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"train acc\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val val\", step_metric=it_or_epoch)\n                # if mdl_watch_log_freq == -1:\n                #     wandb.watch(args.base_model, args.criterion, log=\"all\", log_freq=mdl_watch_log_freq)\n            # - log to wandb\n            wandb.log(data={it_or_epoch: it,  # custom step,\n                            'train loss': train_loss,\n                            'train acc': train_acc,\n                            'val loss': val_loss,\n                            'val acc': val_acc},\n                            commit=True)\n            # if it == total_its:  # not needed here, only needed for normal SL training\n            #     wandb.finish()\n<\/code><\/pre>\n<p>can someone help me decipher what this was supposed to mean? Especially the commit option?<\/p>\n<hr>\n<p>related:<\/p>\n<ul>\n<li><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\">https:\/\/docs.wandb.ai\/guides\/track\/log<\/a><\/li>\n<li><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log#customize-axes-and-summaries-with-define_metric\">https:\/\/docs.wandb.ai\/guides\/track\/log#customize-axes-and-summaries-with-define_metric<\/a><\/li>\n<li><a href=\"https:\/\/colab.research.google.com\/drive\/1uegSY1HRGlKfK-07Uuw-ZxPJsNA9BN_9#scrollTo=0BIYhmSROGmq\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/wandb\/examples\/issues\/89\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Why isn't wandb logging at the last iteration? (when I want to log figs, ckpts etc) \u00b7 Issue #89 \u00b7 wandb\/examples \u00b7 GitHub<\/a><\/li>\n<\/ul>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one change how wandb logs\/prints to my screen so that it always shows it?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-change-how-wandb-logs-prints-to-my-screen-so-that-it-always-shows-it\/1401",
        "Question_created_time":"2021-11-27T03:05:55.385Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":238,
        "Question_body":"<p>I think wandb might be logging with some <code>WARN<\/code> flag or something because I can\u2019t always see the printing when I <code>tail -f <\/code> my scripts output.<\/p>\n<p><strong>How do I change wandb\u2019s settings so that it prints to stdout?<\/strong><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Account storage not being freed?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/account-storage-not-being-freed\/1375",
        "Question_created_time":"2021-11-23T22:42:27.325Z",
        "Question_answer_count":6,
        "Question_score_count":0,
        "Question_view_count":259,
        "Question_body":"<p>I deleted all my projects in order to free up my account storage, but the usage dashboard page still shows it as being used. 36gb of the 100gb available to be precise. Isn\u2019t it supposed to be reclaimed after the projects\/artifacts are deleted?<\/p>\n<p>I used all this space just by uploading some Driverless AI (<a href=\"https:\/\/www.h2o.ai\/products\/h2o-driverless-ai\/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">H2O Driverless AI | H2O.ai<\/a>) models and temporary files I was experimenting with. But if I certainly won\u2019t continue doing this if this space is gone for good.<\/p>\n<p>I can\u2019t really complain as I\u2019ve a free account, but I wonder if you are charging your paying customers for deleted files too\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"New to Wandb making sense of the gradient dashboard, am I seeing exploding gradients?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/new-to-wandb-making-sense-of-the-gradient-dashboard-am-i-seeing-exploding-gradients\/1388",
        "Question_created_time":"2021-11-25T14:59:42.246Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":405,
        "Question_body":"<p>Hi<\/p>\n<p>I\u2019m running my first experiments with weights and biases, I find it pretty cool and quite intuitive to use.<\/p>\n<p>The dashboard is a little confusing at the moment though<br>\nI have random initialized weights, and they seem to gro pretty quickly and then stagnate.<br>\nThe absolute value still seems very small so I\u2019m not sure fi this is due to scaling, are these exploding gradients?<\/p>\n<p>Thanks for any insights and help understanding and getting the most out of this awesome tool.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac.png\" data-download-href=\"\/uploads\/short-url\/mpOj7osjgYRoiIi15BRgeygWpEE.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_690x235.png\" alt=\"image\" data-base62-sha1=\"mpOj7osjgYRoiIi15BRgeygWpEE\" width=\"690\" height=\"235\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_690x235.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_1035x352.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_1380x470.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1785\u00d7610 53.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does wandb.tensorboard.patch works?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-wandb-tensorboard-patch-works\/1386",
        "Question_created_time":"2021-11-25T13:26:44.538Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":312,
        "Question_body":"<p>Hi everyone,<br>\nI\u2019m trying to move from <code>tensorboard<\/code> to <code>wandb<\/code> that seems more flexible and has some useful additional feature to customize plots.<\/p>\n<p>In my code I defined two<code> Tensorboard<\/code> <code>SummaryWriter<\/code>; I\u2019d like to import the plot associated to one of them in <code>wandb<\/code>.<\/p>\n<p>In other words I want to include in <code>wandb<\/code> only a part of the <code>tensorboard<\/code> logs of my code.<br>\nIs it possible to do it?<br>\nIf, for example, I have the 2 summaries stored in 2 different folders a and a\/b<\/p>\n<pre><code class=\"lang-auto\">Sum1 = SummaryWriter('a')\nSum2 = SummaryWriter('a\/b')\n<\/code><\/pre>\n<p>and I\u2019m only interested in import Sum2 in<code> wandb<\/code> .<\/p>\n<p>I thought that<br>\n<code>wandb.tensorboard.patch(root_logdir='a\/b', pytorch=True)<\/code><br>\nwas the way but it doesn\u2019t seem the case.<br>\nIn fact I get this message:<\/p>\n<p><code>e[34me[1mwandbe[0m: e[33mWARNINGe[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in a<\/code><\/p>\n<p>I want that paths outside root_logdir to be ignored.<br>\nApart from this page I did\u2019t found a clear documentation about wandb.tensorboard.patch.<br>\nAny idea about how to proceed?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Listing files of refence artifacts with temporary mounted folder (Azure)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/listing-files-of-refence-artifacts-with-temporary-mounted-folder-azure\/1384",
        "Question_created_time":"2021-11-25T09:53:15.251Z",
        "Question_answer_count":5,
        "Question_score_count":0,
        "Question_view_count":311,
        "Question_body":"<p>I am trying to make wandb work with Azure for versioning my datasets.<br>\nMy dataset is too big for any upload, so I am keeping it in Azure and add it by reference.<br>\nI am using the file based reference (file:\/\/\/) for a folder that is mounted to the compute instance.<br>\nRegistering the dataset, checksumming it etc all works fine.<\/p>\n<p>My problem is now how I <em>USE<\/em> the artifact.<\/p>\n<p>Since the folder is mounted by azure using a randomly generated name each time I cannot use the stored reference name. What I am doing right now is using the keys of the manifest entries:<br>\n<code>artifact.manifest.entries.keys()<\/code><br>\nThis gives me all the filenames and I manually concat it to the mounted folder pathname.<\/p>\n<p>Is there a better, less hacky, way of doing it? (Or even a better way to use Azure, since wandb supports s3 and gc?)<br>\n<code>.download()<\/code> is no option since the dataset is to big and the mounted folder is fine. <code>.checkout()<\/code> does not work, since the folder also contains other files which I do not want to delete. <code>.get()<\/code> and similar also dont work since I dont know the file paths.<\/p>\n<p>In my ideal world I would just have a function <code>artifact.files(root=\"mount_path\", verify=True)<\/code> which returns a list of all filenames and verifies they are correct via checksum. So I can just use the dataset and be sure it is the same one.<\/p>\n<p>Thank you! Artifacts are such a great addition to wandb and I would love to use them <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweep initial value",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-initial-value\/1372",
        "Question_created_time":"2021-11-23T14:42:21.453Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":285,
        "Question_body":"<p>Hi,<\/p>\n<p>is there a way to set min-max values, but to start based on a predefined initial value?<\/p>\n<p>Best<br>\nKarol<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Plot tables with best results from runs",
        "Question_link":"https:\/\/community.wandb.ai\/t\/plot-tables-with-best-results-from-runs\/1365",
        "Question_created_time":"2021-11-22T10:28:34.409Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":296,
        "Question_body":"<p>Hi,<\/p>\n<p>I would like to create a report not just with graph plots of my metrics but also a table with the best metric results (accuracy, mAP, \u2026). So that the viewer does not have to compare each line of  a run, but can instead look at the table with the scalar best results if he wants to identify the best run.<\/p>\n<p>It seems to me as there is currently no such feature implemented?<\/p>\n<p>Best<br>\nKarol<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to download the artifact with a specific alias?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-download-the-artifact-with-a-specific-alias\/1310",
        "Question_created_time":"2021-11-15T20:17:31.357Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":262,
        "Question_body":"<p>Hi,<\/p>\n<p>What\u2019s the best way to download the artifact with a specified alias (the version with the alias I want)? Also, during the inference time, how can I download the artifact and use it without creating a new wandb run directory? At inference time, if a new wandb run directory is created, it will be uploaded to my account, which will add more unnecessary runs in my wandb project. Is there a way to disable creating a new run folder if I just want to download the model in artifact and test the model? Thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"404 error running sweep from local jupyter nb",
        "Question_link":"https:\/\/community.wandb.ai\/t\/404-error-running-sweep-from-local-jupyter-nb\/1270",
        "Question_created_time":"2021-11-12T09:01:15.154Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":327,
        "Question_body":"<p>Hi when I run a project with sweep configuration and click on the link I get a 404 error message. This is my own account so privacy settings should not be an issue. Also under my projects the sweep run from my local jupyter nb is not displayed even though in the overview tab I can see that I run the experiment.<br>\nAny help here?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Group by tag",
        "Question_link":"https:\/\/community.wandb.ai\/t\/group-by-tag\/1364",
        "Question_created_time":"2021-11-22T10:05:44.090Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":301,
        "Question_body":"<p>Hi,<\/p>\n<p>is there a way to group runs in a plot by a given tag? Currently you can only group by hyperparameters, but that is not enough in my case.<\/p>\n<p>Best<br>\nKarol<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweeps hyperparameter tuning with cross validation",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweeps-hyperparameter-tuning-with-cross-validation\/1354",
        "Question_created_time":"2021-11-20T20:10:16.373Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":231,
        "Question_body":"<p>Hey,<\/p>\n<p>I want to do hyperparameter tuning using sweeps for my project. The experiments all involve k-fold cross-validation. Prior to doing hyperparameter tuning, I was separating the folds into different runs in wandb.init() by assigning them to the same group but giving them the fold number as a name. That works well.<br>\nHowever, now that I\u2019m using sweeps for hyperparameter tuning, wandb shows only one run per group (Fold 1) and all folds get packed together into this one run.<\/p>\n<p>Is there any best practice how to do both hyperparameter search with sweeps and k-fold cross-validation?<\/p>\n<p>Thanks a lot!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb Tables to Latex Tables, anyway?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-tables-to-latex-tables-anyway\/1060",
        "Question_created_time":"2021-10-21T13:09:10.155Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":990,
        "Question_body":"<p>I discovered Wandb few years back but I finally sat down to integrate everything with my experiments. I am loving this so much! Something I\u2019d like to know is if there is anyway to export tables to Latex from Wandb itself.<\/p>\n<p>I\u2019m in ML research and I have to include my results in Latex tables for papers. So it would be really cool if I could export them from Wandb, just like reports or graphs. I\u2019m open to suggestions you may have. thank you<\/p>\n<p>(willing to submit a feature request as well)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to do a wandb sweep for each dataset from a bash script?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-do-a-wandb-sweep-for-each-dataset-from-a-bash-script\/1316",
        "Question_created_time":"2021-11-16T15:01:34.881Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":364,
        "Question_body":"<p>I have a function <code>train_model.py<\/code> which fits a model and takes arguments like so.<\/p>\n<pre><code class=\"lang-auto\">parser = argparse.ArgumentParser(description='Train a model.')\nparser.add_argument('--dataset', type=str, default='MUTAG')\nparser.add_argument('--weight_decay', type=float, default=0.0)\nparser.add_argument('--layers', type=int, default=2)\nparser.add_argument('--dropout', type=float, default=0.0)\nparser.add_argument('--monitor', type=str, default='valid_loss')\nparser.add_argument('--seed', type=int, default=0)\nparser.add_argument('--max_epochs', type=int, default=50)\nargs = parser.parse_args()\n<\/code><\/pre>\n<p>I would like to run a sweep over a large dimensional hyper-parameter space (there are more arguments\/parameters than shown above, this is just an illustrative example) and do one sweep per dataset.<\/p>\n<p>Currently, I am doing a random search and my config is like so.<\/p>\n<pre><code class=\"lang-auto\">program: train_model.py\nmethod: random\nmetric:\n  name: valid_accuracy\n  goal: maximise\nparameters:\n  dataset:\n    values: [MUTAG, ENZYMES, PROTEINS]\n  weight_decay:\n    values: [0.0, 0.0001, 0.001, 0.01]\n  layers:\n    values: [1, 2, 3]\n<\/code><\/pre>\n<p>This works for now because (approximately) each dataset is chosen 1\/3 of the time. This is suboptimal however because<\/p>\n<ol>\n<li>The dashboard makes little sense, because the accuracy\/loss range varies for dataset. Hyper-parameter importance may also depend on the dataset. To make sense of the data I have to download the table and filter it per dataset.<\/li>\n<li>I would like to use <code>bayes<\/code> search strategy, but the search will end up focusing on just one dataset (the easiest as it will give higher accuracies).<\/li>\n<\/ol>\n<p>My question is what is the best way to modify my setup so I can specify the dataset and run a sweep via command line? Ideally, I would like to be able to run a bash script like the following where a bayes hyper-parameter search is run over each dataset for 100 runs.<\/p>\n<pre><code class=\"lang-auto\">wandb sweep config.yaml --dataset MUTAG --count 100\nwandb sweep config.yaml --dataset ENZYMES --count 100\nwandb sweep config.yaml --dataset PROTEINS --count 100\n<\/code><\/pre>\n<p>The reason I am unable to do this is<\/p>\n<ol>\n<li>I\u2019m not sure how to pass the dataset flag separately.<\/li>\n<li>To run a sweep I use the command <code>wandb sweep config.yaml<\/code> which gives another command in the terminal output (<code>wandb: Run sweep agent with: wandb agent user\/project\/ccdfy44v<\/code> to actually run the sweep which I manually copy and paste).<\/li>\n<\/ol>\n<p>Another way would be to use the controller in a python script but the docs warn<\/p>\n<blockquote>\n<p>This feature is offered to support faster development and debugging of new algorithms for the Sweeps tool. It is not intended for actual hyperparameter optimization workloads.<\/p>\n<\/blockquote>\n<p>It doesn\u2019t explain why this is the case though.<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to compare different runs' config changes directly in my Workspace",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-compare-different-runs-config-changes-directly-in-my-workspace\/1330",
        "Question_created_time":"2021-11-17T19:34:41.516Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":300,
        "Question_body":"<p>Currently, we can only pin the final values that we \u201clog\u201d. How to pin a certain config \/ parameter for each run, so that its easier to compare the runs or understand what that run is.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb online\/offline status breaks when using WANDB_DIR environment variable",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-online-offline-status-breaks-when-using-wandb-dir-environment-variable\/1230",
        "Question_created_time":"2021-11-05T11:23:04.127Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":297,
        "Question_body":"<p>Hi, while starting to get familiar with <code>wandb<\/code> I ran into a bug.<\/p>\n<p>I was testing a very simple setup with the following file:<\/p>\n<p><em>train.py<\/em><\/p>\n<pre><code class=\"lang-python\">import wandb\nimport random\nimport logging\n\nlog = logging.getLogger(__name__)\n\n\ndef train():\n    with wandb.init(\n        entity=\"jeroenboss\",\n        project=\"wandb_demo\"\n    ) as run:\n        log.info(f\"Running experiment with name {run.name}\")\n        config = run.config\n\n        log.info(f\"Loaded configuration: {config}\")\n        accuracy = 0\n        for x in range(config.get('epochs', 100)):\n            accuracy += (1 - accuracy) * (random.random()*0.9+0.1) * config.get('alpha', 0.1)\n\n            run.log({\"accuracy\": accuracy})\n\n        log.info(\"Finished\")\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    train()\n<\/code><\/pre>\n<p>Because I was testing a few things I wanted to prevent uploading the runs to your servers before I had figured out some bugs. But when I tried to use the <code>wandb offline<\/code> command, it did not seem to work.<br>\nAfter some testing I found that setting <code>WANDB_DIR<\/code> in my <code>~\/.bashrc<\/code> breaks the functionality. Below you can see the output of my commands. Removing <code>WANDB_DIR<\/code> made everything work correctly.<\/p>\n<pre><code class=\"lang-auto\">(wandb_demo) jeroen@jeroen-ThinkPad-P50:~\/sandbox\/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https:\/\/api.wandb.ai\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"project\": null,\n  \"section\": \"default\"\n}\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~\/sandbox\/wandb_test$ wandb offline\nW&amp;B offline, running your script from this directory will only write metadata locally.\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~\/sandbox\/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https:\/\/api.wandb.ai\",\n  \"disabled\": \"true\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"mode\": \"offline\",\n  \"project\": null,\n  \"section\": \"default\"\n}\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~\/sandbox\/wandb_test$ python train.py\nwandb: Currently logged in as: jeroenboss (use `wandb login --relogin` to force relogin)\nwandb: Tracking run with wandb version 0.12.6\nwandb: Syncing run misunderstood-night-24\nwandb: \u2b50\ufe0f View project at https:\/\/wandb.ai\/jeroenboss\/wandb_demo\nwandb: \ud83d\ude80 View run at https:\/\/wandb.ai\/jeroenboss\/wandb_demo\/runs\/kv7r7fst\nwandb: Run data is saved locally in \/home\/jeroen\/.wandb\/runs\/wandb\/run-20211105_121404-kv7r7fst\nwandb: Run `wandb offline` to turn off syncing.\n\nINFO:__main__:Running experiment with name misunderstood-night-24\nINFO:__main__:Loaded configuration: {'epochs': 50, 'alpha': 0.1}\nINFO:__main__:Finished\n\nwandb: Waiting for W&amp;B process to finish, PID 17238... (success).\nwandb:                                                                                \nwandb: Run history:\nwandb:   accuracy \u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\nwandb: \nwandb: Run summary:\nwandb:   accuracy 0.95235\nwandb: \nwandb: Synced 7 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\nwandb: Synced misunderstood-night-24: https:\/\/wandb.ai\/jeroenboss\/wandb_demo\/runs\/kv7r7fst\nwandb: Find logs at: \/home\/jeroen\/.wandb\/runs\/wandb\/run-20211105_121404-kv7r7fst\/logs\/debug.log\nwandb: \n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~\/sandbox\/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https:\/\/api.wandb.ai\",\n  \"disabled\": \"true\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"mode\": \"offline\",\n  \"project\": null,\n  \"section\": \"default\"\n}\n<\/code><\/pre>\n<p>I\u2019m running Python 3.7.12 and wandb 0.12.6<\/p>\n<p>I would like to store my runs in a central folder, so I would like to be able to use <code>WANDB_DIR<\/code>.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Loading past runs in offline mode",
        "Question_link":"https:\/\/community.wandb.ai\/t\/loading-past-runs-in-offline-mode\/1299",
        "Question_created_time":"2021-11-15T16:54:53.288Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":272,
        "Question_body":"<p>So I just recently started using wandb local, tracking experiments running on the GPU cluster at the lab where I work, hosted at localhost on my machine.<\/p>\n<p>I suspect I\u2019ve misunderstood the setup at some point, but the problem I\u2019m having is that every time I spin up a Docker container to run wandb\/local, it requires me to create a new account, with none of my previous project data available through the web server, even though the files and metadata from all previous runs are saved to a persistent folder on my machine. I\u2019m using the following command to set up the container:<\/p>\n<pre><code class=\"lang-auto\">sudo docker run --rm -d -v wandb_vol:\/vol -p 8080:8080 --name wandb-local wandb\/local\n<\/code><\/pre>\n<p>and run metadata is indeed saved to <code>wandb_vol<\/code> locally.  However, each time I spin up the container again, I have to re-enter all my details and I see this:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/262d90592453acb356f466258e064d66dd885d02.png\" data-download-href=\"\/uploads\/short-url\/5rJLmNX4woMxT36lYkqCQvNoVrA.png?dl=1\" title=\"wandb_forum_pic\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/262d90592453acb356f466258e064d66dd885d02_2_690x305.png\" alt=\"wandb_forum_pic\" data-base62-sha1=\"5rJLmNX4woMxT36lYkqCQvNoVrA\" width=\"690\" height=\"305\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/262d90592453acb356f466258e064d66dd885d02_2_690x305.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/262d90592453acb356f466258e064d66dd885d02_2_1035x457.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/262d90592453acb356f466258e064d66dd885d02_2_1380x610.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/262d90592453acb356f466258e064d66dd885d02_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">wandb_forum_pic<\/span><span class=\"informations\">1715\u00d7760 54.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nwhen I click on \u201cGet a free license\u201d I get an error saying \u201cYour account already has a deployment\u201d, which is true, but is there a way to have a persistent account and project folders locally?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one do hyper parameter sweeps when using HPCs\/clusters?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters\/1317",
        "Question_created_time":"2021-11-16T15:55:10.724Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":305,
        "Question_body":"<p>I saw the great video:<\/p>\n<div class=\"youtube-onebox lazy-video-container\" data-video-id=\"9zrmUIlScdY\" data-video-title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" data-provider-name=\"youtube\">\n  <a href=\"https:\/\/www.youtube.com\/watch?v=9zrmUIlScdY\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img class=\"youtube-thumbnail\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/7\/717a711d1aa4e9e0b03bfca700e6c8f019960c7d.jpeg\" title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" width=\"690\" height=\"388\">\n  <\/a>\n<\/div>\n\n<p>but I still wasn\u2019t 100% how to use it in a HPC cluster. I understand there is a central sweep master at wandb\u2019s servers sending commands, but how does it connect to the HPC\/clsuter?<\/p>\n<p>There are some cases I am worried baout<\/p>\n<ol>\n<li>the HPC needs my password<\/li>\n<li>the HPC needs an ssh key<\/li>\n<li>a VPN to connect to the hpc<\/li>\n<li>the HPC needs duo authentication<\/li>\n<li>the HPC uses a workload manager e.g. slurm or condor<\/li>\n<\/ol>\n<p>it would be very nice to have a concrete example with some of these. Perhaps slurm + password is the most common (although I admit I\u2019ve been using condor with a VPN wall + password is my real use case right now).<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Error with logging a wandb table that contains pandas dataframe",
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-with-logging-a-wandb-table-that-contains-pandas-dataframe\/1245",
        "Question_created_time":"2021-11-09T02:36:42.038Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":294,
        "Question_body":"<pre><code class=\"lang-auto\">   wandb.log({'full_results': wandb.Table(dataframe=self.averages_results_df, allow_mixed_types=True)})\n<\/code><\/pre>\n<p>error:<br>\nTypeError: keys must be str, int, float, bool or None, not a tuple<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Unable to run wandb online after running offline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/unable-to-run-wandb-online-after-running-offline\/1252",
        "Question_created_time":"2021-11-10T00:54:00.810Z",
        "Question_answer_count":9,
        "Question_score_count":2,
        "Question_view_count":390,
        "Question_body":"<p>I have a compute environment where I was running wandb offline for quite a while. I am now hoping to use it online (to get automatic syncing), however I seem to be unable to set this up now. The following is a minimal reproducible example:<\/p>\n<pre><code class=\"lang-auto\">&gt;&gt; import wandb\n&gt;&gt; test = wandb.init(mode='online')\nTraceback (most recent call last):\n  File \"[path]\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 867, in init\n    wi.setup(kwargs)\n  File \"[path]\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 182, in setup\n    user_settings = self._wl._load_user_settings()\n  File \"[path]\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_setup.py\", line 183, in _load_user_settings\n    flags = self._server._flags\nAttributeError: 'NoneType' object has no attribute '_flags'\nwandb: ERROR Abnormal program exit\n<\/code><\/pre>\n<p>I have tried<\/p>\n<ul>\n<li>running wandb online in the terminal<\/li>\n<li>setting the wandb mode environment variable to be online<\/li>\n<li>uninstalling and reinstalling wandb<\/li>\n<\/ul>\n<p>Is there any way I can run this online?<\/p>",
        "Question_closed_time":"2021-11-16T03:47:28.659Z",
        "Answer_body":"<p>Hey <a class=\"mention\" href=\"\/u\/dimaduev\">@dimaduev<\/a> , thanks so much for the fixes! I think I was able to resolve this through looking at the different WANDB_DIR locations\u2026 I had several in different bashrc\/zshrc files and I suspect this was causing an issue. It seems to be resolved now!<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Memory Error Cause Fail Sweep Runnings",
        "Question_link":"https:\/\/community.wandb.ai\/t\/memory-error-cause-fail-sweep-runnings\/1259",
        "Question_created_time":"2021-11-11T13:55:35.189Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":316,
        "Question_body":"<p>Hi, I really liked ur amazing tool and just started to use it. I m using sweep config for hyperparameters. Sometimes my running is get broke due to some reason in the models parameters etc. and my gpu get stuck with full memory. Is there a way to kill the gpu\u2019s current job to free the gpu ram? it would be amazing to apply it to my code with a given PID number and kill it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Save_period Not Working",
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-period-not-working\/1264",
        "Question_created_time":"2021-11-12T02:28:56.179Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":264,
        "Question_body":"<p>I\u2019m trying to train a model, but I keep receiving an error that tells me \u201ctrain.py: error: unrecognized arguments: --save_period 1.\u201d<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755.png\" data-download-href=\"\/uploads\/short-url\/8oz1v5B3P0W95o6FWMDht4yfVLD.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png\" alt=\"image\" data-base62-sha1=\"8oz1v5B3P0W95o6FWMDht4yfVLD\" width=\"690\" height=\"337\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_1035x505.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1326\u00d7648 66 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nWhat issue do I have here?  Thanks in advance.<\/p>",
        "Question_closed_time":"2021-11-13T06:40:50.863Z",
        "Answer_body":"<p>I think you have  a typo. According to the usage info, the argument name is <code>--save-period<\/code>  , not <code>--save_period<\/code><\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Transfer my account (email change)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/transfer-my-account-email-change\/1247",
        "Question_created_time":"2021-11-09T11:47:45.080Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":333,
        "Question_body":"<p>My current email id will be deactivated soon, so I need to change the email id associated with W&amp;B. Following the advice from this <a href=\"https:\/\/community.wandb.ai\/t\/possible-to-add-options-to-edit-profile\/123\/7\">thread<\/a>, I have created a new account. Can someone help me on this? (Had emailed someone from the Community team last week as well)<\/p>",
        "Question_closed_time":"2021-11-09T22:15:46.540Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dsteam\">@dsteam<\/a>!<\/p>\n<p>I will be happy to help you move your projects to your new account. Could you email us at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a> about this with the details of the move? Specifically:<\/p>\n<ul>\n<li>The entity name of the account you want projects moved from<\/li>\n<li>The entity name of the account you want projects moved into<\/li>\n<li>Which projects you want moved (or if you want all)<\/li>\n<\/ul>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases support<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb API run.history() skip some values",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-api-run-history-skip-some-values\/1126",
        "Question_created_time":"2021-10-28T08:36:56.225Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":349,
        "Question_body":"<p>Hi,<br>\nI have a task to analyses and choose best model from metrics.<br>\nAnd follow instructions of wnadb API  its easy to use.<br>\nBut when i call run.history() \u2013 my result table skip some values \u2013 there is nan in front of some existing test metric values. API have 48 rows and export csv have 71 rows<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Collab example for building an \"evaluation\" table using wandb.log()",
        "Question_link":"https:\/\/community.wandb.ai\/t\/collab-example-for-building-an-evaluation-table-using-wandb-log\/1232",
        "Question_created_time":"2021-11-05T16:32:49.253Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":277,
        "Question_body":"<p>Hi - in the <a href=\"https:\/\/wandb.ai\/_scott\/wandb_example?workspace=\">wandb_example Workspace<\/a>, there is a table visualisation showing \u201cevaluation\u201d results logged from a run:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185.png\" data-download-href=\"\/uploads\/short-url\/znCckAyMsQCwsr3hGddC1h58tN3.png?dl=1\" title=\"Screenshot 2021-11-05 at 16.21.56\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185_2_689x426.png\" alt=\"Screenshot 2021-11-05 at 16.21.56\" data-base62-sha1=\"znCckAyMsQCwsr3hGddC1h58tN3\" width=\"689\" height=\"426\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185_2_689x426.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185_2_1033x639.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/f7f77fb07316f11f2805765bd0e420843cb50185_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2021-11-05 at 16.21.56<\/span><span class=\"informations\">1212\u00d7749 52.6 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>My understanding is that this table has to be created using wandb.log() in the training code, but I can\u2019t access the notebook used for the run in the example workspace.<\/p>\n<p>I want to create a similar evaluation table using one of your examples:  <a href=\"https:\/\/github.com\/wandb\/examples\/examples\/pytorch\/pytorch-cnn-fashion\/train.py\" rel=\"noopener nofollow ugc\">https:\/\/github.com\/wandb\/examples\/examples\/pytorch\/pytorch-cnn-fashion\/train.py<\/a><\/p>\n<p>Is there a code snippet or collab example for doing this? I\u2019ve seen the docs for logging a table, but I need a specific example like the one in the example workspace that shows clothing images, and metrics e.g. \u2018guess\u2019. \u2018truth\u2019 etc.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to show max performance and average across trials",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-show-max-performance-and-average-across-trials\/1172",
        "Question_created_time":"2021-10-31T06:59:33.755Z",
        "Question_answer_count":7,
        "Question_score_count":6,
        "Question_view_count":508,
        "Question_body":"<p>So I\u2019ve been using the default curves to monitor my RL experiments for a while now. They are very handy and easier to manage than my old <code>.csv<\/code> workflow. In my experiments, I have multiple runs with the same hyperparameters and they are organized into groups. What I\u2019m trying to plot is this: create a bar plot of max performance averaged across trials for each group, versus the name of the group.<\/p>\n<p>I tried to create a panel of bar plot, and in general it looks like what I want: it lists all the groups of runs, and automatically calculates some aggregated value of them, e.g. mean or median. But it seems that the plot is taking the mean\/median of all the values from the whole group (like the concat of all trials) instead of giving me a choice of, e.g., averaging over the max return of each run. Here is what the plot looks like:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e.png\" data-download-href=\"\/uploads\/short-url\/3RySOpsmjzfJzAkEHbaGE2ilpro.png?dl=1\" title=\"WX20211031-025712@2x\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_575x500.png\" alt=\"WX20211031-025712@2x\" data-base62-sha1=\"3RySOpsmjzfJzAkEHbaGE2ilpro\" width=\"575\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_575x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">WX20211031-025712@2x<\/span><span class=\"informations\">716\u00d7622 17.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I saw that there are custom tables, but I\u2019m not quite sure how to use them. If it\u2019s easy to write, can someone give some hints about how to get custom tables to do this for me? Lots of thanks.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delete artifact in s3",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-artifact-in-s3\/1228",
        "Question_created_time":"2021-11-04T20:04:44.051Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":357,
        "Question_body":"<p>Hi <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>I was wondering if it\u2019s possible to delete an artifact that is a reference to an S3 object.<br>\nI mean deleting it within weight and biases but also from S3.<\/p>\n<p>If it\u2019s not built-in, is there any webhook that I can use to delete my model in S3 when deleting it from W&amp;B?<\/p>\n<p>The flow would be :<\/p>\n<ol>\n<li>Train =&gt; Push metrics to W&amp;B, push model to S3, add the S3 reference of the model as an artifact in W&amp;B.<\/li>\n<li>Evaluate, do some comparison, ML magic, etc\u2026<\/li>\n<li>Deciding to delete the run as another was better. Delete in W&amp;B, which will remove all the run and all the files in S3 associated with this run.<\/li>\n<\/ol>\n<p>Thanks in advance for any help.<\/p>\n<p>Have a great day <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Using Wandb with HParams on TF",
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-wandb-with-hparams-on-tf\/1233",
        "Question_created_time":"2021-11-06T01:07:59.946Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":579,
        "Question_body":"<p>I think I may have got confused with this one. I had to code up a custom model using TF. It is training and running but I want to do some hyper parameter tuning so been working on getting HParms integrated.<\/p>\n<p>But I\u2019m trying to link up Wandb to keep track of things.<\/p>\n<p>Currently, since I\u2019m using hparms, when I initialize wandb with wandb.init(), it seems to initialize it for the whole process and it doesn\u2019t change when it is a new parameter set.<\/p>\n<p>I am calling the wandb.init() and logging after each parameter run, but still it doesn\u2019t create a unique job.<\/p>\n<p>This the function I call,<\/p>\n<pre><code class=\"lang-auto\">def write_to_wandb(ldl_model_params, KLi, f1_macro):\n    wandb.init(project=\"newjob1\", entity=\"demou\")\n    wandb.config = ldl_model_params\n\n    wandb_log = {\n        \"train KL\": KLi,\n        \"train F1\": f1_macro,\n        }\n\n    # logging accuracy\n    wandb.log(wandb_log)   \n<\/code><\/pre>\n<p>This is called from this train function (a high-level version of it). This <code>train_model<\/code> function is repeated again through another hyperparamter function with different hyper-parameter.<\/p>\n<pre><code class=\"lang-auto\">\ndef train_model(ldl_model_params,X,Y):\n    model = new_model(ldl_model_params)\n    model.fit(X,Y)\n    predict = model.transform(X)\n    KLi,F1 = model.evaluate(predict,Y)\n    write_to_wandb(ldl_model_params,KLi,F1)\n<\/code><\/pre>\n<p>So how do I fix this? I want each call to train_model to be recorded in a new run.<\/p>\n<p>I\u2019m new to wandb so I have a feeling that I am not using it as it should be. Thanks.<\/p>",
        "Question_closed_time":"2021-11-08T17:17:12.513Z",
        "Answer_body":"<p>Just had a chat with the support and figured out how to fix the problem with over-writing.<\/p>\n<p>Issue was with the init function and there is a flag for reinitializing (<code>reinit=True<\/code>)<\/p>\n<p><code>wandb.init(project=\"newjob1\", entity=\"demou\",reinit=True)<\/code>  this fixed this issue.<\/p>",
        "Question_self_resolution":true
    },
    {
        "Question_title":"Sweep track loss from Tensorboard",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-track-loss-from-tensorboard\/1226",
        "Question_created_time":"2021-11-04T18:57:27.640Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":227,
        "Question_body":"<p>Hi,<br>\nIs it possible to use sweep with a metric that is only visible in Tensorboard?<br>\nIt does show up on WandB when  sync_tensorboard=True<\/p>\n<p>But sweep does not seem to work properly when I use the name showing up in the GUI to be tracked and minimized.<\/p>\n<p>Thanks<br>\nBen<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb sweeps running on Kaggle GPU or Colab GPU are much slower than on my local CPU",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sweeps-running-on-kaggle-gpu-or-colab-gpu-are-much-slower-than-on-my-local-cpu\/794",
        "Question_created_time":"2021-09-27T10:02:32.286Z",
        "Question_answer_count":6,
        "Question_score_count":4,
        "Question_view_count":432,
        "Question_body":"<p>Hi there,<\/p>\n<p>i have run a few sweeps on my local computer and the same sweeps on Kaggle and Colab<\/p>\n<p>i have an i7 (10th gen) CPU in my home computer but no GPU<br>\ni measured around 50secs for 100 epochs (1 run)<\/p>\n<p>on Kaggle and Colab the same 100 epochs took 2mins 30secs (Colab) and ~3mins  (Kaggle) <em>using GPU<\/em><\/p>\n<p>how is that possible? am i doing something wrong?<\/p>\n<p>i observed this extreme slowdown only when using W&amp;B Sweeps<br>\nno slowdown when running single experiments<\/p>\n<p>please help, any idea appreciated!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Chrome Inline JavaScript Issue when Rendering Molecules",
        "Question_link":"https:\/\/community.wandb.ai\/t\/chrome-inline-javascript-issue-when-rendering-molecules\/1217",
        "Question_created_time":"2021-11-03T21:20:07.326Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":307,
        "Question_body":"<p>Hello, everyone.<br>\nI recently have been trying to log wandb.Molecule objects via PyTorch Lightning. However, when I view the logged Molecules in my web browser (Google Chrome, Version 95.0.4638.69, 64-Bit), I see the following error, preventing my Molecules from being rendered.<\/p>\n<p><em>[Report Only] Refused to apply inline style because it violates the following Content Security Policy directive: \u201cdefault-src \u2018none\u2019\u201d. Either the \u2018unsafe-inline\u2019 keyword, a hash (\u2018sha256-NFPvvJTeausaOnuU9syzBhm5OjQ9MGcbA9SexsBrsF4=\u2019), or a nonce (\u2018nonce-\u2026\u2019) is required to enable inline execution. Note also that \u2018style-src\u2019 was not explicitly set, so \u2018default-src\u2019 is used as a fallback.<\/em><\/p>\n<p>It looks to me like Chrome is preventing WandB\u2019s web site from rendering inline JavaScript. For reference, I have disabled any browser extension that may be affecting this, and that didn\u2019t seem to help.<br>\nAny ideas as to how to get around this issue? Without of course using a new browser <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=10\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parallelizing runs with multiple logical GPU's",
        "Question_link":"https:\/\/community.wandb.ai\/t\/parallelizing-runs-with-multiple-logical-gpus\/1220",
        "Question_created_time":"2021-11-04T00:31:12.090Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":257,
        "Question_body":"<p>With Google Colab (or similar large GPUs setups and JupyterHub) you can create multiple logical\/virtual GPU\u2019s and parallelize training runs assuming your models are small enough.<\/p>\n<pre><code class=\"lang-auto\">gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Create 2 virtual GPUs with 1GB memory each\n  try:\n    tf.config.set_logical_device_configuration(\n        gpus[0],\n        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)\n<\/code><\/pre>\n<p>Is it possible to train multiple sweeps runs in parallel with logical GPU\u2019s within a Colab like environment?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wandb process not getting terminated properly",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-process-not-getting-terminated-properly\/1166",
        "Question_created_time":"2021-10-30T13:24:58.677Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":343,
        "Question_body":"<p>My process is not getting terminated properly (running in a multi-GPU setting). It is trying to upload information but gets stuck for some reason. I am facing this problem since yesterday, and haven\u2019t made any changes to the version of the library (although this didn\u2019t get resolved after upgrading the library to the latest version). Any help will be highly appreciated. I can disable wandb completely by passing <code>mode = \"disabled\"<\/code> in the test setting, but need it while running sweeps or logging training metrics.<br>\nP.S.: Same code was running just fine till yesterday.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d.png\" data-download-href=\"\/uploads\/short-url\/7rETgzwUz7nuCquITds6NyYKXVj.png?dl=1\" title=\"Screenshot 2021-10-30 at 6.52.11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png\" alt=\"Screenshot 2021-10-30 at 6.52.11 PM\" data-base62-sha1=\"7rETgzwUz7nuCquITds6NyYKXVj\" width=\"690\" height=\"69\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_1035x103.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2021-10-30 at 6.52.11 PM<\/span><span class=\"informations\">1048\u00d7106 27.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Change logger handler",
        "Question_link":"https:\/\/community.wandb.ai\/t\/change-logger-handler\/1203",
        "Question_created_time":"2021-11-02T19:30:50.395Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":300,
        "Question_body":"<p>Hi,<\/p>\n<p>I use <a href=\"https:\/\/rich.readthedocs.io\/en\/stable\/logging.html\" rel=\"noopener nofollow ugc\">RichHandler<\/a> everywhere in my code as well as <a href=\"https:\/\/rich.readthedocs.io\/en\/stable\/traceback.html\" rel=\"noopener nofollow ugc\">Rich Tracebacks<\/a> as they\u2019re just useful beautiful and really convenient.<\/p>\n<p>I was wondering how I could integrate the handler with WandB to have my logs in the same format.<\/p>\n<p>Thanks in advance for any help.<br>\nHave a great day.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"WandB not using user PID when updating",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-not-using-user-pid-when-updating\/1204",
        "Question_created_time":"2021-11-02T19:49:53.147Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":352,
        "Question_body":"<p>Hello,<\/p>\n<p>I used  <code>tempfile.mkdtemp() <\/code> to create a temporary directory for my runs (as I don\u2019t want a persistent folder with tons of runs)<\/p>\n<p>For training everything works fine but when resuming the run to do some validation \/ evaluation updates, and using <code>run.summary.update({\"key\": value})<\/code> I got a<\/p>\n<pre><code class=\"lang-auto\">wandb: WARNING Path \/tmp\/tmpq5uafy4d\/wandb\/ wasn't writable, using system temp directory\n<\/code><\/pre>\n<p>with obviously<\/p>\n<pre><code class=\"lang-auto\">File \"\/mnt\/Projets\/nlp\/.venv\/lib\/python3.9\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 855, in _update_summary\n    with open(summary_path, \"w\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpq5uafy4d\/wandb\/run-20211102_153311-37264m5k\/files\/wandb-summary.json'\n<\/code><\/pre>\n<p>As in the doc of <a href=\"https:\/\/docs.python.org\/3.9\/library\/tempfile.html#tempfile.mkdtemp\" rel=\"noopener nofollow ugc\"><code>mkdtemp<\/code><\/a> :<\/p>\n<pre><code class=\"lang-auto\"> The directory is readable, writable, and searchable only by the creating user ID.\n<\/code><\/pre>\n<p>So I guess WandB is not using the user ID and thus is not able to write in the directory for updating.<br>\nNote that this directory is different from the training one (as it\u2019s random at each init)<\/p>\n<p>Thanks in advance for any help.<br>\nHave a great day.<\/p>",
        "Question_closed_time":"2021-11-03T18:21:20.198Z",
        "Answer_body":"<p>As of now, there isn\u2019t an option to enable that by default. One issue you should be aware of is that if you are currently logging a run when you call <code>wandb sync --clean<\/code> bad things will happen. We\u2019re working on improving the the robustness of these features and will likely support an automatic clean option in the future.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Wandb Agent - some runs fail",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-agent-some-runs-fail\/1094",
        "Question_created_time":"2021-10-25T21:34:42.205Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":318,
        "Question_body":"<p>I\u2019ve been using the Wandb agent to do some hyperparameter optimization with sweep config. Somehow approx. 70% of my runs fails.  This message is persisted:<\/p>\n<p>wandb: ERROR Run kyg8jl2m errored: InternalError()<\/p>\n<p>Is this a known issue?<\/p>\n<p>edit: I just did another 20 runs<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6fa137232597a0d819fa8d93bcea31af5fc491c8.png\" alt=\"image\" data-base62-sha1=\"fVwoTFqCbnNIdB63Atkf4ye1nm0\" width=\"585\" height=\"211\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"HP sweep - correct way to stop a specific agent (and not the entire sweep)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hp-sweep-correct-way-to-stop-a-specific-agent-and-not-the-entire-sweep\/1173",
        "Question_created_time":"2021-10-31T13:23:16.678Z",
        "Question_answer_count":5,
        "Question_score_count":3,
        "Question_view_count":694,
        "Question_body":"<p>Hi,<\/p>\n<p>I am conducting a parameter sweep, and I use my dev machine during the night for extra compute. My problem is that I don\u2019t know how to correctly stop the local runs. Any suggestions or best practices would be appreciated.<\/p>\n<p>A related question - if I stop an agent run forcefully (for instance, close the process running the agent) how would the sweep controller handle the run data? would it remove it from the dashboard? would it be indicated in any way?<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to log multiple metrics to the same chart?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-log-multiple-metrics-to-the-same-chart\/1160",
        "Question_created_time":"2021-10-30T06:05:46.747Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":762,
        "Question_body":"<p>Under <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log#common-workflows\" class=\"inline-onebox\">Log Data with wandb.log - Documentation<\/a> it says I can have multiple metrics show up on the same chart by logging them in the same dict. On the UI they still show up on different charts though <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/frowning.png?v=10\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\"><br>\nAny ideas on what I could be doing wrong? I can post code if necessary but I really don\u2019t think I\u2019m using the API incorrectly<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get S3 Filepath for WandB Artifact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-s3-filepath-for-wandb-artifact\/990",
        "Question_created_time":"2021-10-15T17:13:38.300Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":378,
        "Question_body":"<p>Hi team,<\/p>\n<p>If I use W&amp;B Artifacts with an S3 Reference, is there any easy way to get the underlying S3 URI?<\/p>\n<pre><code class=\"lang-auto\">artifact = run.use_artifact('my_artifact:latest')\ns3_path = artifact.&lt;some_method&gt;()\n<\/code><\/pre>\n<p>For context, I\u2019m trying to train a HuggingFace model with Sagemaker. When I spin up the job, Sagemaker expects paths to local files or S3 URIs to the dataset. I\u2019m trying to avoid downloading the data to my local machine, by getting the proper S3 URL via W&amp;B Artifacts; since I\u2019m already using Artifacts for data versioning.<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to find out if wandb service is down",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-find-out-if-wandb-service-is-down\/1188",
        "Question_created_time":"2021-11-01T19:37:25.251Z",
        "Question_answer_count":4,
        "Question_score_count":2,
        "Question_view_count":348,
        "Question_body":"<p>Yesterday, wandb initialization was working for me both from my local desktop and on a remote EC2 instance. Today, I get the following error:<\/p>\n<pre><code class=\"lang-auto\">**wandb** : Network error (ReadTimeout), entering retry loop. See wandb\/debug-internal.log for full traceback.\n<\/code><\/pre>\n<p>I haven\u2019t changed anything about the settings, so this makes me think this is a wandb service issue. Is there a page on the website that tells the status of wandb services?<\/p>\n<p>Thanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Programmatically accessing artifact object very slow for first call for large artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/programmatically-accessing-artifact-object-very-slow-for-first-call-for-large-artifacts\/1158",
        "Question_created_time":"2021-10-29T17:07:26.634Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":360,
        "Question_body":"<p>Hello!<\/p>\n<p>I came across this issue recently, and I was wondering whether anything can be done to speed up this process. We are using W&amp;B as source of truth for versioning of our datasets. Each dataset is an artefact in a specific project, and files making up this dataset are added as references (everything is stored on S3).<\/p>\n<p>We sometime need to retrieve the path (including version) to a specific file in the artefact. This is typically very fast (&lt;1s) but for larger artefact (made up of &gt;10K references), the process can slow down significantly and take up to 30 seconds. We realized that this holds true whenever we try to access the artifact for the first time (e.g. getting its digest).<\/p>\n<p>Is it expected that artifacts with a large number of files will result in long wait for the first operation when accessing in programmatically in Python?<\/p>\n<p>We typically use the public API to access the artifact (see below for example) but the same happens when using a run.<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nartifact = api.artifact(\"my_org\/my_project\/my_artifact:latest\")\nfile_info = artifact.get_path(\"example_file_in_artifact\")\ns3_path = file_info.ref\ns3_version = file_info.extra[\"versionID\"]\n<\/code><\/pre>\n<p>Thanks!<\/p>\n<p>Nicolas<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Invalid artifact",
        "Question_link":"https:\/\/community.wandb.ai\/t\/invalid-artifact\/1198",
        "Question_created_time":"2021-11-02T14:31:28.014Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":360,
        "Question_body":"<p>When trying to add a reference to an object stored on s3 I got a :<\/p>\n<pre><code class=\"lang-auto\">CommError: Invalid artifact path: s3:\/\/my_bucket_names\/my_lang_folder\/my_subfolder\/my_file.json\n<\/code><\/pre>\n<p>I used :<\/p>\n<pre><code class=\"lang-auto\"> self.run = wandb.init(\n     project=\"my_project\",\n     entity=\"my_group_name\",\n      dir=self.temp_dir,\n      resume=bool(config.previous_model),\n )\n\n for dataset in config.datasets:\n    self.run.use_artifact(\n        f\"s3:\/\/my_bucket_name\/{make_path(dataset['lang'],dataset['type'],[],dataset['name'],'json')}\",\n        type=\"train_dataset\",\n    )\n<\/code><\/pre>\n<p>I\u2019m sure the dataset exists in this bucket. However, it\u2019s a private bucket but I have access to it with my credentials.<\/p>\n<p>Thanks in advance for any help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Moving projects from one team to another",
        "Question_link":"https:\/\/community.wandb.ai\/t\/moving-projects-from-one-team-to-another\/1192",
        "Question_created_time":"2021-11-02T08:52:48.904Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":284,
        "Question_body":"<p>Hi All,<br>\nWanted to know if it is possible to move projects from one team to another. I want to add a user for a specific project instead of adding him to the team which owns the project. Since it was not possible I thought that a workaround would be to create new team with the specific user and transferring the desired project.<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Scripting reports?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/scripting-reports\/1170",
        "Question_created_time":"2021-10-30T22:10:40.070Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":319,
        "Question_body":"<p>Hello Wandb community,<\/p>\n<p>Is there a way to script reports in Wandb or make report templates? I find myself having to make similar reports for different wandb projects and t would be awesome if there was a way to do this programmatically<\/p>\n<p>Thanks<br>\nTed<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Create your team fails",
        "Question_link":"https:\/\/community.wandb.ai\/t\/create-your-team-fails\/1149",
        "Question_created_time":"2021-10-29T07:18:07.008Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":767,
        "Question_body":"<p>Hey! I am trying to create a team but after trying 10 times (with obscure team names) I still get the following error: \u201cError creating team (an organization with this name already exists). Please try again.\u201d<\/p>\n<p>What am I doing wrong? Thank you!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Running wandb.init() locally causes permission error",
        "Question_link":"https:\/\/community.wandb.ai\/t\/running-wandb-init-locally-causes-permission-error\/824",
        "Question_created_time":"2021-09-30T22:36:10.454Z",
        "Question_answer_count":4,
        "Question_score_count":1,
        "Question_view_count":531,
        "Question_body":"<p>Hello, wandb newbie here. I\u2019m trying to run my first local wandb project locally on a work machine (macOS) where I have admin status. Unfortunately when I run,<\/p>\n<p><code>wandb.init(project=\"my_project\")<\/code><\/p>\n<p>I get the following permission error. Thanks in advance for any helpful feedback!<\/p>\n<pre><code class=\"lang-auto\">wandb: You can find your API key in your browser here: http:\/\/localhost:8080\/authorize\nTraceback (most recent call last):\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 800, in init\n    wi.setup(kwargs)\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_init.py\", line 167, in setup\n    wandb_login._login(anonymous=anonymous, force=force, _disable_warning=True)\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_login.py\", line 268, in _login\n    wlogin.prompt_api_key()\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_login.py\", line 196, in prompt_api_key\n    key, status = self._prompt_api_key()\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/wandb_login.py\", line 184, in _prompt_api_key\n    no_create=self._settings.force if self._settings else None,\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/apikey.py\", line 121, in prompt_api_key\n    write_key(settings, key, api=api)\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/lib\/apikey.py\", line 211, in write_key\n    api.clear_setting(\"anonymous\", globally=True, persist=True)\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 256, in clear_setting\n    Settings.DEFAULT_SECTION, key, globally=globally, persist=persist\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/old\/settings.py\", line 69, in clear\n    clear_setting(self._global_settings, Settings._global_path(), persist)\n  File \"\/opt\/miniconda3\/envs\/abcnet\/lib\/python3.7\/site-packages\/wandb\/old\/settings.py\", line 65, in clear_setting\n    with open(settings_path, \"w+\") as f:\nPermissionError: [Errno 13] Permission denied: '\/Users\/andrew\/.config\/wandb\/settings'\nwandb: ERROR Abnormal program exit\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delete user account",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-user-account\/1140",
        "Question_created_time":"2021-10-28T14:41:47.787Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":250,
        "Question_body":"<p>I have accidentally created two accounts.<br>\nI want to delete this account please.<\/p>\n<p>My user name is ab3-yang<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to only update specific parts of a Table?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-there-a-way-to-only-update-specific-parts-of-a-table\/1110",
        "Question_created_time":"2021-10-27T09:35:20.572Z",
        "Question_answer_count":10,
        "Question_score_count":10,
        "Question_view_count":458,
        "Question_body":"<p>Hello Everyone! (Long time user, first time poster <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slightly_smiling_face.png?v=12\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\" loading=\"lazy\" width=\"20\" height=\"20\">)<\/p>\n<p>I just started using WandB tables to log my predictions alongside their input images. It has been very useful so far. My problem arises when I run my code on a cluster we have at my university.<\/p>\n<p>For simplicity, let\u2019s say that every epoch, I am logging a table with the following columns: <code>[id, Image, prediction]<\/code> which is a list of <code>[string, wandb.Image, int]<\/code>.<\/p>\n<p>Every time<code> wandb.Image()<\/code> is called, it saves the image employing the PIL library (can be seen below).  My problem arises when, after a certain number of epochs, I run into memory problems:<\/p>\n<pre><code class=\"lang-auto\"> Traceback (most recent call last):\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/PhD\/2021\/marato-derma\/derma\/sol\/cnn_recommendations\/processing\/train_utils.py\", line 206, in log_wandb_table\n    row = [img_id, wandb.Image(image),\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/wandb\/sdk\/data_types.py\", line 1587, in __init__\n    self._initialize_from_data(data_or_path, mode)\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/wandb\/sdk\/data_types.py\", line 1700, in _initialize_from_data\n    self._image.save(tmp_path, transparency=None)\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2102, in save\n    save_handler(self, fp, filename)\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/PIL\/PngImagePlugin.py\", line 900, in _save\n    ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/PIL\/ImageFile.py\", line 511, in _save\n    fp.write(d)\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/PIL\/PngImagePlugin.py\", line 748, in write\n    self.chunk(self.fp, b\"IDAT\", data)\n  File \"\/mnt\/gpid07\/imatge\/carlos.hernandez\/Documents\/base\/lib\/python3.6\/site-packages\/PIL\/PngImagePlugin.py\", line 735, in putchunk\n    fp.write(data)\nOSError: [Errno 28] No space left on device\n<\/code><\/pre>\n<p>I was wondering if Tables allow only to update specific columns. The <code>id<\/code> and <code>Image<\/code> remain constant for the entire training, the only values that I am interested in their evolution are the predictions.<\/p>\n<p>Has anyone encountered a similar problem? Any ideas on how to shortcut my lack of memory would be welcome!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"SOLVED: Runs are not logged separately",
        "Question_link":"https:\/\/community.wandb.ai\/t\/solved-runs-are-not-logged-separately\/1103",
        "Question_created_time":"2021-10-26T17:27:02.662Z",
        "Question_answer_count":4,
        "Question_score_count":4,
        "Question_view_count":407,
        "Question_body":"<p>Hello, I\u2019m trying to run several studies and have them log into separate runs but be grouped un der the name \u201cScenario Eval\u201d as part of the project \u201cScenario\u201d. I have one python script running a for-loop with multiple calls of the following lines:<\/p>\n<pre><code class=\"lang-auto\">for STUDY_NAME, study ...:\n    wandb_logger = WandbLogger(project=\"Scenario\",  name=STUDY_NAME+'_EVAL_'+str(study.best_params['lr']),\ngroup='Scenario Eval',\n log_model=\"all\",\n reinit=True)\n            trainer = pl.Trainer(\n                stochastic_weight_avg=False,\n                logger=wandb_logger,\n                checkpoint_callback=False,\n                log_every_n_steps=10,\n                default_root_dir = cache_path,\n                max_epochs=N_EPOCHS_EVAL,\n                gpus=1 if torch.cuda.is_available() else None,\n            )\n            wandb_logger.watch(model)\n            trainer.fit(model, datamodule=datamodule)\n            trainer.logger.log_hyperparams(hyperparameters)\n<\/code><\/pre>\n<p>In Wandb everything shows up as a single run, despite multiple loggers being created in python with explicit \u201creinit=True\u201d.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7.png\" data-download-href=\"\/uploads\/short-url\/tWWeJa1q9uMmt5B1QFE3PPNWdHV.png?dl=1\" title=\"W&amp;amp;B Chart 26.10.2021, 19_30_41\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7_2_690x345.png\" alt=\"W&amp;B Chart 26.10.2021, 19_30_41\" data-base62-sha1=\"tWWeJa1q9uMmt5B1QFE3PPNWdHV\" width=\"690\" height=\"345\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7_2_690x345.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7_2_1035x517.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7_2_1380x690.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d1e8a5e923f3641d8ba225411a83542eece543f7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 26.10.2021, 19_30_41<\/span><span class=\"informations\">2400\u00d71200 225 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nDo I need to do something else to separate these runs?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get all the artifacts of a project from the API",
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-all-the-artifacts-of-a-project-from-the-api\/1088",
        "Question_created_time":"2021-10-25T15:18:59.226Z",
        "Question_answer_count":4,
        "Question_score_count":4,
        "Question_view_count":290,
        "Question_body":"<p>How can I use the API to get all the artifacts of a project, possibly of a given type?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Sweeps with multiple seeds for the same config values",
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweeps-with-multiple-seeds-for-the-same-config-values\/1077",
        "Question_created_time":"2021-10-24T14:31:01.671Z",
        "Question_answer_count":8,
        "Question_score_count":8,
        "Question_view_count":1204,
        "Question_body":"<p>Hi,<\/p>\n<p>Sometimes (for example in RL) agents are very unstable and you only know how a config behaves if you tested it on 5-10 seeds. So I was wondering if there is a feature in wandb sweeps that allows the aggregation of a metric over multiple seeds (but the same config values)?<\/p>\n<p>I know one solution is to define a for loop in my own training script that repeats the same config, but I would like these runs to be executed in parallel, and possibly even on different machines.<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Get best model from artifacts",
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-best-model-from-artifacts\/992",
        "Question_created_time":"2021-10-15T18:42:05.709Z",
        "Question_answer_count":4,
        "Question_score_count":5,
        "Question_view_count":361,
        "Question_body":"<p>Hi,<\/p>\n<p>I guess this use-case is common but I cannot figure it out\u2026<\/p>\n<p>I would like to log one model per run, and in the end, be able to load the best overall model for production.<\/p>\n<p>So like :<br>\nRun 1,2,3,4,5\u2026<\/p>\n<pre><code class=\"lang-auto\">run.log_artifact(my_model_artifact)\n<\/code><\/pre>\n<p>Production:<\/p>\n<pre><code class=\"lang-auto\">artifact = api.artifact.get_best_of_all_my_runs()\n<\/code><\/pre>\n<p>For now my solution is :<\/p>\n<pre><code class=\"lang-auto\">Runs : \nartifact.save() # with the same name so only one artifact for all runs\n\nProduction\nartifact = api.artifact(\"entity\/project\/artifact:alias\") # Get the only model (which also should be the best)\n<\/code><\/pre>\n<p>Thanks in advance for any help.<br>\nhave a great day<\/p>",
        "Question_closed_time":"2021-10-22T19:28:10.719Z",
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ierezell\">@ierezell<\/a>,<\/p>\n<p>I think I understand your question a little better. We are currently working on a feature that will make exactly what you\u2019re asking for super clean and easy <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>In the meantime the most straightforward way of going about this would be to save the performance of all of the metrics you care about to the <code>run.summary<\/code> of the run that produced that model. Then from the <code>api<\/code> you can query all the runs in the project and select the best run using the metrics you set in the summary. Then you can get the download the best model and use it as an input to your production code.<\/p>\n<p>Here is a <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#download-the-best-model-file-from-a-sweep\">related example<\/a> querying the best model from a sweep but the process will be slightly different for you use case.<\/p>",
        "Question_self_resolution":false
    },
    {
        "Question_title":"Detectron2 Visualization",
        "Question_link":"https:\/\/community.wandb.ai\/t\/detectron2-visualization\/1086",
        "Question_created_time":"2021-10-25T09:35:46.674Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":540,
        "Question_body":"<p>Hi,<\/p>\n<p>Has anyone already implemented a visulalization of segmentation or object detection tasks using the detectron2 library?<br>\nThere is already a GitHub issue on this: <a href=\"https:\/\/github.com\/facebookresearch\/detectron2\/issues\/3404\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Visualizations on W&amp;B \u00b7 Issue #3404 \u00b7 facebookresearch\/detectron2 \u00b7 GitHub<\/a> but I was wondering if anyone might already has a somewhat usable code to start with.<\/p>\n<p>Thanks<br>\nBen<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"I think that W&B is having some connection issues since yesterday night",
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-think-that-w-b-is-having-some-connection-issues-since-yesterday-night\/1073",
        "Question_created_time":"2021-10-23T15:10:04.843Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":332,
        "Question_body":"<p>Although it\u2019s still possible to update data to W&amp;B, since yesterday night no data can be downloaded with the error:<\/p>\n<pre><code class=\"lang-auto\">\/requests\/models.py\", line 953, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https:\/\/api.wandb.ai\/graphql\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How can I log best values of a metric\/loss in wandb summary using Pytorch-Lightning?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-log-best-values-of-a-metric-loss-in-wandb-summary-using-pytorch-lightning\/941",
        "Question_created_time":"2021-10-13T06:07:10.356Z",
        "Question_answer_count":5,
        "Question_score_count":3,
        "Question_view_count":363,
        "Question_body":"<p>In wandb documentation there are examples like this: <code>wandb.run.summary[\"best_accuracy\"] = best_accuracy<\/code><br>\nNot sure how to do something like that in training_step\/validation_step using self.log, considering the values of metrics are automatically calculated on epochs under the hood of the API.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"UI : How to drag\/move in a plot?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/ui-how-to-drag-move-in-a-plot\/1021",
        "Question_created_time":"2021-10-18T07:50:20.154Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":295,
        "Question_body":"<p>Let\u2019s say I\u2019m watching a plot.<br>\nThen I zoom in a specific section within the plot.<br>\nThen I want to look a bit more to the right.<br>\nWhat kind of key\/mouse button allows me to move my view to the right  ?<br>\nMiddle mouse button does not work <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"HP Sweep: Conditional Sampling",
        "Question_link":"https:\/\/community.wandb.ai\/t\/hp-sweep-conditional-sampling\/726",
        "Question_created_time":"2021-09-21T16:50:31.093Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":299,
        "Question_body":"<p>Suppose I have a somewhat complicated hyper parameter distribution I\u2019d like to sample:<\/p>\n<p>For example, I have a hyperparameter called HP1 controlling normalization applied my dataset. If I sample HP1 \u2190 maximum-eigenvalue-norm, then maybe I have another hyperparameter I must sample; in this case that could be how to compute maximum eigenvalue which could be in the set {fancy-eigenvalue-computation, torch-built-in-symeig}.<\/p>\n<p>But suppose if normalization technique was sampled as HP1 \u2190 Frobenius-norm, then I have no other hyper parameters to sample.<\/p>\n<p>Optuna handles this nicely, and I was hoping W&amp;B\u2019s had a similar way of auto-magically handling it.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Launching More Agents in HP Sweep",
        "Question_link":"https:\/\/community.wandb.ai\/t\/launching-more-agents-in-hp-sweep\/733",
        "Question_created_time":"2021-09-21T18:59:12.251Z",
        "Question_answer_count":3,
        "Question_score_count":5,
        "Question_view_count":334,
        "Question_body":"<p>The documentation shows how, once the sweep is running, <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/existing-project\">we can spawn off more agents<\/a>.<\/p>\n<p>But I can\u2019t figure out a way to get to that actual page and do it.<\/p>\n<p>If I open the \u201cSweeps\u201d tab, I see the button \u201cCreate Sweep\u201d, but I\u2019m not sure that\u2019s what I\u2019m looking to do (right?). I want to launch a new agent of this sweep, not an entirely new sweep.<\/p>\n<p>Can I simply run the same code on multiple machines, and will it automatically know (through the same project name?) to combine all those runs in the same overall sweep?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Copying run from a project to another and adding the right hyperparameter",
        "Question_link":"https:\/\/community.wandb.ai\/t\/copying-run-from-a-project-to-another-and-adding-the-right-hyperparameter\/1049",
        "Question_created_time":"2021-10-20T13:54:12.400Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":358,
        "Question_body":"<p>Hello,<\/p>\n<p>I have been running several test on differents on different projects and I am struggling for doing something pretty simple I think.<br>\nI have run a sweep in a project:\u201cproject 1\u201d for testing for hyperparameter.<br>\nA bit later I modified a bit my architecture and run another test and send it to another project: \u201cproject 2\u201d.<br>\nNow I want to compare some of the run of project 1 with the one of project 2. I tried to use the option move, however the runs I moved disappeared from project1\u2026 and I don\u2019t want that\u2026 How can I copy the run from one project to another one (Q1)<br>\nMoreover I did not logged my hyperparameter for project 2. Can I add them manually from wandb interface ? (Q2)<\/p>\n<p>Finally I don\u2019t understand why some hyperparameters of my run for project 2 were not logged I did the following:<\/p>\n<pre><code class=\"lang-auto\">\nimport wandb\nwandb.login()\n\nimport stuff\ndefine model and dataloaders\n\nwandb.init(project=\"Structural encoder\", entity=\"barthelemymp\")\nwandb.config = {\n  \"num_layers\": 6,\n  \"forward_expansion\": 2048,\n  \"batch_size\": 10,\n  \"Encoder\": \"Structural\"\n}\n\nfor epoch in range(num_epochs):\n      ...\n      ...\n      ...\n      wandb.log({\"Train loss\": mean_lossTrain, \"Val Loss\":mean_lossVal, \"epoch\":epoch})\n<\/code><\/pre>\n<p>In the end on wandb website for this run I see only the trainloss valloss and epoch but not the config. What have I done wrong ? (Q3)<\/p>\n<p>Lot\u2019s of Question in one post, but any help will be appreciated,<\/p>\n<p>Best<\/p>\n<p>Barth<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Delete files from a run",
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-files-from-a-run\/1031",
        "Question_created_time":"2021-10-19T08:14:59.024Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":706,
        "Question_body":"<p>I need to free up some space and want to delete an heavy file uploaded within a run.<br>\nI dont want to delete the whole logs of the runs, only this one heavy file<\/p>\n<p>How to ?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"ValueError('signal only works in main thread')",
        "Question_link":"https:\/\/community.wandb.ai\/t\/valueerror-signal-only-works-in-main-thread\/686",
        "Question_created_time":"2021-09-18T01:45:50.462Z",
        "Question_answer_count":4,
        "Question_score_count":3,
        "Question_view_count":2218,
        "Question_body":"<p>Has anyone else run into this error:<br>\n<code>ValueError('signal only works in main thread')<\/code><\/p>\n<p>I\u2019m running a hyper parameter sweep using PL and Weights and Biases\u2019s framework.<\/p>\n<p>Running on a GPU on Google Colab which causes all launched runs to fail. Running it locally (Mac OS) prompts \u2018signal only works in main thread\u2019 to be printed to stdout (which also happens on Colab) but it doesn\u2019t crash.<\/p>\n<p>When I train the model with just PL outside of a W&amp;B sweep, it works fine.<\/p>\n<p>Any ideas? It seems people using <a href=\"https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/3651\" rel=\"noopener nofollow ugc\">Ray with PL<\/a> have come across this. The hacky solution presented there ( <code>os.environ['SLURM_JOB_NAME'] = 'bash'<\/code> ) doesn\u2019t work in my case (neither on Mac OS or Colab).<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Parameter importance panel empty in created report",
        "Question_link":"https:\/\/community.wandb.ai\/t\/parameter-importance-panel-empty-in-created-report\/1036",
        "Question_created_time":"2021-10-19T17:20:32.088Z",
        "Question_answer_count":7,
        "Question_score_count":0,
        "Question_view_count":412,
        "Question_body":"<p>Hi,<\/p>\n<p>I completed about 40 hyperparameter tuning runs with Ray Tune, all beautifully logged-in W&amp;B. I wanted to add the parameter importance panel but it does not load any graphs even though I selected all these runs as instructed.<\/p>\n<p>All I get is this empty panel <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ba846238f88dfc543119347ce20730a9afa05f86.png\" data-download-href=\"\/uploads\/short-url\/qC0rig18Mj3Pbm03LKWO3wwZUEu.png?dl=1\" title=\"Screen Shot 2021-10-19 at 7.19.15 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ba846238f88dfc543119347ce20730a9afa05f86_2_690x320.png\" alt=\"Screen Shot 2021-10-19 at 7.19.15 PM\" data-base62-sha1=\"qC0rig18Mj3Pbm03LKWO3wwZUEu\" width=\"690\" height=\"320\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ba846238f88dfc543119347ce20730a9afa05f86_2_690x320.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ba846238f88dfc543119347ce20730a9afa05f86.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/ba846238f88dfc543119347ce20730a9afa05f86.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/ba846238f88dfc543119347ce20730a9afa05f86_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2021-10-19 at 7.19.15 PM<\/span><span class=\"informations\">770\u00d7358 8.55 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>What I am doing wrong?<\/p>\n<p>Best,<br>\nVladimir<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Report command '\/' not working in chrome",
        "Question_link":"https:\/\/community.wandb.ai\/t\/report-command-not-working-in-chrome\/952",
        "Question_created_time":"2021-10-13T16:15:22.845Z",
        "Question_answer_count":5,
        "Question_score_count":2,
        "Question_view_count":289,
        "Question_body":"<p>Hi,<br>\ncurrently trying to access the commands in a report like for creating a panel etc. through typing \u2018\/\u2019 doesn\u2019t work for me in chrome. If I type \u2018\/\u2019  nothing happens. It worked until recently and still works in fire fox.<br>\nMy chrome version is 94.0.4606.81.<br>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Add Metadata after an artifact has been logged",
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-metadata-after-an-artifact-has-been-logged\/970",
        "Question_created_time":"2021-10-14T04:20:51.523Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":379,
        "Question_body":"<p>Hi All,<\/p>\n<p>I\u2019m currently using the W&amp;B Metaflow Integration: <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/other\/metaflow\">https:\/\/docs.wandb.ai\/guides\/integrations\/other\/metaflow<\/a>. Any instance variables that are Pandas Dataframes or PathLibs are automatically logged as dataset artifacts. Due to this, I\u2019m not able to supply a description for the artifact or any metadata for it when the artifact is created. Is there any way to supply this information after the artifact is created?<\/p>\n<p>Thanks for the help!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Colab Disconnecting",
        "Question_link":"https:\/\/community.wandb.ai\/t\/colab-disconnecting\/911",
        "Question_created_time":"2021-10-11T09:19:10.285Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":328,
        "Question_body":"<p>Please help. I\u2019m trying to use wandb in colab and was able to do so yesterday for the first time. All be it, the runtime would disconnect and then reconnect in the same state after each training session.<\/p>\n<p>Today however, Everytime i login, it crashes after hanging for 30 seconds or so.<\/p>\n<p>Has anyone had any similar experiences?<\/p>\n<p>here is my code,<br>\nall in seperate cells<\/p>\n<p><strong>!pip install wandb -qqq<\/strong><\/p>\n<p><strong>import wandb<\/strong><\/p>\n<p><strong>wandb.login()<\/strong><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Creating Artifact Manually While Using Metaflow <> WandB Integration",
        "Question_link":"https:\/\/community.wandb.ai\/t\/creating-artifact-manually-while-using-metaflow-wandb-integration\/935",
        "Question_created_time":"2021-10-12T18:54:06.799Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":303,
        "Question_body":"<p>Hi everyone,<\/p>\n<p>I\u2019m using the <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/other\/metaflow\">MetaFlow Integration with WandB<\/a>. I understand the decorator will help me log instance variables (e.g., pandas data frames) as artifacts to WandB automatically.<\/p>\n<p>In one of Metaflow steps, I\u2019m trying to write a set of arrow files to disk and then upload these to an artifact with WandB. To do such I must run:<\/p>\n<pre><code class=\"lang-auto\">run.log_artifact(artifact)\n<\/code><\/pre>\n<p>Is there an easy way to extract \/ get the <a href=\"https:\/\/github.com\/wandb\/client\/blob\/master\/wandb\/integration\/metaflow\/metaflow.py#L278\" rel=\"noopener nofollow ugc\">run object created by the wandb metaflow decorator<\/a> so that it can be used to log this artifact explicitly?<\/p>\n<p>Thanks!<br>\nSahil<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Logging dictionary from Pytorch Lightning Logger",
        "Question_link":"https:\/\/community.wandb.ai\/t\/logging-dictionary-from-pytorch-lightning-logger\/725",
        "Question_created_time":"2021-09-21T16:36:43.176Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":324,
        "Question_body":"<p>When logging using the W&amp;B Callback, a call to <code>self.log()<\/code> will only take scalars (the call won\u2019t fail, it just won\u2019t show up in the W&amp;B plots). I\u2019d like to to something like the following:<\/p>\n<p>Using the standard PL log call:<br>\n<code>self.log(name='my_metrics', value={ 'a': 1, 'b':2} ).<\/code><br>\nand have nice plots show up auto-magically with all these plots on the same axis or in the same tab.<\/p>\n<p>Currently I am simply looping through my dict and logging them as scalars manually<\/p>\n<p>Note I would like to avoid unpacking the the W&amp;B logger from the PL Trainer, and calling it directly.<br>\n<code>wandb = self.logger.experiment<\/code><\/p>\n<p>I haven\u2019t tested this, but I assume it would work. But it would make my code messy and dependent on knowledge of whether I was using W&amp;B for a particular run.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"[BUG] Config param name inclusing a dot",
        "Question_link":"https:\/\/community.wandb.ai\/t\/bug-config-param-name-inclusing-a-dot\/916",
        "Question_created_time":"2021-10-11T14:42:56.319Z",
        "Question_answer_count":4,
        "Question_score_count":0,
        "Question_view_count":332,
        "Question_body":"<p>I have a config param with the following name:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555.png\" data-download-href=\"\/uploads\/short-url\/dqR4ex4NYNlpeVlIDbLPCuUMzPL.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555_2_690x152.png\" alt=\"image\" data-base62-sha1=\"dqR4ex4NYNlpeVlIDbLPCuUMzPL\" width=\"690\" height=\"152\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555_2_690x152.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5e256d34409e2dff601a90b30f46f777c31ca555_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">893\u00d7198 10.5 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>However, when I call him in my graph, there is a bug and the graph stays white:<\/p>            <div class=\"onebox imgur-album\">\n              <a href=\"https:\/\/imgur.com\/a\/EIML6VO\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n                <span class=\"outer-box\" style=\"width:600px\">\n                  <span class=\"inner-box\">\n                    <span class=\"album-title\">[Album] imgur.com<\/span>\n                  <\/span>\n                <\/span>\n                <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2f6fef7dba514e4297115fb6caaa0d05a941ddf4.jpeg\" title=\"imgur.com\" height=\"315\" width=\"600\">\n              <\/a>\n            <\/div>\n",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Set x axis expression for multiple plots at once",
        "Question_link":"https:\/\/community.wandb.ai\/t\/set-x-axis-expression-for-multiple-plots-at-once\/978",
        "Question_created_time":"2021-10-14T12:54:16.421Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":293,
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f.png\" data-download-href=\"\/uploads\/short-url\/l2VpWvmsWouis0P14ZE8w2DtEWr.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f_2_638x500.png\" alt=\"image\" data-base62-sha1=\"l2VpWvmsWouis0P14ZE8w2DtEWr\" width=\"638\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f_2_638x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/9382546d321c088f70d9f648e6c6f42f91eff90f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">693\u00d7543 28.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nI use this feature to show Epoch instead of Iter on the X axis.<br>\nIt\u2019s a bit laborious to go trough all my plots to set this expression manually.<\/p>\n<p>Is there a workaround ?<br>\nOtherwise, please flag this with [feature request]<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Reopen wandb backend process after finish",
        "Question_link":"https:\/\/community.wandb.ai\/t\/reopen-wandb-backend-process-after-finish\/943",
        "Question_created_time":"2021-10-13T14:11:25.843Z",
        "Question_answer_count":6,
        "Question_score_count":8,
        "Question_view_count":375,
        "Question_body":"<p>Hello,<br>\nI am running  wandb with pytorch Lit. After running the training mode and log all the metric in the dashboard, I want to close the session by running <code>wandb.finish()<\/code>. After that I want to execute the test mode so I ativated the mode by <code>trainer.test(...)<\/code> but i get an error says \u201cThe wandb backend process has shutdown\u201d. it seems logic to me that it can not log to the project to save the test loss because I already close it.<br>\nMy question here, is there any possible way to reopen the same session with the same project name and ID ?<br>\nFYI, i uses the resume mode with the same name and ID but didn\u2019t not work wit me. Each time, it create a new run but in the same project.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Two y-axis chart plotting",
        "Question_link":"https:\/\/community.wandb.ai\/t\/two-y-axis-chart-plotting\/939",
        "Question_created_time":"2021-10-12T23:20:43.431Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":433,
        "Question_body":"<p>Hello, I was wondering if it is possible to create a custom chart with two axis in y direction, such that the first one has a value scale and the other have another scale.<\/p>\n<p>Thank you very much in advance!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Integrate a new plugin to Weights & Biases",
        "Question_link":"https:\/\/community.wandb.ai\/t\/integrate-a-new-plugin-to-weights-biases\/792",
        "Question_created_time":"2021-09-27T07:42:46.426Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":284,
        "Question_body":"<p>Hello,<\/p>\n<p>What is the best way to integrate a new plugin (that compares two runs) in weights &amp; biases interface ?<\/p>\n<p>Best,<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Make user admin for trial",
        "Question_link":"https:\/\/community.wandb.ai\/t\/make-user-admin-for-trial\/826",
        "Question_created_time":"2021-10-01T00:40:01.825Z",
        "Question_answer_count":6,
        "Question_score_count":6,
        "Question_view_count":313,
        "Question_body":"<p>Hi!<\/p>\n<p>I\u2019m trialing wanb for my company to see if its something we\u2019re interested in using.  My account is a \u201cmember\u201d account even though i\u2019m the one who created the Team.  I\u2019d like to invite other team members to my team but because my user isn\u2019t \u201cadmin\u201d status I cannot.  How can I get my team members added to the wand team I created?<\/p>\n<p>Thank you,<br>\nBlake<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Feature request: adding zip files to reports",
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-adding-zip-files-to-reports\/877",
        "Question_created_time":"2021-10-06T21:26:06.071Z",
        "Question_answer_count":5,
        "Question_score_count":4,
        "Question_view_count":319,
        "Question_body":"<p>I often want to upload zip files with a bunch of info from experiments to wandb but currently the web UI does not respond to this. May we have this as a feature?<\/p>\n<hr>\n<p>originally asked as a help question but realized it was likely a feature request or tech support question. Original question: <a href=\"https:\/\/community.wandb.ai\/t\/how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui\/840\/2\" class=\"inline-onebox\">How do I upload artifacts (e.g. zip files) manually in the website GUI? - #2 by brando<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Access denied",
        "Question_link":"https:\/\/community.wandb.ai\/t\/access-denied\/870",
        "Question_created_time":"2021-10-05T19:43:49.810Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":328,
        "Question_body":"<p>I created a hello world example on Jupiter lab, and when I use Iframe to display the wand curves I get a screen with access denied, even though I am already signed in. Could you please help solve this problem?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How do I upload artifacts (e.g. zip files) manually in the website GUI?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui\/840",
        "Question_created_time":"2021-10-01T18:03:05.957Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":542,
        "Question_body":"<p>I just want to upload artifacts manually place and drop and the end of the project. I have 2 zip files. How do I do that?<\/p>\n<p>Ideally, I want to avoid writing code. I tried dropping it into a report but the report didn\u2019t do anything when I dropped my zip files.<\/p>\n<hr>\n<p>also, the artifacts guide seems unncesserily long and not explain the most basic questions imho. e.g.<\/p>\n<ol>\n<li>Are we suppose to upload artifacts on every run?<\/li>\n<li>how do we make sure we don\u2019t double upload data?<\/li>\n<li>how does wandb version to avoid duplicate data uploaded<\/li>\n<\/ol>\n<p>perhaps a shorter tutorial that is more to the point would be nice, especially explaining the expected\/common workflow with artifacts.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Artifact.add_reference('s3:\/\/...'): error in finding credentials",
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifact-add-reference-s3-error-in-finding-credentials\/866",
        "Question_created_time":"2021-10-05T02:48:57.833Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":337,
        "Question_body":"<p>Hi, I am trying to track an artifact that lives in AWS S3. I have a <code>~\/.aws\/credentials<\/code> file with two profiles and I would like to talk to AWS and store the reference with one of those profiles. I rather not use environment variables (i.e. AWS_ACCESS_KEY_ID, etc), but stick with the credentials folder and maintain the existing profiles. Are there any ways of making this work? Thanks!<\/p>\n<p>Problem code:<\/p>\n<pre><code class=\"lang-auto\">    raw_data_uri = os.path.join('s3:\/\/', cfg.bucket_name, cfg.prefix)\n    bucket = S3Bucket(cfg.bucket_name, cfg.aws_profile) # my handler to talk to S3\n    num_items = len(bucket.ls(cfg.prefix))\n    \n    with wandb.init(project=cfg.project, job_type=cfg.job_type, name=cfg.run_stamp) as run:\n        artifact = wandb.Artifact(name='raw_data', type='raw_data',\n                                    metadata={\n                                        'aws_profile': cfg.aws_profile,\n                                        'num_items': num_items\n                                        })\n            \n        artifact.add_reference(raw_data_uri)\n        run.log_artifact(artifact)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code class=\"lang-auto\">botocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"HuggingFace Trainer Doesn't Log Validation Loss to WandB",
        "Question_link":"https:\/\/community.wandb.ai\/t\/huggingface-trainer-doesnt-log-validation-loss-to-wandb\/862",
        "Question_created_time":"2021-10-04T17:58:12.447Z",
        "Question_answer_count":4,
        "Question_score_count":5,
        "Question_view_count":440,
        "Question_body":"<p>I\u2019m trying to use HuggingFace\u2019s Trainer API to fine-tune BERT:<\/p>\n<pre><code class=\"lang-auto\">    # Skip trainer till we can figure out how to specify MSE as loss\n    trainer = Trainer(\n        model=model,  # the instantiated \ud83e\udd17 Transformers model to be trained\n        args=training_args,  # training arguments, defined above\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset)\n\n    trainer.train()\n\n<\/code><\/pre>\n<p>However, the validation loss is not logged to WandB:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bd50bff34014905293a02009ee020924aed36c37.png\" data-download-href=\"\/uploads\/short-url\/r0LflG5PietHrlamoq63Tc6RaLR.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bd50bff34014905293a02009ee020924aed36c37_2_690x132.png\" alt=\"image\" data-base62-sha1=\"r0LflG5PietHrlamoq63Tc6RaLR\" width=\"690\" height=\"132\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bd50bff34014905293a02009ee020924aed36c37_2_690x132.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bd50bff34014905293a02009ee020924aed36c37.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/bd50bff34014905293a02009ee020924aed36c37.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/bd50bff34014905293a02009ee020924aed36c37_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1015\u00d7195 6.61 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>This problem was observed by someone else on the HuggingFace forum: <a href=\"https:\/\/discuss.huggingface.co\/t\/no-loss-being-logged-when-running-mlm-script-colab\/8134\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">No loss being logged, when running MLM script (Colab) - \ud83e\udd17Transformers - Hugging Face Forums<\/a><\/p>\n<p>Can someone please tell me how to ensure the validation loss is logged to WandB?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Stop button",
        "Question_link":"https:\/\/community.wandb.ai\/t\/stop-button\/614",
        "Question_created_time":"2021-09-15T13:53:00.302Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":300,
        "Question_body":"<p>Hi<br>\nI\u2019m running training on aws batch (on docker image) and I want to be able to stop the run manually using the button on the wandb and ideally therefore stop that aws batch instance (since the command finished executing).<br>\nThe training runs are using bot key that was given to me. And when I click the stop button (on website, using my account), it says I can\u2019t view the page.<br>\nIs it a permission issue? Will it work as I described?<br>\nThanks<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"W&B support vs help?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/w-b-support-vs-help\/844",
        "Question_created_time":"2021-10-01T19:15:24.242Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":309,
        "Question_body":"<p>what is the difference between the categories?<\/p>\n<p>which one to use?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to have wandb print how long experiment ran on console?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-have-wandb-print-how-long-experiment-ran-on-console\/845",
        "Question_created_time":"2021-10-01T19:16:30.901Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":265,
        "Question_body":"<p>I always print this string:<\/p>\n<pre><code class=\"lang-auto\">wandb: Find logs at: .\/wandb\/run-20211001_135946-18loi2se\/logs\/debug.log\nwandb: \n-- wandb finished\ntime_passed_msg = time passed: hours:0.0714601335922877, minutes=4.287608015537262, seconds=257.2564809322357\n<\/code><\/pre>\n<p>but it\u2019s sort of annying if I am already running <code>wandb.finish<\/code>. Is it possible to have wandb print it for me? (especially to save it on my wandb log\/print std out file?)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is wandb suppose to get pycharm stuck?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-wandb-suppose-to-get-pycharm-stuck\/842",
        "Question_created_time":"2021-10-01T18:55:45.923Z",
        "Question_answer_count":1,
        "Question_score_count":1,
        "Question_view_count":313,
        "Question_body":"<p>I ran <code>wand.finish()<\/code> but it doesn\u2019t seem to finish properly (e.g. not showing the links to my runs etc):<\/p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish, PID 86593... (success).\nInvalidVersionSpec: Invalid version '1&lt;2': invalid character(s)\n<\/code><\/pre>\n<p>why is wandb not interacting well with pycharm?<\/p>\n<p>or is it just taking time because it\u2019s uploading artifacts?<\/p>\n<p>script<\/p>\n<pre><code class=\"lang-auto\">#%%\n\"\"\"\nI think artifacts are used per run or something but I will just create one run upload of the zip of the data and\nfigs I made. Then create a report that links to the artifact run.\n\nrefs:\nhttps:\/\/docs.wandb.ai\/guides\/artifacts\nhttps:\/\/community.wandb.ai\/t\/how-does-one-manually-upload-a-single-artifact\/841\n\nfailed artifact push: https:\/\/wandb.ai\/brando\/meta-learning-neurips-workshop\/runs\/221fe0xw\n\"\"\"\nfrom argparse import Namespace\nfrom pathlib import Path\n\nimport wandb\n\nimport uutils\n\n# uutils.setup_args_for_experiment() does the following:\n# if hasattr(args, 'log_to_wandb'):\n#     if args.log_to_wandb:\n#         # os.environ['WANDB_MODE'] = 'offline'\n#         import wandb\n#\n#         print(f'{wandb=}')\n#\n#         # - set run name\n#         run_name = None\n#         # if in cluster use the cluster jobid\n#         if hasattr(args, 'jobid'):\n#             # if jobid is actually set to something, use that as the run name in ui\n#             if args.jobid is not None and args.jobid != -1 and str(args.jobid) != '-1':\n#                 run_name: str = f'jobid={str(args.jobid)}'\n#         # if user gives run_name overwrite that always\n#         if hasattr(args, 'run_name'):\n#             run_name = args.run_name if args.run_name is not None else run_name\n#         args.run_name = run_name\n#         # - initialize wandb\n#         wandb.init(project=args.wandb_project,\n#                    entity=args.wandb_entity,\n#                    # job_type=\"job_type\",\n#                    name=run_name,\n#                    group=args.experiment_name\n#                    )\n#         wandb.config.update(args)\n\ndef get_args_for_experiment() -&gt; Namespace:\n    # - get my default args\n    args = uutils.parse_basic_meta_learning_args()\n    args.log_to_wandb = False\n    args.log_to_wandb = True\n    args.wandb_project = 'meta-learning-neurips-workshop'\n    args.experiment_name = 'upload-of-zip-files-synthetic-data-set-all-figs-and-hps'\n    args.run_name = f'{args.experiment_name}_1'\n    args = uutils.setup_args_for_experiment(args)\n    return args\n\ndef get_zips_paths():\n    log_root: Path = Path('~\/Desktop\/').expanduser()\n    dataset_filename: str = 'dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip'\n    all_figs_zip_filename: str = 'all_ckpts_and_figures.zip'\n    return log_root, dataset_filename, all_figs_zip_filename\n\n# wandb.init(job_type=\"dataset-creation\")  # done in uutils.setup_args_for_experiment()\nprint('-- getting args')\nargs = get_args_for_experiment()\n\n# https:\/\/docs.wandb.ai\/ref\/python\/artifact for Artifact api\nprint('-- creating artifacts')\nartifact_data = wandb.Artifact('dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip', type='dataset-as-zip')\nartifact_figs = wandb.Artifact('all_figs_for_paper', type='figs-as-zip')\n\n# - get zip files to log as artifacts\nprint('-- getting path to zipz')\nlog_root, dataset_filename, all_figs_zip_filename = get_zips_paths()\n\n# todo - Imagine more lines of text were added to this text file: (what does this mean?)\nprint('-- wandb artifact logging1 (artifact_data.add_file)')\n# artifact.add_file('my-dataset.txt')\nartifact_data.add_file(log_root \/ dataset_filename)\nartifact_figs.add_file(log_root \/ all_figs_zip_filename)\n\n# Log that artifact, and we identify the changed file\nprint('-- wandb artifact logging2 (wandb.log_artifact)')\nwandb.log_artifact(artifact_data)\nwandb.log_artifact(artifact_figs)\n# todo - Now you have a new version of the artifact, tracked in W&amp;B (don't get it)\n\n# - wandb\nif args.log_to_wandb:\n    print('-- finishing wandb')\n    wandb.finish()\n    print('-- wandb finished')\n\nprint('Done!\\a')\n<\/code><\/pre>\n<p>smallish files ~200mb ~100mb<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one manually upload a single artifact?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-manually-upload-a-single-artifact\/841",
        "Question_created_time":"2021-10-01T18:35:03.047Z",
        "Question_answer_count":3,
        "Question_score_count":0,
        "Question_view_count":719,
        "Question_body":"<p>I have two zip files I want to upload as an artifact (or in any way) to wanbd. I tried:<\/p>\n<pre><code class=\"lang-auto\">#%%\n\"\"\"\nI think artifacts are used per run or something but I will just create one run upload of the zip of the data and\nfigs I made. Then create a report that links to the artifact run.\n\nrefs:\nhttps:\/\/docs.wandb.ai\/guides\/artifacts\nhttps:\/\/community.wandb.ai\/t\/how-does-one-manually-upload-a-single-artifact\/841\n\nfailed artifact push: https:\/\/wandb.ai\/brando\/meta-learning-neurips-workshop\/runs\/221fe0xw\n\"\"\"\nfrom argparse import Namespace\nfrom pathlib import Path\n\nimport wandb\n\nimport uutils\n\n# uutils.setup_args_for_experiment() does the following:\n# if hasattr(args, 'log_to_wandb'):\n#     if args.log_to_wandb:\n#         # os.environ['WANDB_MODE'] = 'offline'\n#         import wandb\n#\n#         print(f'{wandb=}')\n#\n#         # - set run name\n#         run_name = None\n#         # if in cluster use the cluster jobid\n#         if hasattr(args, 'jobid'):\n#             # if jobid is actually set to something, use that as the run name in ui\n#             if args.jobid is not None and args.jobid != -1 and str(args.jobid) != '-1':\n#                 run_name: str = f'jobid={str(args.jobid)}'\n#         # if user gives run_name overwrite that always\n#         if hasattr(args, 'run_name'):\n#             run_name = args.run_name if args.run_name is not None else run_name\n#         args.run_name = run_name\n#         # - initialize wandb\n#         wandb.init(project=args.wandb_project,\n#                    entity=args.wandb_entity,\n#                    # job_type=\"job_type\",\n#                    name=run_name,\n#                    group=args.experiment_name\n#                    )\n#         wandb.config.update(args)\n\ndef get_args_for_experiment() -&gt; Namespace:\n    # - get my default args\n    args = uutils.parse_basic_meta_learning_args()\n    args.log_to_wandb = False\n    args.log_to_wandb = True\n    args.wandb_project = 'meta-learning-neurips-workshop'\n    args.experiment_name = 'upload-of-zip-files-synthetic-data-set-all-figs-and-hps'\n    args.run_name = f'{args.experiment_name}_1'\n    args = uutils.setup_args_for_experiment(args)\n    return args\n\ndef get_zips_paths():\n    log_root: Path = Path('~\/Desktop\/').expanduser()\n    dataset_filename: str = 'dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip'\n    all_figs_zip_filename: str = 'all_ckpts_and_figures.zip'\n    return log_root, dataset_filename, all_figs_zip_filename\n\n# wandb.init(job_type=\"dataset-creation\")  # done in uutils.setup_args_for_experiment()\nargs = get_args_for_experiment()\n\n# https:\/\/docs.wandb.ai\/ref\/python\/artifact for Artifact api\nartifact_data = wandb.Artifact('dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip', type='dataset-as-zip')\nartifact_figs = wandb.Artifact('all_figs_for_paper', type='figs-as-zip')\n\n# - get zip files to log as artifacts\nlog_root, dataset_filename, all_figs_zip_filename = get_zips_paths()\n\n# todo - Imagine more lines of text were added to this text file: (what does this mean?)\n# artifact.add_file('my-dataset.txt')\nartifact_data.add_file(log_root \/ dataset_filename)\nartifact_figs.add_file(log_root \/ all_figs_zip_filename)\n\n# Log that artifact, and we identify the changed file\nwandb.log_artifact(artifact_data)\nwandb.log_artifact(artifact_figs)\n# todo - Now you have a new version of the artifact, tracked in W&amp;B (don't get it)\n\n# - wandb\nif args.log_to_wandb:\n    wandb.finish()\n\nprint('Done!')\n<\/code><\/pre>\n<h2>\n<a name=\"but-my-run-is-emptyhow-do-i-upload-my-two-zip-files-to-wandb-ideally-using-artifacts-i-suppose-1\" class=\"anchor\" href=\"#but-my-run-is-emptyhow-do-i-upload-my-two-zip-files-to-wandb-ideally-using-artifacts-i-suppose-1\"><\/a>but my run is empty\u2026how do I upload my two zip files to wandb? (ideally using artifacts I suppose)<\/h2>\n<p>based from<\/p>\n<pre><code class=\"lang-auto\">wandb.init()\n\nartifact = wandb.Artifact('mnist', type='dataset')\nartifact.add_dir('mnist\/')\nwandb.log_artifact(artifact)\n<\/code><\/pre>\n<p>and<\/p>\n<pre><code class=\"lang-auto\">run = wandb.init(job_type=\"dataset-creation\")\nartifact = wandb.Artifact('my-dataset', type='dataset')\n# Imagine more lines of text were added to this text file:\nartifact.add_file('my-dataset.txt')\n# Log that artifact, and we identify the changed file\nrun.log_artifact(artifact)\n# Now you have a new version of the artifact, tracked in W&amp;B\n<\/code><\/pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/docs.wandb.ai\/guides\/artifacts\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/362;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts\" target=\"_blank\" rel=\"noopener\">Data + Model Versioning<\/a><\/h3>\n\n  <p>Dataset versioning, model versioning, pipeline tracking with flexible and lightweight building blocks<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/docs.wandb.ai\/ref\/python\/artifact\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/artifact\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/362;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/docs.wandb.ai\/ref\/python\/artifact\" target=\"_blank\" rel=\"noopener\">wandb.Artifact<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to include citation of wandb easily with zotero or mendeley?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-include-citation-of-wandb-easily-with-zotero-or-mendeley\/772",
        "Question_created_time":"2021-09-25T18:54:27.622Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":349,
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019d like to help support wandb and I think its important to make it as trivial as possible for user to cite wandb as thats valueble - in the spirit of how amazon makes it trivial to buy things with one click. I believe most of us researchers use zotero or mendeley. I usually go to a webpage and then download the citation automatically that I use for all my future papers - with mendeley or zotero. I suggest something like that is done for wandb. Perhaps with a whitepaper report (like tensorflow has) and then we can download the citation for it.<\/p>\n<p>For now I am just copy pasting this<\/p>\n<pre><code class=\"lang-auto\">@misc{wandb,\ntitle = {Experiment Tracking with Weights and Biases},\nyear = {2020},\nnote = {Software available from wandb.com},\nurl={https:\/\/www.wandb.com\/},\nauthor = {Biewald, Lukas},\n}\n<\/code><\/pre>\n<p>but I don\u2019t think copy pasting this is a good long term solution to promote\/support wanbd.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Cannot use artifact when in offline mode",
        "Question_link":"https:\/\/community.wandb.ai\/t\/cannot-use-artifact-when-in-offline-mode\/739",
        "Question_created_time":"2021-09-22T12:25:02.310Z",
        "Question_answer_count":8,
        "Question_score_count":3,
        "Question_view_count":374,
        "Question_body":"<p>Hi,<\/p>\n<p>How can I use artifacts without actually enabling wandb syncing? Sometimes I want just to play around my notebook without logging anything, but using data\/models logged as artifacts in my project. I think I can do it via cli but I would like to know if there\u2019s something I\u2019m missing in the API.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Span filtering prodigy datasets using W&B Tables",
        "Question_link":"https:\/\/community.wandb.ai\/t\/span-filtering-prodigy-datasets-using-w-b-tables\/646",
        "Question_created_time":"2021-09-16T12:37:01.780Z",
        "Question_answer_count":3,
        "Question_score_count":4,
        "Question_view_count":305,
        "Question_body":"<p>Hi! I am currently testing the new prodigy integration to visualize NER datasets and it works great, thank you! But I have some problems.<br>\nI would like to filter  <code>row[\"spans\"][\"label\"] <\/code> by the special entities and I have problems here. My use case:<\/p>\n<ul>\n<li>Which texts contain only people (PERSON)? Which organisations (ORG) or locations (LOCATION)? How many people do I find in total?<\/li>\n<li>I would like to create new rows\/columns to visualize the results.<\/li>\n<\/ul>\n<p>My problem: I can\u2019t manage to filter according to the entities. What am I doing wrong?<br>\nYour example here is also ok for the test:<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/kshen\/prodigy\/reports\/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7a7a7077833cb4ec4be6e63ad7c2db322d3e15a6.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/kshen\/prodigy\/reports\/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\" target=\"_blank\" rel=\"noopener\" title=\"02:05PM - 17 August 2021\">W&amp;B \u2013 17 Aug 21<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6f5cc42f5be5838eaa024b6166848b71312afb4e.png\" class=\"thumbnail onebox-avatar\" width=\"300\" height=\"300\">\n\n<h3><a href=\"https:\/\/wandb.ai\/kshen\/prodigy\/reports\/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\" target=\"_blank\" rel=\"noopener\">Visualizing Prodigy Datasets Using W&amp;B Tables<\/a><\/h3>\n\n  <p>Use the W&amp;B\/Prodigy integration to upload your Prodigy annotated datasets to W&amp;B for easier visualization. Made by Kevin Shen using Weights &amp; Biases<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0.png\" data-download-href=\"\/uploads\/short-url\/quowLbwH5KL7ZM97JjbPxcjnfNe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_517x186.png\" alt=\"image\" data-base62-sha1=\"quowLbwH5KL7ZM97JjbPxcjnfNe\" width=\"517\" height=\"186\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_517x186.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_775x279.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_1034x372.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1762\u00d7637 64 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thank you<br>\nAlfred<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clarification on Early Termination (Hyperband)",
        "Question_link":"https:\/\/community.wandb.ai\/t\/clarification-on-early-termination-hyperband\/673",
        "Question_created_time":"2021-09-17T18:57:22.768Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":303,
        "Question_body":"<p>Looking to run a large HP Sweep. I\u2019m using Pytorch Lightning (PL) for the model training and W&amp;B for experiment management. I have already have it up and running (using the WandbLogger callback for PL) and I\u2019m hoping to utilize the Early Termination feature that W&amp;B provides, but I find the documentation a little confusing. I\u2019d like to do something as simple as: Check some metric at ~[100, 500, 2500, \u2026] epochs and terminate those who aren\u2019t performing well.<\/p>\n<p>The documentation for HyperBand says:<\/p>\n<blockquote>\n<p>Brackets are based on the number of <em>logged<\/em> iterations, i.e. elements in the run\u2019s history. Depending on where you are calling <code>wandb.log<\/code> , these iterations may correspond to steps, epochs, or something in between. The numerical value of the step counter is not used in bracket calculations.<\/p>\n<\/blockquote>\n<p>I\u2019m having trouble deciphering this.<\/p>\n<p>For example, in my case I only check (and log) validation stuff every 10 epochs (check_val_every_n_epoch=10 is fed to the PL trainer) to save compute. I also log things at the end of a train batch, train epoch, and validation epoch. I log both dicts (in PL: self.log_dict() ) and values (self.log()). In some cases the logger flag is False in the call: self.log( , logger=False) or self.log_dict( , logger=False).<\/p>\n<p>So how is the number of logged iterations computed? How do I go about using this to achieve my original goal: check some metric every [100, 500, 2500, \u2026] epochs and terminate the \u2018bad\u2019 ones (as per the HyperBand alg)?<\/p>\n<p>Thanks in advance,<br>\nMax<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Change pointsizes, background, etc. in Object3D objects",
        "Question_link":"https:\/\/community.wandb.ai\/t\/change-pointsizes-background-etc-in-object3d-objects\/564",
        "Question_created_time":"2021-09-14T10:49:01.633Z",
        "Question_answer_count":3,
        "Question_score_count":1,
        "Question_view_count":293,
        "Question_body":"<p>I am logging pointclouds using numpy arrays following the shape [x,y,z,class], all integers.<br>\nLogging works, but the points are tiny and barely visible. Is it possible to make them larger?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What is the recommended way to use the name value in wandb.init?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-is-the-recommended-way-to-use-the-name-value-in-wandb-init\/721",
        "Question_created_time":"2021-09-20T22:16:35.961Z",
        "Question_answer_count":2,
        "Question_score_count":4,
        "Question_view_count":319,
        "Question_body":"<p>I usually track runs based on the job id of the HPC. So I was thinking I wanted to tack that value to the end to the nice 2 word name that wandb gives. How do I do that?<\/p>\n<p>Also, I am interested in knowing the recommended way to name runs or the common way wandb users, developers etc use this.<\/p>\n<p>note: I am already using the config to track the hyperparams and the group name to group similar experiments. I don\u2019t usually use jobtype actually.<\/p>\n<hr>\n<p>current script:<\/p>\n<pre><code class=\"lang-auto\">    if hasattr(args, 'log_to_wandb'):\n        if args.log_to_wandb:\n            # os.environ['WANDB_MODE'] = 'offline'\n            import wandb\n\n            # - experiment name\n            experiment_name = args.wandb_group\n            # - set run name\n            run_name = None\n            if hasattr(args, 'jobid'):\n                if args.jobid is not None:\n                    run_name: str = f'jobid={str(args.jobid)}'\n            # - initialize wandb\n            wandb.init(project=args.wandb_project,\n                       entity=args.wandb_entity,\n                       # job_type=\"job_type\",\n                       name=run_name,\n                       group=experiment_name\n                       )\n            wandb.config.update(args)\n<\/code><\/pre>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Structuring Code For Interruptible session",
        "Question_link":"https:\/\/community.wandb.ai\/t\/structuring-code-for-interruptible-session\/697",
        "Question_created_time":"2021-09-18T13:43:52.591Z",
        "Question_answer_count":2,
        "Question_score_count":5,
        "Question_view_count":362,
        "Question_body":"<p>Looking to scale up my project to some cloud service, and it seems the prices are much cheaper for interruptible sessions.<\/p>\n<p>How do I use W&amp;B for an experiment (either a single train run or a HP sweep) in such an environment? Is there anything fancy needed to re-start a sweep where it left off?<\/p>\n<p>I\u2019m using Pytorch Lightning for the model\/trainer and hoping to use AWS\/Grid.ai\/other cloud service to scale up.<\/p>\n<p>Thanks,<br>\nMax<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one plot plots with error bars?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-plot-plots-with-error-bars\/651",
        "Question_created_time":"2021-09-16T18:10:46.597Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":720,
        "Question_body":"<p>How does one plot plots with error bars?<\/p>\n<p>I saw it was mentioned here: <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/custom-charts\">https:\/\/docs.wandb.ai\/ref\/app\/features\/custom-charts<\/a> but there aren\u2019t any concrete examples. What is a concrete example that is quick and simple to use?<\/p>\n<p>Btw, I am using custom steps\u2026 e.g. <a href=\"https:\/\/colab.research.google.com\/drive\/1uegSY1HRGlKfK-07Uuw-ZxPJsNA9BN_9?usp=sharing\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is wanbd giving me a multiprocessing error when my code is serially running?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-wanbd-giving-me-a-multiprocessing-error-when-my-code-is-serially-running\/655",
        "Question_created_time":"2021-09-16T21:34:45.267Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":719,
        "Question_body":"<p>I have a multiprocessing error but my code is not multiprocessing (its running serially) - even the pytorch dataloader as <code>num_workers=0<\/code> but I get this error:<\/p>\n<pre><code class=\"lang-auto\">N\/A% (0 of 100) |         | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s\/itTraceback (most recent call last):\n  File \"\/Users\/brando\/anaconda3\/envs\/metalearning\/lib\/python3.9\/multiprocessing\/spawn.py\", line 126, in _main\n    self = reduction.pickle.load(from_parent)\n  File \"\/Users\/brando\/anaconda3\/envs\/metalearning\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 110, in __setstate__\n    self._semlock = _multiprocessing.SemLock._rebuild(*state)\nFileNotFoundError: [Errno 2] No such file or directory\npython-BaseException\nTraceback (most recent call last):\n  File \"\/Users\/brando\/anaconda3\/envs\/metalearning\/lib\/python3.9\/multiprocessing\/spawn.py\", line 126, in _main\n    self = reduction.pickle.load(from_parent)\n  File \"\/Users\/brando\/anaconda3\/envs\/metalearning\/lib\/python3.9\/multiprocessing\/synchronize.py\", line 110, in __setstate__\n    self._semlock = _multiprocessing.SemLock._rebuild(*state)\nFileNotFoundError: [Errno 2] No such file or directory\npython-BaseException\n<\/code><\/pre>\n<p>How do I start debugging this?<\/p>\n<hr>\n<p>I am running this in pycharm. Not sure what else to say, will think about it\u2026<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Previsualization of wandb.plot before logging it",
        "Question_link":"https:\/\/community.wandb.ai\/t\/previsualization-of-wandb-plot-before-logging-it\/664",
        "Question_created_time":"2021-09-17T10:02:55.308Z",
        "Question_answer_count":3,
        "Question_score_count":2,
        "Question_view_count":259,
        "Question_body":"<p>Hi,<\/p>\n<p>Is there any way to previsualize a wandb plot before logging it to the project?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How does one have high disk utilization in pytorch?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-have-high-disk-utilization-in-pytorch\/553",
        "Question_created_time":"2021-09-13T23:18:34.171Z",
        "Question_answer_count":2,
        "Question_score_count":4,
        "Question_view_count":296,
        "Question_body":"<p>I saw that being mentioned here <a href=\"https:\/\/youtu.be\/G7GH0SeNBMA?t=1141\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">\ud83d\udd25 Integrate Weights &amp; Biases with PyTorch - YouTube<\/a> so I was curious - how do we have the data loaders in pytorch to have high disk utilization e.g. is increasing the batch size, num_workers the way to go or something else?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is the InvalidVersionSpec: Invalid version '1<2': invalid character(s) to wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-the-invalidversionspec-invalid-version-1-2-invalid-character-s-to-wandb\/556",
        "Question_created_time":"2021-09-13T23:21:10.538Z",
        "Question_answer_count":2,
        "Question_score_count":1,
        "Question_view_count":307,
        "Question_body":"<p>I noticed that all my scripts that have wandb started to give this error:<\/p>\n<pre><code class=\"lang-auto\">InvalidVersionSpec: Invalid version '1&lt;2': invalid character(s)\n<\/code><\/pre>\n<p>and was wondering if this is something that others have experienced when incorporating wandb and how do you remove it?<\/p>\n<p>Thanks in advance! wandb is pretty cool <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Molecule Visualizations",
        "Question_link":"https:\/\/community.wandb.ai\/t\/molecule-visualizations\/413",
        "Question_created_time":"2021-09-02T22:48:55.192Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":277,
        "Question_body":"<p>I\u2019ve been looking at the wandb.Molecule object and it looks awesome! I\u2019d like to use it for small molecules, but converting molecules to one of the specified file types is a bit of a pain point for me. Any chance of one day being able to create Molecule objects straight from a SMILES string?<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Couldn't make Wandb run on a TPU",
        "Question_link":"https:\/\/community.wandb.ai\/t\/couldnt-make-wandb-run-on-a-tpu\/633",
        "Question_created_time":"2021-09-16T01:57:43.951Z",
        "Question_answer_count":1,
        "Question_score_count":0,
        "Question_view_count":496,
        "Question_body":"<p>I tried a lot of things but was not able to run Wandb on TPU.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626.png\" data-download-href=\"\/uploads\/short-url\/feCu0Sg0RhG0KlIVQ3CeQYH2Tlk.png?dl=1\" title=\"Screenshot from 2021-09-15 21-32-25\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_472x500.png\" alt=\"Screenshot from 2021-09-15 21-32-25\" data-base62-sha1=\"feCu0Sg0RhG0KlIVQ3CeQYH2Tlk\" width=\"472\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_472x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_708x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2021-09-15 21-32-25<\/span><span class=\"informations\">807\u00d7854 105 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p><a href=\"https:\/\/www.kaggle.com\/harveenchadha\/chaii-tpu-train-nfold-xlm-hf-tf-data-extra?scriptVersionId=74865075\" rel=\"noopener nofollow ugc\">Kernel<\/a><\/p>\n<p>If there is something wrong in my code structure please let me know <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> . Have raised an issue on <a href=\"https:\/\/github.com\/wandb\/client\/issues\/2672\" rel=\"noopener nofollow ugc\">github<\/a>  as well.<\/p>\n<p>Cheers!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What happens if the code crashes in the middle and there was no time to fo a .finish?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-happens-if-the-code-crashes-in-the-middle-and-there-was-no-time-to-fo-a-finish\/508",
        "Question_created_time":"2021-09-10T19:47:51.423Z",
        "Question_answer_count":6,
        "Question_score_count":9,
        "Question_view_count":1755,
        "Question_body":"<p>I use DDP a lot and was worried something bad might happen with wandb if my code crashes in the middle.<\/p>\n<p>What happens if the code crashes in the middle? Would there be further processing I need to do to make sure my computer, experiment, resources, account etc are ok?<\/p>\n<p>related: <a href=\"https:\/\/github.com\/wandb\/examples\/issues\/88\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">DDP example is not calling .finish in either log_all nor log with lead worker (rank0) \u00b7 Issue #88 \u00b7 wandb\/examples \u00b7 GitHub<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/when-is-one-supposed-to-run-wandb-watch-so-that-weights-and-biases-tracks-params-and-gradients\/518",
        "Question_created_time":"2021-09-11T17:29:44.170Z",
        "Question_answer_count":3,
        "Question_score_count":3,
        "Question_view_count":976,
        "Question_body":"<p>I run <code>wandb.watch<\/code> before my training script starts but that doesn\u2019t seem to track the histograms of weights and gradients. The script I have is nothing too complicated - just generating random data and fitting it after applying a quadratic:<\/p>\n<p>code in github: <a href=\"https:\/\/github.com\/brando90\/ultimate-utils\/blob\/master\/tutorials_for_myself\/my_wandb\/my_wandb_basic1.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">ultimate-utils\/my_wandb_basic1.py at master \u00b7 brando90\/ultimate-utils \u00b7 GitHub<\/a><\/p>\n<p>sample run: <a href=\"https:\/\/wandb.ai\/brando\/playground\/runs\/wpupxvg1\" class=\"inline-onebox\">Weights &amp; Biases<\/a><\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"What are the recommended practices on how to use DDP with wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-are-the-recommended-practices-on-how-to-use-ddp-with-wandb\/502",
        "Question_created_time":"2021-09-10T16:03:44.937Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":380,
        "Question_body":"<p>I often use distributed data laoders in pytorch DDP and often just check the rank and have only rank 0 log. Is that the recommended way to use DDP and wandb?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Separating Training From Testing",
        "Question_link":"https:\/\/community.wandb.ai\/t\/separating-training-from-testing\/353",
        "Question_created_time":"2021-08-30T11:19:16.926Z",
        "Question_answer_count":2,
        "Question_score_count":0,
        "Question_view_count":321,
        "Question_body":"<p>Hi!<\/p>\n<p>I\u2019ve got a sort of lopsided ML workflow where most of my time is spent producing plots and metrics, and my set of trained models is rarely updated. Is there a good way to separate my training code from all of my evaluation scripts?<\/p>\n<p>I\u2019d like my experiments to have the logging information from when the model was trained, but not to have to retrain it every time.<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How often to log to avoid slow down of code?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-often-to-log-to-avoid-slow-down-of-code\/516",
        "Question_created_time":"2021-09-11T17:15:14.205Z",
        "Question_answer_count":2,
        "Question_score_count":4,
        "Question_view_count":1472,
        "Question_body":"<p>Just curious, do ppl sync artifacts with wandb\u2019s cloud stuff every time they log or less often? I was curious to know if calling <code>wandb.log<\/code> or logging artifacts was slow or does it use a different process and thus slow down is minimum? \u2026 (in the past I discovered that the slowest part of my code was model checkpointing)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Is there a way to aggregate\/transform logged metrics in the UI?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-there-a-way-to-aggregate-transform-logged-metrics-in-the-ui\/488",
        "Question_created_time":"2021-09-10T04:27:41.175Z",
        "Question_answer_count":4,
        "Question_score_count":5,
        "Question_view_count":307,
        "Question_body":"<p>For example, if I logged the F1 of various classes, and I want to average them into a single plot<\/p>\n<p>Or, on a related note, how to average metrics from only certain runs (that have already been logged independently)<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Wanb.watch(model) causing CUDA OOM",
        "Question_link":"https:\/\/community.wandb.ai\/t\/wanb-watch-model-causing-cuda-oom\/499",
        "Question_created_time":"2021-09-10T15:20:05.142Z",
        "Question_answer_count":5,
        "Question_score_count":3,
        "Question_view_count":713,
        "Question_body":"<p>I am trying to use wandb gradient visualization to debug the gradient flow in my neural net on Google Colab. Without wandb logging, the training runs without error, taking up 11Gb\/16GB on the p100 gpu. However, adding this line <code>wandb.watch(model, log='all', log_freq=3)<\/code> causes a cuda out of memory error. How does wandb logging create extra gpu memory overhead? Is there some way to reduce the overhead? Thank you for your help.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to use tensorboard and wandb?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-use-tensorboard-and-wandb\/501",
        "Question_created_time":"2021-09-10T15:48:02.476Z",
        "Question_answer_count":2,
        "Question_score_count":4,
        "Question_view_count":342,
        "Question_body":"<p>I\u2019ve used tensorboard in the past but I am wondering if I really even need it anymore\u2026so my questions are:<\/p>\n<ol>\n<li>can I do everything in wandb?<\/li>\n<li>when is tensorboard useful or a good complement<\/li>\n<li>how do people use both if at all in general?<\/li>\n<\/ol>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Clarity on wandb offline",
        "Question_link":"https:\/\/community.wandb.ai\/t\/clarity-on-wandb-offline\/429",
        "Question_created_time":"2021-09-05T08:09:48.916Z",
        "Question_answer_count":3,
        "Question_score_count":5,
        "Question_view_count":370,
        "Question_body":"<p>Hi,<\/p>\n<p>I was using wandb offline on kaggle. During submission time Internet has to be disabled I noticed that even if you mention the wandb key in secrets, it won\u2019t be able to fetch it because<\/p>\n<pre><code class=\"lang-auto\">user_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\n<\/code><\/pre>\n<p>user_secrets.get_secret requires an active internet connection.<\/p>\n<p>It took me some time to find out that we can specify a dummy key like this to login in offline mode:<\/p>\n<pre><code class=\"lang-auto\">key='X'*40\nwandb.login(key=key)\n\n<\/code><\/pre>\n<p>If my understanding is correct, Can we please update the same information on wandb offline documentation page with a subsection on kaggle?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Early Stopping",
        "Question_link":"https:\/\/community.wandb.ai\/t\/early-stopping\/422",
        "Question_created_time":"2021-09-03T21:39:56.042Z",
        "Question_answer_count":7,
        "Question_score_count":13,
        "Question_view_count":1737,
        "Question_body":"<p>Hello All,<\/p>\n<p>I\u2019m configuring a hyper parameter sweep. I have training, validation, and test set.<\/p>\n<p>I\u2019d like to use the test_loss as the final metric to optimize and val_loss for early stopping.<\/p>\n<p>I don\u2019t see a place to specify a metric for early stopping. Does it default to the same metric specified for overall optimization (of hyper parameters)? If so, how can I change this?<\/p>\n<p>Thanks!<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"View-only report will still expose whole project",
        "Question_link":"https:\/\/community.wandb.ai\/t\/view-only-report-will-still-expose-whole-project\/387",
        "Question_created_time":"2021-09-01T13:49:16.357Z",
        "Question_answer_count":4,
        "Question_score_count":6,
        "Question_view_count":366,
        "Question_body":"<p>I add a report to a private project named \u201csomething\u201d and create a view-only link to this report. By clicking on the link, you can see a report. This is expected. However, by clicking the project name displayed in the navigator, you will see all information about the project, even some runs that are not expected to expose.<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"Use W&B in a Jupyter notebook to load a dataset",
        "Question_link":"https:\/\/community.wandb.ai\/t\/use-w-b-in-a-jupyter-notebook-to-load-a-dataset\/358",
        "Question_created_time":"2021-08-30T14:33:42.499Z",
        "Question_answer_count":4,
        "Question_score_count":6,
        "Question_view_count":380,
        "Question_body":"<p>Hi all,<\/p>\n<p>after a few years working in the field and suggesting people to try W&amp;B, I\u2019m excited to finally get to use it myself <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/grinning.png?v=12\" title=\":grinning:\" class=\"emoji\" alt=\":grinning:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>As part of a remote team, I\u2019m doing an EDA (Exploratory Data Analysis) in Jupyter. We\u2019re storing the dataset as a W&amp;B artifact, and I need my notebook to download the dataset locally,  so I wrote something like:<\/p>\n<pre><code class=\"lang-python\">import wandb\n\nartifact_file = \"my_entity\/my_project\/my_dataset:v0\"\ndata_dir = Path('.').parent \/ 'data'\n\n# Download data from W&amp;B\ndata = wandb.use_artifact(artifact_file)\ndata.download(root=data_dir)\n<\/code><\/pre>\n<p>However,  when I run the cells I get the error:<\/p>\n<p><code>Error: You must call wandb.init() before wandb.use_artifact()<\/code><\/p>\n<p>Two questions:<\/p>\n<ol>\n<li>how do I fix this? Would something like this suffice?<\/li>\n<\/ol>\n<pre><code class=\"lang-python\">run = wandb.init(\n        reinit=True,\n        project=\"my_project\",\n        entity=\"my_entity\",\n        group=\"eda\",\n    )\n\n# Download data from W&amp;B\ndata = wandb.use_artifact(artifact_file)\ndata.download(root=data_dir)\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Since I called <code>wandb.init()<\/code>, I guess I should call  <code>run.finish()<\/code>at the end of my EDA, otherwise the background process will run forever (or more realistically until some timeout). Now, in the usual training script, where all the code has been written and debugged before I launch the <code>wandb<\/code> background process, this would be easy: I would just add the <code>run.finish()<\/code> line at the end of the script. Here however I edit and add code while I continue with the analysis (it\u2019s Jupyter). So what\u2019s the best practice? Do I just go on with my analysis and add a <code>run.finish()<\/code> line in the last cell? Or do I call <code>run.finish()<\/code> immediately after downloading the data to the <code>data_dir<\/code>? In other words, I know the standard workflow for using W&amp;B logger and artifacts in non-interactive mode (Python scripts), but I\u2019m not so familiar with the W&amp;B workflow for interactive analyses (Jupyter notebook). Can you help me? Thanks,<\/li>\n<\/ol>\n<p>Andrea<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    },
    {
        "Question_title":"How to show \"f1_macro\" when using hugging face transformer?",
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-show-f1-macro-when-using-hugging-face-transformer\/182",
        "Question_created_time":"2021-08-24T05:16:18.516Z",
        "Question_answer_count":2,
        "Question_score_count":2,
        "Question_view_count":294,
        "Question_body":"<p>I am using hugging face transforer to fine tune a Bert model. How to show f1 with wandb?<\/p>\n<pre><code class=\"lang-auto\">training_args = TrainingArguments(\n    output_dir='.\/results_'+folder+'\/',          # output directory\n    num_train_epochs = 3,              # total # of training epochs\n    per_device_train_batch_size = n_batch,  # batch size per device during training\n    per_device_eval_batch_size = n_batch,   # batch size for evaluation               \n    weight_decay = 0.01,               # strength of weight decay\n    logging_dir ='.\/logs',            # directory for storing logs\n    learning_rate = lr,\n    #warmup_steps = 1000,  # number of warmup steps for learning rate scheduler\n    load_best_model_at_end = True,\n    evaluation_strategy = 'steps',\n    metric_for_best_model='accuracy',\n    report_to=\"wandb\",\n)\n<\/code><\/pre>\n<p>does not work<\/p>",
        "Question_closed_time":null,
        "Answer_body":null,
        "Question_self_resolution":null
    }
]